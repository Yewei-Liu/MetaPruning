[2025-04-29 21:13:23,851][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:14:03,561][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:14:12,902][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:14:21,889][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:14:30,912][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:14:40,013][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:14:42,376][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:14:49,391][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:14:58,495][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:15:07,785][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:15:17,011][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:15:22,823][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
[2025-04-29 21:15:32,098][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:16:34,886][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:16:34,945][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:16:40,713][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:14,621][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:20,891][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:17:23,878][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:17:30,197][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:17:33,278][train][INFO] - Epoch 2/100, Val Acc=0.6559, Val Loss=1.4929, lr=0.0100
[2025-04-29 21:17:38,508][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:17:42,589][train][INFO] - Epoch 3/100, Val Acc=0.6493, Val Loss=1.5717, lr=0.0100
[2025-04-29 21:17:47,386][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:17:51,819][train][INFO] - Epoch 4/100, Val Acc=0.6716, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:17:56,599][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:18:00,836][train][INFO] - Epoch 5/100, Val Acc=0.6541, Val Loss=1.5486, lr=0.0100
[2025-04-29 21:18:05,679][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:18:10,016][train][INFO] - Epoch 6/100, Val Acc=0.6787, Val Loss=1.4316, lr=0.0100
[2025-04-29 21:18:14,550][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:18:19,288][train][INFO] - Epoch 7/100, Val Acc=0.6565, Val Loss=1.5439, lr=0.0100
[2025-04-29 21:18:23,413][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:18:28,294][train][INFO] - Epoch 8/100, Val Acc=0.6681, Val Loss=1.4811, lr=0.0100
[2025-04-29 21:18:32,758][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
[2025-04-29 21:18:37,477][train][INFO] - Epoch 9/100, Val Acc=0.6764, Val Loss=1.4338, lr=0.0100
[2025-04-29 21:18:41,660][train][INFO] - Epoch 9/100, Val Acc=0.6719, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:18:46,369][train][INFO] - Epoch 10/100, Val Acc=0.6658, Val Loss=1.5013, lr=0.0100
[2025-04-29 21:18:50,398][train][INFO] - Epoch 10/100, Val Acc=0.6556, Val Loss=1.5865, lr=0.0100
[2025-04-29 21:18:55,742][train][INFO] - Epoch 11/100, Val Acc=0.6583, Val Loss=1.5674, lr=0.0100
[2025-04-29 21:18:59,225][train][INFO] - Epoch 11/100, Val Acc=0.6695, Val Loss=1.5202, lr=0.0100
[2025-04-29 21:19:04,889][train][INFO] - Epoch 12/100, Val Acc=0.6701, Val Loss=1.4855, lr=0.0100
[2025-04-29 21:19:08,313][train][INFO] - Epoch 12/100, Val Acc=0.6802, Val Loss=1.4586, lr=0.0100
[2025-04-29 21:19:14,153][train][INFO] - Epoch 13/100, Val Acc=0.6571, Val Loss=1.5929, lr=0.0100
[2025-04-29 21:19:17,399][train][INFO] - Epoch 13/100, Val Acc=0.6604, Val Loss=1.5724, lr=0.0100
[2025-04-29 21:19:23,264][train][INFO] - Epoch 14/100, Val Acc=0.6777, Val Loss=1.4617, lr=0.0100
[2025-04-29 21:19:26,446][train][INFO] - Epoch 14/100, Val Acc=0.6765, Val Loss=1.4714, lr=0.0100
[2025-04-29 21:19:32,312][train][INFO] - Epoch 15/100, Val Acc=0.6640, Val Loss=1.5570, lr=0.0100
[2025-04-29 21:19:35,772][train][INFO] - Epoch 15/100, Val Acc=0.6735, Val Loss=1.5166, lr=0.0100
[2025-04-29 21:19:41,335][train][INFO] - Epoch 16/100, Val Acc=0.6544, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:19:44,730][train][INFO] - Epoch 16/100, Val Acc=0.6552, Val Loss=1.5888, lr=0.0100
[2025-04-29 21:19:50,304][train][INFO] - Epoch 17/100, Val Acc=0.6663, Val Loss=1.5376, lr=0.0100
[2025-04-29 21:19:53,648][train][INFO] - Epoch 17/100, Val Acc=0.6639, Val Loss=1.5253, lr=0.0100
[2025-04-29 21:19:59,540][train][INFO] - Epoch 18/100, Val Acc=0.6688, Val Loss=1.5059, lr=0.0100
[2025-04-29 21:20:02,832][train][INFO] - Epoch 18/100, Val Acc=0.6749, Val Loss=1.4825, lr=0.0100
[2025-04-29 21:20:08,602][train][INFO] - Epoch 19/100, Val Acc=0.6693, Val Loss=1.5015, lr=0.0100
[2025-04-29 21:20:11,990][train][INFO] - Epoch 19/100, Val Acc=0.6623, Val Loss=1.5542, lr=0.0100
[2025-04-29 21:20:17,857][train][INFO] - Epoch 20/100, Val Acc=0.6786, Val Loss=1.4801, lr=0.0100
[2025-04-29 21:20:21,120][train][INFO] - Epoch 20/100, Val Acc=0.6681, Val Loss=1.5447, lr=0.0100
[2025-04-29 21:20:26,928][train][INFO] - Epoch 21/100, Val Acc=0.6652, Val Loss=1.5553, lr=0.0100
[2025-04-29 21:20:30,353][train][INFO] - Epoch 21/100, Val Acc=0.6668, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:20:35,936][train][INFO] - Epoch 22/100, Val Acc=0.6623, Val Loss=1.5446, lr=0.0100
[2025-04-29 21:20:39,397][train][INFO] - Epoch 22/100, Val Acc=0.6714, Val Loss=1.5311, lr=0.0100
[2025-04-29 21:20:45,096][train][INFO] - Epoch 23/100, Val Acc=0.6570, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:20:48,478][train][INFO] - Epoch 23/100, Val Acc=0.6782, Val Loss=1.5189, lr=0.0100
[2025-04-29 21:20:54,211][train][INFO] - Epoch 24/100, Val Acc=0.6686, Val Loss=1.5338, lr=0.0100
[2025-04-29 21:20:57,535][train][INFO] - Epoch 24/100, Val Acc=0.6779, Val Loss=1.4810, lr=0.0100
[2025-04-29 21:21:03,579][train][INFO] - Epoch 25/100, Val Acc=0.6705, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:21:06,771][train][INFO] - Epoch 25/100, Val Acc=0.6698, Val Loss=1.5511, lr=0.0100
[2025-04-29 21:21:12,286][train][INFO] - Epoch 26/100, Val Acc=0.6787, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:21:16,104][train][INFO] - Epoch 26/100, Val Acc=0.6764, Val Loss=1.5026, lr=0.0100
[2025-04-29 21:21:21,306][train][INFO] - Epoch 27/100, Val Acc=0.6724, Val Loss=1.5572, lr=0.0100
[2025-04-29 21:21:25,241][train][INFO] - Epoch 27/100, Val Acc=0.6646, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:21:30,243][train][INFO] - Epoch 28/100, Val Acc=0.6703, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:21:34,198][train][INFO] - Epoch 28/100, Val Acc=0.6731, Val Loss=1.5143, lr=0.0100
[2025-04-29 21:21:39,380][train][INFO] - Epoch 29/100, Val Acc=0.6740, Val Loss=1.5151, lr=0.0100
[2025-04-29 21:21:42,714][train][INFO] - Epoch 29/100, Val Acc=0.6692, Val Loss=1.5227, lr=0.0100
[2025-04-29 21:21:48,492][train][INFO] - Epoch 30/100, Val Acc=0.6677, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:21:51,975][train][INFO] - Epoch 30/100, Val Acc=0.6649, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:21:57,656][train][INFO] - Epoch 31/100, Val Acc=0.6735, Val Loss=1.5356, lr=0.0100
[2025-04-29 21:22:01,180][train][INFO] - Epoch 31/100, Val Acc=0.6602, Val Loss=1.6021, lr=0.0100
[2025-04-29 21:22:06,563][train][INFO] - Epoch 32/100, Val Acc=0.6737, Val Loss=1.5019, lr=0.0100
[2025-04-29 21:22:10,005][train][INFO] - Epoch 32/100, Val Acc=0.6616, Val Loss=1.6076, lr=0.0100
[2025-04-29 21:22:15,600][train][INFO] - Epoch 33/100, Val Acc=0.6670, Val Loss=1.5622, lr=0.0100
[2025-04-29 21:22:19,252][train][INFO] - Epoch 33/100, Val Acc=0.6703, Val Loss=1.5599, lr=0.0100
[2025-04-29 21:22:24,710][train][INFO] - Epoch 34/100, Val Acc=0.6643, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:22:28,393][train][INFO] - Epoch 34/100, Val Acc=0.6721, Val Loss=1.5672, lr=0.0100
[2025-04-29 21:22:33,739][train][INFO] - Epoch 35/100, Val Acc=0.6763, Val Loss=1.4823, lr=0.0100
[2025-04-29 21:22:37,296][train][INFO] - Epoch 35/100, Val Acc=0.6757, Val Loss=1.5177, lr=0.0100
[2025-04-29 21:22:43,087][train][INFO] - Epoch 36/100, Val Acc=0.6689, Val Loss=1.5290, lr=0.0100
[2025-04-29 21:22:46,304][train][INFO] - Epoch 36/100, Val Acc=0.6649, Val Loss=1.5882, lr=0.0100
[2025-04-29 21:22:51,828][train][INFO] - Epoch 37/100, Val Acc=0.6836, Val Loss=1.4839, lr=0.0100
[2025-04-29 21:22:55,664][train][INFO] - Epoch 37/100, Val Acc=0.6519, Val Loss=1.6584, lr=0.0100
[2025-04-29 21:23:01,091][train][INFO] - Epoch 38/100, Val Acc=0.6853, Val Loss=1.4466, lr=0.0100
[2025-04-29 21:23:04,566][train][INFO] - Epoch 38/100, Val Acc=0.6642, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:23:10,010][train][INFO] - Epoch 39/100, Val Acc=0.6598, Val Loss=1.5953, lr=0.0100
[2025-04-29 21:23:13,235][train][INFO] - Epoch 39/100, Val Acc=0.6693, Val Loss=1.5533, lr=0.0100
[2025-04-29 21:23:19,167][train][INFO] - Epoch 40/100, Val Acc=0.6694, Val Loss=1.5803, lr=0.0100
[2025-04-29 21:23:22,205][train][INFO] - Epoch 40/100, Val Acc=0.6578, Val Loss=1.6153, lr=0.0100
[2025-04-29 21:23:27,931][train][INFO] - Epoch 41/100, Val Acc=0.6581, Val Loss=1.6272, lr=0.0100
[2025-04-29 21:23:31,274][train][INFO] - Epoch 41/100, Val Acc=0.6810, Val Loss=1.4824, lr=0.0100
[2025-04-29 21:23:37,095][train][INFO] - Epoch 42/100, Val Acc=0.6684, Val Loss=1.5407, lr=0.0100
[2025-04-29 21:23:40,058][train][INFO] - Epoch 42/100, Val Acc=0.6686, Val Loss=1.5701, lr=0.0100
[2025-04-29 21:23:46,045][train][INFO] - Epoch 43/100, Val Acc=0.6854, Val Loss=1.4351, lr=0.0100
[2025-04-29 21:23:48,377][train][INFO] - Epoch 43/100, Val Acc=0.6726, Val Loss=1.5278, lr=0.0100
[2025-04-29 21:23:55,432][train][INFO] - Epoch 44/100, Val Acc=0.6699, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:23:57,697][train][INFO] - Epoch 44/100, Val Acc=0.6675, Val Loss=1.5595, lr=0.0100
[2025-04-29 21:24:04,231][train][INFO] - Epoch 45/100, Val Acc=0.6640, Val Loss=1.5884, lr=0.0100
[2025-04-29 21:24:06,934][train][INFO] - Epoch 45/100, Val Acc=0.6594, Val Loss=1.5987, lr=0.0100
[2025-04-29 21:24:13,340][train][INFO] - Epoch 46/100, Val Acc=0.6711, Val Loss=1.5410, lr=0.0100
[2025-04-29 21:24:15,878][train][INFO] - Epoch 46/100, Val Acc=0.6762, Val Loss=1.5517, lr=0.0100
[2025-04-29 21:24:22,498][train][INFO] - Epoch 47/100, Val Acc=0.6741, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:24:25,176][train][INFO] - Epoch 47/100, Val Acc=0.6680, Val Loss=1.5546, lr=0.0100
[2025-04-29 21:24:31,408][train][INFO] - Epoch 48/100, Val Acc=0.6663, Val Loss=1.5747, lr=0.0100
[2025-04-29 21:24:34,442][train][INFO] - Epoch 48/100, Val Acc=0.6703, Val Loss=1.5437, lr=0.0100
[2025-04-29 21:24:40,641][train][INFO] - Epoch 49/100, Val Acc=0.6698, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:24:43,323][train][INFO] - Epoch 49/100, Val Acc=0.6805, Val Loss=1.5006, lr=0.0100
[2025-04-29 21:24:50,009][train][INFO] - Epoch 50/100, Val Acc=0.6754, Val Loss=1.5466, lr=0.0100
[2025-04-29 21:24:52,339][train][INFO] - Epoch 50/100, Val Acc=0.6671, Val Loss=1.6240, lr=0.0100
[2025-04-29 21:24:59,344][train][INFO] - Epoch 51/100, Val Acc=0.6635, Val Loss=1.5881, lr=0.0100
[2025-04-29 21:25:01,259][train][INFO] - Epoch 51/100, Val Acc=0.6786, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:25:08,406][train][INFO] - Epoch 52/100, Val Acc=0.6664, Val Loss=1.5959, lr=0.0100
[2025-04-29 21:25:10,043][train][INFO] - Epoch 52/100, Val Acc=0.6670, Val Loss=1.5614, lr=0.0100
[2025-04-29 21:25:17,258][train][INFO] - Epoch 53/100, Val Acc=0.6583, Val Loss=1.6056, lr=0.0100
[2025-04-29 21:25:19,222][train][INFO] - Epoch 53/100, Val Acc=0.6748, Val Loss=1.5412, lr=0.0100
[2025-04-29 21:25:26,404][train][INFO] - Epoch 54/100, Val Acc=0.6694, Val Loss=1.5694, lr=0.0100
[2025-04-29 21:25:28,179][train][INFO] - Epoch 54/100, Val Acc=0.6646, Val Loss=1.5513, lr=0.0100
[2025-04-29 21:25:35,619][train][INFO] - Epoch 55/100, Val Acc=0.6669, Val Loss=1.6020, lr=0.0100
[2025-04-29 21:25:37,223][train][INFO] - Epoch 55/100, Val Acc=0.6703, Val Loss=1.5565, lr=0.0100
[2025-04-29 21:25:44,899][train][INFO] - Epoch 56/100, Val Acc=0.6681, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:25:46,321][train][INFO] - Epoch 56/100, Val Acc=0.6579, Val Loss=1.6059, lr=0.0100
[2025-04-29 21:25:54,098][train][INFO] - Epoch 57/100, Val Acc=0.6557, Val Loss=1.6307, lr=0.0100
[2025-04-29 21:25:55,486][train][INFO] - Epoch 57/100, Val Acc=0.6711, Val Loss=1.5596, lr=0.0100
[2025-04-29 21:26:03,454][train][INFO] - Epoch 58/100, Val Acc=0.6596, Val Loss=1.6495, lr=0.0100
[2025-04-29 21:26:04,375][train][INFO] - Epoch 58/100, Val Acc=0.6715, Val Loss=1.5329, lr=0.0100
[2025-04-29 21:26:12,593][train][INFO] - Epoch 59/100, Val Acc=0.6525, Val Loss=1.6634, lr=0.0100
[2025-04-29 21:26:13,454][train][INFO] - Epoch 59/100, Val Acc=0.6542, Val Loss=1.6370, lr=0.0100
[2025-04-29 21:26:21,637][train][INFO] - Epoch 60/100, Val Acc=0.6810, Val Loss=1.5055, lr=0.0100
[2025-04-29 21:26:22,690][train][INFO] - Epoch 60/100, Val Acc=0.6723, Val Loss=1.5387, lr=0.0100
[2025-04-29 21:26:31,026][train][INFO] - Epoch 61/100, Val Acc=0.7232, Val Loss=1.2862, lr=0.0010
[2025-04-29 21:26:31,900][train][INFO] - Epoch 61/100, Val Acc=0.7273, Val Loss=1.2891, lr=0.0010
[2025-04-29 21:26:40,272][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2759, lr=0.0010
[2025-04-29 21:26:41,137][train][INFO] - Epoch 62/100, Val Acc=0.7330, Val Loss=1.2826, lr=0.0010
[2025-04-29 21:26:49,494][train][INFO] - Epoch 63/100, Val Acc=0.7307, Val Loss=1.2847, lr=0.0010
[2025-04-29 21:26:50,483][train][INFO] - Epoch 63/100, Val Acc=0.7335, Val Loss=1.2901, lr=0.0010
[2025-04-29 21:26:58,657][train][INFO] - Epoch 64/100, Val Acc=0.7330, Val Loss=1.2842, lr=0.0010
[2025-04-29 21:26:59,379][train][INFO] - Epoch 64/100, Val Acc=0.7332, Val Loss=1.2855, lr=0.0010
[2025-04-29 21:27:07,826][train][INFO] - Epoch 65/100, Val Acc=0.7337, Val Loss=1.2950, lr=0.0010
[2025-04-29 21:27:07,989][train][INFO] - Epoch 65/100, Val Acc=0.7351, Val Loss=1.2947, lr=0.0010
[2025-04-29 21:27:17,073][train][INFO] - Epoch 66/100, Val Acc=0.7359, Val Loss=1.3000, lr=0.0010
[2025-04-29 21:27:17,100][train][INFO] - Epoch 66/100, Val Acc=0.7319, Val Loss=1.3047, lr=0.0010
[2025-04-29 21:27:26,347][train][INFO] - Epoch 67/100, Val Acc=0.7374, Val Loss=1.2985, lr=0.0010
[2025-04-29 21:27:26,498][train][INFO] - Epoch 67/100, Val Acc=0.7322, Val Loss=1.3034, lr=0.0010
[2025-04-29 21:27:35,611][train][INFO] - Epoch 68/100, Val Acc=0.7392, Val Loss=1.2936, lr=0.0010
[2025-04-29 21:27:36,026][train][INFO] - Epoch 68/100, Val Acc=0.7371, Val Loss=1.2959, lr=0.0010
[2025-04-29 21:27:44,174][train][INFO] - Epoch 69/100, Val Acc=0.7383, Val Loss=1.3065, lr=0.0010
[2025-04-29 21:27:45,122][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.2939, lr=0.0010
[2025-04-29 21:27:53,267][train][INFO] - Epoch 70/100, Val Acc=0.7368, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:27:54,395][train][INFO] - Epoch 70/100, Val Acc=0.7358, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:02,331][train][INFO] - Epoch 71/100, Val Acc=0.7374, Val Loss=1.3147, lr=0.0010
[2025-04-29 21:28:03,543][train][INFO] - Epoch 71/100, Val Acc=0.7372, Val Loss=1.3052, lr=0.0010
[2025-04-29 21:28:11,422][train][INFO] - Epoch 72/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:28:12,568][train][INFO] - Epoch 72/100, Val Acc=0.7371, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:28:20,660][train][INFO] - Epoch 73/100, Val Acc=0.7386, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:21,731][train][INFO] - Epoch 73/100, Val Acc=0.7362, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:29,893][train][INFO] - Epoch 74/100, Val Acc=0.7397, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:30,857][train][INFO] - Epoch 74/100, Val Acc=0.7361, Val Loss=1.3060, lr=0.0010
[2025-04-29 21:28:39,203][train][INFO] - Epoch 75/100, Val Acc=0.7408, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:39,488][train][INFO] - Epoch 75/100, Val Acc=0.7362, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:28:48,144][train][INFO] - Epoch 76/100, Val Acc=0.7401, Val Loss=1.3140, lr=0.0010
[2025-04-29 21:28:48,618][train][INFO] - Epoch 76/100, Val Acc=0.7370, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:28:57,139][train][INFO] - Epoch 77/100, Val Acc=0.7395, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:28:57,734][train][INFO] - Epoch 77/100, Val Acc=0.7374, Val Loss=1.3039, lr=0.0010
[2025-04-29 21:29:06,341][train][INFO] - Epoch 78/100, Val Acc=0.7398, Val Loss=1.3136, lr=0.0010
[2025-04-29 21:29:06,864][train][INFO] - Epoch 78/100, Val Acc=0.7354, Val Loss=1.3030, lr=0.0010
[2025-04-29 21:29:15,003][train][INFO] - Epoch 79/100, Val Acc=0.7385, Val Loss=1.3145, lr=0.0010
[2025-04-29 21:29:16,025][train][INFO] - Epoch 79/100, Val Acc=0.7386, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:24,196][train][INFO] - Epoch 80/100, Val Acc=0.7397, Val Loss=1.3122, lr=0.0010
[2025-04-29 21:29:25,254][train][INFO] - Epoch 80/100, Val Acc=0.7361, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:29:32,884][train][INFO] - Epoch 81/100, Val Acc=0.7401, Val Loss=1.3084, lr=0.0010
[2025-04-29 21:29:34,433][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3083, lr=0.0010
[2025-04-29 21:29:42,096][train][INFO] - Epoch 82/100, Val Acc=0.7376, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:29:43,544][train][INFO] - Epoch 82/100, Val Acc=0.7361, Val Loss=1.3168, lr=0.0010
[2025-04-29 21:29:51,114][train][INFO] - Epoch 83/100, Val Acc=0.7397, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:52,840][train][INFO] - Epoch 83/100, Val Acc=0.7373, Val Loss=1.3154, lr=0.0010
[2025-04-29 21:30:00,216][train][INFO] - Epoch 84/100, Val Acc=0.7393, Val Loss=1.3120, lr=0.0010
[2025-04-29 21:30:02,021][train][INFO] - Epoch 84/100, Val Acc=0.7389, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:30:09,578][train][INFO] - Epoch 85/100, Val Acc=0.7397, Val Loss=1.3131, lr=0.0010
[2025-04-29 21:30:11,389][train][INFO] - Epoch 85/100, Val Acc=0.7379, Val Loss=1.3130, lr=0.0010
[2025-04-29 21:30:18,697][train][INFO] - Epoch 86/100, Val Acc=0.7412, Val Loss=1.3069, lr=0.0010
[2025-04-29 21:30:20,684][train][INFO] - Epoch 86/100, Val Acc=0.7407, Val Loss=1.3142, lr=0.0010
[2025-04-29 21:30:27,407][train][INFO] - Epoch 87/100, Val Acc=0.7403, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:30:29,862][train][INFO] - Epoch 87/100, Val Acc=0.7395, Val Loss=1.3100, lr=0.0010
[2025-04-29 21:30:36,218][train][INFO] - Epoch 88/100, Val Acc=0.7402, Val Loss=1.3075, lr=0.0010
[2025-04-29 21:30:38,935][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3163, lr=0.0010
[2025-04-29 21:30:44,864][train][INFO] - Epoch 89/100, Val Acc=0.7415, Val Loss=1.3162, lr=0.0010
[2025-04-29 21:30:48,196][train][INFO] - Epoch 89/100, Val Acc=0.7378, Val Loss=1.3224, lr=0.0010
[2025-04-29 21:30:53,860][train][INFO] - Epoch 90/100, Val Acc=0.7402, Val Loss=1.3160, lr=0.0010
[2025-04-29 21:30:57,502][train][INFO] - Epoch 90/100, Val Acc=0.7369, Val Loss=1.3185, lr=0.0010
[2025-04-29 21:31:02,792][train][INFO] - Epoch 91/100, Val Acc=0.7417, Val Loss=1.3142, lr=0.0001
[2025-04-29 21:31:06,880][train][INFO] - Epoch 91/100, Val Acc=0.7375, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:31:12,031][train][INFO] - Epoch 92/100, Val Acc=0.7388, Val Loss=1.3165, lr=0.0001
[2025-04-29 21:31:15,980][train][INFO] - Epoch 92/100, Val Acc=0.7381, Val Loss=1.3166, lr=0.0001
[2025-04-29 21:31:21,020][train][INFO] - Epoch 93/100, Val Acc=0.7403, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:31:25,126][train][INFO] - Epoch 93/100, Val Acc=0.7385, Val Loss=1.3141, lr=0.0001
[2025-04-29 21:31:30,116][train][INFO] - Epoch 94/100, Val Acc=0.7407, Val Loss=1.3087, lr=0.0001
[2025-04-29 21:31:34,200][train][INFO] - Epoch 94/100, Val Acc=0.7397, Val Loss=1.3102, lr=0.0001
[2025-04-29 21:31:39,116][train][INFO] - Epoch 95/100, Val Acc=0.7404, Val Loss=1.3131, lr=0.0001
[2025-04-29 21:31:43,537][train][INFO] - Epoch 95/100, Val Acc=0.7387, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:31:48,063][train][INFO] - Epoch 96/100, Val Acc=0.7429, Val Loss=1.3081, lr=0.0001
[2025-04-29 21:31:52,704][train][INFO] - Epoch 96/100, Val Acc=0.7398, Val Loss=1.3067, lr=0.0001
[2025-04-29 21:31:56,974][train][INFO] - Epoch 97/100, Val Acc=0.7415, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:32:02,041][train][INFO] - Epoch 97/100, Val Acc=0.7418, Val Loss=1.3118, lr=0.0001
[2025-04-29 21:32:05,975][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3096, lr=0.0001
[2025-04-29 21:32:11,084][train][INFO] - Epoch 98/100, Val Acc=0.7389, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:32:14,921][train][INFO] - Epoch 99/100, Val Acc=0.7422, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:32:20,279][train][INFO] - Epoch 99/100, Val Acc=0.7410, Val Loss=1.3169, lr=0.0001
[2025-04-29 21:32:23,991][train][INFO] - Epoch 100/100, Val Acc=0.7418, Val Loss=1.3116, lr=0.0001
[2025-04-29 21:32:29,324][train][INFO] - After training : Train Acc=0.9995  Val Acc=0.7429
[2025-04-29 21:32:29,328][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:32:29,545][train][INFO] - Epoch 100/100, Val Acc=0.7375, Val Loss=1.3119, lr=0.0001
[2025-04-29 21:32:34,979][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7418
[2025-04-29 21:32:34,984][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:34:53,903][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:34:59,489][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:37:17,383][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:17,921][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:37:22,790][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:23,228][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:40:10,349][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:40:49,882][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:40:53,370][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:40:59,065][train][INFO] - Epoch 1/100, Val Acc=0.6257, Val Loss=1.6543, lr=0.0100
[2025-04-29 21:41:08,027][train][INFO] - Epoch 2/100, Val Acc=0.6428, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:41:16,885][train][INFO] - Epoch 3/100, Val Acc=0.6496, Val Loss=1.5084, lr=0.0100
[2025-04-29 21:41:25,890][train][INFO] - Epoch 4/100, Val Acc=0.6656, Val Loss=1.4503, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:41:34,452][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:41:35,197][train][INFO] - Epoch 5/100, Val Acc=0.6521, Val Loss=1.5174, lr=0.0100
[2025-04-29 21:41:44,066][train][INFO] - Epoch 1/100, Val Acc=0.6369, Val Loss=1.5627, lr=0.0100
[2025-04-29 21:41:44,412][train][INFO] - Epoch 6/100, Val Acc=0.6654, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:41:53,151][train][INFO] - Epoch 2/100, Val Acc=0.6300, Val Loss=1.5685, lr=0.0100
[2025-04-29 21:41:53,576][train][INFO] - Epoch 7/100, Val Acc=0.6622, Val Loss=1.4976, lr=0.0100
[2025-04-29 21:42:02,386][train][INFO] - Epoch 8/100, Val Acc=0.6701, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:42:02,554][train][INFO] - Epoch 3/100, Val Acc=0.6416, Val Loss=1.5501, lr=0.0100
[2025-04-29 21:42:11,564][train][INFO] - Epoch 9/100, Val Acc=0.6665, Val Loss=1.4876, lr=0.0100
[2025-04-29 21:42:11,822][train][INFO] - Epoch 4/100, Val Acc=0.6620, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:42:20,752][train][INFO] - Epoch 10/100, Val Acc=0.6711, Val Loss=1.4776, lr=0.0100
[2025-04-29 21:42:21,144][train][INFO] - Epoch 5/100, Val Acc=0.6422, Val Loss=1.5505, lr=0.0100
[2025-04-29 21:42:29,739][train][INFO] - Epoch 11/100, Val Acc=0.6648, Val Loss=1.5057, lr=0.0100
[2025-04-29 21:42:30,670][train][INFO] - Epoch 6/100, Val Acc=0.6635, Val Loss=1.4302, lr=0.0100
[2025-04-29 21:42:38,897][train][INFO] - Epoch 12/100, Val Acc=0.6631, Val Loss=1.5293, lr=0.0100
[2025-04-29 21:42:40,063][train][INFO] - Epoch 7/100, Val Acc=0.6482, Val Loss=1.5347, lr=0.0100
[2025-04-29 21:42:48,128][train][INFO] - Epoch 13/100, Val Acc=0.6671, Val Loss=1.4912, lr=0.0100
[2025-04-29 21:42:49,571][train][INFO] - Epoch 8/100, Val Acc=0.6711, Val Loss=1.4325, lr=0.0100
[2025-04-29 21:42:57,114][train][INFO] - Epoch 14/100, Val Acc=0.6543, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:42:58,797][train][INFO] - Epoch 9/100, Val Acc=0.6535, Val Loss=1.5438, lr=0.0100
[2025-04-29 21:43:05,637][train][INFO] - Epoch 15/100, Val Acc=0.6600, Val Loss=1.5129, lr=0.0100
[2025-04-29 21:43:07,825][train][INFO] - Epoch 10/100, Val Acc=0.6637, Val Loss=1.4938, lr=0.0100
[2025-04-29 21:43:14,509][train][INFO] - Epoch 16/100, Val Acc=0.6548, Val Loss=1.5180, lr=0.0100
[2025-04-29 21:43:17,141][train][INFO] - Epoch 11/100, Val Acc=0.6624, Val Loss=1.4939, lr=0.0100
[2025-04-29 21:43:23,482][train][INFO] - Epoch 17/100, Val Acc=0.6656, Val Loss=1.5355, lr=0.0100
[2025-04-29 21:43:26,650][train][INFO] - Epoch 12/100, Val Acc=0.6768, Val Loss=1.4102, lr=0.0100
[2025-04-29 21:43:32,503][train][INFO] - Epoch 18/100, Val Acc=0.6606, Val Loss=1.5428, lr=0.0100
[2025-04-29 21:43:36,129][train][INFO] - Epoch 13/100, Val Acc=0.6710, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:43:41,500][train][INFO] - Epoch 19/100, Val Acc=0.6796, Val Loss=1.4513, lr=0.0100
[2025-04-29 21:43:45,401][train][INFO] - Epoch 14/100, Val Acc=0.6739, Val Loss=1.4676, lr=0.0100
[2025-04-29 21:43:50,499][train][INFO] - Epoch 20/100, Val Acc=0.6700, Val Loss=1.5303, lr=0.0100
[2025-04-29 21:43:54,513][train][INFO] - Epoch 15/100, Val Acc=0.6568, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:43:59,352][train][INFO] - Epoch 21/100, Val Acc=0.6711, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:44:04,005][train][INFO] - Epoch 16/100, Val Acc=0.6543, Val Loss=1.5705, lr=0.0100
[2025-04-29 21:44:08,305][train][INFO] - Epoch 22/100, Val Acc=0.6486, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:44:13,200][train][INFO] - Epoch 17/100, Val Acc=0.6529, Val Loss=1.6048, lr=0.0100
[2025-04-29 21:44:17,314][train][INFO] - Epoch 23/100, Val Acc=0.6618, Val Loss=1.5304, lr=0.0100
[2025-04-29 21:44:22,658][train][INFO] - Epoch 18/100, Val Acc=0.6823, Val Loss=1.4386, lr=0.0100
[2025-04-29 21:44:26,595][train][INFO] - Epoch 24/100, Val Acc=0.6651, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:44:32,118][train][INFO] - Epoch 19/100, Val Acc=0.6751, Val Loss=1.4674, lr=0.0100
[2025-04-29 21:44:35,312][train][INFO] - Epoch 25/100, Val Acc=0.6714, Val Loss=1.5076, lr=0.0100
[2025-04-29 21:44:41,401][train][INFO] - Epoch 20/100, Val Acc=0.6716, Val Loss=1.4960, lr=0.0100
[2025-04-29 21:44:44,435][train][INFO] - Epoch 26/100, Val Acc=0.6693, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:44:50,722][train][INFO] - Epoch 21/100, Val Acc=0.6706, Val Loss=1.5384, lr=0.0100
[2025-04-29 21:44:53,423][train][INFO] - Epoch 27/100, Val Acc=0.6747, Val Loss=1.4802, lr=0.0100
[2025-04-29 21:44:59,699][train][INFO] - Epoch 22/100, Val Acc=0.6757, Val Loss=1.4804, lr=0.0100
[2025-04-29 21:45:02,423][train][INFO] - Epoch 28/100, Val Acc=0.6645, Val Loss=1.5490, lr=0.0100
[2025-04-29 21:45:08,977][train][INFO] - Epoch 23/100, Val Acc=0.6674, Val Loss=1.4937, lr=0.0100
[2025-04-29 21:45:11,718][train][INFO] - Epoch 29/100, Val Acc=0.6800, Val Loss=1.4548, lr=0.0100
[2025-04-29 21:45:18,377][train][INFO] - Epoch 24/100, Val Acc=0.6720, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:45:21,984][train][INFO] - Epoch 30/100, Val Acc=0.6764, Val Loss=1.5024, lr=0.0100
[2025-04-29 21:45:27,498][train][INFO] - Epoch 25/100, Val Acc=0.6731, Val Loss=1.5116, lr=0.0100
[2025-04-29 21:45:36,367][train][INFO] - Epoch 31/100, Val Acc=0.6687, Val Loss=1.5228, lr=0.0100
[2025-04-29 21:45:36,565][train][INFO] - Epoch 26/100, Val Acc=0.6663, Val Loss=1.5383, lr=0.0100
[2025-04-29 21:45:45,666][train][INFO] - Epoch 27/100, Val Acc=0.6596, Val Loss=1.6001, lr=0.0100
[2025-04-29 21:45:50,939][train][INFO] - Epoch 32/100, Val Acc=0.6559, Val Loss=1.6182, lr=0.0100
[2025-04-29 21:45:54,779][train][INFO] - Epoch 28/100, Val Acc=0.6818, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:46:04,196][train][INFO] - Epoch 29/100, Val Acc=0.6621, Val Loss=1.5992, lr=0.0100
[2025-04-29 21:46:05,262][train][INFO] - Epoch 33/100, Val Acc=0.6615, Val Loss=1.5968, lr=0.0100
[2025-04-29 21:46:13,400][train][INFO] - Epoch 30/100, Val Acc=0.6728, Val Loss=1.5461, lr=0.0100
[2025-04-29 21:46:19,443][train][INFO] - Epoch 34/100, Val Acc=0.6671, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:46:22,452][train][INFO] - Epoch 31/100, Val Acc=0.6721, Val Loss=1.5289, lr=0.0100
[2025-04-29 21:46:31,571][train][INFO] - Epoch 32/100, Val Acc=0.6674, Val Loss=1.5620, lr=0.0100
[2025-04-29 21:46:33,794][train][INFO] - Epoch 35/100, Val Acc=0.6700, Val Loss=1.5275, lr=0.0100
[2025-04-29 21:46:40,841][train][INFO] - Epoch 33/100, Val Acc=0.6763, Val Loss=1.4837, lr=0.0100
[2025-04-29 21:46:48,024][train][INFO] - Epoch 36/100, Val Acc=0.6624, Val Loss=1.5998, lr=0.0100
[2025-04-29 21:46:49,868][train][INFO] - Epoch 34/100, Val Acc=0.6692, Val Loss=1.5875, lr=0.0100
[2025-04-29 21:46:58,977][train][INFO] - Epoch 35/100, Val Acc=0.6677, Val Loss=1.5485, lr=0.0100
[2025-04-29 21:47:02,140][train][INFO] - Epoch 37/100, Val Acc=0.6816, Val Loss=1.4639, lr=0.0100
[2025-04-29 21:47:08,240][train][INFO] - Epoch 36/100, Val Acc=0.6677, Val Loss=1.5615, lr=0.0100
[2025-04-29 21:47:16,411][train][INFO] - Epoch 38/100, Val Acc=0.6778, Val Loss=1.5033, lr=0.0100
[2025-04-29 21:47:17,232][train][INFO] - Epoch 37/100, Val Acc=0.6747, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:47:26,377][train][INFO] - Epoch 38/100, Val Acc=0.6708, Val Loss=1.5313, lr=0.0100
[2025-04-29 21:47:30,910][train][INFO] - Epoch 39/100, Val Acc=0.6669, Val Loss=1.5918, lr=0.0100
[2025-04-29 21:47:35,408][train][INFO] - Epoch 39/100, Val Acc=0.6698, Val Loss=1.5529, lr=0.0100
[2025-04-29 21:47:44,495][train][INFO] - Epoch 40/100, Val Acc=0.6711, Val Loss=1.5507, lr=0.0100
[2025-04-29 21:47:45,491][train][INFO] - Epoch 40/100, Val Acc=0.6797, Val Loss=1.4993, lr=0.0100
[2025-04-29 21:47:53,749][train][INFO] - Epoch 41/100, Val Acc=0.6734, Val Loss=1.5220, lr=0.0100
[2025-04-29 21:47:59,609][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:48:02,823][train][INFO] - Epoch 42/100, Val Acc=0.6822, Val Loss=1.4934, lr=0.0100
[2025-04-29 21:48:12,209][train][INFO] - Epoch 43/100, Val Acc=0.6812, Val Loss=1.5135, lr=0.0100
[2025-04-29 21:48:13,873][train][INFO] - Epoch 42/100, Val Acc=0.6679, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:48:21,452][train][INFO] - Epoch 44/100, Val Acc=0.6608, Val Loss=1.6318, lr=0.0100
[2025-04-29 21:48:28,061][train][INFO] - Epoch 43/100, Val Acc=0.6785, Val Loss=1.5146, lr=0.0100
[2025-04-29 21:48:30,585][train][INFO] - Epoch 45/100, Val Acc=0.6687, Val Loss=1.5555, lr=0.0100
[2025-04-29 21:48:39,776][train][INFO] - Epoch 46/100, Val Acc=0.6768, Val Loss=1.5056, lr=0.0100
[2025-04-29 21:48:42,382][train][INFO] - Epoch 44/100, Val Acc=0.6695, Val Loss=1.5718, lr=0.0100
[2025-04-29 21:48:48,954][train][INFO] - Epoch 47/100, Val Acc=0.6723, Val Loss=1.5183, lr=0.0100
[2025-04-29 21:48:56,599][train][INFO] - Epoch 45/100, Val Acc=0.6679, Val Loss=1.5633, lr=0.0100
[2025-04-29 21:48:58,321][train][INFO] - Epoch 48/100, Val Acc=0.6612, Val Loss=1.6375, lr=0.0100
[2025-04-29 21:49:07,490][train][INFO] - Epoch 49/100, Val Acc=0.6736, Val Loss=1.5120, lr=0.0100
[2025-04-29 21:49:10,847][train][INFO] - Epoch 46/100, Val Acc=0.6659, Val Loss=1.5629, lr=0.0100
[2025-04-29 21:49:16,617][train][INFO] - Epoch 50/100, Val Acc=0.6772, Val Loss=1.4901, lr=0.0100
[2025-04-29 21:49:25,304][train][INFO] - Epoch 47/100, Val Acc=0.6548, Val Loss=1.6385, lr=0.0100
[2025-04-29 21:49:26,124][train][INFO] - Epoch 51/100, Val Acc=0.6860, Val Loss=1.4603, lr=0.0100
[2025-04-29 21:49:35,242][train][INFO] - Epoch 52/100, Val Acc=0.6715, Val Loss=1.5797, lr=0.0100
[2025-04-29 21:49:39,833][train][INFO] - Epoch 48/100, Val Acc=0.6624, Val Loss=1.6049, lr=0.0100
[2025-04-29 21:49:44,272][train][INFO] - Epoch 53/100, Val Acc=0.6779, Val Loss=1.5066, lr=0.0100
[2025-04-29 21:49:53,524][train][INFO] - Epoch 54/100, Val Acc=0.6751, Val Loss=1.5483, lr=0.0100
[2025-04-29 21:49:54,092][train][INFO] - Epoch 49/100, Val Acc=0.6851, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:50:02,931][train][INFO] - Epoch 55/100, Val Acc=0.6654, Val Loss=1.6669, lr=0.0100
[2025-04-29 21:50:08,193][train][INFO] - Epoch 50/100, Val Acc=0.6644, Val Loss=1.5961, lr=0.0100
[2025-04-29 21:50:12,154][train][INFO] - Epoch 56/100, Val Acc=0.6662, Val Loss=1.5693, lr=0.0100
[2025-04-29 21:50:21,400][train][INFO] - Epoch 57/100, Val Acc=0.6684, Val Loss=1.5478, lr=0.0100
[2025-04-29 21:50:22,470][train][INFO] - Epoch 51/100, Val Acc=0.6632, Val Loss=1.5834, lr=0.0100
[2025-04-29 21:50:30,522][train][INFO] - Epoch 58/100, Val Acc=0.6637, Val Loss=1.5977, lr=0.0100
[2025-04-29 21:50:36,634][train][INFO] - Epoch 52/100, Val Acc=0.6738, Val Loss=1.5234, lr=0.0100
[2025-04-29 21:50:39,764][train][INFO] - Epoch 59/100, Val Acc=0.6696, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:50:49,192][train][INFO] - Epoch 60/100, Val Acc=0.6658, Val Loss=1.6064, lr=0.0100
[2025-04-29 21:50:50,929][train][INFO] - Epoch 53/100, Val Acc=0.6771, Val Loss=1.5226, lr=0.0100
[2025-04-29 21:50:58,358][train][INFO] - Epoch 61/100, Val Acc=0.7230, Val Loss=1.2880, lr=0.0010
[2025-04-29 21:51:05,178][train][INFO] - Epoch 54/100, Val Acc=0.6602, Val Loss=1.6317, lr=0.0100
[2025-04-29 21:51:07,630][train][INFO] - Epoch 62/100, Val Acc=0.7252, Val Loss=1.2812, lr=0.0010
[2025-04-29 21:51:16,909][train][INFO] - Epoch 63/100, Val Acc=0.7286, Val Loss=1.2853, lr=0.0010
[2025-04-29 21:51:19,590][train][INFO] - Epoch 55/100, Val Acc=0.6769, Val Loss=1.5502, lr=0.0100
[2025-04-29 21:51:26,175][train][INFO] - Epoch 64/100, Val Acc=0.7316, Val Loss=1.2868, lr=0.0010
[2025-04-29 21:51:34,240][train][INFO] - Epoch 56/100, Val Acc=0.6628, Val Loss=1.5731, lr=0.0100
[2025-04-29 21:51:35,675][train][INFO] - Epoch 65/100, Val Acc=0.7298, Val Loss=1.2904, lr=0.0010
[2025-04-29 21:51:44,878][train][INFO] - Epoch 66/100, Val Acc=0.7295, Val Loss=1.3033, lr=0.0010
[2025-04-29 21:51:48,524][train][INFO] - Epoch 57/100, Val Acc=0.6633, Val Loss=1.6350, lr=0.0100
[2025-04-29 21:51:54,179][train][INFO] - Epoch 67/100, Val Acc=0.7340, Val Loss=1.3009, lr=0.0010
[2025-04-29 21:52:02,745][train][INFO] - Epoch 58/100, Val Acc=0.6603, Val Loss=1.6075, lr=0.0100
[2025-04-29 21:52:03,420][train][INFO] - Epoch 68/100, Val Acc=0.7342, Val Loss=1.3043, lr=0.0010
[2025-04-29 21:52:12,503][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.3058, lr=0.0010
[2025-04-29 21:52:16,927][train][INFO] - Epoch 59/100, Val Acc=0.6693, Val Loss=1.5958, lr=0.0100
[2025-04-29 21:52:21,632][train][INFO] - Epoch 70/100, Val Acc=0.7332, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:52:31,025][train][INFO] - Epoch 71/100, Val Acc=0.7343, Val Loss=1.3237, lr=0.0010
[2025-04-29 21:52:31,232][train][INFO] - Epoch 60/100, Val Acc=0.6681, Val Loss=1.5341, lr=0.0100
[2025-04-29 21:52:40,401][train][INFO] - Epoch 72/100, Val Acc=0.7343, Val Loss=1.3195, lr=0.0010
[2025-04-29 21:52:45,514][train][INFO] - Epoch 61/100, Val Acc=0.7206, Val Loss=1.2915, lr=0.0010
[2025-04-29 21:52:49,781][train][INFO] - Epoch 73/100, Val Acc=0.7360, Val Loss=1.3172, lr=0.0010
[2025-04-29 21:52:58,861][train][INFO] - Epoch 74/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:52:59,752][train][INFO] - Epoch 62/100, Val Acc=0.7243, Val Loss=1.2888, lr=0.0010
[2025-04-29 21:53:08,145][train][INFO] - Epoch 75/100, Val Acc=0.7356, Val Loss=1.3261, lr=0.0010
[2025-04-29 21:53:14,234][train][INFO] - Epoch 63/100, Val Acc=0.7244, Val Loss=1.2993, lr=0.0010
[2025-04-29 21:53:17,319][train][INFO] - Epoch 76/100, Val Acc=0.7378, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:53:26,442][train][INFO] - Epoch 77/100, Val Acc=0.7389, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:53:28,773][train][INFO] - Epoch 64/100, Val Acc=0.7271, Val Loss=1.3022, lr=0.0010
[2025-04-29 21:53:35,810][train][INFO] - Epoch 78/100, Val Acc=0.7382, Val Loss=1.3103, lr=0.0010
[2025-04-29 21:53:42,992][train][INFO] - Epoch 65/100, Val Acc=0.7274, Val Loss=1.3041, lr=0.0010
[2025-04-29 21:53:45,163][train][INFO] - Epoch 79/100, Val Acc=0.7372, Val Loss=1.3201, lr=0.0010
[2025-04-29 21:53:54,433][train][INFO] - Epoch 80/100, Val Acc=0.7377, Val Loss=1.3215, lr=0.0010
[2025-04-29 21:53:57,122][train][INFO] - Epoch 66/100, Val Acc=0.7301, Val Loss=1.3166, lr=0.0010
[2025-04-29 21:54:03,397][train][INFO] - Epoch 81/100, Val Acc=0.7378, Val Loss=1.3244, lr=0.0010
[2025-04-29 21:54:11,312][train][INFO] - Epoch 67/100, Val Acc=0.7312, Val Loss=1.3091, lr=0.0010
[2025-04-29 21:54:12,604][train][INFO] - Epoch 82/100, Val Acc=0.7399, Val Loss=1.3225, lr=0.0010
[2025-04-29 21:54:21,971][train][INFO] - Epoch 83/100, Val Acc=0.7383, Val Loss=1.3155, lr=0.0010
[2025-04-29 21:54:25,661][train][INFO] - Epoch 68/100, Val Acc=0.7330, Val Loss=1.3048, lr=0.0010
[2025-04-29 21:54:31,353][train][INFO] - Epoch 84/100, Val Acc=0.7376, Val Loss=1.3248, lr=0.0010
[2025-04-29 21:54:39,857][train][INFO] - Epoch 69/100, Val Acc=0.7315, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:54:40,699][train][INFO] - Epoch 85/100, Val Acc=0.7370, Val Loss=1.3245, lr=0.0010
[2025-04-29 21:54:49,791][train][INFO] - Epoch 86/100, Val Acc=0.7360, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:54:54,116][train][INFO] - Epoch 70/100, Val Acc=0.7331, Val Loss=1.3243, lr=0.0010
[2025-04-29 21:54:58,976][train][INFO] - Epoch 87/100, Val Acc=0.7366, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:55:08,154][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3270, lr=0.0010
[2025-04-29 21:55:08,577][train][INFO] - Epoch 71/100, Val Acc=0.7304, Val Loss=1.3285, lr=0.0010
[2025-04-29 21:55:17,263][train][INFO] - Epoch 89/100, Val Acc=0.7379, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:55:23,134][train][INFO] - Epoch 72/100, Val Acc=0.7312, Val Loss=1.3351, lr=0.0010
[2025-04-29 21:55:26,509][train][INFO] - Epoch 90/100, Val Acc=0.7372, Val Loss=1.3340, lr=0.0010
[2025-04-29 21:55:35,655][train][INFO] - Epoch 91/100, Val Acc=0.7373, Val Loss=1.3271, lr=0.0001
[2025-04-29 21:55:37,306][train][INFO] - Epoch 73/100, Val Acc=0.7317, Val Loss=1.3323, lr=0.0010
[2025-04-29 21:55:44,969][train][INFO] - Epoch 92/100, Val Acc=0.7370, Val Loss=1.3286, lr=0.0001
[2025-04-29 21:55:51,550][train][INFO] - Epoch 74/100, Val Acc=0.7329, Val Loss=1.3267, lr=0.0010
[2025-04-29 21:55:54,252][train][INFO] - Epoch 93/100, Val Acc=0.7380, Val Loss=1.3234, lr=0.0001
[2025-04-29 21:56:03,709][train][INFO] - Epoch 94/100, Val Acc=0.7380, Val Loss=1.3253, lr=0.0001
[2025-04-29 21:56:05,736][train][INFO] - Epoch 75/100, Val Acc=0.7322, Val Loss=1.3356, lr=0.0010
[2025-04-29 21:56:13,133][train][INFO] - Epoch 95/100, Val Acc=0.7380, Val Loss=1.3265, lr=0.0001
[2025-04-29 21:56:19,978][train][INFO] - Epoch 76/100, Val Acc=0.7327, Val Loss=1.3364, lr=0.0010
[2025-04-29 21:56:22,374][train][INFO] - Epoch 96/100, Val Acc=0.7382, Val Loss=1.3228, lr=0.0001
[2025-04-29 21:56:31,637][train][INFO] - Epoch 97/100, Val Acc=0.7374, Val Loss=1.3227, lr=0.0001
[2025-04-29 21:56:34,230][train][INFO] - Epoch 77/100, Val Acc=0.7326, Val Loss=1.3347, lr=0.0010
[2025-04-29 21:56:40,905][train][INFO] - Epoch 98/100, Val Acc=0.7373, Val Loss=1.3235, lr=0.0001
[2025-04-29 21:56:48,515][train][INFO] - Epoch 78/100, Val Acc=0.7315, Val Loss=1.3324, lr=0.0010
[2025-04-29 21:56:50,109][train][INFO] - Epoch 99/100, Val Acc=0.7371, Val Loss=1.3252, lr=0.0001
[2025-04-29 21:56:59,506][train][INFO] - Epoch 100/100, Val Acc=0.7382, Val Loss=1.3263, lr=0.0001
[2025-04-29 21:57:03,092][train][INFO] - Epoch 79/100, Val Acc=0.7353, Val Loss=1.3338, lr=0.0010
[2025-04-29 21:57:05,043][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7399
[2025-04-29 21:57:05,048][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:57:17,660][train][INFO] - Epoch 80/100, Val Acc=0.7349, Val Loss=1.3414, lr=0.0010
[2025-04-29 21:57:31,910][train][INFO] - Epoch 81/100, Val Acc=0.7341, Val Loss=1.3427, lr=0.0010
[2025-04-29 21:57:46,175][train][INFO] - Epoch 82/100, Val Acc=0.7350, Val Loss=1.3407, lr=0.0010
[2025-04-29 21:58:00,344][train][INFO] - Epoch 83/100, Val Acc=0.7353, Val Loss=1.3484, lr=0.0010
[2025-04-29 21:58:14,672][train][INFO] - Epoch 84/100, Val Acc=0.7349, Val Loss=1.3521, lr=0.0010
[2025-04-29 21:58:28,912][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3379, lr=0.0010
[2025-04-29 21:58:43,184][train][INFO] - Epoch 86/100, Val Acc=0.7362, Val Loss=1.3448, lr=0.0010
[2025-04-29 21:58:57,470][train][INFO] - Epoch 87/100, Val Acc=0.7361, Val Loss=1.3424, lr=0.0010
[2025-04-29 21:59:12,035][train][INFO] - Epoch 88/100, Val Acc=0.7351, Val Loss=1.3510, lr=0.0010
[2025-04-29 21:59:26,523][train][INFO] - Epoch 89/100, Val Acc=0.7370, Val Loss=1.3482, lr=0.0010
[2025-04-29 21:59:31,660][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:59:40,781][train][INFO] - Epoch 90/100, Val Acc=0.7366, Val Loss=1.3503, lr=0.0010
[2025-04-29 21:59:55,084][train][INFO] - Epoch 91/100, Val Acc=0.7368, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:00:09,277][train][INFO] - Epoch 92/100, Val Acc=0.7379, Val Loss=1.3508, lr=0.0001
[2025-04-29 22:00:23,596][train][INFO] - Epoch 93/100, Val Acc=0.7367, Val Loss=1.3444, lr=0.0001
[2025-04-29 22:00:37,848][train][INFO] - Epoch 94/100, Val Acc=0.7372, Val Loss=1.3434, lr=0.0001
[2025-04-29 22:00:52,206][train][INFO] - Epoch 95/100, Val Acc=0.7360, Val Loss=1.3468, lr=0.0001
[2025-04-29 22:01:06,806][train][INFO] - Epoch 96/100, Val Acc=0.7360, Val Loss=1.3439, lr=0.0001
[2025-04-29 22:01:21,028][train][INFO] - Epoch 97/100, Val Acc=0.7365, Val Loss=1.3457, lr=0.0001
[2025-04-29 22:01:35,385][train][INFO] - Epoch 98/100, Val Acc=0.7364, Val Loss=1.3448, lr=0.0001
[2025-04-29 22:01:49,735][train][INFO] - Epoch 99/100, Val Acc=0.7352, Val Loss=1.3470, lr=0.0001
[2025-04-29 22:01:56,143][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:01:56,637][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 22:02:03,915][train][INFO] - Epoch 100/100, Val Acc=0.7362, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:02:09,533][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7379
[2025-04-29 22:02:09,537][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 22:04:56,467][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 22:07:44,794][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:07:45,261][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 11:30:24,255][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 11:31:05,948][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-04-30 11:31:42,751][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8054, lr=0.001
[2025-04-30 11:32:19,426][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6650, lr=0.001
[2025-04-30 11:32:54,785][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8170, lr=0.001
[2025-04-30 11:33:32,060][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.8789, lr=0.001
[2025-04-30 11:34:08,533][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9001, lr=0.001
[2025-04-30 11:34:45,365][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7399, lr=0.001
[2025-04-30 11:35:21,000][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4222, lr=0.001
[2025-04-30 11:35:21,026][meta_train][INFO] - epoch_1 saved !
[2025-04-30 11:35:58,599][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3554, lr=0.001
[2025-04-30 11:36:33,926][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1076, lr=0.001
[2025-04-30 11:37:10,427][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1257, lr=0.001
[2025-04-30 11:37:47,584][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.2335, lr=0.001
[2025-04-30 11:38:25,370][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0825, lr=0.001
[2025-04-30 11:39:00,110][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0752, lr=0.001
[2025-04-30 11:39:37,186][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0667, lr=0.001
[2025-04-30 11:40:14,282][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0571, lr=0.001
[2025-04-30 11:40:14,298][meta_train][INFO] - epoch_2 saved !
[2025-04-30 11:40:50,716][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.0852, lr=0.001
[2025-04-30 11:41:27,473][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0791, lr=0.001
[2025-04-30 11:42:04,144][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0776, lr=0.001
[2025-04-30 11:42:39,344][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.0982, lr=0.001
[2025-04-30 11:43:16,974][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2242, lr=0.001
[2025-04-30 11:43:53,635][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2048, lr=0.001
[2025-04-30 11:44:30,516][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1049, lr=0.001
[2025-04-30 11:45:06,754][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1000, lr=0.001
[2025-04-30 11:45:06,764][meta_train][INFO] - epoch_3 saved !
[2025-04-30 11:45:43,129][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1212, lr=0.001
[2025-04-30 11:46:19,514][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1225, lr=0.001
[2025-04-30 11:46:57,122][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.2522, lr=0.001
[2025-04-30 11:47:33,116][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1173, lr=0.001
[2025-04-30 11:48:11,617][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1231, lr=0.001
[2025-04-30 11:48:46,782][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.2112, lr=0.001
[2025-04-30 11:49:23,435][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.3869, lr=0.001
[2025-04-30 11:49:59,857][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.1797, lr=0.001
[2025-04-30 11:49:59,866][meta_train][INFO] - epoch_4 saved !
[2025-04-30 11:50:36,772][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.3443, lr=0.001
[2025-04-30 11:51:13,921][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.1748, lr=0.001
[2025-04-30 11:51:51,357][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.2491, lr=0.001
[2025-04-30 11:52:27,538][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.2513, lr=0.001
[2025-04-30 11:53:04,557][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=0.6399, lr=0.001
[2025-04-30 11:53:40,932][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.3194, lr=0.001
[2025-04-30 11:54:17,476][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.4219, lr=0.001
[2025-04-30 11:54:53,955][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.3403, lr=0.001
[2025-04-30 11:54:53,970][meta_train][INFO] - epoch_5 saved !
[2025-04-30 11:55:29,845][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=0.7997, lr=0.001
[2025-04-30 11:56:07,743][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.2902, lr=0.001
[2025-04-30 11:56:43,778][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.4564, lr=0.001
[2025-04-30 11:57:20,913][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=0.5632, lr=0.001
[2025-04-30 11:57:57,292][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.3177, lr=0.001
[2025-04-30 11:58:33,601][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.3453, lr=0.001
[2025-04-30 11:59:10,661][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.3072, lr=0.001
[2025-04-30 11:59:48,467][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.3339, lr=0.001
[2025-04-30 11:59:48,477][meta_train][INFO] - epoch_6 saved !
[2025-04-30 12:00:23,675][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=0.5760, lr=0.001
[2025-04-30 12:01:00,835][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=0.6666, lr=0.001
[2025-04-30 12:01:37,880][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.3024, lr=0.001
[2025-04-30 12:02:14,031][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.4275, lr=0.001
[2025-04-30 12:02:49,688][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.2487, lr=0.001
[2025-04-30 12:03:27,059][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.2335, lr=0.001
[2025-04-30 12:04:04,860][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.2636, lr=0.001
[2025-04-30 12:04:40,666][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.2809, lr=0.001
[2025-04-30 12:04:40,687][meta_train][INFO] - epoch_7 saved !
[2025-04-30 12:05:17,434][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.2743, lr=0.001
[2025-04-30 12:05:53,765][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.2842, lr=0.001
[2025-04-30 12:06:30,971][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.2406, lr=0.001
[2025-04-30 12:07:08,017][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.5674, lr=0.001
[2025-04-30 12:07:44,928][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.2337, lr=0.001
[2025-04-30 12:08:22,206][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.2148, lr=0.001
[2025-04-30 12:08:58,125][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.4072, lr=0.001
[2025-04-30 12:09:35,769][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.4274, lr=0.001
[2025-04-30 12:09:35,791][meta_train][INFO] - epoch_8 saved !
[2025-04-30 12:10:11,573][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.2075, lr=0.001
[2025-04-30 12:10:48,860][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.2202, lr=0.001
[2025-04-30 12:11:24,895][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.1966, lr=0.001
[2025-04-30 12:12:01,391][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.4453, lr=0.001
[2025-04-30 12:12:37,778][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.5933, lr=0.001
[2025-04-30 12:13:14,047][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.4373, lr=0.001
[2025-04-30 12:13:51,992][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.2809, lr=0.001
[2025-04-30 12:14:29,253][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2327, lr=0.001
[2025-04-30 12:14:29,266][meta_train][INFO] - epoch_9 saved !
[2025-04-30 12:15:05,037][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.3388, lr=0.001
[2025-04-30 12:15:42,812][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3388, lr=0.001
[2025-04-30 12:16:18,289][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4107, lr=0.001
[2025-04-30 12:16:55,440][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.8359, lr=0.001
[2025-04-30 12:17:32,591][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6126, lr=0.001
[2025-04-30 12:18:07,891][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.0799, lr=0.001
[2025-04-30 12:18:45,255][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.8904, lr=0.001
[2025-04-30 12:19:22,893][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.5186, lr=0.001
[2025-04-30 12:19:22,914][meta_train][INFO] - epoch_10 saved !
[2025-04-30 12:19:59,085][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=0.8725, lr=0.0001
[2025-04-30 12:20:34,876][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.5895, lr=0.0001
[2025-04-30 12:21:12,807][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.7851, lr=0.0001
[2025-04-30 12:21:49,574][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=0.9620, lr=0.0001
[2025-04-30 12:22:25,340][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.3022, lr=0.0001
[2025-04-30 12:23:01,975][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.3555, lr=0.0001
[2025-04-30 12:23:37,159][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=0.7466, lr=0.0001
[2025-04-30 12:24:14,287][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=0.9694, lr=0.0001
[2025-04-30 12:24:14,297][meta_train][INFO] - epoch_11 saved !
[2025-04-30 12:24:50,758][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=0.8743, lr=0.0001
[2025-04-30 12:25:27,673][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=0.7618, lr=0.0001
[2025-04-30 12:26:04,864][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=0.9493, lr=0.0001
[2025-04-30 12:26:42,127][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=1.6123, lr=0.0001
[2025-04-30 12:27:18,295][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=1.3867, lr=0.0001
[2025-04-30 12:27:54,616][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=0.7477, lr=0.0001
[2025-04-30 12:28:31,780][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=1.3346, lr=0.0001
[2025-04-30 12:29:07,851][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=1.0194, lr=0.0001
[2025-04-30 12:29:07,869][meta_train][INFO] - epoch_12 saved !
[2025-04-30 12:29:43,863][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=0.9206, lr=0.0001
[2025-04-30 12:30:21,150][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=1.3698, lr=0.0001
[2025-04-30 12:30:57,335][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=1.0467, lr=0.0001
[2025-04-30 12:31:34,905][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=0.7990, lr=0.0001
[2025-04-30 12:32:11,724][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=1.6963, lr=0.0001
[2025-04-30 12:32:47,786][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=1.0581, lr=0.0001
[2025-04-30 12:33:23,972][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=1.4734, lr=0.0001
[2025-04-30 12:34:01,307][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=0.8539, lr=0.0001
[2025-04-30 12:34:01,316][meta_train][INFO] - epoch_13 saved !
[2025-04-30 12:34:37,072][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=1.1031, lr=0.0001
[2025-04-30 12:35:13,784][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=0.8312, lr=0.0001
[2025-04-30 12:35:51,002][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=1.7404, lr=0.0001
[2025-04-30 12:36:26,620][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=1.5112, lr=0.0001
[2025-04-30 12:37:03,847][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=1.4786, lr=0.0001
[2025-04-30 12:37:41,593][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=1.1136, lr=0.0001
[2025-04-30 12:38:18,119][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=1.0420, lr=0.0001
[2025-04-30 12:38:53,648][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=0.8894, lr=0.0001
[2025-04-30 12:38:53,673][meta_train][INFO] - epoch_14 saved !
[2025-04-30 12:39:31,866][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=1.5031, lr=0.0001
[2025-04-30 12:40:06,696][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=1.5508, lr=0.0001
[2025-04-30 12:40:44,200][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=1.0657, lr=0.0001
[2025-04-30 12:41:19,736][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=1.8003, lr=0.0001
[2025-04-30 12:41:56,585][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=1.1533, lr=0.0001
[2025-04-30 12:42:33,061][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=0.8785, lr=0.0001
[2025-04-30 12:43:10,243][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=1.1917, lr=0.0001
[2025-04-30 12:43:48,542][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=0.9312, lr=0.0001
[2025-04-30 12:43:48,556][meta_train][INFO] - epoch_15 saved !
[2025-04-30 12:44:24,865][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=1.5742, lr=0.0001
[2025-04-30 12:45:00,772][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=0.8974, lr=0.0001
[2025-04-30 12:45:37,465][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=1.2269, lr=0.0001
[2025-04-30 12:46:15,539][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=0.9450, lr=0.0001
[2025-04-30 12:46:50,800][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=1.1436, lr=0.0001
[2025-04-30 12:47:27,389][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=1.8749, lr=0.0001
[2025-04-30 12:48:04,391][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=1.2180, lr=0.0001
[2025-04-30 12:48:40,353][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=1.6475, lr=0.0001
[2025-04-30 12:48:40,363][meta_train][INFO] - epoch_16 saved !
[2025-04-30 12:49:17,625][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=1.6307, lr=0.0001
[2025-04-30 12:49:54,820][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=1.8982, lr=0.0001
[2025-04-30 12:50:30,002][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=1.6692, lr=0.0001
[2025-04-30 12:51:06,541][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=1.1927, lr=0.0001
[2025-04-30 12:51:44,082][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=1.2609, lr=0.0001
[2025-04-30 12:52:21,130][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=0.9492, lr=0.0001
[2025-04-30 12:52:58,191][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=1.2997, lr=0.0001
[2025-04-30 12:53:33,806][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=1.0031, lr=0.0001
[2025-04-30 12:53:33,831][meta_train][INFO] - epoch_17 saved !
[2025-04-30 12:54:11,256][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=1.0060, lr=0.0001
[2025-04-30 12:54:47,403][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=1.9358, lr=0.0001
[2025-04-30 12:55:24,521][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=0.9571, lr=0.0001
[2025-04-30 12:56:00,389][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=1.6929, lr=0.0001
[2025-04-30 12:56:37,571][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=1.3211, lr=0.0001
[2025-04-30 12:57:13,994][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=1.7224, lr=0.0001
[2025-04-30 12:57:50,673][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=1.3154, lr=0.0001
[2025-04-30 12:58:26,517][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=1.2576, lr=0.0001
[2025-04-30 12:58:26,536][meta_train][INFO] - epoch_18 saved !
[2025-04-30 12:59:04,439][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=1.0470, lr=0.0001
[2025-04-30 12:59:40,511][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=1.7412, lr=0.0001
[2025-04-30 13:00:16,046][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=1.2790, lr=0.0001
[2025-04-30 13:00:52,470][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=1.7692, lr=0.0001
[2025-04-30 13:01:28,991][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=2.0034, lr=0.0001
[2025-04-30 13:02:06,039][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=1.3883, lr=0.0001
[2025-04-30 13:02:43,660][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=1.0351, lr=0.0001
[2025-04-30 13:03:20,390][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=1.3947, lr=0.0001
[2025-04-30 13:03:20,416][meta_train][INFO] - epoch_19 saved !
[2025-04-30 13:03:56,861][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=1.4176, lr=0.0001
[2025-04-30 13:04:34,460][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=1.4064, lr=0.0001
[2025-04-30 13:05:10,684][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=1.8089, lr=0.0001
[2025-04-30 13:05:48,404][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=1.1281, lr=0.0001
[2025-04-30 13:06:24,560][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=1.8275, lr=0.0001
[2025-04-30 13:07:01,289][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=2.0519, lr=0.0001
[2025-04-30 13:07:38,340][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=1.3728, lr=0.0001
[2025-04-30 13:08:14,116][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=1.0913, lr=0.0001
[2025-04-30 13:08:14,129][meta_train][INFO] - epoch_20 saved !
[2025-04-30 13:08:50,954][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=1.3983, lr=0.0001
[2025-04-30 13:09:27,719][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=1.1925, lr=0.0001
[2025-04-30 13:10:05,077][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=1.4889, lr=0.0001
[2025-04-30 13:10:42,387][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=2.1082, lr=0.0001
[2025-04-30 13:11:18,984][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=1.5182, lr=0.0001
[2025-04-30 13:11:55,711][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=1.9138, lr=0.0001
[2025-04-30 13:12:31,729][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=1.9239, lr=0.0001
[2025-04-30 13:13:08,736][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=1.1780, lr=0.0001
[2025-04-30 13:13:08,752][meta_train][INFO] - epoch_21 saved !
[2025-04-30 13:13:45,389][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=1.1925, lr=0.0001
[2025-04-30 13:14:21,714][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=1.5730, lr=0.0001
[2025-04-30 13:14:58,971][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=1.9641, lr=0.0001
[2025-04-30 13:15:35,299][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=2.1709, lr=0.0001
[2025-04-30 13:16:10,930][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=1.9764, lr=0.0001
[2025-04-30 13:16:46,927][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=1.5255, lr=0.0001
[2025-04-30 13:17:24,725][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=1.3369, lr=0.0001
[2025-04-30 13:18:01,406][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=1.6203, lr=0.0001
[2025-04-30 13:18:01,416][meta_train][INFO] - epoch_22 saved !
[2025-04-30 13:18:37,027][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=2.1983, lr=0.0001
[2025-04-30 13:19:14,830][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=1.6383, lr=0.0001
[2025-04-30 13:19:51,813][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=1.6375, lr=0.0001
[2025-04-30 13:20:28,835][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=1.2906, lr=0.0001
[2025-04-30 13:21:04,599][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=2.0282, lr=0.0001
[2025-04-30 13:21:41,779][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=1.4064, lr=0.0001
[2025-04-30 13:22:18,726][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=2.0621, lr=0.0001
[2025-04-30 13:22:54,410][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=1.6185, lr=0.0001
[2025-04-30 13:22:54,422][meta_train][INFO] - epoch_23 saved !
[2025-04-30 13:23:32,152][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=2.0900, lr=0.0001
[2025-04-30 13:24:07,802][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=2.0748, lr=0.0001
[2025-04-30 13:24:44,405][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=1.3863, lr=0.0001
[2025-04-30 13:25:21,752][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=1.7474, lr=0.0001
[2025-04-30 13:25:58,823][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=1.5081, lr=0.0001
[2025-04-30 13:26:34,489][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=2.2887, lr=0.0001
[2025-04-30 13:27:10,889][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=1.6879, lr=0.0001
[2025-04-30 13:27:48,356][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=1.7899, lr=0.0001
[2025-04-30 13:27:48,366][meta_train][INFO] - epoch_24 saved !
[2025-04-30 13:28:26,382][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=2.1619, lr=0.0001
[2025-04-30 13:29:03,273][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=1.8001, lr=0.0001
[2025-04-30 13:29:39,061][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=1.7130, lr=0.0001
[2025-04-30 13:30:17,436][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=1.5640, lr=0.0001
[2025-04-30 13:30:53,349][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=2.1600, lr=0.0001
[2025-04-30 13:31:29,605][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=1.4942, lr=0.0001
[2025-04-30 13:32:07,107][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=2.3633, lr=0.0001
[2025-04-30 13:32:43,807][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=1.8736, lr=0.0001
[2025-04-30 13:32:43,816][meta_train][INFO] - epoch_25 saved !
[2025-04-30 13:33:19,984][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=2.2291, lr=0.0001
[2025-04-30 13:33:56,101][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=1.5906, lr=0.0001
[2025-04-30 13:34:33,708][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=1.8416, lr=0.0001
[2025-04-30 13:35:09,418][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=2.3292, lr=0.0001
[2025-04-30 13:35:47,243][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=1.7285, lr=0.0001
[2025-04-30 13:36:23,860][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=1.9637, lr=0.0001
[2025-04-30 13:37:01,260][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=1.9461, lr=0.0001
[2025-04-30 13:37:38,245][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=2.4358, lr=0.0001
[2025-04-30 13:37:38,266][meta_train][INFO] - epoch_26 saved !
[2025-04-30 13:38:14,557][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=2.4367, lr=0.0001
[2025-04-30 13:38:51,544][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=1.6425, lr=0.0001
[2025-04-30 13:39:28,199][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=1.7608, lr=0.0001
[2025-04-30 13:40:04,953][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=1.9124, lr=0.0001
[2025-04-30 13:40:40,627][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=2.3352, lr=0.0001
[2025-04-30 13:41:17,542][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=2.0533, lr=0.0001
[2025-04-30 13:41:53,684][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=2.0607, lr=0.0001
[2025-04-30 13:42:31,120][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=2.4524, lr=0.0001
[2025-04-30 13:42:31,129][meta_train][INFO] - epoch_27 saved !
[2025-04-30 13:43:07,455][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=1.7818, lr=0.0001
[2025-04-30 13:43:44,537][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=2.0985, lr=0.0001
[2025-04-30 13:44:22,453][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=1.9993, lr=0.0001
[2025-04-30 13:44:59,605][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=1.8905, lr=0.0001
[2025-04-30 13:45:36,201][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=2.5454, lr=0.0001
[2025-04-30 13:46:12,557][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=2.4789, lr=0.0001
[2025-04-30 13:46:50,100][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=2.1208, lr=0.0001
[2025-04-30 13:47:25,262][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=2.4365, lr=0.0001
[2025-04-30 13:47:25,276][meta_train][INFO] - epoch_28 saved !
[2025-04-30 13:48:02,827][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=1.9544, lr=0.0001
[2025-04-30 13:48:39,980][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=2.5956, lr=0.0001
[2025-04-30 13:49:16,420][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=2.0958, lr=0.0001
[2025-04-30 13:49:54,202][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=1.9444, lr=0.0001
[2025-04-30 13:50:30,068][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=2.2404, lr=0.0001
[2025-04-30 13:51:06,432][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=2.5294, lr=0.0001
[2025-04-30 13:51:44,688][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=2.2600, lr=0.0001
[2025-04-30 13:52:20,999][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=2.6263, lr=0.0001
[2025-04-30 13:52:21,008][meta_train][INFO] - epoch_29 saved !
[2025-04-30 13:52:57,914][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=2.0111, lr=0.0001
[2025-04-30 13:53:34,384][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=2.5477, lr=0.0001
[2025-04-30 13:54:10,822][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=2.2841, lr=0.0001
[2025-04-30 13:54:48,679][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=2.6324, lr=0.0001
[2025-04-30 13:55:24,801][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=2.2896, lr=0.0001
[2025-04-30 13:56:01,176][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=2.2000, lr=0.0001
[2025-04-30 13:56:37,533][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=2.6821, lr=0.0001
[2025-04-30 13:57:15,480][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=2.1656, lr=0.0001
[2025-04-30 13:57:15,501][meta_train][INFO] - epoch_30 saved !
[2025-04-30 13:57:51,580][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=2.7121, lr=0.0001
[2025-04-30 13:58:28,610][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=2.1520, lr=0.0001
[2025-04-30 13:59:04,835][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=2.4002, lr=0.0001
[2025-04-30 13:59:42,057][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=2.4187, lr=0.0001
[2025-04-30 14:00:18,419][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=2.2768, lr=0.0001
[2025-04-30 14:00:55,155][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=2.6864, lr=0.0001
[2025-04-30 14:01:31,786][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=2.7843, lr=0.0001
[2025-04-30 14:02:08,198][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=2.3649, lr=0.0001
[2025-04-30 14:02:08,208][meta_train][INFO] - epoch_31 saved !
[2025-04-30 14:02:45,338][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=2.7234, lr=0.0001
[2025-04-30 14:03:21,129][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=2.3919, lr=0.0001
[2025-04-30 14:03:58,481][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=2.5084, lr=0.0001
[2025-04-30 14:04:34,923][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=2.3950, lr=0.0001
[2025-04-30 14:05:11,471][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=2.8489, lr=0.0001
[2025-04-30 14:05:46,963][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=2.8773, lr=0.0001
[2025-04-30 14:06:24,197][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=2.5695, lr=0.0001
[2025-04-30 14:07:00,705][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=2.4046, lr=0.0001
[2025-04-30 14:07:00,715][meta_train][INFO] - epoch_32 saved !
[2025-04-30 14:07:38,005][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=2.8694, lr=0.0001
[2025-04-30 14:08:14,429][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=2.4308, lr=0.0001
[2025-04-30 14:08:50,638][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=2.5111, lr=0.0001
[2025-04-30 14:09:28,134][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=2.6373, lr=0.0001
[2025-04-30 14:10:03,747][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=2.5310, lr=0.0001
[2025-04-30 14:10:41,161][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=2.6580, lr=0.0001
[2025-04-30 14:11:17,495][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=2.9908, lr=0.0001
[2025-04-30 14:11:54,880][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=2.9203, lr=0.0001
[2025-04-30 14:11:54,889][meta_train][INFO] - epoch_33 saved !
[2025-04-30 14:12:30,927][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=2.9339, lr=0.0001
[2025-04-30 14:13:07,353][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=2.7181, lr=0.0001
[2025-04-30 14:13:44,480][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=3.0487, lr=0.0001
[2025-04-30 14:14:20,866][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=2.6529, lr=0.0001
[2025-04-30 14:14:57,715][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=2.7952, lr=0.0001
[2025-04-30 14:15:34,683][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=3.0224, lr=0.0001
[2025-04-30 14:16:10,148][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=2.7162, lr=0.0001
[2025-04-30 14:16:47,178][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=2.7318, lr=0.0001
[2025-04-30 14:16:47,188][meta_train][INFO] - epoch_34 saved !
[2025-04-30 14:17:24,456][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=2.7620, lr=0.0001
[2025-04-30 14:18:00,594][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=2.7951, lr=0.0001
[2025-04-30 14:18:36,772][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=2.8815, lr=0.0001
[2025-04-30 14:19:14,633][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=2.8275, lr=0.0001
[2025-04-30 14:19:50,276][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=2.9726, lr=0.0001
[2025-04-30 14:20:28,446][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=3.2458, lr=0.0001
[2025-04-30 14:21:03,642][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=3.1808, lr=0.0001
[2025-04-30 14:21:40,863][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=3.1821, lr=0.0001
[2025-04-30 14:21:40,872][meta_train][INFO] - epoch_35 saved !
[2025-04-30 14:22:16,993][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=3.2076, lr=0.0001
[2025-04-30 14:22:53,822][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=3.0052, lr=0.0001
[2025-04-30 14:23:30,452][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=2.9815, lr=0.0001
[2025-04-30 14:24:07,031][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=3.2328, lr=0.0001
[2025-04-30 14:24:42,943][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=3.3473, lr=0.0001
[2025-04-30 14:25:20,288][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=3.0128, lr=0.0001
[2025-04-30 14:25:56,646][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=3.1530, lr=0.0001
[2025-04-30 14:26:33,618][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=3.1278, lr=0.0001
[2025-04-30 14:26:33,628][meta_train][INFO] - epoch_36 saved !
[2025-04-30 14:27:11,125][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=3.1987, lr=0.0001
[2025-04-30 14:27:48,615][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=3.3715, lr=0.0001
[2025-04-30 14:28:24,329][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=3.4622, lr=0.0001
[2025-04-30 14:29:01,413][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=3.1774, lr=0.0001
[2025-04-30 14:29:38,346][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=3.2469, lr=0.0001
[2025-04-30 14:30:14,370][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=3.1810, lr=0.0001
[2025-04-30 14:30:51,049][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=3.4126, lr=0.0001
[2025-04-30 14:31:28,511][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=3.3032, lr=0.0001
[2025-04-30 14:31:28,521][meta_train][INFO] - epoch_37 saved !
[2025-04-30 14:32:04,163][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=3.4610, lr=0.0001
[2025-04-30 14:32:41,038][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=3.3987, lr=0.0001
[2025-04-30 14:33:17,980][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=3.5817, lr=0.0001
[2025-04-30 14:33:54,054][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=3.4818, lr=0.0001
[2025-04-30 14:34:31,972][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=3.3816, lr=0.0001
[2025-04-30 14:35:07,654][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=3.4444, lr=0.0001
[2025-04-30 14:35:44,796][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=3.4904, lr=0.0001
[2025-04-30 14:36:22,151][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=3.7697, lr=0.0001
[2025-04-30 14:36:22,168][meta_train][INFO] - epoch_38 saved !
[2025-04-30 14:36:58,595][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=3.5790, lr=0.0001
[2025-04-30 14:37:36,291][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=3.7798, lr=0.0001
[2025-04-30 14:38:12,052][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=3.6178, lr=0.0001
[2025-04-30 14:38:49,871][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=3.5409, lr=0.0001
[2025-04-30 14:39:26,117][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=3.6233, lr=0.0001
[2025-04-30 14:40:03,693][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=3.7616, lr=0.0001
[2025-04-30 14:40:40,297][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=3.6092, lr=0.0001
[2025-04-30 14:41:16,344][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=3.6010, lr=0.0001
[2025-04-30 14:41:16,357][meta_train][INFO] - epoch_39 saved !
[2025-04-30 14:41:52,497][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=3.9475, lr=0.0001
[2025-04-30 14:42:29,477][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=3.6694, lr=0.0001
[2025-04-30 14:43:05,334][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=3.7644, lr=0.0001
[2025-04-30 14:43:42,639][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=3.8493, lr=0.0001
[2025-04-30 14:44:18,360][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=3.9724, lr=0.0001
[2025-04-30 14:44:55,444][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=3.8169, lr=0.0001
[2025-04-30 14:45:32,688][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=3.9219, lr=0.0001
[2025-04-30 14:46:09,639][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=3.9460, lr=0.0001
[2025-04-30 14:46:09,649][meta_train][INFO] - epoch_40 saved !
[2025-04-30 14:46:47,258][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=3.9660, lr=0.0001
[2025-04-30 14:47:24,395][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=3.9911, lr=0.0001
[2025-04-30 14:48:00,431][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.0004, lr=0.0001
[2025-04-30 14:48:37,122][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.2167, lr=0.0001
[2025-04-30 14:49:13,747][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=3.9656, lr=0.0001
[2025-04-30 14:49:50,864][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.0105, lr=0.0001
[2025-04-30 14:50:26,305][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=3.9681, lr=0.0001
[2025-04-30 14:51:02,783][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.1813, lr=0.0001
[2025-04-30 14:51:02,793][meta_train][INFO] - epoch_41 saved !
[2025-04-30 14:51:39,255][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.0745, lr=0.0001
[2025-04-30 14:52:15,418][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.0376, lr=0.0001
[2025-04-30 14:52:53,014][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.1511, lr=0.0001
[2025-04-30 14:53:28,595][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.1841, lr=0.0001
[2025-04-30 14:54:05,462][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.2162, lr=0.0001
[2025-04-30 14:54:42,934][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.3120, lr=0.0001
[2025-04-30 14:55:18,665][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.1839, lr=0.0001
[2025-04-30 14:55:55,260][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.4592, lr=0.0001
[2025-04-30 14:55:55,269][meta_train][INFO] - epoch_42 saved !
[2025-04-30 14:56:31,337][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.1990, lr=0.0001
[2025-04-30 14:57:08,425][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.2397, lr=0.0001
[2025-04-30 14:57:44,741][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.3952, lr=0.0001
[2025-04-30 14:58:21,701][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.3432, lr=0.0001
[2025-04-30 14:58:59,225][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.5337, lr=0.0001
[2025-04-30 14:59:34,952][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.3555, lr=0.0001
[2025-04-30 15:00:11,605][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.3604, lr=0.0001
[2025-04-30 15:00:49,153][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.3683, lr=0.0001
[2025-04-30 15:00:49,174][meta_train][INFO] - epoch_43 saved !
[2025-04-30 15:01:26,408][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.4823, lr=0.0001
[2025-04-30 15:02:03,121][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.4347, lr=0.0001
[2025-04-30 15:02:40,279][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.4197, lr=0.0001
[2025-04-30 15:03:15,836][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.4393, lr=0.0001
[2025-04-30 15:03:52,513][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.4259, lr=0.0001
[2025-04-30 15:04:29,427][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.4869, lr=0.0001
[2025-04-30 15:05:05,544][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6678, lr=0.0001
[2025-04-30 15:05:43,199][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.4542, lr=0.0001
[2025-04-30 15:05:43,208][meta_train][INFO] - epoch_44 saved !
[2025-04-30 15:06:20,232][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.5289, lr=0.0001
[2025-04-30 15:06:55,456][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.4768, lr=0.0001
[2025-04-30 15:07:32,765][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6976, lr=0.0001
[2025-04-30 15:08:10,101][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.5090, lr=0.0001
[2025-04-30 15:08:46,614][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6170, lr=0.0001
[2025-04-30 15:09:22,595][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.5492, lr=0.0001
[2025-04-30 15:09:59,977][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.5369, lr=0.0001
[2025-04-30 15:10:37,074][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.5804, lr=0.0001
[2025-04-30 15:10:37,093][meta_train][INFO] - epoch_45 saved !
[2025-04-30 15:11:14,195][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.5548, lr=0.0001
[2025-04-30 15:11:50,447][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.5810, lr=0.0001
[2025-04-30 15:12:27,362][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.7379, lr=0.0001
[2025-04-30 15:13:05,084][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6110, lr=0.0001
[2025-04-30 15:13:41,823][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.5787, lr=0.0001
[2025-04-30 15:14:18,410][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6234, lr=0.0001
[2025-04-30 15:14:54,882][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6789, lr=0.0001
[2025-04-30 15:15:31,407][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.5922, lr=0.0001
[2025-04-30 15:15:31,425][meta_train][INFO] - epoch_46 saved !
[2025-04-30 15:16:08,663][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6247, lr=0.0001
[2025-04-30 15:16:45,440][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6206, lr=0.0001
[2025-04-30 15:17:21,797][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.7554, lr=0.0001
[2025-04-30 15:17:57,716][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6936, lr=0.0001
[2025-04-30 15:18:34,140][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6517, lr=0.0001
[2025-04-30 15:19:11,935][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6494, lr=0.0001
[2025-04-30 15:19:48,902][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6140, lr=0.0001
[2025-04-30 15:20:24,545][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6330, lr=0.0001
[2025-04-30 15:20:24,559][meta_train][INFO] - epoch_47 saved !
[2025-04-30 15:21:01,527][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6501, lr=0.0001
[2025-04-30 15:21:39,323][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:22:16,233][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6422, lr=0.0001
[2025-04-30 15:22:52,280][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6257, lr=0.0001
[2025-04-30 15:23:29,201][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6602, lr=0.0001
[2025-04-30 15:24:05,683][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.7545, lr=0.0001
[2025-04-30 15:24:42,175][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.7099, lr=0.0001
[2025-04-30 15:25:18,484][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6640, lr=0.0001
[2025-04-30 15:25:18,494][meta_train][INFO] - epoch_48 saved !
[2025-04-30 15:25:55,958][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:26:31,697][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.7109, lr=0.0001
[2025-04-30 15:27:08,300][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6359, lr=0.0001
[2025-04-30 15:27:45,735][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6753, lr=0.0001
[2025-04-30 15:28:22,583][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.7471, lr=0.0001
[2025-04-30 15:28:59,195][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6674, lr=0.0001
[2025-04-30 15:29:35,670][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6767, lr=0.0001
[2025-04-30 15:30:11,642][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6616, lr=0.0001
[2025-04-30 15:30:11,651][meta_train][INFO] - epoch_49 saved !
[2025-04-30 15:30:49,352][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.7403, lr=0.0001
[2025-04-30 15:31:24,539][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.7077, lr=0.0001
[2025-04-30 15:32:01,903][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6675, lr=0.0001
[2025-04-30 15:32:38,710][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6636, lr=0.0001
[2025-04-30 15:33:15,247][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6427, lr=0.0001
[2025-04-30 15:33:52,739][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6807, lr=0.0001
[2025-04-30 15:34:29,668][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6648, lr=0.0001
[2025-04-30 15:35:05,862][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6739, lr=0.0001
[2025-04-30 15:35:05,872][meta_train][INFO] - epoch_50 saved !
[2025-04-30 15:35:42,956][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6737, lr=0.0001
[2025-04-30 15:36:20,265][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.7294, lr=0.0001
[2025-04-30 15:36:56,548][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:37:32,936][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6656, lr=0.0001
[2025-04-30 15:38:09,846][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6673, lr=0.0001
[2025-04-30 15:38:47,298][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6450, lr=0.0001
[2025-04-30 15:39:22,797][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.7009, lr=0.0001
[2025-04-30 15:39:59,924][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6831, lr=0.0001
[2025-04-30 15:39:59,934][meta_train][INFO] - epoch_51 saved !
[2025-04-30 15:40:36,595][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6693, lr=0.0001
[2025-04-30 15:41:12,417][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6450, lr=0.0001
[2025-04-30 15:41:49,276][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6645, lr=0.0001
[2025-04-30 15:42:26,613][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6602, lr=0.0001
[2025-04-30 15:43:02,715][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6636, lr=0.0001
[2025-04-30 15:43:39,790][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6818, lr=0.0001
[2025-04-30 15:44:16,646][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6945, lr=0.0001
[2025-04-30 15:44:52,523][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.7070, lr=0.0001
[2025-04-30 15:44:52,545][meta_train][INFO] - epoch_52 saved !
[2025-04-30 15:45:29,807][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.7048, lr=0.0001
[2025-04-30 15:46:06,320][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6608, lr=0.0001
[2025-04-30 15:46:41,669][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6888, lr=0.0001
[2025-04-30 15:47:19,053][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6430, lr=0.0001
[2025-04-30 15:47:54,524][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6594, lr=0.0001
[2025-04-30 15:48:32,309][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6531, lr=0.0001
[2025-04-30 15:49:09,483][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6557, lr=0.0001
[2025-04-30 15:49:46,235][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6766, lr=0.0001
[2025-04-30 15:49:46,258][meta_train][INFO] - epoch_53 saved !
[2025-04-30 15:50:22,014][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6845, lr=0.0001
[2025-04-30 15:50:58,579][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6923, lr=0.0001
[2025-04-30 15:51:35,610][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6552, lr=0.0001
[2025-04-30 15:52:12,636][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6742, lr=0.0001
[2025-04-30 15:52:48,522][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6485, lr=0.0001
[2025-04-30 15:53:25,442][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6500, lr=0.0001
[2025-04-30 15:54:03,080][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6406, lr=0.0001
[2025-04-30 15:54:38,766][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6533, lr=0.0001
[2025-04-30 15:54:38,782][meta_train][INFO] - epoch_54 saved !
[2025-04-30 15:55:14,910][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6529, lr=0.0001
[2025-04-30 15:55:52,870][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6500, lr=0.0001
[2025-04-30 15:56:29,594][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6797, lr=0.0001
[2025-04-30 15:57:05,751][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6691, lr=0.0001
[2025-04-30 15:57:43,335][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6448, lr=0.0001
[2025-04-30 15:58:19,198][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6434, lr=0.0001
[2025-04-30 15:58:56,243][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6701, lr=0.0001
[2025-04-30 15:59:32,922][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6381, lr=0.0001
[2025-04-30 15:59:32,941][meta_train][INFO] - epoch_55 saved !
[2025-04-30 16:00:09,250][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6383, lr=0.0001
[2025-04-30 16:00:45,924][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6702, lr=0.0001
[2025-04-30 16:01:21,909][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6434, lr=0.0001
[2025-04-30 16:01:58,923][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6446, lr=0.0001
[2025-04-30 16:02:35,226][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6708, lr=0.0001
[2025-04-30 16:03:12,158][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6406, lr=0.0001
[2025-04-30 16:03:49,563][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6441, lr=0.0001
[2025-04-30 16:04:26,190][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6603, lr=0.0001
[2025-04-30 16:04:26,212][meta_train][INFO] - epoch_56 saved !
[2025-04-30 16:05:02,208][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6371, lr=0.0001
[2025-04-30 16:05:39,342][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6349, lr=0.0001
[2025-04-30 16:06:15,307][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6592, lr=0.0001
[2025-04-30 16:06:52,189][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6572, lr=0.0001
[2025-04-30 16:07:27,496][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6400, lr=0.0001
[2025-04-30 16:08:04,405][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6582, lr=0.0001
[2025-04-30 16:08:41,349][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6372, lr=0.0001
[2025-04-30 16:09:19,375][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6354, lr=0.0001
[2025-04-30 16:09:19,391][meta_train][INFO] - epoch_57 saved !
[2025-04-30 16:09:54,452][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6612, lr=0.0001
[2025-04-30 16:10:32,342][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6374, lr=0.0001
[2025-04-30 16:11:08,076][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6614, lr=0.0001
[2025-04-30 16:11:45,888][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6589, lr=0.0001
[2025-04-30 16:12:22,531][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6353, lr=0.0001
[2025-04-30 16:12:57,943][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6365, lr=0.0001
[2025-04-30 16:13:34,954][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6299, lr=0.0001
[2025-04-30 16:14:12,316][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6307, lr=0.0001
[2025-04-30 16:14:12,326][meta_train][INFO] - epoch_58 saved !
[2025-04-30 16:14:49,123][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6310, lr=0.0001
[2025-04-30 16:15:25,244][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6486, lr=0.0001
[2025-04-30 16:16:01,129][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6346, lr=0.0001
[2025-04-30 16:16:37,988][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6505, lr=0.0001
[2025-04-30 16:17:15,496][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6527, lr=0.0001
[2025-04-30 16:17:52,140][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6295, lr=0.0001
[2025-04-30 16:18:28,728][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6294, lr=0.0001
[2025-04-30 16:19:04,781][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6312, lr=0.0001
[2025-04-30 16:19:04,791][meta_train][INFO] - epoch_59 saved !
[2025-04-30 16:19:41,640][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6493, lr=0.0001
[2025-04-30 16:20:17,534][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6305, lr=0.0001
[2025-04-30 16:20:53,821][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6315, lr=0.0001
[2025-04-30 16:21:30,009][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6255, lr=0.0001
[2025-04-30 16:22:06,705][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:22:44,368][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6290, lr=0.0001
[2025-04-30 16:23:19,945][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6435, lr=0.0001
[2025-04-30 16:23:56,916][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6437, lr=0.0001
[2025-04-30 16:23:56,925][meta_train][INFO] - epoch_60 saved !
[2025-04-30 16:24:34,910][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6305, lr=0.0001
[2025-04-30 16:25:12,049][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6306, lr=0.0001
[2025-04-30 16:25:47,799][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6443, lr=0.0001
[2025-04-30 16:26:25,134][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6254, lr=0.0001
[2025-04-30 16:27:01,926][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6237, lr=0.0001
[2025-04-30 16:27:37,200][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6396, lr=0.0001
[2025-04-30 16:28:14,034][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6402, lr=0.0001
[2025-04-30 16:28:50,663][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6257, lr=0.0001
[2025-04-30 16:28:50,673][meta_train][INFO] - epoch_61 saved !
[2025-04-30 16:29:27,794][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6255, lr=0.0001
[2025-04-30 16:30:05,002][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6369, lr=0.0001
[2025-04-30 16:30:41,442][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6212, lr=0.0001
[2025-04-30 16:31:18,735][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6221, lr=0.0001
[2025-04-30 16:31:54,658][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6285, lr=0.0001
[2025-04-30 16:32:31,395][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6385, lr=0.0001
[2025-04-30 16:33:09,075][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6276, lr=0.0001
[2025-04-30 16:33:46,085][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6410, lr=0.0001
[2025-04-30 16:33:46,107][meta_train][INFO] - epoch_62 saved !
[2025-04-30 16:34:22,436][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6340, lr=0.0001
[2025-04-30 16:34:58,155][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6189, lr=0.0001
[2025-04-30 16:35:35,176][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6331, lr=0.0001
[2025-04-30 16:36:12,186][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6232, lr=0.0001
[2025-04-30 16:36:47,955][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6183, lr=0.0001
[2025-04-30 16:37:25,198][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6263, lr=0.0001
[2025-04-30 16:38:02,661][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6257, lr=0.0001
[2025-04-30 16:38:39,816][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6408, lr=0.0001
[2025-04-30 16:38:39,825][meta_train][INFO] - epoch_63 saved !
[2025-04-30 16:39:15,309][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6405, lr=0.0001
[2025-04-30 16:39:53,022][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6245, lr=0.0001
[2025-04-30 16:40:28,379][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6180, lr=0.0001
[2025-04-30 16:41:05,879][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6229, lr=0.0001
[2025-04-30 16:41:43,548][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6282, lr=0.0001
[2025-04-30 16:42:19,528][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:42:56,801][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6303, lr=0.0001
[2025-04-30 16:43:33,664][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6173, lr=0.0001
[2025-04-30 16:43:33,685][meta_train][INFO] - epoch_64 saved !
[2025-04-30 16:44:10,548][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6327, lr=0.0001
[2025-04-30 16:44:47,522][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6312, lr=0.0001
[2025-04-30 16:45:23,812][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6232, lr=0.0001
[2025-04-30 16:45:59,518][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6170, lr=0.0001
[2025-04-30 16:46:37,549][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6159, lr=0.0001
[2025-04-30 16:47:14,410][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6316, lr=0.0001
[2025-04-30 16:47:50,961][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6239, lr=0.0001
[2025-04-30 16:48:26,869][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6218, lr=0.0001
[2025-04-30 16:48:26,878][meta_train][INFO] - epoch_65 saved !
[2025-04-30 16:49:04,857][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:49:41,040][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6159, lr=0.0001
[2025-04-30 16:50:17,491][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6225, lr=0.0001
[2025-04-30 16:50:54,984][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6264, lr=0.0001
[2025-04-30 16:51:31,188][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6147, lr=0.0001
[2025-04-30 16:52:08,093][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6192, lr=0.0001
[2025-04-30 16:52:44,190][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6265, lr=0.0001
[2025-04-30 16:53:21,102][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6303, lr=0.0001
[2025-04-30 16:53:21,112][meta_train][INFO] - epoch_66 saved !
[2025-04-30 16:53:57,717][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6147, lr=0.0001
[2025-04-30 16:54:34,139][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6277, lr=0.0001
[2025-04-30 16:55:11,153][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6201, lr=0.0001
[2025-04-30 16:55:47,855][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6311, lr=0.0001
[2025-04-30 16:56:24,808][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6235, lr=0.0001
[2025-04-30 16:57:01,735][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6139, lr=0.0001
[2025-04-30 16:57:37,973][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6203, lr=0.0001
[2025-04-30 16:58:16,103][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6230, lr=0.0001
[2025-04-30 16:58:16,112][meta_train][INFO] - epoch_67 saved !
[2025-04-30 16:58:52,139][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6130, lr=0.0001
[2025-04-30 16:59:29,247][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6242, lr=0.0001
[2025-04-30 17:00:06,481][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6224, lr=0.0001
[2025-04-30 17:00:43,425][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6226, lr=0.0001
[2025-04-30 17:01:19,864][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6201, lr=0.0001
[2025-04-30 17:01:55,704][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6134, lr=0.0001
[2025-04-30 17:02:33,080][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6177, lr=0.0001
[2025-04-30 17:03:10,296][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6269, lr=0.0001
[2025-04-30 17:03:10,310][meta_train][INFO] - epoch_68 saved !
[2025-04-30 17:03:46,766][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6191, lr=0.0001
[2025-04-30 17:04:22,485][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6123, lr=0.0001
[2025-04-30 17:04:59,889][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6218, lr=0.0001
[2025-04-30 17:05:36,014][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6162, lr=0.0001
[2025-04-30 17:06:13,197][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6120, lr=0.0001
[2025-04-30 17:06:50,459][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6226, lr=0.0001
[2025-04-30 17:07:26,854][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6264, lr=0.0001
[2025-04-30 17:08:03,613][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6211, lr=0.0001
[2025-04-30 17:08:03,632][meta_train][INFO] - epoch_69 saved !
[2025-04-30 17:08:40,733][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6120, lr=0.0001
[2025-04-30 17:09:20,904][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6189, lr=0.0001
[2025-04-30 17:09:59,181][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6219, lr=0.0001
[2025-04-30 17:10:36,377][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6249, lr=0.0001
[2025-04-30 17:11:14,065][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6213, lr=0.0001
[2025-04-30 17:11:50,914][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6116, lr=0.0001
[2025-04-30 17:12:27,930][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6149, lr=0.0001
[2025-04-30 17:13:05,563][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6181, lr=0.0001
[2025-04-30 17:13:05,573][meta_train][INFO] - epoch_70 saved !
[2025-04-30 17:13:43,504][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6109, lr=0.0001
[2025-04-30 17:14:21,310][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6144, lr=0.0001
[2025-04-30 17:14:57,878][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:15:35,897][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6233, lr=0.0001
[2025-04-30 17:16:12,203][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6214, lr=0.0001
[2025-04-30 17:16:48,871][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6203, lr=0.0001
[2025-04-30 17:17:27,112][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6107, lr=0.0001
[2025-04-30 17:18:04,957][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6178, lr=0.0001
[2025-04-30 17:18:04,967][meta_train][INFO] - epoch_71 saved !
[2025-04-30 17:18:41,987][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6099, lr=0.0001
[2025-04-30 17:19:19,278][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6184, lr=0.0001
[2025-04-30 17:19:57,636][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6141, lr=0.0001
[2025-04-30 17:20:34,821][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6209, lr=0.0001
[2025-04-30 17:21:11,103][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6180, lr=0.0001
[2025-04-30 17:21:48,403][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6184, lr=0.0001
[2025-04-30 17:22:26,396][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6218, lr=0.0001
[2025-04-30 17:23:03,684][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6101, lr=0.0001
[2025-04-30 17:23:03,706][meta_train][INFO] - epoch_72 saved !
[2025-04-30 17:23:41,351][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6090, lr=0.0001
[2025-04-30 17:24:17,973][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:24:55,791][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6125, lr=0.0001
[2025-04-30 17:25:32,215][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6172, lr=0.0001
[2025-04-30 17:26:09,886][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6104, lr=0.0001
[2025-04-30 17:26:46,454][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6223, lr=0.0001
[2025-04-30 17:27:23,638][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6209, lr=0.0001
[2025-04-30 17:28:01,922][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6171, lr=0.0001
[2025-04-30 17:28:01,932][meta_train][INFO] - epoch_73 saved !
[2025-04-30 17:28:39,008][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6202, lr=0.0001
[2025-04-30 17:29:16,398][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6193, lr=0.0001
[2025-04-30 17:29:52,990][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6150, lr=0.0001
[2025-04-30 17:30:30,656][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6092, lr=0.0001
[2025-04-30 17:31:08,039][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6084, lr=0.0001
[2025-04-30 17:31:43,781][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:32:21,648][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:33:00,012][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6130, lr=0.0001
[2025-04-30 17:33:00,035][meta_train][INFO] - epoch_74 saved !
[2025-04-30 17:33:36,998][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6164, lr=0.0001
[2025-04-30 17:34:15,353][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6202, lr=0.0001
[2025-04-30 17:34:51,500][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:35:29,084][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-04-30 17:36:06,132][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6171, lr=0.0001
[2025-04-30 17:36:43,551][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:37:20,771][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6135, lr=0.0001
[2025-04-30 17:37:58,164][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6145, lr=0.0001
[2025-04-30 17:37:58,179][meta_train][INFO] - epoch_75 saved !
[2025-04-30 17:38:35,045][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6118, lr=0.0001
[2025-04-30 17:39:12,017][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-04-30 17:39:50,356][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6186, lr=0.0001
[2025-04-30 17:40:27,321][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6195, lr=0.0001
[2025-04-30 17:41:04,122][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-04-30 17:41:41,431][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6088, lr=0.0001
[2025-04-30 17:42:20,139][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6139, lr=0.0001
[2025-04-30 17:42:56,917][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6138, lr=0.0001
[2025-04-30 17:42:56,927][meta_train][INFO] - epoch_76 saved !
[2025-04-30 17:43:33,681][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6134, lr=0.0001
[2025-04-30 17:44:10,651][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6110, lr=0.0001
[2025-04-30 17:44:47,363][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6185, lr=0.0001
[2025-04-30 17:45:25,236][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6156, lr=0.0001
[2025-04-30 17:46:02,490][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6153, lr=0.0001
[2025-04-30 17:46:40,082][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6088, lr=0.0001
[2025-04-30 17:47:18,518][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6167, lr=0.0001
[2025-04-30 17:47:55,746][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:47:55,757][meta_train][INFO] - epoch_77 saved !
[2025-04-30 17:48:33,951][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6101, lr=0.0001
[2025-04-30 17:49:10,830][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6080, lr=0.0001
[2025-04-30 17:49:48,618][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:50:26,181][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6144, lr=0.0001
[2025-04-30 17:51:02,980][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6153, lr=0.0001
[2025-04-30 17:51:40,747][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6219, lr=0.0001
[2025-04-30 17:52:18,995][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6089, lr=0.0001
[2025-04-30 17:52:58,326][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:52:58,339][meta_train][INFO] - epoch_78 saved !
[2025-04-30 17:53:35,848][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:54:12,938][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6122, lr=0.0001
[2025-04-30 17:54:49,080][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6114, lr=0.0001
[2025-04-30 17:55:29,163][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6129, lr=0.0001
[2025-04-30 17:56:06,991][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:56:43,542][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6080, lr=0.0001
[2025-04-30 17:57:21,669][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:57:58,991][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6117, lr=0.0001
[2025-04-30 17:57:59,016][meta_train][INFO] - epoch_79 saved !
[2025-04-30 17:58:36,194][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:59:14,182][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6084, lr=0.0001
[2025-04-30 17:59:50,129][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6174, lr=0.0001
[2025-04-30 18:00:27,507][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6120, lr=0.0001
[2025-04-30 18:01:04,567][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:01:42,802][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6076, lr=0.0001
[2025-04-30 18:02:18,621][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6141, lr=0.0001
[2025-04-30 18:02:56,701][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:02:56,721][meta_train][INFO] - epoch_80 saved !
[2025-04-30 18:03:33,305][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6104, lr=0.0001
[2025-04-30 18:04:11,079][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6115, lr=0.0001
[2025-04-30 18:04:47,655][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6144, lr=0.0001
[2025-04-30 18:05:25,055][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6083, lr=0.0001
[2025-04-30 18:06:02,412][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6126, lr=0.0001
[2025-04-30 18:06:39,682][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6174, lr=0.0001
[2025-04-30 18:07:17,852][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6136, lr=0.0001
[2025-04-30 18:07:55,675][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6076, lr=0.0001
[2025-04-30 18:07:55,697][meta_train][INFO] - epoch_81 saved !
[2025-04-30 18:08:31,256][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6121, lr=0.0001
[2025-04-30 18:09:09,467][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6112, lr=0.0001
[2025-04-30 18:09:45,577][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6135, lr=0.0001
[2025-04-30 18:10:22,897][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6126, lr=0.0001
[2025-04-30 18:10:59,729][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6079, lr=0.0001
[2025-04-30 18:11:37,001][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:12:15,556][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:12:51,523][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6167, lr=0.0001
[2025-04-30 18:12:51,533][meta_train][INFO] - epoch_82 saved !
[2025-04-30 18:13:29,637][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6142, lr=0.0001
[2025-04-30 18:14:06,412][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6081, lr=0.0001
[2025-04-30 18:14:43,126][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:15:19,543][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:15:57,081][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6105, lr=0.0001
[2025-04-30 18:16:34,469][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6166, lr=0.0001
[2025-04-30 18:17:12,482][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:17:50,660][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:17:50,683][meta_train][INFO] - epoch_83 saved !
[2025-04-30 18:18:28,290][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6107, lr=0.0001
[2025-04-30 18:19:05,500][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6161, lr=0.0001
[2025-04-30 18:19:42,627][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6122, lr=0.0001
[2025-04-30 18:20:18,323][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:20:56,497][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6123, lr=0.0001
[2025-04-30 18:21:33,955][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6079, lr=0.0001
[2025-04-30 18:22:10,033][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:22:48,531][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:22:48,540][meta_train][INFO] - epoch_84 saved !
[2025-04-30 18:23:24,992][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6163, lr=0.0001
[2025-04-30 18:24:02,333][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6102, lr=0.0001
[2025-04-30 18:24:38,858][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6102, lr=0.0001
[2025-04-30 18:25:16,975][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-04-30 18:25:54,589][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:26:31,883][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6107, lr=0.0001
[2025-04-30 18:27:08,215][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6078, lr=0.0001
[2025-04-30 18:27:45,998][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:27:46,008][meta_train][INFO] - epoch_85 saved !
[2025-04-30 18:28:22,385][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6108, lr=0.0001
[2025-04-30 18:29:00,351][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6123, lr=0.0001
[2025-04-30 18:29:37,318][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-04-30 18:30:15,490][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6154, lr=0.0001
[2025-04-30 18:30:52,645][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:31:29,338][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:32:05,751][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6098, lr=0.0001
[2025-04-30 18:32:43,490][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:32:43,501][meta_train][INFO] - epoch_86 saved !
[2025-04-30 18:33:19,943][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:33:57,566][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:34:35,009][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:35:11,055][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:35:48,034][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:36:24,623][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-04-30 18:37:02,258][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:37:39,462][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6152, lr=0.0001
[2025-04-30 18:37:39,471][meta_train][INFO] - epoch_87 saved !
[2025-04-30 18:38:16,154][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6075, lr=0.0001
[2025-04-30 18:38:52,432][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6156, lr=0.0001
[2025-04-30 18:39:30,220][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:40:06,828][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6118, lr=0.0001
[2025-04-30 18:40:42,880][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:41:20,480][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:41:57,022][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6100, lr=0.0001
[2025-04-30 18:42:33,187][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:42:33,207][meta_train][INFO] - epoch_88 saved !
[2025-04-30 18:43:10,735][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6104, lr=0.0001
[2025-04-30 18:43:46,844][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-04-30 18:44:24,460][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:45:02,235][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:45:38,340][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:46:15,642][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6146, lr=0.0001
[2025-04-30 18:46:51,622][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6091, lr=0.0001
[2025-04-30 18:47:28,869][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:47:28,878][meta_train][INFO] - epoch_89 saved !
[2025-04-30 18:48:06,787][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6150, lr=0.0001
[2025-04-30 18:48:44,619][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6069, lr=0.0001
[2025-04-30 18:49:20,752][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:49:57,845][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6099, lr=0.0001
[2025-04-30 18:50:33,510][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:51:11,189][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:51:48,895][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:52:25,053][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6091, lr=0.0001
[2025-04-30 18:52:25,064][meta_train][INFO] - epoch_90 saved !
[2025-04-30 18:53:01,415][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6146, lr=0.0001
[2025-04-30 18:53:39,143][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6067, lr=0.0001
[2025-04-30 18:54:17,232][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6112, lr=0.0001
[2025-04-30 18:54:54,385][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:55:30,631][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6090, lr=0.0001
[2025-04-30 18:56:07,662][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6089, lr=0.0001
[2025-04-30 18:56:43,938][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6093, lr=0.0001
[2025-04-30 18:57:21,121][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6072, lr=0.0001
[2025-04-30 18:57:21,141][meta_train][INFO] - epoch_91 saved !
[2025-04-30 18:57:58,244][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6114, lr=0.0001
[2025-04-30 18:58:35,673][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 18:59:12,279][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6110, lr=0.0001
[2025-04-30 18:59:48,950][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6071, lr=0.0001
[2025-04-30 19:00:26,441][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6065, lr=0.0001
[2025-04-30 19:01:03,597][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:01:40,712][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6087, lr=0.0001
[2025-04-30 19:02:16,527][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6142, lr=0.0001
[2025-04-30 19:02:16,537][meta_train][INFO] - epoch_92 saved !
[2025-04-30 19:02:53,507][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6109, lr=0.0001
[2025-04-30 19:03:31,339][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:04:07,411][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:04:43,921][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6088, lr=0.0001
[2025-04-30 19:05:20,648][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6089, lr=0.0001
[2025-04-30 19:05:57,591][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6069, lr=0.0001
[2025-04-30 19:06:34,836][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6140, lr=0.0001
[2025-04-30 19:07:12,496][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6107, lr=0.0001
[2025-04-30 19:07:12,508][meta_train][INFO] - epoch_93 saved !
[2025-04-30 19:07:49,802][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6093, lr=0.0001
[2025-04-30 19:08:25,670][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6071, lr=0.0001
[2025-04-30 19:09:02,480][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6091, lr=0.0001
[2025-04-30 19:09:38,518][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:10:16,607][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6137, lr=0.0001
[2025-04-30 19:10:53,476][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6102, lr=0.0001
[2025-04-30 19:11:30,982][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6101, lr=0.0001
[2025-04-30 19:12:07,014][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6065, lr=0.0001
[2025-04-30 19:12:07,023][meta_train][INFO] - epoch_94 saved !
[2025-04-30 19:12:43,868][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:13:21,798][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6136, lr=0.0001
[2025-04-30 19:13:58,406][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6099, lr=0.0001
[2025-04-30 19:14:35,717][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6084, lr=0.0001
[2025-04-30 19:15:11,857][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:15:48,661][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6064, lr=0.0001
[2025-04-30 19:16:26,001][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6070, lr=0.0001
[2025-04-30 19:17:03,047][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:17:03,057][meta_train][INFO] - epoch_95 saved !
[2025-04-30 19:17:40,466][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6064, lr=0.0001
[2025-04-30 19:18:15,594][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6087, lr=0.0001
[2025-04-30 19:18:53,406][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:19:30,588][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:20:07,271][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6069, lr=0.0001
[2025-04-30 19:20:43,264][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6135, lr=0.0001
[2025-04-30 19:21:20,660][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6099, lr=0.0001
[2025-04-30 19:21:57,351][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:21:57,360][meta_train][INFO] - epoch_96 saved !
[2025-04-30 19:22:35,297][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6086, lr=0.0001
[2025-04-30 19:23:12,572][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:23:49,353][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:24:25,925][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6083, lr=0.0001
[2025-04-30 19:25:03,497][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-04-30 19:25:38,613][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:26:16,033][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:26:54,287][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6133, lr=0.0001
[2025-04-30 19:26:54,299][meta_train][INFO] - epoch_97 saved !
[2025-04-30 19:27:31,614][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6131, lr=0.0001
[2025-04-30 19:28:07,535][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6078, lr=0.0001
[2025-04-30 19:28:44,952][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6061, lr=0.0001
[2025-04-30 19:29:21,401][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6082, lr=0.0001
[2025-04-30 19:29:58,540][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:30:35,207][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:31:11,792][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6097, lr=0.0001
[2025-04-30 19:31:48,980][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6100, lr=0.0001
[2025-04-30 19:31:48,990][meta_train][INFO] - epoch_98 saved !
[2025-04-30 19:32:24,668][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6068, lr=0.0001
[2025-04-30 19:33:02,569][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:33:39,218][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6082, lr=0.0001
[2025-04-30 19:34:15,205][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-04-30 19:34:52,140][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6076, lr=0.0001
[2025-04-30 19:35:29,719][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:36:06,369][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6083, lr=0.0001
[2025-04-30 19:36:43,453][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6132, lr=0.0001
[2025-04-30 19:36:43,471][meta_train][INFO] - epoch_99 saved !
[2025-04-30 19:37:19,514][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-04-30 19:37:55,474][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6068, lr=0.0001
[2025-04-30 19:38:32,721][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:39:10,169][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6079, lr=0.0001
[2025-04-30 19:39:46,169][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6060, lr=0.0001
[2025-04-30 19:40:23,016][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6079, lr=0.0001
[2025-04-30 19:40:59,772][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6077, lr=0.0001
[2025-04-30 19:41:37,668][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6094, lr=0.0001
[2025-04-30 19:41:37,681][meta_train][INFO] - epoch_100 saved !
[2025-04-30 19:46:27,948][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:46:37,150][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:46:57,568][train][INFO] - Before training : Train Acc=0.8257  Val Acc=0.6306
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:47:06,035][train][INFO] - Epoch 1/100, Val Acc=0.6407, Val Loss=1.6995, lr=0.0100
[2025-04-30 19:47:07,252][train][INFO] - Before training : Train Acc=0.1055  Val Acc=0.1158
[2025-04-30 19:47:14,416][train][INFO] - Epoch 2/100, Val Acc=0.6528, Val Loss=1.5877, lr=0.0100
[2025-04-30 19:47:15,990][train][INFO] - Epoch 1/100, Val Acc=0.6457, Val Loss=1.6016, lr=0.0100
[2025-04-30 19:47:23,157][train][INFO] - Epoch 3/100, Val Acc=0.6414, Val Loss=1.6361, lr=0.0100
[2025-04-30 19:47:24,835][train][INFO] - Epoch 2/100, Val Acc=0.6383, Val Loss=1.6544, lr=0.0100
[2025-04-30 19:47:31,634][train][INFO] - Epoch 4/100, Val Acc=0.6530, Val Loss=1.6066, lr=0.0100
[2025-04-30 19:47:33,170][train][INFO] - Epoch 3/100, Val Acc=0.6411, Val Loss=1.6179, lr=0.0100
[2025-04-30 19:47:39,773][train][INFO] - Epoch 5/100, Val Acc=0.6603, Val Loss=1.5535, lr=0.0100
[2025-04-30 19:47:41,713][train][INFO] - Epoch 4/100, Val Acc=0.6595, Val Loss=1.5565, lr=0.0100
[2025-04-30 19:47:41,925][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:47:47,911][train][INFO] - Epoch 6/100, Val Acc=0.6725, Val Loss=1.5152, lr=0.0100
[2025-04-30 19:47:49,024][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-04-30 19:47:49,084][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:47:49,085][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:47:49,085][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:47:50,349][train][INFO] - Epoch 5/100, Val Acc=0.6432, Val Loss=1.6024, lr=0.0100
[2025-04-30 19:47:56,807][train][INFO] - Epoch 7/100, Val Acc=0.6638, Val Loss=1.5519, lr=0.0100
[2025-04-30 19:47:58,945][train][INFO] - Epoch 6/100, Val Acc=0.6699, Val Loss=1.5082, lr=0.0100
[2025-04-30 19:48:04,567][train][INFO] - Epoch 8/100, Val Acc=0.6665, Val Loss=1.5878, lr=0.0100
[2025-04-30 19:48:07,605][train][INFO] - Epoch 7/100, Val Acc=0.6663, Val Loss=1.4997, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:48:12,573][train][INFO] - Epoch 9/100, Val Acc=0.6650, Val Loss=1.5326, lr=0.0100
[2025-04-30 19:48:15,193][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 19:48:16,808][train][INFO] - Epoch 8/100, Val Acc=0.6571, Val Loss=1.5771, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:48:21,070][train][INFO] - Epoch 10/100, Val Acc=0.6747, Val Loss=1.5253, lr=0.0100
[2025-04-30 19:48:22,535][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 19:48:25,756][train][INFO] - Epoch 1/100, Val Acc=0.6327, Val Loss=1.5511, lr=0.0100
[2025-04-30 19:48:27,376][train][INFO] - Epoch 9/100, Val Acc=0.6676, Val Loss=1.5176, lr=0.0100
[2025-04-30 19:48:31,595][train][INFO] - Epoch 11/100, Val Acc=0.6618, Val Loss=1.5361, lr=0.0100
[2025-04-30 19:48:33,299][train][INFO] - Epoch 1/100, Val Acc=0.6202, Val Loss=1.6618, lr=0.0100
[2025-04-30 19:48:36,408][train][INFO] - Epoch 2/100, Val Acc=0.6353, Val Loss=1.6206, lr=0.0100
[2025-04-30 19:48:37,990][train][INFO] - Epoch 10/100, Val Acc=0.6609, Val Loss=1.5555, lr=0.0100
[2025-04-30 19:48:42,108][train][INFO] - Epoch 12/100, Val Acc=0.6589, Val Loss=1.5327, lr=0.0100
[2025-04-30 19:48:43,879][train][INFO] - Epoch 2/100, Val Acc=0.6242, Val Loss=1.6651, lr=0.0100
[2025-04-30 19:48:46,850][train][INFO] - Epoch 3/100, Val Acc=0.6350, Val Loss=1.5867, lr=0.0100
[2025-04-30 19:48:48,618][train][INFO] - Epoch 11/100, Val Acc=0.6566, Val Loss=1.5830, lr=0.0100
[2025-04-30 19:48:52,736][train][INFO] - Epoch 13/100, Val Acc=0.6715, Val Loss=1.5349, lr=0.0100
[2025-04-30 19:48:54,512][train][INFO] - Epoch 3/100, Val Acc=0.6378, Val Loss=1.5470, lr=0.0100
[2025-04-30 19:48:57,346][train][INFO] - Epoch 4/100, Val Acc=0.6653, Val Loss=1.4287, lr=0.0100
[2025-04-30 19:48:59,330][train][INFO] - Epoch 12/100, Val Acc=0.6586, Val Loss=1.5659, lr=0.0100
[2025-04-30 19:49:03,229][train][INFO] - Epoch 14/100, Val Acc=0.6721, Val Loss=1.5565, lr=0.0100
[2025-04-30 19:49:05,074][train][INFO] - Epoch 4/100, Val Acc=0.6574, Val Loss=1.4975, lr=0.0100
[2025-04-30 19:49:08,026][train][INFO] - Epoch 5/100, Val Acc=0.6563, Val Loss=1.4773, lr=0.0100
[2025-04-30 19:49:09,874][train][INFO] - Epoch 13/100, Val Acc=0.6646, Val Loss=1.5909, lr=0.0100
[2025-04-30 19:49:13,721][train][INFO] - Epoch 15/100, Val Acc=0.6637, Val Loss=1.5761, lr=0.0100
[2025-04-30 19:49:15,353][train][INFO] - Epoch 5/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-04-30 19:49:18,500][train][INFO] - Epoch 6/100, Val Acc=0.6541, Val Loss=1.5511, lr=0.0100
[2025-04-30 19:49:20,324][train][INFO] - Epoch 14/100, Val Acc=0.6611, Val Loss=1.6061, lr=0.0100
[2025-04-30 19:49:24,353][train][INFO] - Epoch 16/100, Val Acc=0.6739, Val Loss=1.4943, lr=0.0100
[2025-04-30 19:49:26,068][train][INFO] - Epoch 6/100, Val Acc=0.6604, Val Loss=1.5065, lr=0.0100
[2025-04-30 19:49:29,033][train][INFO] - Epoch 7/100, Val Acc=0.6590, Val Loss=1.5539, lr=0.0100
[2025-04-30 19:49:30,849][train][INFO] - Epoch 15/100, Val Acc=0.6678, Val Loss=1.5833, lr=0.0100
[2025-04-30 19:49:34,687][train][INFO] - Epoch 17/100, Val Acc=0.6754, Val Loss=1.5239, lr=0.0100
[2025-04-30 19:49:36,447][train][INFO] - Epoch 7/100, Val Acc=0.6612, Val Loss=1.5037, lr=0.0100
[2025-04-30 19:49:39,567][train][INFO] - Epoch 8/100, Val Acc=0.6354, Val Loss=1.7221, lr=0.0100
[2025-04-30 19:49:41,294][train][INFO] - Epoch 16/100, Val Acc=0.6664, Val Loss=1.5356, lr=0.0100
[2025-04-30 19:49:45,319][train][INFO] - Epoch 18/100, Val Acc=0.6540, Val Loss=1.6374, lr=0.0100
[2025-04-30 19:49:47,014][train][INFO] - Epoch 8/100, Val Acc=0.6640, Val Loss=1.5142, lr=0.0100
[2025-04-30 19:49:50,229][train][INFO] - Epoch 9/100, Val Acc=0.6589, Val Loss=1.5581, lr=0.0100
[2025-04-30 19:49:51,960][train][INFO] - Epoch 17/100, Val Acc=0.6677, Val Loss=1.5597, lr=0.0100
[2025-04-30 19:49:55,888][train][INFO] - Epoch 19/100, Val Acc=0.6666, Val Loss=1.5533, lr=0.0100
[2025-04-30 19:49:57,599][train][INFO] - Epoch 9/100, Val Acc=0.6634, Val Loss=1.4732, lr=0.0100
[2025-04-30 19:50:00,712][train][INFO] - Epoch 10/100, Val Acc=0.6669, Val Loss=1.5094, lr=0.0100
[2025-04-30 19:50:02,435][train][INFO] - Epoch 18/100, Val Acc=0.6695, Val Loss=1.5787, lr=0.0100
[2025-04-30 19:50:06,493][train][INFO] - Epoch 20/100, Val Acc=0.6757, Val Loss=1.5151, lr=0.0100
[2025-04-30 19:50:08,168][train][INFO] - Epoch 10/100, Val Acc=0.6664, Val Loss=1.4902, lr=0.0100
[2025-04-30 19:50:11,099][train][INFO] - Epoch 11/100, Val Acc=0.6585, Val Loss=1.5493, lr=0.0100
[2025-04-30 19:50:12,891][train][INFO] - Epoch 19/100, Val Acc=0.6577, Val Loss=1.6290, lr=0.0100
[2025-04-30 19:50:17,169][train][INFO] - Epoch 21/100, Val Acc=0.6677, Val Loss=1.5805, lr=0.0100
[2025-04-30 19:50:18,642][train][INFO] - Epoch 11/100, Val Acc=0.6538, Val Loss=1.5780, lr=0.0100
[2025-04-30 19:50:21,565][train][INFO] - Epoch 12/100, Val Acc=0.6653, Val Loss=1.5148, lr=0.0100
[2025-04-30 19:50:23,421][train][INFO] - Epoch 20/100, Val Acc=0.6748, Val Loss=1.5282, lr=0.0100
[2025-04-30 19:50:27,721][train][INFO] - Epoch 22/100, Val Acc=0.6614, Val Loss=1.6285, lr=0.0100
[2025-04-30 19:50:29,076][train][INFO] - Epoch 12/100, Val Acc=0.6616, Val Loss=1.5293, lr=0.0100
[2025-04-30 19:50:32,087][train][INFO] - Epoch 13/100, Val Acc=0.6708, Val Loss=1.5368, lr=0.0100
[2025-04-30 19:50:34,023][train][INFO] - Epoch 21/100, Val Acc=0.6722, Val Loss=1.5627, lr=0.0100
[2025-04-30 19:50:38,372][train][INFO] - Epoch 23/100, Val Acc=0.6743, Val Loss=1.5516, lr=0.0100
[2025-04-30 19:50:39,631][train][INFO] - Epoch 13/100, Val Acc=0.6627, Val Loss=1.5777, lr=0.0100
[2025-04-30 19:50:42,784][train][INFO] - Epoch 14/100, Val Acc=0.6717, Val Loss=1.5219, lr=0.0100
[2025-04-30 19:50:44,638][train][INFO] - Epoch 22/100, Val Acc=0.6772, Val Loss=1.4974, lr=0.0100
[2025-04-30 19:50:49,038][train][INFO] - Epoch 24/100, Val Acc=0.6720, Val Loss=1.5453, lr=0.0100
[2025-04-30 19:50:50,301][train][INFO] - Epoch 14/100, Val Acc=0.6748, Val Loss=1.5258, lr=0.0100
[2025-04-30 19:50:53,451][train][INFO] - Epoch 15/100, Val Acc=0.6660, Val Loss=1.5709, lr=0.0100
[2025-04-30 19:50:55,134][train][INFO] - Epoch 23/100, Val Acc=0.6694, Val Loss=1.5835, lr=0.0100
[2025-04-30 19:50:59,841][train][INFO] - Epoch 25/100, Val Acc=0.6760, Val Loss=1.5460, lr=0.0100
[2025-04-30 19:51:01,002][train][INFO] - Epoch 15/100, Val Acc=0.6556, Val Loss=1.5996, lr=0.0100
[2025-04-30 19:51:04,043][train][INFO] - Epoch 16/100, Val Acc=0.6617, Val Loss=1.5363, lr=0.0100
[2025-04-30 19:51:05,762][train][INFO] - Epoch 24/100, Val Acc=0.6699, Val Loss=1.5384, lr=0.0100
[2025-04-30 19:51:10,678][train][INFO] - Epoch 26/100, Val Acc=0.6691, Val Loss=1.5828, lr=0.0100
[2025-04-30 19:51:11,736][train][INFO] - Epoch 16/100, Val Acc=0.6674, Val Loss=1.5137, lr=0.0100
[2025-04-30 19:51:14,554][train][INFO] - Epoch 17/100, Val Acc=0.6593, Val Loss=1.5829, lr=0.0100
[2025-04-30 19:51:16,269][train][INFO] - Epoch 25/100, Val Acc=0.6713, Val Loss=1.5476, lr=0.0100
[2025-04-30 19:51:21,526][train][INFO] - Epoch 27/100, Val Acc=0.6753, Val Loss=1.5177, lr=0.0100
[2025-04-30 19:51:22,545][train][INFO] - Epoch 17/100, Val Acc=0.6703, Val Loss=1.5060, lr=0.0100
[2025-04-30 19:51:25,093][train][INFO] - Epoch 18/100, Val Acc=0.6706, Val Loss=1.5212, lr=0.0100
[2025-04-30 19:51:26,901][train][INFO] - Epoch 26/100, Val Acc=0.6782, Val Loss=1.5540, lr=0.0100
[2025-04-30 19:51:32,437][train][INFO] - Epoch 28/100, Val Acc=0.6705, Val Loss=1.5932, lr=0.0100
[2025-04-30 19:51:33,413][train][INFO] - Epoch 18/100, Val Acc=0.6732, Val Loss=1.5338, lr=0.0100
[2025-04-30 19:51:35,782][train][INFO] - Epoch 19/100, Val Acc=0.6745, Val Loss=1.5121, lr=0.0100
[2025-04-30 19:51:37,565][train][INFO] - Epoch 27/100, Val Acc=0.6665, Val Loss=1.5557, lr=0.0100
[2025-04-30 19:51:43,200][train][INFO] - Epoch 29/100, Val Acc=0.6685, Val Loss=1.5908, lr=0.0100
[2025-04-30 19:51:44,109][train][INFO] - Epoch 19/100, Val Acc=0.6737, Val Loss=1.4919, lr=0.0100
[2025-04-30 19:51:46,370][train][INFO] - Epoch 20/100, Val Acc=0.6700, Val Loss=1.5738, lr=0.0100
[2025-04-30 19:51:48,203][train][INFO] - Epoch 28/100, Val Acc=0.6642, Val Loss=1.5984, lr=0.0100
[2025-04-30 19:51:54,142][train][INFO] - Epoch 30/100, Val Acc=0.6647, Val Loss=1.6335, lr=0.0100
[2025-04-30 19:51:54,984][train][INFO] - Epoch 20/100, Val Acc=0.6624, Val Loss=1.6129, lr=0.0100
[2025-04-30 19:51:57,010][train][INFO] - Epoch 21/100, Val Acc=0.6773, Val Loss=1.4854, lr=0.0100
[2025-04-30 19:51:58,597][train][INFO] - Epoch 29/100, Val Acc=0.6830, Val Loss=1.4854, lr=0.0100
[2025-04-30 19:52:04,903][train][INFO] - Epoch 31/100, Val Acc=0.6704, Val Loss=1.5471, lr=0.0100
[2025-04-30 19:52:05,768][train][INFO] - Epoch 21/100, Val Acc=0.6680, Val Loss=1.5622, lr=0.0100
[2025-04-30 19:52:07,570][train][INFO] - Epoch 22/100, Val Acc=0.6592, Val Loss=1.6106, lr=0.0100
[2025-04-30 19:52:09,151][train][INFO] - Epoch 30/100, Val Acc=0.6645, Val Loss=1.5862, lr=0.0100
[2025-04-30 19:52:15,719][train][INFO] - Epoch 32/100, Val Acc=0.6754, Val Loss=1.5731, lr=0.0100
[2025-04-30 19:52:16,634][train][INFO] - Epoch 22/100, Val Acc=0.6594, Val Loss=1.5800, lr=0.0100
[2025-04-30 19:52:18,183][train][INFO] - Epoch 23/100, Val Acc=0.6635, Val Loss=1.5948, lr=0.0100
[2025-04-30 19:52:19,638][train][INFO] - Epoch 31/100, Val Acc=0.6696, Val Loss=1.5693, lr=0.0100
[2025-04-30 19:52:26,573][train][INFO] - Epoch 33/100, Val Acc=0.6737, Val Loss=1.5440, lr=0.0100
[2025-04-30 19:52:27,461][train][INFO] - Epoch 23/100, Val Acc=0.6712, Val Loss=1.5522, lr=0.0100
[2025-04-30 19:52:28,690][train][INFO] - Epoch 24/100, Val Acc=0.6741, Val Loss=1.5082, lr=0.0100
[2025-04-30 19:52:30,139][train][INFO] - Epoch 32/100, Val Acc=0.6663, Val Loss=1.5957, lr=0.0100
[2025-04-30 19:52:37,438][train][INFO] - Epoch 34/100, Val Acc=0.6610, Val Loss=1.6145, lr=0.0100
[2025-04-30 19:52:38,226][train][INFO] - Epoch 24/100, Val Acc=0.6700, Val Loss=1.5664, lr=0.0100
[2025-04-30 19:52:39,166][train][INFO] - Epoch 25/100, Val Acc=0.6782, Val Loss=1.5278, lr=0.0100
[2025-04-30 19:52:40,698][train][INFO] - Epoch 33/100, Val Acc=0.6646, Val Loss=1.6011, lr=0.0100
[2025-04-30 19:52:48,286][train][INFO] - Epoch 35/100, Val Acc=0.6700, Val Loss=1.5629, lr=0.0100
[2025-04-30 19:52:49,168][train][INFO] - Epoch 25/100, Val Acc=0.6725, Val Loss=1.5728, lr=0.0100
[2025-04-30 19:52:49,577][train][INFO] - Epoch 26/100, Val Acc=0.6717, Val Loss=1.5651, lr=0.0100
[2025-04-30 19:52:51,195][train][INFO] - Epoch 34/100, Val Acc=0.6696, Val Loss=1.5831, lr=0.0100
[2025-04-30 19:52:59,105][train][INFO] - Epoch 36/100, Val Acc=0.6742, Val Loss=1.5769, lr=0.0100
[2025-04-30 19:53:00,018][train][INFO] - Epoch 26/100, Val Acc=0.6755, Val Loss=1.5334, lr=0.0100
[2025-04-30 19:53:00,169][train][INFO] - Epoch 27/100, Val Acc=0.6712, Val Loss=1.5770, lr=0.0100
[2025-04-30 19:53:01,787][train][INFO] - Epoch 35/100, Val Acc=0.6565, Val Loss=1.6218, lr=0.0100
[2025-04-30 19:53:09,945][train][INFO] - Epoch 37/100, Val Acc=0.6538, Val Loss=1.6506, lr=0.0100
[2025-04-30 19:53:10,847][train][INFO] - Epoch 27/100, Val Acc=0.6814, Val Loss=1.5092, lr=0.0100
[2025-04-30 19:53:10,849][train][INFO] - Epoch 28/100, Val Acc=0.6536, Val Loss=1.6234, lr=0.0100
[2025-04-30 19:53:12,373][train][INFO] - Epoch 36/100, Val Acc=0.6659, Val Loss=1.5933, lr=0.0100
[2025-04-30 19:53:20,775][train][INFO] - Epoch 38/100, Val Acc=0.6742, Val Loss=1.5649, lr=0.0100
[2025-04-30 19:53:21,433][train][INFO] - Epoch 29/100, Val Acc=0.6683, Val Loss=1.5452, lr=0.0100
[2025-04-30 19:53:21,714][train][INFO] - Epoch 28/100, Val Acc=0.6648, Val Loss=1.6038, lr=0.0100
[2025-04-30 19:53:22,975][train][INFO] - Epoch 37/100, Val Acc=0.6583, Val Loss=1.6517, lr=0.0100
[2025-04-30 19:53:31,691][train][INFO] - Epoch 39/100, Val Acc=0.6709, Val Loss=1.5750, lr=0.0100
[2025-04-30 19:53:32,068][train][INFO] - Epoch 30/100, Val Acc=0.6653, Val Loss=1.5742, lr=0.0100
[2025-04-30 19:53:32,466][train][INFO] - Epoch 29/100, Val Acc=0.6660, Val Loss=1.6061, lr=0.0100
[2025-04-30 19:53:33,530][train][INFO] - Epoch 38/100, Val Acc=0.6753, Val Loss=1.5436, lr=0.0100
[2025-04-30 19:53:42,478][train][INFO] - Epoch 40/100, Val Acc=0.6763, Val Loss=1.5888, lr=0.0100
[2025-04-30 19:53:42,601][train][INFO] - Epoch 31/100, Val Acc=0.6780, Val Loss=1.4936, lr=0.0100
[2025-04-30 19:53:43,227][train][INFO] - Epoch 30/100, Val Acc=0.6611, Val Loss=1.6284, lr=0.0100
[2025-04-30 19:53:44,079][train][INFO] - Epoch 39/100, Val Acc=0.6786, Val Loss=1.4823, lr=0.0100
[2025-04-30 19:53:53,207][train][INFO] - Epoch 32/100, Val Acc=0.6724, Val Loss=1.5189, lr=0.0100
[2025-04-30 19:53:53,355][train][INFO] - Epoch 41/100, Val Acc=0.6765, Val Loss=1.5309, lr=0.0100
[2025-04-30 19:53:53,908][train][INFO] - Epoch 31/100, Val Acc=0.6623, Val Loss=1.5847, lr=0.0100
[2025-04-30 19:53:54,700][train][INFO] - Epoch 40/100, Val Acc=0.6731, Val Loss=1.5113, lr=0.0100
[2025-04-30 19:54:03,731][train][INFO] - Epoch 33/100, Val Acc=0.6607, Val Loss=1.6152, lr=0.0100
[2025-04-30 19:54:04,088][train][INFO] - Epoch 42/100, Val Acc=0.6676, Val Loss=1.6109, lr=0.0100
[2025-04-30 19:54:04,570][train][INFO] - Epoch 32/100, Val Acc=0.6678, Val Loss=1.5535, lr=0.0100
[2025-04-30 19:54:05,198][train][INFO] - Epoch 41/100, Val Acc=0.6592, Val Loss=1.6490, lr=0.0100
[2025-04-30 19:54:14,273][train][INFO] - Epoch 34/100, Val Acc=0.6731, Val Loss=1.5232, lr=0.0100
[2025-04-30 19:54:15,072][train][INFO] - Epoch 43/100, Val Acc=0.6673, Val Loss=1.5839, lr=0.0100
[2025-04-30 19:54:15,388][train][INFO] - Epoch 33/100, Val Acc=0.6880, Val Loss=1.4769, lr=0.0100
[2025-04-30 19:54:15,788][train][INFO] - Epoch 42/100, Val Acc=0.6640, Val Loss=1.5757, lr=0.0100
[2025-04-30 19:54:24,894][train][INFO] - Epoch 35/100, Val Acc=0.6651, Val Loss=1.5890, lr=0.0100
[2025-04-30 19:54:26,320][train][INFO] - Epoch 44/100, Val Acc=0.6550, Val Loss=1.6932, lr=0.0100
[2025-04-30 19:54:26,392][train][INFO] - Epoch 43/100, Val Acc=0.6853, Val Loss=1.5129, lr=0.0100
[2025-04-30 19:54:26,397][train][INFO] - Epoch 34/100, Val Acc=0.6722, Val Loss=1.5834, lr=0.0100
[2025-04-30 19:54:35,670][train][INFO] - Epoch 36/100, Val Acc=0.6708, Val Loss=1.5873, lr=0.0100
[2025-04-30 19:54:37,040][train][INFO] - Epoch 44/100, Val Acc=0.6779, Val Loss=1.4963, lr=0.0100
[2025-04-30 19:54:37,588][train][INFO] - Epoch 45/100, Val Acc=0.6650, Val Loss=1.6049, lr=0.0100
[2025-04-30 19:54:37,589][train][INFO] - Epoch 35/100, Val Acc=0.6769, Val Loss=1.5179, lr=0.0100
[2025-04-30 19:54:46,352][train][INFO] - Epoch 37/100, Val Acc=0.6620, Val Loss=1.5828, lr=0.0100
[2025-04-30 19:54:47,689][train][INFO] - Epoch 45/100, Val Acc=0.6880, Val Loss=1.4533, lr=0.0100
[2025-04-30 19:54:48,736][train][INFO] - Epoch 36/100, Val Acc=0.6737, Val Loss=1.4921, lr=0.0100
[2025-04-30 19:54:48,787][train][INFO] - Epoch 46/100, Val Acc=0.6570, Val Loss=1.6438, lr=0.0100
[2025-04-30 19:54:57,151][train][INFO] - Epoch 38/100, Val Acc=0.6670, Val Loss=1.5623, lr=0.0100
[2025-04-30 19:54:58,418][train][INFO] - Epoch 46/100, Val Acc=0.6578, Val Loss=1.6360, lr=0.0100
[2025-04-30 19:54:59,824][train][INFO] - Epoch 37/100, Val Acc=0.6593, Val Loss=1.6012, lr=0.0100
[2025-04-30 19:54:59,887][train][INFO] - Epoch 47/100, Val Acc=0.6565, Val Loss=1.6560, lr=0.0100
[2025-04-30 19:55:08,039][train][INFO] - Epoch 39/100, Val Acc=0.6782, Val Loss=1.5551, lr=0.0100
[2025-04-30 19:55:09,206][train][INFO] - Epoch 47/100, Val Acc=0.6698, Val Loss=1.5891, lr=0.0100
[2025-04-30 19:55:10,856][train][INFO] - Epoch 38/100, Val Acc=0.6633, Val Loss=1.5964, lr=0.0100
[2025-04-30 19:55:10,934][train][INFO] - Epoch 48/100, Val Acc=0.6729, Val Loss=1.5494, lr=0.0100
[2025-04-30 19:55:18,923][train][INFO] - Epoch 40/100, Val Acc=0.6657, Val Loss=1.5560, lr=0.0100
[2025-04-30 19:55:20,076][train][INFO] - Epoch 48/100, Val Acc=0.6738, Val Loss=1.5480, lr=0.0100
[2025-04-30 19:55:22,003][train][INFO] - Epoch 39/100, Val Acc=0.6680, Val Loss=1.6009, lr=0.0100
[2025-04-30 19:55:22,073][train][INFO] - Epoch 49/100, Val Acc=0.6746, Val Loss=1.5532, lr=0.0100
[2025-04-30 19:55:29,753][train][INFO] - Epoch 41/100, Val Acc=0.6725, Val Loss=1.5605, lr=0.0100
[2025-04-30 19:55:30,906][train][INFO] - Epoch 49/100, Val Acc=0.6822, Val Loss=1.4855, lr=0.0100
[2025-04-30 19:55:33,032][train][INFO] - Epoch 40/100, Val Acc=0.6705, Val Loss=1.5971, lr=0.0100
[2025-04-30 19:55:33,146][train][INFO] - Epoch 50/100, Val Acc=0.6724, Val Loss=1.5791, lr=0.0100
[2025-04-30 19:55:40,500][train][INFO] - Epoch 42/100, Val Acc=0.6682, Val Loss=1.6073, lr=0.0100
[2025-04-30 19:55:41,656][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.5307, lr=0.0100
[2025-04-30 19:55:44,159][train][INFO] - Epoch 41/100, Val Acc=0.6839, Val Loss=1.5023, lr=0.0100
[2025-04-30 19:55:44,225][train][INFO] - Epoch 51/100, Val Acc=0.6708, Val Loss=1.5613, lr=0.0100
[2025-04-30 19:55:51,239][train][INFO] - Epoch 43/100, Val Acc=0.6654, Val Loss=1.6140, lr=0.0100
[2025-04-30 19:55:52,472][train][INFO] - Epoch 51/100, Val Acc=0.6762, Val Loss=1.5632, lr=0.0100
[2025-04-30 19:55:55,207][train][INFO] - Epoch 42/100, Val Acc=0.6571, Val Loss=1.6374, lr=0.0100
[2025-04-30 19:55:55,277][train][INFO] - Epoch 52/100, Val Acc=0.6726, Val Loss=1.5799, lr=0.0100
[2025-04-30 19:56:01,969][train][INFO] - Epoch 44/100, Val Acc=0.6770, Val Loss=1.5228, lr=0.0100
[2025-04-30 19:56:03,120][train][INFO] - Epoch 52/100, Val Acc=0.6716, Val Loss=1.5546, lr=0.0100
[2025-04-30 19:56:06,343][train][INFO] - Epoch 43/100, Val Acc=0.6785, Val Loss=1.5746, lr=0.0100
[2025-04-30 19:56:06,388][train][INFO] - Epoch 53/100, Val Acc=0.6748, Val Loss=1.5548, lr=0.0100
[2025-04-30 19:56:12,855][train][INFO] - Epoch 45/100, Val Acc=0.6836, Val Loss=1.5344, lr=0.0100
[2025-04-30 19:56:13,956][train][INFO] - Epoch 53/100, Val Acc=0.6720, Val Loss=1.5156, lr=0.0100
[2025-04-30 19:56:17,480][train][INFO] - Epoch 44/100, Val Acc=0.6724, Val Loss=1.5398, lr=0.0100
[2025-04-30 19:56:17,520][train][INFO] - Epoch 54/100, Val Acc=0.6586, Val Loss=1.6337, lr=0.0100
[2025-04-30 19:56:23,737][train][INFO] - Epoch 46/100, Val Acc=0.6693, Val Loss=1.5429, lr=0.0100
[2025-04-30 19:56:24,781][train][INFO] - Epoch 54/100, Val Acc=0.6677, Val Loss=1.5963, lr=0.0100
[2025-04-30 19:56:28,581][train][INFO] - Epoch 45/100, Val Acc=0.6748, Val Loss=1.5704, lr=0.0100
[2025-04-30 19:56:28,654][train][INFO] - Epoch 55/100, Val Acc=0.6704, Val Loss=1.5667, lr=0.0100
[2025-04-30 19:56:34,552][train][INFO] - Epoch 47/100, Val Acc=0.6717, Val Loss=1.5648, lr=0.0100
[2025-04-30 19:56:35,586][train][INFO] - Epoch 55/100, Val Acc=0.6623, Val Loss=1.6333, lr=0.0100
[2025-04-30 19:56:39,656][train][INFO] - Epoch 46/100, Val Acc=0.6673, Val Loss=1.6348, lr=0.0100
[2025-04-30 19:56:39,738][train][INFO] - Epoch 56/100, Val Acc=0.6747, Val Loss=1.5600, lr=0.0100
[2025-04-30 19:56:45,342][train][INFO] - Epoch 48/100, Val Acc=0.6700, Val Loss=1.5740, lr=0.0100
[2025-04-30 19:56:46,400][train][INFO] - Epoch 56/100, Val Acc=0.6773, Val Loss=1.5350, lr=0.0100
[2025-04-30 19:56:50,708][train][INFO] - Epoch 47/100, Val Acc=0.6713, Val Loss=1.5703, lr=0.0100
[2025-04-30 19:56:50,757][train][INFO] - Epoch 57/100, Val Acc=0.6585, Val Loss=1.6313, lr=0.0100
[2025-04-30 19:56:56,234][train][INFO] - Epoch 49/100, Val Acc=0.6636, Val Loss=1.6012, lr=0.0100
[2025-04-30 19:56:57,308][train][INFO] - Epoch 57/100, Val Acc=0.6602, Val Loss=1.6332, lr=0.0100
[2025-04-30 19:57:01,834][train][INFO] - Epoch 48/100, Val Acc=0.6791, Val Loss=1.5053, lr=0.0100
[2025-04-30 19:57:01,882][train][INFO] - Epoch 58/100, Val Acc=0.6671, Val Loss=1.6380, lr=0.0100
[2025-04-30 19:57:07,106][train][INFO] - Epoch 50/100, Val Acc=0.6561, Val Loss=1.6293, lr=0.0100
[2025-04-30 19:57:08,189][train][INFO] - Epoch 58/100, Val Acc=0.6746, Val Loss=1.5571, lr=0.0100
[2025-04-30 19:57:12,918][train][INFO] - Epoch 49/100, Val Acc=0.6820, Val Loss=1.5156, lr=0.0100
[2025-04-30 19:57:13,002][train][INFO] - Epoch 59/100, Val Acc=0.6662, Val Loss=1.5915, lr=0.0100
[2025-04-30 19:57:17,999][train][INFO] - Epoch 51/100, Val Acc=0.6750, Val Loss=1.5851, lr=0.0100
[2025-04-30 19:57:19,091][train][INFO] - Epoch 59/100, Val Acc=0.6669, Val Loss=1.5939, lr=0.0100
[2025-04-30 19:57:24,019][train][INFO] - Epoch 50/100, Val Acc=0.6820, Val Loss=1.5063, lr=0.0100
[2025-04-30 19:57:24,080][train][INFO] - Epoch 60/100, Val Acc=0.6606, Val Loss=1.6156, lr=0.0100
[2025-04-30 19:57:28,869][train][INFO] - Epoch 52/100, Val Acc=0.6759, Val Loss=1.5658, lr=0.0100
[2025-04-30 19:57:29,939][train][INFO] - Epoch 60/100, Val Acc=0.6776, Val Loss=1.5615, lr=0.0100
[2025-04-30 19:57:35,097][train][INFO] - Epoch 51/100, Val Acc=0.6848, Val Loss=1.5300, lr=0.0100
[2025-04-30 19:57:35,167][train][INFO] - Epoch 61/100, Val Acc=0.7226, Val Loss=1.2792, lr=0.0010
[2025-04-30 19:57:39,734][train][INFO] - Epoch 53/100, Val Acc=0.6744, Val Loss=1.5676, lr=0.0100
[2025-04-30 19:57:40,795][train][INFO] - Epoch 61/100, Val Acc=0.7252, Val Loss=1.3195, lr=0.0010
[2025-04-30 19:57:46,217][train][INFO] - Epoch 52/100, Val Acc=0.6688, Val Loss=1.5983, lr=0.0100
[2025-04-30 19:57:46,311][train][INFO] - Epoch 62/100, Val Acc=0.7256, Val Loss=1.2744, lr=0.0010
[2025-04-30 19:57:50,417][train][INFO] - Epoch 54/100, Val Acc=0.6773, Val Loss=1.5507, lr=0.0100
[2025-04-30 19:57:51,657][train][INFO] - Epoch 62/100, Val Acc=0.7310, Val Loss=1.2994, lr=0.0010
[2025-04-30 19:57:57,179][train][INFO] - Epoch 53/100, Val Acc=0.6731, Val Loss=1.5619, lr=0.0100
[2025-04-30 19:57:57,322][train][INFO] - Epoch 63/100, Val Acc=0.7306, Val Loss=1.2784, lr=0.0010
[2025-04-30 19:58:01,231][train][INFO] - Epoch 55/100, Val Acc=0.6612, Val Loss=1.6360, lr=0.0100
[2025-04-30 19:58:02,464][train][INFO] - Epoch 63/100, Val Acc=0.7330, Val Loss=1.3041, lr=0.0010
[2025-04-30 19:58:08,350][train][INFO] - Epoch 54/100, Val Acc=0.6683, Val Loss=1.5741, lr=0.0100
[2025-04-30 19:58:08,426][train][INFO] - Epoch 64/100, Val Acc=0.7303, Val Loss=1.2870, lr=0.0010
[2025-04-30 19:58:11,989][train][INFO] - Epoch 56/100, Val Acc=0.6749, Val Loss=1.5532, lr=0.0100
[2025-04-30 19:58:13,260][train][INFO] - Epoch 64/100, Val Acc=0.7344, Val Loss=1.3048, lr=0.0010
[2025-04-30 19:58:19,441][train][INFO] - Epoch 55/100, Val Acc=0.6803, Val Loss=1.5268, lr=0.0100
[2025-04-30 19:58:19,561][train][INFO] - Epoch 65/100, Val Acc=0.7332, Val Loss=1.2895, lr=0.0010
[2025-04-30 19:58:22,786][train][INFO] - Epoch 57/100, Val Acc=0.6718, Val Loss=1.5736, lr=0.0100
[2025-04-30 19:58:24,001][train][INFO] - Epoch 65/100, Val Acc=0.7351, Val Loss=1.3133, lr=0.0010
[2025-04-30 19:58:30,552][train][INFO] - Epoch 56/100, Val Acc=0.6701, Val Loss=1.5701, lr=0.0100
[2025-04-30 19:58:30,657][train][INFO] - Epoch 66/100, Val Acc=0.7341, Val Loss=1.2895, lr=0.0010
[2025-04-30 19:58:33,835][train][INFO] - Epoch 58/100, Val Acc=0.6701, Val Loss=1.5888, lr=0.0100
[2025-04-30 19:58:34,886][train][INFO] - Epoch 66/100, Val Acc=0.7375, Val Loss=1.3119, lr=0.0010
[2025-04-30 19:58:41,597][train][INFO] - Epoch 57/100, Val Acc=0.6602, Val Loss=1.6520, lr=0.0100
[2025-04-30 19:58:41,675][train][INFO] - Epoch 67/100, Val Acc=0.7357, Val Loss=1.2875, lr=0.0010
[2025-04-30 19:58:44,650][train][INFO] - Epoch 59/100, Val Acc=0.6709, Val Loss=1.5800, lr=0.0100
[2025-04-30 19:58:45,769][train][INFO] - Epoch 67/100, Val Acc=0.7360, Val Loss=1.3137, lr=0.0010
[2025-04-30 19:58:52,714][train][INFO] - Epoch 58/100, Val Acc=0.6738, Val Loss=1.5710, lr=0.0100
[2025-04-30 19:58:52,848][train][INFO] - Epoch 68/100, Val Acc=0.7363, Val Loss=1.2914, lr=0.0010
[2025-04-30 19:58:55,576][train][INFO] - Epoch 60/100, Val Acc=0.6553, Val Loss=1.6648, lr=0.0100
[2025-04-30 19:58:56,646][train][INFO] - Epoch 68/100, Val Acc=0.7389, Val Loss=1.3134, lr=0.0010
[2025-04-30 19:59:03,655][train][INFO] - Epoch 59/100, Val Acc=0.6660, Val Loss=1.6462, lr=0.0100
[2025-04-30 19:59:03,844][train][INFO] - Epoch 69/100, Val Acc=0.7350, Val Loss=1.2914, lr=0.0010
[2025-04-30 19:59:06,352][train][INFO] - Epoch 61/100, Val Acc=0.7229, Val Loss=1.3331, lr=0.0010
[2025-04-30 19:59:07,503][train][INFO] - Epoch 69/100, Val Acc=0.7405, Val Loss=1.3234, lr=0.0010
[2025-04-30 19:59:14,617][train][INFO] - Epoch 60/100, Val Acc=0.6694, Val Loss=1.5923, lr=0.0100
[2025-04-30 19:59:14,849][train][INFO] - Epoch 70/100, Val Acc=0.7358, Val Loss=1.3019, lr=0.0010
[2025-04-30 19:59:17,240][train][INFO] - Epoch 62/100, Val Acc=0.7266, Val Loss=1.3265, lr=0.0010
[2025-04-30 19:59:18,386][train][INFO] - Epoch 70/100, Val Acc=0.7374, Val Loss=1.3408, lr=0.0010
[2025-04-30 19:59:25,632][train][INFO] - Epoch 61/100, Val Acc=0.7249, Val Loss=1.3293, lr=0.0010
[2025-04-30 19:59:25,903][train][INFO] - Epoch 71/100, Val Acc=0.7349, Val Loss=1.3071, lr=0.0010
[2025-04-30 19:59:28,119][train][INFO] - Epoch 63/100, Val Acc=0.7281, Val Loss=1.3325, lr=0.0010
[2025-04-30 19:59:29,218][train][INFO] - Epoch 71/100, Val Acc=0.7375, Val Loss=1.3355, lr=0.0010
[2025-04-30 19:59:36,626][train][INFO] - Epoch 62/100, Val Acc=0.7259, Val Loss=1.3206, lr=0.0010
[2025-04-30 19:59:36,912][train][INFO] - Epoch 72/100, Val Acc=0.7357, Val Loss=1.2989, lr=0.0010
[2025-04-30 19:59:39,019][train][INFO] - Epoch 64/100, Val Acc=0.7305, Val Loss=1.3348, lr=0.0010
[2025-04-30 19:59:40,020][train][INFO] - Epoch 72/100, Val Acc=0.7402, Val Loss=1.3307, lr=0.0010
[2025-04-30 19:59:47,653][train][INFO] - Epoch 63/100, Val Acc=0.7276, Val Loss=1.3266, lr=0.0010
[2025-04-30 19:59:47,954][train][INFO] - Epoch 73/100, Val Acc=0.7385, Val Loss=1.3049, lr=0.0010
[2025-04-30 19:59:49,877][train][INFO] - Epoch 65/100, Val Acc=0.7313, Val Loss=1.3376, lr=0.0010
[2025-04-30 19:59:50,782][train][INFO] - Epoch 73/100, Val Acc=0.7385, Val Loss=1.3295, lr=0.0010
[2025-04-30 19:59:58,671][train][INFO] - Epoch 64/100, Val Acc=0.7281, Val Loss=1.3300, lr=0.0010
[2025-04-30 19:59:58,995][train][INFO] - Epoch 74/100, Val Acc=0.7389, Val Loss=1.2982, lr=0.0010
[2025-04-30 20:00:00,652][train][INFO] - Epoch 66/100, Val Acc=0.7315, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:00:01,626][train][INFO] - Epoch 74/100, Val Acc=0.7395, Val Loss=1.3247, lr=0.0010
[2025-04-30 20:00:09,646][train][INFO] - Epoch 65/100, Val Acc=0.7306, Val Loss=1.3319, lr=0.0010
[2025-04-30 20:00:09,888][train][INFO] - Epoch 75/100, Val Acc=0.7408, Val Loss=1.3008, lr=0.0010
[2025-04-30 20:00:11,490][train][INFO] - Epoch 67/100, Val Acc=0.7316, Val Loss=1.3338, lr=0.0010
[2025-04-30 20:00:12,409][train][INFO] - Epoch 75/100, Val Acc=0.7395, Val Loss=1.3356, lr=0.0010
[2025-04-30 20:00:20,700][train][INFO] - Epoch 66/100, Val Acc=0.7326, Val Loss=1.3428, lr=0.0010
[2025-04-30 20:00:20,942][train][INFO] - Epoch 76/100, Val Acc=0.7408, Val Loss=1.2978, lr=0.0010
[2025-04-30 20:00:22,316][train][INFO] - Epoch 68/100, Val Acc=0.7323, Val Loss=1.3373, lr=0.0010
[2025-04-30 20:00:23,264][train][INFO] - Epoch 76/100, Val Acc=0.7384, Val Loss=1.3365, lr=0.0010
[2025-04-30 20:00:31,780][train][INFO] - Epoch 67/100, Val Acc=0.7309, Val Loss=1.3422, lr=0.0010
[2025-04-30 20:00:31,981][train][INFO] - Epoch 77/100, Val Acc=0.7402, Val Loss=1.2999, lr=0.0010
[2025-04-30 20:00:33,202][train][INFO] - Epoch 69/100, Val Acc=0.7318, Val Loss=1.3450, lr=0.0010
[2025-04-30 20:00:34,093][train][INFO] - Epoch 77/100, Val Acc=0.7387, Val Loss=1.3336, lr=0.0010
[2025-04-30 20:00:42,753][train][INFO] - Epoch 68/100, Val Acc=0.7326, Val Loss=1.3451, lr=0.0010
[2025-04-30 20:00:42,968][train][INFO] - Epoch 78/100, Val Acc=0.7411, Val Loss=1.2960, lr=0.0010
[2025-04-30 20:00:44,057][train][INFO] - Epoch 70/100, Val Acc=0.7325, Val Loss=1.3466, lr=0.0010
[2025-04-30 20:00:44,859][train][INFO] - Epoch 78/100, Val Acc=0.7403, Val Loss=1.3328, lr=0.0010
[2025-04-30 20:00:53,889][train][INFO] - Epoch 69/100, Val Acc=0.7333, Val Loss=1.3450, lr=0.0010
[2025-04-30 20:00:54,042][train][INFO] - Epoch 79/100, Val Acc=0.7400, Val Loss=1.2994, lr=0.0010
[2025-04-30 20:00:54,939][train][INFO] - Epoch 71/100, Val Acc=0.7339, Val Loss=1.3471, lr=0.0010
[2025-04-30 20:00:55,791][train][INFO] - Epoch 79/100, Val Acc=0.7389, Val Loss=1.3380, lr=0.0010
[2025-04-30 20:01:04,933][train][INFO] - Epoch 70/100, Val Acc=0.7339, Val Loss=1.3521, lr=0.0010
[2025-04-30 20:01:05,185][train][INFO] - Epoch 80/100, Val Acc=0.7391, Val Loss=1.2972, lr=0.0010
[2025-04-30 20:01:05,949][train][INFO] - Epoch 72/100, Val Acc=0.7365, Val Loss=1.3486, lr=0.0010
[2025-04-30 20:01:06,593][train][INFO] - Epoch 80/100, Val Acc=0.7397, Val Loss=1.3389, lr=0.0010
[2025-04-30 20:01:15,885][train][INFO] - Epoch 71/100, Val Acc=0.7345, Val Loss=1.3570, lr=0.0010
[2025-04-30 20:01:16,212][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.2960, lr=0.0010
[2025-04-30 20:01:16,671][train][INFO] - Epoch 73/100, Val Acc=0.7372, Val Loss=1.3449, lr=0.0010
[2025-04-30 20:01:17,315][train][INFO] - Epoch 81/100, Val Acc=0.7400, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:01:26,732][train][INFO] - Epoch 72/100, Val Acc=0.7344, Val Loss=1.3517, lr=0.0010
[2025-04-30 20:01:27,198][train][INFO] - Epoch 82/100, Val Acc=0.7393, Val Loss=1.2993, lr=0.0010
[2025-04-30 20:01:27,553][train][INFO] - Epoch 74/100, Val Acc=0.7377, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:01:28,230][train][INFO] - Epoch 82/100, Val Acc=0.7424, Val Loss=1.3271, lr=0.0010
[2025-04-30 20:01:37,459][train][INFO] - Epoch 73/100, Val Acc=0.7342, Val Loss=1.3550, lr=0.0010
[2025-04-30 20:01:38,036][train][INFO] - Epoch 83/100, Val Acc=0.7402, Val Loss=1.3075, lr=0.0010
[2025-04-30 20:01:38,335][train][INFO] - Epoch 75/100, Val Acc=0.7365, Val Loss=1.3522, lr=0.0010
[2025-04-30 20:01:39,162][train][INFO] - Epoch 83/100, Val Acc=0.7418, Val Loss=1.3392, lr=0.0010
[2025-04-30 20:01:48,362][train][INFO] - Epoch 74/100, Val Acc=0.7360, Val Loss=1.3544, lr=0.0010
[2025-04-30 20:01:48,914][train][INFO] - Epoch 84/100, Val Acc=0.7396, Val Loss=1.3068, lr=0.0010
[2025-04-30 20:01:49,092][train][INFO] - Epoch 76/100, Val Acc=0.7344, Val Loss=1.3492, lr=0.0010
[2025-04-30 20:01:50,068][train][INFO] - Epoch 84/100, Val Acc=0.7415, Val Loss=1.3432, lr=0.0010
[2025-04-30 20:01:59,147][train][INFO] - Epoch 75/100, Val Acc=0.7374, Val Loss=1.3557, lr=0.0010
[2025-04-30 20:01:59,812][train][INFO] - Epoch 85/100, Val Acc=0.7403, Val Loss=1.3045, lr=0.0010
[2025-04-30 20:02:00,008][train][INFO] - Epoch 77/100, Val Acc=0.7379, Val Loss=1.3441, lr=0.0010
[2025-04-30 20:02:00,926][train][INFO] - Epoch 85/100, Val Acc=0.7408, Val Loss=1.3314, lr=0.0010
[2025-04-30 20:02:09,946][train][INFO] - Epoch 76/100, Val Acc=0.7378, Val Loss=1.3527, lr=0.0010
[2025-04-30 20:02:10,710][train][INFO] - Epoch 86/100, Val Acc=0.7401, Val Loss=1.3096, lr=0.0010
[2025-04-30 20:02:10,763][train][INFO] - Epoch 78/100, Val Acc=0.7373, Val Loss=1.3415, lr=0.0010
[2025-04-30 20:02:11,804][train][INFO] - Epoch 86/100, Val Acc=0.7439, Val Loss=1.3323, lr=0.0010
[2025-04-30 20:02:20,695][train][INFO] - Epoch 77/100, Val Acc=0.7366, Val Loss=1.3563, lr=0.0010
[2025-04-30 20:02:21,522][train][INFO] - Epoch 87/100, Val Acc=0.7379, Val Loss=1.3038, lr=0.0010
[2025-04-30 20:02:21,581][train][INFO] - Epoch 79/100, Val Acc=0.7361, Val Loss=1.3516, lr=0.0010
[2025-04-30 20:02:22,745][train][INFO] - Epoch 87/100, Val Acc=0.7398, Val Loss=1.3316, lr=0.0010
[2025-04-30 20:02:31,471][train][INFO] - Epoch 78/100, Val Acc=0.7376, Val Loss=1.3494, lr=0.0010
[2025-04-30 20:02:32,363][train][INFO] - Epoch 80/100, Val Acc=0.7384, Val Loss=1.3486, lr=0.0010
[2025-04-30 20:02:32,515][train][INFO] - Epoch 88/100, Val Acc=0.7408, Val Loss=1.3097, lr=0.0010
[2025-04-30 20:02:33,565][train][INFO] - Epoch 88/100, Val Acc=0.7423, Val Loss=1.3322, lr=0.0010
[2025-04-30 20:02:42,279][train][INFO] - Epoch 79/100, Val Acc=0.7366, Val Loss=1.3579, lr=0.0010
[2025-04-30 20:02:43,166][train][INFO] - Epoch 81/100, Val Acc=0.7357, Val Loss=1.3473, lr=0.0010
[2025-04-30 20:02:43,415][train][INFO] - Epoch 89/100, Val Acc=0.7412, Val Loss=1.3078, lr=0.0010
[2025-04-30 20:02:44,315][train][INFO] - Epoch 89/100, Val Acc=0.7449, Val Loss=1.3254, lr=0.0010
[2025-04-30 20:02:53,039][train][INFO] - Epoch 80/100, Val Acc=0.7394, Val Loss=1.3461, lr=0.0010
[2025-04-30 20:02:53,986][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3491, lr=0.0010
[2025-04-30 20:02:54,235][train][INFO] - Epoch 90/100, Val Acc=0.7405, Val Loss=1.3082, lr=0.0010
[2025-04-30 20:02:55,164][train][INFO] - Epoch 90/100, Val Acc=0.7431, Val Loss=1.3308, lr=0.0010
[2025-04-30 20:03:03,764][train][INFO] - Epoch 81/100, Val Acc=0.7379, Val Loss=1.3574, lr=0.0010
[2025-04-30 20:03:04,882][train][INFO] - Epoch 83/100, Val Acc=0.7372, Val Loss=1.3474, lr=0.0010
[2025-04-30 20:03:05,036][train][INFO] - Epoch 91/100, Val Acc=0.7413, Val Loss=1.3043, lr=0.0001
[2025-04-30 20:03:05,925][train][INFO] - Epoch 91/100, Val Acc=0.7419, Val Loss=1.3225, lr=0.0001
[2025-04-30 20:03:14,345][train][INFO] - Epoch 82/100, Val Acc=0.7381, Val Loss=1.3535, lr=0.0010
[2025-04-30 20:03:15,759][train][INFO] - Epoch 92/100, Val Acc=0.7413, Val Loss=1.3052, lr=0.0001
[2025-04-30 20:03:15,811][train][INFO] - Epoch 84/100, Val Acc=0.7366, Val Loss=1.3459, lr=0.0010
[2025-04-30 20:03:16,814][train][INFO] - Epoch 92/100, Val Acc=0.7423, Val Loss=1.3300, lr=0.0001
[2025-04-30 20:03:25,024][train][INFO] - Epoch 83/100, Val Acc=0.7380, Val Loss=1.3577, lr=0.0010
[2025-04-30 20:03:26,442][train][INFO] - Epoch 93/100, Val Acc=0.7409, Val Loss=1.3036, lr=0.0001
[2025-04-30 20:03:26,793][train][INFO] - Epoch 85/100, Val Acc=0.7396, Val Loss=1.3381, lr=0.0010
[2025-04-30 20:03:27,731][train][INFO] - Epoch 93/100, Val Acc=0.7431, Val Loss=1.3274, lr=0.0001
[2025-04-30 20:03:35,539][train][INFO] - Epoch 84/100, Val Acc=0.7381, Val Loss=1.3541, lr=0.0010
[2025-04-30 20:03:37,163][train][INFO] - Epoch 94/100, Val Acc=0.7413, Val Loss=1.2992, lr=0.0001
[2025-04-30 20:03:37,600][train][INFO] - Epoch 86/100, Val Acc=0.7386, Val Loss=1.3478, lr=0.0010
[2025-04-30 20:03:38,550][train][INFO] - Epoch 94/100, Val Acc=0.7441, Val Loss=1.3220, lr=0.0001
[2025-04-30 20:03:45,935][train][INFO] - Epoch 85/100, Val Acc=0.7380, Val Loss=1.3488, lr=0.0010
[2025-04-30 20:03:47,703][train][INFO] - Epoch 95/100, Val Acc=0.7403, Val Loss=1.3103, lr=0.0001
[2025-04-30 20:03:48,523][train][INFO] - Epoch 87/100, Val Acc=0.7383, Val Loss=1.3385, lr=0.0010
[2025-04-30 20:03:49,464][train][INFO] - Epoch 95/100, Val Acc=0.7448, Val Loss=1.3297, lr=0.0001
[2025-04-30 20:03:56,369][train][INFO] - Epoch 86/100, Val Acc=0.7351, Val Loss=1.3561, lr=0.0010
[2025-04-30 20:03:58,372][train][INFO] - Epoch 96/100, Val Acc=0.7426, Val Loss=1.3031, lr=0.0001
[2025-04-30 20:03:59,350][train][INFO] - Epoch 88/100, Val Acc=0.7397, Val Loss=1.3439, lr=0.0010
[2025-04-30 20:04:00,218][train][INFO] - Epoch 96/100, Val Acc=0.7444, Val Loss=1.3230, lr=0.0001
[2025-04-30 20:04:06,841][train][INFO] - Epoch 87/100, Val Acc=0.7377, Val Loss=1.3491, lr=0.0010
[2025-04-30 20:04:08,862][train][INFO] - Epoch 97/100, Val Acc=0.7410, Val Loss=1.3016, lr=0.0001
[2025-04-30 20:04:10,108][train][INFO] - Epoch 89/100, Val Acc=0.7417, Val Loss=1.3445, lr=0.0010
[2025-04-30 20:04:11,008][train][INFO] - Epoch 97/100, Val Acc=0.7439, Val Loss=1.3214, lr=0.0001
[2025-04-30 20:04:17,251][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3548, lr=0.0010
[2025-04-30 20:04:19,502][train][INFO] - Epoch 98/100, Val Acc=0.7415, Val Loss=1.2997, lr=0.0001
[2025-04-30 20:04:20,917][train][INFO] - Epoch 90/100, Val Acc=0.7388, Val Loss=1.3493, lr=0.0010
[2025-04-30 20:04:21,867][train][INFO] - Epoch 98/100, Val Acc=0.7445, Val Loss=1.3195, lr=0.0001
[2025-04-30 20:04:27,848][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3551, lr=0.0010
[2025-04-30 20:04:30,116][train][INFO] - Epoch 99/100, Val Acc=0.7418, Val Loss=1.3031, lr=0.0001
[2025-04-30 20:04:31,793][train][INFO] - Epoch 91/100, Val Acc=0.7402, Val Loss=1.3471, lr=0.0001
[2025-04-30 20:04:32,820][train][INFO] - Epoch 99/100, Val Acc=0.7433, Val Loss=1.3253, lr=0.0001
[2025-04-30 20:04:38,310][train][INFO] - Epoch 90/100, Val Acc=0.7369, Val Loss=1.3611, lr=0.0010
[2025-04-30 20:04:40,781][train][INFO] - Epoch 100/100, Val Acc=0.7413, Val Loss=1.3029, lr=0.0001
[2025-04-30 20:04:42,673][train][INFO] - Epoch 92/100, Val Acc=0.7400, Val Loss=1.3508, lr=0.0001
[2025-04-30 20:04:43,667][train][INFO] - Epoch 100/100, Val Acc=0.7420, Val Loss=1.3272, lr=0.0001
[2025-04-30 20:04:46,250][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7426
[2025-04-30 20:04:46,255][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:04:47,508][train][INFO] - Epoch 91/100, Val Acc=0.7372, Val Loss=1.3541, lr=0.0001
[2025-04-30 20:04:49,132][train][INFO] - After training : Train Acc=0.9994  Val Acc=0.7449
[2025-04-30 20:04:49,137][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:04:51,591][train][INFO] - Epoch 93/100, Val Acc=0.7402, Val Loss=1.3411, lr=0.0001
[2025-04-30 20:04:56,034][train][INFO] - Epoch 92/100, Val Acc=0.7365, Val Loss=1.3595, lr=0.0001
[2025-04-30 20:05:00,293][train][INFO] - Epoch 94/100, Val Acc=0.7405, Val Loss=1.3381, lr=0.0001
[2025-04-30 20:05:04,683][train][INFO] - Epoch 93/100, Val Acc=0.7367, Val Loss=1.3570, lr=0.0001
[2025-04-30 20:05:08,953][train][INFO] - Epoch 95/100, Val Acc=0.7397, Val Loss=1.3455, lr=0.0001
[2025-04-30 20:05:13,427][train][INFO] - Epoch 94/100, Val Acc=0.7376, Val Loss=1.3524, lr=0.0001
[2025-04-30 20:05:17,357][train][INFO] - Epoch 96/100, Val Acc=0.7403, Val Loss=1.3395, lr=0.0001
[2025-04-30 20:05:22,067][train][INFO] - Epoch 95/100, Val Acc=0.7374, Val Loss=1.3577, lr=0.0001
[2025-04-30 20:05:26,180][train][INFO] - Epoch 97/100, Val Acc=0.7394, Val Loss=1.3396, lr=0.0001
[2025-04-30 20:05:30,470][train][INFO] - Epoch 96/100, Val Acc=0.7371, Val Loss=1.3532, lr=0.0001
[2025-04-30 20:05:35,174][train][INFO] - Epoch 98/100, Val Acc=0.7406, Val Loss=1.3387, lr=0.0001
[2025-04-30 20:05:38,906][train][INFO] - Epoch 97/100, Val Acc=0.7383, Val Loss=1.3537, lr=0.0001
[2025-04-30 20:05:43,667][train][INFO] - Epoch 99/100, Val Acc=0.7395, Val Loss=1.3415, lr=0.0001
[2025-04-30 20:05:47,465][train][INFO] - Epoch 98/100, Val Acc=0.7383, Val Loss=1.3470, lr=0.0001
[2025-04-30 20:05:52,346][train][INFO] - Epoch 100/100, Val Acc=0.7406, Val Loss=1.3430, lr=0.0001
[2025-04-30 20:05:56,013][train][INFO] - Epoch 99/100, Val Acc=0.7371, Val Loss=1.3530, lr=0.0001
[2025-04-30 20:05:57,856][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7417
[2025-04-30 20:05:57,860][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:06:04,503][train][INFO] - Epoch 100/100, Val Acc=0.7380, Val Loss=1.3584, lr=0.0001
[2025-04-30 20:06:09,955][train][INFO] - After training : Train Acc=0.9987  Val Acc=0.7394
[2025-04-30 20:06:09,960][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:06:57,864][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:06:58,910][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:08:01,828][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:08:13,987][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:09:02,840][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:09:03,334][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:09:06,523][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:09:07,032][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:10:04,903][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:10:05,389][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:10:15,668][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:10:16,077][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:40:16,601][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 20:40:46,668][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 20:40:55,087][train][INFO] - Epoch 1/100, Val Acc=0.6008, Val Loss=1.6908, lr=0.0100
[2025-04-30 20:41:03,056][train][INFO] - Epoch 2/100, Val Acc=0.6280, Val Loss=1.5495, lr=0.0100
[2025-04-30 20:41:11,465][train][INFO] - Epoch 3/100, Val Acc=0.6310, Val Loss=1.5558, lr=0.0100
[2025-04-30 20:41:19,865][train][INFO] - Epoch 4/100, Val Acc=0.6561, Val Loss=1.4704, lr=0.0100
[2025-04-30 20:41:27,769][train][INFO] - Epoch 5/100, Val Acc=0.6488, Val Loss=1.5299, lr=0.0100
[2025-04-30 20:41:35,519][train][INFO] - Epoch 6/100, Val Acc=0.6516, Val Loss=1.5412, lr=0.0100
[2025-04-30 20:41:43,695][train][INFO] - Epoch 7/100, Val Acc=0.6540, Val Loss=1.5415, lr=0.0100
[2025-04-30 20:41:51,794][train][INFO] - Epoch 8/100, Val Acc=0.6484, Val Loss=1.5928, lr=0.0100
[2025-04-30 20:42:00,336][train][INFO] - Epoch 9/100, Val Acc=0.6582, Val Loss=1.5039, lr=0.0100
[2025-04-30 20:42:07,854][train][INFO] - Epoch 10/100, Val Acc=0.6544, Val Loss=1.5478, lr=0.0100
[2025-04-30 20:42:15,271][train][INFO] - Epoch 11/100, Val Acc=0.6633, Val Loss=1.4638, lr=0.0100
[2025-04-30 20:42:23,551][train][INFO] - Epoch 12/100, Val Acc=0.6767, Val Loss=1.4260, lr=0.0100
[2025-04-30 20:42:31,231][train][INFO] - Epoch 13/100, Val Acc=0.6671, Val Loss=1.4978, lr=0.0100
[2025-04-30 20:42:38,989][train][INFO] - Epoch 14/100, Val Acc=0.6713, Val Loss=1.4731, lr=0.0100
[2025-04-30 20:42:47,175][train][INFO] - Epoch 15/100, Val Acc=0.6502, Val Loss=1.5949, lr=0.0100
[2025-04-30 20:42:55,887][train][INFO] - Epoch 16/100, Val Acc=0.6737, Val Loss=1.4793, lr=0.0100
[2025-04-30 20:43:03,902][train][INFO] - Epoch 17/100, Val Acc=0.6738, Val Loss=1.4928, lr=0.0100
[2025-04-30 20:43:11,434][train][INFO] - Epoch 18/100, Val Acc=0.6665, Val Loss=1.5940, lr=0.0100
[2025-04-30 20:43:19,765][train][INFO] - Epoch 19/100, Val Acc=0.6683, Val Loss=1.5374, lr=0.0100
[2025-04-30 20:43:27,623][train][INFO] - Epoch 20/100, Val Acc=0.6707, Val Loss=1.4998, lr=0.0100
[2025-04-30 20:43:35,967][train][INFO] - Epoch 21/100, Val Acc=0.6650, Val Loss=1.5393, lr=0.0100
[2025-04-30 20:43:44,226][train][INFO] - Epoch 22/100, Val Acc=0.6786, Val Loss=1.4794, lr=0.0100
[2025-04-30 20:43:51,899][train][INFO] - Epoch 23/100, Val Acc=0.6737, Val Loss=1.5060, lr=0.0100
[2025-04-30 20:44:00,169][train][INFO] - Epoch 24/100, Val Acc=0.6844, Val Loss=1.4798, lr=0.0100
[2025-04-30 20:44:08,126][train][INFO] - Epoch 25/100, Val Acc=0.6811, Val Loss=1.4937, lr=0.0100
[2025-04-30 20:44:08,350][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-04-30 20:44:08,413][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 20:44:08,414][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 20:44:08,414][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 20:44:16,564][train][INFO] - Epoch 26/100, Val Acc=0.6647, Val Loss=1.5741, lr=0.0100
[2025-04-30 20:44:25,254][train][INFO] - Epoch 27/100, Val Acc=0.6766, Val Loss=1.5215, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 20:44:34,023][train][INFO] - Epoch 28/100, Val Acc=0.6683, Val Loss=1.5497, lr=0.0100
[2025-04-30 20:44:42,485][train][INFO] - Epoch 29/100, Val Acc=0.6656, Val Loss=1.5849, lr=0.0100
[2025-04-30 20:44:50,651][train][INFO] - Epoch 30/100, Val Acc=0.6833, Val Loss=1.5007, lr=0.0100
[2025-04-30 20:44:52,686][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-04-30 20:44:58,917][train][INFO] - Epoch 31/100, Val Acc=0.6572, Val Loss=1.6534, lr=0.0100
[2025-04-30 20:45:07,627][train][INFO] - Epoch 32/100, Val Acc=0.6695, Val Loss=1.5699, lr=0.0100
[2025-04-30 20:45:15,924][train][INFO] - Epoch 33/100, Val Acc=0.6760, Val Loss=1.5226, lr=0.0100
[2025-04-30 20:45:24,438][train][INFO] - Epoch 34/100, Val Acc=0.6743, Val Loss=1.5793, lr=0.0100
[2025-04-30 20:45:31,840][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8075, lr=0.001
[2025-04-30 20:45:33,014][train][INFO] - Epoch 35/100, Val Acc=0.6789, Val Loss=1.5400, lr=0.0100
[2025-04-30 20:45:41,308][train][INFO] - Epoch 36/100, Val Acc=0.6560, Val Loss=1.6277, lr=0.0100
[2025-04-30 20:45:49,466][train][INFO] - Epoch 37/100, Val Acc=0.6732, Val Loss=1.5250, lr=0.0100
[2025-04-30 20:45:57,851][train][INFO] - Epoch 38/100, Val Acc=0.6858, Val Loss=1.5104, lr=0.0100
[2025-04-30 20:46:05,997][train][INFO] - Epoch 39/100, Val Acc=0.6702, Val Loss=1.6007, lr=0.0100
[2025-04-30 20:46:11,456][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6741, lr=0.001
[2025-04-30 20:46:14,744][train][INFO] - Epoch 40/100, Val Acc=0.6681, Val Loss=1.5600, lr=0.0100
[2025-04-30 20:46:22,777][train][INFO] - Epoch 41/100, Val Acc=0.6748, Val Loss=1.5214, lr=0.0100
[2025-04-30 20:46:31,023][train][INFO] - Epoch 42/100, Val Acc=0.6578, Val Loss=1.6024, lr=0.0100
[2025-04-30 20:46:39,376][train][INFO] - Epoch 43/100, Val Acc=0.6677, Val Loss=1.5765, lr=0.0100
[2025-04-30 20:46:47,254][train][INFO] - Epoch 44/100, Val Acc=0.6656, Val Loss=1.5911, lr=0.0100
[2025-04-30 20:46:49,509][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8369, lr=0.001
[2025-04-30 20:46:55,686][train][INFO] - Epoch 45/100, Val Acc=0.6734, Val Loss=1.5467, lr=0.0100
[2025-04-30 20:47:03,868][train][INFO] - Epoch 46/100, Val Acc=0.6634, Val Loss=1.6254, lr=0.0100
[2025-04-30 20:47:11,896][train][INFO] - Epoch 47/100, Val Acc=0.6675, Val Loss=1.5980, lr=0.0100
[2025-04-30 20:47:19,599][train][INFO] - Epoch 48/100, Val Acc=0.6718, Val Loss=1.5579, lr=0.0100
[2025-04-30 20:47:28,086][train][INFO] - Epoch 49/100, Val Acc=0.6791, Val Loss=1.5344, lr=0.0100
[2025-04-30 20:47:29,592][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.9273, lr=0.001
[2025-04-30 20:47:36,355][train][INFO] - Epoch 50/100, Val Acc=0.6710, Val Loss=1.5441, lr=0.0100
[2025-04-30 20:47:44,642][train][INFO] - Epoch 51/100, Val Acc=0.6763, Val Loss=1.5330, lr=0.0100
[2025-04-30 20:47:53,028][train][INFO] - Epoch 52/100, Val Acc=0.6803, Val Loss=1.5280, lr=0.0100
[2025-04-30 20:48:01,327][train][INFO] - Epoch 53/100, Val Acc=0.6780, Val Loss=1.5191, lr=0.0100
[2025-04-30 20:48:08,867][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9680, lr=0.001
[2025-04-30 20:48:08,951][train][INFO] - Epoch 54/100, Val Acc=0.6718, Val Loss=1.5647, lr=0.0100
[2025-04-30 20:48:17,634][train][INFO] - Epoch 55/100, Val Acc=0.6631, Val Loss=1.6259, lr=0.0100
[2025-04-30 20:48:25,867][train][INFO] - Epoch 56/100, Val Acc=0.6808, Val Loss=1.4870, lr=0.0100
[2025-04-30 20:48:33,927][train][INFO] - Epoch 57/100, Val Acc=0.6766, Val Loss=1.5601, lr=0.0100
[2025-04-30 20:48:41,630][train][INFO] - Epoch 58/100, Val Acc=0.6689, Val Loss=1.5775, lr=0.0100
[2025-04-30 20:48:48,841][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.8066, lr=0.001
[2025-04-30 20:48:49,761][train][INFO] - Epoch 59/100, Val Acc=0.6832, Val Loss=1.5500, lr=0.0100
[2025-04-30 20:48:57,786][train][INFO] - Epoch 60/100, Val Acc=0.6741, Val Loss=1.5722, lr=0.0100
[2025-04-30 20:49:06,115][train][INFO] - Epoch 61/100, Val Acc=0.7277, Val Loss=1.3040, lr=0.0010
[2025-04-30 20:49:14,154][train][INFO] - Epoch 62/100, Val Acc=0.7306, Val Loss=1.2980, lr=0.0010
[2025-04-30 20:49:22,677][train][INFO] - Epoch 63/100, Val Acc=0.7328, Val Loss=1.3065, lr=0.0010
[2025-04-30 20:49:27,729][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.5005, lr=0.001
[2025-04-30 20:49:27,751][meta_train][INFO] - epoch_1 saved !
[2025-04-30 20:49:30,882][train][INFO] - Epoch 64/100, Val Acc=0.7362, Val Loss=1.3068, lr=0.0010
[2025-04-30 20:49:39,182][train][INFO] - Epoch 65/100, Val Acc=0.7373, Val Loss=1.3042, lr=0.0010
[2025-04-30 20:49:47,713][train][INFO] - Epoch 66/100, Val Acc=0.7355, Val Loss=1.3189, lr=0.0010
[2025-04-30 20:49:56,244][train][INFO] - Epoch 67/100, Val Acc=0.7380, Val Loss=1.3127, lr=0.0010
[2025-04-30 20:50:04,200][train][INFO] - Epoch 68/100, Val Acc=0.7380, Val Loss=1.3153, lr=0.0010
[2025-04-30 20:50:08,295][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.4438, lr=0.001
[2025-04-30 20:50:12,539][train][INFO] - Epoch 69/100, Val Acc=0.7351, Val Loss=1.3248, lr=0.0010
[2025-04-30 20:50:20,355][train][INFO] - Epoch 70/100, Val Acc=0.7343, Val Loss=1.3296, lr=0.0010
[2025-04-30 20:50:28,277][train][INFO] - Epoch 71/100, Val Acc=0.7381, Val Loss=1.3319, lr=0.0010
[2025-04-30 20:50:36,275][train][INFO] - Epoch 72/100, Val Acc=0.7382, Val Loss=1.3245, lr=0.0010
[2025-04-30 20:50:44,500][train][INFO] - Epoch 73/100, Val Acc=0.7394, Val Loss=1.3229, lr=0.0010
[2025-04-30 20:50:46,296][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1417, lr=0.001
[2025-04-30 20:50:52,437][train][INFO] - Epoch 74/100, Val Acc=0.7400, Val Loss=1.3177, lr=0.0010
[2025-04-30 20:51:00,912][train][INFO] - Epoch 75/100, Val Acc=0.7401, Val Loss=1.3270, lr=0.0010
[2025-04-30 20:51:08,641][train][INFO] - Epoch 76/100, Val Acc=0.7411, Val Loss=1.3264, lr=0.0010
[2025-04-30 20:51:17,107][train][INFO] - Epoch 77/100, Val Acc=0.7385, Val Loss=1.3250, lr=0.0010
[2025-04-30 20:51:24,888][train][INFO] - Epoch 78/100, Val Acc=0.7416, Val Loss=1.3307, lr=0.0010
[2025-04-30 20:51:25,724][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1675, lr=0.001
[2025-04-30 20:51:33,661][train][INFO] - Epoch 79/100, Val Acc=0.7411, Val Loss=1.3325, lr=0.0010
[2025-04-30 20:51:41,592][train][INFO] - Epoch 80/100, Val Acc=0.7424, Val Loss=1.3303, lr=0.0010
[2025-04-30 20:51:50,056][train][INFO] - Epoch 81/100, Val Acc=0.7394, Val Loss=1.3352, lr=0.0010
[2025-04-30 20:51:57,964][train][INFO] - Epoch 82/100, Val Acc=0.7377, Val Loss=1.3342, lr=0.0010
[2025-04-30 20:52:05,828][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.3302, lr=0.001
[2025-04-30 20:52:06,005][train][INFO] - Epoch 83/100, Val Acc=0.7405, Val Loss=1.3422, lr=0.0010
[2025-04-30 20:52:14,322][train][INFO] - Epoch 84/100, Val Acc=0.7396, Val Loss=1.3327, lr=0.0010
[2025-04-30 20:52:22,746][train][INFO] - Epoch 85/100, Val Acc=0.7424, Val Loss=1.3292, lr=0.0010
[2025-04-30 20:52:31,083][train][INFO] - Epoch 86/100, Val Acc=0.7412, Val Loss=1.3272, lr=0.0010
[2025-04-30 20:52:39,671][train][INFO] - Epoch 87/100, Val Acc=0.7422, Val Loss=1.3179, lr=0.0010
[2025-04-30 20:52:46,256][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.1109, lr=0.001
[2025-04-30 20:52:47,654][train][INFO] - Epoch 88/100, Val Acc=0.7417, Val Loss=1.3275, lr=0.0010
[2025-04-30 20:52:56,368][train][INFO] - Epoch 89/100, Val Acc=0.7419, Val Loss=1.3270, lr=0.0010
[2025-04-30 20:53:05,036][train][INFO] - Epoch 90/100, Val Acc=0.7409, Val Loss=1.3380, lr=0.0010
[2025-04-30 20:53:16,193][train][INFO] - Epoch 91/100, Val Acc=0.7401, Val Loss=1.3301, lr=0.0001
[2025-04-30 20:53:24,766][train][INFO] - Epoch 92/100, Val Acc=0.7394, Val Loss=1.3337, lr=0.0001
[2025-04-30 20:53:30,631][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0965, lr=0.001
[2025-04-30 20:53:33,346][train][INFO] - Epoch 93/100, Val Acc=0.7414, Val Loss=1.3288, lr=0.0001
[2025-04-30 20:53:41,499][train][INFO] - Epoch 94/100, Val Acc=0.7398, Val Loss=1.3258, lr=0.0001
[2025-04-30 20:53:49,668][train][INFO] - Epoch 95/100, Val Acc=0.7399, Val Loss=1.3325, lr=0.0001
[2025-04-30 20:53:57,935][train][INFO] - Epoch 96/100, Val Acc=0.7409, Val Loss=1.3278, lr=0.0001
[2025-04-30 20:54:06,034][train][INFO] - Epoch 97/100, Val Acc=0.7403, Val Loss=1.3262, lr=0.0001
[2025-04-30 20:54:11,022][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0886, lr=0.001
[2025-04-30 20:54:14,633][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3242, lr=0.0001
[2025-04-30 20:54:22,833][train][INFO] - Epoch 99/100, Val Acc=0.7412, Val Loss=1.3287, lr=0.0001
[2025-04-30 20:54:30,904][train][INFO] - Epoch 100/100, Val Acc=0.7423, Val Loss=1.3297, lr=0.0001
[2025-04-30 20:54:36,158][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.7424
[2025-04-30 20:54:36,163][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:54:51,086][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0734, lr=0.001
[2025-04-30 20:54:51,109][meta_train][INFO] - epoch_2 saved !
[2025-04-30 20:55:31,014][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1057, lr=0.001
[2025-04-30 20:56:11,233][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0991, lr=0.001
[2025-04-30 20:56:28,091][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:56:51,483][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0990, lr=0.001
[2025-04-30 20:57:30,559][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.1238, lr=0.001
[2025-04-30 20:58:11,700][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2640, lr=0.001
[2025-04-30 20:58:24,231][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:58:24,680][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:58:51,571][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2490, lr=0.001
[2025-04-30 20:59:30,311][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1372, lr=0.001
[2025-04-30 21:00:08,295][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1343, lr=0.001
[2025-04-30 21:00:08,316][meta_train][INFO] - epoch_3 saved !
[2025-04-30 21:00:46,546][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1629, lr=0.001
[2025-04-30 21:01:24,399][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1719, lr=0.001
[2025-04-30 21:02:03,433][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.3283, lr=0.001
[2025-04-30 21:02:41,447][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1797, lr=0.001
[2025-04-30 21:03:21,772][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1811, lr=0.001
[2025-04-30 21:03:58,480][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.3008, lr=0.001
[2025-04-30 21:04:36,786][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.5628, lr=0.001
[2025-04-30 21:05:14,432][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.3116, lr=0.001
[2025-04-30 21:05:14,441][meta_train][INFO] - epoch_4 saved !
[2025-04-30 21:05:52,985][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.5154, lr=0.001
[2025-04-30 21:06:31,803][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.3117, lr=0.001
[2025-04-30 21:07:10,959][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.4938, lr=0.001
[2025-04-30 21:07:48,683][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.4834, lr=0.001
[2025-04-30 21:08:27,474][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=1.2287, lr=0.001
[2025-04-30 21:09:05,301][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.6893, lr=0.001
[2025-04-30 21:09:43,448][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.7877, lr=0.001
[2025-04-30 21:10:21,634][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.8715, lr=0.001
[2025-04-30 21:10:21,648][meta_train][INFO] - epoch_5 saved !
[2025-04-30 21:10:59,176][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=1.8127, lr=0.001
[2025-04-30 21:11:38,447][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.6902, lr=0.001
[2025-04-30 21:12:15,652][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.9215, lr=0.001
[2025-04-30 21:13:03,770][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=1.0674, lr=0.001
[2025-04-30 21:13:45,198][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.7868, lr=0.001
[2025-04-30 21:14:40,225][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.9430, lr=0.001
[2025-04-30 21:15:19,054][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.9299, lr=0.001
[2025-04-30 21:15:58,898][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.9080, lr=0.001
[2025-04-30 21:15:58,910][meta_train][INFO] - epoch_6 saved !
[2025-04-30 21:16:55,996][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=1.1020, lr=0.001
[2025-04-30 21:17:43,345][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=1.6334, lr=0.001
[2025-04-30 21:18:22,371][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.8662, lr=0.001
[2025-04-30 21:19:00,437][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.9092, lr=0.001
[2025-04-30 21:19:38,168][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.8017, lr=0.001
[2025-04-30 21:20:38,265][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.6183, lr=0.001
[2025-04-30 21:21:18,713][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.7119, lr=0.001
[2025-04-30 21:21:55,066][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.7736, lr=0.001
[2025-04-30 21:21:55,086][meta_train][INFO] - epoch_7 saved !
[2025-04-30 21:22:32,126][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.7121, lr=0.001
[2025-04-30 21:23:08,711][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.7541, lr=0.001
[2025-04-30 21:23:46,211][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.7021, lr=0.001
[2025-04-30 21:24:23,743][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.9933, lr=0.001
[2025-04-30 21:25:21,122][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.6385, lr=0.001
[2025-04-30 21:26:00,082][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.4881, lr=0.001
[2025-04-30 21:26:36,243][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.7350, lr=0.001
[2025-04-30 21:27:14,299][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.7782, lr=0.001
[2025-04-30 21:27:14,308][meta_train][INFO] - epoch_8 saved !
[2025-04-30 21:27:50,793][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.4159, lr=0.001
[2025-04-30 21:28:29,127][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.4579, lr=0.001
[2025-04-30 21:29:25,371][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.3927, lr=0.001
[2025-04-30 21:30:06,737][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.6602, lr=0.001
[2025-04-30 21:30:43,768][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.8224, lr=0.001
[2025-04-30 21:31:20,943][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.6428, lr=0.001
[2025-04-30 21:31:59,684][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.3779, lr=0.001
[2025-04-30 21:32:37,273][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2917, lr=0.001
[2025-04-30 21:32:37,294][meta_train][INFO] - epoch_9 saved !
[2025-04-30 21:33:13,705][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.4356, lr=0.001
[2025-04-30 21:33:51,935][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3741, lr=0.001
[2025-04-30 21:34:41,521][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4572, lr=0.001
[2025-04-30 21:35:32,887][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.9516, lr=0.001
[2025-04-30 21:36:23,386][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6981, lr=0.001
[2025-04-30 21:37:12,352][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.2309, lr=0.001
[2025-04-30 21:38:02,150][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.9478, lr=0.001
[2025-04-30 21:38:54,485][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.7329, lr=0.001
[2025-04-30 21:38:54,495][meta_train][INFO] - epoch_10 saved !
[2025-04-30 21:39:42,920][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=1.1060, lr=0.0001
[2025-04-30 21:40:31,035][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.9030, lr=0.0001
[2025-04-30 21:41:21,692][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.9823, lr=0.0001
[2025-04-30 21:42:07,612][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=1.2461, lr=0.0001
[2025-04-30 21:42:44,430][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.6248, lr=0.0001
[2025-04-30 21:43:21,728][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.7268, lr=0.0001
[2025-04-30 21:43:57,546][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=1.0589, lr=0.0001
[2025-04-30 21:44:35,493][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=1.3359, lr=0.0001
[2025-04-30 21:44:35,512][meta_train][INFO] - epoch_11 saved !
[2025-04-30 21:45:13,082][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=1.2428, lr=0.0001
[2025-04-30 21:45:50,803][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=1.1057, lr=0.0001
[2025-04-30 21:46:28,253][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=1.3831, lr=0.0001
[2025-04-30 21:47:06,318][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=2.0841, lr=0.0001
[2025-04-30 21:47:43,466][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=1.8544, lr=0.0001
[2025-04-30 21:48:21,288][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=1.1657, lr=0.0001
[2025-04-30 21:48:59,963][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=1.8345, lr=0.0001
[2025-04-30 21:49:37,207][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=1.5007, lr=0.0001
[2025-04-30 21:49:37,217][meta_train][INFO] - epoch_12 saved !
[2025-04-30 21:50:14,702][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=1.3949, lr=0.0001
[2025-04-30 21:50:53,406][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=1.9088, lr=0.0001
[2025-04-30 21:51:31,746][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=1.5644, lr=0.0001
[2025-04-30 21:52:15,432][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=1.2839, lr=0.0001
[2025-04-30 21:52:53,544][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=2.2665, lr=0.0001
[2025-04-30 21:53:30,614][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=1.6399, lr=0.0001
[2025-04-30 21:54:08,313][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=2.0529, lr=0.0001
[2025-04-30 21:54:45,469][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=1.3820, lr=0.0001
[2025-04-30 21:54:45,496][meta_train][INFO] - epoch_13 saved !
[2025-04-30 21:55:24,091][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=1.6981, lr=0.0001
[2025-04-30 21:56:02,937][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=1.3830, lr=0.0001
[2025-04-30 21:56:41,178][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=2.3760, lr=0.0001
[2025-04-30 21:57:17,580][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=2.1443, lr=0.0001
[2025-04-30 21:57:56,086][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=2.1555, lr=0.0001
[2025-04-30 21:58:34,160][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=1.7966, lr=0.0001
[2025-04-30 21:59:10,716][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=1.6958, lr=0.0001
[2025-04-30 21:59:48,825][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=1.4991, lr=0.0001
[2025-04-30 21:59:48,845][meta_train][INFO] - epoch_14 saved !
[2025-04-30 22:00:27,778][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=2.2257, lr=0.0001
[2025-04-30 22:01:05,914][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=2.2507, lr=0.0001
[2025-04-30 22:01:42,396][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=1.7606, lr=0.0001
[2025-04-30 22:02:16,467][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 22:02:20,719][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=2.5329, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 22:02:45,790][train][INFO] - Before training : Train Acc=0.7916  Val Acc=0.6116
[2025-04-30 22:02:53,835][train][INFO] - Epoch 1/100, Val Acc=0.6423, Val Loss=1.6432, lr=0.0100
[2025-04-30 22:02:59,626][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=1.9086, lr=0.0001
[2025-04-30 22:03:01,891][train][INFO] - Epoch 2/100, Val Acc=0.6516, Val Loss=1.6468, lr=0.0100
[2025-04-30 22:03:10,446][train][INFO] - Epoch 3/100, Val Acc=0.6514, Val Loss=1.6231, lr=0.0100
[2025-04-30 22:03:18,972][train][INFO] - Epoch 4/100, Val Acc=0.6649, Val Loss=1.5312, lr=0.0100
[2025-04-30 22:03:27,497][train][INFO] - Epoch 5/100, Val Acc=0.6789, Val Loss=1.4667, lr=0.0100
[2025-04-30 22:03:35,426][train][INFO] - Epoch 6/100, Val Acc=0.6661, Val Loss=1.5437, lr=0.0100
[2025-04-30 22:03:39,201][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=1.5390, lr=0.0001
[2025-04-30 22:03:43,117][train][INFO] - Epoch 7/100, Val Acc=0.6648, Val Loss=1.5033, lr=0.0100
[2025-04-30 22:03:51,410][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5341, lr=0.0100
[2025-04-30 22:03:59,396][train][INFO] - Epoch 9/100, Val Acc=0.6646, Val Loss=1.5601, lr=0.0100
[2025-04-30 22:04:07,694][train][INFO] - Epoch 10/100, Val Acc=0.6560, Val Loss=1.5789, lr=0.0100
[2025-04-30 22:04:15,776][train][INFO] - Epoch 11/100, Val Acc=0.6645, Val Loss=1.5595, lr=0.0100
[2025-04-30 22:04:18,201][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=1.9428, lr=0.0001
[2025-04-30 22:04:23,863][train][INFO] - Epoch 12/100, Val Acc=0.6740, Val Loss=1.5203, lr=0.0100
[2025-04-30 22:04:32,193][train][INFO] - Epoch 13/100, Val Acc=0.6641, Val Loss=1.5862, lr=0.0100
[2025-04-30 22:04:40,671][train][INFO] - Epoch 14/100, Val Acc=0.6617, Val Loss=1.5857, lr=0.0100
[2025-04-30 22:04:48,542][train][INFO] - Epoch 15/100, Val Acc=0.6675, Val Loss=1.5226, lr=0.0100
[2025-04-30 22:04:56,505][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=1.5976, lr=0.0001
[2025-04-30 22:04:56,516][meta_train][INFO] - epoch_15 saved !
[2025-04-30 22:04:56,669][train][INFO] - Epoch 16/100, Val Acc=0.6681, Val Loss=1.5377, lr=0.0100
[2025-04-30 22:05:05,238][train][INFO] - Epoch 17/100, Val Acc=0.6687, Val Loss=1.5164, lr=0.0100
[2025-04-30 22:05:13,407][train][INFO] - Epoch 18/100, Val Acc=0.6638, Val Loss=1.6137, lr=0.0100
[2025-04-30 22:05:21,581][train][INFO] - Epoch 19/100, Val Acc=0.6579, Val Loss=1.6279, lr=0.0100
[2025-04-30 22:05:29,692][train][INFO] - Epoch 20/100, Val Acc=0.6718, Val Loss=1.5851, lr=0.0100
[2025-04-30 22:05:35,356][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=2.3653, lr=0.0001
[2025-04-30 22:05:38,720][train][INFO] - Epoch 21/100, Val Acc=0.6696, Val Loss=1.5603, lr=0.0100
[2025-04-30 22:05:46,746][train][INFO] - Epoch 22/100, Val Acc=0.6536, Val Loss=1.6013, lr=0.0100
[2025-04-30 22:05:53,936][train][INFO] - Epoch 23/100, Val Acc=0.6776, Val Loss=1.5387, lr=0.0100
[2025-04-30 22:06:02,212][train][INFO] - Epoch 24/100, Val Acc=0.6608, Val Loss=1.5980, lr=0.0100
[2025-04-30 22:06:10,326][train][INFO] - Epoch 25/100, Val Acc=0.6729, Val Loss=1.5540, lr=0.0100
[2025-04-30 22:06:15,195][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=1.5878, lr=0.0001
[2025-04-30 22:06:18,976][train][INFO] - Epoch 26/100, Val Acc=0.6605, Val Loss=1.6308, lr=0.0100
[2025-04-30 22:06:27,443][train][INFO] - Epoch 27/100, Val Acc=0.6864, Val Loss=1.4884, lr=0.0100
[2025-04-30 22:06:35,850][train][INFO] - Epoch 28/100, Val Acc=0.6545, Val Loss=1.6285, lr=0.0100
[2025-04-30 22:06:43,660][train][INFO] - Epoch 29/100, Val Acc=0.6636, Val Loss=1.5949, lr=0.0100
[2025-04-30 22:06:51,622][train][INFO] - Epoch 30/100, Val Acc=0.6632, Val Loss=1.6235, lr=0.0100
[2025-04-30 22:06:54,454][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=2.0145, lr=0.0001
[2025-04-30 22:06:59,393][train][INFO] - Epoch 31/100, Val Acc=0.6698, Val Loss=1.5338, lr=0.0100
[2025-04-30 22:07:07,515][train][INFO] - Epoch 32/100, Val Acc=0.6559, Val Loss=1.6391, lr=0.0100
[2025-04-30 22:07:16,021][train][INFO] - Epoch 33/100, Val Acc=0.6751, Val Loss=1.5349, lr=0.0100
[2025-04-30 22:07:24,335][train][INFO] - Epoch 34/100, Val Acc=0.6788, Val Loss=1.5122, lr=0.0100
[2025-04-30 22:07:32,257][train][INFO] - Epoch 35/100, Val Acc=0.6702, Val Loss=1.5731, lr=0.0100
[2025-04-30 22:07:33,985][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=1.6378, lr=0.0001
[2025-04-30 22:07:40,524][train][INFO] - Epoch 36/100, Val Acc=0.6634, Val Loss=1.6012, lr=0.0100
[2025-04-30 22:07:48,680][train][INFO] - Epoch 37/100, Val Acc=0.6648, Val Loss=1.6184, lr=0.0100
[2025-04-30 22:07:56,843][train][INFO] - Epoch 38/100, Val Acc=0.6628, Val Loss=1.6328, lr=0.0100
[2025-04-30 22:08:05,034][train][INFO] - Epoch 39/100, Val Acc=0.6668, Val Loss=1.6058, lr=0.0100
[2025-04-30 22:08:11,744][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=1.9337, lr=0.0001
[2025-04-30 22:08:13,018][train][INFO] - Epoch 40/100, Val Acc=0.6745, Val Loss=1.5423, lr=0.0100
[2025-04-30 22:08:21,360][train][INFO] - Epoch 41/100, Val Acc=0.6711, Val Loss=1.5339, lr=0.0100
[2025-04-30 22:08:29,790][train][INFO] - Epoch 42/100, Val Acc=0.6663, Val Loss=1.6022, lr=0.0100
[2025-04-30 22:08:38,129][train][INFO] - Epoch 43/100, Val Acc=0.6762, Val Loss=1.5198, lr=0.0100
[2025-04-30 22:08:46,649][train][INFO] - Epoch 44/100, Val Acc=0.6648, Val Loss=1.6261, lr=0.0100
[2025-04-30 22:08:51,330][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=2.6882, lr=0.0001
[2025-04-30 22:08:55,037][train][INFO] - Epoch 45/100, Val Acc=0.6786, Val Loss=1.5580, lr=0.0100
[2025-04-30 22:09:03,810][train][INFO] - Epoch 46/100, Val Acc=0.6708, Val Loss=1.6132, lr=0.0100
[2025-04-30 22:09:11,929][train][INFO] - Epoch 47/100, Val Acc=0.6725, Val Loss=1.5791, lr=0.0100
[2025-04-30 22:09:20,252][train][INFO] - Epoch 48/100, Val Acc=0.6655, Val Loss=1.6137, lr=0.0100
[2025-04-30 22:09:28,259][train][INFO] - Epoch 49/100, Val Acc=0.6688, Val Loss=1.5985, lr=0.0100
[2025-04-30 22:09:30,674][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=2.0494, lr=0.0001
[2025-04-30 22:09:36,432][train][INFO] - Epoch 50/100, Val Acc=0.6624, Val Loss=1.6367, lr=0.0100
[2025-04-30 22:09:44,854][train][INFO] - Epoch 51/100, Val Acc=0.6722, Val Loss=1.5688, lr=0.0100
[2025-04-30 22:09:53,004][train][INFO] - Epoch 52/100, Val Acc=0.6678, Val Loss=1.5832, lr=0.0100
[2025-04-30 22:10:00,985][train][INFO] - Epoch 53/100, Val Acc=0.6641, Val Loss=1.6481, lr=0.0100
[2025-04-30 22:10:09,183][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=2.4689, lr=0.0001
[2025-04-30 22:10:09,199][meta_train][INFO] - epoch_16 saved !
[2025-04-30 22:10:09,424][train][INFO] - Epoch 54/100, Val Acc=0.6710, Val Loss=1.5373, lr=0.0100
[2025-04-30 22:10:17,588][train][INFO] - Epoch 55/100, Val Acc=0.6697, Val Loss=1.5626, lr=0.0100
[2025-04-30 22:10:25,029][train][INFO] - Epoch 56/100, Val Acc=0.6716, Val Loss=1.5836, lr=0.0100
[2025-04-30 22:10:33,252][train][INFO] - Epoch 57/100, Val Acc=0.6701, Val Loss=1.6161, lr=0.0100
[2025-04-30 22:10:41,536][train][INFO] - Epoch 58/100, Val Acc=0.6714, Val Loss=1.5685, lr=0.0100
[2025-04-30 22:10:48,127][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=2.4643, lr=0.0001
[2025-04-30 22:10:49,809][train][INFO] - Epoch 59/100, Val Acc=0.6636, Val Loss=1.6183, lr=0.0100
[2025-04-30 22:10:58,542][train][INFO] - Epoch 60/100, Val Acc=0.6739, Val Loss=1.5401, lr=0.0100
[2025-04-30 22:11:07,531][train][INFO] - Epoch 61/100, Val Acc=0.7227, Val Loss=1.3092, lr=0.0010
[2025-04-30 22:11:15,328][train][INFO] - Epoch 62/100, Val Acc=0.7267, Val Loss=1.3079, lr=0.0010
[2025-04-30 22:11:23,901][train][INFO] - Epoch 63/100, Val Acc=0.7278, Val Loss=1.3145, lr=0.0010
[2025-04-30 22:11:26,610][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=2.7424, lr=0.0001
[2025-04-30 22:11:32,078][train][INFO] - Epoch 64/100, Val Acc=0.7286, Val Loss=1.3243, lr=0.0010
[2025-04-30 22:11:40,315][train][INFO] - Epoch 65/100, Val Acc=0.7293, Val Loss=1.3179, lr=0.0010
[2025-04-30 22:11:48,122][train][INFO] - Epoch 66/100, Val Acc=0.7310, Val Loss=1.3229, lr=0.0010
[2025-04-30 22:11:56,042][train][INFO] - Epoch 67/100, Val Acc=0.7324, Val Loss=1.3254, lr=0.0010
[2025-04-30 22:12:04,422][train][INFO] - Epoch 68/100, Val Acc=0.7332, Val Loss=1.3246, lr=0.0010
[2025-04-30 22:12:05,331][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=2.5212, lr=0.0001
[2025-04-30 22:12:12,618][train][INFO] - Epoch 69/100, Val Acc=0.7305, Val Loss=1.3291, lr=0.0010
[2025-04-30 22:12:21,116][train][INFO] - Epoch 70/100, Val Acc=0.7291, Val Loss=1.3385, lr=0.0010
[2025-04-30 22:12:29,416][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.3379, lr=0.0010
[2025-04-30 22:12:37,827][train][INFO] - Epoch 72/100, Val Acc=0.7330, Val Loss=1.3368, lr=0.0010
[2025-04-30 22:12:43,037][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=2.0430, lr=0.0001
[2025-04-30 22:12:46,230][train][INFO] - Epoch 73/100, Val Acc=0.7341, Val Loss=1.3314, lr=0.0010
[2025-04-30 22:12:54,894][train][INFO] - Epoch 74/100, Val Acc=0.7358, Val Loss=1.3293, lr=0.0010
[2025-04-30 22:13:03,091][train][INFO] - Epoch 75/100, Val Acc=0.7350, Val Loss=1.3311, lr=0.0010
[2025-04-30 22:13:11,515][train][INFO] - Epoch 76/100, Val Acc=0.7347, Val Loss=1.3243, lr=0.0010
[2025-04-30 22:13:19,728][train][INFO] - Epoch 77/100, Val Acc=0.7366, Val Loss=1.3282, lr=0.0010
[2025-04-30 22:13:22,982][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=2.1434, lr=0.0001
[2025-04-30 22:13:28,567][train][INFO] - Epoch 78/100, Val Acc=0.7362, Val Loss=1.3274, lr=0.0010
[2025-04-30 22:13:36,836][train][INFO] - Epoch 79/100, Val Acc=0.7360, Val Loss=1.3253, lr=0.0010
[2025-04-30 22:13:44,873][train][INFO] - Epoch 80/100, Val Acc=0.7382, Val Loss=1.3298, lr=0.0010
[2025-04-30 22:13:52,753][train][INFO] - Epoch 81/100, Val Acc=0.7379, Val Loss=1.3310, lr=0.0010
[2025-04-30 22:14:00,655][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=1.7180, lr=0.0001
[2025-04-30 22:14:00,732][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3310, lr=0.0010
[2025-04-30 22:14:09,015][train][INFO] - Epoch 83/100, Val Acc=0.7372, Val Loss=1.3320, lr=0.0010
[2025-04-30 22:14:17,637][train][INFO] - Epoch 84/100, Val Acc=0.7363, Val Loss=1.3307, lr=0.0010
[2025-04-30 22:14:25,878][train][INFO] - Epoch 85/100, Val Acc=0.7379, Val Loss=1.3311, lr=0.0010
[2025-04-30 22:14:32,703][train][INFO] - Epoch 86/100, Val Acc=0.7350, Val Loss=1.3324, lr=0.0010
[2025-04-30 22:14:40,878][train][INFO] - Epoch 87/100, Val Acc=0.7367, Val Loss=1.3295, lr=0.0010
[2025-04-30 22:14:40,950][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=2.1884, lr=0.0001
[2025-04-30 22:14:49,506][train][INFO] - Epoch 88/100, Val Acc=0.7371, Val Loss=1.3363, lr=0.0010
[2025-04-30 22:14:57,924][train][INFO] - Epoch 89/100, Val Acc=0.7389, Val Loss=1.3295, lr=0.0010
[2025-04-30 22:15:05,718][train][INFO] - Epoch 90/100, Val Acc=0.7389, Val Loss=1.3375, lr=0.0010
[2025-04-30 22:15:13,887][train][INFO] - Epoch 91/100, Val Acc=0.7395, Val Loss=1.3301, lr=0.0001
[2025-04-30 22:15:18,894][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=1.7648, lr=0.0001
[2025-04-30 22:15:18,914][meta_train][INFO] - epoch_17 saved !
[2025-04-30 22:15:22,203][train][INFO] - Epoch 92/100, Val Acc=0.7367, Val Loss=1.3357, lr=0.0001
[2025-04-30 22:15:30,651][train][INFO] - Epoch 93/100, Val Acc=0.7368, Val Loss=1.3348, lr=0.0001
[2025-04-30 22:15:38,852][train][INFO] - Epoch 94/100, Val Acc=0.7389, Val Loss=1.3268, lr=0.0001
[2025-04-30 22:15:47,473][train][INFO] - Epoch 95/100, Val Acc=0.7395, Val Loss=1.3379, lr=0.0001
[2025-04-30 22:15:55,655][train][INFO] - Epoch 96/100, Val Acc=0.7397, Val Loss=1.3308, lr=0.0001
[2025-04-30 22:15:58,639][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=1.7716, lr=0.0001
[2025-04-30 22:16:04,185][train][INFO] - Epoch 97/100, Val Acc=0.7399, Val Loss=1.3239, lr=0.0001
[2025-04-30 22:16:12,484][train][INFO] - Epoch 98/100, Val Acc=0.7407, Val Loss=1.3273, lr=0.0001
[2025-04-30 22:16:20,723][train][INFO] - Epoch 99/100, Val Acc=0.7391, Val Loss=1.3273, lr=0.0001
[2025-04-30 22:16:29,073][train][INFO] - Epoch 100/100, Val Acc=0.7392, Val Loss=1.3307, lr=0.0001
[2025-04-30 22:16:34,024][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7407
[2025-04-30 22:16:34,031][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 22:16:36,528][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=2.8563, lr=0.0001
[2025-04-30 22:17:16,988][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=1.7618, lr=0.0001
[2025-04-30 22:17:57,976][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=2.6194, lr=0.0001
[2025-04-30 22:18:24,048][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 22:18:37,570][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=2.2657, lr=0.0001
[2025-04-30 22:19:17,937][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=2.6861, lr=0.0001
[2025-04-30 22:19:57,125][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=2.2899, lr=0.0001
[2025-04-30 22:20:14,387][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 22:20:14,828][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 22:20:37,085][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=2.2280, lr=0.0001
[2025-04-30 22:20:37,107][meta_train][INFO] - epoch_18 saved !
[2025-04-30 22:21:15,213][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=1.8825, lr=0.0001
[2025-04-30 22:21:52,331][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=2.7307, lr=0.0001
[2025-04-30 22:22:30,460][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=2.2762, lr=0.0001
[2025-04-30 22:23:07,891][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=2.7910, lr=0.0001
[2025-04-30 22:23:46,104][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=3.0247, lr=0.0001
[2025-04-30 22:24:25,312][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=2.4246, lr=0.0001
[2025-04-30 22:25:03,402][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=1.9552, lr=0.0001
[2025-04-30 22:25:40,485][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=2.4476, lr=0.0001
[2025-04-30 22:25:40,507][meta_train][INFO] - epoch_19 saved !
[2025-04-30 22:26:19,514][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=2.4873, lr=0.0001
[2025-04-30 22:26:57,828][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=2.4835, lr=0.0001
[2025-04-30 22:27:36,199][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=2.8882, lr=0.0001
[2025-04-30 22:28:13,999][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=2.0693, lr=0.0001
[2025-04-30 22:28:52,093][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=2.9491, lr=0.0001
[2025-04-30 22:29:30,153][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=3.1687, lr=0.0001
[2025-04-30 22:30:07,358][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=2.4978, lr=0.0001
[2025-04-30 22:30:46,052][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=2.1164, lr=0.0001
[2025-04-30 22:30:46,061][meta_train][INFO] - epoch_20 saved !
[2025-04-30 22:31:24,361][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=2.5395, lr=0.0001
[2025-04-30 22:32:02,790][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=2.1780, lr=0.0001
[2025-04-30 22:32:40,900][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=2.6431, lr=0.0001
[2025-04-30 22:33:19,957][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=3.2618, lr=0.0001
[2025-04-30 22:33:58,168][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=2.7016, lr=0.0001
[2025-04-30 22:34:35,440][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=3.1042, lr=0.0001
[2025-04-30 22:35:13,838][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=3.1024, lr=0.0001
[2025-04-30 22:35:51,907][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=2.2857, lr=0.0001
[2025-04-30 22:35:51,927][meta_train][INFO] - epoch_21 saved !
[2025-04-30 22:36:30,085][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=2.3220, lr=0.0001
[2025-04-30 22:37:07,387][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=2.8192, lr=0.0001
[2025-04-30 22:37:46,167][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=3.2101, lr=0.0001
[2025-04-30 22:38:24,405][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=3.4140, lr=0.0001
[2025-04-30 22:39:02,326][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=3.2548, lr=0.0001
[2025-04-30 22:39:39,678][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=2.8175, lr=0.0001
[2025-04-30 22:40:18,379][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=2.4889, lr=0.0001
[2025-04-30 22:40:55,586][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=2.9409, lr=0.0001
[2025-04-30 22:40:55,602][meta_train][INFO] - epoch_22 saved !
[2025-04-30 22:41:34,982][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=3.4725, lr=0.0001
[2025-04-30 22:42:16,169][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=2.9359, lr=0.0001
[2025-04-30 22:42:54,279][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=2.9694, lr=0.0001
[2025-04-30 22:43:35,730][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=2.5253, lr=0.0001
[2025-04-30 22:44:29,962][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=3.3628, lr=0.0001
[2025-04-30 22:45:15,305][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=2.6055, lr=0.0001
[2025-04-30 22:46:07,525][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=3.4058, lr=0.0001
[2025-04-30 22:46:57,644][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=2.9970, lr=0.0001
[2025-04-30 22:46:57,660][meta_train][INFO] - epoch_23 saved !
[2025-04-30 22:47:48,509][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=3.4652, lr=0.0001
[2025-04-30 22:48:36,432][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=3.4724, lr=0.0001
[2025-04-30 22:49:26,988][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=2.7609, lr=0.0001
[2025-04-30 22:50:14,803][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=3.2147, lr=0.0001
[2025-04-30 22:51:03,163][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=2.8377, lr=0.0001
[2025-04-30 22:51:52,159][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=3.6869, lr=0.0001
[2025-04-30 22:52:29,258][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=3.1436, lr=0.0001
[2025-04-30 22:53:06,716][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=3.2462, lr=0.0001
[2025-04-30 22:53:06,726][meta_train][INFO] - epoch_24 saved !
[2025-04-30 22:53:45,043][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=3.5965, lr=0.0001
[2025-04-30 22:54:22,615][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=3.2714, lr=0.0001
[2025-04-30 22:54:59,080][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=3.1992, lr=0.0001
[2025-04-30 22:55:35,478][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=2.9410, lr=0.0001
[2025-04-30 22:56:12,269][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=3.6366, lr=0.0001
[2025-04-30 22:56:49,996][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=2.9746, lr=0.0001
[2025-04-30 22:57:27,496][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=3.8057, lr=0.0001
[2025-04-30 22:58:05,854][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=3.4355, lr=0.0001
[2025-04-30 22:58:05,877][meta_train][INFO] - epoch_25 saved !
[2025-04-30 22:58:44,319][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=3.7285, lr=0.0001
[2025-04-30 22:59:21,668][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=3.1273, lr=0.0001
[2025-04-30 23:00:00,275][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=3.4031, lr=0.0001
[2025-04-30 23:00:37,125][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=3.8494, lr=0.0001
[2025-04-30 23:01:15,926][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=3.2325, lr=0.0001
[2025-04-30 23:01:54,316][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=3.5505, lr=0.0001
[2025-04-30 23:02:32,699][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=3.5776, lr=0.0001
[2025-04-30 23:03:10,384][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=3.9364, lr=0.0001
[2025-04-30 23:03:10,400][meta_train][INFO] - epoch_26 saved !
[2025-04-30 23:03:49,050][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=3.9460, lr=0.0001
[2025-04-30 23:04:27,375][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=3.2748, lr=0.0001
[2025-04-30 23:05:05,882][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=3.3227, lr=0.0001
[2025-04-30 23:05:43,468][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=3.5453, lr=0.0001
[2025-04-30 23:06:22,412][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=3.9068, lr=0.0001
[2025-04-30 23:06:59,716][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=3.6812, lr=0.0001
[2025-04-30 23:07:38,040][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=3.7242, lr=0.0001
[2025-04-30 23:08:15,856][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.0258, lr=0.0001
[2025-04-30 23:08:15,879][meta_train][INFO] - epoch_27 saved !
[2025-04-30 23:08:54,293][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=3.4669, lr=0.0001
[2025-04-30 23:09:33,583][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=3.7732, lr=0.0001
[2025-04-30 23:10:11,039][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=3.6940, lr=0.0001
[2025-04-30 23:10:49,380][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=3.5662, lr=0.0001
[2025-04-30 23:11:28,048][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.1075, lr=0.0001
[2025-04-30 23:12:07,221][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.1159, lr=0.0001
[2025-04-30 23:12:45,511][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=3.8624, lr=0.0001
[2025-04-30 23:13:23,667][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.0638, lr=0.0001
[2025-04-30 23:13:23,691][meta_train][INFO] - epoch_28 saved !
[2025-04-30 23:14:02,518][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=3.6415, lr=0.0001
[2025-04-30 23:14:40,924][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.1533, lr=0.0001
[2025-04-30 23:15:19,606][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=3.8007, lr=0.0001
[2025-04-30 23:15:56,898][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=3.6793, lr=0.0001
[2025-04-30 23:16:35,428][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=3.9283, lr=0.0001
[2025-04-30 23:17:14,065][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.1416, lr=0.0001
[2025-04-30 23:17:52,044][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=3.9909, lr=0.0001
[2025-04-30 23:18:30,779][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.2568, lr=0.0001
[2025-04-30 23:18:30,789][meta_train][INFO] - epoch_29 saved !
[2025-04-30 23:19:08,566][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=3.7948, lr=0.0001
[2025-04-30 23:19:45,619][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.1981, lr=0.0001
[2025-04-30 23:20:24,689][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.0359, lr=0.0001
[2025-04-30 23:21:03,659][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.3137, lr=0.0001
[2025-04-30 23:21:41,514][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.0880, lr=0.0001
[2025-04-30 23:22:20,473][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=3.9788, lr=0.0001
[2025-04-30 23:22:58,774][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.2864, lr=0.0001
[2025-04-30 23:23:36,951][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=3.9346, lr=0.0001
[2025-04-30 23:23:36,969][meta_train][INFO] - epoch_30 saved !
[2025-04-30 23:24:14,719][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.3010, lr=0.0001
[2025-04-30 23:24:52,143][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=3.9416, lr=0.0001
[2025-04-30 23:25:31,381][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.1287, lr=0.0001
[2025-04-30 23:26:10,106][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.1747, lr=0.0001
[2025-04-30 23:26:48,317][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.0268, lr=0.0001
[2025-04-30 23:27:25,024][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.3216, lr=0.0001
[2025-04-30 23:28:04,366][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.4365, lr=0.0001
[2025-04-30 23:28:42,287][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.1171, lr=0.0001
[2025-04-30 23:28:42,296][meta_train][INFO] - epoch_31 saved !
[2025-04-30 23:29:19,226][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.3549, lr=0.0001
[2025-04-30 23:29:58,104][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.1398, lr=0.0001
[2025-04-30 23:30:35,369][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.2317, lr=0.0001
[2025-04-30 23:31:13,147][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.1307, lr=0.0001
[2025-04-30 23:31:51,744][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.3926, lr=0.0001
[2025-04-30 23:32:30,527][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.4859, lr=0.0001
[2025-04-30 23:33:09,251][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.2898, lr=0.0001
[2025-04-30 23:33:46,261][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.1506, lr=0.0001
[2025-04-30 23:33:46,272][meta_train][INFO] - epoch_32 saved !
[2025-04-30 23:34:25,948][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.4216, lr=0.0001
[2025-04-30 23:35:04,045][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.1868, lr=0.0001
[2025-04-30 23:35:04,652][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-04-30 23:35:04,708][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 23:35:04,709][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 23:35:04,709][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 23:35:34,555][train][INFO] - Before training : Train Acc=0.0823  Val Acc=0.1024
[2025-04-30 23:35:40,955][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.2408, lr=0.0001
[2025-04-30 23:35:43,435][train][INFO] - Epoch 1/100, Val Acc=0.6393, Val Loss=1.6485, lr=0.0100
[2025-04-30 23:35:51,963][train][INFO] - Epoch 2/100, Val Acc=0.6660, Val Loss=1.5031, lr=0.0100
[2025-04-30 23:36:00,645][train][INFO] - Epoch 3/100, Val Acc=0.6429, Val Loss=1.6330, lr=0.0100
[2025-04-30 23:36:08,905][train][INFO] - Epoch 4/100, Val Acc=0.6486, Val Loss=1.5639, lr=0.0100
[2025-04-30 23:36:17,417][train][INFO] - Epoch 5/100, Val Acc=0.6698, Val Loss=1.5003, lr=0.0100
[2025-04-30 23:36:21,262][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.3604, lr=0.0001
[2025-04-30 23:36:26,093][train][INFO] - Epoch 6/100, Val Acc=0.6536, Val Loss=1.6034, lr=0.0100
[2025-04-30 23:36:34,121][train][INFO] - Epoch 7/100, Val Acc=0.6633, Val Loss=1.5361, lr=0.0100
[2025-04-30 23:36:42,675][train][INFO] - Epoch 8/100, Val Acc=0.6600, Val Loss=1.5739, lr=0.0100
[2025-04-30 23:36:51,309][train][INFO] - Epoch 9/100, Val Acc=0.6602, Val Loss=1.5547, lr=0.0100
[2025-04-30 23:36:59,947][train][INFO] - Epoch 10/100, Val Acc=0.6613, Val Loss=1.6054, lr=0.0100
[2025-04-30 23:37:00,449][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.2656, lr=0.0001
[2025-04-30 23:37:08,728][train][INFO] - Epoch 11/100, Val Acc=0.6649, Val Loss=1.5351, lr=0.0100
[2025-04-30 23:37:17,390][train][INFO] - Epoch 12/100, Val Acc=0.6765, Val Loss=1.4966, lr=0.0100
[2025-04-30 23:37:25,917][train][INFO] - Epoch 13/100, Val Acc=0.6618, Val Loss=1.5822, lr=0.0100
[2025-04-30 23:37:34,413][train][INFO] - Epoch 14/100, Val Acc=0.6711, Val Loss=1.5424, lr=0.0100
[2025-04-30 23:37:39,451][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.3472, lr=0.0001
[2025-04-30 23:37:42,923][train][INFO] - Epoch 15/100, Val Acc=0.6690, Val Loss=1.5437, lr=0.0100
[2025-04-30 23:37:51,342][train][INFO] - Epoch 16/100, Val Acc=0.6627, Val Loss=1.5561, lr=0.0100
[2025-04-30 23:38:00,105][train][INFO] - Epoch 17/100, Val Acc=0.6606, Val Loss=1.5748, lr=0.0100
[2025-04-30 23:38:08,727][train][INFO] - Epoch 18/100, Val Acc=0.6656, Val Loss=1.5425, lr=0.0100
[2025-04-30 23:38:17,258][train][INFO] - Epoch 19/100, Val Acc=0.6691, Val Loss=1.5909, lr=0.0100
[2025-04-30 23:38:19,083][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.5783, lr=0.0001
[2025-04-30 23:38:25,809][train][INFO] - Epoch 20/100, Val Acc=0.6593, Val Loss=1.6105, lr=0.0100
[2025-04-30 23:38:34,419][train][INFO] - Epoch 21/100, Val Acc=0.6688, Val Loss=1.5416, lr=0.0100
[2025-04-30 23:38:43,203][train][INFO] - Epoch 22/100, Val Acc=0.6676, Val Loss=1.5996, lr=0.0100
[2025-04-30 23:38:51,347][train][INFO] - Epoch 23/100, Val Acc=0.6737, Val Loss=1.5107, lr=0.0100
[2025-04-30 23:38:59,224][train][INFO] - Epoch 24/100, Val Acc=0.6529, Val Loss=1.6573, lr=0.0100
[2025-04-30 23:38:59,470][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.4728, lr=0.0001
[2025-04-30 23:38:59,496][meta_train][INFO] - epoch_33 saved !
[2025-04-30 23:39:08,136][train][INFO] - Epoch 25/100, Val Acc=0.6776, Val Loss=1.4988, lr=0.0100
[2025-04-30 23:39:16,617][train][INFO] - Epoch 26/100, Val Acc=0.6709, Val Loss=1.5611, lr=0.0100
[2025-04-30 23:39:25,135][train][INFO] - Epoch 27/100, Val Acc=0.6771, Val Loss=1.5595, lr=0.0100
[2025-04-30 23:39:33,293][train][INFO] - Epoch 28/100, Val Acc=0.6593, Val Loss=1.6294, lr=0.0100
[2025-04-30 23:39:37,164][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.4793, lr=0.0001
[2025-04-30 23:39:41,450][train][INFO] - Epoch 29/100, Val Acc=0.6534, Val Loss=1.6516, lr=0.0100
[2025-04-30 23:39:50,128][train][INFO] - Epoch 30/100, Val Acc=0.6621, Val Loss=1.5928, lr=0.0100
[2025-04-30 23:39:58,594][train][INFO] - Epoch 31/100, Val Acc=0.6681, Val Loss=1.5518, lr=0.0100
[2025-04-30 23:40:06,997][train][INFO] - Epoch 32/100, Val Acc=0.6671, Val Loss=1.5866, lr=0.0100
[2025-04-30 23:40:15,256][train][INFO] - Epoch 33/100, Val Acc=0.6650, Val Loss=1.6231, lr=0.0100
[2025-04-30 23:40:17,194][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.3791, lr=0.0001
[2025-04-30 23:40:23,698][train][INFO] - Epoch 34/100, Val Acc=0.6686, Val Loss=1.5952, lr=0.0100
[2025-04-30 23:40:32,414][train][INFO] - Epoch 35/100, Val Acc=0.6693, Val Loss=1.5967, lr=0.0100
[2025-04-30 23:40:41,069][train][INFO] - Epoch 36/100, Val Acc=0.6805, Val Loss=1.4842, lr=0.0100
[2025-04-30 23:40:49,429][train][INFO] - Epoch 37/100, Val Acc=0.6663, Val Loss=1.5695, lr=0.0100
[2025-04-30 23:40:57,756][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6060, lr=0.0001
[2025-04-30 23:40:58,078][train][INFO] - Epoch 38/100, Val Acc=0.6701, Val Loss=1.5643, lr=0.0100
[2025-04-30 23:41:06,958][train][INFO] - Epoch 39/100, Val Acc=0.6735, Val Loss=1.5848, lr=0.0100
[2025-04-30 23:41:15,891][train][INFO] - Epoch 40/100, Val Acc=0.6643, Val Loss=1.6089, lr=0.0100
[2025-04-30 23:41:24,458][train][INFO] - Epoch 41/100, Val Acc=0.6748, Val Loss=1.5248, lr=0.0100
[2025-04-30 23:41:32,932][train][INFO] - Epoch 42/100, Val Acc=0.6651, Val Loss=1.5883, lr=0.0100
[2025-04-30 23:41:37,045][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.3085, lr=0.0001
[2025-04-30 23:41:41,246][train][INFO] - Epoch 43/100, Val Acc=0.6799, Val Loss=1.5055, lr=0.0100
[2025-04-30 23:41:49,820][train][INFO] - Epoch 44/100, Val Acc=0.6703, Val Loss=1.5899, lr=0.0100
[2025-04-30 23:41:58,488][train][INFO] - Epoch 45/100, Val Acc=0.6608, Val Loss=1.6389, lr=0.0100
[2025-04-30 23:42:07,155][train][INFO] - Epoch 46/100, Val Acc=0.6699, Val Loss=1.5693, lr=0.0100
[2025-04-30 23:42:15,482][train][INFO] - Epoch 47/100, Val Acc=0.6748, Val Loss=1.5289, lr=0.0100
[2025-04-30 23:42:16,957][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.4374, lr=0.0001
[2025-04-30 23:42:24,278][train][INFO] - Epoch 48/100, Val Acc=0.6660, Val Loss=1.5908, lr=0.0100
[2025-04-30 23:42:33,051][train][INFO] - Epoch 49/100, Val Acc=0.6575, Val Loss=1.6564, lr=0.0100
[2025-04-30 23:42:41,536][train][INFO] - Epoch 50/100, Val Acc=0.6758, Val Loss=1.5180, lr=0.0100
[2025-04-30 23:42:49,995][train][INFO] - Epoch 51/100, Val Acc=0.6624, Val Loss=1.5737, lr=0.0100
[2025-04-30 23:42:54,886][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.5081, lr=0.0001
[2025-04-30 23:42:58,689][train][INFO] - Epoch 52/100, Val Acc=0.6656, Val Loss=1.6134, lr=0.0100
[2025-04-30 23:43:06,988][train][INFO] - Epoch 53/100, Val Acc=0.6741, Val Loss=1.4904, lr=0.0100
[2025-04-30 23:43:15,093][train][INFO] - Epoch 54/100, Val Acc=0.6750, Val Loss=1.5413, lr=0.0100
[2025-04-30 23:43:23,726][train][INFO] - Epoch 55/100, Val Acc=0.6533, Val Loss=1.6686, lr=0.0100
[2025-04-30 23:43:32,006][train][INFO] - Epoch 56/100, Val Acc=0.6676, Val Loss=1.5528, lr=0.0100
[2025-04-30 23:43:34,636][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.3780, lr=0.0001
[2025-04-30 23:43:40,744][train][INFO] - Epoch 57/100, Val Acc=0.6774, Val Loss=1.5585, lr=0.0100
[2025-04-30 23:43:49,495][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.6712, lr=0.0100
[2025-04-30 23:43:58,188][train][INFO] - Epoch 59/100, Val Acc=0.6667, Val Loss=1.5614, lr=0.0100
[2025-04-30 23:44:06,650][train][INFO] - Epoch 60/100, Val Acc=0.6704, Val Loss=1.5336, lr=0.0100
[2025-04-30 23:44:14,963][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.3663, lr=0.0001
[2025-04-30 23:44:14,973][meta_train][INFO] - epoch_34 saved !
[2025-04-30 23:44:15,452][train][INFO] - Epoch 61/100, Val Acc=0.7235, Val Loss=1.3053, lr=0.0010
[2025-04-30 23:44:24,474][train][INFO] - Epoch 62/100, Val Acc=0.7294, Val Loss=1.2967, lr=0.0010
[2025-04-30 23:44:33,580][train][INFO] - Epoch 63/100, Val Acc=0.7274, Val Loss=1.3125, lr=0.0010
[2025-04-30 23:44:42,142][train][INFO] - Epoch 64/100, Val Acc=0.7312, Val Loss=1.3106, lr=0.0010
[2025-04-30 23:44:50,293][train][INFO] - Epoch 65/100, Val Acc=0.7329, Val Loss=1.3112, lr=0.0010
[2025-04-30 23:44:54,609][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.3910, lr=0.0001
[2025-04-30 23:44:58,981][train][INFO] - Epoch 66/100, Val Acc=0.7322, Val Loss=1.3199, lr=0.0010
[2025-04-30 23:45:07,218][train][INFO] - Epoch 67/100, Val Acc=0.7335, Val Loss=1.3187, lr=0.0010
[2025-04-30 23:45:16,083][train][INFO] - Epoch 68/100, Val Acc=0.7341, Val Loss=1.3142, lr=0.0010
[2025-04-30 23:45:24,537][train][INFO] - Epoch 69/100, Val Acc=0.7345, Val Loss=1.3194, lr=0.0010
[2025-04-30 23:45:32,862][train][INFO] - Epoch 70/100, Val Acc=0.7338, Val Loss=1.3270, lr=0.0010
[2025-04-30 23:45:33,442][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.3614, lr=0.0001
[2025-04-30 23:45:41,324][train][INFO] - Epoch 71/100, Val Acc=0.7336, Val Loss=1.3288, lr=0.0010
[2025-04-30 23:45:49,922][train][INFO] - Epoch 72/100, Val Acc=0.7344, Val Loss=1.3271, lr=0.0010
[2025-04-30 23:45:58,606][train][INFO] - Epoch 73/100, Val Acc=0.7347, Val Loss=1.3331, lr=0.0010
[2025-04-30 23:46:07,069][train][INFO] - Epoch 74/100, Val Acc=0.7349, Val Loss=1.3250, lr=0.0010
[2025-04-30 23:46:12,046][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.4429, lr=0.0001
[2025-04-30 23:46:15,818][train][INFO] - Epoch 75/100, Val Acc=0.7354, Val Loss=1.3294, lr=0.0010
[2025-04-30 23:46:24,552][train][INFO] - Epoch 76/100, Val Acc=0.7346, Val Loss=1.3300, lr=0.0010
[2025-04-30 23:46:33,226][train][INFO] - Epoch 77/100, Val Acc=0.7372, Val Loss=1.3302, lr=0.0010
[2025-04-30 23:46:41,616][train][INFO] - Epoch 78/100, Val Acc=0.7369, Val Loss=1.3269, lr=0.0010
[2025-04-30 23:46:50,217][train][INFO] - Epoch 79/100, Val Acc=0.7364, Val Loss=1.3322, lr=0.0010
[2025-04-30 23:46:51,900][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.3898, lr=0.0001
[2025-04-30 23:46:58,932][train][INFO] - Epoch 80/100, Val Acc=0.7354, Val Loss=1.3318, lr=0.0010
[2025-04-30 23:47:07,737][train][INFO] - Epoch 81/100, Val Acc=0.7362, Val Loss=1.3281, lr=0.0010
[2025-04-30 23:47:16,678][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3279, lr=0.0010
[2025-04-30 23:47:24,943][train][INFO] - Epoch 83/100, Val Acc=0.7371, Val Loss=1.3346, lr=0.0010
[2025-04-30 23:47:32,264][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.4891, lr=0.0001
[2025-04-30 23:47:33,637][train][INFO] - Epoch 84/100, Val Acc=0.7383, Val Loss=1.3314, lr=0.0010
[2025-04-30 23:47:41,976][train][INFO] - Epoch 85/100, Val Acc=0.7370, Val Loss=1.3230, lr=0.0010
[2025-04-30 23:47:50,690][train][INFO] - Epoch 86/100, Val Acc=0.7383, Val Loss=1.3289, lr=0.0010
[2025-04-30 23:47:59,326][train][INFO] - Epoch 87/100, Val Acc=0.7393, Val Loss=1.3263, lr=0.0010
[2025-04-30 23:48:07,100][train][INFO] - Epoch 88/100, Val Acc=0.7368, Val Loss=1.3251, lr=0.0010
[2025-04-30 23:48:10,619][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6686, lr=0.0001
[2025-04-30 23:48:15,986][train][INFO] - Epoch 89/100, Val Acc=0.7377, Val Loss=1.3287, lr=0.0010
[2025-04-30 23:48:24,550][train][INFO] - Epoch 90/100, Val Acc=0.7380, Val Loss=1.3265, lr=0.0010
[2025-04-30 23:48:33,180][train][INFO] - Epoch 91/100, Val Acc=0.7381, Val Loss=1.3257, lr=0.0001
[2025-04-30 23:48:41,537][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3253, lr=0.0001
[2025-04-30 23:48:49,069][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.5670, lr=0.0001
[2025-04-30 23:48:50,193][train][INFO] - Epoch 93/100, Val Acc=0.7390, Val Loss=1.3251, lr=0.0001
[2025-04-30 23:48:59,249][train][INFO] - Epoch 94/100, Val Acc=0.7366, Val Loss=1.3227, lr=0.0001
[2025-04-30 23:49:08,500][train][INFO] - Epoch 95/100, Val Acc=0.7398, Val Loss=1.3282, lr=0.0001
[2025-04-30 23:49:17,058][train][INFO] - Epoch 96/100, Val Acc=0.7383, Val Loss=1.3245, lr=0.0001
[2025-04-30 23:49:25,628][train][INFO] - Epoch 97/100, Val Acc=0.7380, Val Loss=1.3229, lr=0.0001
[2025-04-30 23:49:28,638][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.5588, lr=0.0001
[2025-04-30 23:49:28,648][meta_train][INFO] - epoch_35 saved !
[2025-04-30 23:49:34,610][train][INFO] - Epoch 98/100, Val Acc=0.7382, Val Loss=1.3214, lr=0.0001
[2025-04-30 23:49:42,652][train][INFO] - Epoch 99/100, Val Acc=0.7383, Val Loss=1.3248, lr=0.0001
[2025-04-30 23:49:51,462][train][INFO] - Epoch 100/100, Val Acc=0.7386, Val Loss=1.3244, lr=0.0001
[2025-04-30 23:49:56,697][train][INFO] - After training : Train Acc=0.9992  Val Acc=0.7398
[2025-04-30 23:49:56,703][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 23:50:08,394][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.5828, lr=0.0001
[2025-04-30 23:50:47,912][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.5046, lr=0.0001
[2025-04-30 23:51:28,955][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.4909, lr=0.0001
[2025-04-30 23:51:46,414][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 23:52:08,368][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.5767, lr=0.0001
[2025-04-30 23:52:49,110][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.7043, lr=0.0001
[2025-04-30 23:53:28,118][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.4725, lr=0.0001
[2025-04-30 23:53:37,192][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 23:53:37,647][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 23:54:08,148][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.5544, lr=0.0001
[2025-04-30 23:54:46,393][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.4764, lr=0.0001
[2025-04-30 23:54:46,403][meta_train][INFO] - epoch_36 saved !
[2025-04-30 23:55:25,149][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.5654, lr=0.0001
[2025-04-30 23:56:03,584][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6182, lr=0.0001
[2025-04-30 23:56:41,092][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.7257, lr=0.0001
[2025-04-30 23:57:18,870][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.5484, lr=0.0001
[2025-04-30 23:57:56,770][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.5109, lr=0.0001
[2025-04-30 23:58:33,866][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.5266, lr=0.0001
[2025-04-30 23:59:13,361][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6158, lr=0.0001
[2025-04-30 23:59:50,273][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.5735, lr=0.0001
[2025-04-30 23:59:50,284][meta_train][INFO] - epoch_37 saved !
[2025-05-01 00:00:28,200][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6213, lr=0.0001
[2025-05-01 00:01:05,717][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.5344, lr=0.0001
[2025-05-01 00:01:42,069][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6482, lr=0.0001
[2025-05-01 00:02:20,357][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6117, lr=0.0001
[2025-05-01 00:02:58,958][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.5621, lr=0.0001
[2025-05-01 00:03:36,509][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6002, lr=0.0001
[2025-05-01 00:04:13,577][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6008, lr=0.0001
[2025-05-01 00:04:51,385][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.7512, lr=0.0001
[2025-05-01 00:04:51,412][meta_train][INFO] - epoch_38 saved !
[2025-05-01 00:05:28,004][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6263, lr=0.0001
[2025-05-01 00:06:06,358][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.7526, lr=0.0001
[2025-05-01 00:06:43,132][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6466, lr=0.0001
[2025-05-01 00:07:20,630][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6173, lr=0.0001
[2025-05-01 00:07:58,512][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.5792, lr=0.0001
[2025-05-01 00:08:34,907][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6732, lr=0.0001
[2025-05-01 00:09:12,669][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6331, lr=0.0001
[2025-05-01 00:09:49,810][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6028, lr=0.0001
[2025-05-01 00:09:49,820][meta_train][INFO] - epoch_39 saved !
[2025-05-01 00:10:28,521][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.7549, lr=0.0001
[2025-05-01 00:11:04,732][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6072, lr=0.0001
[2025-05-01 00:11:43,238][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6323, lr=0.0001
[2025-05-01 00:12:20,593][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6588, lr=0.0001
[2025-05-01 00:12:56,614][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6826, lr=0.0001
[2025-05-01 00:13:34,638][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6508, lr=0.0001
[2025-05-01 00:14:12,007][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6030, lr=0.0001
[2025-05-01 00:14:49,691][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6497, lr=0.0001
[2025-05-01 00:14:49,714][meta_train][INFO] - epoch_40 saved !
[2025-05-01 00:15:26,048][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6060, lr=0.0001
[2025-05-01 00:16:04,623][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6512, lr=0.0001
[2025-05-01 00:16:41,623][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6638, lr=0.0001
[2025-05-01 00:17:19,391][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.7491, lr=0.0001
[2025-05-01 00:17:57,005][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6630, lr=0.0001
[2025-05-01 00:18:34,452][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6483, lr=0.0001
[2025-05-01 00:19:11,207][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6357, lr=0.0001
[2025-05-01 00:19:48,420][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6873, lr=0.0001
[2025-05-01 00:19:48,430][meta_train][INFO] - epoch_41 saved !
[2025-05-01 00:20:26,386][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6504, lr=0.0001
[2025-05-01 00:21:03,971][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6394, lr=0.0001
[2025-05-01 00:21:40,573][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6660, lr=0.0001
[2025-05-01 00:22:18,916][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6213, lr=0.0001
[2025-05-01 00:22:57,331][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6538, lr=0.0001
[2025-05-01 00:23:34,822][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6880, lr=0.0001
[2025-05-01 00:24:12,879][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6725, lr=0.0001
[2025-05-01 00:24:51,002][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.7367, lr=0.0001
[2025-05-01 00:24:51,012][meta_train][INFO] - epoch_42 saved !
[2025-05-01 00:25:30,176][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6451, lr=0.0001
[2025-05-01 00:26:08,317][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6745, lr=0.0001
[2025-05-01 00:26:45,443][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6871, lr=0.0001
[2025-05-01 00:27:24,236][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6532, lr=0.0001
[2025-05-01 00:28:02,632][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.7272, lr=0.0001
[2025-05-01 00:28:40,000][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6636, lr=0.0001
[2025-05-01 00:29:18,510][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6276, lr=0.0001
[2025-05-01 00:29:57,082][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6531, lr=0.0001
[2025-05-01 00:29:57,091][meta_train][INFO] - epoch_43 saved !
[2025-05-01 00:30:33,763][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6812, lr=0.0001
[2025-05-01 00:31:11,490][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6495, lr=0.0001
[2025-05-01 00:31:49,880][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6285, lr=0.0001
[2025-05-01 00:32:28,753][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6522, lr=0.0001
[2025-05-01 00:33:07,967][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6745, lr=0.0001
[2025-05-01 00:33:46,655][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6589, lr=0.0001
[2025-05-01 00:34:24,050][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.7113, lr=0.0001
[2025-05-01 00:35:03,342][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6480, lr=0.0001
[2025-05-01 00:35:03,367][meta_train][INFO] - epoch_44 saved !
[2025-05-01 00:35:22,338][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 00:35:41,032][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6466, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 00:35:51,955][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0101
[2025-05-01 00:35:59,845][train][INFO] - Epoch 1/100, Val Acc=0.6289, Val Loss=1.6286, lr=0.0100
[2025-05-01 00:36:08,578][train][INFO] - Epoch 2/100, Val Acc=0.6495, Val Loss=1.5944, lr=0.0100
[2025-05-01 00:36:17,177][train][INFO] - Epoch 3/100, Val Acc=0.6376, Val Loss=1.6359, lr=0.0100
[2025-05-01 00:36:20,407][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6477, lr=0.0001
[2025-05-01 00:36:25,697][train][INFO] - Epoch 4/100, Val Acc=0.6650, Val Loss=1.4642, lr=0.0100
[2025-05-01 00:36:33,309][train][INFO] - Epoch 5/100, Val Acc=0.6578, Val Loss=1.5247, lr=0.0100
[2025-05-01 00:36:41,581][train][INFO] - Epoch 6/100, Val Acc=0.6649, Val Loss=1.5132, lr=0.0100
[2025-05-01 00:36:49,573][train][INFO] - Epoch 7/100, Val Acc=0.6592, Val Loss=1.5374, lr=0.0100
[2025-05-01 00:36:58,004][train][INFO] - Epoch 8/100, Val Acc=0.6671, Val Loss=1.5194, lr=0.0100
[2025-05-01 00:36:59,103][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.7042, lr=0.0001
[2025-05-01 00:37:06,686][train][INFO] - Epoch 9/100, Val Acc=0.6675, Val Loss=1.5084, lr=0.0100
[2025-05-01 00:37:14,981][train][INFO] - Epoch 10/100, Val Acc=0.6685, Val Loss=1.5027, lr=0.0100
[2025-05-01 00:37:22,794][train][INFO] - Epoch 11/100, Val Acc=0.6653, Val Loss=1.5192, lr=0.0100
[2025-05-01 00:37:30,689][train][INFO] - Epoch 12/100, Val Acc=0.6700, Val Loss=1.5211, lr=0.0100
[2025-05-01 00:37:38,656][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6735, lr=0.0001
[2025-05-01 00:37:39,087][train][INFO] - Epoch 13/100, Val Acc=0.6504, Val Loss=1.6326, lr=0.0100
[2025-05-01 00:37:47,027][train][INFO] - Epoch 14/100, Val Acc=0.6686, Val Loss=1.5586, lr=0.0100
[2025-05-01 00:37:55,618][train][INFO] - Epoch 15/100, Val Acc=0.6579, Val Loss=1.6244, lr=0.0100
[2025-05-01 00:38:04,102][train][INFO] - Epoch 16/100, Val Acc=0.6580, Val Loss=1.5834, lr=0.0100
[2025-05-01 00:38:12,738][train][INFO] - Epoch 17/100, Val Acc=0.6664, Val Loss=1.5262, lr=0.0100
[2025-05-01 00:38:17,069][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6737, lr=0.0001
[2025-05-01 00:38:21,307][train][INFO] - Epoch 18/100, Val Acc=0.6717, Val Loss=1.5267, lr=0.0100
[2025-05-01 00:38:29,649][train][INFO] - Epoch 19/100, Val Acc=0.6673, Val Loss=1.6046, lr=0.0100
[2025-05-01 00:38:38,350][train][INFO] - Epoch 20/100, Val Acc=0.6713, Val Loss=1.5738, lr=0.0100
[2025-05-01 00:38:46,206][train][INFO] - Epoch 21/100, Val Acc=0.6680, Val Loss=1.5823, lr=0.0100
[2025-05-01 00:38:54,673][train][INFO] - Epoch 22/100, Val Acc=0.6665, Val Loss=1.5742, lr=0.0100
[2025-05-01 00:38:57,230][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6490, lr=0.0001
[2025-05-01 00:39:03,108][train][INFO] - Epoch 23/100, Val Acc=0.6585, Val Loss=1.5963, lr=0.0100
[2025-05-01 00:39:11,652][train][INFO] - Epoch 24/100, Val Acc=0.6781, Val Loss=1.5212, lr=0.0100
[2025-05-01 00:39:20,149][train][INFO] - Epoch 25/100, Val Acc=0.6672, Val Loss=1.5825, lr=0.0100
[2025-05-01 00:39:28,792][train][INFO] - Epoch 26/100, Val Acc=0.6723, Val Loss=1.5670, lr=0.0100
[2025-05-01 00:39:35,560][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6297, lr=0.0001
[2025-05-01 00:39:36,864][train][INFO] - Epoch 27/100, Val Acc=0.6663, Val Loss=1.6188, lr=0.0100
[2025-05-01 00:39:45,251][train][INFO] - Epoch 28/100, Val Acc=0.6782, Val Loss=1.5374, lr=0.0100
[2025-05-01 00:39:54,252][train][INFO] - Epoch 29/100, Val Acc=0.6689, Val Loss=1.5974, lr=0.0100
[2025-05-01 00:40:02,058][train][INFO] - Epoch 30/100, Val Acc=0.6762, Val Loss=1.5287, lr=0.0100
[2025-05-01 00:40:10,446][train][INFO] - Epoch 31/100, Val Acc=0.6749, Val Loss=1.5422, lr=0.0100
[2025-05-01 00:40:15,041][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6531, lr=0.0001
[2025-05-01 00:40:15,057][meta_train][INFO] - epoch_45 saved !
[2025-05-01 00:40:18,439][train][INFO] - Epoch 32/100, Val Acc=0.6632, Val Loss=1.6214, lr=0.0100
[2025-05-01 00:40:26,413][train][INFO] - Epoch 33/100, Val Acc=0.6664, Val Loss=1.6080, lr=0.0100
[2025-05-01 00:40:34,270][train][INFO] - Epoch 34/100, Val Acc=0.6803, Val Loss=1.5312, lr=0.0100
[2025-05-01 00:40:42,284][train][INFO] - Epoch 35/100, Val Acc=0.6699, Val Loss=1.5711, lr=0.0100
[2025-05-01 00:40:50,240][train][INFO] - Epoch 36/100, Val Acc=0.6746, Val Loss=1.5239, lr=0.0100
[2025-05-01 00:40:54,939][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6728, lr=0.0001
[2025-05-01 00:40:58,730][train][INFO] - Epoch 37/100, Val Acc=0.6644, Val Loss=1.6576, lr=0.0100
[2025-05-01 00:41:06,284][train][INFO] - Epoch 38/100, Val Acc=0.6744, Val Loss=1.5382, lr=0.0100
[2025-05-01 00:41:14,649][train][INFO] - Epoch 39/100, Val Acc=0.6668, Val Loss=1.5539, lr=0.0100
[2025-05-01 00:41:23,168][train][INFO] - Epoch 40/100, Val Acc=0.6696, Val Loss=1.5994, lr=0.0100
[2025-05-01 00:41:31,722][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.6125, lr=0.0100
[2025-05-01 00:41:34,713][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6478, lr=0.0001
[2025-05-01 00:41:40,466][train][INFO] - Epoch 42/100, Val Acc=0.6581, Val Loss=1.6392, lr=0.0100
[2025-05-01 00:41:49,098][train][INFO] - Epoch 43/100, Val Acc=0.6740, Val Loss=1.5583, lr=0.0100
[2025-05-01 00:41:57,886][train][INFO] - Epoch 44/100, Val Acc=0.6765, Val Loss=1.5394, lr=0.0100
[2025-05-01 00:42:06,748][train][INFO] - Epoch 45/100, Val Acc=0.6555, Val Loss=1.6597, lr=0.0100
[2025-05-01 00:42:14,676][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6948, lr=0.0001
[2025-05-01 00:42:15,168][train][INFO] - Epoch 46/100, Val Acc=0.6743, Val Loss=1.5639, lr=0.0100
[2025-05-01 00:42:22,897][train][INFO] - Epoch 47/100, Val Acc=0.6557, Val Loss=1.6675, lr=0.0100
[2025-05-01 00:42:31,318][train][INFO] - Epoch 48/100, Val Acc=0.6708, Val Loss=1.5699, lr=0.0100
[2025-05-01 00:42:39,573][train][INFO] - Epoch 49/100, Val Acc=0.6685, Val Loss=1.6002, lr=0.0100
[2025-05-01 00:42:48,105][train][INFO] - Epoch 50/100, Val Acc=0.6667, Val Loss=1.6034, lr=0.0100
[2025-05-01 00:42:54,211][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6414, lr=0.0001
[2025-05-01 00:42:55,604][train][INFO] - Epoch 51/100, Val Acc=0.6714, Val Loss=1.6086, lr=0.0100
[2025-05-01 00:43:03,799][train][INFO] - Epoch 52/100, Val Acc=0.6785, Val Loss=1.5412, lr=0.0100
[2025-05-01 00:43:11,744][train][INFO] - Epoch 53/100, Val Acc=0.6823, Val Loss=1.5410, lr=0.0100
[2025-05-01 00:43:19,977][train][INFO] - Epoch 54/100, Val Acc=0.6680, Val Loss=1.5443, lr=0.0100
[2025-05-01 00:43:28,290][train][INFO] - Epoch 55/100, Val Acc=0.6738, Val Loss=1.5766, lr=0.0100
[2025-05-01 00:43:32,455][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6450, lr=0.0001
[2025-05-01 00:43:36,439][train][INFO] - Epoch 56/100, Val Acc=0.6707, Val Loss=1.6004, lr=0.0100
[2025-05-01 00:43:44,794][train][INFO] - Epoch 57/100, Val Acc=0.6621, Val Loss=1.6096, lr=0.0100
[2025-05-01 00:43:52,609][train][INFO] - Epoch 58/100, Val Acc=0.6556, Val Loss=1.6278, lr=0.0100
[2025-05-01 00:44:00,571][train][INFO] - Epoch 59/100, Val Acc=0.6538, Val Loss=1.6854, lr=0.0100
[2025-05-01 00:44:08,671][train][INFO] - Epoch 60/100, Val Acc=0.6585, Val Loss=1.6530, lr=0.0100
[2025-05-01 00:44:11,975][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6481, lr=0.0001
[2025-05-01 00:44:16,662][train][INFO] - Epoch 61/100, Val Acc=0.7207, Val Loss=1.3267, lr=0.0010
[2025-05-01 00:44:25,094][train][INFO] - Epoch 62/100, Val Acc=0.7272, Val Loss=1.3175, lr=0.0010
[2025-05-01 00:44:33,166][train][INFO] - Epoch 63/100, Val Acc=0.7287, Val Loss=1.3253, lr=0.0010
[2025-05-01 00:44:41,220][train][INFO] - Epoch 64/100, Val Acc=0.7304, Val Loss=1.3216, lr=0.0010
[2025-05-01 00:44:49,332][train][INFO] - Epoch 65/100, Val Acc=0.7291, Val Loss=1.3308, lr=0.0010
[2025-05-01 00:44:51,589][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6654, lr=0.0001
[2025-05-01 00:44:57,526][train][INFO] - Epoch 66/100, Val Acc=0.7320, Val Loss=1.3302, lr=0.0010
[2025-05-01 00:45:05,676][train][INFO] - Epoch 67/100, Val Acc=0.7308, Val Loss=1.3305, lr=0.0010
[2025-05-01 00:45:13,352][train][INFO] - Epoch 68/100, Val Acc=0.7314, Val Loss=1.3263, lr=0.0010
[2025-05-01 00:45:21,609][train][INFO] - Epoch 69/100, Val Acc=0.7341, Val Loss=1.3317, lr=0.0010
[2025-05-01 00:45:29,515][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6283, lr=0.0001
[2025-05-01 00:45:29,519][train][INFO] - Epoch 70/100, Val Acc=0.7327, Val Loss=1.3432, lr=0.0010
[2025-05-01 00:45:29,525][meta_train][INFO] - epoch_46 saved !
[2025-05-01 00:45:38,599][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.3437, lr=0.0010
[2025-05-01 00:45:47,502][train][INFO] - Epoch 72/100, Val Acc=0.7343, Val Loss=1.3464, lr=0.0010
[2025-05-01 00:45:55,977][train][INFO] - Epoch 73/100, Val Acc=0.7352, Val Loss=1.3427, lr=0.0010
[2025-05-01 00:46:04,035][train][INFO] - Epoch 74/100, Val Acc=0.7357, Val Loss=1.3411, lr=0.0010
[2025-05-01 00:46:09,792][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6425, lr=0.0001
[2025-05-01 00:46:12,427][train][INFO] - Epoch 75/100, Val Acc=0.7371, Val Loss=1.3428, lr=0.0010
[2025-05-01 00:46:20,920][train][INFO] - Epoch 76/100, Val Acc=0.7355, Val Loss=1.3441, lr=0.0010
[2025-05-01 00:46:28,731][train][INFO] - Epoch 77/100, Val Acc=0.7372, Val Loss=1.3443, lr=0.0010
[2025-05-01 00:46:37,136][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.3440, lr=0.0010
[2025-05-01 00:46:45,529][train][INFO] - Epoch 79/100, Val Acc=0.7378, Val Loss=1.3494, lr=0.0010
[2025-05-01 00:46:49,385][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6675, lr=0.0001
[2025-05-01 00:46:53,860][train][INFO] - Epoch 80/100, Val Acc=0.7372, Val Loss=1.3433, lr=0.0010
[2025-05-01 00:47:02,315][train][INFO] - Epoch 81/100, Val Acc=0.7389, Val Loss=1.3420, lr=0.0010
[2025-05-01 00:47:10,187][train][INFO] - Epoch 82/100, Val Acc=0.7393, Val Loss=1.3442, lr=0.0010
[2025-05-01 00:47:18,881][train][INFO] - Epoch 83/100, Val Acc=0.7382, Val Loss=1.3479, lr=0.0010
[2025-05-01 00:47:26,950][train][INFO] - Epoch 84/100, Val Acc=0.7381, Val Loss=1.3420, lr=0.0010
[2025-05-01 00:47:28,985][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6831, lr=0.0001
[2025-05-01 00:47:35,071][train][INFO] - Epoch 85/100, Val Acc=0.7373, Val Loss=1.3412, lr=0.0010
[2025-05-01 00:47:43,753][train][INFO] - Epoch 86/100, Val Acc=0.7386, Val Loss=1.3469, lr=0.0010
[2025-05-01 00:47:51,710][train][INFO] - Epoch 87/100, Val Acc=0.7391, Val Loss=1.3443, lr=0.0010
[2025-05-01 00:47:59,850][train][INFO] - Epoch 88/100, Val Acc=0.7383, Val Loss=1.3424, lr=0.0010
[2025-05-01 00:48:07,382][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6638, lr=0.0001
[2025-05-01 00:48:08,192][train][INFO] - Epoch 89/100, Val Acc=0.7407, Val Loss=1.3425, lr=0.0010
[2025-05-01 00:48:17,221][train][INFO] - Epoch 90/100, Val Acc=0.7376, Val Loss=1.3524, lr=0.0010
[2025-05-01 00:48:25,777][train][INFO] - Epoch 91/100, Val Acc=0.7381, Val Loss=1.3473, lr=0.0001
[2025-05-01 00:48:34,098][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3461, lr=0.0001
[2025-05-01 00:48:42,131][train][INFO] - Epoch 93/100, Val Acc=0.7394, Val Loss=1.3455, lr=0.0001
[2025-05-01 00:48:46,095][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6447, lr=0.0001
[2025-05-01 00:48:49,902][train][INFO] - Epoch 94/100, Val Acc=0.7403, Val Loss=1.3418, lr=0.0001
[2025-05-01 00:48:58,096][train][INFO] - Epoch 95/100, Val Acc=0.7382, Val Loss=1.3469, lr=0.0001
[2025-05-01 00:49:06,172][train][INFO] - Epoch 96/100, Val Acc=0.7407, Val Loss=1.3431, lr=0.0001
[2025-05-01 00:49:14,322][train][INFO] - Epoch 97/100, Val Acc=0.7416, Val Loss=1.3420, lr=0.0001
[2025-05-01 00:49:22,584][train][INFO] - Epoch 98/100, Val Acc=0.7403, Val Loss=1.3390, lr=0.0001
[2025-05-01 00:49:27,105][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6367, lr=0.0001
[2025-05-01 00:49:31,049][train][INFO] - Epoch 99/100, Val Acc=0.7405, Val Loss=1.3454, lr=0.0001
[2025-05-01 00:49:39,889][train][INFO] - Epoch 100/100, Val Acc=0.7383, Val Loss=1.3456, lr=0.0001
[2025-05-01 00:49:44,886][train][INFO] - After training : Train Acc=0.9994  Val Acc=0.7416
[2025-05-01 00:49:44,896][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 00:50:06,802][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6280, lr=0.0001
[2025-05-01 00:50:45,689][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6415, lr=0.0001
[2025-05-01 00:50:45,698][meta_train][INFO] - epoch_47 saved !
[2025-05-01 00:51:25,301][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6395, lr=0.0001
[2025-05-01 00:51:31,811][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 00:52:05,766][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6409, lr=0.0001
[2025-05-01 00:52:46,447][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6395, lr=0.0001
[2025-05-01 00:53:19,796][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 00:53:20,250][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 00:53:26,944][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6266, lr=0.0001
[2025-05-01 00:54:05,867][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6617, lr=0.0001
[2025-05-01 00:54:43,035][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6702, lr=0.0001
[2025-05-01 00:55:21,517][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6560, lr=0.0001
[2025-05-01 00:56:00,884][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6321, lr=0.0001
[2025-05-01 00:56:00,905][meta_train][INFO] - epoch_48 saved !
[2025-05-01 00:56:40,112][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6319, lr=0.0001
[2025-05-01 00:57:19,925][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6553, lr=0.0001
[2025-05-01 00:57:59,362][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6263, lr=0.0001
[2025-05-01 00:58:37,940][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6365, lr=0.0001
[2025-05-01 00:59:15,536][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6654, lr=0.0001
[2025-05-01 00:59:56,179][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6337, lr=0.0001
[2025-05-01 01:00:35,629][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6587, lr=0.0001
[2025-05-01 01:01:14,283][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6354, lr=0.0001
[2025-05-01 01:01:14,312][meta_train][INFO] - epoch_49 saved !
[2025-05-01 01:01:53,273][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6605, lr=0.0001
[2025-05-01 01:02:32,429][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6494, lr=0.0001
[2025-05-01 01:03:11,739][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6299, lr=0.0001
[2025-05-01 01:03:52,369][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6325, lr=0.0001
[2025-05-01 01:04:33,330][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6237, lr=0.0001
[2025-05-01 01:05:12,391][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6528, lr=0.0001
[2025-05-01 01:05:53,423][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6266, lr=0.0001
[2025-05-01 01:06:34,279][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6302, lr=0.0001
[2025-05-01 01:06:34,290][meta_train][INFO] - epoch_50 saved !
[2025-05-01 01:07:12,725][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6301, lr=0.0001
[2025-05-01 01:07:53,094][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6545, lr=0.0001
[2025-05-01 01:08:32,811][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6259, lr=0.0001
[2025-05-01 01:09:12,203][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6306, lr=0.0001
[2025-05-01 01:09:52,284][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6256, lr=0.0001
[2025-05-01 01:10:32,985][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6222, lr=0.0001
[2025-05-01 01:11:11,477][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6416, lr=0.0001
[2025-05-01 01:11:51,297][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6476, lr=0.0001
[2025-05-01 01:11:51,317][meta_train][INFO] - epoch_51 saved !
[2025-05-01 01:12:30,595][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6255, lr=0.0001
[2025-05-01 01:13:11,115][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6223, lr=0.0001
[2025-05-01 01:13:50,966][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6246, lr=0.0001
[2025-05-01 01:14:30,933][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6237, lr=0.0001
[2025-05-01 01:15:10,349][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6280, lr=0.0001
[2025-05-01 01:15:49,951][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6461, lr=0.0001
[2025-05-01 01:16:29,219][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6382, lr=0.0001
[2025-05-01 01:17:08,295][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6413, lr=0.0001
[2025-05-01 01:17:08,318][meta_train][INFO] - epoch_52 saved !
[2025-05-01 01:17:49,421][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6402, lr=0.0001
[2025-05-01 01:18:29,251][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6243, lr=0.0001
[2025-05-01 01:19:07,293][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6355, lr=0.0001
[2025-05-01 01:19:48,801][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6203, lr=0.0001
[2025-05-01 01:20:28,339][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6211, lr=0.0001
[2025-05-01 01:21:08,058][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6209, lr=0.0001
[2025-05-01 01:21:48,438][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6205, lr=0.0001
[2025-05-01 01:22:28,937][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6422, lr=0.0001
[2025-05-01 01:22:28,950][meta_train][INFO] - epoch_53 saved !
[2025-05-01 01:23:06,795][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6345, lr=0.0001
[2025-05-01 01:23:47,930][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6366, lr=0.0001
[2025-05-01 01:24:27,910][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6186, lr=0.0001
[2025-05-01 01:25:05,945][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6376, lr=0.0001
[2025-05-01 01:25:46,454][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6185, lr=0.0001
[2025-05-01 01:26:24,458][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6178, lr=0.0001
[2025-05-01 01:27:04,117][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6194, lr=0.0001
[2025-05-01 01:27:41,596][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6225, lr=0.0001
[2025-05-01 01:27:41,617][meta_train][INFO] - epoch_54 saved !
[2025-05-01 01:28:21,223][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6222, lr=0.0001
[2025-05-01 01:28:58,655][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6179, lr=0.0001
[2025-05-01 01:29:37,910][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6325, lr=0.0001
[2025-05-01 01:29:52,857][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 01:29:52,934][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 01:29:52,935][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 01:29:52,935][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 01:30:18,119][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6351, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 01:30:24,878][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 01:30:33,542][train][INFO] - Epoch 1/100, Val Acc=0.6188, Val Loss=1.7082, lr=0.0100
[2025-05-01 01:30:42,037][train][INFO] - Epoch 2/100, Val Acc=0.6543, Val Loss=1.5455, lr=0.0100
[2025-05-01 01:30:50,269][train][INFO] - Epoch 3/100, Val Acc=0.6363, Val Loss=1.5997, lr=0.0100
[2025-05-01 01:30:58,576][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-05-01 01:30:58,666][train][INFO] - Epoch 4/100, Val Acc=0.6640, Val Loss=1.5027, lr=0.0100
[2025-05-01 01:31:07,504][train][INFO] - Epoch 5/100, Val Acc=0.6494, Val Loss=1.6039, lr=0.0100
[2025-05-01 01:31:16,046][train][INFO] - Epoch 6/100, Val Acc=0.6586, Val Loss=1.5182, lr=0.0100
[2025-05-01 01:31:24,367][train][INFO] - Epoch 7/100, Val Acc=0.6484, Val Loss=1.5781, lr=0.0100
[2025-05-01 01:31:32,834][train][INFO] - Epoch 8/100, Val Acc=0.6805, Val Loss=1.4691, lr=0.0100
[2025-05-01 01:31:38,935][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6173, lr=0.0001
[2025-05-01 01:31:41,149][train][INFO] - Epoch 9/100, Val Acc=0.6739, Val Loss=1.4870, lr=0.0100
[2025-05-01 01:31:50,182][train][INFO] - Epoch 10/100, Val Acc=0.6636, Val Loss=1.5261, lr=0.0100
[2025-05-01 01:31:58,459][train][INFO] - Epoch 11/100, Val Acc=0.6674, Val Loss=1.5164, lr=0.0100
[2025-05-01 01:32:06,659][train][INFO] - Epoch 12/100, Val Acc=0.6736, Val Loss=1.4828, lr=0.0100
[2025-05-01 01:32:15,106][train][INFO] - Epoch 13/100, Val Acc=0.6743, Val Loss=1.5306, lr=0.0100
[2025-05-01 01:32:18,373][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6290, lr=0.0001
[2025-05-01 01:32:23,804][train][INFO] - Epoch 14/100, Val Acc=0.6697, Val Loss=1.5341, lr=0.0100
[2025-05-01 01:32:32,518][train][INFO] - Epoch 15/100, Val Acc=0.6609, Val Loss=1.6052, lr=0.0100
[2025-05-01 01:32:40,768][train][INFO] - Epoch 16/100, Val Acc=0.6699, Val Loss=1.5074, lr=0.0100
[2025-05-01 01:32:48,803][train][INFO] - Epoch 17/100, Val Acc=0.6758, Val Loss=1.4803, lr=0.0100
[2025-05-01 01:32:56,603][train][INFO] - Epoch 18/100, Val Acc=0.6705, Val Loss=1.5681, lr=0.0100
[2025-05-01 01:32:57,449][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6183, lr=0.0001
[2025-05-01 01:32:57,462][meta_train][INFO] - epoch_55 saved !
[2025-05-01 01:33:05,433][train][INFO] - Epoch 19/100, Val Acc=0.6838, Val Loss=1.4834, lr=0.0100
[2025-05-01 01:33:13,933][train][INFO] - Epoch 20/100, Val Acc=0.6767, Val Loss=1.4944, lr=0.0100
[2025-05-01 01:33:22,428][train][INFO] - Epoch 21/100, Val Acc=0.6552, Val Loss=1.6172, lr=0.0100
[2025-05-01 01:33:30,985][train][INFO] - Epoch 22/100, Val Acc=0.6738, Val Loss=1.5114, lr=0.0100
[2025-05-01 01:33:37,929][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6184, lr=0.0001
[2025-05-01 01:33:39,478][train][INFO] - Epoch 23/100, Val Acc=0.6806, Val Loss=1.4976, lr=0.0100
[2025-05-01 01:33:48,287][train][INFO] - Epoch 24/100, Val Acc=0.6739, Val Loss=1.5547, lr=0.0100
[2025-05-01 01:33:56,860][train][INFO] - Epoch 25/100, Val Acc=0.6817, Val Loss=1.5231, lr=0.0100
[2025-05-01 01:34:05,257][train][INFO] - Epoch 26/100, Val Acc=0.6735, Val Loss=1.5446, lr=0.0100
[2025-05-01 01:34:13,558][train][INFO] - Epoch 27/100, Val Acc=0.6869, Val Loss=1.5026, lr=0.0100
[2025-05-01 01:34:17,578][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6291, lr=0.0001
[2025-05-01 01:34:22,407][train][INFO] - Epoch 28/100, Val Acc=0.6742, Val Loss=1.5556, lr=0.0100
[2025-05-01 01:34:30,884][train][INFO] - Epoch 29/100, Val Acc=0.6777, Val Loss=1.5510, lr=0.0100
[2025-05-01 01:34:38,896][train][INFO] - Epoch 30/100, Val Acc=0.6683, Val Loss=1.5926, lr=0.0100
[2025-05-01 01:34:47,060][train][INFO] - Epoch 31/100, Val Acc=0.6793, Val Loss=1.5394, lr=0.0100
[2025-05-01 01:34:55,028][train][INFO] - Epoch 32/100, Val Acc=0.6794, Val Loss=1.5076, lr=0.0100
[2025-05-01 01:34:59,566][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6174, lr=0.0001
[2025-05-01 01:35:03,616][train][INFO] - Epoch 33/100, Val Acc=0.6630, Val Loss=1.5601, lr=0.0100
[2025-05-01 01:35:12,222][train][INFO] - Epoch 34/100, Val Acc=0.6902, Val Loss=1.4750, lr=0.0100
[2025-05-01 01:35:20,471][train][INFO] - Epoch 35/100, Val Acc=0.6673, Val Loss=1.5726, lr=0.0100
[2025-05-01 01:35:28,575][train][INFO] - Epoch 36/100, Val Acc=0.6676, Val Loss=1.5825, lr=0.0100
[2025-05-01 01:35:36,828][train][INFO] - Epoch 37/100, Val Acc=0.6550, Val Loss=1.6390, lr=0.0100
[2025-05-01 01:35:41,392][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6156, lr=0.0001
[2025-05-01 01:35:45,013][train][INFO] - Epoch 38/100, Val Acc=0.6771, Val Loss=1.5415, lr=0.0100
[2025-05-01 01:35:53,191][train][INFO] - Epoch 39/100, Val Acc=0.6690, Val Loss=1.5664, lr=0.0100
[2025-05-01 01:36:01,976][train][INFO] - Epoch 40/100, Val Acc=0.6756, Val Loss=1.5347, lr=0.0100
[2025-05-01 01:36:10,007][train][INFO] - Epoch 41/100, Val Acc=0.6724, Val Loss=1.5592, lr=0.0100
[2025-05-01 01:36:18,346][train][INFO] - Epoch 42/100, Val Acc=0.6685, Val Loss=1.5652, lr=0.0100
[2025-05-01 01:36:22,168][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6287, lr=0.0001
[2025-05-01 01:36:26,330][train][INFO] - Epoch 43/100, Val Acc=0.6741, Val Loss=1.5377, lr=0.0100
[2025-05-01 01:36:34,657][train][INFO] - Epoch 44/100, Val Acc=0.6743, Val Loss=1.5522, lr=0.0100
[2025-05-01 01:36:43,512][train][INFO] - Epoch 45/100, Val Acc=0.6625, Val Loss=1.6073, lr=0.0100
[2025-05-01 01:36:51,549][train][INFO] - Epoch 46/100, Val Acc=0.6753, Val Loss=1.5243, lr=0.0100
[2025-05-01 01:36:59,519][train][INFO] - Epoch 47/100, Val Acc=0.6644, Val Loss=1.5883, lr=0.0100
[2025-05-01 01:37:03,984][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6142, lr=0.0001
[2025-05-01 01:37:07,930][train][INFO] - Epoch 48/100, Val Acc=0.6687, Val Loss=1.5641, lr=0.0100
[2025-05-01 01:37:16,537][train][INFO] - Epoch 49/100, Val Acc=0.6664, Val Loss=1.6304, lr=0.0100
[2025-05-01 01:37:24,817][train][INFO] - Epoch 50/100, Val Acc=0.6630, Val Loss=1.6591, lr=0.0100
[2025-05-01 01:37:33,037][train][INFO] - Epoch 51/100, Val Acc=0.6689, Val Loss=1.5864, lr=0.0100
[2025-05-01 01:37:40,841][train][INFO] - Epoch 52/100, Val Acc=0.6617, Val Loss=1.6181, lr=0.0100
[2025-05-01 01:37:44,504][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6172, lr=0.0001
[2025-05-01 01:37:49,271][train][INFO] - Epoch 53/100, Val Acc=0.6707, Val Loss=1.5443, lr=0.0100
[2025-05-01 01:37:57,590][train][INFO] - Epoch 54/100, Val Acc=0.6721, Val Loss=1.5258, lr=0.0100
[2025-05-01 01:38:05,918][train][INFO] - Epoch 55/100, Val Acc=0.6767, Val Loss=1.5452, lr=0.0100
[2025-05-01 01:38:13,934][train][INFO] - Epoch 56/100, Val Acc=0.6719, Val Loss=1.5487, lr=0.0100
[2025-05-01 01:38:22,526][train][INFO] - Epoch 57/100, Val Acc=0.6732, Val Loss=1.5974, lr=0.0100
[2025-05-01 01:38:25,686][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6304, lr=0.0001
[2025-05-01 01:38:25,695][meta_train][INFO] - epoch_56 saved !
[2025-05-01 01:38:31,059][train][INFO] - Epoch 58/100, Val Acc=0.6744, Val Loss=1.5768, lr=0.0100
[2025-05-01 01:38:39,717][train][INFO] - Epoch 59/100, Val Acc=0.6558, Val Loss=1.6858, lr=0.0100
[2025-05-01 01:38:48,177][train][INFO] - Epoch 60/100, Val Acc=0.6756, Val Loss=1.5352, lr=0.0100
[2025-05-01 01:38:56,847][train][INFO] - Epoch 61/100, Val Acc=0.7251, Val Loss=1.3032, lr=0.0010
[2025-05-01 01:39:03,771][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6138, lr=0.0001
[2025-05-01 01:39:05,338][train][INFO] - Epoch 62/100, Val Acc=0.7302, Val Loss=1.2886, lr=0.0010
[2025-05-01 01:39:13,920][train][INFO] - Epoch 63/100, Val Acc=0.7326, Val Loss=1.2911, lr=0.0010
[2025-05-01 01:39:21,843][train][INFO] - Epoch 64/100, Val Acc=0.7325, Val Loss=1.2922, lr=0.0010
[2025-05-01 01:39:30,751][train][INFO] - Epoch 65/100, Val Acc=0.7335, Val Loss=1.3015, lr=0.0010
[2025-05-01 01:39:38,910][train][INFO] - Epoch 66/100, Val Acc=0.7369, Val Loss=1.3021, lr=0.0010
[2025-05-01 01:39:44,134][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6134, lr=0.0001
[2025-05-01 01:39:47,382][train][INFO] - Epoch 67/100, Val Acc=0.7361, Val Loss=1.2986, lr=0.0010
[2025-05-01 01:39:55,913][train][INFO] - Epoch 68/100, Val Acc=0.7360, Val Loss=1.3010, lr=0.0010
[2025-05-01 01:40:04,835][train][INFO] - Epoch 69/100, Val Acc=0.7354, Val Loss=1.3085, lr=0.0010
[2025-05-01 01:40:13,566][train][INFO] - Epoch 70/100, Val Acc=0.7362, Val Loss=1.3223, lr=0.0010
[2025-05-01 01:40:22,129][train][INFO] - Epoch 71/100, Val Acc=0.7359, Val Loss=1.3253, lr=0.0010
[2025-05-01 01:40:23,996][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6260, lr=0.0001
[2025-05-01 01:40:31,196][train][INFO] - Epoch 72/100, Val Acc=0.7361, Val Loss=1.3165, lr=0.0010
[2025-05-01 01:40:40,351][train][INFO] - Epoch 73/100, Val Acc=0.7380, Val Loss=1.3120, lr=0.0010
[2025-05-01 01:40:48,690][train][INFO] - Epoch 74/100, Val Acc=0.7387, Val Loss=1.3159, lr=0.0010
[2025-05-01 01:40:57,532][train][INFO] - Epoch 75/100, Val Acc=0.7381, Val Loss=1.3217, lr=0.0010
[2025-05-01 01:41:02,408][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6243, lr=0.0001
[2025-05-01 01:41:06,170][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3200, lr=0.0010
[2025-05-01 01:41:14,652][train][INFO] - Epoch 77/100, Val Acc=0.7390, Val Loss=1.3122, lr=0.0010
[2025-05-01 01:41:23,404][train][INFO] - Epoch 78/100, Val Acc=0.7391, Val Loss=1.3155, lr=0.0010
[2025-05-01 01:41:32,032][train][INFO] - Epoch 79/100, Val Acc=0.7396, Val Loss=1.3194, lr=0.0010
[2025-05-01 01:41:39,954][train][INFO] - Epoch 80/100, Val Acc=0.7395, Val Loss=1.3198, lr=0.0010
[2025-05-01 01:41:43,551][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6161, lr=0.0001
[2025-05-01 01:41:48,677][train][INFO] - Epoch 81/100, Val Acc=0.7388, Val Loss=1.3287, lr=0.0010
[2025-05-01 01:41:56,688][train][INFO] - Epoch 82/100, Val Acc=0.7366, Val Loss=1.3309, lr=0.0010
[2025-05-01 01:42:04,674][train][INFO] - Epoch 83/100, Val Acc=0.7381, Val Loss=1.3307, lr=0.0010
[2025-05-01 01:42:12,769][train][INFO] - Epoch 84/100, Val Acc=0.7395, Val Loss=1.3246, lr=0.0010
[2025-05-01 01:42:20,933][train][INFO] - Epoch 85/100, Val Acc=0.7403, Val Loss=1.3187, lr=0.0010
[2025-05-01 01:42:24,264][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6290, lr=0.0001
[2025-05-01 01:42:29,685][train][INFO] - Epoch 86/100, Val Acc=0.7399, Val Loss=1.3301, lr=0.0010
[2025-05-01 01:42:37,015][train][INFO] - Epoch 87/100, Val Acc=0.7416, Val Loss=1.3206, lr=0.0010
[2025-05-01 01:42:45,147][train][INFO] - Epoch 88/100, Val Acc=0.7412, Val Loss=1.3196, lr=0.0010
[2025-05-01 01:42:53,026][train][INFO] - Epoch 89/100, Val Acc=0.7402, Val Loss=1.3181, lr=0.0010
[2025-05-01 01:43:01,213][train][INFO] - Epoch 90/100, Val Acc=0.7401, Val Loss=1.3223, lr=0.0010
[2025-05-01 01:43:04,850][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6153, lr=0.0001
[2025-05-01 01:43:09,200][train][INFO] - Epoch 91/100, Val Acc=0.7411, Val Loss=1.3188, lr=0.0001
[2025-05-01 01:43:17,287][train][INFO] - Epoch 92/100, Val Acc=0.7409, Val Loss=1.3205, lr=0.0001
[2025-05-01 01:43:25,243][train][INFO] - Epoch 93/100, Val Acc=0.7404, Val Loss=1.3183, lr=0.0001
[2025-05-01 01:43:33,114][train][INFO] - Epoch 94/100, Val Acc=0.7426, Val Loss=1.3141, lr=0.0001
[2025-05-01 01:43:41,316][train][INFO] - Epoch 95/100, Val Acc=0.7405, Val Loss=1.3248, lr=0.0001
[2025-05-01 01:43:45,009][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6171, lr=0.0001
[2025-05-01 01:43:45,020][meta_train][INFO] - epoch_57 saved !
[2025-05-01 01:43:49,715][train][INFO] - Epoch 96/100, Val Acc=0.7426, Val Loss=1.3134, lr=0.0001
[2025-05-01 01:43:57,795][train][INFO] - Epoch 97/100, Val Acc=0.7416, Val Loss=1.3142, lr=0.0001
[2025-05-01 01:44:05,878][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3133, lr=0.0001
[2025-05-01 01:44:13,851][train][INFO] - Epoch 99/100, Val Acc=0.7415, Val Loss=1.3152, lr=0.0001
[2025-05-01 01:44:21,794][train][INFO] - Epoch 100/100, Val Acc=0.7411, Val Loss=1.3170, lr=0.0001
[2025-05-01 01:44:25,661][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6257, lr=0.0001
[2025-05-01 01:44:27,234][train][INFO] - After training : Train Acc=0.9992  Val Acc=0.7426
[2025-05-01 01:44:27,238][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 01:45:07,914][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6142, lr=0.0001
[2025-05-01 01:45:48,299][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6322, lr=0.0001
[2025-05-01 01:46:30,855][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6255, lr=0.0001
[2025-05-01 01:46:32,353][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 01:47:11,412][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6147, lr=0.0001
[2025-05-01 01:47:52,024][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6144, lr=0.0001
[2025-05-01 01:48:33,538][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6112, lr=0.0001
[2025-05-01 01:48:38,291][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 01:48:38,752][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 01:49:15,286][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6151, lr=0.0001
[2025-05-01 01:49:15,310][meta_train][INFO] - epoch_58 saved !
[2025-05-01 01:49:57,311][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-05-01 01:50:39,684][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6210, lr=0.0001
[2025-05-01 01:51:19,902][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6147, lr=0.0001
[2025-05-01 01:52:02,548][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6229, lr=0.0001
[2025-05-01 01:52:43,779][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6273, lr=0.0001
[2025-05-01 01:53:25,379][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6115, lr=0.0001
[2025-05-01 01:54:03,216][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6114, lr=0.0001
[2025-05-01 01:54:43,294][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6156, lr=0.0001
[2025-05-01 01:54:43,306][meta_train][INFO] - epoch_59 saved !
[2025-05-01 01:55:21,679][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6251, lr=0.0001
[2025-05-01 01:56:03,119][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6135, lr=0.0001
[2025-05-01 01:56:44,213][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6135, lr=0.0001
[2025-05-01 01:57:23,463][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 01:58:03,471][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6101, lr=0.0001
[2025-05-01 01:58:43,992][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6148, lr=0.0001
[2025-05-01 01:59:22,990][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6189, lr=0.0001
[2025-05-01 02:00:03,646][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6200, lr=0.0001
[2025-05-01 02:00:03,660][meta_train][INFO] - epoch_60 saved !
[2025-05-01 02:00:45,320][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6135, lr=0.0001
[2025-05-01 02:01:26,199][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6156, lr=0.0001
[2025-05-01 02:02:05,316][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6204, lr=0.0001
[2025-05-01 02:02:46,190][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:03:26,887][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6098, lr=0.0001
[2025-05-01 02:04:05,575][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6170, lr=0.0001
[2025-05-01 02:04:45,797][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6195, lr=0.0001
[2025-05-01 02:05:25,905][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6111, lr=0.0001
[2025-05-01 02:05:25,922][meta_train][INFO] - epoch_61 saved !
[2025-05-01 02:06:06,984][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6117, lr=0.0001
[2025-05-01 02:06:47,370][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6169, lr=0.0001
[2025-05-01 02:07:27,060][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:08:08,086][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6099, lr=0.0001
[2025-05-01 02:08:47,391][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6150, lr=0.0001
[2025-05-01 02:09:27,708][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6183, lr=0.0001
[2025-05-01 02:10:08,862][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:10:49,268][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6199, lr=0.0001
[2025-05-01 02:10:49,285][meta_train][INFO] - epoch_62 saved !
[2025-05-01 02:11:29,075][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6161, lr=0.0001
[2025-05-01 02:12:08,484][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6087, lr=0.0001
[2025-05-01 02:12:49,298][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6153, lr=0.0001
[2025-05-01 02:13:29,960][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:14:09,156][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6086, lr=0.0001
[2025-05-01 02:14:49,555][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6141, lr=0.0001
[2025-05-01 02:15:30,589][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:16:11,023][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6211, lr=0.0001
[2025-05-01 02:16:11,046][meta_train][INFO] - epoch_63 saved !
[2025-05-01 02:16:49,787][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6208, lr=0.0001
[2025-05-01 02:17:30,966][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6111, lr=0.0001
[2025-05-01 02:18:09,318][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6085, lr=0.0001
[2025-05-01 02:18:50,132][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:19:31,486][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6140, lr=0.0001
[2025-05-01 02:20:10,852][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6132, lr=0.0001
[2025-05-01 02:20:51,860][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6145, lr=0.0001
[2025-05-01 02:21:32,167][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6085, lr=0.0001
[2025-05-01 02:21:32,190][meta_train][INFO] - epoch_64 saved !
[2025-05-01 02:22:12,503][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6157, lr=0.0001
[2025-05-01 02:22:52,569][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6158, lr=0.0001
[2025-05-01 02:23:32,232][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:24:11,911][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6081, lr=0.0001
[2025-05-01 02:24:52,584][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6077, lr=0.0001
[2025-05-01 02:25:33,178][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6158, lr=0.0001
[2025-05-01 02:26:13,328][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6133, lr=0.0001
[2025-05-01 02:26:54,070][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6108, lr=0.0001
[2025-05-01 02:26:54,092][meta_train][INFO] - epoch_65 saved !
[2025-05-01 02:27:35,125][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6136, lr=0.0001
[2025-05-01 02:28:14,135][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6080, lr=0.0001
[2025-05-01 02:28:55,403][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6103, lr=0.0001
[2025-05-01 02:29:36,614][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6131, lr=0.0001
[2025-05-01 02:30:16,200][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:30:56,717][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6093, lr=0.0001
[2025-05-01 02:31:36,594][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6133, lr=0.0001
[2025-05-01 02:32:17,637][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6166, lr=0.0001
[2025-05-01 02:32:17,659][meta_train][INFO] - epoch_66 saved !
[2025-05-01 02:32:57,534][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6078, lr=0.0001
[2025-05-01 02:33:36,780][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6136, lr=0.0001
[2025-05-01 02:34:17,163][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6094, lr=0.0001
[2025-05-01 02:34:58,711][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6143, lr=0.0001
[2025-05-01 02:35:37,871][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6126, lr=0.0001
[2025-05-01 02:36:17,522][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:36:57,741][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6101, lr=0.0001
[2025-05-01 02:37:38,320][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6131, lr=0.0001
[2025-05-01 02:37:38,330][meta_train][INFO] - epoch_67 saved !
[2025-05-01 02:38:17,346][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 02:38:55,790][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:39:35,380][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6118, lr=0.0001
[2025-05-01 02:40:14,590][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6123, lr=0.0001
[2025-05-01 02:40:55,299][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:41:35,270][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:42:13,708][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6091, lr=0.0001
[2025-05-01 02:42:52,698][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6143, lr=0.0001
[2025-05-01 02:42:52,709][meta_train][INFO] - epoch_68 saved !
[2025-05-01 02:43:33,944][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:44:13,861][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 02:44:52,475][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:45:31,704][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6082, lr=0.0001
[2025-05-01 02:46:11,357][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-05-01 02:46:49,881][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6114, lr=0.0001
[2025-05-01 02:47:29,744][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6141, lr=0.0001
[2025-05-01 02:48:09,707][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6121, lr=0.0001
[2025-05-01 02:48:09,722][meta_train][INFO] - epoch_69 saved !
[2025-05-01 02:48:51,419][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6069, lr=0.0001
[2025-05-01 02:49:30,903][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-05-01 02:50:12,348][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6121, lr=0.0001
[2025-05-01 02:50:51,045][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6122, lr=0.0001
[2025-05-01 02:51:31,787][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:52:10,410][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6068, lr=0.0001
[2025-05-01 02:52:50,702][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6080, lr=0.0001
[2025-05-01 02:53:31,593][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:53:31,606][meta_train][INFO] - epoch_70 saved !
[2025-05-01 02:54:10,333][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 02:54:49,730][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6079, lr=0.0001
[2025-05-01 02:55:30,089][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6089, lr=0.0001
[2025-05-01 02:56:11,053][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:56:50,633][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:57:29,561][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6103, lr=0.0001
[2025-05-01 02:58:11,154][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 02:58:53,016][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6104, lr=0.0001
[2025-05-01 02:58:53,040][meta_train][INFO] - epoch_71 saved !
[2025-05-01 02:59:34,082][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:00:14,585][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6101, lr=0.0001
[2025-05-01 03:00:54,075][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6080, lr=0.0001
[2025-05-01 03:01:34,955][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-05-01 03:02:15,809][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6089, lr=0.0001
[2025-05-01 03:02:56,948][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6101, lr=0.0001
[2025-05-01 03:03:35,419][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6105, lr=0.0001
[2025-05-01 03:04:15,073][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6064, lr=0.0001
[2025-05-01 03:04:15,097][meta_train][INFO] - epoch_72 saved !
[2025-05-01 03:04:55,862][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:05:34,579][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:06:14,635][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6076, lr=0.0001
[2025-05-01 03:06:54,113][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-05-01 03:07:34,489][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:08:13,889][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6112, lr=0.0001
[2025-05-01 03:08:52,955][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6116, lr=0.0001
[2025-05-01 03:09:32,669][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:09:32,680][meta_train][INFO] - epoch_73 saved !
[2025-05-01 03:10:13,453][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6115, lr=0.0001
[2025-05-01 03:10:53,401][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6104, lr=0.0001
[2025-05-01 03:11:33,626][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:12:12,701][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:12:52,938][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:13:32,814][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:14:13,238][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 03:14:53,342][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6078, lr=0.0001
[2025-05-01 03:14:53,353][meta_train][INFO] - epoch_74 saved !
[2025-05-01 03:15:32,441][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:16:13,405][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6113, lr=0.0001
[2025-05-01 03:16:52,489][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:17:33,458][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:18:12,478][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:18:53,727][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:19:33,920][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6089, lr=0.0001
[2025-05-01 03:20:12,315][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:20:12,338][meta_train][INFO] - epoch_75 saved !
[2025-05-01 03:20:53,188][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:21:34,476][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6063, lr=0.0001
[2025-05-01 03:22:13,098][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:22:53,902][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6110, lr=0.0001
[2025-05-01 03:23:33,149][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6083, lr=0.0001
[2025-05-01 03:24:14,419][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:24:55,943][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 03:25:36,592][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6079, lr=0.0001
[2025-05-01 03:25:36,612][meta_train][INFO] - epoch_76 saved !
[2025-05-01 03:26:15,787][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6079, lr=0.0001
[2025-05-01 03:26:56,230][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 03:27:37,928][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6110, lr=0.0001
[2025-05-01 03:28:17,480][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:28:57,821][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-05-01 03:29:38,436][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:30:19,278][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:30:58,172][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:30:58,182][meta_train][INFO] - epoch_77 saved !
[2025-05-01 03:31:38,070][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:32:18,563][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:32:59,201][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6105, lr=0.0001
[2025-05-01 03:33:39,852][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:34:19,920][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:34:59,204][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6113, lr=0.0001
[2025-05-01 03:35:40,497][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:36:20,888][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-05-01 03:36:20,905][meta_train][INFO] - epoch_78 saved !
[2025-05-01 03:37:01,061][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:37:40,523][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:38:20,253][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:39:01,795][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:39:41,425][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6104, lr=0.0001
[2025-05-01 03:40:22,676][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6060, lr=0.0001
[2025-05-01 03:41:03,452][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6098, lr=0.0001
[2025-05-01 03:41:43,653][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6071, lr=0.0001
[2025-05-01 03:41:43,667][meta_train][INFO] - epoch_79 saved !
[2025-05-01 03:42:23,570][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:43:02,424][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:43:43,188][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:44:24,626][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6078, lr=0.0001
[2025-05-01 03:45:03,862][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-05-01 03:45:43,995][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:46:24,630][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:47:05,525][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:47:05,539][meta_train][INFO] - epoch_80 saved !
[2025-05-01 03:47:45,021][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6068, lr=0.0001
[2025-05-01 03:48:24,897][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:49:04,609][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6083, lr=0.0001
[2025-05-01 03:49:45,261][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:50:24,636][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:51:05,175][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:51:45,732][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:52:26,928][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:52:26,951][meta_train][INFO] - epoch_81 saved !
[2025-05-01 03:53:05,891][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:53:46,147][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:54:26,095][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6082, lr=0.0001
[2025-05-01 03:55:07,545][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:55:48,130][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6058, lr=0.0001
[2025-05-01 03:56:26,664][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6066, lr=0.0001
[2025-05-01 03:57:05,968][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 03:57:46,700][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6097, lr=0.0001
[2025-05-01 03:57:46,713][meta_train][INFO] - epoch_82 saved !
[2025-05-01 03:58:26,003][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6082, lr=0.0001
[2025-05-01 03:59:06,148][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:59:45,555][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6074, lr=0.0001
[2025-05-01 04:00:25,495][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:01:04,914][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:01:44,494][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:02:24,336][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:03:03,666][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:03:03,685][meta_train][INFO] - epoch_83 saved !
[2025-05-01 04:03:44,221][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:04:23,832][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:05:03,756][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:05:42,956][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:06:21,990][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:07:01,263][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:07:41,196][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:08:22,550][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:08:22,562][meta_train][INFO] - epoch_84 saved !
[2025-05-01 04:09:01,236][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:09:40,297][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:10:18,130][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:10:57,515][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:11:36,716][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:12:15,325][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:12:53,520][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:13:33,416][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:13:33,430][meta_train][INFO] - epoch_85 saved !
[2025-05-01 04:14:12,255][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:14:52,355][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:15:32,655][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:16:10,857][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6091, lr=0.0001
[2025-05-01 04:16:50,561][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:17:29,620][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6072, lr=0.0001
[2025-05-01 04:18:08,631][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:18:47,714][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:18:47,732][meta_train][INFO] - epoch_86 saved !
[2025-05-01 04:19:27,864][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:20:05,760][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:20:45,180][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:21:23,420][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6072, lr=0.0001
[2025-05-01 04:22:02,254][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:22:41,101][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:23:20,143][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:24:00,350][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6091, lr=0.0001
[2025-05-01 04:24:00,371][meta_train][INFO] - epoch_87 saved !
[2025-05-01 04:24:39,851][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:25:17,763][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-05-01 04:25:57,338][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:26:37,173][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:27:16,524][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:27:54,879][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:28:33,799][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:29:12,356][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:29:12,369][meta_train][INFO] - epoch_88 saved !
[2025-05-01 04:29:50,741][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:30:30,753][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:31:10,652][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:31:49,685][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:32:27,886][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:33:07,047][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6087, lr=0.0001
[2025-05-01 04:33:46,686][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:34:25,027][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:34:25,049][meta_train][INFO] - epoch_89 saved !
[2025-05-01 04:35:04,993][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6089, lr=0.0001
[2025-05-01 04:35:44,571][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:36:24,101][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6068, lr=0.0001
[2025-05-01 04:37:02,464][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:37:42,532][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:38:20,658][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:39:00,674][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:39:38,545][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:39:38,559][meta_train][INFO] - epoch_90 saved !
[2025-05-01 04:40:18,034][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6088, lr=0.0001
[2025-05-01 04:40:56,753][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:41:36,108][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:42:16,318][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6068, lr=0.0001
[2025-05-01 04:42:54,111][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6064, lr=0.0001
[2025-05-01 04:43:34,149][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:44:12,758][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:44:51,661][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:44:51,685][meta_train][INFO] - epoch_91 saved !
[2025-05-01 04:45:30,341][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:46:08,508][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:46:48,156][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:47:28,566][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:48:06,835][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:48:45,454][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:49:24,623][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:50:04,979][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6086, lr=0.0001
[2025-05-01 04:50:05,005][meta_train][INFO] - epoch_92 saved !
[2025-05-01 04:50:44,207][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:51:23,378][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:52:02,678][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6064, lr=0.0001
[2025-05-01 04:52:41,100][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:53:18,961][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:53:58,473][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6055, lr=0.0001
[2025-05-01 04:54:38,131][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 04:55:17,654][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:55:17,670][meta_train][INFO] - epoch_93 saved !
[2025-05-01 04:55:57,531][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:56:37,372][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:57:17,485][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:57:57,760][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:58:39,657][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6083, lr=0.0001
[2025-05-01 04:59:19,345][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6064, lr=0.0001
[2025-05-01 05:00:00,313][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 05:00:41,567][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:00:41,580][meta_train][INFO] - epoch_94 saved !
[2025-05-01 05:01:22,537][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:02:03,906][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6083, lr=0.0001
[2025-05-01 05:02:46,167][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:03:26,394][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:04:06,077][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:04:47,097][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:05:29,320][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:06:09,609][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:06:09,634][meta_train][INFO] - epoch_95 saved !
[2025-05-01 05:06:49,662][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:07:30,126][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:08:10,295][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:08:49,369][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:09:28,843][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:10:09,335][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6083, lr=0.0001
[2025-05-01 05:10:50,324][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:11:31,033][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:11:31,050][meta_train][INFO] - epoch_96 saved !
[2025-05-01 05:12:11,214][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:12:51,014][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:13:30,014][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:14:09,940][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:14:51,469][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:15:29,979][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:16:11,034][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:16:51,379][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6082, lr=0.0001
[2025-05-01 05:16:51,389][meta_train][INFO] - epoch_97 saved !
[2025-05-01 05:17:32,067][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:18:11,260][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:18:52,383][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:19:31,216][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:20:11,323][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:20:51,169][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:21:30,968][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:22:11,696][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:22:11,718][meta_train][INFO] - epoch_98 saved !
[2025-05-01 05:22:50,886][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:23:31,642][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:24:11,469][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:24:50,403][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:25:30,656][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:26:10,717][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:26:50,859][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:27:31,083][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:27:31,100][meta_train][INFO] - epoch_99 saved !
[2025-05-01 05:28:11,410][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:28:50,237][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:29:30,316][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:30:10,024][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:30:50,408][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:31:31,262][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:32:11,505][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:32:50,931][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:32:50,941][meta_train][INFO] - epoch_100 saved !
[2025-05-01 11:44:03,653][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 11:44:35,765][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 11:45:04,993][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 11:45:13,737][train][INFO] - Epoch 1/100, Val Acc=0.6087, Val Loss=1.6476, lr=0.0100
[2025-05-01 11:45:21,996][train][INFO] - Epoch 2/100, Val Acc=0.6130, Val Loss=1.6572, lr=0.0100
[2025-05-01 11:45:30,003][train][INFO] - Epoch 3/100, Val Acc=0.6248, Val Loss=1.6061, lr=0.0100
[2025-05-01 11:45:38,062][train][INFO] - Epoch 4/100, Val Acc=0.6433, Val Loss=1.5141, lr=0.0100
[2025-05-01 11:45:46,742][train][INFO] - Epoch 5/100, Val Acc=0.6407, Val Loss=1.5735, lr=0.0100
[2025-05-01 11:45:55,036][train][INFO] - Epoch 6/100, Val Acc=0.6615, Val Loss=1.4623, lr=0.0100
[2025-05-01 11:46:02,851][train][INFO] - Epoch 7/100, Val Acc=0.6550, Val Loss=1.4965, lr=0.0100
[2025-05-01 11:46:11,013][train][INFO] - Epoch 8/100, Val Acc=0.6571, Val Loss=1.5628, lr=0.0100
[2025-05-01 11:46:19,419][train][INFO] - Epoch 9/100, Val Acc=0.6499, Val Loss=1.5558, lr=0.0100
[2025-05-01 11:46:28,489][train][INFO] - Epoch 10/100, Val Acc=0.6550, Val Loss=1.5181, lr=0.0100
[2025-05-01 11:46:37,132][train][INFO] - Epoch 11/100, Val Acc=0.6772, Val Loss=1.4299, lr=0.0100
[2025-05-01 11:46:44,946][train][INFO] - Epoch 12/100, Val Acc=0.6580, Val Loss=1.5072, lr=0.0100
[2025-05-01 11:46:53,121][train][INFO] - Epoch 13/100, Val Acc=0.6585, Val Loss=1.5412, lr=0.0100
[2025-05-01 11:47:01,551][train][INFO] - Epoch 14/100, Val Acc=0.6786, Val Loss=1.5074, lr=0.0100
[2025-05-01 11:47:09,810][train][INFO] - Epoch 15/100, Val Acc=0.6617, Val Loss=1.5728, lr=0.0100
[2025-05-01 11:47:17,732][train][INFO] - Epoch 16/100, Val Acc=0.6681, Val Loss=1.5066, lr=0.0100
[2025-05-01 11:47:24,989][train][INFO] - Epoch 17/100, Val Acc=0.6870, Val Loss=1.4066, lr=0.0100
[2025-05-01 11:47:33,295][train][INFO] - Epoch 18/100, Val Acc=0.6651, Val Loss=1.5411, lr=0.0100
[2025-05-01 11:47:41,121][train][INFO] - Epoch 19/100, Val Acc=0.6737, Val Loss=1.5166, lr=0.0100
[2025-05-01 11:47:49,993][train][INFO] - Epoch 20/100, Val Acc=0.6717, Val Loss=1.5219, lr=0.0100
[2025-05-01 11:47:57,851][train][INFO] - Epoch 21/100, Val Acc=0.6805, Val Loss=1.4347, lr=0.0100
[2025-05-01 11:48:06,058][train][INFO] - Epoch 22/100, Val Acc=0.6693, Val Loss=1.5336, lr=0.0100
[2025-05-01 11:48:13,752][train][INFO] - Epoch 23/100, Val Acc=0.6820, Val Loss=1.4631, lr=0.0100
[2025-05-01 11:48:21,648][train][INFO] - Epoch 24/100, Val Acc=0.6793, Val Loss=1.4986, lr=0.0100
[2025-05-01 11:48:30,013][train][INFO] - Epoch 25/100, Val Acc=0.6760, Val Loss=1.5220, lr=0.0100
[2025-05-01 11:48:38,525][train][INFO] - Epoch 26/100, Val Acc=0.6807, Val Loss=1.5162, lr=0.0100
[2025-05-01 11:48:46,700][train][INFO] - Epoch 27/100, Val Acc=0.6702, Val Loss=1.5688, lr=0.0100
[2025-05-01 11:48:55,079][train][INFO] - Epoch 28/100, Val Acc=0.6706, Val Loss=1.5441, lr=0.0100
[2025-05-01 11:49:03,078][train][INFO] - Epoch 29/100, Val Acc=0.6557, Val Loss=1.6561, lr=0.0100
[2025-05-01 11:49:11,447][train][INFO] - Epoch 30/100, Val Acc=0.6761, Val Loss=1.5481, lr=0.0100
[2025-05-01 11:49:18,815][train][INFO] - Epoch 31/100, Val Acc=0.6792, Val Loss=1.4999, lr=0.0100
[2025-05-01 11:49:27,488][train][INFO] - Epoch 32/100, Val Acc=0.6735, Val Loss=1.5509, lr=0.0100
[2025-05-01 11:49:35,680][train][INFO] - Epoch 33/100, Val Acc=0.6647, Val Loss=1.5593, lr=0.0100
[2025-05-01 11:49:43,982][train][INFO] - Epoch 34/100, Val Acc=0.6764, Val Loss=1.5105, lr=0.0100
[2025-05-01 11:49:52,268][train][INFO] - Epoch 35/100, Val Acc=0.6728, Val Loss=1.5446, lr=0.0100
[2025-05-01 11:50:00,616][train][INFO] - Epoch 36/100, Val Acc=0.6698, Val Loss=1.5613, lr=0.0100
[2025-05-01 11:50:09,689][train][INFO] - Epoch 37/100, Val Acc=0.6718, Val Loss=1.5142, lr=0.0100
[2025-05-01 11:50:17,077][train][INFO] - Epoch 38/100, Val Acc=0.6816, Val Loss=1.4852, lr=0.0100
[2025-05-01 11:50:24,997][train][INFO] - Epoch 39/100, Val Acc=0.6804, Val Loss=1.4926, lr=0.0100
[2025-05-01 11:50:33,021][train][INFO] - Epoch 40/100, Val Acc=0.6737, Val Loss=1.5205, lr=0.0100
[2025-05-01 11:50:41,172][train][INFO] - Epoch 41/100, Val Acc=0.6753, Val Loss=1.5343, lr=0.0100
[2025-05-01 11:50:50,005][train][INFO] - Epoch 42/100, Val Acc=0.6777, Val Loss=1.5098, lr=0.0100
[2025-05-01 11:50:58,778][train][INFO] - Epoch 43/100, Val Acc=0.6801, Val Loss=1.4731, lr=0.0100
[2025-05-01 11:51:07,830][train][INFO] - Epoch 44/100, Val Acc=0.6687, Val Loss=1.5526, lr=0.0100
[2025-05-01 11:51:16,675][train][INFO] - Epoch 45/100, Val Acc=0.6716, Val Loss=1.5366, lr=0.0100
[2025-05-01 11:51:24,822][train][INFO] - Epoch 46/100, Val Acc=0.6782, Val Loss=1.5464, lr=0.0100
[2025-05-01 11:51:32,998][train][INFO] - Epoch 47/100, Val Acc=0.6698, Val Loss=1.5436, lr=0.0100
[2025-05-01 11:51:41,674][train][INFO] - Epoch 48/100, Val Acc=0.6716, Val Loss=1.5714, lr=0.0100
[2025-05-01 11:51:49,834][train][INFO] - Epoch 49/100, Val Acc=0.6752, Val Loss=1.5529, lr=0.0100
[2025-05-01 11:51:58,524][train][INFO] - Epoch 50/100, Val Acc=0.6737, Val Loss=1.5448, lr=0.0100
[2025-05-01 11:52:07,094][train][INFO] - Epoch 51/100, Val Acc=0.6630, Val Loss=1.5604, lr=0.0100
[2025-05-01 11:52:15,814][train][INFO] - Epoch 52/100, Val Acc=0.6734, Val Loss=1.5669, lr=0.0100
[2025-05-01 11:52:23,581][train][INFO] - Epoch 53/100, Val Acc=0.6715, Val Loss=1.5753, lr=0.0100
[2025-05-01 11:52:32,049][train][INFO] - Epoch 54/100, Val Acc=0.6763, Val Loss=1.4942, lr=0.0100
[2025-05-01 11:52:40,803][train][INFO] - Epoch 55/100, Val Acc=0.6732, Val Loss=1.5552, lr=0.0100
[2025-05-01 11:52:47,727][train][INFO] - Epoch 56/100, Val Acc=0.6560, Val Loss=1.6783, lr=0.0100
[2025-05-01 11:52:55,544][train][INFO] - Epoch 57/100, Val Acc=0.6798, Val Loss=1.5230, lr=0.0100
[2025-05-01 11:53:03,538][train][INFO] - Epoch 58/100, Val Acc=0.6672, Val Loss=1.5792, lr=0.0100
[2025-05-01 11:53:11,830][train][INFO] - Epoch 59/100, Val Acc=0.6537, Val Loss=1.6794, lr=0.0100
[2025-05-01 11:53:20,005][train][INFO] - Epoch 60/100, Val Acc=0.6744, Val Loss=1.5546, lr=0.0100
[2025-05-01 11:53:28,331][train][INFO] - Epoch 61/100, Val Acc=0.7233, Val Loss=1.2964, lr=0.0010
[2025-05-01 11:53:36,453][train][INFO] - Epoch 62/100, Val Acc=0.7283, Val Loss=1.2836, lr=0.0010
[2025-05-01 11:53:44,609][train][INFO] - Epoch 63/100, Val Acc=0.7315, Val Loss=1.2998, lr=0.0010
[2025-05-01 11:53:52,713][train][INFO] - Epoch 64/100, Val Acc=0.7299, Val Loss=1.2992, lr=0.0010
[2025-05-01 11:54:00,579][train][INFO] - Epoch 65/100, Val Acc=0.7333, Val Loss=1.3034, lr=0.0010
[2025-05-01 11:54:08,639][train][INFO] - Epoch 66/100, Val Acc=0.7316, Val Loss=1.3103, lr=0.0010
[2025-05-01 11:54:17,564][train][INFO] - Epoch 67/100, Val Acc=0.7326, Val Loss=1.3113, lr=0.0010
[2025-05-01 11:54:26,117][train][INFO] - Epoch 68/100, Val Acc=0.7360, Val Loss=1.3100, lr=0.0010
[2025-05-01 11:54:34,131][train][INFO] - Epoch 69/100, Val Acc=0.7365, Val Loss=1.3156, lr=0.0010
[2025-05-01 11:54:42,453][train][INFO] - Epoch 70/100, Val Acc=0.7352, Val Loss=1.3227, lr=0.0010
[2025-05-01 11:54:51,187][train][INFO] - Epoch 71/100, Val Acc=0.7338, Val Loss=1.3248, lr=0.0010
[2025-05-01 11:54:59,941][train][INFO] - Epoch 72/100, Val Acc=0.7364, Val Loss=1.3299, lr=0.0010
[2025-05-01 11:55:08,663][train][INFO] - Epoch 73/100, Val Acc=0.7375, Val Loss=1.3243, lr=0.0010
[2025-05-01 11:55:16,844][train][INFO] - Epoch 74/100, Val Acc=0.7360, Val Loss=1.3221, lr=0.0010
[2025-05-01 11:55:25,313][train][INFO] - Epoch 75/100, Val Acc=0.7367, Val Loss=1.3240, lr=0.0010
[2025-05-01 11:55:32,840][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3159, lr=0.0010
[2025-05-01 11:55:40,645][train][INFO] - Epoch 77/100, Val Acc=0.7374, Val Loss=1.3225, lr=0.0010
[2025-05-01 11:55:47,929][train][INFO] - Epoch 78/100, Val Acc=0.7384, Val Loss=1.3189, lr=0.0010
[2025-05-01 11:55:56,711][train][INFO] - Epoch 79/100, Val Acc=0.7368, Val Loss=1.3276, lr=0.0010
[2025-05-01 11:56:05,062][train][INFO] - Epoch 80/100, Val Acc=0.7372, Val Loss=1.3189, lr=0.0010
[2025-05-01 11:56:13,306][train][INFO] - Epoch 81/100, Val Acc=0.7384, Val Loss=1.3231, lr=0.0010
[2025-05-01 11:56:21,893][train][INFO] - Epoch 82/100, Val Acc=0.7413, Val Loss=1.3198, lr=0.0010
[2025-05-01 11:56:30,096][train][INFO] - Epoch 83/100, Val Acc=0.7402, Val Loss=1.3208, lr=0.0010
[2025-05-01 11:56:38,058][train][INFO] - Epoch 84/100, Val Acc=0.7401, Val Loss=1.3150, lr=0.0010
[2025-05-01 11:56:46,048][train][INFO] - Epoch 85/100, Val Acc=0.7398, Val Loss=1.3182, lr=0.0010
[2025-05-01 11:56:53,466][train][INFO] - Epoch 86/100, Val Acc=0.7413, Val Loss=1.3171, lr=0.0010
[2025-05-01 11:57:01,499][train][INFO] - Epoch 87/100, Val Acc=0.7414, Val Loss=1.3109, lr=0.0010
[2025-05-01 11:57:09,772][train][INFO] - Epoch 88/100, Val Acc=0.7393, Val Loss=1.3140, lr=0.0010
[2025-05-01 11:57:17,559][train][INFO] - Epoch 89/100, Val Acc=0.7399, Val Loss=1.3115, lr=0.0010
[2025-05-01 11:57:25,450][train][INFO] - Epoch 90/100, Val Acc=0.7383, Val Loss=1.3233, lr=0.0010
[2025-05-01 11:57:34,073][train][INFO] - Epoch 91/100, Val Acc=0.7389, Val Loss=1.3172, lr=0.0001
[2025-05-01 11:57:42,388][train][INFO] - Epoch 92/100, Val Acc=0.7400, Val Loss=1.3199, lr=0.0001
[2025-05-01 11:57:50,539][train][INFO] - Epoch 93/100, Val Acc=0.7388, Val Loss=1.3140, lr=0.0001
[2025-05-01 11:57:58,680][train][INFO] - Epoch 94/100, Val Acc=0.7409, Val Loss=1.3118, lr=0.0001
[2025-05-01 11:58:06,320][train][INFO] - Epoch 95/100, Val Acc=0.7386, Val Loss=1.3203, lr=0.0001
[2025-05-01 11:58:13,664][train][INFO] - Epoch 96/100, Val Acc=0.7392, Val Loss=1.3186, lr=0.0001
[2025-05-01 11:58:21,681][train][INFO] - Epoch 97/100, Val Acc=0.7399, Val Loss=1.3162, lr=0.0001
[2025-05-01 11:58:29,618][train][INFO] - Epoch 98/100, Val Acc=0.7415, Val Loss=1.3137, lr=0.0001
[2025-05-01 11:58:37,572][train][INFO] - Epoch 99/100, Val Acc=0.7400, Val Loss=1.3172, lr=0.0001
[2025-05-01 11:58:45,360][train][INFO] - Epoch 100/100, Val Acc=0.7378, Val Loss=1.3207, lr=0.0001
[2025-05-01 11:58:50,371][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7415
[2025-05-01 11:58:50,375][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 12:00:42,276][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 12:02:38,328][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 12:02:38,770][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 12:41:43,706][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-01 12:41:43,800][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 12:41:43,801][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 12:41:43,801][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 12:42:26,009][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-05-01 12:43:03,076][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8054, lr=0.001
[2025-05-01 12:43:40,218][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6650, lr=0.001
[2025-05-01 12:44:16,062][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8170, lr=0.001
[2025-05-01 12:44:53,968][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.8789, lr=0.001
[2025-05-01 12:45:31,266][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9001, lr=0.001
[2025-05-01 12:46:08,701][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7399, lr=0.001
[2025-05-01 12:46:44,856][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4222, lr=0.001
[2025-05-01 12:46:44,875][meta_train][INFO] - epoch_1 saved !
[2025-05-01 12:47:22,711][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3554, lr=0.001
[2025-05-01 12:47:58,328][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1076, lr=0.001
[2025-05-01 12:48:35,269][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1257, lr=0.001
[2025-05-01 12:49:12,852][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.2335, lr=0.001
[2025-05-01 12:49:51,119][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0825, lr=0.001
[2025-05-01 12:50:26,337][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0752, lr=0.001
[2025-05-01 12:51:03,951][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0667, lr=0.001
[2025-05-01 12:51:41,392][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0571, lr=0.001
[2025-05-01 12:51:41,412][meta_train][INFO] - epoch_2 saved !
[2025-05-01 12:52:18,085][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.0852, lr=0.001
[2025-05-01 12:52:55,070][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0791, lr=0.001
[2025-05-01 12:53:32,082][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0776, lr=0.001
[2025-05-01 12:54:07,838][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.0982, lr=0.001
[2025-05-01 12:54:45,627][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2242, lr=0.001
[2025-05-01 12:55:22,755][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2048, lr=0.001
[2025-05-01 12:56:00,035][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1049, lr=0.001
[2025-05-01 12:56:36,746][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1000, lr=0.001
[2025-05-01 12:56:36,759][meta_train][INFO] - epoch_3 saved !
[2025-05-01 12:57:13,349][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1212, lr=0.001
[2025-05-01 12:57:50,034][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1225, lr=0.001
[2025-05-01 12:58:27,797][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.2522, lr=0.001
[2025-05-01 12:59:04,304][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1173, lr=0.001
[2025-05-01 12:59:43,071][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1231, lr=0.001
[2025-05-01 13:00:18,635][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.2112, lr=0.001
[2025-05-01 13:00:55,677][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.3869, lr=0.001
[2025-05-01 13:01:32,154][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.1797, lr=0.001
[2025-05-01 13:01:32,177][meta_train][INFO] - epoch_4 saved !
[2025-05-01 13:02:09,330][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.3443, lr=0.001
[2025-05-01 13:02:47,350][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.1748, lr=0.001
[2025-05-01 13:03:25,371][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.2491, lr=0.001
[2025-05-01 13:04:01,849][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.2513, lr=0.001
[2025-05-01 13:04:39,355][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=0.6399, lr=0.001
[2025-05-01 13:05:15,925][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.3194, lr=0.001
[2025-05-01 13:05:52,318][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.4219, lr=0.001
[2025-05-01 13:06:28,903][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.3403, lr=0.001
[2025-05-01 13:06:28,913][meta_train][INFO] - epoch_5 saved !
[2025-05-01 13:07:05,091][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=0.7997, lr=0.001
[2025-05-01 13:07:43,255][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.2902, lr=0.001
[2025-05-01 13:08:19,456][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.4564, lr=0.001
[2025-05-01 13:08:56,945][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=0.5632, lr=0.001
[2025-05-01 13:09:33,749][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.3177, lr=0.001
[2025-05-01 13:10:10,331][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.3453, lr=0.001
[2025-05-01 13:10:47,686][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.3072, lr=0.001
[2025-05-01 13:11:25,543][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.3339, lr=0.001
[2025-05-01 13:11:25,564][meta_train][INFO] - epoch_6 saved !
[2025-05-01 13:12:01,330][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=0.5760, lr=0.001
[2025-05-01 13:12:39,162][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=0.6666, lr=0.001
[2025-05-01 13:13:16,504][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.3024, lr=0.001
[2025-05-01 13:13:53,049][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.4275, lr=0.001
[2025-05-01 13:14:29,088][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.2487, lr=0.001
[2025-05-01 13:15:06,942][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.2335, lr=0.001
[2025-05-01 13:15:45,173][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.2636, lr=0.001
[2025-05-01 13:16:21,547][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.2809, lr=0.001
[2025-05-01 13:16:21,559][meta_train][INFO] - epoch_7 saved !
[2025-05-01 13:16:58,601][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.2743, lr=0.001
[2025-05-01 13:17:35,394][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.2842, lr=0.001
[2025-05-01 13:18:12,806][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.2406, lr=0.001
[2025-05-01 13:18:49,918][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.5674, lr=0.001
[2025-05-01 13:19:27,015][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.2337, lr=0.001
[2025-05-01 13:20:04,811][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.2148, lr=0.001
[2025-05-01 13:20:40,831][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.4072, lr=0.001
[2025-05-01 13:21:18,725][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.4274, lr=0.001
[2025-05-01 13:21:18,737][meta_train][INFO] - epoch_8 saved !
[2025-05-01 13:21:54,992][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.2075, lr=0.001
[2025-05-01 13:22:32,408][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.2202, lr=0.001
[2025-05-01 13:23:08,687][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.1966, lr=0.001
[2025-05-01 13:23:45,485][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.4453, lr=0.001
[2025-05-01 13:24:22,035][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.5933, lr=0.001
[2025-05-01 13:24:58,557][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.4373, lr=0.001
[2025-05-01 13:25:36,918][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.2809, lr=0.001
[2025-05-01 13:26:14,274][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2327, lr=0.001
[2025-05-01 13:26:14,290][meta_train][INFO] - epoch_9 saved !
[2025-05-01 13:26:50,389][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.3388, lr=0.001
[2025-05-01 13:27:28,385][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3388, lr=0.001
[2025-05-01 13:28:04,381][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4107, lr=0.001
[2025-05-01 13:28:42,033][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.8359, lr=0.001
[2025-05-01 13:29:19,318][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6126, lr=0.001
[2025-05-01 13:29:54,916][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.0799, lr=0.001
[2025-05-01 13:30:32,593][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.8904, lr=0.001
[2025-05-01 13:31:10,406][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.5186, lr=0.001
[2025-05-01 13:31:10,430][meta_train][INFO] - epoch_10 saved !
[2025-05-01 13:31:46,904][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=0.8725, lr=0.001
[2025-05-01 13:32:23,193][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.6354, lr=0.001
[2025-05-01 13:33:01,370][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.8063, lr=0.001
[2025-05-01 13:33:38,553][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=1.0392, lr=0.001
[2025-05-01 13:34:14,975][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.4816, lr=0.001
[2025-05-01 13:34:52,200][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.6638, lr=0.001
[2025-05-01 13:35:27,856][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=0.9407, lr=0.001
[2025-05-01 13:36:05,681][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=1.3799, lr=0.001
[2025-05-01 13:36:05,697][meta_train][INFO] - epoch_11 saved !
[2025-05-01 13:36:42,732][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=1.3544, lr=0.001
[2025-05-01 13:37:19,970][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=1.2919, lr=0.001
[2025-05-01 13:37:57,402][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=1.9023, lr=0.001
[2025-05-01 13:38:35,124][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=2.7865, lr=0.001
[2025-05-01 13:39:11,595][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=2.8045, lr=0.001
[2025-05-01 13:39:48,370][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=2.2700, lr=0.001
[2025-05-01 13:40:25,926][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=2.7282, lr=0.001
[2025-05-01 13:41:02,399][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=2.2081, lr=0.001
[2025-05-01 13:41:02,419][meta_train][INFO] - epoch_12 saved !
[2025-05-01 13:41:38,983][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=2.0904, lr=0.001
[2025-05-01 13:42:16,736][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=2.5145, lr=0.001
[2025-05-01 13:42:53,651][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=2.5717, lr=0.001
[2025-05-01 13:43:31,483][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=2.8387, lr=0.001
[2025-05-01 13:44:08,666][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=3.1814, lr=0.001
[2025-05-01 13:44:44,883][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=3.2589, lr=0.001
[2025-05-01 13:45:21,333][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=3.6104, lr=0.001
[2025-05-01 13:45:59,431][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=3.7792, lr=0.001
[2025-05-01 13:45:59,452][meta_train][INFO] - epoch_13 saved !
[2025-05-01 13:46:35,907][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.1598, lr=0.001
[2025-05-01 13:47:12,889][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.3716, lr=0.001
[2025-05-01 13:47:50,413][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.5737, lr=0.001
[2025-05-01 13:48:26,294][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6633, lr=0.001
[2025-05-01 13:49:03,879][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.7552, lr=0.001
[2025-05-01 13:49:42,229][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.6567, lr=0.001
[2025-05-01 13:50:18,900][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=4.6530, lr=0.001
[2025-05-01 13:50:54,371][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6751, lr=0.001
[2025-05-01 13:50:54,393][meta_train][INFO] - epoch_14 saved !
[2025-05-01 13:51:32,651][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.7296, lr=0.001
[2025-05-01 13:52:07,773][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6930, lr=0.001
[2025-05-01 13:52:45,289][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=4.6514, lr=0.001
[2025-05-01 13:53:21,098][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.6469, lr=0.001
[2025-05-01 13:53:58,155][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.6493, lr=0.001
[2025-05-01 13:54:34,925][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6447, lr=0.001
[2025-05-01 13:55:12,382][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.6477, lr=0.001
[2025-05-01 13:55:50,767][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6472, lr=0.001
[2025-05-01 13:55:50,777][meta_train][INFO] - epoch_15 saved !
[2025-05-01 13:56:27,430][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.6455, lr=0.001
[2025-05-01 13:57:03,526][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6372, lr=0.001
[2025-05-01 13:57:40,830][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.6421, lr=0.001
[2025-05-01 13:58:19,006][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6471, lr=0.001
[2025-05-01 13:58:54,739][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=4.6346, lr=0.001
[2025-05-01 13:59:31,554][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.6225, lr=0.001
[2025-05-01 14:00:09,082][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.6210, lr=0.001
[2025-05-01 14:00:45,266][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6440, lr=0.001
[2025-05-01 14:00:45,290][meta_train][INFO] - epoch_16 saved !
[2025-05-01 14:01:22,907][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.6338, lr=0.001
[2025-05-01 14:02:00,766][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.6254, lr=0.001
[2025-05-01 14:02:36,232][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6414, lr=0.001
[2025-05-01 14:03:13,461][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=4.6267, lr=0.001
[2025-05-01 14:03:51,259][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.6175, lr=0.001
[2025-05-01 14:04:28,571][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6334, lr=0.001
[2025-05-01 14:05:06,508][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.6388, lr=0.001
[2025-05-01 14:05:42,291][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6354, lr=0.001
[2025-05-01 14:05:42,312][meta_train][INFO] - epoch_17 saved !
[2025-05-01 14:06:19,669][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6271, lr=0.001
[2025-05-01 14:06:56,353][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.6171, lr=0.001
[2025-05-01 14:07:33,402][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6315, lr=0.001
[2025-05-01 14:08:10,779][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6221, lr=0.001
[2025-05-01 14:08:48,093][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.6317, lr=0.001
[2025-05-01 14:09:23,266][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6253, lr=0.001
[2025-05-01 14:10:00,994][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.6143, lr=0.001
[2025-05-01 14:10:38,738][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.6250, lr=0.001
[2025-05-01 14:10:38,759][meta_train][INFO] - epoch_18 saved !
[2025-05-01 14:11:15,987][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6252, lr=0.001
[2025-05-01 14:11:52,807][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6181, lr=0.001
[2025-05-01 14:12:29,008][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.6213, lr=0.001
[2025-05-01 14:13:05,211][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6245, lr=0.001
[2025-05-01 14:13:42,023][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.6179, lr=0.001
[2025-05-01 14:14:19,756][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.6283, lr=0.001
[2025-05-01 14:14:55,869][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6267, lr=0.001
[2025-05-01 14:15:33,083][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.6121, lr=0.001
[2025-05-01 14:15:33,092][meta_train][INFO] - epoch_19 saved !
[2025-05-01 14:16:08,785][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.6273, lr=0.001
[2025-05-01 14:16:46,375][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.6119, lr=0.001
[2025-05-01 14:17:23,824][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6157, lr=0.001
[2025-05-01 14:18:00,927][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6176, lr=0.001
[2025-05-01 14:18:37,195][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6194, lr=0.001
[2025-05-01 14:19:13,585][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.6154, lr=0.001
[2025-05-01 14:19:50,539][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.6186, lr=0.001
[2025-05-01 14:20:26,145][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6234, lr=0.001
[2025-05-01 14:20:26,154][meta_train][INFO] - epoch_20 saved !
[2025-05-01 14:21:02,944][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.6177, lr=0.001
[2025-05-01 14:21:40,164][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6161, lr=0.001
[2025-05-01 14:22:17,332][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.6104, lr=0.001
[2025-05-01 14:22:55,088][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6139, lr=0.001
[2025-05-01 14:23:31,636][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.6207, lr=0.001
[2025-05-01 14:24:08,611][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6158, lr=0.001
[2025-05-01 14:24:44,409][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6138, lr=0.001
[2025-05-01 14:25:21,790][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6206, lr=0.001
[2025-05-01 14:25:21,800][meta_train][INFO] - epoch_21 saved !
[2025-05-01 14:25:58,275][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6202, lr=0.001
[2025-05-01 14:26:34,754][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6097, lr=0.001
[2025-05-01 14:27:12,079][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6127, lr=0.001
[2025-05-01 14:27:48,439][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6118, lr=0.001
[2025-05-01 14:28:24,293][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6150, lr=0.001
[2025-05-01 14:29:00,228][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.6143, lr=0.001
[2025-05-01 14:29:38,167][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6132, lr=0.001
[2025-05-01 14:30:15,106][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6177, lr=0.001
[2025-05-01 14:30:15,122][meta_train][INFO] - epoch_22 saved !
[2025-05-01 14:30:51,118][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6115, lr=0.001
[2025-05-01 14:31:29,038][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6089, lr=0.001
[2025-05-01 14:32:06,361][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6169, lr=0.001
[2025-05-01 14:32:43,525][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6176, lr=0.001
[2025-05-01 14:33:19,310][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6131, lr=0.001
[2025-05-01 14:33:56,609][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6122, lr=0.001
[2025-05-01 14:34:33,898][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6110, lr=0.001
[2025-05-01 14:35:09,750][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.6119, lr=0.001
[2025-05-01 14:35:09,775][meta_train][INFO] - epoch_23 saved !
[2025-05-01 14:35:47,606][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6106, lr=0.001
[2025-05-01 14:36:23,267][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6119, lr=0.001
[2025-05-01 14:37:00,036][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6155, lr=0.001
[2025-05-01 14:37:37,511][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6140, lr=0.001
[2025-05-01 14:38:14,641][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6106, lr=0.001
[2025-05-01 14:38:50,389][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6088, lr=0.001
[2025-05-01 14:39:26,939][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.6102, lr=0.001
[2025-05-01 14:40:04,504][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6074, lr=0.001
[2025-05-01 14:40:04,514][meta_train][INFO] - epoch_24 saved !
[2025-05-01 14:40:42,559][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6092, lr=0.001
[2025-05-01 14:41:19,489][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-01 14:41:55,048][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.6094, lr=0.001
[2025-05-01 14:42:33,489][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6092, lr=0.001
[2025-05-01 14:43:09,219][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6094, lr=0.001
[2025-05-01 14:43:45,277][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6126, lr=0.001
[2025-05-01 14:44:22,810][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6075, lr=0.001
[2025-05-01 14:44:59,475][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6108, lr=0.001
[2025-05-01 14:44:59,501][meta_train][INFO] - epoch_25 saved !
[2025-05-01 14:45:35,703][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6088, lr=0.001
[2025-05-01 14:46:11,779][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6118, lr=0.001
[2025-05-01 14:46:49,036][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.6081, lr=0.001
[2025-05-01 14:47:24,471][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6078, lr=0.001
[2025-05-01 14:48:01,807][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6079, lr=0.001
[2025-05-01 14:48:38,526][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6064, lr=0.001
[2025-05-01 14:49:15,576][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6095, lr=0.001
[2025-05-01 14:49:52,301][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6068, lr=0.001
[2025-05-01 14:49:52,322][meta_train][INFO] - epoch_26 saved !
[2025-05-01 14:50:28,754][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6067, lr=0.001
[2025-05-01 14:51:05,896][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6104, lr=0.001
[2025-05-01 14:51:42,550][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6073, lr=0.001
[2025-05-01 14:52:19,242][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.6072, lr=0.001
[2025-05-01 14:52:54,946][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6074, lr=0.001
[2025-05-01 14:53:32,187][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 14:54:08,445][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6084, lr=0.001
[2025-05-01 14:54:46,034][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6069, lr=0.001
[2025-05-01 14:54:46,052][meta_train][INFO] - epoch_27 saved !
[2025-05-01 14:55:22,285][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6095, lr=0.001
[2025-05-01 14:55:59,252][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6059, lr=0.001
[2025-05-01 14:56:36,960][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.6067, lr=0.001
[2025-05-01 14:57:13,833][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6067, lr=0.001
[2025-05-01 14:57:50,430][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6061, lr=0.001
[2025-05-01 14:58:26,350][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6066, lr=0.001
[2025-05-01 14:59:03,960][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6077, lr=0.001
[2025-05-01 14:59:38,730][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6067, lr=0.001
[2025-05-01 14:59:38,740][meta_train][INFO] - epoch_28 saved !
[2025-05-01 15:00:16,200][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6065, lr=0.001
[2025-05-01 15:00:53,089][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6060, lr=0.001
[2025-05-01 15:01:29,205][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6063, lr=0.001
[2025-05-01 15:02:06,705][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6085, lr=0.001
[2025-05-01 15:02:42,570][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 15:03:19,098][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6064, lr=0.001
[2025-05-01 15:03:57,037][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6072, lr=0.001
[2025-05-01 15:04:33,469][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6062, lr=0.001
[2025-05-01 15:04:33,478][meta_train][INFO] - epoch_29 saved !
[2025-05-01 15:05:10,419][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6082, lr=0.001
[2025-05-01 15:05:46,976][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6063, lr=0.001
[2025-05-01 15:06:23,287][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 15:07:01,214][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6061, lr=0.001
[2025-05-01 15:07:37,678][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6070, lr=0.001
[2025-05-01 15:08:14,189][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 15:08:50,971][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 15:09:29,008][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6060, lr=0.001
[2025-05-01 15:09:29,033][meta_train][INFO] - epoch_30 saved !
[2025-05-01 15:10:05,221][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 15:10:42,589][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6077, lr=0.001
[2025-05-01 15:11:18,695][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 15:11:56,089][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6068, lr=0.001
[2025-05-01 15:12:32,706][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6060, lr=0.001
[2025-05-01 15:13:09,535][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 15:13:46,280][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6059, lr=0.001
[2025-05-01 15:14:22,878][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 15:14:22,888][meta_train][INFO] - epoch_31 saved !
[2025-05-01 15:15:00,032][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6060, lr=0.001
[2025-05-01 15:15:35,962][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6058, lr=0.001
[2025-05-01 15:16:13,642][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:16:50,488][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6059, lr=0.001
[2025-05-01 15:17:27,173][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 15:18:02,950][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6059, lr=0.001
[2025-05-01 15:18:40,378][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6065, lr=0.001
[2025-05-01 15:19:08,038][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 15:19:17,161][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6072, lr=0.001
[2025-05-01 15:19:17,171][meta_train][INFO] - epoch_32 saved !
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 15:19:37,397][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 15:19:45,829][train][INFO] - Epoch 1/100, Val Acc=0.0706, Val Loss=3.8937, lr=0.0100
[2025-05-01 15:19:54,245][train][INFO] - Epoch 2/100, Val Acc=0.2108, Val Loss=2.9731, lr=0.0100
[2025-05-01 15:19:55,122][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:20:02,808][train][INFO] - Epoch 3/100, Val Acc=0.2912, Val Loss=2.7967, lr=0.0100
[2025-05-01 15:20:10,383][train][INFO] - Epoch 4/100, Val Acc=0.4286, Val Loss=2.0857, lr=0.0100
[2025-05-01 15:20:18,538][train][INFO] - Epoch 5/100, Val Acc=0.4561, Val Loss=2.0563, lr=0.0100
[2025-05-01 15:20:26,692][train][INFO] - Epoch 6/100, Val Acc=0.4436, Val Loss=2.2707, lr=0.0100
[2025-05-01 15:20:32,310][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6071, lr=0.001
[2025-05-01 15:20:34,626][train][INFO] - Epoch 7/100, Val Acc=0.5218, Val Loss=1.8155, lr=0.0100
[2025-05-01 15:20:42,686][train][INFO] - Epoch 8/100, Val Acc=0.5249, Val Loss=1.8638, lr=0.0100
[2025-05-01 15:20:50,737][train][INFO] - Epoch 9/100, Val Acc=0.5352, Val Loss=1.8255, lr=0.0100
[2025-05-01 15:20:58,713][train][INFO] - Epoch 10/100, Val Acc=0.5553, Val Loss=1.7265, lr=0.0100
[2025-05-01 15:21:05,980][train][INFO] - Epoch 11/100, Val Acc=0.5912, Val Loss=1.5787, lr=0.0100
[2025-05-01 15:21:09,159][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 15:21:14,328][train][INFO] - Epoch 12/100, Val Acc=0.5757, Val Loss=1.6837, lr=0.0100
[2025-05-01 15:21:22,581][train][INFO] - Epoch 13/100, Val Acc=0.5847, Val Loss=1.6419, lr=0.0100
[2025-05-01 15:21:30,294][train][INFO] - Epoch 14/100, Val Acc=0.5962, Val Loss=1.5629, lr=0.0100
[2025-05-01 15:21:38,149][train][INFO] - Epoch 15/100, Val Acc=0.5978, Val Loss=1.6183, lr=0.0100
[2025-05-01 15:21:45,728][train][INFO] - Epoch 16/100, Val Acc=0.6105, Val Loss=1.5315, lr=0.0100
[2025-05-01 15:21:47,502][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.6064, lr=0.001
[2025-05-01 15:21:53,607][train][INFO] - Epoch 17/100, Val Acc=0.5738, Val Loss=1.7595, lr=0.0100
[2025-05-01 15:22:01,604][train][INFO] - Epoch 18/100, Val Acc=0.6279, Val Loss=1.4818, lr=0.0100
[2025-05-01 15:22:09,744][train][INFO] - Epoch 19/100, Val Acc=0.6344, Val Loss=1.4927, lr=0.0100
[2025-05-01 15:22:18,443][train][INFO] - Epoch 20/100, Val Acc=0.6238, Val Loss=1.5212, lr=0.0100
[2025-05-01 15:22:24,099][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 15:22:26,322][train][INFO] - Epoch 21/100, Val Acc=0.6147, Val Loss=1.5916, lr=0.0100
[2025-05-01 15:22:34,596][train][INFO] - Epoch 22/100, Val Acc=0.6151, Val Loss=1.6332, lr=0.0100
[2025-05-01 15:22:42,173][train][INFO] - Epoch 23/100, Val Acc=0.6109, Val Loss=1.6300, lr=0.0100
[2025-05-01 15:22:49,759][train][INFO] - Epoch 24/100, Val Acc=0.6447, Val Loss=1.4446, lr=0.0100
[2025-05-01 15:22:58,539][train][INFO] - Epoch 25/100, Val Acc=0.6389, Val Loss=1.5132, lr=0.0100
[2025-05-01 15:23:02,665][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 15:23:06,318][train][INFO] - Epoch 26/100, Val Acc=0.6126, Val Loss=1.6543, lr=0.0100
[2025-05-01 15:23:14,199][train][INFO] - Epoch 27/100, Val Acc=0.6025, Val Loss=1.7044, lr=0.0100
[2025-05-01 15:23:22,300][train][INFO] - Epoch 28/100, Val Acc=0.6349, Val Loss=1.5484, lr=0.0100
[2025-05-01 15:23:30,486][train][INFO] - Epoch 29/100, Val Acc=0.6474, Val Loss=1.4652, lr=0.0100
[2025-05-01 15:23:38,319][train][INFO] - Epoch 30/100, Val Acc=0.6550, Val Loss=1.4441, lr=0.0100
[2025-05-01 15:23:39,996][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 15:23:46,871][train][INFO] - Epoch 31/100, Val Acc=0.6458, Val Loss=1.5034, lr=0.0100
[2025-05-01 15:23:55,201][train][INFO] - Epoch 32/100, Val Acc=0.6276, Val Loss=1.5984, lr=0.0100
[2025-05-01 15:24:03,175][train][INFO] - Epoch 33/100, Val Acc=0.6379, Val Loss=1.5567, lr=0.0100
[2025-05-01 15:24:11,262][train][INFO] - Epoch 34/100, Val Acc=0.6523, Val Loss=1.4781, lr=0.0100
[2025-05-01 15:24:18,029][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 15:24:18,049][meta_train][INFO] - epoch_33 saved !
[2025-05-01 15:24:19,600][train][INFO] - Epoch 35/100, Val Acc=0.6443, Val Loss=1.5522, lr=0.0100
[2025-05-01 15:24:28,213][train][INFO] - Epoch 36/100, Val Acc=0.6421, Val Loss=1.5500, lr=0.0100
[2025-05-01 15:24:36,069][train][INFO] - Epoch 37/100, Val Acc=0.6285, Val Loss=1.6178, lr=0.0100
[2025-05-01 15:24:44,011][train][INFO] - Epoch 38/100, Val Acc=0.6208, Val Loss=1.6405, lr=0.0100
[2025-05-01 15:24:51,525][train][INFO] - Epoch 39/100, Val Acc=0.6448, Val Loss=1.5211, lr=0.0100
[2025-05-01 15:24:55,271][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 15:24:59,268][train][INFO] - Epoch 40/100, Val Acc=0.6589, Val Loss=1.4578, lr=0.0100
[2025-05-01 15:25:07,592][train][INFO] - Epoch 41/100, Val Acc=0.6410, Val Loss=1.5647, lr=0.0100
[2025-05-01 15:25:15,903][train][INFO] - Epoch 42/100, Val Acc=0.6371, Val Loss=1.5811, lr=0.0100
[2025-05-01 15:25:23,999][train][INFO] - Epoch 43/100, Val Acc=0.6444, Val Loss=1.5672, lr=0.0100
[2025-05-01 15:25:32,052][train][INFO] - Epoch 44/100, Val Acc=0.6448, Val Loss=1.5721, lr=0.0100
[2025-05-01 15:25:32,282][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:25:39,935][train][INFO] - Epoch 45/100, Val Acc=0.6455, Val Loss=1.5733, lr=0.0100
[2025-05-01 15:25:47,952][train][INFO] - Epoch 46/100, Val Acc=0.6416, Val Loss=1.5996, lr=0.0100
[2025-05-01 15:25:56,332][train][INFO] - Epoch 47/100, Val Acc=0.6398, Val Loss=1.6223, lr=0.0100
[2025-05-01 15:26:04,401][train][INFO] - Epoch 48/100, Val Acc=0.6481, Val Loss=1.5288, lr=0.0100
[2025-05-01 15:26:09,721][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 15:26:12,319][train][INFO] - Epoch 49/100, Val Acc=0.6611, Val Loss=1.4779, lr=0.0100
[2025-05-01 15:26:18,971][train][INFO] - Epoch 50/100, Val Acc=0.6411, Val Loss=1.6265, lr=0.0100
[2025-05-01 15:26:27,337][train][INFO] - Epoch 51/100, Val Acc=0.6561, Val Loss=1.5558, lr=0.0100
[2025-05-01 15:26:35,762][train][INFO] - Epoch 52/100, Val Acc=0.6450, Val Loss=1.6309, lr=0.0100
[2025-05-01 15:26:43,537][train][INFO] - Epoch 53/100, Val Acc=0.6504, Val Loss=1.5771, lr=0.0100
[2025-05-01 15:26:47,002][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6068, lr=0.001
[2025-05-01 15:26:50,589][train][INFO] - Epoch 54/100, Val Acc=0.6460, Val Loss=1.6231, lr=0.0100
[2025-05-01 15:26:58,834][train][INFO] - Epoch 55/100, Val Acc=0.6514, Val Loss=1.5778, lr=0.0100
[2025-05-01 15:27:07,084][train][INFO] - Epoch 56/100, Val Acc=0.6452, Val Loss=1.6444, lr=0.0100
[2025-05-01 15:27:15,128][train][INFO] - Epoch 57/100, Val Acc=0.6499, Val Loss=1.5883, lr=0.0100
[2025-05-01 15:27:22,791][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.5571, lr=0.0100
[2025-05-01 15:27:24,667][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.6062, lr=0.001
[2025-05-01 15:27:30,333][train][INFO] - Epoch 59/100, Val Acc=0.6471, Val Loss=1.5725, lr=0.0100
[2025-05-01 15:27:38,216][train][INFO] - Epoch 60/100, Val Acc=0.6504, Val Loss=1.5868, lr=0.0100
[2025-05-01 15:27:45,655][train][INFO] - Epoch 61/100, Val Acc=0.7129, Val Loss=1.2725, lr=0.0010
[2025-05-01 15:27:53,743][train][INFO] - Epoch 62/100, Val Acc=0.7158, Val Loss=1.2676, lr=0.0010
[2025-05-01 15:28:01,847][train][INFO] - Epoch 63/100, Val Acc=0.7183, Val Loss=1.2778, lr=0.0010
[2025-05-01 15:28:02,342][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 15:28:10,128][train][INFO] - Epoch 64/100, Val Acc=0.7201, Val Loss=1.2846, lr=0.0010
[2025-05-01 15:28:18,338][train][INFO] - Epoch 65/100, Val Acc=0.7185, Val Loss=1.2964, lr=0.0010
[2025-05-01 15:28:26,657][train][INFO] - Epoch 66/100, Val Acc=0.7193, Val Loss=1.3128, lr=0.0010
[2025-05-01 15:28:35,082][train][INFO] - Epoch 67/100, Val Acc=0.7189, Val Loss=1.3188, lr=0.0010
[2025-05-01 15:28:38,432][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 15:28:43,025][train][INFO] - Epoch 68/100, Val Acc=0.7205, Val Loss=1.3176, lr=0.0010
[2025-05-01 15:28:50,791][train][INFO] - Epoch 69/100, Val Acc=0.7195, Val Loss=1.3333, lr=0.0010
[2025-05-01 15:28:58,603][train][INFO] - Epoch 70/100, Val Acc=0.7197, Val Loss=1.3369, lr=0.0010
[2025-05-01 15:29:06,585][train][INFO] - Epoch 71/100, Val Acc=0.7191, Val Loss=1.3453, lr=0.0010
[2025-05-01 15:29:14,347][train][INFO] - Epoch 72/100, Val Acc=0.7189, Val Loss=1.3444, lr=0.0010
[2025-05-01 15:29:16,155][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 15:29:16,178][meta_train][INFO] - epoch_34 saved !
[2025-05-01 15:29:22,859][train][INFO] - Epoch 73/100, Val Acc=0.7194, Val Loss=1.3543, lr=0.0010
[2025-05-01 15:29:31,513][train][INFO] - Epoch 74/100, Val Acc=0.7216, Val Loss=1.3619, lr=0.0010
[2025-05-01 15:29:39,181][train][INFO] - Epoch 75/100, Val Acc=0.7204, Val Loss=1.3636, lr=0.0010
[2025-05-01 15:29:47,377][train][INFO] - Epoch 76/100, Val Acc=0.7190, Val Loss=1.3655, lr=0.0010
[2025-05-01 15:29:54,189][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:29:55,370][train][INFO] - Epoch 77/100, Val Acc=0.7213, Val Loss=1.3802, lr=0.0010
[2025-05-01 15:30:03,574][train][INFO] - Epoch 78/100, Val Acc=0.7216, Val Loss=1.3769, lr=0.0010
[2025-05-01 15:30:11,289][train][INFO] - Epoch 79/100, Val Acc=0.7207, Val Loss=1.3812, lr=0.0010
[2025-05-01 15:30:19,208][train][INFO] - Epoch 80/100, Val Acc=0.7197, Val Loss=1.3875, lr=0.0010
[2025-05-01 15:30:26,802][train][INFO] - Epoch 81/100, Val Acc=0.7200, Val Loss=1.3970, lr=0.0010
[2025-05-01 15:30:31,323][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6066, lr=0.001
[2025-05-01 15:30:34,811][train][INFO] - Epoch 82/100, Val Acc=0.7223, Val Loss=1.3973, lr=0.0010
[2025-05-01 15:30:43,212][train][INFO] - Epoch 83/100, Val Acc=0.7222, Val Loss=1.3847, lr=0.0010
[2025-05-01 15:30:51,075][train][INFO] - Epoch 84/100, Val Acc=0.7229, Val Loss=1.3986, lr=0.0010
[2025-05-01 15:30:58,769][train][INFO] - Epoch 85/100, Val Acc=0.7237, Val Loss=1.4124, lr=0.0010
[2025-05-01 15:31:07,138][train][INFO] - Epoch 86/100, Val Acc=0.7230, Val Loss=1.4058, lr=0.0010
[2025-05-01 15:31:08,479][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 15:31:14,437][train][INFO] - Epoch 87/100, Val Acc=0.7249, Val Loss=1.4100, lr=0.0010
[2025-05-01 15:31:22,542][train][INFO] - Epoch 88/100, Val Acc=0.7224, Val Loss=1.4000, lr=0.0010
[2025-05-01 15:31:30,774][train][INFO] - Epoch 89/100, Val Acc=0.7242, Val Loss=1.4086, lr=0.0010
[2025-05-01 15:31:38,610][train][INFO] - Epoch 90/100, Val Acc=0.7213, Val Loss=1.4144, lr=0.0010
[2025-05-01 15:31:46,732][train][INFO] - Epoch 91/100, Val Acc=0.7226, Val Loss=1.4094, lr=0.0001
[2025-05-01 15:31:46,993][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 15:31:55,167][train][INFO] - Epoch 92/100, Val Acc=0.7237, Val Loss=1.4149, lr=0.0001
[2025-05-01 15:32:03,354][train][INFO] - Epoch 93/100, Val Acc=0.7230, Val Loss=1.4141, lr=0.0001
[2025-05-01 15:32:11,246][train][INFO] - Epoch 94/100, Val Acc=0.7241, Val Loss=1.4118, lr=0.0001
[2025-05-01 15:32:19,846][train][INFO] - Epoch 95/100, Val Acc=0.7234, Val Loss=1.4121, lr=0.0001
[2025-05-01 15:32:23,457][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.6060, lr=0.001
[2025-05-01 15:32:27,640][train][INFO] - Epoch 96/100, Val Acc=0.7232, Val Loss=1.4080, lr=0.0001
[2025-05-01 15:32:35,817][train][INFO] - Epoch 97/100, Val Acc=0.7237, Val Loss=1.4129, lr=0.0001
[2025-05-01 15:32:43,944][train][INFO] - Epoch 98/100, Val Acc=0.7242, Val Loss=1.4058, lr=0.0001
[2025-05-01 15:32:52,394][train][INFO] - Epoch 99/100, Val Acc=0.7238, Val Loss=1.4111, lr=0.0001
[2025-05-01 15:33:00,495][train][INFO] - Epoch 100/100, Val Acc=0.7246, Val Loss=1.4087, lr=0.0001
[2025-05-01 15:33:02,458][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 15:33:05,602][train][INFO] - After training : Train Acc=0.9963  Val Acc=0.7249
[2025-05-01 15:33:05,607][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 15:33:39,356][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 15:34:18,621][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 15:34:18,633][meta_train][INFO] - epoch_35 saved !
[2025-05-01 15:34:56,339][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:34:57,996][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 15:35:34,822][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:36:13,015][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:36:51,356][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 15:37:28,669][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 15:37:31,038][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 15:37:31,500][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 15:38:06,885][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:38:43,661][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 15:39:20,723][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6062, lr=0.001
[2025-05-01 15:39:20,742][meta_train][INFO] - epoch_36 saved !
[2025-05-01 15:39:58,484][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 15:40:36,432][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 15:41:12,583][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:41:49,768][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 15:42:27,083][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6061, lr=0.001
[2025-05-01 15:43:03,223][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 15:43:40,232][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 15:44:17,980][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 15:44:17,989][meta_train][INFO] - epoch_37 saved !
[2025-05-01 15:44:53,448][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 15:45:30,493][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6060, lr=0.001
[2025-05-01 15:46:07,257][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 15:46:43,787][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 15:47:21,681][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 15:47:56,981][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:48:33,819][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 15:49:11,390][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 15:49:11,399][meta_train][INFO] - epoch_38 saved !
[2025-05-01 15:49:48,283][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:50:25,846][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:51:01,726][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 15:51:39,527][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 15:52:15,957][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6059, lr=0.001
[2025-05-01 15:52:54,085][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:53:30,989][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 15:54:07,274][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 15:54:07,284][meta_train][INFO] - epoch_39 saved !
[2025-05-01 15:54:43,697][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 15:55:21,065][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 15:55:57,138][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 15:56:34,885][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 15:57:10,722][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 15:57:47,926][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 15:58:24,868][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 15:59:02,000][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 15:59:02,019][meta_train][INFO] - epoch_40 saved !
[2025-05-01 15:59:39,706][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 16:00:17,157][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 16:00:53,071][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:01:29,704][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:02:06,950][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:02:44,347][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:19,990][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:56,847][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:56,868][meta_train][INFO] - epoch_41 saved !
[2025-05-01 16:04:33,788][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:05:10,197][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:05:47,655][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:06:23,142][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 16:07:00,270][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 16:07:38,103][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:14,175][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:50,922][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:50,932][meta_train][INFO] - epoch_42 saved !
[2025-05-01 16:09:27,032][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:10:03,923][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:10:40,191][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:11:17,480][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:11:42,868][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 16:11:55,262][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6053, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=50']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 122, in main
    metanetwork = load_metanetwork(index)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 106, in load_metanetwork
    raise ValueError(f"no metanetwork found with index {index}")
ValueError: no metanetwork found with index 50

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-01 16:12:31,247][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:13:08,179][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 16:13:45,588][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:13:45,608][meta_train][INFO] - epoch_43 saved !
[2025-05-01 16:14:22,881][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:14:59,897][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 16:15:37,516][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 16:16:13,378][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:16:50,279][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:17:27,423][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:03,614][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:41,395][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:41,405][meta_train][INFO] - epoch_44 saved !
[2025-05-01 16:19:18,855][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 16:19:54,140][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:20:31,298][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:21:09,094][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:21:45,471][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:22:21,482][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:22:59,192][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 16:23:36,571][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:23:36,581][meta_train][INFO] - epoch_45 saved !
[2025-05-01 16:24:13,622][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:24:49,607][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:25:26,723][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:26:04,524][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:26:41,488][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:27:18,098][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:27:54,701][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:28:31,588][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 16:28:31,598][meta_train][INFO] - epoch_46 saved !
[2025-05-01 16:29:09,125][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:29:46,054][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:30:22,471][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:30:58,481][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:31:35,229][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:32:13,247][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 16:32:50,746][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 16:33:26,595][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:33:26,614][meta_train][INFO] - epoch_47 saved !
[2025-05-01 16:34:03,859][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:34:41,647][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:35:18,596][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:35:54,731][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 16:36:31,785][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:37:08,260][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:37:45,184][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:38:21,637][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 16:38:21,648][meta_train][INFO] - epoch_48 saved !
[2025-05-01 16:38:59,270][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:39:34,973][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:40:11,717][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 16:40:49,179][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:41:26,041][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:42:03,051][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-01 16:42:39,667][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:43:15,677][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-01 16:43:15,711][meta_train][INFO] - epoch_49 saved !
[2025-05-01 16:43:53,498][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:44:28,596][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:45:06,086][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-01 16:45:43,154][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:46:19,739][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 16:46:57,311][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:47:33,912][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:48:10,020][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:48:10,034][meta_train][INFO] - epoch_50 saved !
[2025-05-01 16:48:46,980][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:49:24,630][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:50:01,187][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:50:37,772][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:51:14,809][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-01 16:51:52,657][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 16:52:28,293][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:53:05,589][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:53:05,599][meta_train][INFO] - epoch_51 saved !
[2025-05-01 16:53:42,418][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:54:18,698][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 16:54:56,001][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-01 16:55:33,391][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:56:09,763][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:56:47,059][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:57:24,127][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:58:00,136][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:58:00,154][meta_train][INFO] - epoch_52 saved !
[2025-05-01 16:58:37,834][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:59:14,628][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:59:50,192][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:00:27,849][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 17:01:03,439][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:01:41,608][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:02:18,541][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-01 17:02:55,282][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:02:55,301][meta_train][INFO] - epoch_53 saved !
[2025-05-01 17:03:30,994][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:04:07,817][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:04:44,909][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:05:21,811][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:05:57,927][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:06:35,101][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-01 17:07:12,708][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:07:48,399][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:07:48,408][meta_train][INFO] - epoch_54 saved !
[2025-05-01 17:08:24,721][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:09:02,554][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:09:39,224][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:10:15,531][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:10:53,102][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-01 17:11:28,921][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:12:06,048][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:12:42,768][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:12:42,777][meta_train][INFO] - epoch_55 saved !
[2025-05-01 17:13:19,202][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:13:56,227][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:14:32,386][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:15:09,760][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:15:46,027][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:16:23,124][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:00,988][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:38,009][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:38,032][meta_train][INFO] - epoch_56 saved !
[2025-05-01 17:18:14,125][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:18:51,468][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:19:27,555][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:20:04,630][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:20:40,247][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:21:17,616][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:21:54,887][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:22:33,111][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:22:33,126][meta_train][INFO] - epoch_57 saved !
[2025-05-01 17:23:08,204][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:23:46,445][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:24:21,985][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:24:59,745][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:25:36,712][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:26:12,252][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:26:49,375][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:27:26,911][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:27:26,920][meta_train][INFO] - epoch_58 saved !
[2025-05-01 17:28:04,075][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:28:40,367][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:29:16,332][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:29:53,392][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:30:31,290][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:31:08,287][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:31:44,978][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:32:21,327][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:32:21,340][meta_train][INFO] - epoch_59 saved !
[2025-05-01 17:32:58,296][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:33:34,449][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:34:11,256][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:34:47,809][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:35:25,052][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:36:02,978][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 17:36:38,825][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:37:16,275][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:37:16,285][meta_train][INFO] - epoch_60 saved !
[2025-05-01 17:37:54,729][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:38:32,029][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:39:08,019][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:39:45,459][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:40:22,609][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:40:58,134][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:41:35,112][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:42:11,670][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:42:11,679][meta_train][INFO] - epoch_61 saved !
[2025-05-01 17:42:49,265][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:43:26,518][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:44:03,307][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:44:40,515][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:45:16,865][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:45:53,634][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:46:31,384][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:47:08,684][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:47:08,702][meta_train][INFO] - epoch_62 saved !
[2025-05-01 17:47:45,297][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:48:21,209][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:48:58,549][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:49:35,500][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:50:11,570][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:50:48,711][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 17:51:26,262][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:52:02,920][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:52:02,930][meta_train][INFO] - epoch_63 saved !
[2025-05-01 17:52:38,586][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:53:16,221][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:53:51,498][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:54:28,973][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 17:55:06,819][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:55:42,777][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 17:56:20,014][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:56:56,891][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:56:56,901][meta_train][INFO] - epoch_64 saved !
[2025-05-01 17:57:33,637][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:58:10,248][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:58:46,571][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 17:59:22,392][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 18:00:00,368][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 18:00:37,261][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:01:13,935][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:01:50,123][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:01:50,144][meta_train][INFO] - epoch_65 saved !
[2025-05-01 18:02:28,097][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 18:03:04,506][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:03:40,890][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:04:18,431][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 18:04:54,567][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 18:05:31,659][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:07,789][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:44,762][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:44,783][meta_train][INFO] - epoch_66 saved !
[2025-05-01 18:07:21,218][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 18:07:57,813][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:08:34,826][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:09:11,394][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 18:09:48,388][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:10:25,203][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:11:01,396][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:11:39,345][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:11:39,365][meta_train][INFO] - epoch_67 saved !
[2025-05-01 18:12:15,509][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 18:12:52,656][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:13:29,857][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:14:06,715][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:14:42,874][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:15:18,477][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:15:55,719][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:16:32,891][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:16:32,900][meta_train][INFO] - epoch_68 saved !
[2025-05-01 18:17:09,145][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 18:17:44,747][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:18:21,876][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:18:57,986][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:19:35,258][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 18:20:12,176][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:20:48,205][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:21:24,616][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:21:24,625][meta_train][INFO] - epoch_69 saved !
[2025-05-01 18:22:01,000][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:22:39,049][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:23:15,841][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:23:51,476][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:24:28,459][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 18:25:04,886][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:25:40,894][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:26:17,047][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:26:17,056][meta_train][INFO] - epoch_70 saved !
[2025-05-01 18:26:54,054][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:27:30,763][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:28:06,833][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:28:43,998][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:29:19,806][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:29:56,029][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:30:33,542][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:31:10,876][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:31:10,886][meta_train][INFO] - epoch_71 saved !
[2025-05-01 18:31:47,459][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:32:24,283][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:33:01,741][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:33:38,558][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 18:34:14,230][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:34:50,961][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:35:28,878][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:36:05,713][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:36:05,723][meta_train][INFO] - epoch_72 saved !
[2025-05-01 18:36:42,878][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:37:19,102][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:37:56,824][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:38:32,877][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:39:10,116][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:39:45,917][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 18:40:22,617][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:41:00,195][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:41:00,215][meta_train][INFO] - epoch_73 saved !
[2025-05-01 18:41:37,044][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:42:13,666][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:42:49,269][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:43:26,625][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:44:03,694][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:44:39,390][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:45:16,740][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:45:54,020][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:45:54,029][meta_train][INFO] - epoch_74 saved !
[2025-05-01 18:46:30,471][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:47:08,046][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 18:47:43,873][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:48:21,044][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 18:48:57,369][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:49:33,705][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:50:10,524][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:50:47,493][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:50:47,516][meta_train][INFO] - epoch_75 saved !
[2025-05-01 18:51:23,880][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 18:51:59,878][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:52:37,698][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:53:13,998][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 18:53:50,452][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:54:27,473][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:55:05,455][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:55:41,838][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:55:41,848][meta_train][INFO] - epoch_76 saved !
[2025-05-01 18:56:17,817][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:56:54,323][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 18:57:30,534][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 18:58:08,322][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 18:58:45,219][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:59:21,002][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 18:59:58,190][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:00:34,286][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:00:34,297][meta_train][INFO] - epoch_77 saved !
[2025-05-01 19:01:11,334][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:01:47,026][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:02:23,859][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:03:01,091][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:03:37,241][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:04:14,553][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:04:52,038][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 19:05:30,031][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:05:30,054][meta_train][INFO] - epoch_78 saved !
[2025-05-01 19:06:06,837][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:06:43,422][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:07:19,186][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:07:57,509][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:08:34,252][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:09:10,541][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:09:47,971][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:10:24,654][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 19:10:24,670][meta_train][INFO] - epoch_79 saved !
[2025-05-01 19:11:01,157][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:11:38,787][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:12:14,547][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:12:51,578][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:13:28,330][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 19:14:06,167][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:14:41,797][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:15:19,516][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 19:15:19,542][meta_train][INFO] - epoch_80 saved !
[2025-05-01 19:15:55,624][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 19:16:33,149][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:17:09,395][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:17:46,299][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:18:22,955][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:18:59,823][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 19:19:37,536][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:20:14,859][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:20:14,869][meta_train][INFO] - epoch_81 saved !
[2025-05-01 19:20:50,062][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:21:27,761][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:22:03,438][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:22:40,315][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:23:16,680][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:23:53,325][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 19:24:31,311][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:25:07,079][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 19:25:07,099][meta_train][INFO] - epoch_82 saved !
[2025-05-01 19:25:45,074][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 19:26:21,547][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:26:57,874][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:27:33,642][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:28:10,715][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 19:28:47,227][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:29:24,635][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:30:02,267][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:30:02,287][meta_train][INFO] - epoch_83 saved !
[2025-05-01 19:30:39,361][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:31:16,037][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:31:52,866][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:32:28,257][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:33:05,944][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:33:42,888][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:34:18,636][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:34:56,442][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:34:56,452][meta_train][INFO] - epoch_84 saved !
[2025-05-01 19:35:32,482][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:36:09,438][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:36:45,392][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 19:37:23,047][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 19:38:00,072][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:38:36,647][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:39:12,413][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:39:50,040][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:39:50,055][meta_train][INFO] - epoch_85 saved !
[2025-05-01 19:40:26,012][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:41:03,529][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:41:40,123][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:42:17,613][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:42:54,557][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:43:31,002][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:44:07,232][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:44:44,737][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 19:44:44,760][meta_train][INFO] - epoch_86 saved !
[2025-05-01 19:45:20,702][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:45:57,974][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:46:35,162][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:47:11,043][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:47:47,439][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:48:23,844][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:49:01,439][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 19:49:38,556][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:49:38,582][meta_train][INFO] - epoch_87 saved !
[2025-05-01 19:50:15,190][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:50:51,282][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:51:28,896][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:52:05,239][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 19:52:41,085][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:53:18,840][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:53:55,310][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 19:54:31,450][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:54:31,459][meta_train][INFO] - epoch_88 saved !
[2025-05-01 19:55:08,565][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:55:44,438][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 19:56:22,080][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:56:59,560][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 19:57:35,598][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:58:12,887][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:58:48,649][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:59:25,647][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:59:25,666][meta_train][INFO] - epoch_89 saved !
[2025-05-01 20:00:03,332][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 20:00:41,029][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:01:17,144][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:01:54,038][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:02:29,320][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:03:06,592][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:03:44,613][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:04:19,910][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:04:19,920][meta_train][INFO] - epoch_90 saved !
[2025-05-01 20:04:57,024][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:05:34,438][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:06:11,777][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 20:06:48,253][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:07:26,309][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:08:02,997][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:08:38,416][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 20:09:15,332][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:09:15,353][meta_train][INFO] - epoch_91 saved !
[2025-05-01 20:09:52,059][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:10:27,837][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:11:05,172][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:11:42,009][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:12:17,848][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 20:12:55,147][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:13:30,764][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:14:08,281][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:14:08,292][meta_train][INFO] - epoch_92 saved !
[2025-05-01 20:14:45,949][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:15:22,152][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 20:15:58,570][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:16:36,705][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:17:13,127][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 20:17:49,900][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 20:18:25,911][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:19:02,884][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:19:02,898][meta_train][INFO] - epoch_93 saved !
[2025-05-01 20:19:39,633][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:20:16,233][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:20:52,499][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:21:29,217][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:22:06,341][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:22:43,330][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:23:19,156][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:23:57,089][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 20:23:57,098][meta_train][INFO] - epoch_94 saved !
[2025-05-01 20:24:33,341][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:25:11,164][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:25:48,129][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:26:23,557][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:27:01,291][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:27:37,540][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:28:14,731][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:28:50,208][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:28:50,224][meta_train][INFO] - epoch_95 saved !
[2025-05-01 20:29:27,674][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:30:03,901][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:30:40,871][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:31:17,602][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:31:54,072][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 20:32:30,946][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:33:07,145][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:33:45,269][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:33:45,279][meta_train][INFO] - epoch_96 saved !
[2025-05-01 20:34:21,591][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:34:58,748][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:35:36,507][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:36:12,105][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:36:49,557][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:37:25,859][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:38:02,139][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:38:39,909][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:38:39,927][meta_train][INFO] - epoch_97 saved !
[2025-05-01 20:39:16,669][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:39:54,282][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:40:31,815][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:41:07,011][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:41:44,158][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:42:21,281][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:42:59,315][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 20:43:35,218][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:43:35,229][meta_train][INFO] - epoch_98 saved !
[2025-05-01 20:44:13,165][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:44:49,116][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:45:27,200][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:46:04,226][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:46:40,604][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:47:17,095][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:47:53,652][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:48:31,635][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:48:31,645][meta_train][INFO] - epoch_99 saved !
[2025-05-01 20:49:08,531][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:49:45,487][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:50:21,583][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:50:57,985][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:51:36,453][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:52:13,209][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:52:50,208][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:53:26,109][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:53:26,127][meta_train][INFO] - epoch_100 saved !
[2025-05-01 22:20:40,762][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 22:20:53,489][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:10,082][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:21:16,936][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6071, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:23,776][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:21:25,433][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-01 22:21:32,176][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-01 22:21:32,723][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 22:21:33,443][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:21:39,791][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:21:41,720][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:21:47,943][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:21:50,247][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:21:56,542][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:58,823][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-01 22:22:04,088][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:22:04,326][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-01 22:22:06,441][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:11,849][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:22:12,081][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-01 22:22:13,889][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:19,542][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:19,755][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:22:21,360][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:27,102][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:22:27,251][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-01 22:22:29,358][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:35,081][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-01 22:22:35,109][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:37,256][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:42,853][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:22:42,882][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-01 22:22:44,938][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:50,436][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:22:50,618][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:52,882][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:22:58,231][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:22:58,279][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:23:00,536][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:05,959][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-01 22:23:06,168][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:08,492][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:13,636][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:13,709][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:23:15,951][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:21,287][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:21,810][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:23:23,826][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:29,079][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-01 22:23:29,501][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:23:31,580][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:36,816][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:37,123][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:39,512][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:44,096][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:44,886][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:47,280][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:51,711][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:52,535][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:54,903][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:23:59,054][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:00,285][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:24:02,597][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:06,603][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:08,078][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-01 22:24:10,092][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:14,330][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:15,862][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:17,948][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:22,126][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:23,531][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:25,638][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:29,927][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:31,461][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:33,340][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:37,428][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:39,354][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:40,955][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:24:45,225][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:47,014][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:48,825][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:52,688][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:24:54,836][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:56,375][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:00,405][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:02,361][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:04,351][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:08,378][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:10,051][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:11,556][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:16,277][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:18,052][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:19,420][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:24,085][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:25,619][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:27,140][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:31,636][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:33,191][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:34,782][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:39,288][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:40,921][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:42,657][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:46,664][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:48,792][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:50,437][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:54,164][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:56,802][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:58,430][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:01,678][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:04,139][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:06,157][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:09,706][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:11,799][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:14,047][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:17,674][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:19,592][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:21,758][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:25,103][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:26,936][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:29,586][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:32,753][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:34,608][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:37,735][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:40,372][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:42,315][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:45,885][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:48,151][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:50,274][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:53,841][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:55,812][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:57,958][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:01,580][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:03,417][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:05,788][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:09,080][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:11,444][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:13,524][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:17,124][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:18,881][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:21,343][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:24,490][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:26,242][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:28,774][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:32,161][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:34,356][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:36,496][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:39,818][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:41,864][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:44,045][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:47,604][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:49,566][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:51,899][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:55,589][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:57,327][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:59,844][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:03,491][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:04,963][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:07,634][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:11,296][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:12,336][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:15,704][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:19,063][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:20,057][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:23,484][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:26,827][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:27,799][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:31,171][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:34,047][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:35,678][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:38,897][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:42,044][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:43,606][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:46,525][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:49,327][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:51,277][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:54,500][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:57,086][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:59,116][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:01,990][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:05,165][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:06,971][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:09,898][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:12,424][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:14,472][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:17,535][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:20,154][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:22,277][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:25,251][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:28,085][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:29,979][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:32,655][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:35,937][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:37,417][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:39,926][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:43,664][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:44,970][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:47,506][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:51,305][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:52,714][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:54,954][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:58,859][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:59,716][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:02,838][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:06,423][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:07,437][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:10,664][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:13,717][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:15,241][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:17,953][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:21,477][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:23,015][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:25,676][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:29,448][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:30,269][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:33,295][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:37,045][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:37,738][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:40,981][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:44,911][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:45,686][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:48,580][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:52,658][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:53,378][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:56,362][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:00,475][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:01,099][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:04,028][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:08,011][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:08,631][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:11,550][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:15,596][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:16,453][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:19,278][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:23,291][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:24,255][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:26,768][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:30,711][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:31,853][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:34,004][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:38,254][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:39,304][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:41,552][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:46,060][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:47,070][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:49,408][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:53,455][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:54,640][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:57,145][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:01,225][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:02,395][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:04,871][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:08,834][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:09,625][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:12,260][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:16,090][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:16,669][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:19,403][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:23,246][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:23,736][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:26,687][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:30,511][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:30,862][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:34,041][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:37,929][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:38,148][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:41,378][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:45,194][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:45,298][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:48,582][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:52,352][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:52,445][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:32:55,967][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:59,603][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:32:59,707][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:03,154][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:06,848][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:07,074][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:10,475][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:13,841][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:14,282][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:17,514][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:20,891][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:21,561][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:24,743][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:27,741][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:28,549][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:31,931][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:34,695][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:35,925][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:39,276][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:41,566][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:43,162][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:46,501][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:48,710][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:50,475][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:53,864][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:55,660][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:58,064][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:01,092][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:02,967][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:03,494][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:03,500][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:34:08,243][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:08,248][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:34:08,763][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:16,487][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:24,260][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:31,931][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:39,897][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:47,626][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:52,848][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:52,856][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:36:04,917][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:36:05,466][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:36:47,864][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:38:03,496][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:04,024][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 22:38:11,144][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:11,664][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 22:38:44,167][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:44,633][Visualize acc speed up curve][INFO] - End visualizing
Could not override 'pruning_index'.
To append to your config use +pruning_index=3.0
Key 'pruning_index' is not in struct
    full_key: pruning_index
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-01 22:55:57,798][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:56:27,487][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:56:35,449][train][INFO] - Epoch 1/100, Val Acc=0.0706, Val Loss=3.8937, lr=0.0100
[2025-05-01 22:56:43,649][train][INFO] - Epoch 2/100, Val Acc=0.2108, Val Loss=2.9731, lr=0.0100
[2025-05-01 22:56:51,633][train][INFO] - Epoch 3/100, Val Acc=0.2912, Val Loss=2.7967, lr=0.0100
[2025-05-01 22:56:59,007][train][INFO] - Epoch 4/100, Val Acc=0.4286, Val Loss=2.0857, lr=0.0100
[2025-05-01 22:57:06,790][train][INFO] - Epoch 5/100, Val Acc=0.4561, Val Loss=2.0563, lr=0.0100
[2025-05-01 22:57:14,624][train][INFO] - Epoch 6/100, Val Acc=0.4436, Val Loss=2.2707, lr=0.0100
[2025-05-01 22:57:22,444][train][INFO] - Epoch 7/100, Val Acc=0.5218, Val Loss=1.8155, lr=0.0100
[2025-05-01 22:57:30,925][train][INFO] - Epoch 8/100, Val Acc=0.5249, Val Loss=1.8638, lr=0.0100
[2025-05-01 22:57:39,140][train][INFO] - Epoch 9/100, Val Acc=0.5352, Val Loss=1.8255, lr=0.0100
[2025-05-01 22:57:47,381][train][INFO] - Epoch 10/100, Val Acc=0.5553, Val Loss=1.7265, lr=0.0100
[2025-05-01 22:57:55,171][train][INFO] - Epoch 11/100, Val Acc=0.5912, Val Loss=1.5787, lr=0.0100
[2025-05-01 22:58:02,764][train][INFO] - Epoch 12/100, Val Acc=0.5757, Val Loss=1.6837, lr=0.0100
[2025-05-01 22:58:10,359][train][INFO] - Epoch 13/100, Val Acc=0.5847, Val Loss=1.6419, lr=0.0100
[2025-05-01 22:58:18,590][train][INFO] - Epoch 14/100, Val Acc=0.5962, Val Loss=1.5629, lr=0.0100
[2025-05-01 22:58:26,410][train][INFO] - Epoch 15/100, Val Acc=0.5978, Val Loss=1.6183, lr=0.0100
[2025-05-01 22:58:34,433][train][INFO] - Epoch 16/100, Val Acc=0.6105, Val Loss=1.5315, lr=0.0100
[2025-05-01 22:58:42,313][train][INFO] - Epoch 17/100, Val Acc=0.5738, Val Loss=1.7595, lr=0.0100
[2025-05-01 22:58:49,462][train][INFO] - Epoch 18/100, Val Acc=0.6279, Val Loss=1.4818, lr=0.0100
[2025-05-01 22:58:57,267][train][INFO] - Epoch 19/100, Val Acc=0.6344, Val Loss=1.4927, lr=0.0100
[2025-05-01 22:59:05,442][train][INFO] - Epoch 20/100, Val Acc=0.6238, Val Loss=1.5212, lr=0.0100
[2025-05-01 22:59:13,539][train][INFO] - Epoch 21/100, Val Acc=0.6147, Val Loss=1.5916, lr=0.0100
[2025-05-01 22:59:21,252][train][INFO] - Epoch 22/100, Val Acc=0.6151, Val Loss=1.6332, lr=0.0100
[2025-05-01 22:59:29,180][train][INFO] - Epoch 23/100, Val Acc=0.6109, Val Loss=1.6300, lr=0.0100
[2025-05-01 22:59:36,781][train][INFO] - Epoch 24/100, Val Acc=0.6447, Val Loss=1.4446, lr=0.0100
[2025-05-01 22:59:44,274][train][INFO] - Epoch 25/100, Val Acc=0.6389, Val Loss=1.5132, lr=0.0100
[2025-05-01 22:59:51,807][train][INFO] - Epoch 26/100, Val Acc=0.6126, Val Loss=1.6543, lr=0.0100
[2025-05-01 22:59:59,487][train][INFO] - Epoch 27/100, Val Acc=0.6025, Val Loss=1.7044, lr=0.0100
[2025-05-01 23:00:07,736][train][INFO] - Epoch 28/100, Val Acc=0.6349, Val Loss=1.5484, lr=0.0100
[2025-05-01 23:00:10,220][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 23:00:16,546][train][INFO] - Epoch 29/100, Val Acc=0.6474, Val Loss=1.4652, lr=0.0100
[2025-05-01 23:00:24,669][train][INFO] - Epoch 30/100, Val Acc=0.6550, Val Loss=1.4441, lr=0.0100
[2025-05-01 23:00:32,698][train][INFO] - Epoch 31/100, Val Acc=0.6458, Val Loss=1.5034, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 23:00:40,273][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 23:00:40,892][train][INFO] - Epoch 32/100, Val Acc=0.6276, Val Loss=1.5984, lr=0.0100
[2025-05-01 23:00:48,770][train][INFO] - Epoch 1/100, Val Acc=0.0294, Val Loss=4.5471, lr=0.0100
[2025-05-01 23:00:49,111][train][INFO] - Epoch 33/100, Val Acc=0.6379, Val Loss=1.5567, lr=0.0100
[2025-05-01 23:00:56,685][train][INFO] - Epoch 34/100, Val Acc=0.6523, Val Loss=1.4781, lr=0.0100
[2025-05-01 23:00:57,194][train][INFO] - Epoch 2/100, Val Acc=0.0856, Val Loss=3.8208, lr=0.0100
[2025-05-01 23:01:05,169][train][INFO] - Epoch 35/100, Val Acc=0.6443, Val Loss=1.5522, lr=0.0100
[2025-05-01 23:01:05,316][train][INFO] - Epoch 3/100, Val Acc=0.1140, Val Loss=3.6978, lr=0.0100
[2025-05-01 23:01:13,271][train][INFO] - Epoch 36/100, Val Acc=0.6421, Val Loss=1.5500, lr=0.0100
[2025-05-01 23:01:13,910][train][INFO] - Epoch 4/100, Val Acc=0.1550, Val Loss=3.3267, lr=0.0100
[2025-05-01 23:01:21,534][train][INFO] - Epoch 37/100, Val Acc=0.6285, Val Loss=1.6178, lr=0.0100
[2025-05-01 23:01:22,283][train][INFO] - Epoch 5/100, Val Acc=0.2230, Val Loss=2.9118, lr=0.0100
[2025-05-01 23:01:29,626][train][INFO] - Epoch 38/100, Val Acc=0.6208, Val Loss=1.6405, lr=0.0100
[2025-05-01 23:01:30,125][train][INFO] - Epoch 6/100, Val Acc=0.2245, Val Loss=2.9727, lr=0.0100
[2025-05-01 23:01:38,242][train][INFO] - Epoch 39/100, Val Acc=0.6448, Val Loss=1.5211, lr=0.0100
[2025-05-01 23:01:38,722][train][INFO] - Epoch 7/100, Val Acc=0.2385, Val Loss=2.9828, lr=0.0100
[2025-05-01 23:01:46,550][train][INFO] - Epoch 40/100, Val Acc=0.6589, Val Loss=1.4578, lr=0.0100
[2025-05-01 23:01:46,741][train][INFO] - Epoch 8/100, Val Acc=0.3038, Val Loss=2.5710, lr=0.0100
[2025-05-01 23:01:54,865][train][INFO] - Epoch 41/100, Val Acc=0.6410, Val Loss=1.5647, lr=0.0100
[2025-05-01 23:01:54,917][train][INFO] - Epoch 9/100, Val Acc=0.3250, Val Loss=2.5166, lr=0.0100
[2025-05-01 23:02:02,935][train][INFO] - Epoch 10/100, Val Acc=0.3479, Val Loss=2.4564, lr=0.0100
[2025-05-01 23:02:03,336][train][INFO] - Epoch 42/100, Val Acc=0.6371, Val Loss=1.5811, lr=0.0100
[2025-05-01 23:02:11,288][train][INFO] - Epoch 43/100, Val Acc=0.6444, Val Loss=1.5672, lr=0.0100
[2025-05-01 23:02:11,399][train][INFO] - Epoch 11/100, Val Acc=0.3325, Val Loss=2.5834, lr=0.0100
[2025-05-01 23:02:19,467][train][INFO] - Epoch 12/100, Val Acc=0.3833, Val Loss=2.2904, lr=0.0100
[2025-05-01 23:02:19,556][train][INFO] - Epoch 44/100, Val Acc=0.6448, Val Loss=1.5721, lr=0.0100
[2025-05-01 23:02:27,499][train][INFO] - Epoch 13/100, Val Acc=0.4030, Val Loss=2.2425, lr=0.0100
[2025-05-01 23:02:28,009][train][INFO] - Epoch 45/100, Val Acc=0.6455, Val Loss=1.5733, lr=0.0100
[2025-05-01 23:02:36,067][train][INFO] - Epoch 14/100, Val Acc=0.4293, Val Loss=2.1352, lr=0.0100
[2025-05-01 23:02:36,354][train][INFO] - Epoch 46/100, Val Acc=0.6416, Val Loss=1.5996, lr=0.0100
[2025-05-01 23:02:43,933][train][INFO] - Epoch 15/100, Val Acc=0.4002, Val Loss=2.3065, lr=0.0100
[2025-05-01 23:02:44,956][train][INFO] - Epoch 47/100, Val Acc=0.6398, Val Loss=1.6223, lr=0.0100
[2025-05-01 23:02:52,124][train][INFO] - Epoch 16/100, Val Acc=0.4199, Val Loss=2.2373, lr=0.0100
[2025-05-01 23:02:53,384][train][INFO] - Epoch 48/100, Val Acc=0.6481, Val Loss=1.5288, lr=0.0100
[2025-05-01 23:02:59,995][train][INFO] - Epoch 17/100, Val Acc=0.4732, Val Loss=1.9590, lr=0.0100
[2025-05-01 23:03:01,678][train][INFO] - Epoch 49/100, Val Acc=0.6611, Val Loss=1.4779, lr=0.0100
[2025-05-01 23:03:07,843][train][INFO] - Epoch 18/100, Val Acc=0.4517, Val Loss=2.1348, lr=0.0100
[2025-05-01 23:03:10,269][train][INFO] - Epoch 50/100, Val Acc=0.6411, Val Loss=1.6265, lr=0.0100
[2025-05-01 23:03:15,877][train][INFO] - Epoch 19/100, Val Acc=0.4934, Val Loss=1.8773, lr=0.0100
[2025-05-01 23:03:18,809][train][INFO] - Epoch 51/100, Val Acc=0.6561, Val Loss=1.5558, lr=0.0100
[2025-05-01 23:03:23,799][train][INFO] - Epoch 20/100, Val Acc=0.5124, Val Loss=1.7831, lr=0.0100
[2025-05-01 23:03:27,009][train][INFO] - Epoch 52/100, Val Acc=0.6450, Val Loss=1.6309, lr=0.0100
[2025-05-01 23:03:32,136][train][INFO] - Epoch 21/100, Val Acc=0.5039, Val Loss=1.8466, lr=0.0100
[2025-05-01 23:03:35,600][train][INFO] - Epoch 53/100, Val Acc=0.6504, Val Loss=1.5771, lr=0.0100
[2025-05-01 23:03:40,003][train][INFO] - Epoch 22/100, Val Acc=0.5157, Val Loss=1.8648, lr=0.0100
[2025-05-01 23:03:43,672][train][INFO] - Epoch 54/100, Val Acc=0.6460, Val Loss=1.6231, lr=0.0100
[2025-05-01 23:03:47,776][train][INFO] - Epoch 23/100, Val Acc=0.5083, Val Loss=1.8836, lr=0.0100
[2025-05-01 23:03:52,205][train][INFO] - Epoch 55/100, Val Acc=0.6514, Val Loss=1.5778, lr=0.0100
[2025-05-01 23:03:55,770][train][INFO] - Epoch 24/100, Val Acc=0.5194, Val Loss=1.8245, lr=0.0100
[2025-05-01 23:04:00,692][train][INFO] - Epoch 56/100, Val Acc=0.6452, Val Loss=1.6444, lr=0.0100
[2025-05-01 23:04:03,851][train][INFO] - Epoch 25/100, Val Acc=0.5575, Val Loss=1.6480, lr=0.0100
[2025-05-01 23:04:08,811][train][INFO] - Epoch 57/100, Val Acc=0.6499, Val Loss=1.5883, lr=0.0100
[2025-05-01 23:04:11,193][train][INFO] - Epoch 26/100, Val Acc=0.5416, Val Loss=1.7187, lr=0.0100
[2025-05-01 23:04:17,331][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.5571, lr=0.0100
[2025-05-01 23:04:19,180][train][INFO] - Epoch 27/100, Val Acc=0.5269, Val Loss=1.7866, lr=0.0100
[2025-05-01 23:04:25,218][train][INFO] - Epoch 59/100, Val Acc=0.6471, Val Loss=1.5725, lr=0.0100
[2025-05-01 23:04:26,831][train][INFO] - Epoch 28/100, Val Acc=0.5291, Val Loss=1.8330, lr=0.0100
[2025-05-01 23:04:33,583][train][INFO] - Epoch 60/100, Val Acc=0.6504, Val Loss=1.5868, lr=0.0100
[2025-05-01 23:04:34,822][train][INFO] - Epoch 29/100, Val Acc=0.5462, Val Loss=1.7363, lr=0.0100
[2025-05-01 23:04:41,937][train][INFO] - Epoch 61/100, Val Acc=0.7129, Val Loss=1.2725, lr=0.0010
[2025-05-01 23:04:42,747][train][INFO] - Epoch 30/100, Val Acc=0.5812, Val Loss=1.5910, lr=0.0100
[2025-05-01 23:04:49,965][train][INFO] - Epoch 62/100, Val Acc=0.7158, Val Loss=1.2676, lr=0.0010
[2025-05-01 23:04:51,144][train][INFO] - Epoch 31/100, Val Acc=0.5492, Val Loss=1.7281, lr=0.0100
[2025-05-01 23:04:57,882][train][INFO] - Epoch 63/100, Val Acc=0.7183, Val Loss=1.2778, lr=0.0010
[2025-05-01 23:04:59,167][train][INFO] - Epoch 32/100, Val Acc=0.5605, Val Loss=1.6805, lr=0.0100
[2025-05-01 23:05:05,763][train][INFO] - Epoch 64/100, Val Acc=0.7201, Val Loss=1.2846, lr=0.0010
[2025-05-01 23:05:07,125][train][INFO] - Epoch 33/100, Val Acc=0.5724, Val Loss=1.6247, lr=0.0100
[2025-05-01 23:05:14,002][train][INFO] - Epoch 65/100, Val Acc=0.7185, Val Loss=1.2964, lr=0.0010
[2025-05-01 23:05:14,848][train][INFO] - Epoch 34/100, Val Acc=0.5814, Val Loss=1.6101, lr=0.0100
[2025-05-01 23:05:22,605][train][INFO] - Epoch 66/100, Val Acc=0.7193, Val Loss=1.3128, lr=0.0010
[2025-05-01 23:05:23,282][train][INFO] - Epoch 35/100, Val Acc=0.5657, Val Loss=1.7024, lr=0.0100
[2025-05-01 23:05:30,682][train][INFO] - Epoch 67/100, Val Acc=0.7189, Val Loss=1.3188, lr=0.0010
[2025-05-01 23:05:31,409][train][INFO] - Epoch 36/100, Val Acc=0.5633, Val Loss=1.7350, lr=0.0100
[2025-05-01 23:05:38,963][train][INFO] - Epoch 68/100, Val Acc=0.7205, Val Loss=1.3176, lr=0.0010
[2025-05-01 23:05:39,576][train][INFO] - Epoch 37/100, Val Acc=0.5837, Val Loss=1.6230, lr=0.0100
[2025-05-01 23:05:46,706][train][INFO] - Epoch 69/100, Val Acc=0.7195, Val Loss=1.3333, lr=0.0010
[2025-05-01 23:05:47,496][train][INFO] - Epoch 38/100, Val Acc=0.5669, Val Loss=1.6805, lr=0.0100
[2025-05-01 23:05:54,881][train][INFO] - Epoch 70/100, Val Acc=0.7197, Val Loss=1.3369, lr=0.0010
[2025-05-01 23:05:55,310][train][INFO] - Epoch 39/100, Val Acc=0.5559, Val Loss=1.7881, lr=0.0100
[2025-05-01 23:06:02,655][train][INFO] - Epoch 71/100, Val Acc=0.7191, Val Loss=1.3453, lr=0.0010
[2025-05-01 23:06:03,608][train][INFO] - Epoch 40/100, Val Acc=0.5763, Val Loss=1.7011, lr=0.0100
[2025-05-01 23:06:10,934][train][INFO] - Epoch 72/100, Val Acc=0.7189, Val Loss=1.3444, lr=0.0010
[2025-05-01 23:06:11,809][train][INFO] - Epoch 41/100, Val Acc=0.5834, Val Loss=1.7062, lr=0.0100
[2025-05-01 23:06:19,490][train][INFO] - Epoch 73/100, Val Acc=0.7194, Val Loss=1.3543, lr=0.0010
[2025-05-01 23:06:20,149][train][INFO] - Epoch 42/100, Val Acc=0.5766, Val Loss=1.6730, lr=0.0100
[2025-05-01 23:06:28,256][train][INFO] - Epoch 74/100, Val Acc=0.7216, Val Loss=1.3619, lr=0.0010
[2025-05-01 23:06:28,490][train][INFO] - Epoch 43/100, Val Acc=0.5826, Val Loss=1.6590, lr=0.0100
[2025-05-01 23:06:36,371][train][INFO] - Epoch 44/100, Val Acc=0.5792, Val Loss=1.6753, lr=0.0100
[2025-05-01 23:06:36,668][train][INFO] - Epoch 75/100, Val Acc=0.7204, Val Loss=1.3636, lr=0.0010
[2025-05-01 23:06:44,473][train][INFO] - Epoch 45/100, Val Acc=0.5828, Val Loss=1.6957, lr=0.0100
[2025-05-01 23:06:44,777][train][INFO] - Epoch 76/100, Val Acc=0.7190, Val Loss=1.3655, lr=0.0010
[2025-05-01 23:06:52,046][train][INFO] - Epoch 46/100, Val Acc=0.5956, Val Loss=1.6198, lr=0.0100
[2025-05-01 23:06:52,840][train][INFO] - Epoch 77/100, Val Acc=0.7213, Val Loss=1.3802, lr=0.0010
[2025-05-01 23:07:00,432][train][INFO] - Epoch 47/100, Val Acc=0.6048, Val Loss=1.5809, lr=0.0100
[2025-05-01 23:07:00,889][train][INFO] - Epoch 78/100, Val Acc=0.7216, Val Loss=1.3769, lr=0.0010
[2025-05-01 23:07:08,491][train][INFO] - Epoch 79/100, Val Acc=0.7207, Val Loss=1.3812, lr=0.0010
[2025-05-01 23:07:08,493][train][INFO] - Epoch 48/100, Val Acc=0.6090, Val Loss=1.5786, lr=0.0100
[2025-05-01 23:07:16,691][train][INFO] - Epoch 80/100, Val Acc=0.7197, Val Loss=1.3875, lr=0.0010
[2025-05-01 23:07:16,725][train][INFO] - Epoch 49/100, Val Acc=0.6058, Val Loss=1.5649, lr=0.0100
[2025-05-01 23:07:24,812][train][INFO] - Epoch 81/100, Val Acc=0.7200, Val Loss=1.3970, lr=0.0010
[2025-05-01 23:07:25,066][train][INFO] - Epoch 50/100, Val Acc=0.6052, Val Loss=1.5704, lr=0.0100
[2025-05-01 23:07:32,921][train][INFO] - Epoch 82/100, Val Acc=0.7223, Val Loss=1.3973, lr=0.0010
[2025-05-01 23:07:33,064][train][INFO] - Epoch 51/100, Val Acc=0.6037, Val Loss=1.6158, lr=0.0100
[2025-05-01 23:07:40,735][train][INFO] - Epoch 52/100, Val Acc=0.6006, Val Loss=1.6191, lr=0.0100
[2025-05-01 23:07:41,114][train][INFO] - Epoch 83/100, Val Acc=0.7222, Val Loss=1.3847, lr=0.0010
[2025-05-01 23:07:48,526][train][INFO] - Epoch 53/100, Val Acc=0.6043, Val Loss=1.5945, lr=0.0100
[2025-05-01 23:07:48,594][train][INFO] - Epoch 84/100, Val Acc=0.7229, Val Loss=1.3986, lr=0.0010
[2025-05-01 23:07:55,875][train][INFO] - Epoch 85/100, Val Acc=0.7237, Val Loss=1.4124, lr=0.0010
[2025-05-01 23:07:56,230][train][INFO] - Epoch 54/100, Val Acc=0.5996, Val Loss=1.6636, lr=0.0100
[2025-05-01 23:08:03,712][train][INFO] - Epoch 86/100, Val Acc=0.7230, Val Loss=1.4058, lr=0.0010
[2025-05-01 23:08:03,976][train][INFO] - Epoch 55/100, Val Acc=0.6140, Val Loss=1.5015, lr=0.0100
[2025-05-01 23:08:11,467][train][INFO] - Epoch 87/100, Val Acc=0.7249, Val Loss=1.4100, lr=0.0010
[2025-05-01 23:08:12,032][train][INFO] - Epoch 56/100, Val Acc=0.6129, Val Loss=1.5736, lr=0.0100
[2025-05-01 23:08:19,915][train][INFO] - Epoch 88/100, Val Acc=0.7224, Val Loss=1.4000, lr=0.0010
[2025-05-01 23:08:19,976][train][INFO] - Epoch 57/100, Val Acc=0.5853, Val Loss=1.7358, lr=0.0100
[2025-05-01 23:08:27,769][train][INFO] - Epoch 89/100, Val Acc=0.7242, Val Loss=1.4086, lr=0.0010
[2025-05-01 23:08:28,345][train][INFO] - Epoch 58/100, Val Acc=0.6109, Val Loss=1.5894, lr=0.0100
[2025-05-01 23:08:36,295][train][INFO] - Epoch 90/100, Val Acc=0.7213, Val Loss=1.4144, lr=0.0010
[2025-05-01 23:08:36,437][train][INFO] - Epoch 59/100, Val Acc=0.6199, Val Loss=1.5124, lr=0.0100
[2025-05-01 23:08:43,566][train][INFO] - Epoch 60/100, Val Acc=0.6216, Val Loss=1.5584, lr=0.0100
[2025-05-01 23:08:44,079][train][INFO] - Epoch 91/100, Val Acc=0.7226, Val Loss=1.4094, lr=0.0001
[2025-05-01 23:08:51,447][train][INFO] - Epoch 61/100, Val Acc=0.6754, Val Loss=1.2923, lr=0.0010
[2025-05-01 23:08:52,382][train][INFO] - Epoch 92/100, Val Acc=0.7237, Val Loss=1.4149, lr=0.0001
[2025-05-01 23:08:59,609][train][INFO] - Epoch 62/100, Val Acc=0.6826, Val Loss=1.2875, lr=0.0010
[2025-05-01 23:09:00,333][train][INFO] - Epoch 93/100, Val Acc=0.7230, Val Loss=1.4141, lr=0.0001
[2025-05-01 23:09:07,782][train][INFO] - Epoch 63/100, Val Acc=0.6840, Val Loss=1.2946, lr=0.0010
[2025-05-01 23:09:08,514][train][INFO] - Epoch 94/100, Val Acc=0.7241, Val Loss=1.4118, lr=0.0001
[2025-05-01 23:09:15,862][train][INFO] - Epoch 64/100, Val Acc=0.6818, Val Loss=1.3046, lr=0.0010
[2025-05-01 23:09:16,245][train][INFO] - Epoch 95/100, Val Acc=0.7234, Val Loss=1.4121, lr=0.0001
[2025-05-01 23:09:23,621][train][INFO] - Epoch 65/100, Val Acc=0.6831, Val Loss=1.3007, lr=0.0010
[2025-05-01 23:09:24,499][train][INFO] - Epoch 96/100, Val Acc=0.7232, Val Loss=1.4080, lr=0.0001
[2025-05-01 23:09:31,850][train][INFO] - Epoch 66/100, Val Acc=0.6834, Val Loss=1.3195, lr=0.0010
[2025-05-01 23:09:32,641][train][INFO] - Epoch 97/100, Val Acc=0.7237, Val Loss=1.4129, lr=0.0001
[2025-05-01 23:09:39,694][train][INFO] - Epoch 67/100, Val Acc=0.6832, Val Loss=1.3202, lr=0.0010
[2025-05-01 23:09:41,237][train][INFO] - Epoch 98/100, Val Acc=0.7242, Val Loss=1.4058, lr=0.0001
[2025-05-01 23:09:48,079][train][INFO] - Epoch 68/100, Val Acc=0.6850, Val Loss=1.3252, lr=0.0010
[2025-05-01 23:09:49,397][train][INFO] - Epoch 99/100, Val Acc=0.7238, Val Loss=1.4111, lr=0.0001
[2025-05-01 23:09:56,045][train][INFO] - Epoch 69/100, Val Acc=0.6862, Val Loss=1.3308, lr=0.0010
[2025-05-01 23:09:57,731][train][INFO] - Epoch 100/100, Val Acc=0.7246, Val Loss=1.4087, lr=0.0001
[2025-05-01 23:10:02,885][train][INFO] - After training : Train Acc=0.9963  Val Acc=0.7249
[2025-05-01 23:10:04,177][train][INFO] - Epoch 70/100, Val Acc=0.6844, Val Loss=1.3419, lr=0.0010
[2025-05-01 23:10:12,496][train][INFO] - Epoch 71/100, Val Acc=0.6822, Val Loss=1.3559, lr=0.0010
[2025-05-01 23:10:13,667][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-01 23:10:13,668][Progressive pruning][INFO] - Current speed up: 2.28
[2025-05-01 23:10:18,812][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 23:10:20,898][train][INFO] - Epoch 72/100, Val Acc=0.6820, Val Loss=1.3745, lr=0.0010
[2025-05-01 23:10:27,230][train][INFO] - Epoch 1/140, Val Acc=0.5282, Val Loss=2.1740, lr=0.0100
[2025-05-01 23:10:28,403][train][INFO] - Epoch 73/100, Val Acc=0.6848, Val Loss=1.3495, lr=0.0010
[2025-05-01 23:10:35,727][train][INFO] - Epoch 2/140, Val Acc=0.5519, Val Loss=2.0892, lr=0.0100
[2025-05-01 23:10:36,193][train][INFO] - Epoch 74/100, Val Acc=0.6853, Val Loss=1.3607, lr=0.0010
[2025-05-01 23:10:44,118][train][INFO] - Epoch 3/140, Val Acc=0.6038, Val Loss=1.7326, lr=0.0100
[2025-05-01 23:10:44,608][train][INFO] - Epoch 75/100, Val Acc=0.6852, Val Loss=1.3720, lr=0.0010
[2025-05-01 23:10:52,291][train][INFO] - Epoch 4/140, Val Acc=0.5981, Val Loss=1.7900, lr=0.0100
[2025-05-01 23:10:53,029][train][INFO] - Epoch 76/100, Val Acc=0.6881, Val Loss=1.3673, lr=0.0010
[2025-05-01 23:11:00,026][train][INFO] - Epoch 5/140, Val Acc=0.6090, Val Loss=1.7011, lr=0.0100
[2025-05-01 23:11:01,372][train][INFO] - Epoch 77/100, Val Acc=0.6854, Val Loss=1.3936, lr=0.0010
[2025-05-01 23:11:07,958][train][INFO] - Epoch 6/140, Val Acc=0.6190, Val Loss=1.7214, lr=0.0100
[2025-05-01 23:11:09,989][train][INFO] - Epoch 78/100, Val Acc=0.6810, Val Loss=1.3901, lr=0.0010
[2025-05-01 23:11:16,499][train][INFO] - Epoch 7/140, Val Acc=0.6441, Val Loss=1.5628, lr=0.0100
[2025-05-01 23:11:18,139][train][INFO] - Epoch 79/100, Val Acc=0.6870, Val Loss=1.4041, lr=0.0010
[2025-05-01 23:11:25,092][train][INFO] - Epoch 8/140, Val Acc=0.6165, Val Loss=1.7210, lr=0.0100
[2025-05-01 23:11:26,010][train][INFO] - Epoch 80/100, Val Acc=0.6851, Val Loss=1.4087, lr=0.0010
[2025-05-01 23:11:33,404][train][INFO] - Epoch 9/140, Val Acc=0.6123, Val Loss=1.7184, lr=0.0100
[2025-05-01 23:11:33,547][train][INFO] - Epoch 81/100, Val Acc=0.6820, Val Loss=1.4197, lr=0.0010
[2025-05-01 23:11:41,199][train][INFO] - Epoch 82/100, Val Acc=0.6856, Val Loss=1.4154, lr=0.0010
[2025-05-01 23:11:42,190][train][INFO] - Epoch 10/140, Val Acc=0.6404, Val Loss=1.5901, lr=0.0100
[2025-05-01 23:11:49,426][train][INFO] - Epoch 83/100, Val Acc=0.6814, Val Loss=1.4278, lr=0.0010
[2025-05-01 23:11:50,268][train][INFO] - Epoch 11/140, Val Acc=0.6406, Val Loss=1.6072, lr=0.0100
[2025-05-01 23:11:57,082][train][INFO] - Epoch 84/100, Val Acc=0.6829, Val Loss=1.4447, lr=0.0010
[2025-05-01 23:11:58,128][train][INFO] - Epoch 12/140, Val Acc=0.6338, Val Loss=1.6312, lr=0.0100
[2025-05-01 23:12:05,516][train][INFO] - Epoch 85/100, Val Acc=0.6854, Val Loss=1.4329, lr=0.0010
[2025-05-01 23:12:05,551][train][INFO] - Epoch 13/140, Val Acc=0.6244, Val Loss=1.6705, lr=0.0100
[2025-05-01 23:12:13,975][train][INFO] - Epoch 86/100, Val Acc=0.6820, Val Loss=1.4432, lr=0.0010
[2025-05-01 23:12:14,245][train][INFO] - Epoch 14/140, Val Acc=0.6256, Val Loss=1.6830, lr=0.0100
[2025-05-01 23:12:21,070][train][INFO] - Epoch 87/100, Val Acc=0.6816, Val Loss=1.4503, lr=0.0010
[2025-05-01 23:12:22,415][train][INFO] - Epoch 15/140, Val Acc=0.6267, Val Loss=1.7233, lr=0.0100
[2025-05-01 23:12:29,450][train][INFO] - Epoch 88/100, Val Acc=0.6818, Val Loss=1.4579, lr=0.0010
[2025-05-01 23:12:30,966][train][INFO] - Epoch 16/140, Val Acc=0.6362, Val Loss=1.6747, lr=0.0100
[2025-05-01 23:12:37,850][train][INFO] - Epoch 89/100, Val Acc=0.6789, Val Loss=1.4684, lr=0.0010
[2025-05-01 23:12:39,462][train][INFO] - Epoch 17/140, Val Acc=0.6363, Val Loss=1.6340, lr=0.0100
[2025-05-01 23:12:45,616][train][INFO] - Epoch 90/100, Val Acc=0.6844, Val Loss=1.4764, lr=0.0010
[2025-05-01 23:12:47,697][train][INFO] - Epoch 18/140, Val Acc=0.6438, Val Loss=1.6118, lr=0.0100
[2025-05-01 23:12:53,794][train][INFO] - Epoch 91/100, Val Acc=0.6841, Val Loss=1.4570, lr=0.0001
[2025-05-01 23:12:55,595][train][INFO] - Epoch 19/140, Val Acc=0.6346, Val Loss=1.6836, lr=0.0100
[2025-05-01 23:13:01,712][train][INFO] - Epoch 92/100, Val Acc=0.6841, Val Loss=1.4638, lr=0.0001
[2025-05-01 23:13:04,132][train][INFO] - Epoch 20/140, Val Acc=0.6437, Val Loss=1.6113, lr=0.0100
[2025-05-01 23:13:09,744][train][INFO] - Epoch 93/100, Val Acc=0.6857, Val Loss=1.4591, lr=0.0001
[2025-05-01 23:13:12,546][train][INFO] - Epoch 21/140, Val Acc=0.6310, Val Loss=1.7069, lr=0.0100
[2025-05-01 23:13:16,803][train][INFO] - Epoch 94/100, Val Acc=0.6878, Val Loss=1.4511, lr=0.0001
[2025-05-01 23:13:20,696][train][INFO] - Epoch 22/140, Val Acc=0.6355, Val Loss=1.7047, lr=0.0100
[2025-05-01 23:13:24,854][train][INFO] - Epoch 95/100, Val Acc=0.6865, Val Loss=1.4601, lr=0.0001
[2025-05-01 23:13:28,701][train][INFO] - Epoch 23/140, Val Acc=0.6420, Val Loss=1.6657, lr=0.0100
[2025-05-01 23:13:33,355][train][INFO] - Epoch 96/100, Val Acc=0.6874, Val Loss=1.4536, lr=0.0001
[2025-05-01 23:13:37,145][train][INFO] - Epoch 24/140, Val Acc=0.6280, Val Loss=1.7396, lr=0.0100
[2025-05-01 23:13:41,763][train][INFO] - Epoch 97/100, Val Acc=0.6855, Val Loss=1.4601, lr=0.0001
[2025-05-01 23:13:45,582][train][INFO] - Epoch 25/140, Val Acc=0.6282, Val Loss=1.7342, lr=0.0100
[2025-05-01 23:13:50,437][train][INFO] - Epoch 98/100, Val Acc=0.6859, Val Loss=1.4594, lr=0.0001
[2025-05-01 23:13:53,996][train][INFO] - Epoch 26/140, Val Acc=0.6417, Val Loss=1.6490, lr=0.0100
[2025-05-01 23:13:58,726][train][INFO] - Epoch 99/100, Val Acc=0.6884, Val Loss=1.4637, lr=0.0001
[2025-05-01 23:14:02,424][train][INFO] - Epoch 27/140, Val Acc=0.6360, Val Loss=1.6876, lr=0.0100
[2025-05-01 23:14:06,532][train][INFO] - Epoch 100/100, Val Acc=0.6860, Val Loss=1.4632, lr=0.0001
[2025-05-01 23:14:10,765][train][INFO] - Epoch 28/140, Val Acc=0.6390, Val Loss=1.6520, lr=0.0100
[2025-05-01 23:14:11,781][train][INFO] - After training : Train Acc=0.9632  Val Acc=0.6884
[2025-05-01 23:14:11,790][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 23:14:18,852][train][INFO] - Epoch 29/140, Val Acc=0.6502, Val Loss=1.5822, lr=0.0100
[2025-05-01 23:14:27,408][train][INFO] - Epoch 30/140, Val Acc=0.6428, Val Loss=1.6443, lr=0.0100
[2025-05-01 23:14:35,868][train][INFO] - Epoch 31/140, Val Acc=0.6311, Val Loss=1.7504, lr=0.0100
[2025-05-01 23:14:44,151][train][INFO] - Epoch 32/140, Val Acc=0.6478, Val Loss=1.6185, lr=0.0100
[2025-05-01 23:14:52,489][train][INFO] - Epoch 33/140, Val Acc=0.6503, Val Loss=1.6151, lr=0.0100
[2025-05-01 23:15:00,630][train][INFO] - Epoch 34/140, Val Acc=0.6361, Val Loss=1.7393, lr=0.0100
[2025-05-01 23:15:08,894][train][INFO] - Epoch 35/140, Val Acc=0.6071, Val Loss=1.8943, lr=0.0100
[2025-05-01 23:15:16,920][train][INFO] - Epoch 36/140, Val Acc=0.6549, Val Loss=1.5716, lr=0.0100
[2025-05-01 23:15:24,956][train][INFO] - Epoch 37/140, Val Acc=0.6398, Val Loss=1.6666, lr=0.0100
[2025-05-01 23:15:32,692][train][INFO] - Epoch 38/140, Val Acc=0.6483, Val Loss=1.6383, lr=0.0100
[2025-05-01 23:15:41,128][train][INFO] - Epoch 39/140, Val Acc=0.6314, Val Loss=1.7582, lr=0.0100
[2025-05-01 23:15:48,636][train][INFO] - Epoch 40/140, Val Acc=0.6456, Val Loss=1.6652, lr=0.0100
[2025-05-01 23:15:56,720][train][INFO] - Epoch 41/140, Val Acc=0.6392, Val Loss=1.6786, lr=0.0100
[2025-05-01 23:16:02,069][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 23:16:04,927][train][INFO] - Epoch 42/140, Val Acc=0.6460, Val Loss=1.6137, lr=0.0100
[2025-05-01 23:16:13,247][train][INFO] - Epoch 43/140, Val Acc=0.6219, Val Loss=1.7683, lr=0.0100
[2025-05-01 23:16:21,350][train][INFO] - Epoch 44/140, Val Acc=0.6516, Val Loss=1.6147, lr=0.0100
[2025-05-01 23:16:29,610][train][INFO] - Epoch 45/140, Val Acc=0.6260, Val Loss=1.7713, lr=0.0100
[2025-05-01 23:16:37,975][train][INFO] - Epoch 46/140, Val Acc=0.6402, Val Loss=1.6494, lr=0.0100
[2025-05-01 23:16:45,721][train][INFO] - Epoch 47/140, Val Acc=0.6399, Val Loss=1.7253, lr=0.0100
[2025-05-01 23:16:54,144][train][INFO] - Epoch 48/140, Val Acc=0.6345, Val Loss=1.7356, lr=0.0100
[2025-05-01 23:17:01,772][train][INFO] - Epoch 49/140, Val Acc=0.6541, Val Loss=1.6278, lr=0.0100
[2025-05-01 23:17:10,225][train][INFO] - Epoch 50/140, Val Acc=0.6169, Val Loss=1.8158, lr=0.0100
[2025-05-01 23:17:17,938][train][INFO] - Epoch 51/140, Val Acc=0.6379, Val Loss=1.7416, lr=0.0100
[2025-05-01 23:17:26,320][train][INFO] - Epoch 52/140, Val Acc=0.6299, Val Loss=1.7691, lr=0.0100
[2025-05-01 23:17:34,447][train][INFO] - Epoch 53/140, Val Acc=0.6317, Val Loss=1.7385, lr=0.0100
[2025-05-01 23:17:42,816][train][INFO] - Epoch 54/140, Val Acc=0.6300, Val Loss=1.7757, lr=0.0100
[2025-05-01 23:17:50,947][train][INFO] - Epoch 55/140, Val Acc=0.6337, Val Loss=1.7563, lr=0.0100
[2025-05-01 23:17:59,437][train][INFO] - Epoch 56/140, Val Acc=0.6413, Val Loss=1.6504, lr=0.0100
[2025-05-01 23:18:07,250][train][INFO] - Epoch 57/140, Val Acc=0.6327, Val Loss=1.7381, lr=0.0100
[2025-05-01 23:18:15,580][train][INFO] - Epoch 58/140, Val Acc=0.6369, Val Loss=1.7281, lr=0.0100
[2025-05-01 23:18:23,684][train][INFO] - Epoch 59/140, Val Acc=0.6137, Val Loss=1.8401, lr=0.0100
[2025-05-01 23:18:24,057][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 23:18:24,528][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 23:18:30,662][train][INFO] - Epoch 60/140, Val Acc=0.6358, Val Loss=1.7031, lr=0.0100
[2025-05-01 23:18:38,818][train][INFO] - Epoch 61/140, Val Acc=0.6495, Val Loss=1.6334, lr=0.0100
[2025-05-01 23:18:46,899][train][INFO] - Epoch 62/140, Val Acc=0.6495, Val Loss=1.6509, lr=0.0100
[2025-05-01 23:18:55,184][train][INFO] - Epoch 63/140, Val Acc=0.6517, Val Loss=1.6168, lr=0.0100
[2025-05-01 23:19:03,330][train][INFO] - Epoch 64/140, Val Acc=0.6411, Val Loss=1.6671, lr=0.0100
[2025-05-01 23:19:11,493][train][INFO] - Epoch 65/140, Val Acc=0.6460, Val Loss=1.7068, lr=0.0100
[2025-05-01 23:19:18,817][train][INFO] - Epoch 66/140, Val Acc=0.6397, Val Loss=1.7072, lr=0.0100
[2025-05-01 23:19:26,829][train][INFO] - Epoch 67/140, Val Acc=0.6275, Val Loss=1.7786, lr=0.0100
[2025-05-01 23:19:34,667][train][INFO] - Epoch 68/140, Val Acc=0.6337, Val Loss=1.7595, lr=0.0100
[2025-05-01 23:19:42,507][train][INFO] - Epoch 69/140, Val Acc=0.6524, Val Loss=1.6624, lr=0.0100
[2025-05-01 23:19:49,849][train][INFO] - Epoch 70/140, Val Acc=0.6445, Val Loss=1.7186, lr=0.0100
[2025-05-01 23:19:58,442][train][INFO] - Epoch 71/140, Val Acc=0.6274, Val Loss=1.7966, lr=0.0100
[2025-05-01 23:20:06,127][train][INFO] - Epoch 72/140, Val Acc=0.6466, Val Loss=1.6838, lr=0.0100
[2025-05-01 23:20:14,760][train][INFO] - Epoch 73/140, Val Acc=0.6384, Val Loss=1.7065, lr=0.0100
[2025-05-01 23:20:22,856][train][INFO] - Epoch 74/140, Val Acc=0.6459, Val Loss=1.6645, lr=0.0100
[2025-05-01 23:20:30,914][train][INFO] - Epoch 75/140, Val Acc=0.6449, Val Loss=1.7158, lr=0.0100
[2025-05-01 23:20:39,532][train][INFO] - Epoch 76/140, Val Acc=0.6282, Val Loss=1.7950, lr=0.0100
[2025-05-01 23:20:47,589][train][INFO] - Epoch 77/140, Val Acc=0.6449, Val Loss=1.6657, lr=0.0100
[2025-05-01 23:20:54,919][train][INFO] - Epoch 78/140, Val Acc=0.6361, Val Loss=1.7484, lr=0.0100
[2025-05-01 23:21:03,376][train][INFO] - Epoch 79/140, Val Acc=0.6442, Val Loss=1.7153, lr=0.0100
[2025-05-01 23:21:11,975][train][INFO] - Epoch 80/140, Val Acc=0.6453, Val Loss=1.6753, lr=0.0100
[2025-05-01 23:21:20,170][train][INFO] - Epoch 81/140, Val Acc=0.7000, Val Loss=1.4090, lr=0.0010
[2025-05-01 23:21:27,901][train][INFO] - Epoch 82/140, Val Acc=0.7071, Val Loss=1.4032, lr=0.0010
[2025-05-01 23:21:36,079][train][INFO] - Epoch 83/140, Val Acc=0.7090, Val Loss=1.4028, lr=0.0010
[2025-05-01 23:21:44,224][train][INFO] - Epoch 84/140, Val Acc=0.7117, Val Loss=1.4092, lr=0.0010
[2025-05-01 23:21:52,587][train][INFO] - Epoch 85/140, Val Acc=0.7114, Val Loss=1.4108, lr=0.0010
[2025-05-01 23:22:00,413][train][INFO] - Epoch 86/140, Val Acc=0.7092, Val Loss=1.4225, lr=0.0010
[2025-05-01 23:22:08,342][train][INFO] - Epoch 87/140, Val Acc=0.7133, Val Loss=1.4238, lr=0.0010
[2025-05-01 23:22:16,927][train][INFO] - Epoch 88/140, Val Acc=0.7139, Val Loss=1.4265, lr=0.0010
[2025-05-01 23:22:25,306][train][INFO] - Epoch 89/140, Val Acc=0.7121, Val Loss=1.4306, lr=0.0010
[2025-05-01 23:22:33,562][train][INFO] - Epoch 90/140, Val Acc=0.7124, Val Loss=1.4282, lr=0.0010
[2025-05-01 23:22:42,061][train][INFO] - Epoch 91/140, Val Acc=0.7128, Val Loss=1.4452, lr=0.0010
[2025-05-01 23:22:49,747][train][INFO] - Epoch 92/140, Val Acc=0.7131, Val Loss=1.4448, lr=0.0010
[2025-05-01 23:22:57,120][train][INFO] - Epoch 93/140, Val Acc=0.7155, Val Loss=1.4389, lr=0.0010
[2025-05-01 23:23:04,495][train][INFO] - Epoch 94/140, Val Acc=0.7148, Val Loss=1.4505, lr=0.0010
[2025-05-01 23:23:13,048][train][INFO] - Epoch 95/140, Val Acc=0.7160, Val Loss=1.4436, lr=0.0010
[2025-05-01 23:23:20,866][train][INFO] - Epoch 96/140, Val Acc=0.7153, Val Loss=1.4532, lr=0.0010
[2025-05-01 23:23:29,458][train][INFO] - Epoch 97/140, Val Acc=0.7139, Val Loss=1.4556, lr=0.0010
[2025-05-01 23:23:38,481][train][INFO] - Epoch 98/140, Val Acc=0.7110, Val Loss=1.4601, lr=0.0010
[2025-05-01 23:23:46,896][train][INFO] - Epoch 99/140, Val Acc=0.7130, Val Loss=1.4652, lr=0.0010
[2025-05-01 23:23:55,345][train][INFO] - Epoch 100/140, Val Acc=0.7140, Val Loss=1.4580, lr=0.0010
[2025-05-01 23:24:02,779][train][INFO] - Epoch 101/140, Val Acc=0.7119, Val Loss=1.4597, lr=0.0010
[2025-05-01 23:24:10,952][train][INFO] - Epoch 102/140, Val Acc=0.7130, Val Loss=1.4700, lr=0.0010
[2025-05-01 23:24:18,750][train][INFO] - Epoch 103/140, Val Acc=0.7162, Val Loss=1.4610, lr=0.0010
[2025-05-01 23:24:26,921][train][INFO] - Epoch 104/140, Val Acc=0.7125, Val Loss=1.4768, lr=0.0010
[2025-05-01 23:24:35,271][train][INFO] - Epoch 105/140, Val Acc=0.7151, Val Loss=1.4718, lr=0.0010
[2025-05-01 23:24:43,255][train][INFO] - Epoch 106/140, Val Acc=0.7138, Val Loss=1.4777, lr=0.0010
[2025-05-01 23:24:51,957][train][INFO] - Epoch 107/140, Val Acc=0.7160, Val Loss=1.4711, lr=0.0010
[2025-05-01 23:25:00,021][train][INFO] - Epoch 108/140, Val Acc=0.7141, Val Loss=1.4705, lr=0.0010
[2025-05-01 23:25:08,648][train][INFO] - Epoch 109/140, Val Acc=0.7171, Val Loss=1.4748, lr=0.0010
[2025-05-01 23:25:16,804][train][INFO] - Epoch 110/140, Val Acc=0.7164, Val Loss=1.4820, lr=0.0010
[2025-05-01 23:25:25,022][train][INFO] - Epoch 111/140, Val Acc=0.7203, Val Loss=1.4690, lr=0.0010
[2025-05-01 23:25:32,887][train][INFO] - Epoch 112/140, Val Acc=0.7159, Val Loss=1.4744, lr=0.0010
[2025-05-01 23:25:41,279][train][INFO] - Epoch 113/140, Val Acc=0.7159, Val Loss=1.4743, lr=0.0010
[2025-05-01 23:25:49,946][train][INFO] - Epoch 114/140, Val Acc=0.7155, Val Loss=1.4780, lr=0.0010
[2025-05-01 23:25:58,415][train][INFO] - Epoch 115/140, Val Acc=0.7168, Val Loss=1.4809, lr=0.0010
[2025-05-01 23:26:06,753][train][INFO] - Epoch 116/140, Val Acc=0.7161, Val Loss=1.4745, lr=0.0010
[2025-05-01 23:26:15,018][train][INFO] - Epoch 117/140, Val Acc=0.7164, Val Loss=1.4848, lr=0.0010
[2025-05-01 23:26:23,409][train][INFO] - Epoch 118/140, Val Acc=0.7149, Val Loss=1.4896, lr=0.0010
[2025-05-01 23:26:31,396][train][INFO] - Epoch 119/140, Val Acc=0.7145, Val Loss=1.4853, lr=0.0010
[2025-05-01 23:26:40,074][train][INFO] - Epoch 120/140, Val Acc=0.7134, Val Loss=1.4819, lr=0.0010
[2025-05-01 23:26:48,722][train][INFO] - Epoch 121/140, Val Acc=0.7158, Val Loss=1.4747, lr=0.0001
[2025-05-01 23:26:57,072][train][INFO] - Epoch 122/140, Val Acc=0.7146, Val Loss=1.4761, lr=0.0001
[2025-05-01 23:27:05,106][train][INFO] - Epoch 123/140, Val Acc=0.7160, Val Loss=1.4739, lr=0.0001
[2025-05-01 23:27:13,515][train][INFO] - Epoch 124/140, Val Acc=0.7162, Val Loss=1.4723, lr=0.0001
[2025-05-01 23:27:21,061][train][INFO] - Epoch 125/140, Val Acc=0.7168, Val Loss=1.4753, lr=0.0001
[2025-05-01 23:27:29,302][train][INFO] - Epoch 126/140, Val Acc=0.7188, Val Loss=1.4737, lr=0.0001
[2025-05-01 23:27:37,817][train][INFO] - Epoch 127/140, Val Acc=0.7178, Val Loss=1.4845, lr=0.0001
[2025-05-01 23:27:45,142][train][INFO] - Epoch 128/140, Val Acc=0.7181, Val Loss=1.4718, lr=0.0001
[2025-05-01 23:27:53,511][train][INFO] - Epoch 129/140, Val Acc=0.7169, Val Loss=1.4699, lr=0.0001
[2025-05-01 23:28:01,470][train][INFO] - Epoch 130/140, Val Acc=0.7173, Val Loss=1.4747, lr=0.0001
[2025-05-01 23:28:09,861][train][INFO] - Epoch 131/140, Val Acc=0.7161, Val Loss=1.4793, lr=0.0001
[2025-05-01 23:28:18,090][train][INFO] - Epoch 132/140, Val Acc=0.7160, Val Loss=1.4821, lr=0.0001
[2025-05-01 23:28:26,021][train][INFO] - Epoch 133/140, Val Acc=0.7181, Val Loss=1.4772, lr=0.0001
[2025-05-01 23:28:34,082][train][INFO] - Epoch 134/140, Val Acc=0.7184, Val Loss=1.4754, lr=0.0001
[2025-05-01 23:28:40,918][train][INFO] - Epoch 135/140, Val Acc=0.7173, Val Loss=1.4791, lr=0.0001
[2025-05-01 23:28:49,347][train][INFO] - Epoch 136/140, Val Acc=0.7180, Val Loss=1.4764, lr=0.0001
[2025-05-01 23:28:58,043][train][INFO] - Epoch 137/140, Val Acc=0.7172, Val Loss=1.4801, lr=0.0001
[2025-05-01 23:29:06,194][train][INFO] - Epoch 138/140, Val Acc=0.7192, Val Loss=1.4760, lr=0.0001
[2025-05-01 23:29:14,286][train][INFO] - Epoch 139/140, Val Acc=0.7174, Val Loss=1.4773, lr=0.0001
[2025-05-01 23:29:22,791][train][INFO] - Epoch 140/140, Val Acc=0.7172, Val Loss=1.4812, lr=0.0001
[2025-05-01 23:29:28,092][train][INFO] - After training : Train Acc=0.9984  Val Acc=0.7203
[2025-05-01 23:29:28,126][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(9, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(51, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(120, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(254, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(252, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(122, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(38, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(5, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(3, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(41, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(19, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(40, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(115, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=127, out_features=100, bias=True)
)
[2025-05-01 23:29:28,126][Pruning][INFO] - Origin val acc : 0.736799955368042 Final val acc : 0.7202999591827393
                      Speed up: 2.28   Final speed up: 3.03
