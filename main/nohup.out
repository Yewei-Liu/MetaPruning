[2025-04-28 23:06:49,017][root][INFO] - 

task:
  _recursive_: true
  model_name: resnet56
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR10
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: resnet56_on_CIFAR10
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '2'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.925
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 128
      in_node_dim: 8
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index: 2.86
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oliver
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 21
seed: 7
index:
- 10
- 14
- 18
- 22
- 26
- 30

[2025-04-28 23:06:49,148][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-28 23:06:49,148][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-28 23:06:49,148][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-28 23:07:01,342][train][INFO] - Before training : Train Acc=0.1021  Val Acc=0.1027
[2025-04-28 23:07:15,443][train][INFO] - Epoch 1/100, Val Acc=0.8387, Val Loss=0.5031, lr=0.0100
[2025-04-28 23:07:46,370][root][INFO] - 

task:
  _recursive_: true
  model_name: resnet56
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR10
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: resnet56_on_CIFAR10
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '2'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.925
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 128
      in_node_dim: 8
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index: 2.86
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oliver
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 21
seed: 7
index:
- 10
- 14
- 18
- 22
- 26
- 30
- 34
- 38
- 42

[2025-04-28 23:07:46,513][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-28 23:07:46,513][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-28 23:07:46,513][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-28 23:07:58,861][train][INFO] - Before training : Train Acc=0.1021  Val Acc=0.1027
[2025-04-28 23:08:14,221][train][INFO] - Epoch 1/100, Val Acc=0.8387, Val Loss=0.5031, lr=0.0100
[2025-04-28 23:08:30,946][train][INFO] - Epoch 2/100, Val Acc=0.8584, Val Loss=0.4243, lr=0.0100
[2025-04-28 23:08:47,331][train][INFO] - Epoch 3/100, Val Acc=0.8597, Val Loss=0.4404, lr=0.0100
[2025-04-28 23:09:03,325][train][INFO] - Epoch 4/100, Val Acc=0.8899, Val Loss=0.3397, lr=0.0100
[2025-04-28 23:09:18,595][train][INFO] - Epoch 5/100, Val Acc=0.8884, Val Loss=0.3425, lr=0.0100
[2025-04-28 23:09:33,079][train][INFO] - Epoch 6/100, Val Acc=0.8858, Val Loss=0.3656, lr=0.0100
[2025-04-28 23:09:48,980][train][INFO] - Epoch 7/100, Val Acc=0.8857, Val Loss=0.3683, lr=0.0100
[2025-04-28 23:10:04,007][train][INFO] - Epoch 8/100, Val Acc=0.8910, Val Loss=0.3472, lr=0.0100
[2025-04-28 23:10:18,982][train][INFO] - Epoch 9/100, Val Acc=0.8916, Val Loss=0.3544, lr=0.0100
[2025-04-28 23:10:36,943][train][INFO] - Epoch 10/100, Val Acc=0.8907, Val Loss=0.3500, lr=0.0100
[2025-04-28 23:10:54,049][train][INFO] - Epoch 11/100, Val Acc=0.9011, Val Loss=0.3266, lr=0.0100
[2025-04-28 23:11:10,297][train][INFO] - Epoch 12/100, Val Acc=0.8965, Val Loss=0.3377, lr=0.0100
[2025-04-28 23:11:25,768][train][INFO] - Epoch 13/100, Val Acc=0.8973, Val Loss=0.3396, lr=0.0100
[2025-04-28 23:11:41,731][train][INFO] - Epoch 14/100, Val Acc=0.8958, Val Loss=0.3427, lr=0.0100
[2025-04-28 23:11:57,476][train][INFO] - Epoch 15/100, Val Acc=0.8930, Val Loss=0.3704, lr=0.0100
[2025-04-28 23:12:14,029][train][INFO] - Epoch 16/100, Val Acc=0.8990, Val Loss=0.3509, lr=0.0100
[2025-04-28 23:12:30,243][train][INFO] - Epoch 17/100, Val Acc=0.9051, Val Loss=0.3149, lr=0.0100
[2025-04-28 23:12:46,314][train][INFO] - Epoch 18/100, Val Acc=0.9033, Val Loss=0.3386, lr=0.0100
[2025-04-28 23:13:01,139][train][INFO] - Epoch 19/100, Val Acc=0.8978, Val Loss=0.3337, lr=0.0100
[2025-04-28 23:13:16,646][train][INFO] - Epoch 20/100, Val Acc=0.9125, Val Loss=0.3028, lr=0.0100
[2025-04-28 23:13:33,014][train][INFO] - Epoch 21/100, Val Acc=0.8986, Val Loss=0.3423, lr=0.0100
[2025-04-28 23:13:49,060][train][INFO] - Epoch 22/100, Val Acc=0.9015, Val Loss=0.3400, lr=0.0100
[2025-04-28 23:14:03,871][train][INFO] - Epoch 23/100, Val Acc=0.8959, Val Loss=0.3620, lr=0.0100
[2025-04-28 23:14:19,359][train][INFO] - Epoch 24/100, Val Acc=0.8971, Val Loss=0.3424, lr=0.0100
[2025-04-28 23:14:36,152][train][INFO] - Epoch 25/100, Val Acc=0.8961, Val Loss=0.3419, lr=0.0100
[2025-04-28 23:14:51,359][train][INFO] - Epoch 26/100, Val Acc=0.9072, Val Loss=0.3170, lr=0.0100
[2025-04-28 23:15:07,539][train][INFO] - Epoch 27/100, Val Acc=0.9054, Val Loss=0.3234, lr=0.0100
[2025-04-28 23:15:24,298][train][INFO] - Epoch 28/100, Val Acc=0.9072, Val Loss=0.3139, lr=0.0100
[2025-04-28 23:15:40,958][train][INFO] - Epoch 29/100, Val Acc=0.9033, Val Loss=0.3373, lr=0.0100
[2025-04-28 23:15:56,304][train][INFO] - Epoch 30/100, Val Acc=0.8946, Val Loss=0.3721, lr=0.0100
[2025-04-28 23:16:10,947][train][INFO] - Epoch 31/100, Val Acc=0.8987, Val Loss=0.3456, lr=0.0100
[2025-04-28 23:16:24,512][train][INFO] - Epoch 32/100, Val Acc=0.8999, Val Loss=0.3582, lr=0.0100
[2025-04-28 23:16:40,580][train][INFO] - Epoch 33/100, Val Acc=0.9048, Val Loss=0.3317, lr=0.0100
[2025-04-28 23:16:55,498][train][INFO] - Epoch 34/100, Val Acc=0.8927, Val Loss=0.3892, lr=0.0100
[2025-04-28 23:17:09,614][train][INFO] - Epoch 35/100, Val Acc=0.9127, Val Loss=0.2920, lr=0.0100
[2025-04-28 23:17:23,604][train][INFO] - Epoch 36/100, Val Acc=0.9035, Val Loss=0.3341, lr=0.0100
[2025-04-28 23:17:39,042][train][INFO] - Epoch 37/100, Val Acc=0.9054, Val Loss=0.3290, lr=0.0100
[2025-04-28 23:17:55,872][train][INFO] - Epoch 38/100, Val Acc=0.9091, Val Loss=0.3358, lr=0.0100
[2025-04-28 23:18:12,361][train][INFO] - Epoch 39/100, Val Acc=0.9049, Val Loss=0.3309, lr=0.0100
[2025-04-28 23:18:28,768][train][INFO] - Epoch 40/100, Val Acc=0.9065, Val Loss=0.3239, lr=0.0100
[2025-04-28 23:18:44,147][train][INFO] - Epoch 41/100, Val Acc=0.9048, Val Loss=0.3219, lr=0.0100
[2025-04-28 23:19:00,449][train][INFO] - Epoch 42/100, Val Acc=0.9027, Val Loss=0.3291, lr=0.0100
[2025-04-28 23:19:16,518][train][INFO] - Epoch 43/100, Val Acc=0.9044, Val Loss=0.3279, lr=0.0100
[2025-04-28 23:19:32,542][train][INFO] - Epoch 44/100, Val Acc=0.8997, Val Loss=0.3513, lr=0.0100
[2025-04-28 23:19:48,298][train][INFO] - Epoch 45/100, Val Acc=0.9094, Val Loss=0.3302, lr=0.0100
[2025-04-28 23:20:05,823][train][INFO] - Epoch 46/100, Val Acc=0.9093, Val Loss=0.3233, lr=0.0100
[2025-04-28 23:20:23,023][train][INFO] - Epoch 47/100, Val Acc=0.9024, Val Loss=0.3390, lr=0.0100
[2025-04-28 23:20:37,630][train][INFO] - Epoch 48/100, Val Acc=0.9032, Val Loss=0.3433, lr=0.0100
[2025-04-28 23:20:53,719][train][INFO] - Epoch 49/100, Val Acc=0.9125, Val Loss=0.3150, lr=0.0100
[2025-04-28 23:21:08,722][train][INFO] - Epoch 50/100, Val Acc=0.9059, Val Loss=0.3277, lr=0.0100
[2025-04-28 23:21:25,437][train][INFO] - Epoch 51/100, Val Acc=0.8959, Val Loss=0.3723, lr=0.0100
[2025-04-28 23:21:41,389][train][INFO] - Epoch 52/100, Val Acc=0.9031, Val Loss=0.3534, lr=0.0100
[2025-04-28 23:21:56,792][train][INFO] - Epoch 53/100, Val Acc=0.8962, Val Loss=0.3694, lr=0.0100
[2025-04-28 23:22:12,311][train][INFO] - Epoch 54/100, Val Acc=0.9029, Val Loss=0.3349, lr=0.0100
[2025-04-28 23:22:28,327][train][INFO] - Epoch 55/100, Val Acc=0.9091, Val Loss=0.3212, lr=0.0100
[2025-04-28 23:22:44,116][train][INFO] - Epoch 56/100, Val Acc=0.9089, Val Loss=0.3109, lr=0.0100
[2025-04-28 23:22:57,612][train][INFO] - Epoch 57/100, Val Acc=0.9039, Val Loss=0.3318, lr=0.0100
[2025-04-28 23:23:11,321][train][INFO] - Epoch 58/100, Val Acc=0.8975, Val Loss=0.3723, lr=0.0100
[2025-04-28 23:23:26,230][train][INFO] - Epoch 59/100, Val Acc=0.9073, Val Loss=0.3251, lr=0.0100
[2025-04-28 23:23:40,654][train][INFO] - Epoch 60/100, Val Acc=0.9015, Val Loss=0.3490, lr=0.0100
[2025-04-28 23:23:54,260][train][INFO] - Epoch 61/100, Val Acc=0.9316, Val Loss=0.2468, lr=0.0010
[2025-04-28 23:24:07,157][train][INFO] - Epoch 62/100, Val Acc=0.9326, Val Loss=0.2465, lr=0.0010
[2025-04-28 23:24:22,028][train][INFO] - Epoch 63/100, Val Acc=0.9307, Val Loss=0.2467, lr=0.0010
[2025-04-28 23:24:37,229][train][INFO] - Epoch 64/100, Val Acc=0.9331, Val Loss=0.2512, lr=0.0010
[2025-04-28 23:24:52,290][train][INFO] - Epoch 65/100, Val Acc=0.9343, Val Loss=0.2499, lr=0.0010
[2025-04-28 23:25:08,725][train][INFO] - Epoch 66/100, Val Acc=0.9343, Val Loss=0.2504, lr=0.0010
[2025-04-28 23:25:25,165][train][INFO] - Epoch 67/100, Val Acc=0.9346, Val Loss=0.2506, lr=0.0010
[2025-04-28 23:25:41,217][train][INFO] - Epoch 68/100, Val Acc=0.9353, Val Loss=0.2519, lr=0.0010
[2025-04-28 23:25:56,946][train][INFO] - Epoch 69/100, Val Acc=0.9345, Val Loss=0.2520, lr=0.0010
[2025-04-28 23:26:13,358][train][INFO] - Epoch 70/100, Val Acc=0.9358, Val Loss=0.2536, lr=0.0010
[2025-04-28 23:26:29,456][train][INFO] - Epoch 71/100, Val Acc=0.9353, Val Loss=0.2547, lr=0.0010
[2025-04-28 23:26:45,050][train][INFO] - Epoch 72/100, Val Acc=0.9359, Val Loss=0.2555, lr=0.0010
[2025-04-28 23:27:01,170][train][INFO] - Epoch 73/100, Val Acc=0.9354, Val Loss=0.2561, lr=0.0010
[2025-04-28 23:27:17,621][train][INFO] - Epoch 74/100, Val Acc=0.9368, Val Loss=0.2540, lr=0.0010
[2025-04-28 23:27:34,324][train][INFO] - Epoch 75/100, Val Acc=0.9364, Val Loss=0.2551, lr=0.0010
[2025-04-28 23:27:49,811][train][INFO] - Epoch 76/100, Val Acc=0.9364, Val Loss=0.2541, lr=0.0010
[2025-04-28 23:28:04,457][train][INFO] - Epoch 77/100, Val Acc=0.9366, Val Loss=0.2584, lr=0.0010
[2025-04-28 23:28:20,560][train][INFO] - Epoch 78/100, Val Acc=0.9358, Val Loss=0.2527, lr=0.0010
[2025-04-28 23:28:36,329][train][INFO] - Epoch 79/100, Val Acc=0.9350, Val Loss=0.2581, lr=0.0010
[2025-04-28 23:28:51,721][train][INFO] - Epoch 80/100, Val Acc=0.9358, Val Loss=0.2601, lr=0.0010
[2025-04-28 23:29:06,925][train][INFO] - Epoch 81/100, Val Acc=0.9356, Val Loss=0.2600, lr=0.0010
[2025-04-28 23:29:24,175][train][INFO] - Epoch 82/100, Val Acc=0.9348, Val Loss=0.2599, lr=0.0010
[2025-04-28 23:29:40,652][train][INFO] - Epoch 83/100, Val Acc=0.9352, Val Loss=0.2639, lr=0.0010
[2025-04-28 23:29:57,972][train][INFO] - Epoch 84/100, Val Acc=0.9360, Val Loss=0.2640, lr=0.0010
[2025-04-28 23:30:13,433][train][INFO] - Epoch 85/100, Val Acc=0.9352, Val Loss=0.2610, lr=0.0010
[2025-04-28 23:30:28,960][train][INFO] - Epoch 86/100, Val Acc=0.9349, Val Loss=0.2611, lr=0.0010
[2025-04-28 23:30:44,595][train][INFO] - Epoch 87/100, Val Acc=0.9360, Val Loss=0.2634, lr=0.0010
[2025-04-28 23:31:01,285][train][INFO] - Epoch 88/100, Val Acc=0.9361, Val Loss=0.2642, lr=0.0010
[2025-04-28 23:31:17,118][train][INFO] - Epoch 89/100, Val Acc=0.9359, Val Loss=0.2627, lr=0.0010
[2025-04-28 23:31:33,602][train][INFO] - Epoch 90/100, Val Acc=0.9363, Val Loss=0.2684, lr=0.0010
[2025-04-28 23:31:49,563][train][INFO] - Epoch 91/100, Val Acc=0.9348, Val Loss=0.2656, lr=0.0001
[2025-04-28 23:32:05,618][train][INFO] - Epoch 92/100, Val Acc=0.9349, Val Loss=0.2650, lr=0.0001
[2025-04-28 23:32:21,421][train][INFO] - Epoch 93/100, Val Acc=0.9351, Val Loss=0.2643, lr=0.0001
[2025-04-28 23:32:37,084][train][INFO] - Epoch 94/100, Val Acc=0.9351, Val Loss=0.2669, lr=0.0001
[2025-04-28 23:32:52,966][train][INFO] - Epoch 95/100, Val Acc=0.9352, Val Loss=0.2668, lr=0.0001
[2025-04-28 23:33:07,573][train][INFO] - Epoch 96/100, Val Acc=0.9352, Val Loss=0.2659, lr=0.0001
[2025-04-28 23:33:23,307][train][INFO] - Epoch 97/100, Val Acc=0.9355, Val Loss=0.2645, lr=0.0001
[2025-04-28 23:33:38,430][train][INFO] - Epoch 98/100, Val Acc=0.9356, Val Loss=0.2639, lr=0.0001
[2025-04-28 23:33:53,581][train][INFO] - Epoch 99/100, Val Acc=0.9352, Val Loss=0.2631, lr=0.0001
[2025-04-28 23:34:10,637][train][INFO] - Epoch 100/100, Val Acc=0.9352, Val Loss=0.2635, lr=0.0001
[2025-04-28 23:34:16,706][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.9368
[2025-04-28 23:34:23,316][train][INFO] - Before training : Train Acc=0.1000  Val Acc=0.1000
[2025-04-28 23:34:39,952][train][INFO] - Epoch 1/100, Val Acc=0.6592, Val Loss=1.0488, lr=0.0100
[2025-04-28 23:34:56,630][train][INFO] - Epoch 2/100, Val Acc=0.8278, Val Loss=0.5104, lr=0.0100
[2025-04-28 23:35:12,705][train][INFO] - Epoch 3/100, Val Acc=0.8602, Val Loss=0.4296, lr=0.0100
