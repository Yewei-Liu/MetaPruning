[2025-04-29 21:13:23,851][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:14:03,561][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:14:12,902][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:14:21,889][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:14:30,912][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:14:40,013][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:14:42,376][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:14:49,391][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:14:58,495][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:15:07,785][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:15:17,011][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:15:22,823][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
[2025-04-29 21:15:32,098][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:16:34,886][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:16:34,945][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:16:40,713][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:14,621][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:20,891][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:17:23,878][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:17:30,197][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:17:33,278][train][INFO] - Epoch 2/100, Val Acc=0.6559, Val Loss=1.4929, lr=0.0100
[2025-04-29 21:17:38,508][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:17:42,589][train][INFO] - Epoch 3/100, Val Acc=0.6493, Val Loss=1.5717, lr=0.0100
[2025-04-29 21:17:47,386][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:17:51,819][train][INFO] - Epoch 4/100, Val Acc=0.6716, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:17:56,599][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:18:00,836][train][INFO] - Epoch 5/100, Val Acc=0.6541, Val Loss=1.5486, lr=0.0100
[2025-04-29 21:18:05,679][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:18:10,016][train][INFO] - Epoch 6/100, Val Acc=0.6787, Val Loss=1.4316, lr=0.0100
[2025-04-29 21:18:14,550][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:18:19,288][train][INFO] - Epoch 7/100, Val Acc=0.6565, Val Loss=1.5439, lr=0.0100
[2025-04-29 21:18:23,413][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:18:28,294][train][INFO] - Epoch 8/100, Val Acc=0.6681, Val Loss=1.4811, lr=0.0100
[2025-04-29 21:18:32,758][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
[2025-04-29 21:18:37,477][train][INFO] - Epoch 9/100, Val Acc=0.6764, Val Loss=1.4338, lr=0.0100
[2025-04-29 21:18:41,660][train][INFO] - Epoch 9/100, Val Acc=0.6719, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:18:46,369][train][INFO] - Epoch 10/100, Val Acc=0.6658, Val Loss=1.5013, lr=0.0100
[2025-04-29 21:18:50,398][train][INFO] - Epoch 10/100, Val Acc=0.6556, Val Loss=1.5865, lr=0.0100
[2025-04-29 21:18:55,742][train][INFO] - Epoch 11/100, Val Acc=0.6583, Val Loss=1.5674, lr=0.0100
[2025-04-29 21:18:59,225][train][INFO] - Epoch 11/100, Val Acc=0.6695, Val Loss=1.5202, lr=0.0100
[2025-04-29 21:19:04,889][train][INFO] - Epoch 12/100, Val Acc=0.6701, Val Loss=1.4855, lr=0.0100
[2025-04-29 21:19:08,313][train][INFO] - Epoch 12/100, Val Acc=0.6802, Val Loss=1.4586, lr=0.0100
[2025-04-29 21:19:14,153][train][INFO] - Epoch 13/100, Val Acc=0.6571, Val Loss=1.5929, lr=0.0100
[2025-04-29 21:19:17,399][train][INFO] - Epoch 13/100, Val Acc=0.6604, Val Loss=1.5724, lr=0.0100
[2025-04-29 21:19:23,264][train][INFO] - Epoch 14/100, Val Acc=0.6777, Val Loss=1.4617, lr=0.0100
[2025-04-29 21:19:26,446][train][INFO] - Epoch 14/100, Val Acc=0.6765, Val Loss=1.4714, lr=0.0100
[2025-04-29 21:19:32,312][train][INFO] - Epoch 15/100, Val Acc=0.6640, Val Loss=1.5570, lr=0.0100
[2025-04-29 21:19:35,772][train][INFO] - Epoch 15/100, Val Acc=0.6735, Val Loss=1.5166, lr=0.0100
[2025-04-29 21:19:41,335][train][INFO] - Epoch 16/100, Val Acc=0.6544, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:19:44,730][train][INFO] - Epoch 16/100, Val Acc=0.6552, Val Loss=1.5888, lr=0.0100
[2025-04-29 21:19:50,304][train][INFO] - Epoch 17/100, Val Acc=0.6663, Val Loss=1.5376, lr=0.0100
[2025-04-29 21:19:53,648][train][INFO] - Epoch 17/100, Val Acc=0.6639, Val Loss=1.5253, lr=0.0100
[2025-04-29 21:19:59,540][train][INFO] - Epoch 18/100, Val Acc=0.6688, Val Loss=1.5059, lr=0.0100
[2025-04-29 21:20:02,832][train][INFO] - Epoch 18/100, Val Acc=0.6749, Val Loss=1.4825, lr=0.0100
[2025-04-29 21:20:08,602][train][INFO] - Epoch 19/100, Val Acc=0.6693, Val Loss=1.5015, lr=0.0100
[2025-04-29 21:20:11,990][train][INFO] - Epoch 19/100, Val Acc=0.6623, Val Loss=1.5542, lr=0.0100
[2025-04-29 21:20:17,857][train][INFO] - Epoch 20/100, Val Acc=0.6786, Val Loss=1.4801, lr=0.0100
[2025-04-29 21:20:21,120][train][INFO] - Epoch 20/100, Val Acc=0.6681, Val Loss=1.5447, lr=0.0100
[2025-04-29 21:20:26,928][train][INFO] - Epoch 21/100, Val Acc=0.6652, Val Loss=1.5553, lr=0.0100
[2025-04-29 21:20:30,353][train][INFO] - Epoch 21/100, Val Acc=0.6668, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:20:35,936][train][INFO] - Epoch 22/100, Val Acc=0.6623, Val Loss=1.5446, lr=0.0100
[2025-04-29 21:20:39,397][train][INFO] - Epoch 22/100, Val Acc=0.6714, Val Loss=1.5311, lr=0.0100
[2025-04-29 21:20:45,096][train][INFO] - Epoch 23/100, Val Acc=0.6570, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:20:48,478][train][INFO] - Epoch 23/100, Val Acc=0.6782, Val Loss=1.5189, lr=0.0100
[2025-04-29 21:20:54,211][train][INFO] - Epoch 24/100, Val Acc=0.6686, Val Loss=1.5338, lr=0.0100
[2025-04-29 21:20:57,535][train][INFO] - Epoch 24/100, Val Acc=0.6779, Val Loss=1.4810, lr=0.0100
[2025-04-29 21:21:03,579][train][INFO] - Epoch 25/100, Val Acc=0.6705, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:21:06,771][train][INFO] - Epoch 25/100, Val Acc=0.6698, Val Loss=1.5511, lr=0.0100
[2025-04-29 21:21:12,286][train][INFO] - Epoch 26/100, Val Acc=0.6787, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:21:16,104][train][INFO] - Epoch 26/100, Val Acc=0.6764, Val Loss=1.5026, lr=0.0100
[2025-04-29 21:21:21,306][train][INFO] - Epoch 27/100, Val Acc=0.6724, Val Loss=1.5572, lr=0.0100
[2025-04-29 21:21:25,241][train][INFO] - Epoch 27/100, Val Acc=0.6646, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:21:30,243][train][INFO] - Epoch 28/100, Val Acc=0.6703, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:21:34,198][train][INFO] - Epoch 28/100, Val Acc=0.6731, Val Loss=1.5143, lr=0.0100
[2025-04-29 21:21:39,380][train][INFO] - Epoch 29/100, Val Acc=0.6740, Val Loss=1.5151, lr=0.0100
[2025-04-29 21:21:42,714][train][INFO] - Epoch 29/100, Val Acc=0.6692, Val Loss=1.5227, lr=0.0100
[2025-04-29 21:21:48,492][train][INFO] - Epoch 30/100, Val Acc=0.6677, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:21:51,975][train][INFO] - Epoch 30/100, Val Acc=0.6649, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:21:57,656][train][INFO] - Epoch 31/100, Val Acc=0.6735, Val Loss=1.5356, lr=0.0100
[2025-04-29 21:22:01,180][train][INFO] - Epoch 31/100, Val Acc=0.6602, Val Loss=1.6021, lr=0.0100
[2025-04-29 21:22:06,563][train][INFO] - Epoch 32/100, Val Acc=0.6737, Val Loss=1.5019, lr=0.0100
[2025-04-29 21:22:10,005][train][INFO] - Epoch 32/100, Val Acc=0.6616, Val Loss=1.6076, lr=0.0100
[2025-04-29 21:22:15,600][train][INFO] - Epoch 33/100, Val Acc=0.6670, Val Loss=1.5622, lr=0.0100
[2025-04-29 21:22:19,252][train][INFO] - Epoch 33/100, Val Acc=0.6703, Val Loss=1.5599, lr=0.0100
[2025-04-29 21:22:24,710][train][INFO] - Epoch 34/100, Val Acc=0.6643, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:22:28,393][train][INFO] - Epoch 34/100, Val Acc=0.6721, Val Loss=1.5672, lr=0.0100
[2025-04-29 21:22:33,739][train][INFO] - Epoch 35/100, Val Acc=0.6763, Val Loss=1.4823, lr=0.0100
[2025-04-29 21:22:37,296][train][INFO] - Epoch 35/100, Val Acc=0.6757, Val Loss=1.5177, lr=0.0100
[2025-04-29 21:22:43,087][train][INFO] - Epoch 36/100, Val Acc=0.6689, Val Loss=1.5290, lr=0.0100
[2025-04-29 21:22:46,304][train][INFO] - Epoch 36/100, Val Acc=0.6649, Val Loss=1.5882, lr=0.0100
[2025-04-29 21:22:51,828][train][INFO] - Epoch 37/100, Val Acc=0.6836, Val Loss=1.4839, lr=0.0100
[2025-04-29 21:22:55,664][train][INFO] - Epoch 37/100, Val Acc=0.6519, Val Loss=1.6584, lr=0.0100
[2025-04-29 21:23:01,091][train][INFO] - Epoch 38/100, Val Acc=0.6853, Val Loss=1.4466, lr=0.0100
[2025-04-29 21:23:04,566][train][INFO] - Epoch 38/100, Val Acc=0.6642, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:23:10,010][train][INFO] - Epoch 39/100, Val Acc=0.6598, Val Loss=1.5953, lr=0.0100
[2025-04-29 21:23:13,235][train][INFO] - Epoch 39/100, Val Acc=0.6693, Val Loss=1.5533, lr=0.0100
[2025-04-29 21:23:19,167][train][INFO] - Epoch 40/100, Val Acc=0.6694, Val Loss=1.5803, lr=0.0100
[2025-04-29 21:23:22,205][train][INFO] - Epoch 40/100, Val Acc=0.6578, Val Loss=1.6153, lr=0.0100
[2025-04-29 21:23:27,931][train][INFO] - Epoch 41/100, Val Acc=0.6581, Val Loss=1.6272, lr=0.0100
[2025-04-29 21:23:31,274][train][INFO] - Epoch 41/100, Val Acc=0.6810, Val Loss=1.4824, lr=0.0100
[2025-04-29 21:23:37,095][train][INFO] - Epoch 42/100, Val Acc=0.6684, Val Loss=1.5407, lr=0.0100
[2025-04-29 21:23:40,058][train][INFO] - Epoch 42/100, Val Acc=0.6686, Val Loss=1.5701, lr=0.0100
[2025-04-29 21:23:46,045][train][INFO] - Epoch 43/100, Val Acc=0.6854, Val Loss=1.4351, lr=0.0100
[2025-04-29 21:23:48,377][train][INFO] - Epoch 43/100, Val Acc=0.6726, Val Loss=1.5278, lr=0.0100
[2025-04-29 21:23:55,432][train][INFO] - Epoch 44/100, Val Acc=0.6699, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:23:57,697][train][INFO] - Epoch 44/100, Val Acc=0.6675, Val Loss=1.5595, lr=0.0100
[2025-04-29 21:24:04,231][train][INFO] - Epoch 45/100, Val Acc=0.6640, Val Loss=1.5884, lr=0.0100
[2025-04-29 21:24:06,934][train][INFO] - Epoch 45/100, Val Acc=0.6594, Val Loss=1.5987, lr=0.0100
[2025-04-29 21:24:13,340][train][INFO] - Epoch 46/100, Val Acc=0.6711, Val Loss=1.5410, lr=0.0100
[2025-04-29 21:24:15,878][train][INFO] - Epoch 46/100, Val Acc=0.6762, Val Loss=1.5517, lr=0.0100
[2025-04-29 21:24:22,498][train][INFO] - Epoch 47/100, Val Acc=0.6741, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:24:25,176][train][INFO] - Epoch 47/100, Val Acc=0.6680, Val Loss=1.5546, lr=0.0100
[2025-04-29 21:24:31,408][train][INFO] - Epoch 48/100, Val Acc=0.6663, Val Loss=1.5747, lr=0.0100
[2025-04-29 21:24:34,442][train][INFO] - Epoch 48/100, Val Acc=0.6703, Val Loss=1.5437, lr=0.0100
[2025-04-29 21:24:40,641][train][INFO] - Epoch 49/100, Val Acc=0.6698, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:24:43,323][train][INFO] - Epoch 49/100, Val Acc=0.6805, Val Loss=1.5006, lr=0.0100
[2025-04-29 21:24:50,009][train][INFO] - Epoch 50/100, Val Acc=0.6754, Val Loss=1.5466, lr=0.0100
[2025-04-29 21:24:52,339][train][INFO] - Epoch 50/100, Val Acc=0.6671, Val Loss=1.6240, lr=0.0100
[2025-04-29 21:24:59,344][train][INFO] - Epoch 51/100, Val Acc=0.6635, Val Loss=1.5881, lr=0.0100
[2025-04-29 21:25:01,259][train][INFO] - Epoch 51/100, Val Acc=0.6786, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:25:08,406][train][INFO] - Epoch 52/100, Val Acc=0.6664, Val Loss=1.5959, lr=0.0100
[2025-04-29 21:25:10,043][train][INFO] - Epoch 52/100, Val Acc=0.6670, Val Loss=1.5614, lr=0.0100
[2025-04-29 21:25:17,258][train][INFO] - Epoch 53/100, Val Acc=0.6583, Val Loss=1.6056, lr=0.0100
[2025-04-29 21:25:19,222][train][INFO] - Epoch 53/100, Val Acc=0.6748, Val Loss=1.5412, lr=0.0100
[2025-04-29 21:25:26,404][train][INFO] - Epoch 54/100, Val Acc=0.6694, Val Loss=1.5694, lr=0.0100
[2025-04-29 21:25:28,179][train][INFO] - Epoch 54/100, Val Acc=0.6646, Val Loss=1.5513, lr=0.0100
[2025-04-29 21:25:35,619][train][INFO] - Epoch 55/100, Val Acc=0.6669, Val Loss=1.6020, lr=0.0100
[2025-04-29 21:25:37,223][train][INFO] - Epoch 55/100, Val Acc=0.6703, Val Loss=1.5565, lr=0.0100
[2025-04-29 21:25:44,899][train][INFO] - Epoch 56/100, Val Acc=0.6681, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:25:46,321][train][INFO] - Epoch 56/100, Val Acc=0.6579, Val Loss=1.6059, lr=0.0100
[2025-04-29 21:25:54,098][train][INFO] - Epoch 57/100, Val Acc=0.6557, Val Loss=1.6307, lr=0.0100
[2025-04-29 21:25:55,486][train][INFO] - Epoch 57/100, Val Acc=0.6711, Val Loss=1.5596, lr=0.0100
[2025-04-29 21:26:03,454][train][INFO] - Epoch 58/100, Val Acc=0.6596, Val Loss=1.6495, lr=0.0100
[2025-04-29 21:26:04,375][train][INFO] - Epoch 58/100, Val Acc=0.6715, Val Loss=1.5329, lr=0.0100
[2025-04-29 21:26:12,593][train][INFO] - Epoch 59/100, Val Acc=0.6525, Val Loss=1.6634, lr=0.0100
[2025-04-29 21:26:13,454][train][INFO] - Epoch 59/100, Val Acc=0.6542, Val Loss=1.6370, lr=0.0100
[2025-04-29 21:26:21,637][train][INFO] - Epoch 60/100, Val Acc=0.6810, Val Loss=1.5055, lr=0.0100
[2025-04-29 21:26:22,690][train][INFO] - Epoch 60/100, Val Acc=0.6723, Val Loss=1.5387, lr=0.0100
[2025-04-29 21:26:31,026][train][INFO] - Epoch 61/100, Val Acc=0.7232, Val Loss=1.2862, lr=0.0010
[2025-04-29 21:26:31,900][train][INFO] - Epoch 61/100, Val Acc=0.7273, Val Loss=1.2891, lr=0.0010
[2025-04-29 21:26:40,272][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2759, lr=0.0010
[2025-04-29 21:26:41,137][train][INFO] - Epoch 62/100, Val Acc=0.7330, Val Loss=1.2826, lr=0.0010
[2025-04-29 21:26:49,494][train][INFO] - Epoch 63/100, Val Acc=0.7307, Val Loss=1.2847, lr=0.0010
[2025-04-29 21:26:50,483][train][INFO] - Epoch 63/100, Val Acc=0.7335, Val Loss=1.2901, lr=0.0010
[2025-04-29 21:26:58,657][train][INFO] - Epoch 64/100, Val Acc=0.7330, Val Loss=1.2842, lr=0.0010
[2025-04-29 21:26:59,379][train][INFO] - Epoch 64/100, Val Acc=0.7332, Val Loss=1.2855, lr=0.0010
[2025-04-29 21:27:07,826][train][INFO] - Epoch 65/100, Val Acc=0.7337, Val Loss=1.2950, lr=0.0010
[2025-04-29 21:27:07,989][train][INFO] - Epoch 65/100, Val Acc=0.7351, Val Loss=1.2947, lr=0.0010
[2025-04-29 21:27:17,073][train][INFO] - Epoch 66/100, Val Acc=0.7359, Val Loss=1.3000, lr=0.0010
[2025-04-29 21:27:17,100][train][INFO] - Epoch 66/100, Val Acc=0.7319, Val Loss=1.3047, lr=0.0010
[2025-04-29 21:27:26,347][train][INFO] - Epoch 67/100, Val Acc=0.7374, Val Loss=1.2985, lr=0.0010
[2025-04-29 21:27:26,498][train][INFO] - Epoch 67/100, Val Acc=0.7322, Val Loss=1.3034, lr=0.0010
[2025-04-29 21:27:35,611][train][INFO] - Epoch 68/100, Val Acc=0.7392, Val Loss=1.2936, lr=0.0010
[2025-04-29 21:27:36,026][train][INFO] - Epoch 68/100, Val Acc=0.7371, Val Loss=1.2959, lr=0.0010
[2025-04-29 21:27:44,174][train][INFO] - Epoch 69/100, Val Acc=0.7383, Val Loss=1.3065, lr=0.0010
[2025-04-29 21:27:45,122][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.2939, lr=0.0010
[2025-04-29 21:27:53,267][train][INFO] - Epoch 70/100, Val Acc=0.7368, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:27:54,395][train][INFO] - Epoch 70/100, Val Acc=0.7358, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:02,331][train][INFO] - Epoch 71/100, Val Acc=0.7374, Val Loss=1.3147, lr=0.0010
[2025-04-29 21:28:03,543][train][INFO] - Epoch 71/100, Val Acc=0.7372, Val Loss=1.3052, lr=0.0010
[2025-04-29 21:28:11,422][train][INFO] - Epoch 72/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:28:12,568][train][INFO] - Epoch 72/100, Val Acc=0.7371, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:28:20,660][train][INFO] - Epoch 73/100, Val Acc=0.7386, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:21,731][train][INFO] - Epoch 73/100, Val Acc=0.7362, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:29,893][train][INFO] - Epoch 74/100, Val Acc=0.7397, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:30,857][train][INFO] - Epoch 74/100, Val Acc=0.7361, Val Loss=1.3060, lr=0.0010
[2025-04-29 21:28:39,203][train][INFO] - Epoch 75/100, Val Acc=0.7408, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:39,488][train][INFO] - Epoch 75/100, Val Acc=0.7362, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:28:48,144][train][INFO] - Epoch 76/100, Val Acc=0.7401, Val Loss=1.3140, lr=0.0010
[2025-04-29 21:28:48,618][train][INFO] - Epoch 76/100, Val Acc=0.7370, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:28:57,139][train][INFO] - Epoch 77/100, Val Acc=0.7395, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:28:57,734][train][INFO] - Epoch 77/100, Val Acc=0.7374, Val Loss=1.3039, lr=0.0010
[2025-04-29 21:29:06,341][train][INFO] - Epoch 78/100, Val Acc=0.7398, Val Loss=1.3136, lr=0.0010
[2025-04-29 21:29:06,864][train][INFO] - Epoch 78/100, Val Acc=0.7354, Val Loss=1.3030, lr=0.0010
[2025-04-29 21:29:15,003][train][INFO] - Epoch 79/100, Val Acc=0.7385, Val Loss=1.3145, lr=0.0010
[2025-04-29 21:29:16,025][train][INFO] - Epoch 79/100, Val Acc=0.7386, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:24,196][train][INFO] - Epoch 80/100, Val Acc=0.7397, Val Loss=1.3122, lr=0.0010
[2025-04-29 21:29:25,254][train][INFO] - Epoch 80/100, Val Acc=0.7361, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:29:32,884][train][INFO] - Epoch 81/100, Val Acc=0.7401, Val Loss=1.3084, lr=0.0010
[2025-04-29 21:29:34,433][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3083, lr=0.0010
[2025-04-29 21:29:42,096][train][INFO] - Epoch 82/100, Val Acc=0.7376, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:29:43,544][train][INFO] - Epoch 82/100, Val Acc=0.7361, Val Loss=1.3168, lr=0.0010
[2025-04-29 21:29:51,114][train][INFO] - Epoch 83/100, Val Acc=0.7397, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:52,840][train][INFO] - Epoch 83/100, Val Acc=0.7373, Val Loss=1.3154, lr=0.0010
[2025-04-29 21:30:00,216][train][INFO] - Epoch 84/100, Val Acc=0.7393, Val Loss=1.3120, lr=0.0010
[2025-04-29 21:30:02,021][train][INFO] - Epoch 84/100, Val Acc=0.7389, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:30:09,578][train][INFO] - Epoch 85/100, Val Acc=0.7397, Val Loss=1.3131, lr=0.0010
[2025-04-29 21:30:11,389][train][INFO] - Epoch 85/100, Val Acc=0.7379, Val Loss=1.3130, lr=0.0010
[2025-04-29 21:30:18,697][train][INFO] - Epoch 86/100, Val Acc=0.7412, Val Loss=1.3069, lr=0.0010
[2025-04-29 21:30:20,684][train][INFO] - Epoch 86/100, Val Acc=0.7407, Val Loss=1.3142, lr=0.0010
[2025-04-29 21:30:27,407][train][INFO] - Epoch 87/100, Val Acc=0.7403, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:30:29,862][train][INFO] - Epoch 87/100, Val Acc=0.7395, Val Loss=1.3100, lr=0.0010
[2025-04-29 21:30:36,218][train][INFO] - Epoch 88/100, Val Acc=0.7402, Val Loss=1.3075, lr=0.0010
[2025-04-29 21:30:38,935][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3163, lr=0.0010
[2025-04-29 21:30:44,864][train][INFO] - Epoch 89/100, Val Acc=0.7415, Val Loss=1.3162, lr=0.0010
[2025-04-29 21:30:48,196][train][INFO] - Epoch 89/100, Val Acc=0.7378, Val Loss=1.3224, lr=0.0010
[2025-04-29 21:30:53,860][train][INFO] - Epoch 90/100, Val Acc=0.7402, Val Loss=1.3160, lr=0.0010
[2025-04-29 21:30:57,502][train][INFO] - Epoch 90/100, Val Acc=0.7369, Val Loss=1.3185, lr=0.0010
[2025-04-29 21:31:02,792][train][INFO] - Epoch 91/100, Val Acc=0.7417, Val Loss=1.3142, lr=0.0001
[2025-04-29 21:31:06,880][train][INFO] - Epoch 91/100, Val Acc=0.7375, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:31:12,031][train][INFO] - Epoch 92/100, Val Acc=0.7388, Val Loss=1.3165, lr=0.0001
[2025-04-29 21:31:15,980][train][INFO] - Epoch 92/100, Val Acc=0.7381, Val Loss=1.3166, lr=0.0001
[2025-04-29 21:31:21,020][train][INFO] - Epoch 93/100, Val Acc=0.7403, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:31:25,126][train][INFO] - Epoch 93/100, Val Acc=0.7385, Val Loss=1.3141, lr=0.0001
[2025-04-29 21:31:30,116][train][INFO] - Epoch 94/100, Val Acc=0.7407, Val Loss=1.3087, lr=0.0001
[2025-04-29 21:31:34,200][train][INFO] - Epoch 94/100, Val Acc=0.7397, Val Loss=1.3102, lr=0.0001
[2025-04-29 21:31:39,116][train][INFO] - Epoch 95/100, Val Acc=0.7404, Val Loss=1.3131, lr=0.0001
[2025-04-29 21:31:43,537][train][INFO] - Epoch 95/100, Val Acc=0.7387, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:31:48,063][train][INFO] - Epoch 96/100, Val Acc=0.7429, Val Loss=1.3081, lr=0.0001
[2025-04-29 21:31:52,704][train][INFO] - Epoch 96/100, Val Acc=0.7398, Val Loss=1.3067, lr=0.0001
[2025-04-29 21:31:56,974][train][INFO] - Epoch 97/100, Val Acc=0.7415, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:32:02,041][train][INFO] - Epoch 97/100, Val Acc=0.7418, Val Loss=1.3118, lr=0.0001
[2025-04-29 21:32:05,975][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3096, lr=0.0001
[2025-04-29 21:32:11,084][train][INFO] - Epoch 98/100, Val Acc=0.7389, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:32:14,921][train][INFO] - Epoch 99/100, Val Acc=0.7422, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:32:20,279][train][INFO] - Epoch 99/100, Val Acc=0.7410, Val Loss=1.3169, lr=0.0001
[2025-04-29 21:32:23,991][train][INFO] - Epoch 100/100, Val Acc=0.7418, Val Loss=1.3116, lr=0.0001
[2025-04-29 21:32:29,324][train][INFO] - After training : Train Acc=0.9995  Val Acc=0.7429
[2025-04-29 21:32:29,328][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:32:29,545][train][INFO] - Epoch 100/100, Val Acc=0.7375, Val Loss=1.3119, lr=0.0001
[2025-04-29 21:32:34,979][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7418
[2025-04-29 21:32:34,984][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:34:53,903][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:34:59,489][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:37:17,383][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:17,921][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:37:22,790][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:23,228][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:40:10,349][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:40:49,882][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:40:53,370][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:40:59,065][train][INFO] - Epoch 1/100, Val Acc=0.6257, Val Loss=1.6543, lr=0.0100
[2025-04-29 21:41:08,027][train][INFO] - Epoch 2/100, Val Acc=0.6428, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:41:16,885][train][INFO] - Epoch 3/100, Val Acc=0.6496, Val Loss=1.5084, lr=0.0100
[2025-04-29 21:41:25,890][train][INFO] - Epoch 4/100, Val Acc=0.6656, Val Loss=1.4503, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:41:34,452][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:41:35,197][train][INFO] - Epoch 5/100, Val Acc=0.6521, Val Loss=1.5174, lr=0.0100
[2025-04-29 21:41:44,066][train][INFO] - Epoch 1/100, Val Acc=0.6369, Val Loss=1.5627, lr=0.0100
[2025-04-29 21:41:44,412][train][INFO] - Epoch 6/100, Val Acc=0.6654, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:41:53,151][train][INFO] - Epoch 2/100, Val Acc=0.6300, Val Loss=1.5685, lr=0.0100
[2025-04-29 21:41:53,576][train][INFO] - Epoch 7/100, Val Acc=0.6622, Val Loss=1.4976, lr=0.0100
[2025-04-29 21:42:02,386][train][INFO] - Epoch 8/100, Val Acc=0.6701, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:42:02,554][train][INFO] - Epoch 3/100, Val Acc=0.6416, Val Loss=1.5501, lr=0.0100
[2025-04-29 21:42:11,564][train][INFO] - Epoch 9/100, Val Acc=0.6665, Val Loss=1.4876, lr=0.0100
[2025-04-29 21:42:11,822][train][INFO] - Epoch 4/100, Val Acc=0.6620, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:42:20,752][train][INFO] - Epoch 10/100, Val Acc=0.6711, Val Loss=1.4776, lr=0.0100
[2025-04-29 21:42:21,144][train][INFO] - Epoch 5/100, Val Acc=0.6422, Val Loss=1.5505, lr=0.0100
[2025-04-29 21:42:29,739][train][INFO] - Epoch 11/100, Val Acc=0.6648, Val Loss=1.5057, lr=0.0100
[2025-04-29 21:42:30,670][train][INFO] - Epoch 6/100, Val Acc=0.6635, Val Loss=1.4302, lr=0.0100
[2025-04-29 21:42:38,897][train][INFO] - Epoch 12/100, Val Acc=0.6631, Val Loss=1.5293, lr=0.0100
[2025-04-29 21:42:40,063][train][INFO] - Epoch 7/100, Val Acc=0.6482, Val Loss=1.5347, lr=0.0100
[2025-04-29 21:42:48,128][train][INFO] - Epoch 13/100, Val Acc=0.6671, Val Loss=1.4912, lr=0.0100
[2025-04-29 21:42:49,571][train][INFO] - Epoch 8/100, Val Acc=0.6711, Val Loss=1.4325, lr=0.0100
[2025-04-29 21:42:57,114][train][INFO] - Epoch 14/100, Val Acc=0.6543, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:42:58,797][train][INFO] - Epoch 9/100, Val Acc=0.6535, Val Loss=1.5438, lr=0.0100
[2025-04-29 21:43:05,637][train][INFO] - Epoch 15/100, Val Acc=0.6600, Val Loss=1.5129, lr=0.0100
[2025-04-29 21:43:07,825][train][INFO] - Epoch 10/100, Val Acc=0.6637, Val Loss=1.4938, lr=0.0100
[2025-04-29 21:43:14,509][train][INFO] - Epoch 16/100, Val Acc=0.6548, Val Loss=1.5180, lr=0.0100
[2025-04-29 21:43:17,141][train][INFO] - Epoch 11/100, Val Acc=0.6624, Val Loss=1.4939, lr=0.0100
[2025-04-29 21:43:23,482][train][INFO] - Epoch 17/100, Val Acc=0.6656, Val Loss=1.5355, lr=0.0100
[2025-04-29 21:43:26,650][train][INFO] - Epoch 12/100, Val Acc=0.6768, Val Loss=1.4102, lr=0.0100
[2025-04-29 21:43:32,503][train][INFO] - Epoch 18/100, Val Acc=0.6606, Val Loss=1.5428, lr=0.0100
[2025-04-29 21:43:36,129][train][INFO] - Epoch 13/100, Val Acc=0.6710, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:43:41,500][train][INFO] - Epoch 19/100, Val Acc=0.6796, Val Loss=1.4513, lr=0.0100
[2025-04-29 21:43:45,401][train][INFO] - Epoch 14/100, Val Acc=0.6739, Val Loss=1.4676, lr=0.0100
[2025-04-29 21:43:50,499][train][INFO] - Epoch 20/100, Val Acc=0.6700, Val Loss=1.5303, lr=0.0100
[2025-04-29 21:43:54,513][train][INFO] - Epoch 15/100, Val Acc=0.6568, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:43:59,352][train][INFO] - Epoch 21/100, Val Acc=0.6711, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:44:04,005][train][INFO] - Epoch 16/100, Val Acc=0.6543, Val Loss=1.5705, lr=0.0100
[2025-04-29 21:44:08,305][train][INFO] - Epoch 22/100, Val Acc=0.6486, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:44:13,200][train][INFO] - Epoch 17/100, Val Acc=0.6529, Val Loss=1.6048, lr=0.0100
[2025-04-29 21:44:17,314][train][INFO] - Epoch 23/100, Val Acc=0.6618, Val Loss=1.5304, lr=0.0100
[2025-04-29 21:44:22,658][train][INFO] - Epoch 18/100, Val Acc=0.6823, Val Loss=1.4386, lr=0.0100
[2025-04-29 21:44:26,595][train][INFO] - Epoch 24/100, Val Acc=0.6651, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:44:32,118][train][INFO] - Epoch 19/100, Val Acc=0.6751, Val Loss=1.4674, lr=0.0100
[2025-04-29 21:44:35,312][train][INFO] - Epoch 25/100, Val Acc=0.6714, Val Loss=1.5076, lr=0.0100
[2025-04-29 21:44:41,401][train][INFO] - Epoch 20/100, Val Acc=0.6716, Val Loss=1.4960, lr=0.0100
[2025-04-29 21:44:44,435][train][INFO] - Epoch 26/100, Val Acc=0.6693, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:44:50,722][train][INFO] - Epoch 21/100, Val Acc=0.6706, Val Loss=1.5384, lr=0.0100
[2025-04-29 21:44:53,423][train][INFO] - Epoch 27/100, Val Acc=0.6747, Val Loss=1.4802, lr=0.0100
[2025-04-29 21:44:59,699][train][INFO] - Epoch 22/100, Val Acc=0.6757, Val Loss=1.4804, lr=0.0100
[2025-04-29 21:45:02,423][train][INFO] - Epoch 28/100, Val Acc=0.6645, Val Loss=1.5490, lr=0.0100
[2025-04-29 21:45:08,977][train][INFO] - Epoch 23/100, Val Acc=0.6674, Val Loss=1.4937, lr=0.0100
[2025-04-29 21:45:11,718][train][INFO] - Epoch 29/100, Val Acc=0.6800, Val Loss=1.4548, lr=0.0100
[2025-04-29 21:45:18,377][train][INFO] - Epoch 24/100, Val Acc=0.6720, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:45:21,984][train][INFO] - Epoch 30/100, Val Acc=0.6764, Val Loss=1.5024, lr=0.0100
[2025-04-29 21:45:27,498][train][INFO] - Epoch 25/100, Val Acc=0.6731, Val Loss=1.5116, lr=0.0100
[2025-04-29 21:45:36,367][train][INFO] - Epoch 31/100, Val Acc=0.6687, Val Loss=1.5228, lr=0.0100
[2025-04-29 21:45:36,565][train][INFO] - Epoch 26/100, Val Acc=0.6663, Val Loss=1.5383, lr=0.0100
[2025-04-29 21:45:45,666][train][INFO] - Epoch 27/100, Val Acc=0.6596, Val Loss=1.6001, lr=0.0100
[2025-04-29 21:45:50,939][train][INFO] - Epoch 32/100, Val Acc=0.6559, Val Loss=1.6182, lr=0.0100
[2025-04-29 21:45:54,779][train][INFO] - Epoch 28/100, Val Acc=0.6818, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:46:04,196][train][INFO] - Epoch 29/100, Val Acc=0.6621, Val Loss=1.5992, lr=0.0100
[2025-04-29 21:46:05,262][train][INFO] - Epoch 33/100, Val Acc=0.6615, Val Loss=1.5968, lr=0.0100
[2025-04-29 21:46:13,400][train][INFO] - Epoch 30/100, Val Acc=0.6728, Val Loss=1.5461, lr=0.0100
[2025-04-29 21:46:19,443][train][INFO] - Epoch 34/100, Val Acc=0.6671, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:46:22,452][train][INFO] - Epoch 31/100, Val Acc=0.6721, Val Loss=1.5289, lr=0.0100
[2025-04-29 21:46:31,571][train][INFO] - Epoch 32/100, Val Acc=0.6674, Val Loss=1.5620, lr=0.0100
[2025-04-29 21:46:33,794][train][INFO] - Epoch 35/100, Val Acc=0.6700, Val Loss=1.5275, lr=0.0100
[2025-04-29 21:46:40,841][train][INFO] - Epoch 33/100, Val Acc=0.6763, Val Loss=1.4837, lr=0.0100
[2025-04-29 21:46:48,024][train][INFO] - Epoch 36/100, Val Acc=0.6624, Val Loss=1.5998, lr=0.0100
[2025-04-29 21:46:49,868][train][INFO] - Epoch 34/100, Val Acc=0.6692, Val Loss=1.5875, lr=0.0100
[2025-04-29 21:46:58,977][train][INFO] - Epoch 35/100, Val Acc=0.6677, Val Loss=1.5485, lr=0.0100
[2025-04-29 21:47:02,140][train][INFO] - Epoch 37/100, Val Acc=0.6816, Val Loss=1.4639, lr=0.0100
[2025-04-29 21:47:08,240][train][INFO] - Epoch 36/100, Val Acc=0.6677, Val Loss=1.5615, lr=0.0100
[2025-04-29 21:47:16,411][train][INFO] - Epoch 38/100, Val Acc=0.6778, Val Loss=1.5033, lr=0.0100
[2025-04-29 21:47:17,232][train][INFO] - Epoch 37/100, Val Acc=0.6747, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:47:26,377][train][INFO] - Epoch 38/100, Val Acc=0.6708, Val Loss=1.5313, lr=0.0100
[2025-04-29 21:47:30,910][train][INFO] - Epoch 39/100, Val Acc=0.6669, Val Loss=1.5918, lr=0.0100
[2025-04-29 21:47:35,408][train][INFO] - Epoch 39/100, Val Acc=0.6698, Val Loss=1.5529, lr=0.0100
[2025-04-29 21:47:44,495][train][INFO] - Epoch 40/100, Val Acc=0.6711, Val Loss=1.5507, lr=0.0100
[2025-04-29 21:47:45,491][train][INFO] - Epoch 40/100, Val Acc=0.6797, Val Loss=1.4993, lr=0.0100
[2025-04-29 21:47:53,749][train][INFO] - Epoch 41/100, Val Acc=0.6734, Val Loss=1.5220, lr=0.0100
[2025-04-29 21:47:59,609][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:48:02,823][train][INFO] - Epoch 42/100, Val Acc=0.6822, Val Loss=1.4934, lr=0.0100
[2025-04-29 21:48:12,209][train][INFO] - Epoch 43/100, Val Acc=0.6812, Val Loss=1.5135, lr=0.0100
[2025-04-29 21:48:13,873][train][INFO] - Epoch 42/100, Val Acc=0.6679, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:48:21,452][train][INFO] - Epoch 44/100, Val Acc=0.6608, Val Loss=1.6318, lr=0.0100
[2025-04-29 21:48:28,061][train][INFO] - Epoch 43/100, Val Acc=0.6785, Val Loss=1.5146, lr=0.0100
[2025-04-29 21:48:30,585][train][INFO] - Epoch 45/100, Val Acc=0.6687, Val Loss=1.5555, lr=0.0100
[2025-04-29 21:48:39,776][train][INFO] - Epoch 46/100, Val Acc=0.6768, Val Loss=1.5056, lr=0.0100
[2025-04-29 21:48:42,382][train][INFO] - Epoch 44/100, Val Acc=0.6695, Val Loss=1.5718, lr=0.0100
[2025-04-29 21:48:48,954][train][INFO] - Epoch 47/100, Val Acc=0.6723, Val Loss=1.5183, lr=0.0100
[2025-04-29 21:48:56,599][train][INFO] - Epoch 45/100, Val Acc=0.6679, Val Loss=1.5633, lr=0.0100
[2025-04-29 21:48:58,321][train][INFO] - Epoch 48/100, Val Acc=0.6612, Val Loss=1.6375, lr=0.0100
[2025-04-29 21:49:07,490][train][INFO] - Epoch 49/100, Val Acc=0.6736, Val Loss=1.5120, lr=0.0100
[2025-04-29 21:49:10,847][train][INFO] - Epoch 46/100, Val Acc=0.6659, Val Loss=1.5629, lr=0.0100
[2025-04-29 21:49:16,617][train][INFO] - Epoch 50/100, Val Acc=0.6772, Val Loss=1.4901, lr=0.0100
[2025-04-29 21:49:25,304][train][INFO] - Epoch 47/100, Val Acc=0.6548, Val Loss=1.6385, lr=0.0100
[2025-04-29 21:49:26,124][train][INFO] - Epoch 51/100, Val Acc=0.6860, Val Loss=1.4603, lr=0.0100
[2025-04-29 21:49:35,242][train][INFO] - Epoch 52/100, Val Acc=0.6715, Val Loss=1.5797, lr=0.0100
[2025-04-29 21:49:39,833][train][INFO] - Epoch 48/100, Val Acc=0.6624, Val Loss=1.6049, lr=0.0100
[2025-04-29 21:49:44,272][train][INFO] - Epoch 53/100, Val Acc=0.6779, Val Loss=1.5066, lr=0.0100
[2025-04-29 21:49:53,524][train][INFO] - Epoch 54/100, Val Acc=0.6751, Val Loss=1.5483, lr=0.0100
[2025-04-29 21:49:54,092][train][INFO] - Epoch 49/100, Val Acc=0.6851, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:50:02,931][train][INFO] - Epoch 55/100, Val Acc=0.6654, Val Loss=1.6669, lr=0.0100
[2025-04-29 21:50:08,193][train][INFO] - Epoch 50/100, Val Acc=0.6644, Val Loss=1.5961, lr=0.0100
[2025-04-29 21:50:12,154][train][INFO] - Epoch 56/100, Val Acc=0.6662, Val Loss=1.5693, lr=0.0100
[2025-04-29 21:50:21,400][train][INFO] - Epoch 57/100, Val Acc=0.6684, Val Loss=1.5478, lr=0.0100
[2025-04-29 21:50:22,470][train][INFO] - Epoch 51/100, Val Acc=0.6632, Val Loss=1.5834, lr=0.0100
[2025-04-29 21:50:30,522][train][INFO] - Epoch 58/100, Val Acc=0.6637, Val Loss=1.5977, lr=0.0100
[2025-04-29 21:50:36,634][train][INFO] - Epoch 52/100, Val Acc=0.6738, Val Loss=1.5234, lr=0.0100
[2025-04-29 21:50:39,764][train][INFO] - Epoch 59/100, Val Acc=0.6696, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:50:49,192][train][INFO] - Epoch 60/100, Val Acc=0.6658, Val Loss=1.6064, lr=0.0100
[2025-04-29 21:50:50,929][train][INFO] - Epoch 53/100, Val Acc=0.6771, Val Loss=1.5226, lr=0.0100
[2025-04-29 21:50:58,358][train][INFO] - Epoch 61/100, Val Acc=0.7230, Val Loss=1.2880, lr=0.0010
[2025-04-29 21:51:05,178][train][INFO] - Epoch 54/100, Val Acc=0.6602, Val Loss=1.6317, lr=0.0100
[2025-04-29 21:51:07,630][train][INFO] - Epoch 62/100, Val Acc=0.7252, Val Loss=1.2812, lr=0.0010
[2025-04-29 21:51:16,909][train][INFO] - Epoch 63/100, Val Acc=0.7286, Val Loss=1.2853, lr=0.0010
[2025-04-29 21:51:19,590][train][INFO] - Epoch 55/100, Val Acc=0.6769, Val Loss=1.5502, lr=0.0100
[2025-04-29 21:51:26,175][train][INFO] - Epoch 64/100, Val Acc=0.7316, Val Loss=1.2868, lr=0.0010
[2025-04-29 21:51:34,240][train][INFO] - Epoch 56/100, Val Acc=0.6628, Val Loss=1.5731, lr=0.0100
[2025-04-29 21:51:35,675][train][INFO] - Epoch 65/100, Val Acc=0.7298, Val Loss=1.2904, lr=0.0010
[2025-04-29 21:51:44,878][train][INFO] - Epoch 66/100, Val Acc=0.7295, Val Loss=1.3033, lr=0.0010
[2025-04-29 21:51:48,524][train][INFO] - Epoch 57/100, Val Acc=0.6633, Val Loss=1.6350, lr=0.0100
[2025-04-29 21:51:54,179][train][INFO] - Epoch 67/100, Val Acc=0.7340, Val Loss=1.3009, lr=0.0010
[2025-04-29 21:52:02,745][train][INFO] - Epoch 58/100, Val Acc=0.6603, Val Loss=1.6075, lr=0.0100
[2025-04-29 21:52:03,420][train][INFO] - Epoch 68/100, Val Acc=0.7342, Val Loss=1.3043, lr=0.0010
[2025-04-29 21:52:12,503][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.3058, lr=0.0010
[2025-04-29 21:52:16,927][train][INFO] - Epoch 59/100, Val Acc=0.6693, Val Loss=1.5958, lr=0.0100
[2025-04-29 21:52:21,632][train][INFO] - Epoch 70/100, Val Acc=0.7332, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:52:31,025][train][INFO] - Epoch 71/100, Val Acc=0.7343, Val Loss=1.3237, lr=0.0010
[2025-04-29 21:52:31,232][train][INFO] - Epoch 60/100, Val Acc=0.6681, Val Loss=1.5341, lr=0.0100
[2025-04-29 21:52:40,401][train][INFO] - Epoch 72/100, Val Acc=0.7343, Val Loss=1.3195, lr=0.0010
[2025-04-29 21:52:45,514][train][INFO] - Epoch 61/100, Val Acc=0.7206, Val Loss=1.2915, lr=0.0010
[2025-04-29 21:52:49,781][train][INFO] - Epoch 73/100, Val Acc=0.7360, Val Loss=1.3172, lr=0.0010
[2025-04-29 21:52:58,861][train][INFO] - Epoch 74/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:52:59,752][train][INFO] - Epoch 62/100, Val Acc=0.7243, Val Loss=1.2888, lr=0.0010
[2025-04-29 21:53:08,145][train][INFO] - Epoch 75/100, Val Acc=0.7356, Val Loss=1.3261, lr=0.0010
[2025-04-29 21:53:14,234][train][INFO] - Epoch 63/100, Val Acc=0.7244, Val Loss=1.2993, lr=0.0010
[2025-04-29 21:53:17,319][train][INFO] - Epoch 76/100, Val Acc=0.7378, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:53:26,442][train][INFO] - Epoch 77/100, Val Acc=0.7389, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:53:28,773][train][INFO] - Epoch 64/100, Val Acc=0.7271, Val Loss=1.3022, lr=0.0010
[2025-04-29 21:53:35,810][train][INFO] - Epoch 78/100, Val Acc=0.7382, Val Loss=1.3103, lr=0.0010
[2025-04-29 21:53:42,992][train][INFO] - Epoch 65/100, Val Acc=0.7274, Val Loss=1.3041, lr=0.0010
[2025-04-29 21:53:45,163][train][INFO] - Epoch 79/100, Val Acc=0.7372, Val Loss=1.3201, lr=0.0010
[2025-04-29 21:53:54,433][train][INFO] - Epoch 80/100, Val Acc=0.7377, Val Loss=1.3215, lr=0.0010
[2025-04-29 21:53:57,122][train][INFO] - Epoch 66/100, Val Acc=0.7301, Val Loss=1.3166, lr=0.0010
[2025-04-29 21:54:03,397][train][INFO] - Epoch 81/100, Val Acc=0.7378, Val Loss=1.3244, lr=0.0010
[2025-04-29 21:54:11,312][train][INFO] - Epoch 67/100, Val Acc=0.7312, Val Loss=1.3091, lr=0.0010
[2025-04-29 21:54:12,604][train][INFO] - Epoch 82/100, Val Acc=0.7399, Val Loss=1.3225, lr=0.0010
[2025-04-29 21:54:21,971][train][INFO] - Epoch 83/100, Val Acc=0.7383, Val Loss=1.3155, lr=0.0010
[2025-04-29 21:54:25,661][train][INFO] - Epoch 68/100, Val Acc=0.7330, Val Loss=1.3048, lr=0.0010
[2025-04-29 21:54:31,353][train][INFO] - Epoch 84/100, Val Acc=0.7376, Val Loss=1.3248, lr=0.0010
[2025-04-29 21:54:39,857][train][INFO] - Epoch 69/100, Val Acc=0.7315, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:54:40,699][train][INFO] - Epoch 85/100, Val Acc=0.7370, Val Loss=1.3245, lr=0.0010
[2025-04-29 21:54:49,791][train][INFO] - Epoch 86/100, Val Acc=0.7360, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:54:54,116][train][INFO] - Epoch 70/100, Val Acc=0.7331, Val Loss=1.3243, lr=0.0010
[2025-04-29 21:54:58,976][train][INFO] - Epoch 87/100, Val Acc=0.7366, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:55:08,154][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3270, lr=0.0010
[2025-04-29 21:55:08,577][train][INFO] - Epoch 71/100, Val Acc=0.7304, Val Loss=1.3285, lr=0.0010
[2025-04-29 21:55:17,263][train][INFO] - Epoch 89/100, Val Acc=0.7379, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:55:23,134][train][INFO] - Epoch 72/100, Val Acc=0.7312, Val Loss=1.3351, lr=0.0010
[2025-04-29 21:55:26,509][train][INFO] - Epoch 90/100, Val Acc=0.7372, Val Loss=1.3340, lr=0.0010
[2025-04-29 21:55:35,655][train][INFO] - Epoch 91/100, Val Acc=0.7373, Val Loss=1.3271, lr=0.0001
[2025-04-29 21:55:37,306][train][INFO] - Epoch 73/100, Val Acc=0.7317, Val Loss=1.3323, lr=0.0010
[2025-04-29 21:55:44,969][train][INFO] - Epoch 92/100, Val Acc=0.7370, Val Loss=1.3286, lr=0.0001
[2025-04-29 21:55:51,550][train][INFO] - Epoch 74/100, Val Acc=0.7329, Val Loss=1.3267, lr=0.0010
[2025-04-29 21:55:54,252][train][INFO] - Epoch 93/100, Val Acc=0.7380, Val Loss=1.3234, lr=0.0001
[2025-04-29 21:56:03,709][train][INFO] - Epoch 94/100, Val Acc=0.7380, Val Loss=1.3253, lr=0.0001
[2025-04-29 21:56:05,736][train][INFO] - Epoch 75/100, Val Acc=0.7322, Val Loss=1.3356, lr=0.0010
[2025-04-29 21:56:13,133][train][INFO] - Epoch 95/100, Val Acc=0.7380, Val Loss=1.3265, lr=0.0001
[2025-04-29 21:56:19,978][train][INFO] - Epoch 76/100, Val Acc=0.7327, Val Loss=1.3364, lr=0.0010
[2025-04-29 21:56:22,374][train][INFO] - Epoch 96/100, Val Acc=0.7382, Val Loss=1.3228, lr=0.0001
[2025-04-29 21:56:31,637][train][INFO] - Epoch 97/100, Val Acc=0.7374, Val Loss=1.3227, lr=0.0001
[2025-04-29 21:56:34,230][train][INFO] - Epoch 77/100, Val Acc=0.7326, Val Loss=1.3347, lr=0.0010
[2025-04-29 21:56:40,905][train][INFO] - Epoch 98/100, Val Acc=0.7373, Val Loss=1.3235, lr=0.0001
[2025-04-29 21:56:48,515][train][INFO] - Epoch 78/100, Val Acc=0.7315, Val Loss=1.3324, lr=0.0010
[2025-04-29 21:56:50,109][train][INFO] - Epoch 99/100, Val Acc=0.7371, Val Loss=1.3252, lr=0.0001
[2025-04-29 21:56:59,506][train][INFO] - Epoch 100/100, Val Acc=0.7382, Val Loss=1.3263, lr=0.0001
[2025-04-29 21:57:03,092][train][INFO] - Epoch 79/100, Val Acc=0.7353, Val Loss=1.3338, lr=0.0010
[2025-04-29 21:57:05,043][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7399
[2025-04-29 21:57:05,048][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:57:17,660][train][INFO] - Epoch 80/100, Val Acc=0.7349, Val Loss=1.3414, lr=0.0010
[2025-04-29 21:57:31,910][train][INFO] - Epoch 81/100, Val Acc=0.7341, Val Loss=1.3427, lr=0.0010
[2025-04-29 21:57:46,175][train][INFO] - Epoch 82/100, Val Acc=0.7350, Val Loss=1.3407, lr=0.0010
[2025-04-29 21:58:00,344][train][INFO] - Epoch 83/100, Val Acc=0.7353, Val Loss=1.3484, lr=0.0010
[2025-04-29 21:58:14,672][train][INFO] - Epoch 84/100, Val Acc=0.7349, Val Loss=1.3521, lr=0.0010
[2025-04-29 21:58:28,912][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3379, lr=0.0010
[2025-04-29 21:58:43,184][train][INFO] - Epoch 86/100, Val Acc=0.7362, Val Loss=1.3448, lr=0.0010
[2025-04-29 21:58:57,470][train][INFO] - Epoch 87/100, Val Acc=0.7361, Val Loss=1.3424, lr=0.0010
[2025-04-29 21:59:12,035][train][INFO] - Epoch 88/100, Val Acc=0.7351, Val Loss=1.3510, lr=0.0010
[2025-04-29 21:59:26,523][train][INFO] - Epoch 89/100, Val Acc=0.7370, Val Loss=1.3482, lr=0.0010
[2025-04-29 21:59:31,660][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:59:40,781][train][INFO] - Epoch 90/100, Val Acc=0.7366, Val Loss=1.3503, lr=0.0010
[2025-04-29 21:59:55,084][train][INFO] - Epoch 91/100, Val Acc=0.7368, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:00:09,277][train][INFO] - Epoch 92/100, Val Acc=0.7379, Val Loss=1.3508, lr=0.0001
[2025-04-29 22:00:23,596][train][INFO] - Epoch 93/100, Val Acc=0.7367, Val Loss=1.3444, lr=0.0001
[2025-04-29 22:00:37,848][train][INFO] - Epoch 94/100, Val Acc=0.7372, Val Loss=1.3434, lr=0.0001
[2025-04-29 22:00:52,206][train][INFO] - Epoch 95/100, Val Acc=0.7360, Val Loss=1.3468, lr=0.0001
[2025-04-29 22:01:06,806][train][INFO] - Epoch 96/100, Val Acc=0.7360, Val Loss=1.3439, lr=0.0001
[2025-04-29 22:01:21,028][train][INFO] - Epoch 97/100, Val Acc=0.7365, Val Loss=1.3457, lr=0.0001
[2025-04-29 22:01:35,385][train][INFO] - Epoch 98/100, Val Acc=0.7364, Val Loss=1.3448, lr=0.0001
[2025-04-29 22:01:49,735][train][INFO] - Epoch 99/100, Val Acc=0.7352, Val Loss=1.3470, lr=0.0001
[2025-04-29 22:01:56,143][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:01:56,637][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 22:02:03,915][train][INFO] - Epoch 100/100, Val Acc=0.7362, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:02:09,533][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7379
[2025-04-29 22:02:09,537][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 22:04:56,467][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 22:07:44,794][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:07:45,261][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 11:30:24,255][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 11:30:24,335][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 11:31:05,948][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-04-30 11:31:42,751][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8054, lr=0.001
[2025-04-30 11:32:19,426][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6650, lr=0.001
[2025-04-30 11:32:54,785][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8170, lr=0.001
[2025-04-30 11:33:32,060][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.8789, lr=0.001
[2025-04-30 11:34:08,533][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9001, lr=0.001
[2025-04-30 11:34:45,365][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7399, lr=0.001
[2025-04-30 11:35:21,000][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4222, lr=0.001
[2025-04-30 11:35:21,026][meta_train][INFO] - epoch_1 saved !
[2025-04-30 11:35:58,599][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3554, lr=0.001
[2025-04-30 11:36:33,926][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1076, lr=0.001
[2025-04-30 11:37:10,427][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1257, lr=0.001
[2025-04-30 11:37:47,584][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.2335, lr=0.001
[2025-04-30 11:38:25,370][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0825, lr=0.001
[2025-04-30 11:39:00,110][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0752, lr=0.001
[2025-04-30 11:39:37,186][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0667, lr=0.001
[2025-04-30 11:40:14,282][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0571, lr=0.001
[2025-04-30 11:40:14,298][meta_train][INFO] - epoch_2 saved !
[2025-04-30 11:40:50,716][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.0852, lr=0.001
[2025-04-30 11:41:27,473][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0791, lr=0.001
[2025-04-30 11:42:04,144][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0776, lr=0.001
[2025-04-30 11:42:39,344][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.0982, lr=0.001
[2025-04-30 11:43:16,974][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2242, lr=0.001
[2025-04-30 11:43:53,635][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2048, lr=0.001
[2025-04-30 11:44:30,516][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1049, lr=0.001
[2025-04-30 11:45:06,754][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1000, lr=0.001
[2025-04-30 11:45:06,764][meta_train][INFO] - epoch_3 saved !
[2025-04-30 11:45:43,129][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1212, lr=0.001
[2025-04-30 11:46:19,514][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1225, lr=0.001
[2025-04-30 11:46:57,122][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.2522, lr=0.001
[2025-04-30 11:47:33,116][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1173, lr=0.001
[2025-04-30 11:48:11,617][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1231, lr=0.001
[2025-04-30 11:48:46,782][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.2112, lr=0.001
[2025-04-30 11:49:23,435][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.3869, lr=0.001
[2025-04-30 11:49:59,857][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.1797, lr=0.001
[2025-04-30 11:49:59,866][meta_train][INFO] - epoch_4 saved !
[2025-04-30 11:50:36,772][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.3443, lr=0.001
[2025-04-30 11:51:13,921][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.1748, lr=0.001
[2025-04-30 11:51:51,357][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.2491, lr=0.001
[2025-04-30 11:52:27,538][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.2513, lr=0.001
[2025-04-30 11:53:04,557][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=0.6399, lr=0.001
[2025-04-30 11:53:40,932][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.3194, lr=0.001
[2025-04-30 11:54:17,476][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.4219, lr=0.001
[2025-04-30 11:54:53,955][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.3403, lr=0.001
[2025-04-30 11:54:53,970][meta_train][INFO] - epoch_5 saved !
[2025-04-30 11:55:29,845][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=0.7997, lr=0.001
[2025-04-30 11:56:07,743][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.2902, lr=0.001
[2025-04-30 11:56:43,778][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.4564, lr=0.001
[2025-04-30 11:57:20,913][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=0.5632, lr=0.001
[2025-04-30 11:57:57,292][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.3177, lr=0.001
[2025-04-30 11:58:33,601][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.3453, lr=0.001
[2025-04-30 11:59:10,661][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.3072, lr=0.001
[2025-04-30 11:59:48,467][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.3339, lr=0.001
[2025-04-30 11:59:48,477][meta_train][INFO] - epoch_6 saved !
[2025-04-30 12:00:23,675][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=0.5760, lr=0.001
[2025-04-30 12:01:00,835][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=0.6666, lr=0.001
[2025-04-30 12:01:37,880][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.3024, lr=0.001
[2025-04-30 12:02:14,031][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.4275, lr=0.001
[2025-04-30 12:02:49,688][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.2487, lr=0.001
[2025-04-30 12:03:27,059][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.2335, lr=0.001
[2025-04-30 12:04:04,860][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.2636, lr=0.001
[2025-04-30 12:04:40,666][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.2809, lr=0.001
[2025-04-30 12:04:40,687][meta_train][INFO] - epoch_7 saved !
[2025-04-30 12:05:17,434][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.2743, lr=0.001
[2025-04-30 12:05:53,765][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.2842, lr=0.001
[2025-04-30 12:06:30,971][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.2406, lr=0.001
[2025-04-30 12:07:08,017][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.5674, lr=0.001
[2025-04-30 12:07:44,928][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.2337, lr=0.001
[2025-04-30 12:08:22,206][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.2148, lr=0.001
[2025-04-30 12:08:58,125][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.4072, lr=0.001
[2025-04-30 12:09:35,769][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.4274, lr=0.001
[2025-04-30 12:09:35,791][meta_train][INFO] - epoch_8 saved !
[2025-04-30 12:10:11,573][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.2075, lr=0.001
[2025-04-30 12:10:48,860][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.2202, lr=0.001
[2025-04-30 12:11:24,895][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.1966, lr=0.001
[2025-04-30 12:12:01,391][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.4453, lr=0.001
[2025-04-30 12:12:37,778][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.5933, lr=0.001
[2025-04-30 12:13:14,047][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.4373, lr=0.001
[2025-04-30 12:13:51,992][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.2809, lr=0.001
[2025-04-30 12:14:29,253][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2327, lr=0.001
[2025-04-30 12:14:29,266][meta_train][INFO] - epoch_9 saved !
[2025-04-30 12:15:05,037][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.3388, lr=0.001
[2025-04-30 12:15:42,812][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3388, lr=0.001
[2025-04-30 12:16:18,289][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4107, lr=0.001
[2025-04-30 12:16:55,440][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.8359, lr=0.001
[2025-04-30 12:17:32,591][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6126, lr=0.001
[2025-04-30 12:18:07,891][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.0799, lr=0.001
[2025-04-30 12:18:45,255][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.8904, lr=0.001
[2025-04-30 12:19:22,893][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.5186, lr=0.001
[2025-04-30 12:19:22,914][meta_train][INFO] - epoch_10 saved !
[2025-04-30 12:19:59,085][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=0.8725, lr=0.0001
[2025-04-30 12:20:34,876][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.5895, lr=0.0001
[2025-04-30 12:21:12,807][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.7851, lr=0.0001
[2025-04-30 12:21:49,574][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=0.9620, lr=0.0001
[2025-04-30 12:22:25,340][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.3022, lr=0.0001
[2025-04-30 12:23:01,975][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.3555, lr=0.0001
[2025-04-30 12:23:37,159][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=0.7466, lr=0.0001
[2025-04-30 12:24:14,287][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=0.9694, lr=0.0001
[2025-04-30 12:24:14,297][meta_train][INFO] - epoch_11 saved !
[2025-04-30 12:24:50,758][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=0.8743, lr=0.0001
[2025-04-30 12:25:27,673][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=0.7618, lr=0.0001
[2025-04-30 12:26:04,864][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=0.9493, lr=0.0001
[2025-04-30 12:26:42,127][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=1.6123, lr=0.0001
[2025-04-30 12:27:18,295][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=1.3867, lr=0.0001
[2025-04-30 12:27:54,616][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=0.7477, lr=0.0001
[2025-04-30 12:28:31,780][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=1.3346, lr=0.0001
[2025-04-30 12:29:07,851][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=1.0194, lr=0.0001
[2025-04-30 12:29:07,869][meta_train][INFO] - epoch_12 saved !
[2025-04-30 12:29:43,863][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=0.9206, lr=0.0001
[2025-04-30 12:30:21,150][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=1.3698, lr=0.0001
[2025-04-30 12:30:57,335][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=1.0467, lr=0.0001
[2025-04-30 12:31:34,905][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=0.7990, lr=0.0001
[2025-04-30 12:32:11,724][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=1.6963, lr=0.0001
[2025-04-30 12:32:47,786][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=1.0581, lr=0.0001
[2025-04-30 12:33:23,972][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=1.4734, lr=0.0001
[2025-04-30 12:34:01,307][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=0.8539, lr=0.0001
[2025-04-30 12:34:01,316][meta_train][INFO] - epoch_13 saved !
[2025-04-30 12:34:37,072][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=1.1031, lr=0.0001
[2025-04-30 12:35:13,784][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=0.8312, lr=0.0001
[2025-04-30 12:35:51,002][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=1.7404, lr=0.0001
[2025-04-30 12:36:26,620][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=1.5112, lr=0.0001
[2025-04-30 12:37:03,847][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=1.4786, lr=0.0001
[2025-04-30 12:37:41,593][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=1.1136, lr=0.0001
[2025-04-30 12:38:18,119][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=1.0420, lr=0.0001
[2025-04-30 12:38:53,648][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=0.8894, lr=0.0001
[2025-04-30 12:38:53,673][meta_train][INFO] - epoch_14 saved !
[2025-04-30 12:39:31,866][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=1.5031, lr=0.0001
[2025-04-30 12:40:06,696][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=1.5508, lr=0.0001
[2025-04-30 12:40:44,200][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=1.0657, lr=0.0001
[2025-04-30 12:41:19,736][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=1.8003, lr=0.0001
[2025-04-30 12:41:56,585][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=1.1533, lr=0.0001
[2025-04-30 12:42:33,061][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=0.8785, lr=0.0001
[2025-04-30 12:43:10,243][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=1.1917, lr=0.0001
[2025-04-30 12:43:48,542][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=0.9312, lr=0.0001
[2025-04-30 12:43:48,556][meta_train][INFO] - epoch_15 saved !
[2025-04-30 12:44:24,865][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=1.5742, lr=0.0001
[2025-04-30 12:45:00,772][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=0.8974, lr=0.0001
[2025-04-30 12:45:37,465][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=1.2269, lr=0.0001
[2025-04-30 12:46:15,539][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=0.9450, lr=0.0001
[2025-04-30 12:46:50,800][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=1.1436, lr=0.0001
[2025-04-30 12:47:27,389][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=1.8749, lr=0.0001
[2025-04-30 12:48:04,391][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=1.2180, lr=0.0001
[2025-04-30 12:48:40,353][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=1.6475, lr=0.0001
[2025-04-30 12:48:40,363][meta_train][INFO] - epoch_16 saved !
[2025-04-30 12:49:17,625][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=1.6307, lr=0.0001
[2025-04-30 12:49:54,820][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=1.8982, lr=0.0001
[2025-04-30 12:50:30,002][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=1.6692, lr=0.0001
[2025-04-30 12:51:06,541][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=1.1927, lr=0.0001
[2025-04-30 12:51:44,082][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=1.2609, lr=0.0001
[2025-04-30 12:52:21,130][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=0.9492, lr=0.0001
[2025-04-30 12:52:58,191][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=1.2997, lr=0.0001
[2025-04-30 12:53:33,806][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=1.0031, lr=0.0001
[2025-04-30 12:53:33,831][meta_train][INFO] - epoch_17 saved !
[2025-04-30 12:54:11,256][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=1.0060, lr=0.0001
[2025-04-30 12:54:47,403][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=1.9358, lr=0.0001
[2025-04-30 12:55:24,521][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=0.9571, lr=0.0001
[2025-04-30 12:56:00,389][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=1.6929, lr=0.0001
[2025-04-30 12:56:37,571][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=1.3211, lr=0.0001
[2025-04-30 12:57:13,994][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=1.7224, lr=0.0001
[2025-04-30 12:57:50,673][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=1.3154, lr=0.0001
[2025-04-30 12:58:26,517][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=1.2576, lr=0.0001
[2025-04-30 12:58:26,536][meta_train][INFO] - epoch_18 saved !
[2025-04-30 12:59:04,439][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=1.0470, lr=0.0001
[2025-04-30 12:59:40,511][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=1.7412, lr=0.0001
[2025-04-30 13:00:16,046][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=1.2790, lr=0.0001
[2025-04-30 13:00:52,470][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=1.7692, lr=0.0001
[2025-04-30 13:01:28,991][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=2.0034, lr=0.0001
[2025-04-30 13:02:06,039][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=1.3883, lr=0.0001
[2025-04-30 13:02:43,660][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=1.0351, lr=0.0001
[2025-04-30 13:03:20,390][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=1.3947, lr=0.0001
[2025-04-30 13:03:20,416][meta_train][INFO] - epoch_19 saved !
[2025-04-30 13:03:56,861][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=1.4176, lr=0.0001
[2025-04-30 13:04:34,460][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=1.4064, lr=0.0001
[2025-04-30 13:05:10,684][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=1.8089, lr=0.0001
[2025-04-30 13:05:48,404][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=1.1281, lr=0.0001
[2025-04-30 13:06:24,560][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=1.8275, lr=0.0001
[2025-04-30 13:07:01,289][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=2.0519, lr=0.0001
[2025-04-30 13:07:38,340][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=1.3728, lr=0.0001
[2025-04-30 13:08:14,116][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=1.0913, lr=0.0001
[2025-04-30 13:08:14,129][meta_train][INFO] - epoch_20 saved !
[2025-04-30 13:08:50,954][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=1.3983, lr=0.0001
[2025-04-30 13:09:27,719][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=1.1925, lr=0.0001
[2025-04-30 13:10:05,077][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=1.4889, lr=0.0001
[2025-04-30 13:10:42,387][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=2.1082, lr=0.0001
[2025-04-30 13:11:18,984][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=1.5182, lr=0.0001
[2025-04-30 13:11:55,711][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=1.9138, lr=0.0001
[2025-04-30 13:12:31,729][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=1.9239, lr=0.0001
[2025-04-30 13:13:08,736][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=1.1780, lr=0.0001
[2025-04-30 13:13:08,752][meta_train][INFO] - epoch_21 saved !
[2025-04-30 13:13:45,389][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=1.1925, lr=0.0001
[2025-04-30 13:14:21,714][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=1.5730, lr=0.0001
[2025-04-30 13:14:58,971][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=1.9641, lr=0.0001
[2025-04-30 13:15:35,299][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=2.1709, lr=0.0001
[2025-04-30 13:16:10,930][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=1.9764, lr=0.0001
[2025-04-30 13:16:46,927][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=1.5255, lr=0.0001
[2025-04-30 13:17:24,725][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=1.3369, lr=0.0001
[2025-04-30 13:18:01,406][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=1.6203, lr=0.0001
[2025-04-30 13:18:01,416][meta_train][INFO] - epoch_22 saved !
[2025-04-30 13:18:37,027][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=2.1983, lr=0.0001
[2025-04-30 13:19:14,830][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=1.6383, lr=0.0001
[2025-04-30 13:19:51,813][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=1.6375, lr=0.0001
[2025-04-30 13:20:28,835][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=1.2906, lr=0.0001
[2025-04-30 13:21:04,599][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=2.0282, lr=0.0001
[2025-04-30 13:21:41,779][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=1.4064, lr=0.0001
[2025-04-30 13:22:18,726][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=2.0621, lr=0.0001
[2025-04-30 13:22:54,410][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=1.6185, lr=0.0001
[2025-04-30 13:22:54,422][meta_train][INFO] - epoch_23 saved !
[2025-04-30 13:23:32,152][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=2.0900, lr=0.0001
[2025-04-30 13:24:07,802][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=2.0748, lr=0.0001
[2025-04-30 13:24:44,405][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=1.3863, lr=0.0001
[2025-04-30 13:25:21,752][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=1.7474, lr=0.0001
[2025-04-30 13:25:58,823][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=1.5081, lr=0.0001
[2025-04-30 13:26:34,489][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=2.2887, lr=0.0001
[2025-04-30 13:27:10,889][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=1.6879, lr=0.0001
[2025-04-30 13:27:48,356][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=1.7899, lr=0.0001
[2025-04-30 13:27:48,366][meta_train][INFO] - epoch_24 saved !
[2025-04-30 13:28:26,382][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=2.1619, lr=0.0001
[2025-04-30 13:29:03,273][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=1.8001, lr=0.0001
[2025-04-30 13:29:39,061][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=1.7130, lr=0.0001
[2025-04-30 13:30:17,436][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=1.5640, lr=0.0001
[2025-04-30 13:30:53,349][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=2.1600, lr=0.0001
[2025-04-30 13:31:29,605][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=1.4942, lr=0.0001
[2025-04-30 13:32:07,107][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=2.3633, lr=0.0001
[2025-04-30 13:32:43,807][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=1.8736, lr=0.0001
[2025-04-30 13:32:43,816][meta_train][INFO] - epoch_25 saved !
[2025-04-30 13:33:19,984][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=2.2291, lr=0.0001
[2025-04-30 13:33:56,101][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=1.5906, lr=0.0001
[2025-04-30 13:34:33,708][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=1.8416, lr=0.0001
[2025-04-30 13:35:09,418][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=2.3292, lr=0.0001
[2025-04-30 13:35:47,243][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=1.7285, lr=0.0001
[2025-04-30 13:36:23,860][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=1.9637, lr=0.0001
[2025-04-30 13:37:01,260][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=1.9461, lr=0.0001
[2025-04-30 13:37:38,245][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=2.4358, lr=0.0001
[2025-04-30 13:37:38,266][meta_train][INFO] - epoch_26 saved !
[2025-04-30 13:38:14,557][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=2.4367, lr=0.0001
[2025-04-30 13:38:51,544][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=1.6425, lr=0.0001
[2025-04-30 13:39:28,199][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=1.7608, lr=0.0001
[2025-04-30 13:40:04,953][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=1.9124, lr=0.0001
[2025-04-30 13:40:40,627][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=2.3352, lr=0.0001
[2025-04-30 13:41:17,542][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=2.0533, lr=0.0001
[2025-04-30 13:41:53,684][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=2.0607, lr=0.0001
[2025-04-30 13:42:31,120][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=2.4524, lr=0.0001
[2025-04-30 13:42:31,129][meta_train][INFO] - epoch_27 saved !
[2025-04-30 13:43:07,455][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=1.7818, lr=0.0001
[2025-04-30 13:43:44,537][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=2.0985, lr=0.0001
[2025-04-30 13:44:22,453][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=1.9993, lr=0.0001
[2025-04-30 13:44:59,605][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=1.8905, lr=0.0001
[2025-04-30 13:45:36,201][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=2.5454, lr=0.0001
[2025-04-30 13:46:12,557][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=2.4789, lr=0.0001
[2025-04-30 13:46:50,100][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=2.1208, lr=0.0001
[2025-04-30 13:47:25,262][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=2.4365, lr=0.0001
[2025-04-30 13:47:25,276][meta_train][INFO] - epoch_28 saved !
[2025-04-30 13:48:02,827][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=1.9544, lr=0.0001
[2025-04-30 13:48:39,980][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=2.5956, lr=0.0001
[2025-04-30 13:49:16,420][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=2.0958, lr=0.0001
[2025-04-30 13:49:54,202][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=1.9444, lr=0.0001
[2025-04-30 13:50:30,068][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=2.2404, lr=0.0001
[2025-04-30 13:51:06,432][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=2.5294, lr=0.0001
[2025-04-30 13:51:44,688][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=2.2600, lr=0.0001
[2025-04-30 13:52:20,999][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=2.6263, lr=0.0001
[2025-04-30 13:52:21,008][meta_train][INFO] - epoch_29 saved !
[2025-04-30 13:52:57,914][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=2.0111, lr=0.0001
[2025-04-30 13:53:34,384][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=2.5477, lr=0.0001
[2025-04-30 13:54:10,822][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=2.2841, lr=0.0001
[2025-04-30 13:54:48,679][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=2.6324, lr=0.0001
[2025-04-30 13:55:24,801][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=2.2896, lr=0.0001
[2025-04-30 13:56:01,176][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=2.2000, lr=0.0001
[2025-04-30 13:56:37,533][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=2.6821, lr=0.0001
[2025-04-30 13:57:15,480][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=2.1656, lr=0.0001
[2025-04-30 13:57:15,501][meta_train][INFO] - epoch_30 saved !
[2025-04-30 13:57:51,580][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=2.7121, lr=0.0001
[2025-04-30 13:58:28,610][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=2.1520, lr=0.0001
[2025-04-30 13:59:04,835][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=2.4002, lr=0.0001
[2025-04-30 13:59:42,057][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=2.4187, lr=0.0001
[2025-04-30 14:00:18,419][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=2.2768, lr=0.0001
[2025-04-30 14:00:55,155][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=2.6864, lr=0.0001
[2025-04-30 14:01:31,786][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=2.7843, lr=0.0001
[2025-04-30 14:02:08,198][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=2.3649, lr=0.0001
[2025-04-30 14:02:08,208][meta_train][INFO] - epoch_31 saved !
[2025-04-30 14:02:45,338][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=2.7234, lr=0.0001
[2025-04-30 14:03:21,129][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=2.3919, lr=0.0001
[2025-04-30 14:03:58,481][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=2.5084, lr=0.0001
[2025-04-30 14:04:34,923][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=2.3950, lr=0.0001
[2025-04-30 14:05:11,471][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=2.8489, lr=0.0001
[2025-04-30 14:05:46,963][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=2.8773, lr=0.0001
[2025-04-30 14:06:24,197][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=2.5695, lr=0.0001
[2025-04-30 14:07:00,705][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=2.4046, lr=0.0001
[2025-04-30 14:07:00,715][meta_train][INFO] - epoch_32 saved !
[2025-04-30 14:07:38,005][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=2.8694, lr=0.0001
[2025-04-30 14:08:14,429][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=2.4308, lr=0.0001
[2025-04-30 14:08:50,638][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=2.5111, lr=0.0001
[2025-04-30 14:09:28,134][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=2.6373, lr=0.0001
[2025-04-30 14:10:03,747][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=2.5310, lr=0.0001
[2025-04-30 14:10:41,161][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=2.6580, lr=0.0001
[2025-04-30 14:11:17,495][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=2.9908, lr=0.0001
[2025-04-30 14:11:54,880][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=2.9203, lr=0.0001
[2025-04-30 14:11:54,889][meta_train][INFO] - epoch_33 saved !
[2025-04-30 14:12:30,927][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=2.9339, lr=0.0001
[2025-04-30 14:13:07,353][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=2.7181, lr=0.0001
[2025-04-30 14:13:44,480][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=3.0487, lr=0.0001
[2025-04-30 14:14:20,866][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=2.6529, lr=0.0001
[2025-04-30 14:14:57,715][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=2.7952, lr=0.0001
[2025-04-30 14:15:34,683][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=3.0224, lr=0.0001
[2025-04-30 14:16:10,148][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=2.7162, lr=0.0001
[2025-04-30 14:16:47,178][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=2.7318, lr=0.0001
[2025-04-30 14:16:47,188][meta_train][INFO] - epoch_34 saved !
[2025-04-30 14:17:24,456][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=2.7620, lr=0.0001
[2025-04-30 14:18:00,594][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=2.7951, lr=0.0001
[2025-04-30 14:18:36,772][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=2.8815, lr=0.0001
[2025-04-30 14:19:14,633][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=2.8275, lr=0.0001
[2025-04-30 14:19:50,276][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=2.9726, lr=0.0001
[2025-04-30 14:20:28,446][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=3.2458, lr=0.0001
[2025-04-30 14:21:03,642][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=3.1808, lr=0.0001
[2025-04-30 14:21:40,863][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=3.1821, lr=0.0001
[2025-04-30 14:21:40,872][meta_train][INFO] - epoch_35 saved !
[2025-04-30 14:22:16,993][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=3.2076, lr=0.0001
[2025-04-30 14:22:53,822][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=3.0052, lr=0.0001
[2025-04-30 14:23:30,452][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=2.9815, lr=0.0001
[2025-04-30 14:24:07,031][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=3.2328, lr=0.0001
[2025-04-30 14:24:42,943][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=3.3473, lr=0.0001
[2025-04-30 14:25:20,288][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=3.0128, lr=0.0001
[2025-04-30 14:25:56,646][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=3.1530, lr=0.0001
[2025-04-30 14:26:33,618][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=3.1278, lr=0.0001
[2025-04-30 14:26:33,628][meta_train][INFO] - epoch_36 saved !
[2025-04-30 14:27:11,125][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=3.1987, lr=0.0001
[2025-04-30 14:27:48,615][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=3.3715, lr=0.0001
[2025-04-30 14:28:24,329][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=3.4622, lr=0.0001
[2025-04-30 14:29:01,413][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=3.1774, lr=0.0001
[2025-04-30 14:29:38,346][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=3.2469, lr=0.0001
[2025-04-30 14:30:14,370][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=3.1810, lr=0.0001
[2025-04-30 14:30:51,049][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=3.4126, lr=0.0001
[2025-04-30 14:31:28,511][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=3.3032, lr=0.0001
[2025-04-30 14:31:28,521][meta_train][INFO] - epoch_37 saved !
[2025-04-30 14:32:04,163][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=3.4610, lr=0.0001
[2025-04-30 14:32:41,038][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=3.3987, lr=0.0001
[2025-04-30 14:33:17,980][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=3.5817, lr=0.0001
[2025-04-30 14:33:54,054][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=3.4818, lr=0.0001
[2025-04-30 14:34:31,972][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=3.3816, lr=0.0001
[2025-04-30 14:35:07,654][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=3.4444, lr=0.0001
[2025-04-30 14:35:44,796][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=3.4904, lr=0.0001
[2025-04-30 14:36:22,151][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=3.7697, lr=0.0001
[2025-04-30 14:36:22,168][meta_train][INFO] - epoch_38 saved !
[2025-04-30 14:36:58,595][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=3.5790, lr=0.0001
[2025-04-30 14:37:36,291][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=3.7798, lr=0.0001
[2025-04-30 14:38:12,052][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=3.6178, lr=0.0001
[2025-04-30 14:38:49,871][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=3.5409, lr=0.0001
[2025-04-30 14:39:26,117][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=3.6233, lr=0.0001
[2025-04-30 14:40:03,693][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=3.7616, lr=0.0001
[2025-04-30 14:40:40,297][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=3.6092, lr=0.0001
[2025-04-30 14:41:16,344][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=3.6010, lr=0.0001
[2025-04-30 14:41:16,357][meta_train][INFO] - epoch_39 saved !
[2025-04-30 14:41:52,497][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=3.9475, lr=0.0001
[2025-04-30 14:42:29,477][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=3.6694, lr=0.0001
[2025-04-30 14:43:05,334][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=3.7644, lr=0.0001
[2025-04-30 14:43:42,639][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=3.8493, lr=0.0001
[2025-04-30 14:44:18,360][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=3.9724, lr=0.0001
[2025-04-30 14:44:55,444][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=3.8169, lr=0.0001
[2025-04-30 14:45:32,688][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=3.9219, lr=0.0001
[2025-04-30 14:46:09,639][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=3.9460, lr=0.0001
[2025-04-30 14:46:09,649][meta_train][INFO] - epoch_40 saved !
[2025-04-30 14:46:47,258][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=3.9660, lr=0.0001
[2025-04-30 14:47:24,395][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=3.9911, lr=0.0001
[2025-04-30 14:48:00,431][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.0004, lr=0.0001
[2025-04-30 14:48:37,122][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.2167, lr=0.0001
[2025-04-30 14:49:13,747][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=3.9656, lr=0.0001
[2025-04-30 14:49:50,864][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.0105, lr=0.0001
[2025-04-30 14:50:26,305][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=3.9681, lr=0.0001
[2025-04-30 14:51:02,783][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.1813, lr=0.0001
[2025-04-30 14:51:02,793][meta_train][INFO] - epoch_41 saved !
[2025-04-30 14:51:39,255][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.0745, lr=0.0001
[2025-04-30 14:52:15,418][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.0376, lr=0.0001
[2025-04-30 14:52:53,014][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.1511, lr=0.0001
[2025-04-30 14:53:28,595][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.1841, lr=0.0001
[2025-04-30 14:54:05,462][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.2162, lr=0.0001
[2025-04-30 14:54:42,934][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.3120, lr=0.0001
[2025-04-30 14:55:18,665][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.1839, lr=0.0001
[2025-04-30 14:55:55,260][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.4592, lr=0.0001
[2025-04-30 14:55:55,269][meta_train][INFO] - epoch_42 saved !
[2025-04-30 14:56:31,337][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.1990, lr=0.0001
[2025-04-30 14:57:08,425][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.2397, lr=0.0001
[2025-04-30 14:57:44,741][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.3952, lr=0.0001
[2025-04-30 14:58:21,701][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.3432, lr=0.0001
[2025-04-30 14:58:59,225][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.5337, lr=0.0001
[2025-04-30 14:59:34,952][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.3555, lr=0.0001
[2025-04-30 15:00:11,605][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.3604, lr=0.0001
[2025-04-30 15:00:49,153][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.3683, lr=0.0001
[2025-04-30 15:00:49,174][meta_train][INFO] - epoch_43 saved !
[2025-04-30 15:01:26,408][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.4823, lr=0.0001
[2025-04-30 15:02:03,121][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.4347, lr=0.0001
[2025-04-30 15:02:40,279][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.4197, lr=0.0001
[2025-04-30 15:03:15,836][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.4393, lr=0.0001
[2025-04-30 15:03:52,513][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.4259, lr=0.0001
[2025-04-30 15:04:29,427][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.4869, lr=0.0001
[2025-04-30 15:05:05,544][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6678, lr=0.0001
[2025-04-30 15:05:43,199][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.4542, lr=0.0001
[2025-04-30 15:05:43,208][meta_train][INFO] - epoch_44 saved !
[2025-04-30 15:06:20,232][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.5289, lr=0.0001
[2025-04-30 15:06:55,456][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.4768, lr=0.0001
[2025-04-30 15:07:32,765][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6976, lr=0.0001
[2025-04-30 15:08:10,101][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.5090, lr=0.0001
[2025-04-30 15:08:46,614][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6170, lr=0.0001
[2025-04-30 15:09:22,595][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.5492, lr=0.0001
[2025-04-30 15:09:59,977][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.5369, lr=0.0001
[2025-04-30 15:10:37,074][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.5804, lr=0.0001
[2025-04-30 15:10:37,093][meta_train][INFO] - epoch_45 saved !
[2025-04-30 15:11:14,195][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.5548, lr=0.0001
[2025-04-30 15:11:50,447][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.5810, lr=0.0001
[2025-04-30 15:12:27,362][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.7379, lr=0.0001
[2025-04-30 15:13:05,084][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6110, lr=0.0001
[2025-04-30 15:13:41,823][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.5787, lr=0.0001
[2025-04-30 15:14:18,410][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6234, lr=0.0001
[2025-04-30 15:14:54,882][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6789, lr=0.0001
[2025-04-30 15:15:31,407][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.5922, lr=0.0001
[2025-04-30 15:15:31,425][meta_train][INFO] - epoch_46 saved !
[2025-04-30 15:16:08,663][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6247, lr=0.0001
[2025-04-30 15:16:45,440][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6206, lr=0.0001
[2025-04-30 15:17:21,797][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.7554, lr=0.0001
[2025-04-30 15:17:57,716][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6936, lr=0.0001
[2025-04-30 15:18:34,140][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6517, lr=0.0001
[2025-04-30 15:19:11,935][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6494, lr=0.0001
[2025-04-30 15:19:48,902][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6140, lr=0.0001
[2025-04-30 15:20:24,545][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6330, lr=0.0001
[2025-04-30 15:20:24,559][meta_train][INFO] - epoch_47 saved !
[2025-04-30 15:21:01,527][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6501, lr=0.0001
[2025-04-30 15:21:39,323][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:22:16,233][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6422, lr=0.0001
[2025-04-30 15:22:52,280][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6257, lr=0.0001
[2025-04-30 15:23:29,201][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6602, lr=0.0001
[2025-04-30 15:24:05,683][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.7545, lr=0.0001
[2025-04-30 15:24:42,175][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.7099, lr=0.0001
[2025-04-30 15:25:18,484][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6640, lr=0.0001
[2025-04-30 15:25:18,494][meta_train][INFO] - epoch_48 saved !
[2025-04-30 15:25:55,958][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:26:31,697][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.7109, lr=0.0001
[2025-04-30 15:27:08,300][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6359, lr=0.0001
[2025-04-30 15:27:45,735][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6753, lr=0.0001
[2025-04-30 15:28:22,583][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.7471, lr=0.0001
[2025-04-30 15:28:59,195][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6674, lr=0.0001
[2025-04-30 15:29:35,670][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6767, lr=0.0001
[2025-04-30 15:30:11,642][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6616, lr=0.0001
[2025-04-30 15:30:11,651][meta_train][INFO] - epoch_49 saved !
[2025-04-30 15:30:49,352][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.7403, lr=0.0001
[2025-04-30 15:31:24,539][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.7077, lr=0.0001
[2025-04-30 15:32:01,903][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6675, lr=0.0001
[2025-04-30 15:32:38,710][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6636, lr=0.0001
[2025-04-30 15:33:15,247][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6427, lr=0.0001
[2025-04-30 15:33:52,739][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6807, lr=0.0001
[2025-04-30 15:34:29,668][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6648, lr=0.0001
[2025-04-30 15:35:05,862][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6739, lr=0.0001
[2025-04-30 15:35:05,872][meta_train][INFO] - epoch_50 saved !
[2025-04-30 15:35:42,956][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6737, lr=0.0001
[2025-04-30 15:36:20,265][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.7294, lr=0.0001
[2025-04-30 15:36:56,548][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6646, lr=0.0001
[2025-04-30 15:37:32,936][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6656, lr=0.0001
[2025-04-30 15:38:09,846][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6673, lr=0.0001
[2025-04-30 15:38:47,298][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6450, lr=0.0001
[2025-04-30 15:39:22,797][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.7009, lr=0.0001
[2025-04-30 15:39:59,924][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6831, lr=0.0001
[2025-04-30 15:39:59,934][meta_train][INFO] - epoch_51 saved !
[2025-04-30 15:40:36,595][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6693, lr=0.0001
[2025-04-30 15:41:12,417][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6450, lr=0.0001
[2025-04-30 15:41:49,276][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6645, lr=0.0001
[2025-04-30 15:42:26,613][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6602, lr=0.0001
[2025-04-30 15:43:02,715][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6636, lr=0.0001
[2025-04-30 15:43:39,790][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6818, lr=0.0001
[2025-04-30 15:44:16,646][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6945, lr=0.0001
[2025-04-30 15:44:52,523][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.7070, lr=0.0001
[2025-04-30 15:44:52,545][meta_train][INFO] - epoch_52 saved !
[2025-04-30 15:45:29,807][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.7048, lr=0.0001
[2025-04-30 15:46:06,320][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6608, lr=0.0001
[2025-04-30 15:46:41,669][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6888, lr=0.0001
[2025-04-30 15:47:19,053][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6430, lr=0.0001
[2025-04-30 15:47:54,524][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6594, lr=0.0001
[2025-04-30 15:48:32,309][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6531, lr=0.0001
[2025-04-30 15:49:09,483][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6557, lr=0.0001
[2025-04-30 15:49:46,235][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6766, lr=0.0001
[2025-04-30 15:49:46,258][meta_train][INFO] - epoch_53 saved !
[2025-04-30 15:50:22,014][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6845, lr=0.0001
[2025-04-30 15:50:58,579][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6923, lr=0.0001
[2025-04-30 15:51:35,610][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6552, lr=0.0001
[2025-04-30 15:52:12,636][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6742, lr=0.0001
[2025-04-30 15:52:48,522][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6485, lr=0.0001
[2025-04-30 15:53:25,442][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6500, lr=0.0001
[2025-04-30 15:54:03,080][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6406, lr=0.0001
[2025-04-30 15:54:38,766][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6533, lr=0.0001
[2025-04-30 15:54:38,782][meta_train][INFO] - epoch_54 saved !
[2025-04-30 15:55:14,910][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6529, lr=0.0001
[2025-04-30 15:55:52,870][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6500, lr=0.0001
[2025-04-30 15:56:29,594][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6797, lr=0.0001
[2025-04-30 15:57:05,751][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6691, lr=0.0001
[2025-04-30 15:57:43,335][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6448, lr=0.0001
[2025-04-30 15:58:19,198][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6434, lr=0.0001
[2025-04-30 15:58:56,243][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6701, lr=0.0001
[2025-04-30 15:59:32,922][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6381, lr=0.0001
[2025-04-30 15:59:32,941][meta_train][INFO] - epoch_55 saved !
[2025-04-30 16:00:09,250][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6383, lr=0.0001
[2025-04-30 16:00:45,924][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6702, lr=0.0001
[2025-04-30 16:01:21,909][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6434, lr=0.0001
[2025-04-30 16:01:58,923][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6446, lr=0.0001
[2025-04-30 16:02:35,226][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6708, lr=0.0001
[2025-04-30 16:03:12,158][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6406, lr=0.0001
[2025-04-30 16:03:49,563][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6441, lr=0.0001
[2025-04-30 16:04:26,190][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6603, lr=0.0001
[2025-04-30 16:04:26,212][meta_train][INFO] - epoch_56 saved !
[2025-04-30 16:05:02,208][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6371, lr=0.0001
[2025-04-30 16:05:39,342][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6349, lr=0.0001
[2025-04-30 16:06:15,307][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6592, lr=0.0001
[2025-04-30 16:06:52,189][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6572, lr=0.0001
[2025-04-30 16:07:27,496][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6400, lr=0.0001
[2025-04-30 16:08:04,405][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6582, lr=0.0001
[2025-04-30 16:08:41,349][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6372, lr=0.0001
[2025-04-30 16:09:19,375][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6354, lr=0.0001
[2025-04-30 16:09:19,391][meta_train][INFO] - epoch_57 saved !
[2025-04-30 16:09:54,452][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6612, lr=0.0001
[2025-04-30 16:10:32,342][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6374, lr=0.0001
[2025-04-30 16:11:08,076][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6614, lr=0.0001
[2025-04-30 16:11:45,888][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6589, lr=0.0001
[2025-04-30 16:12:22,531][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6353, lr=0.0001
[2025-04-30 16:12:57,943][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6365, lr=0.0001
[2025-04-30 16:13:34,954][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6299, lr=0.0001
[2025-04-30 16:14:12,316][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6307, lr=0.0001
[2025-04-30 16:14:12,326][meta_train][INFO] - epoch_58 saved !
[2025-04-30 16:14:49,123][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6310, lr=0.0001
[2025-04-30 16:15:25,244][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6486, lr=0.0001
[2025-04-30 16:16:01,129][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6346, lr=0.0001
[2025-04-30 16:16:37,988][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6505, lr=0.0001
[2025-04-30 16:17:15,496][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6527, lr=0.0001
[2025-04-30 16:17:52,140][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6295, lr=0.0001
[2025-04-30 16:18:28,728][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6294, lr=0.0001
[2025-04-30 16:19:04,781][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6312, lr=0.0001
[2025-04-30 16:19:04,791][meta_train][INFO] - epoch_59 saved !
[2025-04-30 16:19:41,640][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6493, lr=0.0001
[2025-04-30 16:20:17,534][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6305, lr=0.0001
[2025-04-30 16:20:53,821][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6315, lr=0.0001
[2025-04-30 16:21:30,009][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6255, lr=0.0001
[2025-04-30 16:22:06,705][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:22:44,368][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6290, lr=0.0001
[2025-04-30 16:23:19,945][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6435, lr=0.0001
[2025-04-30 16:23:56,916][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6437, lr=0.0001
[2025-04-30 16:23:56,925][meta_train][INFO] - epoch_60 saved !
[2025-04-30 16:24:34,910][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6305, lr=0.0001
[2025-04-30 16:25:12,049][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6306, lr=0.0001
[2025-04-30 16:25:47,799][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6443, lr=0.0001
[2025-04-30 16:26:25,134][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6254, lr=0.0001
[2025-04-30 16:27:01,926][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6237, lr=0.0001
[2025-04-30 16:27:37,200][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6396, lr=0.0001
[2025-04-30 16:28:14,034][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6402, lr=0.0001
[2025-04-30 16:28:50,663][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6257, lr=0.0001
[2025-04-30 16:28:50,673][meta_train][INFO] - epoch_61 saved !
[2025-04-30 16:29:27,794][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6255, lr=0.0001
[2025-04-30 16:30:05,002][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6369, lr=0.0001
[2025-04-30 16:30:41,442][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6212, lr=0.0001
[2025-04-30 16:31:18,735][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6221, lr=0.0001
[2025-04-30 16:31:54,658][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6285, lr=0.0001
[2025-04-30 16:32:31,395][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6385, lr=0.0001
[2025-04-30 16:33:09,075][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6276, lr=0.0001
[2025-04-30 16:33:46,085][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6410, lr=0.0001
[2025-04-30 16:33:46,107][meta_train][INFO] - epoch_62 saved !
[2025-04-30 16:34:22,436][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6340, lr=0.0001
[2025-04-30 16:34:58,155][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6189, lr=0.0001
[2025-04-30 16:35:35,176][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6331, lr=0.0001
[2025-04-30 16:36:12,186][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6232, lr=0.0001
[2025-04-30 16:36:47,955][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6183, lr=0.0001
[2025-04-30 16:37:25,198][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6263, lr=0.0001
[2025-04-30 16:38:02,661][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6257, lr=0.0001
[2025-04-30 16:38:39,816][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6408, lr=0.0001
[2025-04-30 16:38:39,825][meta_train][INFO] - epoch_63 saved !
[2025-04-30 16:39:15,309][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6405, lr=0.0001
[2025-04-30 16:39:53,022][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6245, lr=0.0001
[2025-04-30 16:40:28,379][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6180, lr=0.0001
[2025-04-30 16:41:05,879][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6229, lr=0.0001
[2025-04-30 16:41:43,548][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6282, lr=0.0001
[2025-04-30 16:42:19,528][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:42:56,801][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6303, lr=0.0001
[2025-04-30 16:43:33,664][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6173, lr=0.0001
[2025-04-30 16:43:33,685][meta_train][INFO] - epoch_64 saved !
[2025-04-30 16:44:10,548][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6327, lr=0.0001
[2025-04-30 16:44:47,522][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6312, lr=0.0001
[2025-04-30 16:45:23,812][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6232, lr=0.0001
[2025-04-30 16:45:59,518][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6170, lr=0.0001
[2025-04-30 16:46:37,549][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6159, lr=0.0001
[2025-04-30 16:47:14,410][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6316, lr=0.0001
[2025-04-30 16:47:50,961][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6239, lr=0.0001
[2025-04-30 16:48:26,869][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6218, lr=0.0001
[2025-04-30 16:48:26,878][meta_train][INFO] - epoch_65 saved !
[2025-04-30 16:49:04,857][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6243, lr=0.0001
[2025-04-30 16:49:41,040][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6159, lr=0.0001
[2025-04-30 16:50:17,491][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6225, lr=0.0001
[2025-04-30 16:50:54,984][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6264, lr=0.0001
[2025-04-30 16:51:31,188][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6147, lr=0.0001
[2025-04-30 16:52:08,093][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6192, lr=0.0001
[2025-04-30 16:52:44,190][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6265, lr=0.0001
[2025-04-30 16:53:21,102][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6303, lr=0.0001
[2025-04-30 16:53:21,112][meta_train][INFO] - epoch_66 saved !
[2025-04-30 16:53:57,717][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6147, lr=0.0001
[2025-04-30 16:54:34,139][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6277, lr=0.0001
[2025-04-30 16:55:11,153][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6201, lr=0.0001
[2025-04-30 16:55:47,855][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6311, lr=0.0001
[2025-04-30 16:56:24,808][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6235, lr=0.0001
[2025-04-30 16:57:01,735][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6139, lr=0.0001
[2025-04-30 16:57:37,973][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6203, lr=0.0001
[2025-04-30 16:58:16,103][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6230, lr=0.0001
[2025-04-30 16:58:16,112][meta_train][INFO] - epoch_67 saved !
[2025-04-30 16:58:52,139][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6130, lr=0.0001
[2025-04-30 16:59:29,247][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6242, lr=0.0001
[2025-04-30 17:00:06,481][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6224, lr=0.0001
[2025-04-30 17:00:43,425][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6226, lr=0.0001
[2025-04-30 17:01:19,864][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6201, lr=0.0001
[2025-04-30 17:01:55,704][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6134, lr=0.0001
[2025-04-30 17:02:33,080][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6177, lr=0.0001
[2025-04-30 17:03:10,296][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6269, lr=0.0001
[2025-04-30 17:03:10,310][meta_train][INFO] - epoch_68 saved !
[2025-04-30 17:03:46,766][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6191, lr=0.0001
[2025-04-30 17:04:22,485][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6123, lr=0.0001
[2025-04-30 17:04:59,889][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6218, lr=0.0001
[2025-04-30 17:05:36,014][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6162, lr=0.0001
[2025-04-30 17:06:13,197][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6120, lr=0.0001
[2025-04-30 17:06:50,459][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6226, lr=0.0001
[2025-04-30 17:07:26,854][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6264, lr=0.0001
[2025-04-30 17:08:03,613][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6211, lr=0.0001
[2025-04-30 17:08:03,632][meta_train][INFO] - epoch_69 saved !
[2025-04-30 17:08:40,733][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6120, lr=0.0001
[2025-04-30 17:09:20,904][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6189, lr=0.0001
[2025-04-30 17:09:59,181][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6219, lr=0.0001
[2025-04-30 17:10:36,377][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6249, lr=0.0001
[2025-04-30 17:11:14,065][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6213, lr=0.0001
[2025-04-30 17:11:50,914][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6116, lr=0.0001
[2025-04-30 17:12:27,930][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6149, lr=0.0001
[2025-04-30 17:13:05,563][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6181, lr=0.0001
[2025-04-30 17:13:05,573][meta_train][INFO] - epoch_70 saved !
[2025-04-30 17:13:43,504][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6109, lr=0.0001
[2025-04-30 17:14:21,310][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6144, lr=0.0001
[2025-04-30 17:14:57,878][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:15:35,897][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6233, lr=0.0001
[2025-04-30 17:16:12,203][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6214, lr=0.0001
[2025-04-30 17:16:48,871][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6203, lr=0.0001
[2025-04-30 17:17:27,112][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6107, lr=0.0001
[2025-04-30 17:18:04,957][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6178, lr=0.0001
[2025-04-30 17:18:04,967][meta_train][INFO] - epoch_71 saved !
[2025-04-30 17:18:41,987][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6099, lr=0.0001
[2025-04-30 17:19:19,278][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6184, lr=0.0001
[2025-04-30 17:19:57,636][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6141, lr=0.0001
[2025-04-30 17:20:34,821][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6209, lr=0.0001
[2025-04-30 17:21:11,103][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6180, lr=0.0001
[2025-04-30 17:21:48,403][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6184, lr=0.0001
[2025-04-30 17:22:26,396][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6218, lr=0.0001
[2025-04-30 17:23:03,684][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6101, lr=0.0001
[2025-04-30 17:23:03,706][meta_train][INFO] - epoch_72 saved !
[2025-04-30 17:23:41,351][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6090, lr=0.0001
[2025-04-30 17:24:17,973][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:24:55,791][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6125, lr=0.0001
[2025-04-30 17:25:32,215][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6172, lr=0.0001
[2025-04-30 17:26:09,886][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6104, lr=0.0001
[2025-04-30 17:26:46,454][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6223, lr=0.0001
[2025-04-30 17:27:23,638][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6209, lr=0.0001
[2025-04-30 17:28:01,922][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6171, lr=0.0001
[2025-04-30 17:28:01,932][meta_train][INFO] - epoch_73 saved !
[2025-04-30 17:28:39,008][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6202, lr=0.0001
[2025-04-30 17:29:16,398][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6193, lr=0.0001
[2025-04-30 17:29:52,990][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6150, lr=0.0001
[2025-04-30 17:30:30,656][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6092, lr=0.0001
[2025-04-30 17:31:08,039][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6084, lr=0.0001
[2025-04-30 17:31:43,781][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:32:21,648][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6152, lr=0.0001
[2025-04-30 17:33:00,012][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6130, lr=0.0001
[2025-04-30 17:33:00,035][meta_train][INFO] - epoch_74 saved !
[2025-04-30 17:33:36,998][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6164, lr=0.0001
[2025-04-30 17:34:15,353][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6202, lr=0.0001
[2025-04-30 17:34:51,500][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:35:29,084][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-04-30 17:36:06,132][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6171, lr=0.0001
[2025-04-30 17:36:43,551][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:37:20,771][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6135, lr=0.0001
[2025-04-30 17:37:58,164][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6145, lr=0.0001
[2025-04-30 17:37:58,179][meta_train][INFO] - epoch_75 saved !
[2025-04-30 17:38:35,045][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6118, lr=0.0001
[2025-04-30 17:39:12,017][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-04-30 17:39:50,356][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6186, lr=0.0001
[2025-04-30 17:40:27,321][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6195, lr=0.0001
[2025-04-30 17:41:04,122][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-04-30 17:41:41,431][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6088, lr=0.0001
[2025-04-30 17:42:20,139][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6139, lr=0.0001
[2025-04-30 17:42:56,917][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6138, lr=0.0001
[2025-04-30 17:42:56,927][meta_train][INFO] - epoch_76 saved !
[2025-04-30 17:43:33,681][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6134, lr=0.0001
[2025-04-30 17:44:10,651][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6110, lr=0.0001
[2025-04-30 17:44:47,363][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6185, lr=0.0001
[2025-04-30 17:45:25,236][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6156, lr=0.0001
[2025-04-30 17:46:02,490][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6153, lr=0.0001
[2025-04-30 17:46:40,082][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6088, lr=0.0001
[2025-04-30 17:47:18,518][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6167, lr=0.0001
[2025-04-30 17:47:55,746][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:47:55,757][meta_train][INFO] - epoch_77 saved !
[2025-04-30 17:48:33,951][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6101, lr=0.0001
[2025-04-30 17:49:10,830][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6080, lr=0.0001
[2025-04-30 17:49:48,618][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:50:26,181][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6144, lr=0.0001
[2025-04-30 17:51:02,980][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6153, lr=0.0001
[2025-04-30 17:51:40,747][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6219, lr=0.0001
[2025-04-30 17:52:18,995][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6089, lr=0.0001
[2025-04-30 17:52:58,326][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:52:58,339][meta_train][INFO] - epoch_78 saved !
[2025-04-30 17:53:35,848][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6083, lr=0.0001
[2025-04-30 17:54:12,938][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6122, lr=0.0001
[2025-04-30 17:54:49,080][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6114, lr=0.0001
[2025-04-30 17:55:29,163][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6129, lr=0.0001
[2025-04-30 17:56:06,991][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:56:43,542][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6080, lr=0.0001
[2025-04-30 17:57:21,669][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6175, lr=0.0001
[2025-04-30 17:57:58,991][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6117, lr=0.0001
[2025-04-30 17:57:59,016][meta_train][INFO] - epoch_79 saved !
[2025-04-30 17:58:36,194][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-04-30 17:59:14,182][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6084, lr=0.0001
[2025-04-30 17:59:50,129][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6174, lr=0.0001
[2025-04-30 18:00:27,507][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6120, lr=0.0001
[2025-04-30 18:01:04,567][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:01:42,802][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6076, lr=0.0001
[2025-04-30 18:02:18,621][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6141, lr=0.0001
[2025-04-30 18:02:56,701][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:02:56,721][meta_train][INFO] - epoch_80 saved !
[2025-04-30 18:03:33,305][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6104, lr=0.0001
[2025-04-30 18:04:11,079][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6115, lr=0.0001
[2025-04-30 18:04:47,655][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6144, lr=0.0001
[2025-04-30 18:05:25,055][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6083, lr=0.0001
[2025-04-30 18:06:02,412][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6126, lr=0.0001
[2025-04-30 18:06:39,682][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6174, lr=0.0001
[2025-04-30 18:07:17,852][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6136, lr=0.0001
[2025-04-30 18:07:55,675][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6076, lr=0.0001
[2025-04-30 18:07:55,697][meta_train][INFO] - epoch_81 saved !
[2025-04-30 18:08:31,256][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6121, lr=0.0001
[2025-04-30 18:09:09,467][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6112, lr=0.0001
[2025-04-30 18:09:45,577][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6135, lr=0.0001
[2025-04-30 18:10:22,897][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6126, lr=0.0001
[2025-04-30 18:10:59,729][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6079, lr=0.0001
[2025-04-30 18:11:37,001][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:12:15,556][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:12:51,523][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6167, lr=0.0001
[2025-04-30 18:12:51,533][meta_train][INFO] - epoch_82 saved !
[2025-04-30 18:13:29,637][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6142, lr=0.0001
[2025-04-30 18:14:06,412][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6081, lr=0.0001
[2025-04-30 18:14:43,126][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:15:19,543][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:15:57,081][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6105, lr=0.0001
[2025-04-30 18:16:34,469][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6166, lr=0.0001
[2025-04-30 18:17:12,482][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:17:50,660][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:17:50,683][meta_train][INFO] - epoch_83 saved !
[2025-04-30 18:18:28,290][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6107, lr=0.0001
[2025-04-30 18:19:05,500][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6161, lr=0.0001
[2025-04-30 18:19:42,627][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6122, lr=0.0001
[2025-04-30 18:20:18,323][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:20:56,497][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6123, lr=0.0001
[2025-04-30 18:21:33,955][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6079, lr=0.0001
[2025-04-30 18:22:10,033][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:22:48,531][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:22:48,540][meta_train][INFO] - epoch_84 saved !
[2025-04-30 18:23:24,992][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6163, lr=0.0001
[2025-04-30 18:24:02,333][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6102, lr=0.0001
[2025-04-30 18:24:38,858][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6102, lr=0.0001
[2025-04-30 18:25:16,975][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-04-30 18:25:54,589][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:26:31,883][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6107, lr=0.0001
[2025-04-30 18:27:08,215][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6078, lr=0.0001
[2025-04-30 18:27:45,998][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:27:46,008][meta_train][INFO] - epoch_85 saved !
[2025-04-30 18:28:22,385][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6108, lr=0.0001
[2025-04-30 18:29:00,351][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6123, lr=0.0001
[2025-04-30 18:29:37,318][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-04-30 18:30:15,490][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6154, lr=0.0001
[2025-04-30 18:30:52,645][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:31:29,338][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6117, lr=0.0001
[2025-04-30 18:32:05,751][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6098, lr=0.0001
[2025-04-30 18:32:43,490][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:32:43,501][meta_train][INFO] - epoch_86 saved !
[2025-04-30 18:33:19,943][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:33:57,566][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:34:35,009][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:35:11,055][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:35:48,034][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6103, lr=0.0001
[2025-04-30 18:36:24,623][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-04-30 18:37:02,258][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:37:39,462][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6152, lr=0.0001
[2025-04-30 18:37:39,471][meta_train][INFO] - epoch_87 saved !
[2025-04-30 18:38:16,154][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6075, lr=0.0001
[2025-04-30 18:38:52,432][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6156, lr=0.0001
[2025-04-30 18:39:30,220][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6129, lr=0.0001
[2025-04-30 18:40:06,828][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6118, lr=0.0001
[2025-04-30 18:40:42,880][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:41:20,480][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6068, lr=0.0001
[2025-04-30 18:41:57,022][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6100, lr=0.0001
[2025-04-30 18:42:33,187][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:42:33,207][meta_train][INFO] - epoch_88 saved !
[2025-04-30 18:43:10,735][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6104, lr=0.0001
[2025-04-30 18:43:46,844][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-04-30 18:44:24,460][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6125, lr=0.0001
[2025-04-30 18:45:02,235][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:45:38,340][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:46:15,642][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6146, lr=0.0001
[2025-04-30 18:46:51,622][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6091, lr=0.0001
[2025-04-30 18:47:28,869][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:47:28,878][meta_train][INFO] - epoch_89 saved !
[2025-04-30 18:48:06,787][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6150, lr=0.0001
[2025-04-30 18:48:44,619][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6069, lr=0.0001
[2025-04-30 18:49:20,752][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6096, lr=0.0001
[2025-04-30 18:49:57,845][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6099, lr=0.0001
[2025-04-30 18:50:33,510][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6073, lr=0.0001
[2025-04-30 18:51:11,189][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6109, lr=0.0001
[2025-04-30 18:51:48,895][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6106, lr=0.0001
[2025-04-30 18:52:25,053][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6091, lr=0.0001
[2025-04-30 18:52:25,064][meta_train][INFO] - epoch_90 saved !
[2025-04-30 18:53:01,415][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6146, lr=0.0001
[2025-04-30 18:53:39,143][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6067, lr=0.0001
[2025-04-30 18:54:17,232][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6112, lr=0.0001
[2025-04-30 18:54:54,385][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6111, lr=0.0001
[2025-04-30 18:55:30,631][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6090, lr=0.0001
[2025-04-30 18:56:07,662][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6089, lr=0.0001
[2025-04-30 18:56:43,938][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6093, lr=0.0001
[2025-04-30 18:57:21,121][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6072, lr=0.0001
[2025-04-30 18:57:21,141][meta_train][INFO] - epoch_91 saved !
[2025-04-30 18:57:58,244][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6114, lr=0.0001
[2025-04-30 18:58:35,673][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 18:59:12,279][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6110, lr=0.0001
[2025-04-30 18:59:48,950][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6071, lr=0.0001
[2025-04-30 19:00:26,441][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6065, lr=0.0001
[2025-04-30 19:01:03,597][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:01:40,712][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6087, lr=0.0001
[2025-04-30 19:02:16,527][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6142, lr=0.0001
[2025-04-30 19:02:16,537][meta_train][INFO] - epoch_92 saved !
[2025-04-30 19:02:53,507][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6109, lr=0.0001
[2025-04-30 19:03:31,339][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:04:07,411][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:04:43,921][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6088, lr=0.0001
[2025-04-30 19:05:20,648][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6089, lr=0.0001
[2025-04-30 19:05:57,591][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6069, lr=0.0001
[2025-04-30 19:06:34,836][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6140, lr=0.0001
[2025-04-30 19:07:12,496][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6107, lr=0.0001
[2025-04-30 19:07:12,508][meta_train][INFO] - epoch_93 saved !
[2025-04-30 19:07:49,802][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6093, lr=0.0001
[2025-04-30 19:08:25,670][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6071, lr=0.0001
[2025-04-30 19:09:02,480][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6091, lr=0.0001
[2025-04-30 19:09:38,518][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:10:16,607][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6137, lr=0.0001
[2025-04-30 19:10:53,476][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6102, lr=0.0001
[2025-04-30 19:11:30,982][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6101, lr=0.0001
[2025-04-30 19:12:07,014][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6065, lr=0.0001
[2025-04-30 19:12:07,023][meta_train][INFO] - epoch_94 saved !
[2025-04-30 19:12:43,868][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:13:21,798][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6136, lr=0.0001
[2025-04-30 19:13:58,406][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6099, lr=0.0001
[2025-04-30 19:14:35,717][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6084, lr=0.0001
[2025-04-30 19:15:11,857][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:15:48,661][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6064, lr=0.0001
[2025-04-30 19:16:26,001][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6070, lr=0.0001
[2025-04-30 19:17:03,047][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:17:03,057][meta_train][INFO] - epoch_95 saved !
[2025-04-30 19:17:40,466][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6064, lr=0.0001
[2025-04-30 19:18:15,594][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6087, lr=0.0001
[2025-04-30 19:18:53,406][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:19:30,588][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:20:07,271][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6069, lr=0.0001
[2025-04-30 19:20:43,264][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6135, lr=0.0001
[2025-04-30 19:21:20,660][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6099, lr=0.0001
[2025-04-30 19:21:57,351][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:21:57,360][meta_train][INFO] - epoch_96 saved !
[2025-04-30 19:22:35,297][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6086, lr=0.0001
[2025-04-30 19:23:12,572][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:23:49,353][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:24:25,925][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6083, lr=0.0001
[2025-04-30 19:25:03,497][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-04-30 19:25:38,613][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6090, lr=0.0001
[2025-04-30 19:26:16,033][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:26:54,287][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6133, lr=0.0001
[2025-04-30 19:26:54,299][meta_train][INFO] - epoch_97 saved !
[2025-04-30 19:27:31,614][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6131, lr=0.0001
[2025-04-30 19:28:07,535][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6078, lr=0.0001
[2025-04-30 19:28:44,952][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6061, lr=0.0001
[2025-04-30 19:29:21,401][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6082, lr=0.0001
[2025-04-30 19:29:58,540][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6067, lr=0.0001
[2025-04-30 19:30:35,207][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6085, lr=0.0001
[2025-04-30 19:31:11,792][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6097, lr=0.0001
[2025-04-30 19:31:48,980][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6100, lr=0.0001
[2025-04-30 19:31:48,990][meta_train][INFO] - epoch_98 saved !
[2025-04-30 19:32:24,668][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6068, lr=0.0001
[2025-04-30 19:33:02,569][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-04-30 19:33:39,218][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6082, lr=0.0001
[2025-04-30 19:34:15,205][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-04-30 19:34:52,140][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6076, lr=0.0001
[2025-04-30 19:35:29,719][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:36:06,369][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6083, lr=0.0001
[2025-04-30 19:36:43,453][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6132, lr=0.0001
[2025-04-30 19:36:43,471][meta_train][INFO] - epoch_99 saved !
[2025-04-30 19:37:19,514][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-04-30 19:37:55,474][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6068, lr=0.0001
[2025-04-30 19:38:32,721][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6081, lr=0.0001
[2025-04-30 19:39:10,169][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6079, lr=0.0001
[2025-04-30 19:39:46,169][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6060, lr=0.0001
[2025-04-30 19:40:23,016][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6079, lr=0.0001
[2025-04-30 19:40:59,772][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6077, lr=0.0001
[2025-04-30 19:41:37,668][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6094, lr=0.0001
[2025-04-30 19:41:37,681][meta_train][INFO] - epoch_100 saved !
[2025-04-30 19:46:27,948][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:46:28,004][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:46:37,150][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:46:37,205][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:46:57,568][train][INFO] - Before training : Train Acc=0.8257  Val Acc=0.6306
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:47:06,035][train][INFO] - Epoch 1/100, Val Acc=0.6407, Val Loss=1.6995, lr=0.0100
[2025-04-30 19:47:07,252][train][INFO] - Before training : Train Acc=0.1055  Val Acc=0.1158
[2025-04-30 19:47:14,416][train][INFO] - Epoch 2/100, Val Acc=0.6528, Val Loss=1.5877, lr=0.0100
[2025-04-30 19:47:15,990][train][INFO] - Epoch 1/100, Val Acc=0.6457, Val Loss=1.6016, lr=0.0100
[2025-04-30 19:47:23,157][train][INFO] - Epoch 3/100, Val Acc=0.6414, Val Loss=1.6361, lr=0.0100
[2025-04-30 19:47:24,835][train][INFO] - Epoch 2/100, Val Acc=0.6383, Val Loss=1.6544, lr=0.0100
[2025-04-30 19:47:31,634][train][INFO] - Epoch 4/100, Val Acc=0.6530, Val Loss=1.6066, lr=0.0100
[2025-04-30 19:47:33,170][train][INFO] - Epoch 3/100, Val Acc=0.6411, Val Loss=1.6179, lr=0.0100
[2025-04-30 19:47:39,773][train][INFO] - Epoch 5/100, Val Acc=0.6603, Val Loss=1.5535, lr=0.0100
[2025-04-30 19:47:41,713][train][INFO] - Epoch 4/100, Val Acc=0.6595, Val Loss=1.5565, lr=0.0100
[2025-04-30 19:47:41,925][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:47:41,991][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:47:47,911][train][INFO] - Epoch 6/100, Val Acc=0.6725, Val Loss=1.5152, lr=0.0100
[2025-04-30 19:47:49,024][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-04-30 19:47:49,084][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 19:47:49,085][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 19:47:49,085][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 19:47:50,349][train][INFO] - Epoch 5/100, Val Acc=0.6432, Val Loss=1.6024, lr=0.0100
[2025-04-30 19:47:56,807][train][INFO] - Epoch 7/100, Val Acc=0.6638, Val Loss=1.5519, lr=0.0100
[2025-04-30 19:47:58,945][train][INFO] - Epoch 6/100, Val Acc=0.6699, Val Loss=1.5082, lr=0.0100
[2025-04-30 19:48:04,567][train][INFO] - Epoch 8/100, Val Acc=0.6665, Val Loss=1.5878, lr=0.0100
[2025-04-30 19:48:07,605][train][INFO] - Epoch 7/100, Val Acc=0.6663, Val Loss=1.4997, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:48:12,573][train][INFO] - Epoch 9/100, Val Acc=0.6650, Val Loss=1.5326, lr=0.0100
[2025-04-30 19:48:15,193][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 19:48:16,808][train][INFO] - Epoch 8/100, Val Acc=0.6571, Val Loss=1.5771, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 19:48:21,070][train][INFO] - Epoch 10/100, Val Acc=0.6747, Val Loss=1.5253, lr=0.0100
[2025-04-30 19:48:22,535][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 19:48:25,756][train][INFO] - Epoch 1/100, Val Acc=0.6327, Val Loss=1.5511, lr=0.0100
[2025-04-30 19:48:27,376][train][INFO] - Epoch 9/100, Val Acc=0.6676, Val Loss=1.5176, lr=0.0100
[2025-04-30 19:48:31,595][train][INFO] - Epoch 11/100, Val Acc=0.6618, Val Loss=1.5361, lr=0.0100
[2025-04-30 19:48:33,299][train][INFO] - Epoch 1/100, Val Acc=0.6202, Val Loss=1.6618, lr=0.0100
[2025-04-30 19:48:36,408][train][INFO] - Epoch 2/100, Val Acc=0.6353, Val Loss=1.6206, lr=0.0100
[2025-04-30 19:48:37,990][train][INFO] - Epoch 10/100, Val Acc=0.6609, Val Loss=1.5555, lr=0.0100
[2025-04-30 19:48:42,108][train][INFO] - Epoch 12/100, Val Acc=0.6589, Val Loss=1.5327, lr=0.0100
[2025-04-30 19:48:43,879][train][INFO] - Epoch 2/100, Val Acc=0.6242, Val Loss=1.6651, lr=0.0100
[2025-04-30 19:48:46,850][train][INFO] - Epoch 3/100, Val Acc=0.6350, Val Loss=1.5867, lr=0.0100
[2025-04-30 19:48:48,618][train][INFO] - Epoch 11/100, Val Acc=0.6566, Val Loss=1.5830, lr=0.0100
[2025-04-30 19:48:52,736][train][INFO] - Epoch 13/100, Val Acc=0.6715, Val Loss=1.5349, lr=0.0100
[2025-04-30 19:48:54,512][train][INFO] - Epoch 3/100, Val Acc=0.6378, Val Loss=1.5470, lr=0.0100
[2025-04-30 19:48:57,346][train][INFO] - Epoch 4/100, Val Acc=0.6653, Val Loss=1.4287, lr=0.0100
[2025-04-30 19:48:59,330][train][INFO] - Epoch 12/100, Val Acc=0.6586, Val Loss=1.5659, lr=0.0100
[2025-04-30 19:49:03,229][train][INFO] - Epoch 14/100, Val Acc=0.6721, Val Loss=1.5565, lr=0.0100
[2025-04-30 19:49:05,074][train][INFO] - Epoch 4/100, Val Acc=0.6574, Val Loss=1.4975, lr=0.0100
[2025-04-30 19:49:08,026][train][INFO] - Epoch 5/100, Val Acc=0.6563, Val Loss=1.4773, lr=0.0100
[2025-04-30 19:49:09,874][train][INFO] - Epoch 13/100, Val Acc=0.6646, Val Loss=1.5909, lr=0.0100
[2025-04-30 19:49:13,721][train][INFO] - Epoch 15/100, Val Acc=0.6637, Val Loss=1.5761, lr=0.0100
[2025-04-30 19:49:15,353][train][INFO] - Epoch 5/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-04-30 19:49:18,500][train][INFO] - Epoch 6/100, Val Acc=0.6541, Val Loss=1.5511, lr=0.0100
[2025-04-30 19:49:20,324][train][INFO] - Epoch 14/100, Val Acc=0.6611, Val Loss=1.6061, lr=0.0100
[2025-04-30 19:49:24,353][train][INFO] - Epoch 16/100, Val Acc=0.6739, Val Loss=1.4943, lr=0.0100
[2025-04-30 19:49:26,068][train][INFO] - Epoch 6/100, Val Acc=0.6604, Val Loss=1.5065, lr=0.0100
[2025-04-30 19:49:29,033][train][INFO] - Epoch 7/100, Val Acc=0.6590, Val Loss=1.5539, lr=0.0100
[2025-04-30 19:49:30,849][train][INFO] - Epoch 15/100, Val Acc=0.6678, Val Loss=1.5833, lr=0.0100
[2025-04-30 19:49:34,687][train][INFO] - Epoch 17/100, Val Acc=0.6754, Val Loss=1.5239, lr=0.0100
[2025-04-30 19:49:36,447][train][INFO] - Epoch 7/100, Val Acc=0.6612, Val Loss=1.5037, lr=0.0100
[2025-04-30 19:49:39,567][train][INFO] - Epoch 8/100, Val Acc=0.6354, Val Loss=1.7221, lr=0.0100
[2025-04-30 19:49:41,294][train][INFO] - Epoch 16/100, Val Acc=0.6664, Val Loss=1.5356, lr=0.0100
[2025-04-30 19:49:45,319][train][INFO] - Epoch 18/100, Val Acc=0.6540, Val Loss=1.6374, lr=0.0100
[2025-04-30 19:49:47,014][train][INFO] - Epoch 8/100, Val Acc=0.6640, Val Loss=1.5142, lr=0.0100
[2025-04-30 19:49:50,229][train][INFO] - Epoch 9/100, Val Acc=0.6589, Val Loss=1.5581, lr=0.0100
[2025-04-30 19:49:51,960][train][INFO] - Epoch 17/100, Val Acc=0.6677, Val Loss=1.5597, lr=0.0100
[2025-04-30 19:49:55,888][train][INFO] - Epoch 19/100, Val Acc=0.6666, Val Loss=1.5533, lr=0.0100
[2025-04-30 19:49:57,599][train][INFO] - Epoch 9/100, Val Acc=0.6634, Val Loss=1.4732, lr=0.0100
[2025-04-30 19:50:00,712][train][INFO] - Epoch 10/100, Val Acc=0.6669, Val Loss=1.5094, lr=0.0100
[2025-04-30 19:50:02,435][train][INFO] - Epoch 18/100, Val Acc=0.6695, Val Loss=1.5787, lr=0.0100
[2025-04-30 19:50:06,493][train][INFO] - Epoch 20/100, Val Acc=0.6757, Val Loss=1.5151, lr=0.0100
[2025-04-30 19:50:08,168][train][INFO] - Epoch 10/100, Val Acc=0.6664, Val Loss=1.4902, lr=0.0100
[2025-04-30 19:50:11,099][train][INFO] - Epoch 11/100, Val Acc=0.6585, Val Loss=1.5493, lr=0.0100
[2025-04-30 19:50:12,891][train][INFO] - Epoch 19/100, Val Acc=0.6577, Val Loss=1.6290, lr=0.0100
[2025-04-30 19:50:17,169][train][INFO] - Epoch 21/100, Val Acc=0.6677, Val Loss=1.5805, lr=0.0100
[2025-04-30 19:50:18,642][train][INFO] - Epoch 11/100, Val Acc=0.6538, Val Loss=1.5780, lr=0.0100
[2025-04-30 19:50:21,565][train][INFO] - Epoch 12/100, Val Acc=0.6653, Val Loss=1.5148, lr=0.0100
[2025-04-30 19:50:23,421][train][INFO] - Epoch 20/100, Val Acc=0.6748, Val Loss=1.5282, lr=0.0100
[2025-04-30 19:50:27,721][train][INFO] - Epoch 22/100, Val Acc=0.6614, Val Loss=1.6285, lr=0.0100
[2025-04-30 19:50:29,076][train][INFO] - Epoch 12/100, Val Acc=0.6616, Val Loss=1.5293, lr=0.0100
[2025-04-30 19:50:32,087][train][INFO] - Epoch 13/100, Val Acc=0.6708, Val Loss=1.5368, lr=0.0100
[2025-04-30 19:50:34,023][train][INFO] - Epoch 21/100, Val Acc=0.6722, Val Loss=1.5627, lr=0.0100
[2025-04-30 19:50:38,372][train][INFO] - Epoch 23/100, Val Acc=0.6743, Val Loss=1.5516, lr=0.0100
[2025-04-30 19:50:39,631][train][INFO] - Epoch 13/100, Val Acc=0.6627, Val Loss=1.5777, lr=0.0100
[2025-04-30 19:50:42,784][train][INFO] - Epoch 14/100, Val Acc=0.6717, Val Loss=1.5219, lr=0.0100
[2025-04-30 19:50:44,638][train][INFO] - Epoch 22/100, Val Acc=0.6772, Val Loss=1.4974, lr=0.0100
[2025-04-30 19:50:49,038][train][INFO] - Epoch 24/100, Val Acc=0.6720, Val Loss=1.5453, lr=0.0100
[2025-04-30 19:50:50,301][train][INFO] - Epoch 14/100, Val Acc=0.6748, Val Loss=1.5258, lr=0.0100
[2025-04-30 19:50:53,451][train][INFO] - Epoch 15/100, Val Acc=0.6660, Val Loss=1.5709, lr=0.0100
[2025-04-30 19:50:55,134][train][INFO] - Epoch 23/100, Val Acc=0.6694, Val Loss=1.5835, lr=0.0100
[2025-04-30 19:50:59,841][train][INFO] - Epoch 25/100, Val Acc=0.6760, Val Loss=1.5460, lr=0.0100
[2025-04-30 19:51:01,002][train][INFO] - Epoch 15/100, Val Acc=0.6556, Val Loss=1.5996, lr=0.0100
[2025-04-30 19:51:04,043][train][INFO] - Epoch 16/100, Val Acc=0.6617, Val Loss=1.5363, lr=0.0100
[2025-04-30 19:51:05,762][train][INFO] - Epoch 24/100, Val Acc=0.6699, Val Loss=1.5384, lr=0.0100
[2025-04-30 19:51:10,678][train][INFO] - Epoch 26/100, Val Acc=0.6691, Val Loss=1.5828, lr=0.0100
[2025-04-30 19:51:11,736][train][INFO] - Epoch 16/100, Val Acc=0.6674, Val Loss=1.5137, lr=0.0100
[2025-04-30 19:51:14,554][train][INFO] - Epoch 17/100, Val Acc=0.6593, Val Loss=1.5829, lr=0.0100
[2025-04-30 19:51:16,269][train][INFO] - Epoch 25/100, Val Acc=0.6713, Val Loss=1.5476, lr=0.0100
[2025-04-30 19:51:21,526][train][INFO] - Epoch 27/100, Val Acc=0.6753, Val Loss=1.5177, lr=0.0100
[2025-04-30 19:51:22,545][train][INFO] - Epoch 17/100, Val Acc=0.6703, Val Loss=1.5060, lr=0.0100
[2025-04-30 19:51:25,093][train][INFO] - Epoch 18/100, Val Acc=0.6706, Val Loss=1.5212, lr=0.0100
[2025-04-30 19:51:26,901][train][INFO] - Epoch 26/100, Val Acc=0.6782, Val Loss=1.5540, lr=0.0100
[2025-04-30 19:51:32,437][train][INFO] - Epoch 28/100, Val Acc=0.6705, Val Loss=1.5932, lr=0.0100
[2025-04-30 19:51:33,413][train][INFO] - Epoch 18/100, Val Acc=0.6732, Val Loss=1.5338, lr=0.0100
[2025-04-30 19:51:35,782][train][INFO] - Epoch 19/100, Val Acc=0.6745, Val Loss=1.5121, lr=0.0100
[2025-04-30 19:51:37,565][train][INFO] - Epoch 27/100, Val Acc=0.6665, Val Loss=1.5557, lr=0.0100
[2025-04-30 19:51:43,200][train][INFO] - Epoch 29/100, Val Acc=0.6685, Val Loss=1.5908, lr=0.0100
[2025-04-30 19:51:44,109][train][INFO] - Epoch 19/100, Val Acc=0.6737, Val Loss=1.4919, lr=0.0100
[2025-04-30 19:51:46,370][train][INFO] - Epoch 20/100, Val Acc=0.6700, Val Loss=1.5738, lr=0.0100
[2025-04-30 19:51:48,203][train][INFO] - Epoch 28/100, Val Acc=0.6642, Val Loss=1.5984, lr=0.0100
[2025-04-30 19:51:54,142][train][INFO] - Epoch 30/100, Val Acc=0.6647, Val Loss=1.6335, lr=0.0100
[2025-04-30 19:51:54,984][train][INFO] - Epoch 20/100, Val Acc=0.6624, Val Loss=1.6129, lr=0.0100
[2025-04-30 19:51:57,010][train][INFO] - Epoch 21/100, Val Acc=0.6773, Val Loss=1.4854, lr=0.0100
[2025-04-30 19:51:58,597][train][INFO] - Epoch 29/100, Val Acc=0.6830, Val Loss=1.4854, lr=0.0100
[2025-04-30 19:52:04,903][train][INFO] - Epoch 31/100, Val Acc=0.6704, Val Loss=1.5471, lr=0.0100
[2025-04-30 19:52:05,768][train][INFO] - Epoch 21/100, Val Acc=0.6680, Val Loss=1.5622, lr=0.0100
[2025-04-30 19:52:07,570][train][INFO] - Epoch 22/100, Val Acc=0.6592, Val Loss=1.6106, lr=0.0100
[2025-04-30 19:52:09,151][train][INFO] - Epoch 30/100, Val Acc=0.6645, Val Loss=1.5862, lr=0.0100
[2025-04-30 19:52:15,719][train][INFO] - Epoch 32/100, Val Acc=0.6754, Val Loss=1.5731, lr=0.0100
[2025-04-30 19:52:16,634][train][INFO] - Epoch 22/100, Val Acc=0.6594, Val Loss=1.5800, lr=0.0100
[2025-04-30 19:52:18,183][train][INFO] - Epoch 23/100, Val Acc=0.6635, Val Loss=1.5948, lr=0.0100
[2025-04-30 19:52:19,638][train][INFO] - Epoch 31/100, Val Acc=0.6696, Val Loss=1.5693, lr=0.0100
[2025-04-30 19:52:26,573][train][INFO] - Epoch 33/100, Val Acc=0.6737, Val Loss=1.5440, lr=0.0100
[2025-04-30 19:52:27,461][train][INFO] - Epoch 23/100, Val Acc=0.6712, Val Loss=1.5522, lr=0.0100
[2025-04-30 19:52:28,690][train][INFO] - Epoch 24/100, Val Acc=0.6741, Val Loss=1.5082, lr=0.0100
[2025-04-30 19:52:30,139][train][INFO] - Epoch 32/100, Val Acc=0.6663, Val Loss=1.5957, lr=0.0100
[2025-04-30 19:52:37,438][train][INFO] - Epoch 34/100, Val Acc=0.6610, Val Loss=1.6145, lr=0.0100
[2025-04-30 19:52:38,226][train][INFO] - Epoch 24/100, Val Acc=0.6700, Val Loss=1.5664, lr=0.0100
[2025-04-30 19:52:39,166][train][INFO] - Epoch 25/100, Val Acc=0.6782, Val Loss=1.5278, lr=0.0100
[2025-04-30 19:52:40,698][train][INFO] - Epoch 33/100, Val Acc=0.6646, Val Loss=1.6011, lr=0.0100
[2025-04-30 19:52:48,286][train][INFO] - Epoch 35/100, Val Acc=0.6700, Val Loss=1.5629, lr=0.0100
[2025-04-30 19:52:49,168][train][INFO] - Epoch 25/100, Val Acc=0.6725, Val Loss=1.5728, lr=0.0100
[2025-04-30 19:52:49,577][train][INFO] - Epoch 26/100, Val Acc=0.6717, Val Loss=1.5651, lr=0.0100
[2025-04-30 19:52:51,195][train][INFO] - Epoch 34/100, Val Acc=0.6696, Val Loss=1.5831, lr=0.0100
[2025-04-30 19:52:59,105][train][INFO] - Epoch 36/100, Val Acc=0.6742, Val Loss=1.5769, lr=0.0100
[2025-04-30 19:53:00,018][train][INFO] - Epoch 26/100, Val Acc=0.6755, Val Loss=1.5334, lr=0.0100
[2025-04-30 19:53:00,169][train][INFO] - Epoch 27/100, Val Acc=0.6712, Val Loss=1.5770, lr=0.0100
[2025-04-30 19:53:01,787][train][INFO] - Epoch 35/100, Val Acc=0.6565, Val Loss=1.6218, lr=0.0100
[2025-04-30 19:53:09,945][train][INFO] - Epoch 37/100, Val Acc=0.6538, Val Loss=1.6506, lr=0.0100
[2025-04-30 19:53:10,847][train][INFO] - Epoch 27/100, Val Acc=0.6814, Val Loss=1.5092, lr=0.0100
[2025-04-30 19:53:10,849][train][INFO] - Epoch 28/100, Val Acc=0.6536, Val Loss=1.6234, lr=0.0100
[2025-04-30 19:53:12,373][train][INFO] - Epoch 36/100, Val Acc=0.6659, Val Loss=1.5933, lr=0.0100
[2025-04-30 19:53:20,775][train][INFO] - Epoch 38/100, Val Acc=0.6742, Val Loss=1.5649, lr=0.0100
[2025-04-30 19:53:21,433][train][INFO] - Epoch 29/100, Val Acc=0.6683, Val Loss=1.5452, lr=0.0100
[2025-04-30 19:53:21,714][train][INFO] - Epoch 28/100, Val Acc=0.6648, Val Loss=1.6038, lr=0.0100
[2025-04-30 19:53:22,975][train][INFO] - Epoch 37/100, Val Acc=0.6583, Val Loss=1.6517, lr=0.0100
[2025-04-30 19:53:31,691][train][INFO] - Epoch 39/100, Val Acc=0.6709, Val Loss=1.5750, lr=0.0100
[2025-04-30 19:53:32,068][train][INFO] - Epoch 30/100, Val Acc=0.6653, Val Loss=1.5742, lr=0.0100
[2025-04-30 19:53:32,466][train][INFO] - Epoch 29/100, Val Acc=0.6660, Val Loss=1.6061, lr=0.0100
[2025-04-30 19:53:33,530][train][INFO] - Epoch 38/100, Val Acc=0.6753, Val Loss=1.5436, lr=0.0100
[2025-04-30 19:53:42,478][train][INFO] - Epoch 40/100, Val Acc=0.6763, Val Loss=1.5888, lr=0.0100
[2025-04-30 19:53:42,601][train][INFO] - Epoch 31/100, Val Acc=0.6780, Val Loss=1.4936, lr=0.0100
[2025-04-30 19:53:43,227][train][INFO] - Epoch 30/100, Val Acc=0.6611, Val Loss=1.6284, lr=0.0100
[2025-04-30 19:53:44,079][train][INFO] - Epoch 39/100, Val Acc=0.6786, Val Loss=1.4823, lr=0.0100
[2025-04-30 19:53:53,207][train][INFO] - Epoch 32/100, Val Acc=0.6724, Val Loss=1.5189, lr=0.0100
[2025-04-30 19:53:53,355][train][INFO] - Epoch 41/100, Val Acc=0.6765, Val Loss=1.5309, lr=0.0100
[2025-04-30 19:53:53,908][train][INFO] - Epoch 31/100, Val Acc=0.6623, Val Loss=1.5847, lr=0.0100
[2025-04-30 19:53:54,700][train][INFO] - Epoch 40/100, Val Acc=0.6731, Val Loss=1.5113, lr=0.0100
[2025-04-30 19:54:03,731][train][INFO] - Epoch 33/100, Val Acc=0.6607, Val Loss=1.6152, lr=0.0100
[2025-04-30 19:54:04,088][train][INFO] - Epoch 42/100, Val Acc=0.6676, Val Loss=1.6109, lr=0.0100
[2025-04-30 19:54:04,570][train][INFO] - Epoch 32/100, Val Acc=0.6678, Val Loss=1.5535, lr=0.0100
[2025-04-30 19:54:05,198][train][INFO] - Epoch 41/100, Val Acc=0.6592, Val Loss=1.6490, lr=0.0100
[2025-04-30 19:54:14,273][train][INFO] - Epoch 34/100, Val Acc=0.6731, Val Loss=1.5232, lr=0.0100
[2025-04-30 19:54:15,072][train][INFO] - Epoch 43/100, Val Acc=0.6673, Val Loss=1.5839, lr=0.0100
[2025-04-30 19:54:15,388][train][INFO] - Epoch 33/100, Val Acc=0.6880, Val Loss=1.4769, lr=0.0100
[2025-04-30 19:54:15,788][train][INFO] - Epoch 42/100, Val Acc=0.6640, Val Loss=1.5757, lr=0.0100
[2025-04-30 19:54:24,894][train][INFO] - Epoch 35/100, Val Acc=0.6651, Val Loss=1.5890, lr=0.0100
[2025-04-30 19:54:26,320][train][INFO] - Epoch 44/100, Val Acc=0.6550, Val Loss=1.6932, lr=0.0100
[2025-04-30 19:54:26,392][train][INFO] - Epoch 43/100, Val Acc=0.6853, Val Loss=1.5129, lr=0.0100
[2025-04-30 19:54:26,397][train][INFO] - Epoch 34/100, Val Acc=0.6722, Val Loss=1.5834, lr=0.0100
[2025-04-30 19:54:35,670][train][INFO] - Epoch 36/100, Val Acc=0.6708, Val Loss=1.5873, lr=0.0100
[2025-04-30 19:54:37,040][train][INFO] - Epoch 44/100, Val Acc=0.6779, Val Loss=1.4963, lr=0.0100
[2025-04-30 19:54:37,588][train][INFO] - Epoch 45/100, Val Acc=0.6650, Val Loss=1.6049, lr=0.0100
[2025-04-30 19:54:37,589][train][INFO] - Epoch 35/100, Val Acc=0.6769, Val Loss=1.5179, lr=0.0100
[2025-04-30 19:54:46,352][train][INFO] - Epoch 37/100, Val Acc=0.6620, Val Loss=1.5828, lr=0.0100
[2025-04-30 19:54:47,689][train][INFO] - Epoch 45/100, Val Acc=0.6880, Val Loss=1.4533, lr=0.0100
[2025-04-30 19:54:48,736][train][INFO] - Epoch 36/100, Val Acc=0.6737, Val Loss=1.4921, lr=0.0100
[2025-04-30 19:54:48,787][train][INFO] - Epoch 46/100, Val Acc=0.6570, Val Loss=1.6438, lr=0.0100
[2025-04-30 19:54:57,151][train][INFO] - Epoch 38/100, Val Acc=0.6670, Val Loss=1.5623, lr=0.0100
[2025-04-30 19:54:58,418][train][INFO] - Epoch 46/100, Val Acc=0.6578, Val Loss=1.6360, lr=0.0100
[2025-04-30 19:54:59,824][train][INFO] - Epoch 37/100, Val Acc=0.6593, Val Loss=1.6012, lr=0.0100
[2025-04-30 19:54:59,887][train][INFO] - Epoch 47/100, Val Acc=0.6565, Val Loss=1.6560, lr=0.0100
[2025-04-30 19:55:08,039][train][INFO] - Epoch 39/100, Val Acc=0.6782, Val Loss=1.5551, lr=0.0100
[2025-04-30 19:55:09,206][train][INFO] - Epoch 47/100, Val Acc=0.6698, Val Loss=1.5891, lr=0.0100
[2025-04-30 19:55:10,856][train][INFO] - Epoch 38/100, Val Acc=0.6633, Val Loss=1.5964, lr=0.0100
[2025-04-30 19:55:10,934][train][INFO] - Epoch 48/100, Val Acc=0.6729, Val Loss=1.5494, lr=0.0100
[2025-04-30 19:55:18,923][train][INFO] - Epoch 40/100, Val Acc=0.6657, Val Loss=1.5560, lr=0.0100
[2025-04-30 19:55:20,076][train][INFO] - Epoch 48/100, Val Acc=0.6738, Val Loss=1.5480, lr=0.0100
[2025-04-30 19:55:22,003][train][INFO] - Epoch 39/100, Val Acc=0.6680, Val Loss=1.6009, lr=0.0100
[2025-04-30 19:55:22,073][train][INFO] - Epoch 49/100, Val Acc=0.6746, Val Loss=1.5532, lr=0.0100
[2025-04-30 19:55:29,753][train][INFO] - Epoch 41/100, Val Acc=0.6725, Val Loss=1.5605, lr=0.0100
[2025-04-30 19:55:30,906][train][INFO] - Epoch 49/100, Val Acc=0.6822, Val Loss=1.4855, lr=0.0100
[2025-04-30 19:55:33,032][train][INFO] - Epoch 40/100, Val Acc=0.6705, Val Loss=1.5971, lr=0.0100
[2025-04-30 19:55:33,146][train][INFO] - Epoch 50/100, Val Acc=0.6724, Val Loss=1.5791, lr=0.0100
[2025-04-30 19:55:40,500][train][INFO] - Epoch 42/100, Val Acc=0.6682, Val Loss=1.6073, lr=0.0100
[2025-04-30 19:55:41,656][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.5307, lr=0.0100
[2025-04-30 19:55:44,159][train][INFO] - Epoch 41/100, Val Acc=0.6839, Val Loss=1.5023, lr=0.0100
[2025-04-30 19:55:44,225][train][INFO] - Epoch 51/100, Val Acc=0.6708, Val Loss=1.5613, lr=0.0100
[2025-04-30 19:55:51,239][train][INFO] - Epoch 43/100, Val Acc=0.6654, Val Loss=1.6140, lr=0.0100
[2025-04-30 19:55:52,472][train][INFO] - Epoch 51/100, Val Acc=0.6762, Val Loss=1.5632, lr=0.0100
[2025-04-30 19:55:55,207][train][INFO] - Epoch 42/100, Val Acc=0.6571, Val Loss=1.6374, lr=0.0100
[2025-04-30 19:55:55,277][train][INFO] - Epoch 52/100, Val Acc=0.6726, Val Loss=1.5799, lr=0.0100
[2025-04-30 19:56:01,969][train][INFO] - Epoch 44/100, Val Acc=0.6770, Val Loss=1.5228, lr=0.0100
[2025-04-30 19:56:03,120][train][INFO] - Epoch 52/100, Val Acc=0.6716, Val Loss=1.5546, lr=0.0100
[2025-04-30 19:56:06,343][train][INFO] - Epoch 43/100, Val Acc=0.6785, Val Loss=1.5746, lr=0.0100
[2025-04-30 19:56:06,388][train][INFO] - Epoch 53/100, Val Acc=0.6748, Val Loss=1.5548, lr=0.0100
[2025-04-30 19:56:12,855][train][INFO] - Epoch 45/100, Val Acc=0.6836, Val Loss=1.5344, lr=0.0100
[2025-04-30 19:56:13,956][train][INFO] - Epoch 53/100, Val Acc=0.6720, Val Loss=1.5156, lr=0.0100
[2025-04-30 19:56:17,480][train][INFO] - Epoch 44/100, Val Acc=0.6724, Val Loss=1.5398, lr=0.0100
[2025-04-30 19:56:17,520][train][INFO] - Epoch 54/100, Val Acc=0.6586, Val Loss=1.6337, lr=0.0100
[2025-04-30 19:56:23,737][train][INFO] - Epoch 46/100, Val Acc=0.6693, Val Loss=1.5429, lr=0.0100
[2025-04-30 19:56:24,781][train][INFO] - Epoch 54/100, Val Acc=0.6677, Val Loss=1.5963, lr=0.0100
[2025-04-30 19:56:28,581][train][INFO] - Epoch 45/100, Val Acc=0.6748, Val Loss=1.5704, lr=0.0100
[2025-04-30 19:56:28,654][train][INFO] - Epoch 55/100, Val Acc=0.6704, Val Loss=1.5667, lr=0.0100
[2025-04-30 19:56:34,552][train][INFO] - Epoch 47/100, Val Acc=0.6717, Val Loss=1.5648, lr=0.0100
[2025-04-30 19:56:35,586][train][INFO] - Epoch 55/100, Val Acc=0.6623, Val Loss=1.6333, lr=0.0100
[2025-04-30 19:56:39,656][train][INFO] - Epoch 46/100, Val Acc=0.6673, Val Loss=1.6348, lr=0.0100
[2025-04-30 19:56:39,738][train][INFO] - Epoch 56/100, Val Acc=0.6747, Val Loss=1.5600, lr=0.0100
[2025-04-30 19:56:45,342][train][INFO] - Epoch 48/100, Val Acc=0.6700, Val Loss=1.5740, lr=0.0100
[2025-04-30 19:56:46,400][train][INFO] - Epoch 56/100, Val Acc=0.6773, Val Loss=1.5350, lr=0.0100
[2025-04-30 19:56:50,708][train][INFO] - Epoch 47/100, Val Acc=0.6713, Val Loss=1.5703, lr=0.0100
[2025-04-30 19:56:50,757][train][INFO] - Epoch 57/100, Val Acc=0.6585, Val Loss=1.6313, lr=0.0100
[2025-04-30 19:56:56,234][train][INFO] - Epoch 49/100, Val Acc=0.6636, Val Loss=1.6012, lr=0.0100
[2025-04-30 19:56:57,308][train][INFO] - Epoch 57/100, Val Acc=0.6602, Val Loss=1.6332, lr=0.0100
[2025-04-30 19:57:01,834][train][INFO] - Epoch 48/100, Val Acc=0.6791, Val Loss=1.5053, lr=0.0100
[2025-04-30 19:57:01,882][train][INFO] - Epoch 58/100, Val Acc=0.6671, Val Loss=1.6380, lr=0.0100
[2025-04-30 19:57:07,106][train][INFO] - Epoch 50/100, Val Acc=0.6561, Val Loss=1.6293, lr=0.0100
[2025-04-30 19:57:08,189][train][INFO] - Epoch 58/100, Val Acc=0.6746, Val Loss=1.5571, lr=0.0100
[2025-04-30 19:57:12,918][train][INFO] - Epoch 49/100, Val Acc=0.6820, Val Loss=1.5156, lr=0.0100
[2025-04-30 19:57:13,002][train][INFO] - Epoch 59/100, Val Acc=0.6662, Val Loss=1.5915, lr=0.0100
[2025-04-30 19:57:17,999][train][INFO] - Epoch 51/100, Val Acc=0.6750, Val Loss=1.5851, lr=0.0100
[2025-04-30 19:57:19,091][train][INFO] - Epoch 59/100, Val Acc=0.6669, Val Loss=1.5939, lr=0.0100
[2025-04-30 19:57:24,019][train][INFO] - Epoch 50/100, Val Acc=0.6820, Val Loss=1.5063, lr=0.0100
[2025-04-30 19:57:24,080][train][INFO] - Epoch 60/100, Val Acc=0.6606, Val Loss=1.6156, lr=0.0100
[2025-04-30 19:57:28,869][train][INFO] - Epoch 52/100, Val Acc=0.6759, Val Loss=1.5658, lr=0.0100
[2025-04-30 19:57:29,939][train][INFO] - Epoch 60/100, Val Acc=0.6776, Val Loss=1.5615, lr=0.0100
[2025-04-30 19:57:35,097][train][INFO] - Epoch 51/100, Val Acc=0.6848, Val Loss=1.5300, lr=0.0100
[2025-04-30 19:57:35,167][train][INFO] - Epoch 61/100, Val Acc=0.7226, Val Loss=1.2792, lr=0.0010
[2025-04-30 19:57:39,734][train][INFO] - Epoch 53/100, Val Acc=0.6744, Val Loss=1.5676, lr=0.0100
[2025-04-30 19:57:40,795][train][INFO] - Epoch 61/100, Val Acc=0.7252, Val Loss=1.3195, lr=0.0010
[2025-04-30 19:57:46,217][train][INFO] - Epoch 52/100, Val Acc=0.6688, Val Loss=1.5983, lr=0.0100
[2025-04-30 19:57:46,311][train][INFO] - Epoch 62/100, Val Acc=0.7256, Val Loss=1.2744, lr=0.0010
[2025-04-30 19:57:50,417][train][INFO] - Epoch 54/100, Val Acc=0.6773, Val Loss=1.5507, lr=0.0100
[2025-04-30 19:57:51,657][train][INFO] - Epoch 62/100, Val Acc=0.7310, Val Loss=1.2994, lr=0.0010
[2025-04-30 19:57:57,179][train][INFO] - Epoch 53/100, Val Acc=0.6731, Val Loss=1.5619, lr=0.0100
[2025-04-30 19:57:57,322][train][INFO] - Epoch 63/100, Val Acc=0.7306, Val Loss=1.2784, lr=0.0010
[2025-04-30 19:58:01,231][train][INFO] - Epoch 55/100, Val Acc=0.6612, Val Loss=1.6360, lr=0.0100
[2025-04-30 19:58:02,464][train][INFO] - Epoch 63/100, Val Acc=0.7330, Val Loss=1.3041, lr=0.0010
[2025-04-30 19:58:08,350][train][INFO] - Epoch 54/100, Val Acc=0.6683, Val Loss=1.5741, lr=0.0100
[2025-04-30 19:58:08,426][train][INFO] - Epoch 64/100, Val Acc=0.7303, Val Loss=1.2870, lr=0.0010
[2025-04-30 19:58:11,989][train][INFO] - Epoch 56/100, Val Acc=0.6749, Val Loss=1.5532, lr=0.0100
[2025-04-30 19:58:13,260][train][INFO] - Epoch 64/100, Val Acc=0.7344, Val Loss=1.3048, lr=0.0010
[2025-04-30 19:58:19,441][train][INFO] - Epoch 55/100, Val Acc=0.6803, Val Loss=1.5268, lr=0.0100
[2025-04-30 19:58:19,561][train][INFO] - Epoch 65/100, Val Acc=0.7332, Val Loss=1.2895, lr=0.0010
[2025-04-30 19:58:22,786][train][INFO] - Epoch 57/100, Val Acc=0.6718, Val Loss=1.5736, lr=0.0100
[2025-04-30 19:58:24,001][train][INFO] - Epoch 65/100, Val Acc=0.7351, Val Loss=1.3133, lr=0.0010
[2025-04-30 19:58:30,552][train][INFO] - Epoch 56/100, Val Acc=0.6701, Val Loss=1.5701, lr=0.0100
[2025-04-30 19:58:30,657][train][INFO] - Epoch 66/100, Val Acc=0.7341, Val Loss=1.2895, lr=0.0010
[2025-04-30 19:58:33,835][train][INFO] - Epoch 58/100, Val Acc=0.6701, Val Loss=1.5888, lr=0.0100
[2025-04-30 19:58:34,886][train][INFO] - Epoch 66/100, Val Acc=0.7375, Val Loss=1.3119, lr=0.0010
[2025-04-30 19:58:41,597][train][INFO] - Epoch 57/100, Val Acc=0.6602, Val Loss=1.6520, lr=0.0100
[2025-04-30 19:58:41,675][train][INFO] - Epoch 67/100, Val Acc=0.7357, Val Loss=1.2875, lr=0.0010
[2025-04-30 19:58:44,650][train][INFO] - Epoch 59/100, Val Acc=0.6709, Val Loss=1.5800, lr=0.0100
[2025-04-30 19:58:45,769][train][INFO] - Epoch 67/100, Val Acc=0.7360, Val Loss=1.3137, lr=0.0010
[2025-04-30 19:58:52,714][train][INFO] - Epoch 58/100, Val Acc=0.6738, Val Loss=1.5710, lr=0.0100
[2025-04-30 19:58:52,848][train][INFO] - Epoch 68/100, Val Acc=0.7363, Val Loss=1.2914, lr=0.0010
[2025-04-30 19:58:55,576][train][INFO] - Epoch 60/100, Val Acc=0.6553, Val Loss=1.6648, lr=0.0100
[2025-04-30 19:58:56,646][train][INFO] - Epoch 68/100, Val Acc=0.7389, Val Loss=1.3134, lr=0.0010
[2025-04-30 19:59:03,655][train][INFO] - Epoch 59/100, Val Acc=0.6660, Val Loss=1.6462, lr=0.0100
[2025-04-30 19:59:03,844][train][INFO] - Epoch 69/100, Val Acc=0.7350, Val Loss=1.2914, lr=0.0010
[2025-04-30 19:59:06,352][train][INFO] - Epoch 61/100, Val Acc=0.7229, Val Loss=1.3331, lr=0.0010
[2025-04-30 19:59:07,503][train][INFO] - Epoch 69/100, Val Acc=0.7405, Val Loss=1.3234, lr=0.0010
[2025-04-30 19:59:14,617][train][INFO] - Epoch 60/100, Val Acc=0.6694, Val Loss=1.5923, lr=0.0100
[2025-04-30 19:59:14,849][train][INFO] - Epoch 70/100, Val Acc=0.7358, Val Loss=1.3019, lr=0.0010
[2025-04-30 19:59:17,240][train][INFO] - Epoch 62/100, Val Acc=0.7266, Val Loss=1.3265, lr=0.0010
[2025-04-30 19:59:18,386][train][INFO] - Epoch 70/100, Val Acc=0.7374, Val Loss=1.3408, lr=0.0010
[2025-04-30 19:59:25,632][train][INFO] - Epoch 61/100, Val Acc=0.7249, Val Loss=1.3293, lr=0.0010
[2025-04-30 19:59:25,903][train][INFO] - Epoch 71/100, Val Acc=0.7349, Val Loss=1.3071, lr=0.0010
[2025-04-30 19:59:28,119][train][INFO] - Epoch 63/100, Val Acc=0.7281, Val Loss=1.3325, lr=0.0010
[2025-04-30 19:59:29,218][train][INFO] - Epoch 71/100, Val Acc=0.7375, Val Loss=1.3355, lr=0.0010
[2025-04-30 19:59:36,626][train][INFO] - Epoch 62/100, Val Acc=0.7259, Val Loss=1.3206, lr=0.0010
[2025-04-30 19:59:36,912][train][INFO] - Epoch 72/100, Val Acc=0.7357, Val Loss=1.2989, lr=0.0010
[2025-04-30 19:59:39,019][train][INFO] - Epoch 64/100, Val Acc=0.7305, Val Loss=1.3348, lr=0.0010
[2025-04-30 19:59:40,020][train][INFO] - Epoch 72/100, Val Acc=0.7402, Val Loss=1.3307, lr=0.0010
[2025-04-30 19:59:47,653][train][INFO] - Epoch 63/100, Val Acc=0.7276, Val Loss=1.3266, lr=0.0010
[2025-04-30 19:59:47,954][train][INFO] - Epoch 73/100, Val Acc=0.7385, Val Loss=1.3049, lr=0.0010
[2025-04-30 19:59:49,877][train][INFO] - Epoch 65/100, Val Acc=0.7313, Val Loss=1.3376, lr=0.0010
[2025-04-30 19:59:50,782][train][INFO] - Epoch 73/100, Val Acc=0.7385, Val Loss=1.3295, lr=0.0010
[2025-04-30 19:59:58,671][train][INFO] - Epoch 64/100, Val Acc=0.7281, Val Loss=1.3300, lr=0.0010
[2025-04-30 19:59:58,995][train][INFO] - Epoch 74/100, Val Acc=0.7389, Val Loss=1.2982, lr=0.0010
[2025-04-30 20:00:00,652][train][INFO] - Epoch 66/100, Val Acc=0.7315, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:00:01,626][train][INFO] - Epoch 74/100, Val Acc=0.7395, Val Loss=1.3247, lr=0.0010
[2025-04-30 20:00:09,646][train][INFO] - Epoch 65/100, Val Acc=0.7306, Val Loss=1.3319, lr=0.0010
[2025-04-30 20:00:09,888][train][INFO] - Epoch 75/100, Val Acc=0.7408, Val Loss=1.3008, lr=0.0010
[2025-04-30 20:00:11,490][train][INFO] - Epoch 67/100, Val Acc=0.7316, Val Loss=1.3338, lr=0.0010
[2025-04-30 20:00:12,409][train][INFO] - Epoch 75/100, Val Acc=0.7395, Val Loss=1.3356, lr=0.0010
[2025-04-30 20:00:20,700][train][INFO] - Epoch 66/100, Val Acc=0.7326, Val Loss=1.3428, lr=0.0010
[2025-04-30 20:00:20,942][train][INFO] - Epoch 76/100, Val Acc=0.7408, Val Loss=1.2978, lr=0.0010
[2025-04-30 20:00:22,316][train][INFO] - Epoch 68/100, Val Acc=0.7323, Val Loss=1.3373, lr=0.0010
[2025-04-30 20:00:23,264][train][INFO] - Epoch 76/100, Val Acc=0.7384, Val Loss=1.3365, lr=0.0010
[2025-04-30 20:00:31,780][train][INFO] - Epoch 67/100, Val Acc=0.7309, Val Loss=1.3422, lr=0.0010
[2025-04-30 20:00:31,981][train][INFO] - Epoch 77/100, Val Acc=0.7402, Val Loss=1.2999, lr=0.0010
[2025-04-30 20:00:33,202][train][INFO] - Epoch 69/100, Val Acc=0.7318, Val Loss=1.3450, lr=0.0010
[2025-04-30 20:00:34,093][train][INFO] - Epoch 77/100, Val Acc=0.7387, Val Loss=1.3336, lr=0.0010
[2025-04-30 20:00:42,753][train][INFO] - Epoch 68/100, Val Acc=0.7326, Val Loss=1.3451, lr=0.0010
[2025-04-30 20:00:42,968][train][INFO] - Epoch 78/100, Val Acc=0.7411, Val Loss=1.2960, lr=0.0010
[2025-04-30 20:00:44,057][train][INFO] - Epoch 70/100, Val Acc=0.7325, Val Loss=1.3466, lr=0.0010
[2025-04-30 20:00:44,859][train][INFO] - Epoch 78/100, Val Acc=0.7403, Val Loss=1.3328, lr=0.0010
[2025-04-30 20:00:53,889][train][INFO] - Epoch 69/100, Val Acc=0.7333, Val Loss=1.3450, lr=0.0010
[2025-04-30 20:00:54,042][train][INFO] - Epoch 79/100, Val Acc=0.7400, Val Loss=1.2994, lr=0.0010
[2025-04-30 20:00:54,939][train][INFO] - Epoch 71/100, Val Acc=0.7339, Val Loss=1.3471, lr=0.0010
[2025-04-30 20:00:55,791][train][INFO] - Epoch 79/100, Val Acc=0.7389, Val Loss=1.3380, lr=0.0010
[2025-04-30 20:01:04,933][train][INFO] - Epoch 70/100, Val Acc=0.7339, Val Loss=1.3521, lr=0.0010
[2025-04-30 20:01:05,185][train][INFO] - Epoch 80/100, Val Acc=0.7391, Val Loss=1.2972, lr=0.0010
[2025-04-30 20:01:05,949][train][INFO] - Epoch 72/100, Val Acc=0.7365, Val Loss=1.3486, lr=0.0010
[2025-04-30 20:01:06,593][train][INFO] - Epoch 80/100, Val Acc=0.7397, Val Loss=1.3389, lr=0.0010
[2025-04-30 20:01:15,885][train][INFO] - Epoch 71/100, Val Acc=0.7345, Val Loss=1.3570, lr=0.0010
[2025-04-30 20:01:16,212][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.2960, lr=0.0010
[2025-04-30 20:01:16,671][train][INFO] - Epoch 73/100, Val Acc=0.7372, Val Loss=1.3449, lr=0.0010
[2025-04-30 20:01:17,315][train][INFO] - Epoch 81/100, Val Acc=0.7400, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:01:26,732][train][INFO] - Epoch 72/100, Val Acc=0.7344, Val Loss=1.3517, lr=0.0010
[2025-04-30 20:01:27,198][train][INFO] - Epoch 82/100, Val Acc=0.7393, Val Loss=1.2993, lr=0.0010
[2025-04-30 20:01:27,553][train][INFO] - Epoch 74/100, Val Acc=0.7377, Val Loss=1.3401, lr=0.0010
[2025-04-30 20:01:28,230][train][INFO] - Epoch 82/100, Val Acc=0.7424, Val Loss=1.3271, lr=0.0010
[2025-04-30 20:01:37,459][train][INFO] - Epoch 73/100, Val Acc=0.7342, Val Loss=1.3550, lr=0.0010
[2025-04-30 20:01:38,036][train][INFO] - Epoch 83/100, Val Acc=0.7402, Val Loss=1.3075, lr=0.0010
[2025-04-30 20:01:38,335][train][INFO] - Epoch 75/100, Val Acc=0.7365, Val Loss=1.3522, lr=0.0010
[2025-04-30 20:01:39,162][train][INFO] - Epoch 83/100, Val Acc=0.7418, Val Loss=1.3392, lr=0.0010
[2025-04-30 20:01:48,362][train][INFO] - Epoch 74/100, Val Acc=0.7360, Val Loss=1.3544, lr=0.0010
[2025-04-30 20:01:48,914][train][INFO] - Epoch 84/100, Val Acc=0.7396, Val Loss=1.3068, lr=0.0010
[2025-04-30 20:01:49,092][train][INFO] - Epoch 76/100, Val Acc=0.7344, Val Loss=1.3492, lr=0.0010
[2025-04-30 20:01:50,068][train][INFO] - Epoch 84/100, Val Acc=0.7415, Val Loss=1.3432, lr=0.0010
[2025-04-30 20:01:59,147][train][INFO] - Epoch 75/100, Val Acc=0.7374, Val Loss=1.3557, lr=0.0010
[2025-04-30 20:01:59,812][train][INFO] - Epoch 85/100, Val Acc=0.7403, Val Loss=1.3045, lr=0.0010
[2025-04-30 20:02:00,008][train][INFO] - Epoch 77/100, Val Acc=0.7379, Val Loss=1.3441, lr=0.0010
[2025-04-30 20:02:00,926][train][INFO] - Epoch 85/100, Val Acc=0.7408, Val Loss=1.3314, lr=0.0010
[2025-04-30 20:02:09,946][train][INFO] - Epoch 76/100, Val Acc=0.7378, Val Loss=1.3527, lr=0.0010
[2025-04-30 20:02:10,710][train][INFO] - Epoch 86/100, Val Acc=0.7401, Val Loss=1.3096, lr=0.0010
[2025-04-30 20:02:10,763][train][INFO] - Epoch 78/100, Val Acc=0.7373, Val Loss=1.3415, lr=0.0010
[2025-04-30 20:02:11,804][train][INFO] - Epoch 86/100, Val Acc=0.7439, Val Loss=1.3323, lr=0.0010
[2025-04-30 20:02:20,695][train][INFO] - Epoch 77/100, Val Acc=0.7366, Val Loss=1.3563, lr=0.0010
[2025-04-30 20:02:21,522][train][INFO] - Epoch 87/100, Val Acc=0.7379, Val Loss=1.3038, lr=0.0010
[2025-04-30 20:02:21,581][train][INFO] - Epoch 79/100, Val Acc=0.7361, Val Loss=1.3516, lr=0.0010
[2025-04-30 20:02:22,745][train][INFO] - Epoch 87/100, Val Acc=0.7398, Val Loss=1.3316, lr=0.0010
[2025-04-30 20:02:31,471][train][INFO] - Epoch 78/100, Val Acc=0.7376, Val Loss=1.3494, lr=0.0010
[2025-04-30 20:02:32,363][train][INFO] - Epoch 80/100, Val Acc=0.7384, Val Loss=1.3486, lr=0.0010
[2025-04-30 20:02:32,515][train][INFO] - Epoch 88/100, Val Acc=0.7408, Val Loss=1.3097, lr=0.0010
[2025-04-30 20:02:33,565][train][INFO] - Epoch 88/100, Val Acc=0.7423, Val Loss=1.3322, lr=0.0010
[2025-04-30 20:02:42,279][train][INFO] - Epoch 79/100, Val Acc=0.7366, Val Loss=1.3579, lr=0.0010
[2025-04-30 20:02:43,166][train][INFO] - Epoch 81/100, Val Acc=0.7357, Val Loss=1.3473, lr=0.0010
[2025-04-30 20:02:43,415][train][INFO] - Epoch 89/100, Val Acc=0.7412, Val Loss=1.3078, lr=0.0010
[2025-04-30 20:02:44,315][train][INFO] - Epoch 89/100, Val Acc=0.7449, Val Loss=1.3254, lr=0.0010
[2025-04-30 20:02:53,039][train][INFO] - Epoch 80/100, Val Acc=0.7394, Val Loss=1.3461, lr=0.0010
[2025-04-30 20:02:53,986][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3491, lr=0.0010
[2025-04-30 20:02:54,235][train][INFO] - Epoch 90/100, Val Acc=0.7405, Val Loss=1.3082, lr=0.0010
[2025-04-30 20:02:55,164][train][INFO] - Epoch 90/100, Val Acc=0.7431, Val Loss=1.3308, lr=0.0010
[2025-04-30 20:03:03,764][train][INFO] - Epoch 81/100, Val Acc=0.7379, Val Loss=1.3574, lr=0.0010
[2025-04-30 20:03:04,882][train][INFO] - Epoch 83/100, Val Acc=0.7372, Val Loss=1.3474, lr=0.0010
[2025-04-30 20:03:05,036][train][INFO] - Epoch 91/100, Val Acc=0.7413, Val Loss=1.3043, lr=0.0001
[2025-04-30 20:03:05,925][train][INFO] - Epoch 91/100, Val Acc=0.7419, Val Loss=1.3225, lr=0.0001
[2025-04-30 20:03:14,345][train][INFO] - Epoch 82/100, Val Acc=0.7381, Val Loss=1.3535, lr=0.0010
[2025-04-30 20:03:15,759][train][INFO] - Epoch 92/100, Val Acc=0.7413, Val Loss=1.3052, lr=0.0001
[2025-04-30 20:03:15,811][train][INFO] - Epoch 84/100, Val Acc=0.7366, Val Loss=1.3459, lr=0.0010
[2025-04-30 20:03:16,814][train][INFO] - Epoch 92/100, Val Acc=0.7423, Val Loss=1.3300, lr=0.0001
[2025-04-30 20:03:25,024][train][INFO] - Epoch 83/100, Val Acc=0.7380, Val Loss=1.3577, lr=0.0010
[2025-04-30 20:03:26,442][train][INFO] - Epoch 93/100, Val Acc=0.7409, Val Loss=1.3036, lr=0.0001
[2025-04-30 20:03:26,793][train][INFO] - Epoch 85/100, Val Acc=0.7396, Val Loss=1.3381, lr=0.0010
[2025-04-30 20:03:27,731][train][INFO] - Epoch 93/100, Val Acc=0.7431, Val Loss=1.3274, lr=0.0001
[2025-04-30 20:03:35,539][train][INFO] - Epoch 84/100, Val Acc=0.7381, Val Loss=1.3541, lr=0.0010
[2025-04-30 20:03:37,163][train][INFO] - Epoch 94/100, Val Acc=0.7413, Val Loss=1.2992, lr=0.0001
[2025-04-30 20:03:37,600][train][INFO] - Epoch 86/100, Val Acc=0.7386, Val Loss=1.3478, lr=0.0010
[2025-04-30 20:03:38,550][train][INFO] - Epoch 94/100, Val Acc=0.7441, Val Loss=1.3220, lr=0.0001
[2025-04-30 20:03:45,935][train][INFO] - Epoch 85/100, Val Acc=0.7380, Val Loss=1.3488, lr=0.0010
[2025-04-30 20:03:47,703][train][INFO] - Epoch 95/100, Val Acc=0.7403, Val Loss=1.3103, lr=0.0001
[2025-04-30 20:03:48,523][train][INFO] - Epoch 87/100, Val Acc=0.7383, Val Loss=1.3385, lr=0.0010
[2025-04-30 20:03:49,464][train][INFO] - Epoch 95/100, Val Acc=0.7448, Val Loss=1.3297, lr=0.0001
[2025-04-30 20:03:56,369][train][INFO] - Epoch 86/100, Val Acc=0.7351, Val Loss=1.3561, lr=0.0010
[2025-04-30 20:03:58,372][train][INFO] - Epoch 96/100, Val Acc=0.7426, Val Loss=1.3031, lr=0.0001
[2025-04-30 20:03:59,350][train][INFO] - Epoch 88/100, Val Acc=0.7397, Val Loss=1.3439, lr=0.0010
[2025-04-30 20:04:00,218][train][INFO] - Epoch 96/100, Val Acc=0.7444, Val Loss=1.3230, lr=0.0001
[2025-04-30 20:04:06,841][train][INFO] - Epoch 87/100, Val Acc=0.7377, Val Loss=1.3491, lr=0.0010
[2025-04-30 20:04:08,862][train][INFO] - Epoch 97/100, Val Acc=0.7410, Val Loss=1.3016, lr=0.0001
[2025-04-30 20:04:10,108][train][INFO] - Epoch 89/100, Val Acc=0.7417, Val Loss=1.3445, lr=0.0010
[2025-04-30 20:04:11,008][train][INFO] - Epoch 97/100, Val Acc=0.7439, Val Loss=1.3214, lr=0.0001
[2025-04-30 20:04:17,251][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3548, lr=0.0010
[2025-04-30 20:04:19,502][train][INFO] - Epoch 98/100, Val Acc=0.7415, Val Loss=1.2997, lr=0.0001
[2025-04-30 20:04:20,917][train][INFO] - Epoch 90/100, Val Acc=0.7388, Val Loss=1.3493, lr=0.0010
[2025-04-30 20:04:21,867][train][INFO] - Epoch 98/100, Val Acc=0.7445, Val Loss=1.3195, lr=0.0001
[2025-04-30 20:04:27,848][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3551, lr=0.0010
[2025-04-30 20:04:30,116][train][INFO] - Epoch 99/100, Val Acc=0.7418, Val Loss=1.3031, lr=0.0001
[2025-04-30 20:04:31,793][train][INFO] - Epoch 91/100, Val Acc=0.7402, Val Loss=1.3471, lr=0.0001
[2025-04-30 20:04:32,820][train][INFO] - Epoch 99/100, Val Acc=0.7433, Val Loss=1.3253, lr=0.0001
[2025-04-30 20:04:38,310][train][INFO] - Epoch 90/100, Val Acc=0.7369, Val Loss=1.3611, lr=0.0010
[2025-04-30 20:04:40,781][train][INFO] - Epoch 100/100, Val Acc=0.7413, Val Loss=1.3029, lr=0.0001
[2025-04-30 20:04:42,673][train][INFO] - Epoch 92/100, Val Acc=0.7400, Val Loss=1.3508, lr=0.0001
[2025-04-30 20:04:43,667][train][INFO] - Epoch 100/100, Val Acc=0.7420, Val Loss=1.3272, lr=0.0001
[2025-04-30 20:04:46,250][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7426
[2025-04-30 20:04:46,255][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:04:47,508][train][INFO] - Epoch 91/100, Val Acc=0.7372, Val Loss=1.3541, lr=0.0001
[2025-04-30 20:04:49,132][train][INFO] - After training : Train Acc=0.9994  Val Acc=0.7449
[2025-04-30 20:04:49,137][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:04:51,591][train][INFO] - Epoch 93/100, Val Acc=0.7402, Val Loss=1.3411, lr=0.0001
[2025-04-30 20:04:56,034][train][INFO] - Epoch 92/100, Val Acc=0.7365, Val Loss=1.3595, lr=0.0001
[2025-04-30 20:05:00,293][train][INFO] - Epoch 94/100, Val Acc=0.7405, Val Loss=1.3381, lr=0.0001
[2025-04-30 20:05:04,683][train][INFO] - Epoch 93/100, Val Acc=0.7367, Val Loss=1.3570, lr=0.0001
[2025-04-30 20:05:08,953][train][INFO] - Epoch 95/100, Val Acc=0.7397, Val Loss=1.3455, lr=0.0001
[2025-04-30 20:05:13,427][train][INFO] - Epoch 94/100, Val Acc=0.7376, Val Loss=1.3524, lr=0.0001
[2025-04-30 20:05:17,357][train][INFO] - Epoch 96/100, Val Acc=0.7403, Val Loss=1.3395, lr=0.0001
[2025-04-30 20:05:22,067][train][INFO] - Epoch 95/100, Val Acc=0.7374, Val Loss=1.3577, lr=0.0001
[2025-04-30 20:05:26,180][train][INFO] - Epoch 97/100, Val Acc=0.7394, Val Loss=1.3396, lr=0.0001
[2025-04-30 20:05:30,470][train][INFO] - Epoch 96/100, Val Acc=0.7371, Val Loss=1.3532, lr=0.0001
[2025-04-30 20:05:35,174][train][INFO] - Epoch 98/100, Val Acc=0.7406, Val Loss=1.3387, lr=0.0001
[2025-04-30 20:05:38,906][train][INFO] - Epoch 97/100, Val Acc=0.7383, Val Loss=1.3537, lr=0.0001
[2025-04-30 20:05:43,667][train][INFO] - Epoch 99/100, Val Acc=0.7395, Val Loss=1.3415, lr=0.0001
[2025-04-30 20:05:47,465][train][INFO] - Epoch 98/100, Val Acc=0.7383, Val Loss=1.3470, lr=0.0001
[2025-04-30 20:05:52,346][train][INFO] - Epoch 100/100, Val Acc=0.7406, Val Loss=1.3430, lr=0.0001
[2025-04-30 20:05:56,013][train][INFO] - Epoch 99/100, Val Acc=0.7371, Val Loss=1.3530, lr=0.0001
[2025-04-30 20:05:57,856][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7417
[2025-04-30 20:05:57,860][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:06:04,503][train][INFO] - Epoch 100/100, Val Acc=0.7380, Val Loss=1.3584, lr=0.0001
[2025-04-30 20:06:09,955][train][INFO] - After training : Train Acc=0.9987  Val Acc=0.7394
[2025-04-30 20:06:09,960][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:06:57,864][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:06:58,910][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:08:01,828][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:08:13,987][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:09:02,840][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:09:03,334][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:09:06,523][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:09:07,032][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:10:04,903][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:10:05,389][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:10:15,668][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:10:16,077][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:40:16,601][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Bob
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 20:40:16,694][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 20:40:46,668][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-30 20:40:55,087][train][INFO] - Epoch 1/100, Val Acc=0.6008, Val Loss=1.6908, lr=0.0100
[2025-04-30 20:41:03,056][train][INFO] - Epoch 2/100, Val Acc=0.6280, Val Loss=1.5495, lr=0.0100
[2025-04-30 20:41:11,465][train][INFO] - Epoch 3/100, Val Acc=0.6310, Val Loss=1.5558, lr=0.0100
[2025-04-30 20:41:19,865][train][INFO] - Epoch 4/100, Val Acc=0.6561, Val Loss=1.4704, lr=0.0100
[2025-04-30 20:41:27,769][train][INFO] - Epoch 5/100, Val Acc=0.6488, Val Loss=1.5299, lr=0.0100
[2025-04-30 20:41:35,519][train][INFO] - Epoch 6/100, Val Acc=0.6516, Val Loss=1.5412, lr=0.0100
[2025-04-30 20:41:43,695][train][INFO] - Epoch 7/100, Val Acc=0.6540, Val Loss=1.5415, lr=0.0100
[2025-04-30 20:41:51,794][train][INFO] - Epoch 8/100, Val Acc=0.6484, Val Loss=1.5928, lr=0.0100
[2025-04-30 20:42:00,336][train][INFO] - Epoch 9/100, Val Acc=0.6582, Val Loss=1.5039, lr=0.0100
[2025-04-30 20:42:07,854][train][INFO] - Epoch 10/100, Val Acc=0.6544, Val Loss=1.5478, lr=0.0100
[2025-04-30 20:42:15,271][train][INFO] - Epoch 11/100, Val Acc=0.6633, Val Loss=1.4638, lr=0.0100
[2025-04-30 20:42:23,551][train][INFO] - Epoch 12/100, Val Acc=0.6767, Val Loss=1.4260, lr=0.0100
[2025-04-30 20:42:31,231][train][INFO] - Epoch 13/100, Val Acc=0.6671, Val Loss=1.4978, lr=0.0100
[2025-04-30 20:42:38,989][train][INFO] - Epoch 14/100, Val Acc=0.6713, Val Loss=1.4731, lr=0.0100
[2025-04-30 20:42:47,175][train][INFO] - Epoch 15/100, Val Acc=0.6502, Val Loss=1.5949, lr=0.0100
[2025-04-30 20:42:55,887][train][INFO] - Epoch 16/100, Val Acc=0.6737, Val Loss=1.4793, lr=0.0100
[2025-04-30 20:43:03,902][train][INFO] - Epoch 17/100, Val Acc=0.6738, Val Loss=1.4928, lr=0.0100
[2025-04-30 20:43:11,434][train][INFO] - Epoch 18/100, Val Acc=0.6665, Val Loss=1.5940, lr=0.0100
[2025-04-30 20:43:19,765][train][INFO] - Epoch 19/100, Val Acc=0.6683, Val Loss=1.5374, lr=0.0100
[2025-04-30 20:43:27,623][train][INFO] - Epoch 20/100, Val Acc=0.6707, Val Loss=1.4998, lr=0.0100
[2025-04-30 20:43:35,967][train][INFO] - Epoch 21/100, Val Acc=0.6650, Val Loss=1.5393, lr=0.0100
[2025-04-30 20:43:44,226][train][INFO] - Epoch 22/100, Val Acc=0.6786, Val Loss=1.4794, lr=0.0100
[2025-04-30 20:43:51,899][train][INFO] - Epoch 23/100, Val Acc=0.6737, Val Loss=1.5060, lr=0.0100
[2025-04-30 20:44:00,169][train][INFO] - Epoch 24/100, Val Acc=0.6844, Val Loss=1.4798, lr=0.0100
[2025-04-30 20:44:08,126][train][INFO] - Epoch 25/100, Val Acc=0.6811, Val Loss=1.4937, lr=0.0100
[2025-04-30 20:44:08,350][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-04-30 20:44:08,413][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 20:44:08,414][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 20:44:08,414][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 20:44:16,564][train][INFO] - Epoch 26/100, Val Acc=0.6647, Val Loss=1.5741, lr=0.0100
[2025-04-30 20:44:25,254][train][INFO] - Epoch 27/100, Val Acc=0.6766, Val Loss=1.5215, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 20:44:34,023][train][INFO] - Epoch 28/100, Val Acc=0.6683, Val Loss=1.5497, lr=0.0100
[2025-04-30 20:44:42,485][train][INFO] - Epoch 29/100, Val Acc=0.6656, Val Loss=1.5849, lr=0.0100
[2025-04-30 20:44:50,651][train][INFO] - Epoch 30/100, Val Acc=0.6833, Val Loss=1.5007, lr=0.0100
[2025-04-30 20:44:52,686][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-04-30 20:44:58,917][train][INFO] - Epoch 31/100, Val Acc=0.6572, Val Loss=1.6534, lr=0.0100
[2025-04-30 20:45:07,627][train][INFO] - Epoch 32/100, Val Acc=0.6695, Val Loss=1.5699, lr=0.0100
[2025-04-30 20:45:15,924][train][INFO] - Epoch 33/100, Val Acc=0.6760, Val Loss=1.5226, lr=0.0100
[2025-04-30 20:45:24,438][train][INFO] - Epoch 34/100, Val Acc=0.6743, Val Loss=1.5793, lr=0.0100
[2025-04-30 20:45:31,840][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8075, lr=0.001
[2025-04-30 20:45:33,014][train][INFO] - Epoch 35/100, Val Acc=0.6789, Val Loss=1.5400, lr=0.0100
[2025-04-30 20:45:41,308][train][INFO] - Epoch 36/100, Val Acc=0.6560, Val Loss=1.6277, lr=0.0100
[2025-04-30 20:45:49,466][train][INFO] - Epoch 37/100, Val Acc=0.6732, Val Loss=1.5250, lr=0.0100
[2025-04-30 20:45:57,851][train][INFO] - Epoch 38/100, Val Acc=0.6858, Val Loss=1.5104, lr=0.0100
[2025-04-30 20:46:05,997][train][INFO] - Epoch 39/100, Val Acc=0.6702, Val Loss=1.6007, lr=0.0100
[2025-04-30 20:46:11,456][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6741, lr=0.001
[2025-04-30 20:46:14,744][train][INFO] - Epoch 40/100, Val Acc=0.6681, Val Loss=1.5600, lr=0.0100
[2025-04-30 20:46:22,777][train][INFO] - Epoch 41/100, Val Acc=0.6748, Val Loss=1.5214, lr=0.0100
[2025-04-30 20:46:31,023][train][INFO] - Epoch 42/100, Val Acc=0.6578, Val Loss=1.6024, lr=0.0100
[2025-04-30 20:46:39,376][train][INFO] - Epoch 43/100, Val Acc=0.6677, Val Loss=1.5765, lr=0.0100
[2025-04-30 20:46:47,254][train][INFO] - Epoch 44/100, Val Acc=0.6656, Val Loss=1.5911, lr=0.0100
[2025-04-30 20:46:49,509][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8369, lr=0.001
[2025-04-30 20:46:55,686][train][INFO] - Epoch 45/100, Val Acc=0.6734, Val Loss=1.5467, lr=0.0100
[2025-04-30 20:47:03,868][train][INFO] - Epoch 46/100, Val Acc=0.6634, Val Loss=1.6254, lr=0.0100
[2025-04-30 20:47:11,896][train][INFO] - Epoch 47/100, Val Acc=0.6675, Val Loss=1.5980, lr=0.0100
[2025-04-30 20:47:19,599][train][INFO] - Epoch 48/100, Val Acc=0.6718, Val Loss=1.5579, lr=0.0100
[2025-04-30 20:47:28,086][train][INFO] - Epoch 49/100, Val Acc=0.6791, Val Loss=1.5344, lr=0.0100
[2025-04-30 20:47:29,592][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.9273, lr=0.001
[2025-04-30 20:47:36,355][train][INFO] - Epoch 50/100, Val Acc=0.6710, Val Loss=1.5441, lr=0.0100
[2025-04-30 20:47:44,642][train][INFO] - Epoch 51/100, Val Acc=0.6763, Val Loss=1.5330, lr=0.0100
[2025-04-30 20:47:53,028][train][INFO] - Epoch 52/100, Val Acc=0.6803, Val Loss=1.5280, lr=0.0100
[2025-04-30 20:48:01,327][train][INFO] - Epoch 53/100, Val Acc=0.6780, Val Loss=1.5191, lr=0.0100
[2025-04-30 20:48:08,867][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9680, lr=0.001
[2025-04-30 20:48:08,951][train][INFO] - Epoch 54/100, Val Acc=0.6718, Val Loss=1.5647, lr=0.0100
[2025-04-30 20:48:17,634][train][INFO] - Epoch 55/100, Val Acc=0.6631, Val Loss=1.6259, lr=0.0100
[2025-04-30 20:48:25,867][train][INFO] - Epoch 56/100, Val Acc=0.6808, Val Loss=1.4870, lr=0.0100
[2025-04-30 20:48:33,927][train][INFO] - Epoch 57/100, Val Acc=0.6766, Val Loss=1.5601, lr=0.0100
[2025-04-30 20:48:41,630][train][INFO] - Epoch 58/100, Val Acc=0.6689, Val Loss=1.5775, lr=0.0100
[2025-04-30 20:48:48,841][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.8066, lr=0.001
[2025-04-30 20:48:49,761][train][INFO] - Epoch 59/100, Val Acc=0.6832, Val Loss=1.5500, lr=0.0100
[2025-04-30 20:48:57,786][train][INFO] - Epoch 60/100, Val Acc=0.6741, Val Loss=1.5722, lr=0.0100
[2025-04-30 20:49:06,115][train][INFO] - Epoch 61/100, Val Acc=0.7277, Val Loss=1.3040, lr=0.0010
[2025-04-30 20:49:14,154][train][INFO] - Epoch 62/100, Val Acc=0.7306, Val Loss=1.2980, lr=0.0010
[2025-04-30 20:49:22,677][train][INFO] - Epoch 63/100, Val Acc=0.7328, Val Loss=1.3065, lr=0.0010
[2025-04-30 20:49:27,729][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.5005, lr=0.001
[2025-04-30 20:49:27,751][meta_train][INFO] - epoch_1 saved !
[2025-04-30 20:49:30,882][train][INFO] - Epoch 64/100, Val Acc=0.7362, Val Loss=1.3068, lr=0.0010
[2025-04-30 20:49:39,182][train][INFO] - Epoch 65/100, Val Acc=0.7373, Val Loss=1.3042, lr=0.0010
[2025-04-30 20:49:47,713][train][INFO] - Epoch 66/100, Val Acc=0.7355, Val Loss=1.3189, lr=0.0010
[2025-04-30 20:49:56,244][train][INFO] - Epoch 67/100, Val Acc=0.7380, Val Loss=1.3127, lr=0.0010
[2025-04-30 20:50:04,200][train][INFO] - Epoch 68/100, Val Acc=0.7380, Val Loss=1.3153, lr=0.0010
[2025-04-30 20:50:08,295][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.4438, lr=0.001
[2025-04-30 20:50:12,539][train][INFO] - Epoch 69/100, Val Acc=0.7351, Val Loss=1.3248, lr=0.0010
[2025-04-30 20:50:20,355][train][INFO] - Epoch 70/100, Val Acc=0.7343, Val Loss=1.3296, lr=0.0010
[2025-04-30 20:50:28,277][train][INFO] - Epoch 71/100, Val Acc=0.7381, Val Loss=1.3319, lr=0.0010
[2025-04-30 20:50:36,275][train][INFO] - Epoch 72/100, Val Acc=0.7382, Val Loss=1.3245, lr=0.0010
[2025-04-30 20:50:44,500][train][INFO] - Epoch 73/100, Val Acc=0.7394, Val Loss=1.3229, lr=0.0010
[2025-04-30 20:50:46,296][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1417, lr=0.001
[2025-04-30 20:50:52,437][train][INFO] - Epoch 74/100, Val Acc=0.7400, Val Loss=1.3177, lr=0.0010
[2025-04-30 20:51:00,912][train][INFO] - Epoch 75/100, Val Acc=0.7401, Val Loss=1.3270, lr=0.0010
[2025-04-30 20:51:08,641][train][INFO] - Epoch 76/100, Val Acc=0.7411, Val Loss=1.3264, lr=0.0010
[2025-04-30 20:51:17,107][train][INFO] - Epoch 77/100, Val Acc=0.7385, Val Loss=1.3250, lr=0.0010
[2025-04-30 20:51:24,888][train][INFO] - Epoch 78/100, Val Acc=0.7416, Val Loss=1.3307, lr=0.0010
[2025-04-30 20:51:25,724][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1675, lr=0.001
[2025-04-30 20:51:33,661][train][INFO] - Epoch 79/100, Val Acc=0.7411, Val Loss=1.3325, lr=0.0010
[2025-04-30 20:51:41,592][train][INFO] - Epoch 80/100, Val Acc=0.7424, Val Loss=1.3303, lr=0.0010
[2025-04-30 20:51:50,056][train][INFO] - Epoch 81/100, Val Acc=0.7394, Val Loss=1.3352, lr=0.0010
[2025-04-30 20:51:57,964][train][INFO] - Epoch 82/100, Val Acc=0.7377, Val Loss=1.3342, lr=0.0010
[2025-04-30 20:52:05,828][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.3302, lr=0.001
[2025-04-30 20:52:06,005][train][INFO] - Epoch 83/100, Val Acc=0.7405, Val Loss=1.3422, lr=0.0010
[2025-04-30 20:52:14,322][train][INFO] - Epoch 84/100, Val Acc=0.7396, Val Loss=1.3327, lr=0.0010
[2025-04-30 20:52:22,746][train][INFO] - Epoch 85/100, Val Acc=0.7424, Val Loss=1.3292, lr=0.0010
[2025-04-30 20:52:31,083][train][INFO] - Epoch 86/100, Val Acc=0.7412, Val Loss=1.3272, lr=0.0010
[2025-04-30 20:52:39,671][train][INFO] - Epoch 87/100, Val Acc=0.7422, Val Loss=1.3179, lr=0.0010
[2025-04-30 20:52:46,256][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.1109, lr=0.001
[2025-04-30 20:52:47,654][train][INFO] - Epoch 88/100, Val Acc=0.7417, Val Loss=1.3275, lr=0.0010
[2025-04-30 20:52:56,368][train][INFO] - Epoch 89/100, Val Acc=0.7419, Val Loss=1.3270, lr=0.0010
[2025-04-30 20:53:05,036][train][INFO] - Epoch 90/100, Val Acc=0.7409, Val Loss=1.3380, lr=0.0010
[2025-04-30 20:53:16,193][train][INFO] - Epoch 91/100, Val Acc=0.7401, Val Loss=1.3301, lr=0.0001
[2025-04-30 20:53:24,766][train][INFO] - Epoch 92/100, Val Acc=0.7394, Val Loss=1.3337, lr=0.0001
[2025-04-30 20:53:30,631][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0965, lr=0.001
[2025-04-30 20:53:33,346][train][INFO] - Epoch 93/100, Val Acc=0.7414, Val Loss=1.3288, lr=0.0001
[2025-04-30 20:53:41,499][train][INFO] - Epoch 94/100, Val Acc=0.7398, Val Loss=1.3258, lr=0.0001
[2025-04-30 20:53:49,668][train][INFO] - Epoch 95/100, Val Acc=0.7399, Val Loss=1.3325, lr=0.0001
[2025-04-30 20:53:57,935][train][INFO] - Epoch 96/100, Val Acc=0.7409, Val Loss=1.3278, lr=0.0001
[2025-04-30 20:54:06,034][train][INFO] - Epoch 97/100, Val Acc=0.7403, Val Loss=1.3262, lr=0.0001
[2025-04-30 20:54:11,022][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0886, lr=0.001
[2025-04-30 20:54:14,633][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3242, lr=0.0001
[2025-04-30 20:54:22,833][train][INFO] - Epoch 99/100, Val Acc=0.7412, Val Loss=1.3287, lr=0.0001
[2025-04-30 20:54:30,904][train][INFO] - Epoch 100/100, Val Acc=0.7423, Val Loss=1.3297, lr=0.0001
[2025-04-30 20:54:36,158][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.7424
[2025-04-30 20:54:36,163][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 20:54:51,086][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0734, lr=0.001
[2025-04-30 20:54:51,109][meta_train][INFO] - epoch_2 saved !
[2025-04-30 20:55:31,014][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1057, lr=0.001
[2025-04-30 20:56:11,233][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0991, lr=0.001
[2025-04-30 20:56:28,091][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 20:56:51,483][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0990, lr=0.001
[2025-04-30 20:57:30,559][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.1238, lr=0.001
[2025-04-30 20:58:11,700][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2640, lr=0.001
[2025-04-30 20:58:24,231][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 20:58:24,680][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 20:58:51,571][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2490, lr=0.001
[2025-04-30 20:59:30,311][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1372, lr=0.001
[2025-04-30 21:00:08,295][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1343, lr=0.001
[2025-04-30 21:00:08,316][meta_train][INFO] - epoch_3 saved !
[2025-04-30 21:00:46,546][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1629, lr=0.001
[2025-04-30 21:01:24,399][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1719, lr=0.001
[2025-04-30 21:02:03,433][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.3283, lr=0.001
[2025-04-30 21:02:41,447][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1797, lr=0.001
[2025-04-30 21:03:21,772][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1811, lr=0.001
[2025-04-30 21:03:58,480][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.3008, lr=0.001
[2025-04-30 21:04:36,786][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.5628, lr=0.001
[2025-04-30 21:05:14,432][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.3116, lr=0.001
[2025-04-30 21:05:14,441][meta_train][INFO] - epoch_4 saved !
[2025-04-30 21:05:52,985][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.5154, lr=0.001
[2025-04-30 21:06:31,803][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.3117, lr=0.001
[2025-04-30 21:07:10,959][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.4938, lr=0.001
[2025-04-30 21:07:48,683][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.4834, lr=0.001
[2025-04-30 21:08:27,474][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=1.2287, lr=0.001
[2025-04-30 21:09:05,301][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.6893, lr=0.001
[2025-04-30 21:09:43,448][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.7877, lr=0.001
[2025-04-30 21:10:21,634][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.8715, lr=0.001
[2025-04-30 21:10:21,648][meta_train][INFO] - epoch_5 saved !
[2025-04-30 21:10:59,176][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=1.8127, lr=0.001
[2025-04-30 21:11:38,447][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.6902, lr=0.001
[2025-04-30 21:12:15,652][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.9215, lr=0.001
[2025-04-30 21:13:03,770][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=1.0674, lr=0.001
[2025-04-30 21:13:45,198][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.7868, lr=0.001
[2025-04-30 21:14:40,225][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.9430, lr=0.001
[2025-04-30 21:15:19,054][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.9299, lr=0.001
[2025-04-30 21:15:58,898][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.9080, lr=0.001
[2025-04-30 21:15:58,910][meta_train][INFO] - epoch_6 saved !
[2025-04-30 21:16:55,996][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=1.1020, lr=0.001
[2025-04-30 21:17:43,345][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=1.6334, lr=0.001
[2025-04-30 21:18:22,371][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.8662, lr=0.001
[2025-04-30 21:19:00,437][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.9092, lr=0.001
[2025-04-30 21:19:38,168][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.8017, lr=0.001
[2025-04-30 21:20:38,265][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.6183, lr=0.001
[2025-04-30 21:21:18,713][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.7119, lr=0.001
[2025-04-30 21:21:55,066][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.7736, lr=0.001
[2025-04-30 21:21:55,086][meta_train][INFO] - epoch_7 saved !
[2025-04-30 21:22:32,126][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.7121, lr=0.001
[2025-04-30 21:23:08,711][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.7541, lr=0.001
[2025-04-30 21:23:46,211][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.7021, lr=0.001
[2025-04-30 21:24:23,743][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.9933, lr=0.001
[2025-04-30 21:25:21,122][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.6385, lr=0.001
[2025-04-30 21:26:00,082][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.4881, lr=0.001
[2025-04-30 21:26:36,243][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.7350, lr=0.001
[2025-04-30 21:27:14,299][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.7782, lr=0.001
[2025-04-30 21:27:14,308][meta_train][INFO] - epoch_8 saved !
[2025-04-30 21:27:50,793][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.4159, lr=0.001
[2025-04-30 21:28:29,127][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.4579, lr=0.001
[2025-04-30 21:29:25,371][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.3927, lr=0.001
[2025-04-30 21:30:06,737][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.6602, lr=0.001
[2025-04-30 21:30:43,768][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.8224, lr=0.001
[2025-04-30 21:31:20,943][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.6428, lr=0.001
[2025-04-30 21:31:59,684][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.3779, lr=0.001
[2025-04-30 21:32:37,273][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2917, lr=0.001
[2025-04-30 21:32:37,294][meta_train][INFO] - epoch_9 saved !
[2025-04-30 21:33:13,705][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.4356, lr=0.001
[2025-04-30 21:33:51,935][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3741, lr=0.001
[2025-04-30 21:34:41,521][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4572, lr=0.001
[2025-04-30 21:35:32,887][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.9516, lr=0.001
[2025-04-30 21:36:23,386][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6981, lr=0.001
[2025-04-30 21:37:12,352][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.2309, lr=0.001
[2025-04-30 21:38:02,150][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.9478, lr=0.001
[2025-04-30 21:38:54,485][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.7329, lr=0.001
[2025-04-30 21:38:54,495][meta_train][INFO] - epoch_10 saved !
[2025-04-30 21:39:42,920][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=1.1060, lr=0.0001
[2025-04-30 21:40:31,035][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.9030, lr=0.0001
[2025-04-30 21:41:21,692][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.9823, lr=0.0001
[2025-04-30 21:42:07,612][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=1.2461, lr=0.0001
[2025-04-30 21:42:44,430][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.6248, lr=0.0001
[2025-04-30 21:43:21,728][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.7268, lr=0.0001
[2025-04-30 21:43:57,546][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=1.0589, lr=0.0001
[2025-04-30 21:44:35,493][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=1.3359, lr=0.0001
[2025-04-30 21:44:35,512][meta_train][INFO] - epoch_11 saved !
[2025-04-30 21:45:13,082][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=1.2428, lr=0.0001
[2025-04-30 21:45:50,803][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=1.1057, lr=0.0001
[2025-04-30 21:46:28,253][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=1.3831, lr=0.0001
[2025-04-30 21:47:06,318][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=2.0841, lr=0.0001
[2025-04-30 21:47:43,466][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=1.8544, lr=0.0001
[2025-04-30 21:48:21,288][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=1.1657, lr=0.0001
[2025-04-30 21:48:59,963][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=1.8345, lr=0.0001
[2025-04-30 21:49:37,207][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=1.5007, lr=0.0001
[2025-04-30 21:49:37,217][meta_train][INFO] - epoch_12 saved !
[2025-04-30 21:50:14,702][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=1.3949, lr=0.0001
[2025-04-30 21:50:53,406][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=1.9088, lr=0.0001
[2025-04-30 21:51:31,746][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=1.5644, lr=0.0001
[2025-04-30 21:52:15,432][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=1.2839, lr=0.0001
[2025-04-30 21:52:53,544][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=2.2665, lr=0.0001
[2025-04-30 21:53:30,614][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=1.6399, lr=0.0001
[2025-04-30 21:54:08,313][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=2.0529, lr=0.0001
[2025-04-30 21:54:45,469][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=1.3820, lr=0.0001
[2025-04-30 21:54:45,496][meta_train][INFO] - epoch_13 saved !
[2025-04-30 21:55:24,091][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=1.6981, lr=0.0001
[2025-04-30 21:56:02,937][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=1.3830, lr=0.0001
[2025-04-30 21:56:41,178][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=2.3760, lr=0.0001
[2025-04-30 21:57:17,580][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=2.1443, lr=0.0001
[2025-04-30 21:57:56,086][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=2.1555, lr=0.0001
[2025-04-30 21:58:34,160][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=1.7966, lr=0.0001
[2025-04-30 21:59:10,716][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=1.6958, lr=0.0001
[2025-04-30 21:59:48,825][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=1.4991, lr=0.0001
[2025-04-30 21:59:48,845][meta_train][INFO] - epoch_14 saved !
[2025-04-30 22:00:27,778][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=2.2257, lr=0.0001
[2025-04-30 22:01:05,914][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=2.2507, lr=0.0001
[2025-04-30 22:01:42,396][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=1.7606, lr=0.0001
[2025-04-30 22:02:16,467][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 22:02:16,522][get_dataset_model_loader][INFO] - ==================================================
[2025-04-30 22:02:20,719][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=2.5329, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 22:02:45,790][train][INFO] - Before training : Train Acc=0.7916  Val Acc=0.6116
[2025-04-30 22:02:53,835][train][INFO] - Epoch 1/100, Val Acc=0.6423, Val Loss=1.6432, lr=0.0100
[2025-04-30 22:02:59,626][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=1.9086, lr=0.0001
[2025-04-30 22:03:01,891][train][INFO] - Epoch 2/100, Val Acc=0.6516, Val Loss=1.6468, lr=0.0100
[2025-04-30 22:03:10,446][train][INFO] - Epoch 3/100, Val Acc=0.6514, Val Loss=1.6231, lr=0.0100
[2025-04-30 22:03:18,972][train][INFO] - Epoch 4/100, Val Acc=0.6649, Val Loss=1.5312, lr=0.0100
[2025-04-30 22:03:27,497][train][INFO] - Epoch 5/100, Val Acc=0.6789, Val Loss=1.4667, lr=0.0100
[2025-04-30 22:03:35,426][train][INFO] - Epoch 6/100, Val Acc=0.6661, Val Loss=1.5437, lr=0.0100
[2025-04-30 22:03:39,201][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=1.5390, lr=0.0001
[2025-04-30 22:03:43,117][train][INFO] - Epoch 7/100, Val Acc=0.6648, Val Loss=1.5033, lr=0.0100
[2025-04-30 22:03:51,410][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5341, lr=0.0100
[2025-04-30 22:03:59,396][train][INFO] - Epoch 9/100, Val Acc=0.6646, Val Loss=1.5601, lr=0.0100
[2025-04-30 22:04:07,694][train][INFO] - Epoch 10/100, Val Acc=0.6560, Val Loss=1.5789, lr=0.0100
[2025-04-30 22:04:15,776][train][INFO] - Epoch 11/100, Val Acc=0.6645, Val Loss=1.5595, lr=0.0100
[2025-04-30 22:04:18,201][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=1.9428, lr=0.0001
[2025-04-30 22:04:23,863][train][INFO] - Epoch 12/100, Val Acc=0.6740, Val Loss=1.5203, lr=0.0100
[2025-04-30 22:04:32,193][train][INFO] - Epoch 13/100, Val Acc=0.6641, Val Loss=1.5862, lr=0.0100
[2025-04-30 22:04:40,671][train][INFO] - Epoch 14/100, Val Acc=0.6617, Val Loss=1.5857, lr=0.0100
[2025-04-30 22:04:48,542][train][INFO] - Epoch 15/100, Val Acc=0.6675, Val Loss=1.5226, lr=0.0100
[2025-04-30 22:04:56,505][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=1.5976, lr=0.0001
[2025-04-30 22:04:56,516][meta_train][INFO] - epoch_15 saved !
[2025-04-30 22:04:56,669][train][INFO] - Epoch 16/100, Val Acc=0.6681, Val Loss=1.5377, lr=0.0100
[2025-04-30 22:05:05,238][train][INFO] - Epoch 17/100, Val Acc=0.6687, Val Loss=1.5164, lr=0.0100
[2025-04-30 22:05:13,407][train][INFO] - Epoch 18/100, Val Acc=0.6638, Val Loss=1.6137, lr=0.0100
[2025-04-30 22:05:21,581][train][INFO] - Epoch 19/100, Val Acc=0.6579, Val Loss=1.6279, lr=0.0100
[2025-04-30 22:05:29,692][train][INFO] - Epoch 20/100, Val Acc=0.6718, Val Loss=1.5851, lr=0.0100
[2025-04-30 22:05:35,356][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=2.3653, lr=0.0001
[2025-04-30 22:05:38,720][train][INFO] - Epoch 21/100, Val Acc=0.6696, Val Loss=1.5603, lr=0.0100
[2025-04-30 22:05:46,746][train][INFO] - Epoch 22/100, Val Acc=0.6536, Val Loss=1.6013, lr=0.0100
[2025-04-30 22:05:53,936][train][INFO] - Epoch 23/100, Val Acc=0.6776, Val Loss=1.5387, lr=0.0100
[2025-04-30 22:06:02,212][train][INFO] - Epoch 24/100, Val Acc=0.6608, Val Loss=1.5980, lr=0.0100
[2025-04-30 22:06:10,326][train][INFO] - Epoch 25/100, Val Acc=0.6729, Val Loss=1.5540, lr=0.0100
[2025-04-30 22:06:15,195][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=1.5878, lr=0.0001
[2025-04-30 22:06:18,976][train][INFO] - Epoch 26/100, Val Acc=0.6605, Val Loss=1.6308, lr=0.0100
[2025-04-30 22:06:27,443][train][INFO] - Epoch 27/100, Val Acc=0.6864, Val Loss=1.4884, lr=0.0100
[2025-04-30 22:06:35,850][train][INFO] - Epoch 28/100, Val Acc=0.6545, Val Loss=1.6285, lr=0.0100
[2025-04-30 22:06:43,660][train][INFO] - Epoch 29/100, Val Acc=0.6636, Val Loss=1.5949, lr=0.0100
[2025-04-30 22:06:51,622][train][INFO] - Epoch 30/100, Val Acc=0.6632, Val Loss=1.6235, lr=0.0100
[2025-04-30 22:06:54,454][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=2.0145, lr=0.0001
[2025-04-30 22:06:59,393][train][INFO] - Epoch 31/100, Val Acc=0.6698, Val Loss=1.5338, lr=0.0100
[2025-04-30 22:07:07,515][train][INFO] - Epoch 32/100, Val Acc=0.6559, Val Loss=1.6391, lr=0.0100
[2025-04-30 22:07:16,021][train][INFO] - Epoch 33/100, Val Acc=0.6751, Val Loss=1.5349, lr=0.0100
[2025-04-30 22:07:24,335][train][INFO] - Epoch 34/100, Val Acc=0.6788, Val Loss=1.5122, lr=0.0100
[2025-04-30 22:07:32,257][train][INFO] - Epoch 35/100, Val Acc=0.6702, Val Loss=1.5731, lr=0.0100
[2025-04-30 22:07:33,985][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=1.6378, lr=0.0001
[2025-04-30 22:07:40,524][train][INFO] - Epoch 36/100, Val Acc=0.6634, Val Loss=1.6012, lr=0.0100
[2025-04-30 22:07:48,680][train][INFO] - Epoch 37/100, Val Acc=0.6648, Val Loss=1.6184, lr=0.0100
[2025-04-30 22:07:56,843][train][INFO] - Epoch 38/100, Val Acc=0.6628, Val Loss=1.6328, lr=0.0100
[2025-04-30 22:08:05,034][train][INFO] - Epoch 39/100, Val Acc=0.6668, Val Loss=1.6058, lr=0.0100
[2025-04-30 22:08:11,744][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=1.9337, lr=0.0001
[2025-04-30 22:08:13,018][train][INFO] - Epoch 40/100, Val Acc=0.6745, Val Loss=1.5423, lr=0.0100
[2025-04-30 22:08:21,360][train][INFO] - Epoch 41/100, Val Acc=0.6711, Val Loss=1.5339, lr=0.0100
[2025-04-30 22:08:29,790][train][INFO] - Epoch 42/100, Val Acc=0.6663, Val Loss=1.6022, lr=0.0100
[2025-04-30 22:08:38,129][train][INFO] - Epoch 43/100, Val Acc=0.6762, Val Loss=1.5198, lr=0.0100
[2025-04-30 22:08:46,649][train][INFO] - Epoch 44/100, Val Acc=0.6648, Val Loss=1.6261, lr=0.0100
[2025-04-30 22:08:51,330][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=2.6882, lr=0.0001
[2025-04-30 22:08:55,037][train][INFO] - Epoch 45/100, Val Acc=0.6786, Val Loss=1.5580, lr=0.0100
[2025-04-30 22:09:03,810][train][INFO] - Epoch 46/100, Val Acc=0.6708, Val Loss=1.6132, lr=0.0100
[2025-04-30 22:09:11,929][train][INFO] - Epoch 47/100, Val Acc=0.6725, Val Loss=1.5791, lr=0.0100
[2025-04-30 22:09:20,252][train][INFO] - Epoch 48/100, Val Acc=0.6655, Val Loss=1.6137, lr=0.0100
[2025-04-30 22:09:28,259][train][INFO] - Epoch 49/100, Val Acc=0.6688, Val Loss=1.5985, lr=0.0100
[2025-04-30 22:09:30,674][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=2.0494, lr=0.0001
[2025-04-30 22:09:36,432][train][INFO] - Epoch 50/100, Val Acc=0.6624, Val Loss=1.6367, lr=0.0100
[2025-04-30 22:09:44,854][train][INFO] - Epoch 51/100, Val Acc=0.6722, Val Loss=1.5688, lr=0.0100
[2025-04-30 22:09:53,004][train][INFO] - Epoch 52/100, Val Acc=0.6678, Val Loss=1.5832, lr=0.0100
[2025-04-30 22:10:00,985][train][INFO] - Epoch 53/100, Val Acc=0.6641, Val Loss=1.6481, lr=0.0100
[2025-04-30 22:10:09,183][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=2.4689, lr=0.0001
[2025-04-30 22:10:09,199][meta_train][INFO] - epoch_16 saved !
[2025-04-30 22:10:09,424][train][INFO] - Epoch 54/100, Val Acc=0.6710, Val Loss=1.5373, lr=0.0100
[2025-04-30 22:10:17,588][train][INFO] - Epoch 55/100, Val Acc=0.6697, Val Loss=1.5626, lr=0.0100
[2025-04-30 22:10:25,029][train][INFO] - Epoch 56/100, Val Acc=0.6716, Val Loss=1.5836, lr=0.0100
[2025-04-30 22:10:33,252][train][INFO] - Epoch 57/100, Val Acc=0.6701, Val Loss=1.6161, lr=0.0100
[2025-04-30 22:10:41,536][train][INFO] - Epoch 58/100, Val Acc=0.6714, Val Loss=1.5685, lr=0.0100
[2025-04-30 22:10:48,127][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=2.4643, lr=0.0001
[2025-04-30 22:10:49,809][train][INFO] - Epoch 59/100, Val Acc=0.6636, Val Loss=1.6183, lr=0.0100
[2025-04-30 22:10:58,542][train][INFO] - Epoch 60/100, Val Acc=0.6739, Val Loss=1.5401, lr=0.0100
[2025-04-30 22:11:07,531][train][INFO] - Epoch 61/100, Val Acc=0.7227, Val Loss=1.3092, lr=0.0010
[2025-04-30 22:11:15,328][train][INFO] - Epoch 62/100, Val Acc=0.7267, Val Loss=1.3079, lr=0.0010
[2025-04-30 22:11:23,901][train][INFO] - Epoch 63/100, Val Acc=0.7278, Val Loss=1.3145, lr=0.0010
[2025-04-30 22:11:26,610][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=2.7424, lr=0.0001
[2025-04-30 22:11:32,078][train][INFO] - Epoch 64/100, Val Acc=0.7286, Val Loss=1.3243, lr=0.0010
[2025-04-30 22:11:40,315][train][INFO] - Epoch 65/100, Val Acc=0.7293, Val Loss=1.3179, lr=0.0010
[2025-04-30 22:11:48,122][train][INFO] - Epoch 66/100, Val Acc=0.7310, Val Loss=1.3229, lr=0.0010
[2025-04-30 22:11:56,042][train][INFO] - Epoch 67/100, Val Acc=0.7324, Val Loss=1.3254, lr=0.0010
[2025-04-30 22:12:04,422][train][INFO] - Epoch 68/100, Val Acc=0.7332, Val Loss=1.3246, lr=0.0010
[2025-04-30 22:12:05,331][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=2.5212, lr=0.0001
[2025-04-30 22:12:12,618][train][INFO] - Epoch 69/100, Val Acc=0.7305, Val Loss=1.3291, lr=0.0010
[2025-04-30 22:12:21,116][train][INFO] - Epoch 70/100, Val Acc=0.7291, Val Loss=1.3385, lr=0.0010
[2025-04-30 22:12:29,416][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.3379, lr=0.0010
[2025-04-30 22:12:37,827][train][INFO] - Epoch 72/100, Val Acc=0.7330, Val Loss=1.3368, lr=0.0010
[2025-04-30 22:12:43,037][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=2.0430, lr=0.0001
[2025-04-30 22:12:46,230][train][INFO] - Epoch 73/100, Val Acc=0.7341, Val Loss=1.3314, lr=0.0010
[2025-04-30 22:12:54,894][train][INFO] - Epoch 74/100, Val Acc=0.7358, Val Loss=1.3293, lr=0.0010
[2025-04-30 22:13:03,091][train][INFO] - Epoch 75/100, Val Acc=0.7350, Val Loss=1.3311, lr=0.0010
[2025-04-30 22:13:11,515][train][INFO] - Epoch 76/100, Val Acc=0.7347, Val Loss=1.3243, lr=0.0010
[2025-04-30 22:13:19,728][train][INFO] - Epoch 77/100, Val Acc=0.7366, Val Loss=1.3282, lr=0.0010
[2025-04-30 22:13:22,982][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=2.1434, lr=0.0001
[2025-04-30 22:13:28,567][train][INFO] - Epoch 78/100, Val Acc=0.7362, Val Loss=1.3274, lr=0.0010
[2025-04-30 22:13:36,836][train][INFO] - Epoch 79/100, Val Acc=0.7360, Val Loss=1.3253, lr=0.0010
[2025-04-30 22:13:44,873][train][INFO] - Epoch 80/100, Val Acc=0.7382, Val Loss=1.3298, lr=0.0010
[2025-04-30 22:13:52,753][train][INFO] - Epoch 81/100, Val Acc=0.7379, Val Loss=1.3310, lr=0.0010
[2025-04-30 22:14:00,655][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=1.7180, lr=0.0001
[2025-04-30 22:14:00,732][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3310, lr=0.0010
[2025-04-30 22:14:09,015][train][INFO] - Epoch 83/100, Val Acc=0.7372, Val Loss=1.3320, lr=0.0010
[2025-04-30 22:14:17,637][train][INFO] - Epoch 84/100, Val Acc=0.7363, Val Loss=1.3307, lr=0.0010
[2025-04-30 22:14:25,878][train][INFO] - Epoch 85/100, Val Acc=0.7379, Val Loss=1.3311, lr=0.0010
[2025-04-30 22:14:32,703][train][INFO] - Epoch 86/100, Val Acc=0.7350, Val Loss=1.3324, lr=0.0010
[2025-04-30 22:14:40,878][train][INFO] - Epoch 87/100, Val Acc=0.7367, Val Loss=1.3295, lr=0.0010
[2025-04-30 22:14:40,950][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=2.1884, lr=0.0001
[2025-04-30 22:14:49,506][train][INFO] - Epoch 88/100, Val Acc=0.7371, Val Loss=1.3363, lr=0.0010
[2025-04-30 22:14:57,924][train][INFO] - Epoch 89/100, Val Acc=0.7389, Val Loss=1.3295, lr=0.0010
[2025-04-30 22:15:05,718][train][INFO] - Epoch 90/100, Val Acc=0.7389, Val Loss=1.3375, lr=0.0010
[2025-04-30 22:15:13,887][train][INFO] - Epoch 91/100, Val Acc=0.7395, Val Loss=1.3301, lr=0.0001
[2025-04-30 22:15:18,894][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=1.7648, lr=0.0001
[2025-04-30 22:15:18,914][meta_train][INFO] - epoch_17 saved !
[2025-04-30 22:15:22,203][train][INFO] - Epoch 92/100, Val Acc=0.7367, Val Loss=1.3357, lr=0.0001
[2025-04-30 22:15:30,651][train][INFO] - Epoch 93/100, Val Acc=0.7368, Val Loss=1.3348, lr=0.0001
[2025-04-30 22:15:38,852][train][INFO] - Epoch 94/100, Val Acc=0.7389, Val Loss=1.3268, lr=0.0001
[2025-04-30 22:15:47,473][train][INFO] - Epoch 95/100, Val Acc=0.7395, Val Loss=1.3379, lr=0.0001
[2025-04-30 22:15:55,655][train][INFO] - Epoch 96/100, Val Acc=0.7397, Val Loss=1.3308, lr=0.0001
[2025-04-30 22:15:58,639][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=1.7716, lr=0.0001
[2025-04-30 22:16:04,185][train][INFO] - Epoch 97/100, Val Acc=0.7399, Val Loss=1.3239, lr=0.0001
[2025-04-30 22:16:12,484][train][INFO] - Epoch 98/100, Val Acc=0.7407, Val Loss=1.3273, lr=0.0001
[2025-04-30 22:16:20,723][train][INFO] - Epoch 99/100, Val Acc=0.7391, Val Loss=1.3273, lr=0.0001
[2025-04-30 22:16:29,073][train][INFO] - Epoch 100/100, Val Acc=0.7392, Val Loss=1.3307, lr=0.0001
[2025-04-30 22:16:34,024][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7407
[2025-04-30 22:16:34,031][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 22:16:36,528][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=2.8563, lr=0.0001
[2025-04-30 22:17:16,988][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=1.7618, lr=0.0001
[2025-04-30 22:17:57,976][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=2.6194, lr=0.0001
[2025-04-30 22:18:24,048][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 22:18:37,570][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=2.2657, lr=0.0001
[2025-04-30 22:19:17,937][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=2.6861, lr=0.0001
[2025-04-30 22:19:57,125][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=2.2899, lr=0.0001
[2025-04-30 22:20:14,387][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 22:20:14,828][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 22:20:37,085][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=2.2280, lr=0.0001
[2025-04-30 22:20:37,107][meta_train][INFO] - epoch_18 saved !
[2025-04-30 22:21:15,213][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=1.8825, lr=0.0001
[2025-04-30 22:21:52,331][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=2.7307, lr=0.0001
[2025-04-30 22:22:30,460][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=2.2762, lr=0.0001
[2025-04-30 22:23:07,891][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=2.7910, lr=0.0001
[2025-04-30 22:23:46,104][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=3.0247, lr=0.0001
[2025-04-30 22:24:25,312][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=2.4246, lr=0.0001
[2025-04-30 22:25:03,402][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=1.9552, lr=0.0001
[2025-04-30 22:25:40,485][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=2.4476, lr=0.0001
[2025-04-30 22:25:40,507][meta_train][INFO] - epoch_19 saved !
[2025-04-30 22:26:19,514][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=2.4873, lr=0.0001
[2025-04-30 22:26:57,828][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=2.4835, lr=0.0001
[2025-04-30 22:27:36,199][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=2.8882, lr=0.0001
[2025-04-30 22:28:13,999][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=2.0693, lr=0.0001
[2025-04-30 22:28:52,093][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=2.9491, lr=0.0001
[2025-04-30 22:29:30,153][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=3.1687, lr=0.0001
[2025-04-30 22:30:07,358][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=2.4978, lr=0.0001
[2025-04-30 22:30:46,052][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=2.1164, lr=0.0001
[2025-04-30 22:30:46,061][meta_train][INFO] - epoch_20 saved !
[2025-04-30 22:31:24,361][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=2.5395, lr=0.0001
[2025-04-30 22:32:02,790][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=2.1780, lr=0.0001
[2025-04-30 22:32:40,900][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=2.6431, lr=0.0001
[2025-04-30 22:33:19,957][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=3.2618, lr=0.0001
[2025-04-30 22:33:58,168][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=2.7016, lr=0.0001
[2025-04-30 22:34:35,440][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=3.1042, lr=0.0001
[2025-04-30 22:35:13,838][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=3.1024, lr=0.0001
[2025-04-30 22:35:51,907][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=2.2857, lr=0.0001
[2025-04-30 22:35:51,927][meta_train][INFO] - epoch_21 saved !
[2025-04-30 22:36:30,085][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=2.3220, lr=0.0001
[2025-04-30 22:37:07,387][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=2.8192, lr=0.0001
[2025-04-30 22:37:46,167][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=3.2101, lr=0.0001
[2025-04-30 22:38:24,405][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=3.4140, lr=0.0001
[2025-04-30 22:39:02,326][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=3.2548, lr=0.0001
[2025-04-30 22:39:39,678][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=2.8175, lr=0.0001
[2025-04-30 22:40:18,379][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=2.4889, lr=0.0001
[2025-04-30 22:40:55,586][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=2.9409, lr=0.0001
[2025-04-30 22:40:55,602][meta_train][INFO] - epoch_22 saved !
[2025-04-30 22:41:34,982][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=3.4725, lr=0.0001
[2025-04-30 22:42:16,169][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=2.9359, lr=0.0001
[2025-04-30 22:42:54,279][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=2.9694, lr=0.0001
[2025-04-30 22:43:35,730][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=2.5253, lr=0.0001
[2025-04-30 22:44:29,962][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=3.3628, lr=0.0001
[2025-04-30 22:45:15,305][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=2.6055, lr=0.0001
[2025-04-30 22:46:07,525][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=3.4058, lr=0.0001
[2025-04-30 22:46:57,644][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=2.9970, lr=0.0001
[2025-04-30 22:46:57,660][meta_train][INFO] - epoch_23 saved !
[2025-04-30 22:47:48,509][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=3.4652, lr=0.0001
[2025-04-30 22:48:36,432][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=3.4724, lr=0.0001
[2025-04-30 22:49:26,988][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=2.7609, lr=0.0001
[2025-04-30 22:50:14,803][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=3.2147, lr=0.0001
[2025-04-30 22:51:03,163][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=2.8377, lr=0.0001
[2025-04-30 22:51:52,159][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=3.6869, lr=0.0001
[2025-04-30 22:52:29,258][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=3.1436, lr=0.0001
[2025-04-30 22:53:06,716][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=3.2462, lr=0.0001
[2025-04-30 22:53:06,726][meta_train][INFO] - epoch_24 saved !
[2025-04-30 22:53:45,043][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=3.5965, lr=0.0001
[2025-04-30 22:54:22,615][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=3.2714, lr=0.0001
[2025-04-30 22:54:59,080][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=3.1992, lr=0.0001
[2025-04-30 22:55:35,478][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=2.9410, lr=0.0001
[2025-04-30 22:56:12,269][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=3.6366, lr=0.0001
[2025-04-30 22:56:49,996][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=2.9746, lr=0.0001
[2025-04-30 22:57:27,496][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=3.8057, lr=0.0001
[2025-04-30 22:58:05,854][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=3.4355, lr=0.0001
[2025-04-30 22:58:05,877][meta_train][INFO] - epoch_25 saved !
[2025-04-30 22:58:44,319][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=3.7285, lr=0.0001
[2025-04-30 22:59:21,668][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=3.1273, lr=0.0001
[2025-04-30 23:00:00,275][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=3.4031, lr=0.0001
[2025-04-30 23:00:37,125][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=3.8494, lr=0.0001
[2025-04-30 23:01:15,926][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=3.2325, lr=0.0001
[2025-04-30 23:01:54,316][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=3.5505, lr=0.0001
[2025-04-30 23:02:32,699][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=3.5776, lr=0.0001
[2025-04-30 23:03:10,384][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=3.9364, lr=0.0001
[2025-04-30 23:03:10,400][meta_train][INFO] - epoch_26 saved !
[2025-04-30 23:03:49,050][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=3.9460, lr=0.0001
[2025-04-30 23:04:27,375][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=3.2748, lr=0.0001
[2025-04-30 23:05:05,882][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=3.3227, lr=0.0001
[2025-04-30 23:05:43,468][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=3.5453, lr=0.0001
[2025-04-30 23:06:22,412][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=3.9068, lr=0.0001
[2025-04-30 23:06:59,716][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=3.6812, lr=0.0001
[2025-04-30 23:07:38,040][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=3.7242, lr=0.0001
[2025-04-30 23:08:15,856][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.0258, lr=0.0001
[2025-04-30 23:08:15,879][meta_train][INFO] - epoch_27 saved !
[2025-04-30 23:08:54,293][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=3.4669, lr=0.0001
[2025-04-30 23:09:33,583][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=3.7732, lr=0.0001
[2025-04-30 23:10:11,039][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=3.6940, lr=0.0001
[2025-04-30 23:10:49,380][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=3.5662, lr=0.0001
[2025-04-30 23:11:28,048][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.1075, lr=0.0001
[2025-04-30 23:12:07,221][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.1159, lr=0.0001
[2025-04-30 23:12:45,511][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=3.8624, lr=0.0001
[2025-04-30 23:13:23,667][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.0638, lr=0.0001
[2025-04-30 23:13:23,691][meta_train][INFO] - epoch_28 saved !
[2025-04-30 23:14:02,518][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=3.6415, lr=0.0001
[2025-04-30 23:14:40,924][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.1533, lr=0.0001
[2025-04-30 23:15:19,606][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=3.8007, lr=0.0001
[2025-04-30 23:15:56,898][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=3.6793, lr=0.0001
[2025-04-30 23:16:35,428][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=3.9283, lr=0.0001
[2025-04-30 23:17:14,065][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.1416, lr=0.0001
[2025-04-30 23:17:52,044][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=3.9909, lr=0.0001
[2025-04-30 23:18:30,779][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.2568, lr=0.0001
[2025-04-30 23:18:30,789][meta_train][INFO] - epoch_29 saved !
[2025-04-30 23:19:08,566][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=3.7948, lr=0.0001
[2025-04-30 23:19:45,619][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.1981, lr=0.0001
[2025-04-30 23:20:24,689][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.0359, lr=0.0001
[2025-04-30 23:21:03,659][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.3137, lr=0.0001
[2025-04-30 23:21:41,514][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.0880, lr=0.0001
[2025-04-30 23:22:20,473][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=3.9788, lr=0.0001
[2025-04-30 23:22:58,774][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.2864, lr=0.0001
[2025-04-30 23:23:36,951][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=3.9346, lr=0.0001
[2025-04-30 23:23:36,969][meta_train][INFO] - epoch_30 saved !
[2025-04-30 23:24:14,719][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.3010, lr=0.0001
[2025-04-30 23:24:52,143][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=3.9416, lr=0.0001
[2025-04-30 23:25:31,381][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.1287, lr=0.0001
[2025-04-30 23:26:10,106][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.1747, lr=0.0001
[2025-04-30 23:26:48,317][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.0268, lr=0.0001
[2025-04-30 23:27:25,024][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.3216, lr=0.0001
[2025-04-30 23:28:04,366][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.4365, lr=0.0001
[2025-04-30 23:28:42,287][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.1171, lr=0.0001
[2025-04-30 23:28:42,296][meta_train][INFO] - epoch_31 saved !
[2025-04-30 23:29:19,226][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.3549, lr=0.0001
[2025-04-30 23:29:58,104][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.1398, lr=0.0001
[2025-04-30 23:30:35,369][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.2317, lr=0.0001
[2025-04-30 23:31:13,147][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.1307, lr=0.0001
[2025-04-30 23:31:51,744][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.3926, lr=0.0001
[2025-04-30 23:32:30,527][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.4859, lr=0.0001
[2025-04-30 23:33:09,251][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.2898, lr=0.0001
[2025-04-30 23:33:46,261][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.1506, lr=0.0001
[2025-04-30 23:33:46,272][meta_train][INFO] - epoch_32 saved !
[2025-04-30 23:34:25,948][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.4216, lr=0.0001
[2025-04-30 23:35:04,045][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.1868, lr=0.0001
[2025-04-30 23:35:04,652][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-04-30 23:35:04,708][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-30 23:35:04,709][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-30 23:35:04,709][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-30 23:35:34,555][train][INFO] - Before training : Train Acc=0.0823  Val Acc=0.1024
[2025-04-30 23:35:40,955][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.2408, lr=0.0001
[2025-04-30 23:35:43,435][train][INFO] - Epoch 1/100, Val Acc=0.6393, Val Loss=1.6485, lr=0.0100
[2025-04-30 23:35:51,963][train][INFO] - Epoch 2/100, Val Acc=0.6660, Val Loss=1.5031, lr=0.0100
[2025-04-30 23:36:00,645][train][INFO] - Epoch 3/100, Val Acc=0.6429, Val Loss=1.6330, lr=0.0100
[2025-04-30 23:36:08,905][train][INFO] - Epoch 4/100, Val Acc=0.6486, Val Loss=1.5639, lr=0.0100
[2025-04-30 23:36:17,417][train][INFO] - Epoch 5/100, Val Acc=0.6698, Val Loss=1.5003, lr=0.0100
[2025-04-30 23:36:21,262][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.3604, lr=0.0001
[2025-04-30 23:36:26,093][train][INFO] - Epoch 6/100, Val Acc=0.6536, Val Loss=1.6034, lr=0.0100
[2025-04-30 23:36:34,121][train][INFO] - Epoch 7/100, Val Acc=0.6633, Val Loss=1.5361, lr=0.0100
[2025-04-30 23:36:42,675][train][INFO] - Epoch 8/100, Val Acc=0.6600, Val Loss=1.5739, lr=0.0100
[2025-04-30 23:36:51,309][train][INFO] - Epoch 9/100, Val Acc=0.6602, Val Loss=1.5547, lr=0.0100
[2025-04-30 23:36:59,947][train][INFO] - Epoch 10/100, Val Acc=0.6613, Val Loss=1.6054, lr=0.0100
[2025-04-30 23:37:00,449][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.2656, lr=0.0001
[2025-04-30 23:37:08,728][train][INFO] - Epoch 11/100, Val Acc=0.6649, Val Loss=1.5351, lr=0.0100
[2025-04-30 23:37:17,390][train][INFO] - Epoch 12/100, Val Acc=0.6765, Val Loss=1.4966, lr=0.0100
[2025-04-30 23:37:25,917][train][INFO] - Epoch 13/100, Val Acc=0.6618, Val Loss=1.5822, lr=0.0100
[2025-04-30 23:37:34,413][train][INFO] - Epoch 14/100, Val Acc=0.6711, Val Loss=1.5424, lr=0.0100
[2025-04-30 23:37:39,451][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.3472, lr=0.0001
[2025-04-30 23:37:42,923][train][INFO] - Epoch 15/100, Val Acc=0.6690, Val Loss=1.5437, lr=0.0100
[2025-04-30 23:37:51,342][train][INFO] - Epoch 16/100, Val Acc=0.6627, Val Loss=1.5561, lr=0.0100
[2025-04-30 23:38:00,105][train][INFO] - Epoch 17/100, Val Acc=0.6606, Val Loss=1.5748, lr=0.0100
[2025-04-30 23:38:08,727][train][INFO] - Epoch 18/100, Val Acc=0.6656, Val Loss=1.5425, lr=0.0100
[2025-04-30 23:38:17,258][train][INFO] - Epoch 19/100, Val Acc=0.6691, Val Loss=1.5909, lr=0.0100
[2025-04-30 23:38:19,083][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.5783, lr=0.0001
[2025-04-30 23:38:25,809][train][INFO] - Epoch 20/100, Val Acc=0.6593, Val Loss=1.6105, lr=0.0100
[2025-04-30 23:38:34,419][train][INFO] - Epoch 21/100, Val Acc=0.6688, Val Loss=1.5416, lr=0.0100
[2025-04-30 23:38:43,203][train][INFO] - Epoch 22/100, Val Acc=0.6676, Val Loss=1.5996, lr=0.0100
[2025-04-30 23:38:51,347][train][INFO] - Epoch 23/100, Val Acc=0.6737, Val Loss=1.5107, lr=0.0100
[2025-04-30 23:38:59,224][train][INFO] - Epoch 24/100, Val Acc=0.6529, Val Loss=1.6573, lr=0.0100
[2025-04-30 23:38:59,470][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.4728, lr=0.0001
[2025-04-30 23:38:59,496][meta_train][INFO] - epoch_33 saved !
[2025-04-30 23:39:08,136][train][INFO] - Epoch 25/100, Val Acc=0.6776, Val Loss=1.4988, lr=0.0100
[2025-04-30 23:39:16,617][train][INFO] - Epoch 26/100, Val Acc=0.6709, Val Loss=1.5611, lr=0.0100
[2025-04-30 23:39:25,135][train][INFO] - Epoch 27/100, Val Acc=0.6771, Val Loss=1.5595, lr=0.0100
[2025-04-30 23:39:33,293][train][INFO] - Epoch 28/100, Val Acc=0.6593, Val Loss=1.6294, lr=0.0100
[2025-04-30 23:39:37,164][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.4793, lr=0.0001
[2025-04-30 23:39:41,450][train][INFO] - Epoch 29/100, Val Acc=0.6534, Val Loss=1.6516, lr=0.0100
[2025-04-30 23:39:50,128][train][INFO] - Epoch 30/100, Val Acc=0.6621, Val Loss=1.5928, lr=0.0100
[2025-04-30 23:39:58,594][train][INFO] - Epoch 31/100, Val Acc=0.6681, Val Loss=1.5518, lr=0.0100
[2025-04-30 23:40:06,997][train][INFO] - Epoch 32/100, Val Acc=0.6671, Val Loss=1.5866, lr=0.0100
[2025-04-30 23:40:15,256][train][INFO] - Epoch 33/100, Val Acc=0.6650, Val Loss=1.6231, lr=0.0100
[2025-04-30 23:40:17,194][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.3791, lr=0.0001
[2025-04-30 23:40:23,698][train][INFO] - Epoch 34/100, Val Acc=0.6686, Val Loss=1.5952, lr=0.0100
[2025-04-30 23:40:32,414][train][INFO] - Epoch 35/100, Val Acc=0.6693, Val Loss=1.5967, lr=0.0100
[2025-04-30 23:40:41,069][train][INFO] - Epoch 36/100, Val Acc=0.6805, Val Loss=1.4842, lr=0.0100
[2025-04-30 23:40:49,429][train][INFO] - Epoch 37/100, Val Acc=0.6663, Val Loss=1.5695, lr=0.0100
[2025-04-30 23:40:57,756][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6060, lr=0.0001
[2025-04-30 23:40:58,078][train][INFO] - Epoch 38/100, Val Acc=0.6701, Val Loss=1.5643, lr=0.0100
[2025-04-30 23:41:06,958][train][INFO] - Epoch 39/100, Val Acc=0.6735, Val Loss=1.5848, lr=0.0100
[2025-04-30 23:41:15,891][train][INFO] - Epoch 40/100, Val Acc=0.6643, Val Loss=1.6089, lr=0.0100
[2025-04-30 23:41:24,458][train][INFO] - Epoch 41/100, Val Acc=0.6748, Val Loss=1.5248, lr=0.0100
[2025-04-30 23:41:32,932][train][INFO] - Epoch 42/100, Val Acc=0.6651, Val Loss=1.5883, lr=0.0100
[2025-04-30 23:41:37,045][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.3085, lr=0.0001
[2025-04-30 23:41:41,246][train][INFO] - Epoch 43/100, Val Acc=0.6799, Val Loss=1.5055, lr=0.0100
[2025-04-30 23:41:49,820][train][INFO] - Epoch 44/100, Val Acc=0.6703, Val Loss=1.5899, lr=0.0100
[2025-04-30 23:41:58,488][train][INFO] - Epoch 45/100, Val Acc=0.6608, Val Loss=1.6389, lr=0.0100
[2025-04-30 23:42:07,155][train][INFO] - Epoch 46/100, Val Acc=0.6699, Val Loss=1.5693, lr=0.0100
[2025-04-30 23:42:15,482][train][INFO] - Epoch 47/100, Val Acc=0.6748, Val Loss=1.5289, lr=0.0100
[2025-04-30 23:42:16,957][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.4374, lr=0.0001
[2025-04-30 23:42:24,278][train][INFO] - Epoch 48/100, Val Acc=0.6660, Val Loss=1.5908, lr=0.0100
[2025-04-30 23:42:33,051][train][INFO] - Epoch 49/100, Val Acc=0.6575, Val Loss=1.6564, lr=0.0100
[2025-04-30 23:42:41,536][train][INFO] - Epoch 50/100, Val Acc=0.6758, Val Loss=1.5180, lr=0.0100
[2025-04-30 23:42:49,995][train][INFO] - Epoch 51/100, Val Acc=0.6624, Val Loss=1.5737, lr=0.0100
[2025-04-30 23:42:54,886][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.5081, lr=0.0001
[2025-04-30 23:42:58,689][train][INFO] - Epoch 52/100, Val Acc=0.6656, Val Loss=1.6134, lr=0.0100
[2025-04-30 23:43:06,988][train][INFO] - Epoch 53/100, Val Acc=0.6741, Val Loss=1.4904, lr=0.0100
[2025-04-30 23:43:15,093][train][INFO] - Epoch 54/100, Val Acc=0.6750, Val Loss=1.5413, lr=0.0100
[2025-04-30 23:43:23,726][train][INFO] - Epoch 55/100, Val Acc=0.6533, Val Loss=1.6686, lr=0.0100
[2025-04-30 23:43:32,006][train][INFO] - Epoch 56/100, Val Acc=0.6676, Val Loss=1.5528, lr=0.0100
[2025-04-30 23:43:34,636][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.3780, lr=0.0001
[2025-04-30 23:43:40,744][train][INFO] - Epoch 57/100, Val Acc=0.6774, Val Loss=1.5585, lr=0.0100
[2025-04-30 23:43:49,495][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.6712, lr=0.0100
[2025-04-30 23:43:58,188][train][INFO] - Epoch 59/100, Val Acc=0.6667, Val Loss=1.5614, lr=0.0100
[2025-04-30 23:44:06,650][train][INFO] - Epoch 60/100, Val Acc=0.6704, Val Loss=1.5336, lr=0.0100
[2025-04-30 23:44:14,963][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.3663, lr=0.0001
[2025-04-30 23:44:14,973][meta_train][INFO] - epoch_34 saved !
[2025-04-30 23:44:15,452][train][INFO] - Epoch 61/100, Val Acc=0.7235, Val Loss=1.3053, lr=0.0010
[2025-04-30 23:44:24,474][train][INFO] - Epoch 62/100, Val Acc=0.7294, Val Loss=1.2967, lr=0.0010
[2025-04-30 23:44:33,580][train][INFO] - Epoch 63/100, Val Acc=0.7274, Val Loss=1.3125, lr=0.0010
[2025-04-30 23:44:42,142][train][INFO] - Epoch 64/100, Val Acc=0.7312, Val Loss=1.3106, lr=0.0010
[2025-04-30 23:44:50,293][train][INFO] - Epoch 65/100, Val Acc=0.7329, Val Loss=1.3112, lr=0.0010
[2025-04-30 23:44:54,609][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.3910, lr=0.0001
[2025-04-30 23:44:58,981][train][INFO] - Epoch 66/100, Val Acc=0.7322, Val Loss=1.3199, lr=0.0010
[2025-04-30 23:45:07,218][train][INFO] - Epoch 67/100, Val Acc=0.7335, Val Loss=1.3187, lr=0.0010
[2025-04-30 23:45:16,083][train][INFO] - Epoch 68/100, Val Acc=0.7341, Val Loss=1.3142, lr=0.0010
[2025-04-30 23:45:24,537][train][INFO] - Epoch 69/100, Val Acc=0.7345, Val Loss=1.3194, lr=0.0010
[2025-04-30 23:45:32,862][train][INFO] - Epoch 70/100, Val Acc=0.7338, Val Loss=1.3270, lr=0.0010
[2025-04-30 23:45:33,442][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.3614, lr=0.0001
[2025-04-30 23:45:41,324][train][INFO] - Epoch 71/100, Val Acc=0.7336, Val Loss=1.3288, lr=0.0010
[2025-04-30 23:45:49,922][train][INFO] - Epoch 72/100, Val Acc=0.7344, Val Loss=1.3271, lr=0.0010
[2025-04-30 23:45:58,606][train][INFO] - Epoch 73/100, Val Acc=0.7347, Val Loss=1.3331, lr=0.0010
[2025-04-30 23:46:07,069][train][INFO] - Epoch 74/100, Val Acc=0.7349, Val Loss=1.3250, lr=0.0010
[2025-04-30 23:46:12,046][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.4429, lr=0.0001
[2025-04-30 23:46:15,818][train][INFO] - Epoch 75/100, Val Acc=0.7354, Val Loss=1.3294, lr=0.0010
[2025-04-30 23:46:24,552][train][INFO] - Epoch 76/100, Val Acc=0.7346, Val Loss=1.3300, lr=0.0010
[2025-04-30 23:46:33,226][train][INFO] - Epoch 77/100, Val Acc=0.7372, Val Loss=1.3302, lr=0.0010
[2025-04-30 23:46:41,616][train][INFO] - Epoch 78/100, Val Acc=0.7369, Val Loss=1.3269, lr=0.0010
[2025-04-30 23:46:50,217][train][INFO] - Epoch 79/100, Val Acc=0.7364, Val Loss=1.3322, lr=0.0010
[2025-04-30 23:46:51,900][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.3898, lr=0.0001
[2025-04-30 23:46:58,932][train][INFO] - Epoch 80/100, Val Acc=0.7354, Val Loss=1.3318, lr=0.0010
[2025-04-30 23:47:07,737][train][INFO] - Epoch 81/100, Val Acc=0.7362, Val Loss=1.3281, lr=0.0010
[2025-04-30 23:47:16,678][train][INFO] - Epoch 82/100, Val Acc=0.7374, Val Loss=1.3279, lr=0.0010
[2025-04-30 23:47:24,943][train][INFO] - Epoch 83/100, Val Acc=0.7371, Val Loss=1.3346, lr=0.0010
[2025-04-30 23:47:32,264][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.4891, lr=0.0001
[2025-04-30 23:47:33,637][train][INFO] - Epoch 84/100, Val Acc=0.7383, Val Loss=1.3314, lr=0.0010
[2025-04-30 23:47:41,976][train][INFO] - Epoch 85/100, Val Acc=0.7370, Val Loss=1.3230, lr=0.0010
[2025-04-30 23:47:50,690][train][INFO] - Epoch 86/100, Val Acc=0.7383, Val Loss=1.3289, lr=0.0010
[2025-04-30 23:47:59,326][train][INFO] - Epoch 87/100, Val Acc=0.7393, Val Loss=1.3263, lr=0.0010
[2025-04-30 23:48:07,100][train][INFO] - Epoch 88/100, Val Acc=0.7368, Val Loss=1.3251, lr=0.0010
[2025-04-30 23:48:10,619][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6686, lr=0.0001
[2025-04-30 23:48:15,986][train][INFO] - Epoch 89/100, Val Acc=0.7377, Val Loss=1.3287, lr=0.0010
[2025-04-30 23:48:24,550][train][INFO] - Epoch 90/100, Val Acc=0.7380, Val Loss=1.3265, lr=0.0010
[2025-04-30 23:48:33,180][train][INFO] - Epoch 91/100, Val Acc=0.7381, Val Loss=1.3257, lr=0.0001
[2025-04-30 23:48:41,537][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3253, lr=0.0001
[2025-04-30 23:48:49,069][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.5670, lr=0.0001
[2025-04-30 23:48:50,193][train][INFO] - Epoch 93/100, Val Acc=0.7390, Val Loss=1.3251, lr=0.0001
[2025-04-30 23:48:59,249][train][INFO] - Epoch 94/100, Val Acc=0.7366, Val Loss=1.3227, lr=0.0001
[2025-04-30 23:49:08,500][train][INFO] - Epoch 95/100, Val Acc=0.7398, Val Loss=1.3282, lr=0.0001
[2025-04-30 23:49:17,058][train][INFO] - Epoch 96/100, Val Acc=0.7383, Val Loss=1.3245, lr=0.0001
[2025-04-30 23:49:25,628][train][INFO] - Epoch 97/100, Val Acc=0.7380, Val Loss=1.3229, lr=0.0001
[2025-04-30 23:49:28,638][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.5588, lr=0.0001
[2025-04-30 23:49:28,648][meta_train][INFO] - epoch_35 saved !
[2025-04-30 23:49:34,610][train][INFO] - Epoch 98/100, Val Acc=0.7382, Val Loss=1.3214, lr=0.0001
[2025-04-30 23:49:42,652][train][INFO] - Epoch 99/100, Val Acc=0.7383, Val Loss=1.3248, lr=0.0001
[2025-04-30 23:49:51,462][train][INFO] - Epoch 100/100, Val Acc=0.7386, Val Loss=1.3244, lr=0.0001
[2025-04-30 23:49:56,697][train][INFO] - After training : Train Acc=0.9992  Val Acc=0.7398
[2025-04-30 23:49:56,703][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-30 23:50:08,394][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.5828, lr=0.0001
[2025-04-30 23:50:47,912][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.5046, lr=0.0001
[2025-04-30 23:51:28,955][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.4909, lr=0.0001
[2025-04-30 23:51:46,414][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-30 23:52:08,368][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.5767, lr=0.0001
[2025-04-30 23:52:49,110][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.7043, lr=0.0001
[2025-04-30 23:53:28,118][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.4725, lr=0.0001
[2025-04-30 23:53:37,192][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-30 23:53:37,647][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-30 23:54:08,148][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.5544, lr=0.0001
[2025-04-30 23:54:46,393][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.4764, lr=0.0001
[2025-04-30 23:54:46,403][meta_train][INFO] - epoch_36 saved !
[2025-04-30 23:55:25,149][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.5654, lr=0.0001
[2025-04-30 23:56:03,584][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6182, lr=0.0001
[2025-04-30 23:56:41,092][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.7257, lr=0.0001
[2025-04-30 23:57:18,870][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.5484, lr=0.0001
[2025-04-30 23:57:56,770][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.5109, lr=0.0001
[2025-04-30 23:58:33,866][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.5266, lr=0.0001
[2025-04-30 23:59:13,361][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6158, lr=0.0001
[2025-04-30 23:59:50,273][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.5735, lr=0.0001
[2025-04-30 23:59:50,284][meta_train][INFO] - epoch_37 saved !
[2025-05-01 00:00:28,200][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6213, lr=0.0001
[2025-05-01 00:01:05,717][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.5344, lr=0.0001
[2025-05-01 00:01:42,069][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6482, lr=0.0001
[2025-05-01 00:02:20,357][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6117, lr=0.0001
[2025-05-01 00:02:58,958][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.5621, lr=0.0001
[2025-05-01 00:03:36,509][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6002, lr=0.0001
[2025-05-01 00:04:13,577][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6008, lr=0.0001
[2025-05-01 00:04:51,385][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.7512, lr=0.0001
[2025-05-01 00:04:51,412][meta_train][INFO] - epoch_38 saved !
[2025-05-01 00:05:28,004][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6263, lr=0.0001
[2025-05-01 00:06:06,358][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.7526, lr=0.0001
[2025-05-01 00:06:43,132][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6466, lr=0.0001
[2025-05-01 00:07:20,630][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6173, lr=0.0001
[2025-05-01 00:07:58,512][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.5792, lr=0.0001
[2025-05-01 00:08:34,907][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6732, lr=0.0001
[2025-05-01 00:09:12,669][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6331, lr=0.0001
[2025-05-01 00:09:49,810][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6028, lr=0.0001
[2025-05-01 00:09:49,820][meta_train][INFO] - epoch_39 saved !
[2025-05-01 00:10:28,521][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.7549, lr=0.0001
[2025-05-01 00:11:04,732][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6072, lr=0.0001
[2025-05-01 00:11:43,238][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6323, lr=0.0001
[2025-05-01 00:12:20,593][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6588, lr=0.0001
[2025-05-01 00:12:56,614][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6826, lr=0.0001
[2025-05-01 00:13:34,638][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6508, lr=0.0001
[2025-05-01 00:14:12,007][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6030, lr=0.0001
[2025-05-01 00:14:49,691][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6497, lr=0.0001
[2025-05-01 00:14:49,714][meta_train][INFO] - epoch_40 saved !
[2025-05-01 00:15:26,048][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6060, lr=0.0001
[2025-05-01 00:16:04,623][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6512, lr=0.0001
[2025-05-01 00:16:41,623][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6638, lr=0.0001
[2025-05-01 00:17:19,391][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.7491, lr=0.0001
[2025-05-01 00:17:57,005][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6630, lr=0.0001
[2025-05-01 00:18:34,452][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6483, lr=0.0001
[2025-05-01 00:19:11,207][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6357, lr=0.0001
[2025-05-01 00:19:48,420][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6873, lr=0.0001
[2025-05-01 00:19:48,430][meta_train][INFO] - epoch_41 saved !
[2025-05-01 00:20:26,386][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6504, lr=0.0001
[2025-05-01 00:21:03,971][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6394, lr=0.0001
[2025-05-01 00:21:40,573][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6660, lr=0.0001
[2025-05-01 00:22:18,916][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6213, lr=0.0001
[2025-05-01 00:22:57,331][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6538, lr=0.0001
[2025-05-01 00:23:34,822][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6880, lr=0.0001
[2025-05-01 00:24:12,879][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6725, lr=0.0001
[2025-05-01 00:24:51,002][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.7367, lr=0.0001
[2025-05-01 00:24:51,012][meta_train][INFO] - epoch_42 saved !
[2025-05-01 00:25:30,176][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6451, lr=0.0001
[2025-05-01 00:26:08,317][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6745, lr=0.0001
[2025-05-01 00:26:45,443][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6871, lr=0.0001
[2025-05-01 00:27:24,236][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6532, lr=0.0001
[2025-05-01 00:28:02,632][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.7272, lr=0.0001
[2025-05-01 00:28:40,000][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6636, lr=0.0001
[2025-05-01 00:29:18,510][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6276, lr=0.0001
[2025-05-01 00:29:57,082][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6531, lr=0.0001
[2025-05-01 00:29:57,091][meta_train][INFO] - epoch_43 saved !
[2025-05-01 00:30:33,763][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6812, lr=0.0001
[2025-05-01 00:31:11,490][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6495, lr=0.0001
[2025-05-01 00:31:49,880][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6285, lr=0.0001
[2025-05-01 00:32:28,753][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6522, lr=0.0001
[2025-05-01 00:33:07,967][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6745, lr=0.0001
[2025-05-01 00:33:46,655][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6589, lr=0.0001
[2025-05-01 00:34:24,050][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.7113, lr=0.0001
[2025-05-01 00:35:03,342][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6480, lr=0.0001
[2025-05-01 00:35:03,367][meta_train][INFO] - epoch_44 saved !
[2025-05-01 00:35:22,338][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 00:35:22,412][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 00:35:41,032][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6466, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 00:35:51,955][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0101
[2025-05-01 00:35:59,845][train][INFO] - Epoch 1/100, Val Acc=0.6289, Val Loss=1.6286, lr=0.0100
[2025-05-01 00:36:08,578][train][INFO] - Epoch 2/100, Val Acc=0.6495, Val Loss=1.5944, lr=0.0100
[2025-05-01 00:36:17,177][train][INFO] - Epoch 3/100, Val Acc=0.6376, Val Loss=1.6359, lr=0.0100
[2025-05-01 00:36:20,407][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6477, lr=0.0001
[2025-05-01 00:36:25,697][train][INFO] - Epoch 4/100, Val Acc=0.6650, Val Loss=1.4642, lr=0.0100
[2025-05-01 00:36:33,309][train][INFO] - Epoch 5/100, Val Acc=0.6578, Val Loss=1.5247, lr=0.0100
[2025-05-01 00:36:41,581][train][INFO] - Epoch 6/100, Val Acc=0.6649, Val Loss=1.5132, lr=0.0100
[2025-05-01 00:36:49,573][train][INFO] - Epoch 7/100, Val Acc=0.6592, Val Loss=1.5374, lr=0.0100
[2025-05-01 00:36:58,004][train][INFO] - Epoch 8/100, Val Acc=0.6671, Val Loss=1.5194, lr=0.0100
[2025-05-01 00:36:59,103][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.7042, lr=0.0001
[2025-05-01 00:37:06,686][train][INFO] - Epoch 9/100, Val Acc=0.6675, Val Loss=1.5084, lr=0.0100
[2025-05-01 00:37:14,981][train][INFO] - Epoch 10/100, Val Acc=0.6685, Val Loss=1.5027, lr=0.0100
[2025-05-01 00:37:22,794][train][INFO] - Epoch 11/100, Val Acc=0.6653, Val Loss=1.5192, lr=0.0100
[2025-05-01 00:37:30,689][train][INFO] - Epoch 12/100, Val Acc=0.6700, Val Loss=1.5211, lr=0.0100
[2025-05-01 00:37:38,656][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6735, lr=0.0001
[2025-05-01 00:37:39,087][train][INFO] - Epoch 13/100, Val Acc=0.6504, Val Loss=1.6326, lr=0.0100
[2025-05-01 00:37:47,027][train][INFO] - Epoch 14/100, Val Acc=0.6686, Val Loss=1.5586, lr=0.0100
[2025-05-01 00:37:55,618][train][INFO] - Epoch 15/100, Val Acc=0.6579, Val Loss=1.6244, lr=0.0100
[2025-05-01 00:38:04,102][train][INFO] - Epoch 16/100, Val Acc=0.6580, Val Loss=1.5834, lr=0.0100
[2025-05-01 00:38:12,738][train][INFO] - Epoch 17/100, Val Acc=0.6664, Val Loss=1.5262, lr=0.0100
[2025-05-01 00:38:17,069][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6737, lr=0.0001
[2025-05-01 00:38:21,307][train][INFO] - Epoch 18/100, Val Acc=0.6717, Val Loss=1.5267, lr=0.0100
[2025-05-01 00:38:29,649][train][INFO] - Epoch 19/100, Val Acc=0.6673, Val Loss=1.6046, lr=0.0100
[2025-05-01 00:38:38,350][train][INFO] - Epoch 20/100, Val Acc=0.6713, Val Loss=1.5738, lr=0.0100
[2025-05-01 00:38:46,206][train][INFO] - Epoch 21/100, Val Acc=0.6680, Val Loss=1.5823, lr=0.0100
[2025-05-01 00:38:54,673][train][INFO] - Epoch 22/100, Val Acc=0.6665, Val Loss=1.5742, lr=0.0100
[2025-05-01 00:38:57,230][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6490, lr=0.0001
[2025-05-01 00:39:03,108][train][INFO] - Epoch 23/100, Val Acc=0.6585, Val Loss=1.5963, lr=0.0100
[2025-05-01 00:39:11,652][train][INFO] - Epoch 24/100, Val Acc=0.6781, Val Loss=1.5212, lr=0.0100
[2025-05-01 00:39:20,149][train][INFO] - Epoch 25/100, Val Acc=0.6672, Val Loss=1.5825, lr=0.0100
[2025-05-01 00:39:28,792][train][INFO] - Epoch 26/100, Val Acc=0.6723, Val Loss=1.5670, lr=0.0100
[2025-05-01 00:39:35,560][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6297, lr=0.0001
[2025-05-01 00:39:36,864][train][INFO] - Epoch 27/100, Val Acc=0.6663, Val Loss=1.6188, lr=0.0100
[2025-05-01 00:39:45,251][train][INFO] - Epoch 28/100, Val Acc=0.6782, Val Loss=1.5374, lr=0.0100
[2025-05-01 00:39:54,252][train][INFO] - Epoch 29/100, Val Acc=0.6689, Val Loss=1.5974, lr=0.0100
[2025-05-01 00:40:02,058][train][INFO] - Epoch 30/100, Val Acc=0.6762, Val Loss=1.5287, lr=0.0100
[2025-05-01 00:40:10,446][train][INFO] - Epoch 31/100, Val Acc=0.6749, Val Loss=1.5422, lr=0.0100
[2025-05-01 00:40:15,041][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6531, lr=0.0001
[2025-05-01 00:40:15,057][meta_train][INFO] - epoch_45 saved !
[2025-05-01 00:40:18,439][train][INFO] - Epoch 32/100, Val Acc=0.6632, Val Loss=1.6214, lr=0.0100
[2025-05-01 00:40:26,413][train][INFO] - Epoch 33/100, Val Acc=0.6664, Val Loss=1.6080, lr=0.0100
[2025-05-01 00:40:34,270][train][INFO] - Epoch 34/100, Val Acc=0.6803, Val Loss=1.5312, lr=0.0100
[2025-05-01 00:40:42,284][train][INFO] - Epoch 35/100, Val Acc=0.6699, Val Loss=1.5711, lr=0.0100
[2025-05-01 00:40:50,240][train][INFO] - Epoch 36/100, Val Acc=0.6746, Val Loss=1.5239, lr=0.0100
[2025-05-01 00:40:54,939][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6728, lr=0.0001
[2025-05-01 00:40:58,730][train][INFO] - Epoch 37/100, Val Acc=0.6644, Val Loss=1.6576, lr=0.0100
[2025-05-01 00:41:06,284][train][INFO] - Epoch 38/100, Val Acc=0.6744, Val Loss=1.5382, lr=0.0100
[2025-05-01 00:41:14,649][train][INFO] - Epoch 39/100, Val Acc=0.6668, Val Loss=1.5539, lr=0.0100
[2025-05-01 00:41:23,168][train][INFO] - Epoch 40/100, Val Acc=0.6696, Val Loss=1.5994, lr=0.0100
[2025-05-01 00:41:31,722][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.6125, lr=0.0100
[2025-05-01 00:41:34,713][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6478, lr=0.0001
[2025-05-01 00:41:40,466][train][INFO] - Epoch 42/100, Val Acc=0.6581, Val Loss=1.6392, lr=0.0100
[2025-05-01 00:41:49,098][train][INFO] - Epoch 43/100, Val Acc=0.6740, Val Loss=1.5583, lr=0.0100
[2025-05-01 00:41:57,886][train][INFO] - Epoch 44/100, Val Acc=0.6765, Val Loss=1.5394, lr=0.0100
[2025-05-01 00:42:06,748][train][INFO] - Epoch 45/100, Val Acc=0.6555, Val Loss=1.6597, lr=0.0100
[2025-05-01 00:42:14,676][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6948, lr=0.0001
[2025-05-01 00:42:15,168][train][INFO] - Epoch 46/100, Val Acc=0.6743, Val Loss=1.5639, lr=0.0100
[2025-05-01 00:42:22,897][train][INFO] - Epoch 47/100, Val Acc=0.6557, Val Loss=1.6675, lr=0.0100
[2025-05-01 00:42:31,318][train][INFO] - Epoch 48/100, Val Acc=0.6708, Val Loss=1.5699, lr=0.0100
[2025-05-01 00:42:39,573][train][INFO] - Epoch 49/100, Val Acc=0.6685, Val Loss=1.6002, lr=0.0100
[2025-05-01 00:42:48,105][train][INFO] - Epoch 50/100, Val Acc=0.6667, Val Loss=1.6034, lr=0.0100
[2025-05-01 00:42:54,211][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6414, lr=0.0001
[2025-05-01 00:42:55,604][train][INFO] - Epoch 51/100, Val Acc=0.6714, Val Loss=1.6086, lr=0.0100
[2025-05-01 00:43:03,799][train][INFO] - Epoch 52/100, Val Acc=0.6785, Val Loss=1.5412, lr=0.0100
[2025-05-01 00:43:11,744][train][INFO] - Epoch 53/100, Val Acc=0.6823, Val Loss=1.5410, lr=0.0100
[2025-05-01 00:43:19,977][train][INFO] - Epoch 54/100, Val Acc=0.6680, Val Loss=1.5443, lr=0.0100
[2025-05-01 00:43:28,290][train][INFO] - Epoch 55/100, Val Acc=0.6738, Val Loss=1.5766, lr=0.0100
[2025-05-01 00:43:32,455][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6450, lr=0.0001
[2025-05-01 00:43:36,439][train][INFO] - Epoch 56/100, Val Acc=0.6707, Val Loss=1.6004, lr=0.0100
[2025-05-01 00:43:44,794][train][INFO] - Epoch 57/100, Val Acc=0.6621, Val Loss=1.6096, lr=0.0100
[2025-05-01 00:43:52,609][train][INFO] - Epoch 58/100, Val Acc=0.6556, Val Loss=1.6278, lr=0.0100
[2025-05-01 00:44:00,571][train][INFO] - Epoch 59/100, Val Acc=0.6538, Val Loss=1.6854, lr=0.0100
[2025-05-01 00:44:08,671][train][INFO] - Epoch 60/100, Val Acc=0.6585, Val Loss=1.6530, lr=0.0100
[2025-05-01 00:44:11,975][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6481, lr=0.0001
[2025-05-01 00:44:16,662][train][INFO] - Epoch 61/100, Val Acc=0.7207, Val Loss=1.3267, lr=0.0010
[2025-05-01 00:44:25,094][train][INFO] - Epoch 62/100, Val Acc=0.7272, Val Loss=1.3175, lr=0.0010
[2025-05-01 00:44:33,166][train][INFO] - Epoch 63/100, Val Acc=0.7287, Val Loss=1.3253, lr=0.0010
[2025-05-01 00:44:41,220][train][INFO] - Epoch 64/100, Val Acc=0.7304, Val Loss=1.3216, lr=0.0010
[2025-05-01 00:44:49,332][train][INFO] - Epoch 65/100, Val Acc=0.7291, Val Loss=1.3308, lr=0.0010
[2025-05-01 00:44:51,589][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6654, lr=0.0001
[2025-05-01 00:44:57,526][train][INFO] - Epoch 66/100, Val Acc=0.7320, Val Loss=1.3302, lr=0.0010
[2025-05-01 00:45:05,676][train][INFO] - Epoch 67/100, Val Acc=0.7308, Val Loss=1.3305, lr=0.0010
[2025-05-01 00:45:13,352][train][INFO] - Epoch 68/100, Val Acc=0.7314, Val Loss=1.3263, lr=0.0010
[2025-05-01 00:45:21,609][train][INFO] - Epoch 69/100, Val Acc=0.7341, Val Loss=1.3317, lr=0.0010
[2025-05-01 00:45:29,515][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6283, lr=0.0001
[2025-05-01 00:45:29,519][train][INFO] - Epoch 70/100, Val Acc=0.7327, Val Loss=1.3432, lr=0.0010
[2025-05-01 00:45:29,525][meta_train][INFO] - epoch_46 saved !
[2025-05-01 00:45:38,599][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.3437, lr=0.0010
[2025-05-01 00:45:47,502][train][INFO] - Epoch 72/100, Val Acc=0.7343, Val Loss=1.3464, lr=0.0010
[2025-05-01 00:45:55,977][train][INFO] - Epoch 73/100, Val Acc=0.7352, Val Loss=1.3427, lr=0.0010
[2025-05-01 00:46:04,035][train][INFO] - Epoch 74/100, Val Acc=0.7357, Val Loss=1.3411, lr=0.0010
[2025-05-01 00:46:09,792][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6425, lr=0.0001
[2025-05-01 00:46:12,427][train][INFO] - Epoch 75/100, Val Acc=0.7371, Val Loss=1.3428, lr=0.0010
[2025-05-01 00:46:20,920][train][INFO] - Epoch 76/100, Val Acc=0.7355, Val Loss=1.3441, lr=0.0010
[2025-05-01 00:46:28,731][train][INFO] - Epoch 77/100, Val Acc=0.7372, Val Loss=1.3443, lr=0.0010
[2025-05-01 00:46:37,136][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.3440, lr=0.0010
[2025-05-01 00:46:45,529][train][INFO] - Epoch 79/100, Val Acc=0.7378, Val Loss=1.3494, lr=0.0010
[2025-05-01 00:46:49,385][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6675, lr=0.0001
[2025-05-01 00:46:53,860][train][INFO] - Epoch 80/100, Val Acc=0.7372, Val Loss=1.3433, lr=0.0010
[2025-05-01 00:47:02,315][train][INFO] - Epoch 81/100, Val Acc=0.7389, Val Loss=1.3420, lr=0.0010
[2025-05-01 00:47:10,187][train][INFO] - Epoch 82/100, Val Acc=0.7393, Val Loss=1.3442, lr=0.0010
[2025-05-01 00:47:18,881][train][INFO] - Epoch 83/100, Val Acc=0.7382, Val Loss=1.3479, lr=0.0010
[2025-05-01 00:47:26,950][train][INFO] - Epoch 84/100, Val Acc=0.7381, Val Loss=1.3420, lr=0.0010
[2025-05-01 00:47:28,985][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6831, lr=0.0001
[2025-05-01 00:47:35,071][train][INFO] - Epoch 85/100, Val Acc=0.7373, Val Loss=1.3412, lr=0.0010
[2025-05-01 00:47:43,753][train][INFO] - Epoch 86/100, Val Acc=0.7386, Val Loss=1.3469, lr=0.0010
[2025-05-01 00:47:51,710][train][INFO] - Epoch 87/100, Val Acc=0.7391, Val Loss=1.3443, lr=0.0010
[2025-05-01 00:47:59,850][train][INFO] - Epoch 88/100, Val Acc=0.7383, Val Loss=1.3424, lr=0.0010
[2025-05-01 00:48:07,382][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6638, lr=0.0001
[2025-05-01 00:48:08,192][train][INFO] - Epoch 89/100, Val Acc=0.7407, Val Loss=1.3425, lr=0.0010
[2025-05-01 00:48:17,221][train][INFO] - Epoch 90/100, Val Acc=0.7376, Val Loss=1.3524, lr=0.0010
[2025-05-01 00:48:25,777][train][INFO] - Epoch 91/100, Val Acc=0.7381, Val Loss=1.3473, lr=0.0001
[2025-05-01 00:48:34,098][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3461, lr=0.0001
[2025-05-01 00:48:42,131][train][INFO] - Epoch 93/100, Val Acc=0.7394, Val Loss=1.3455, lr=0.0001
[2025-05-01 00:48:46,095][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6447, lr=0.0001
[2025-05-01 00:48:49,902][train][INFO] - Epoch 94/100, Val Acc=0.7403, Val Loss=1.3418, lr=0.0001
[2025-05-01 00:48:58,096][train][INFO] - Epoch 95/100, Val Acc=0.7382, Val Loss=1.3469, lr=0.0001
[2025-05-01 00:49:06,172][train][INFO] - Epoch 96/100, Val Acc=0.7407, Val Loss=1.3431, lr=0.0001
[2025-05-01 00:49:14,322][train][INFO] - Epoch 97/100, Val Acc=0.7416, Val Loss=1.3420, lr=0.0001
[2025-05-01 00:49:22,584][train][INFO] - Epoch 98/100, Val Acc=0.7403, Val Loss=1.3390, lr=0.0001
[2025-05-01 00:49:27,105][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6367, lr=0.0001
[2025-05-01 00:49:31,049][train][INFO] - Epoch 99/100, Val Acc=0.7405, Val Loss=1.3454, lr=0.0001
[2025-05-01 00:49:39,889][train][INFO] - Epoch 100/100, Val Acc=0.7383, Val Loss=1.3456, lr=0.0001
[2025-05-01 00:49:44,886][train][INFO] - After training : Train Acc=0.9994  Val Acc=0.7416
[2025-05-01 00:49:44,896][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 00:50:06,802][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6280, lr=0.0001
[2025-05-01 00:50:45,689][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6415, lr=0.0001
[2025-05-01 00:50:45,698][meta_train][INFO] - epoch_47 saved !
[2025-05-01 00:51:25,301][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6395, lr=0.0001
[2025-05-01 00:51:31,811][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 00:52:05,766][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6409, lr=0.0001
[2025-05-01 00:52:46,447][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6395, lr=0.0001
[2025-05-01 00:53:19,796][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 00:53:20,250][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 00:53:26,944][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6266, lr=0.0001
[2025-05-01 00:54:05,867][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6617, lr=0.0001
[2025-05-01 00:54:43,035][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6702, lr=0.0001
[2025-05-01 00:55:21,517][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6560, lr=0.0001
[2025-05-01 00:56:00,884][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6321, lr=0.0001
[2025-05-01 00:56:00,905][meta_train][INFO] - epoch_48 saved !
[2025-05-01 00:56:40,112][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6319, lr=0.0001
[2025-05-01 00:57:19,925][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6553, lr=0.0001
[2025-05-01 00:57:59,362][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6263, lr=0.0001
[2025-05-01 00:58:37,940][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6365, lr=0.0001
[2025-05-01 00:59:15,536][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6654, lr=0.0001
[2025-05-01 00:59:56,179][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6337, lr=0.0001
[2025-05-01 01:00:35,629][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6587, lr=0.0001
[2025-05-01 01:01:14,283][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6354, lr=0.0001
[2025-05-01 01:01:14,312][meta_train][INFO] - epoch_49 saved !
[2025-05-01 01:01:53,273][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6605, lr=0.0001
[2025-05-01 01:02:32,429][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6494, lr=0.0001
[2025-05-01 01:03:11,739][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6299, lr=0.0001
[2025-05-01 01:03:52,369][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6325, lr=0.0001
[2025-05-01 01:04:33,330][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6237, lr=0.0001
[2025-05-01 01:05:12,391][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6528, lr=0.0001
[2025-05-01 01:05:53,423][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6266, lr=0.0001
[2025-05-01 01:06:34,279][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6302, lr=0.0001
[2025-05-01 01:06:34,290][meta_train][INFO] - epoch_50 saved !
[2025-05-01 01:07:12,725][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6301, lr=0.0001
[2025-05-01 01:07:53,094][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6545, lr=0.0001
[2025-05-01 01:08:32,811][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6259, lr=0.0001
[2025-05-01 01:09:12,203][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6306, lr=0.0001
[2025-05-01 01:09:52,284][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6256, lr=0.0001
[2025-05-01 01:10:32,985][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6222, lr=0.0001
[2025-05-01 01:11:11,477][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6416, lr=0.0001
[2025-05-01 01:11:51,297][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6476, lr=0.0001
[2025-05-01 01:11:51,317][meta_train][INFO] - epoch_51 saved !
[2025-05-01 01:12:30,595][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6255, lr=0.0001
[2025-05-01 01:13:11,115][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6223, lr=0.0001
[2025-05-01 01:13:50,966][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6246, lr=0.0001
[2025-05-01 01:14:30,933][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6237, lr=0.0001
[2025-05-01 01:15:10,349][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6280, lr=0.0001
[2025-05-01 01:15:49,951][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6461, lr=0.0001
[2025-05-01 01:16:29,219][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6382, lr=0.0001
[2025-05-01 01:17:08,295][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6413, lr=0.0001
[2025-05-01 01:17:08,318][meta_train][INFO] - epoch_52 saved !
[2025-05-01 01:17:49,421][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6402, lr=0.0001
[2025-05-01 01:18:29,251][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6243, lr=0.0001
[2025-05-01 01:19:07,293][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6355, lr=0.0001
[2025-05-01 01:19:48,801][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6203, lr=0.0001
[2025-05-01 01:20:28,339][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6211, lr=0.0001
[2025-05-01 01:21:08,058][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6209, lr=0.0001
[2025-05-01 01:21:48,438][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6205, lr=0.0001
[2025-05-01 01:22:28,937][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6422, lr=0.0001
[2025-05-01 01:22:28,950][meta_train][INFO] - epoch_53 saved !
[2025-05-01 01:23:06,795][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6345, lr=0.0001
[2025-05-01 01:23:47,930][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6366, lr=0.0001
[2025-05-01 01:24:27,910][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6186, lr=0.0001
[2025-05-01 01:25:05,945][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6376, lr=0.0001
[2025-05-01 01:25:46,454][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6185, lr=0.0001
[2025-05-01 01:26:24,458][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6178, lr=0.0001
[2025-05-01 01:27:04,117][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6194, lr=0.0001
[2025-05-01 01:27:41,596][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6225, lr=0.0001
[2025-05-01 01:27:41,617][meta_train][INFO] - epoch_54 saved !
[2025-05-01 01:28:21,223][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6222, lr=0.0001
[2025-05-01 01:28:58,655][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6179, lr=0.0001
[2025-05-01 01:29:37,910][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6325, lr=0.0001
[2025-05-01 01:29:52,857][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 01:29:52,934][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 01:29:52,935][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 01:29:52,935][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 01:30:18,119][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6351, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 01:30:24,878][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 01:30:33,542][train][INFO] - Epoch 1/100, Val Acc=0.6188, Val Loss=1.7082, lr=0.0100
[2025-05-01 01:30:42,037][train][INFO] - Epoch 2/100, Val Acc=0.6543, Val Loss=1.5455, lr=0.0100
[2025-05-01 01:30:50,269][train][INFO] - Epoch 3/100, Val Acc=0.6363, Val Loss=1.5997, lr=0.0100
[2025-05-01 01:30:58,576][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-05-01 01:30:58,666][train][INFO] - Epoch 4/100, Val Acc=0.6640, Val Loss=1.5027, lr=0.0100
[2025-05-01 01:31:07,504][train][INFO] - Epoch 5/100, Val Acc=0.6494, Val Loss=1.6039, lr=0.0100
[2025-05-01 01:31:16,046][train][INFO] - Epoch 6/100, Val Acc=0.6586, Val Loss=1.5182, lr=0.0100
[2025-05-01 01:31:24,367][train][INFO] - Epoch 7/100, Val Acc=0.6484, Val Loss=1.5781, lr=0.0100
[2025-05-01 01:31:32,834][train][INFO] - Epoch 8/100, Val Acc=0.6805, Val Loss=1.4691, lr=0.0100
[2025-05-01 01:31:38,935][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6173, lr=0.0001
[2025-05-01 01:31:41,149][train][INFO] - Epoch 9/100, Val Acc=0.6739, Val Loss=1.4870, lr=0.0100
[2025-05-01 01:31:50,182][train][INFO] - Epoch 10/100, Val Acc=0.6636, Val Loss=1.5261, lr=0.0100
[2025-05-01 01:31:58,459][train][INFO] - Epoch 11/100, Val Acc=0.6674, Val Loss=1.5164, lr=0.0100
[2025-05-01 01:32:06,659][train][INFO] - Epoch 12/100, Val Acc=0.6736, Val Loss=1.4828, lr=0.0100
[2025-05-01 01:32:15,106][train][INFO] - Epoch 13/100, Val Acc=0.6743, Val Loss=1.5306, lr=0.0100
[2025-05-01 01:32:18,373][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6290, lr=0.0001
[2025-05-01 01:32:23,804][train][INFO] - Epoch 14/100, Val Acc=0.6697, Val Loss=1.5341, lr=0.0100
[2025-05-01 01:32:32,518][train][INFO] - Epoch 15/100, Val Acc=0.6609, Val Loss=1.6052, lr=0.0100
[2025-05-01 01:32:40,768][train][INFO] - Epoch 16/100, Val Acc=0.6699, Val Loss=1.5074, lr=0.0100
[2025-05-01 01:32:48,803][train][INFO] - Epoch 17/100, Val Acc=0.6758, Val Loss=1.4803, lr=0.0100
[2025-05-01 01:32:56,603][train][INFO] - Epoch 18/100, Val Acc=0.6705, Val Loss=1.5681, lr=0.0100
[2025-05-01 01:32:57,449][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6183, lr=0.0001
[2025-05-01 01:32:57,462][meta_train][INFO] - epoch_55 saved !
[2025-05-01 01:33:05,433][train][INFO] - Epoch 19/100, Val Acc=0.6838, Val Loss=1.4834, lr=0.0100
[2025-05-01 01:33:13,933][train][INFO] - Epoch 20/100, Val Acc=0.6767, Val Loss=1.4944, lr=0.0100
[2025-05-01 01:33:22,428][train][INFO] - Epoch 21/100, Val Acc=0.6552, Val Loss=1.6172, lr=0.0100
[2025-05-01 01:33:30,985][train][INFO] - Epoch 22/100, Val Acc=0.6738, Val Loss=1.5114, lr=0.0100
[2025-05-01 01:33:37,929][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6184, lr=0.0001
[2025-05-01 01:33:39,478][train][INFO] - Epoch 23/100, Val Acc=0.6806, Val Loss=1.4976, lr=0.0100
[2025-05-01 01:33:48,287][train][INFO] - Epoch 24/100, Val Acc=0.6739, Val Loss=1.5547, lr=0.0100
[2025-05-01 01:33:56,860][train][INFO] - Epoch 25/100, Val Acc=0.6817, Val Loss=1.5231, lr=0.0100
[2025-05-01 01:34:05,257][train][INFO] - Epoch 26/100, Val Acc=0.6735, Val Loss=1.5446, lr=0.0100
[2025-05-01 01:34:13,558][train][INFO] - Epoch 27/100, Val Acc=0.6869, Val Loss=1.5026, lr=0.0100
[2025-05-01 01:34:17,578][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6291, lr=0.0001
[2025-05-01 01:34:22,407][train][INFO] - Epoch 28/100, Val Acc=0.6742, Val Loss=1.5556, lr=0.0100
[2025-05-01 01:34:30,884][train][INFO] - Epoch 29/100, Val Acc=0.6777, Val Loss=1.5510, lr=0.0100
[2025-05-01 01:34:38,896][train][INFO] - Epoch 30/100, Val Acc=0.6683, Val Loss=1.5926, lr=0.0100
[2025-05-01 01:34:47,060][train][INFO] - Epoch 31/100, Val Acc=0.6793, Val Loss=1.5394, lr=0.0100
[2025-05-01 01:34:55,028][train][INFO] - Epoch 32/100, Val Acc=0.6794, Val Loss=1.5076, lr=0.0100
[2025-05-01 01:34:59,566][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6174, lr=0.0001
[2025-05-01 01:35:03,616][train][INFO] - Epoch 33/100, Val Acc=0.6630, Val Loss=1.5601, lr=0.0100
[2025-05-01 01:35:12,222][train][INFO] - Epoch 34/100, Val Acc=0.6902, Val Loss=1.4750, lr=0.0100
[2025-05-01 01:35:20,471][train][INFO] - Epoch 35/100, Val Acc=0.6673, Val Loss=1.5726, lr=0.0100
[2025-05-01 01:35:28,575][train][INFO] - Epoch 36/100, Val Acc=0.6676, Val Loss=1.5825, lr=0.0100
[2025-05-01 01:35:36,828][train][INFO] - Epoch 37/100, Val Acc=0.6550, Val Loss=1.6390, lr=0.0100
[2025-05-01 01:35:41,392][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6156, lr=0.0001
[2025-05-01 01:35:45,013][train][INFO] - Epoch 38/100, Val Acc=0.6771, Val Loss=1.5415, lr=0.0100
[2025-05-01 01:35:53,191][train][INFO] - Epoch 39/100, Val Acc=0.6690, Val Loss=1.5664, lr=0.0100
[2025-05-01 01:36:01,976][train][INFO] - Epoch 40/100, Val Acc=0.6756, Val Loss=1.5347, lr=0.0100
[2025-05-01 01:36:10,007][train][INFO] - Epoch 41/100, Val Acc=0.6724, Val Loss=1.5592, lr=0.0100
[2025-05-01 01:36:18,346][train][INFO] - Epoch 42/100, Val Acc=0.6685, Val Loss=1.5652, lr=0.0100
[2025-05-01 01:36:22,168][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6287, lr=0.0001
[2025-05-01 01:36:26,330][train][INFO] - Epoch 43/100, Val Acc=0.6741, Val Loss=1.5377, lr=0.0100
[2025-05-01 01:36:34,657][train][INFO] - Epoch 44/100, Val Acc=0.6743, Val Loss=1.5522, lr=0.0100
[2025-05-01 01:36:43,512][train][INFO] - Epoch 45/100, Val Acc=0.6625, Val Loss=1.6073, lr=0.0100
[2025-05-01 01:36:51,549][train][INFO] - Epoch 46/100, Val Acc=0.6753, Val Loss=1.5243, lr=0.0100
[2025-05-01 01:36:59,519][train][INFO] - Epoch 47/100, Val Acc=0.6644, Val Loss=1.5883, lr=0.0100
[2025-05-01 01:37:03,984][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6142, lr=0.0001
[2025-05-01 01:37:07,930][train][INFO] - Epoch 48/100, Val Acc=0.6687, Val Loss=1.5641, lr=0.0100
[2025-05-01 01:37:16,537][train][INFO] - Epoch 49/100, Val Acc=0.6664, Val Loss=1.6304, lr=0.0100
[2025-05-01 01:37:24,817][train][INFO] - Epoch 50/100, Val Acc=0.6630, Val Loss=1.6591, lr=0.0100
[2025-05-01 01:37:33,037][train][INFO] - Epoch 51/100, Val Acc=0.6689, Val Loss=1.5864, lr=0.0100
[2025-05-01 01:37:40,841][train][INFO] - Epoch 52/100, Val Acc=0.6617, Val Loss=1.6181, lr=0.0100
[2025-05-01 01:37:44,504][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6172, lr=0.0001
[2025-05-01 01:37:49,271][train][INFO] - Epoch 53/100, Val Acc=0.6707, Val Loss=1.5443, lr=0.0100
[2025-05-01 01:37:57,590][train][INFO] - Epoch 54/100, Val Acc=0.6721, Val Loss=1.5258, lr=0.0100
[2025-05-01 01:38:05,918][train][INFO] - Epoch 55/100, Val Acc=0.6767, Val Loss=1.5452, lr=0.0100
[2025-05-01 01:38:13,934][train][INFO] - Epoch 56/100, Val Acc=0.6719, Val Loss=1.5487, lr=0.0100
[2025-05-01 01:38:22,526][train][INFO] - Epoch 57/100, Val Acc=0.6732, Val Loss=1.5974, lr=0.0100
[2025-05-01 01:38:25,686][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6304, lr=0.0001
[2025-05-01 01:38:25,695][meta_train][INFO] - epoch_56 saved !
[2025-05-01 01:38:31,059][train][INFO] - Epoch 58/100, Val Acc=0.6744, Val Loss=1.5768, lr=0.0100
[2025-05-01 01:38:39,717][train][INFO] - Epoch 59/100, Val Acc=0.6558, Val Loss=1.6858, lr=0.0100
[2025-05-01 01:38:48,177][train][INFO] - Epoch 60/100, Val Acc=0.6756, Val Loss=1.5352, lr=0.0100
[2025-05-01 01:38:56,847][train][INFO] - Epoch 61/100, Val Acc=0.7251, Val Loss=1.3032, lr=0.0010
[2025-05-01 01:39:03,771][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6138, lr=0.0001
[2025-05-01 01:39:05,338][train][INFO] - Epoch 62/100, Val Acc=0.7302, Val Loss=1.2886, lr=0.0010
[2025-05-01 01:39:13,920][train][INFO] - Epoch 63/100, Val Acc=0.7326, Val Loss=1.2911, lr=0.0010
[2025-05-01 01:39:21,843][train][INFO] - Epoch 64/100, Val Acc=0.7325, Val Loss=1.2922, lr=0.0010
[2025-05-01 01:39:30,751][train][INFO] - Epoch 65/100, Val Acc=0.7335, Val Loss=1.3015, lr=0.0010
[2025-05-01 01:39:38,910][train][INFO] - Epoch 66/100, Val Acc=0.7369, Val Loss=1.3021, lr=0.0010
[2025-05-01 01:39:44,134][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6134, lr=0.0001
[2025-05-01 01:39:47,382][train][INFO] - Epoch 67/100, Val Acc=0.7361, Val Loss=1.2986, lr=0.0010
[2025-05-01 01:39:55,913][train][INFO] - Epoch 68/100, Val Acc=0.7360, Val Loss=1.3010, lr=0.0010
[2025-05-01 01:40:04,835][train][INFO] - Epoch 69/100, Val Acc=0.7354, Val Loss=1.3085, lr=0.0010
[2025-05-01 01:40:13,566][train][INFO] - Epoch 70/100, Val Acc=0.7362, Val Loss=1.3223, lr=0.0010
[2025-05-01 01:40:22,129][train][INFO] - Epoch 71/100, Val Acc=0.7359, Val Loss=1.3253, lr=0.0010
[2025-05-01 01:40:23,996][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6260, lr=0.0001
[2025-05-01 01:40:31,196][train][INFO] - Epoch 72/100, Val Acc=0.7361, Val Loss=1.3165, lr=0.0010
[2025-05-01 01:40:40,351][train][INFO] - Epoch 73/100, Val Acc=0.7380, Val Loss=1.3120, lr=0.0010
[2025-05-01 01:40:48,690][train][INFO] - Epoch 74/100, Val Acc=0.7387, Val Loss=1.3159, lr=0.0010
[2025-05-01 01:40:57,532][train][INFO] - Epoch 75/100, Val Acc=0.7381, Val Loss=1.3217, lr=0.0010
[2025-05-01 01:41:02,408][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6243, lr=0.0001
[2025-05-01 01:41:06,170][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3200, lr=0.0010
[2025-05-01 01:41:14,652][train][INFO] - Epoch 77/100, Val Acc=0.7390, Val Loss=1.3122, lr=0.0010
[2025-05-01 01:41:23,404][train][INFO] - Epoch 78/100, Val Acc=0.7391, Val Loss=1.3155, lr=0.0010
[2025-05-01 01:41:32,032][train][INFO] - Epoch 79/100, Val Acc=0.7396, Val Loss=1.3194, lr=0.0010
[2025-05-01 01:41:39,954][train][INFO] - Epoch 80/100, Val Acc=0.7395, Val Loss=1.3198, lr=0.0010
[2025-05-01 01:41:43,551][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6161, lr=0.0001
[2025-05-01 01:41:48,677][train][INFO] - Epoch 81/100, Val Acc=0.7388, Val Loss=1.3287, lr=0.0010
[2025-05-01 01:41:56,688][train][INFO] - Epoch 82/100, Val Acc=0.7366, Val Loss=1.3309, lr=0.0010
[2025-05-01 01:42:04,674][train][INFO] - Epoch 83/100, Val Acc=0.7381, Val Loss=1.3307, lr=0.0010
[2025-05-01 01:42:12,769][train][INFO] - Epoch 84/100, Val Acc=0.7395, Val Loss=1.3246, lr=0.0010
[2025-05-01 01:42:20,933][train][INFO] - Epoch 85/100, Val Acc=0.7403, Val Loss=1.3187, lr=0.0010
[2025-05-01 01:42:24,264][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6290, lr=0.0001
[2025-05-01 01:42:29,685][train][INFO] - Epoch 86/100, Val Acc=0.7399, Val Loss=1.3301, lr=0.0010
[2025-05-01 01:42:37,015][train][INFO] - Epoch 87/100, Val Acc=0.7416, Val Loss=1.3206, lr=0.0010
[2025-05-01 01:42:45,147][train][INFO] - Epoch 88/100, Val Acc=0.7412, Val Loss=1.3196, lr=0.0010
[2025-05-01 01:42:53,026][train][INFO] - Epoch 89/100, Val Acc=0.7402, Val Loss=1.3181, lr=0.0010
[2025-05-01 01:43:01,213][train][INFO] - Epoch 90/100, Val Acc=0.7401, Val Loss=1.3223, lr=0.0010
[2025-05-01 01:43:04,850][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6153, lr=0.0001
[2025-05-01 01:43:09,200][train][INFO] - Epoch 91/100, Val Acc=0.7411, Val Loss=1.3188, lr=0.0001
[2025-05-01 01:43:17,287][train][INFO] - Epoch 92/100, Val Acc=0.7409, Val Loss=1.3205, lr=0.0001
[2025-05-01 01:43:25,243][train][INFO] - Epoch 93/100, Val Acc=0.7404, Val Loss=1.3183, lr=0.0001
[2025-05-01 01:43:33,114][train][INFO] - Epoch 94/100, Val Acc=0.7426, Val Loss=1.3141, lr=0.0001
[2025-05-01 01:43:41,316][train][INFO] - Epoch 95/100, Val Acc=0.7405, Val Loss=1.3248, lr=0.0001
[2025-05-01 01:43:45,009][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6171, lr=0.0001
[2025-05-01 01:43:45,020][meta_train][INFO] - epoch_57 saved !
[2025-05-01 01:43:49,715][train][INFO] - Epoch 96/100, Val Acc=0.7426, Val Loss=1.3134, lr=0.0001
[2025-05-01 01:43:57,795][train][INFO] - Epoch 97/100, Val Acc=0.7416, Val Loss=1.3142, lr=0.0001
[2025-05-01 01:44:05,878][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3133, lr=0.0001
[2025-05-01 01:44:13,851][train][INFO] - Epoch 99/100, Val Acc=0.7415, Val Loss=1.3152, lr=0.0001
[2025-05-01 01:44:21,794][train][INFO] - Epoch 100/100, Val Acc=0.7411, Val Loss=1.3170, lr=0.0001
[2025-05-01 01:44:25,661][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6257, lr=0.0001
[2025-05-01 01:44:27,234][train][INFO] - After training : Train Acc=0.9992  Val Acc=0.7426
[2025-05-01 01:44:27,238][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 01:45:07,914][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6142, lr=0.0001
[2025-05-01 01:45:48,299][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6322, lr=0.0001
[2025-05-01 01:46:30,855][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6255, lr=0.0001
[2025-05-01 01:46:32,353][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 01:47:11,412][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6147, lr=0.0001
[2025-05-01 01:47:52,024][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6144, lr=0.0001
[2025-05-01 01:48:33,538][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6112, lr=0.0001
[2025-05-01 01:48:38,291][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 01:48:38,752][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 01:49:15,286][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6151, lr=0.0001
[2025-05-01 01:49:15,310][meta_train][INFO] - epoch_58 saved !
[2025-05-01 01:49:57,311][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6133, lr=0.0001
[2025-05-01 01:50:39,684][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6210, lr=0.0001
[2025-05-01 01:51:19,902][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6147, lr=0.0001
[2025-05-01 01:52:02,548][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6229, lr=0.0001
[2025-05-01 01:52:43,779][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6273, lr=0.0001
[2025-05-01 01:53:25,379][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6115, lr=0.0001
[2025-05-01 01:54:03,216][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6114, lr=0.0001
[2025-05-01 01:54:43,294][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6156, lr=0.0001
[2025-05-01 01:54:43,306][meta_train][INFO] - epoch_59 saved !
[2025-05-01 01:55:21,679][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6251, lr=0.0001
[2025-05-01 01:56:03,119][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6135, lr=0.0001
[2025-05-01 01:56:44,213][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6135, lr=0.0001
[2025-05-01 01:57:23,463][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 01:58:03,471][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6101, lr=0.0001
[2025-05-01 01:58:43,992][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6148, lr=0.0001
[2025-05-01 01:59:22,990][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6189, lr=0.0001
[2025-05-01 02:00:03,646][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6200, lr=0.0001
[2025-05-01 02:00:03,660][meta_train][INFO] - epoch_60 saved !
[2025-05-01 02:00:45,320][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6135, lr=0.0001
[2025-05-01 02:01:26,199][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6156, lr=0.0001
[2025-05-01 02:02:05,316][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6204, lr=0.0001
[2025-05-01 02:02:46,190][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:03:26,887][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6098, lr=0.0001
[2025-05-01 02:04:05,575][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6170, lr=0.0001
[2025-05-01 02:04:45,797][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6195, lr=0.0001
[2025-05-01 02:05:25,905][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6111, lr=0.0001
[2025-05-01 02:05:25,922][meta_train][INFO] - epoch_61 saved !
[2025-05-01 02:06:06,984][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6117, lr=0.0001
[2025-05-01 02:06:47,370][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6169, lr=0.0001
[2025-05-01 02:07:27,060][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:08:08,086][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6099, lr=0.0001
[2025-05-01 02:08:47,391][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6150, lr=0.0001
[2025-05-01 02:09:27,708][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6183, lr=0.0001
[2025-05-01 02:10:08,862][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:10:49,268][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6199, lr=0.0001
[2025-05-01 02:10:49,285][meta_train][INFO] - epoch_62 saved !
[2025-05-01 02:11:29,075][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6161, lr=0.0001
[2025-05-01 02:12:08,484][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6087, lr=0.0001
[2025-05-01 02:12:49,298][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6153, lr=0.0001
[2025-05-01 02:13:29,960][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:14:09,156][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6086, lr=0.0001
[2025-05-01 02:14:49,555][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6141, lr=0.0001
[2025-05-01 02:15:30,589][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:16:11,023][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6211, lr=0.0001
[2025-05-01 02:16:11,046][meta_train][INFO] - epoch_63 saved !
[2025-05-01 02:16:49,787][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6208, lr=0.0001
[2025-05-01 02:17:30,966][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6111, lr=0.0001
[2025-05-01 02:18:09,318][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6085, lr=0.0001
[2025-05-01 02:18:50,132][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:19:31,486][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6140, lr=0.0001
[2025-05-01 02:20:10,852][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6132, lr=0.0001
[2025-05-01 02:20:51,860][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6145, lr=0.0001
[2025-05-01 02:21:32,167][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6085, lr=0.0001
[2025-05-01 02:21:32,190][meta_train][INFO] - epoch_64 saved !
[2025-05-01 02:22:12,503][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6157, lr=0.0001
[2025-05-01 02:22:52,569][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6158, lr=0.0001
[2025-05-01 02:23:32,232][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:24:11,911][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6081, lr=0.0001
[2025-05-01 02:24:52,584][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6077, lr=0.0001
[2025-05-01 02:25:33,178][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6158, lr=0.0001
[2025-05-01 02:26:13,328][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6133, lr=0.0001
[2025-05-01 02:26:54,070][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6108, lr=0.0001
[2025-05-01 02:26:54,092][meta_train][INFO] - epoch_65 saved !
[2025-05-01 02:27:35,125][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6136, lr=0.0001
[2025-05-01 02:28:14,135][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6080, lr=0.0001
[2025-05-01 02:28:55,403][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6103, lr=0.0001
[2025-05-01 02:29:36,614][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6131, lr=0.0001
[2025-05-01 02:30:16,200][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:30:56,717][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6093, lr=0.0001
[2025-05-01 02:31:36,594][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6133, lr=0.0001
[2025-05-01 02:32:17,637][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6166, lr=0.0001
[2025-05-01 02:32:17,659][meta_train][INFO] - epoch_66 saved !
[2025-05-01 02:32:57,534][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6078, lr=0.0001
[2025-05-01 02:33:36,780][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6136, lr=0.0001
[2025-05-01 02:34:17,163][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6094, lr=0.0001
[2025-05-01 02:34:58,711][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6143, lr=0.0001
[2025-05-01 02:35:37,871][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6126, lr=0.0001
[2025-05-01 02:36:17,522][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:36:57,741][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6101, lr=0.0001
[2025-05-01 02:37:38,320][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6131, lr=0.0001
[2025-05-01 02:37:38,330][meta_train][INFO] - epoch_67 saved !
[2025-05-01 02:38:17,346][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 02:38:55,790][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:39:35,380][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6118, lr=0.0001
[2025-05-01 02:40:14,590][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6123, lr=0.0001
[2025-05-01 02:40:55,299][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:41:35,270][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6074, lr=0.0001
[2025-05-01 02:42:13,708][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6091, lr=0.0001
[2025-05-01 02:42:52,698][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6143, lr=0.0001
[2025-05-01 02:42:52,709][meta_train][INFO] - epoch_68 saved !
[2025-05-01 02:43:33,944][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6095, lr=0.0001
[2025-05-01 02:44:13,861][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 02:44:52,475][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:45:31,704][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6082, lr=0.0001
[2025-05-01 02:46:11,357][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-05-01 02:46:49,881][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6114, lr=0.0001
[2025-05-01 02:47:29,744][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6141, lr=0.0001
[2025-05-01 02:48:09,707][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6121, lr=0.0001
[2025-05-01 02:48:09,722][meta_train][INFO] - epoch_69 saved !
[2025-05-01 02:48:51,419][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6069, lr=0.0001
[2025-05-01 02:49:30,903][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-05-01 02:50:12,348][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6121, lr=0.0001
[2025-05-01 02:50:51,045][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6122, lr=0.0001
[2025-05-01 02:51:31,787][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6106, lr=0.0001
[2025-05-01 02:52:10,410][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6068, lr=0.0001
[2025-05-01 02:52:50,702][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6080, lr=0.0001
[2025-05-01 02:53:31,593][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6105, lr=0.0001
[2025-05-01 02:53:31,606][meta_train][INFO] - epoch_70 saved !
[2025-05-01 02:54:10,333][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 02:54:49,730][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6079, lr=0.0001
[2025-05-01 02:55:30,089][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6089, lr=0.0001
[2025-05-01 02:56:11,053][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-05-01 02:56:50,633][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6120, lr=0.0001
[2025-05-01 02:57:29,561][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6103, lr=0.0001
[2025-05-01 02:58:11,154][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 02:58:53,016][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6104, lr=0.0001
[2025-05-01 02:58:53,040][meta_train][INFO] - epoch_71 saved !
[2025-05-01 02:59:34,082][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:00:14,585][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6101, lr=0.0001
[2025-05-01 03:00:54,075][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6080, lr=0.0001
[2025-05-01 03:01:34,955][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6119, lr=0.0001
[2025-05-01 03:02:15,809][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6089, lr=0.0001
[2025-05-01 03:02:56,948][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6101, lr=0.0001
[2025-05-01 03:03:35,419][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6105, lr=0.0001
[2025-05-01 03:04:15,073][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6064, lr=0.0001
[2025-05-01 03:04:15,097][meta_train][INFO] - epoch_72 saved !
[2025-05-01 03:04:55,862][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:05:34,579][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:06:14,635][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6076, lr=0.0001
[2025-05-01 03:06:54,113][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6096, lr=0.0001
[2025-05-01 03:07:34,489][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:08:13,889][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6112, lr=0.0001
[2025-05-01 03:08:52,955][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6116, lr=0.0001
[2025-05-01 03:09:32,669][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:09:32,680][meta_train][INFO] - epoch_73 saved !
[2025-05-01 03:10:13,453][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6115, lr=0.0001
[2025-05-01 03:10:53,401][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6104, lr=0.0001
[2025-05-01 03:11:33,626][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:12:12,701][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:12:52,938][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:13:32,814][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:14:13,238][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 03:14:53,342][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6078, lr=0.0001
[2025-05-01 03:14:53,353][meta_train][INFO] - epoch_74 saved !
[2025-05-01 03:15:32,441][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:16:13,405][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6113, lr=0.0001
[2025-05-01 03:16:52,489][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:17:33,458][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 03:18:12,478][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:18:53,727][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:19:33,920][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6089, lr=0.0001
[2025-05-01 03:20:12,315][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:20:12,338][meta_train][INFO] - epoch_75 saved !
[2025-05-01 03:20:53,188][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:21:34,476][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6063, lr=0.0001
[2025-05-01 03:22:13,098][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:22:53,902][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6110, lr=0.0001
[2025-05-01 03:23:33,149][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6083, lr=0.0001
[2025-05-01 03:24:14,419][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:24:55,943][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 03:25:36,592][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6079, lr=0.0001
[2025-05-01 03:25:36,612][meta_train][INFO] - epoch_76 saved !
[2025-05-01 03:26:15,787][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6079, lr=0.0001
[2025-05-01 03:26:56,230][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 03:27:37,928][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6110, lr=0.0001
[2025-05-01 03:28:17,480][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6087, lr=0.0001
[2025-05-01 03:28:57,821][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6095, lr=0.0001
[2025-05-01 03:29:38,436][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:30:19,278][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:30:58,172][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:30:58,182][meta_train][INFO] - epoch_77 saved !
[2025-05-01 03:31:38,070][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6065, lr=0.0001
[2025-05-01 03:32:18,563][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:32:59,201][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6105, lr=0.0001
[2025-05-01 03:33:39,852][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:34:19,920][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6091, lr=0.0001
[2025-05-01 03:34:59,204][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6113, lr=0.0001
[2025-05-01 03:35:40,497][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 03:36:20,888][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-05-01 03:36:20,905][meta_train][INFO] - epoch_78 saved !
[2025-05-01 03:37:01,061][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:37:40,523][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:38:20,253][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:39:01,795][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:39:41,425][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6104, lr=0.0001
[2025-05-01 03:40:22,676][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6060, lr=0.0001
[2025-05-01 03:41:03,452][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6098, lr=0.0001
[2025-05-01 03:41:43,653][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6071, lr=0.0001
[2025-05-01 03:41:43,667][meta_train][INFO] - epoch_79 saved !
[2025-05-01 03:42:23,570][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:43:02,424][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:43:43,188][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:44:24,626][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6078, lr=0.0001
[2025-05-01 03:45:03,862][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6068, lr=0.0001
[2025-05-01 03:45:43,995][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:46:24,630][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6084, lr=0.0001
[2025-05-01 03:47:05,525][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:47:05,539][meta_train][INFO] - epoch_80 saved !
[2025-05-01 03:47:45,021][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6068, lr=0.0001
[2025-05-01 03:48:24,897][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:49:04,609][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6083, lr=0.0001
[2025-05-01 03:49:45,261][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:50:24,636][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6074, lr=0.0001
[2025-05-01 03:51:05,175][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6100, lr=0.0001
[2025-05-01 03:51:45,732][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:52:26,928][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:52:26,951][meta_train][INFO] - epoch_81 saved !
[2025-05-01 03:53:05,891][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6075, lr=0.0001
[2025-05-01 03:53:46,147][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6077, lr=0.0001
[2025-05-01 03:54:26,095][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6082, lr=0.0001
[2025-05-01 03:55:07,545][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6073, lr=0.0001
[2025-05-01 03:55:48,130][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6058, lr=0.0001
[2025-05-01 03:56:26,664][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6066, lr=0.0001
[2025-05-01 03:57:05,968][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 03:57:46,700][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6097, lr=0.0001
[2025-05-01 03:57:46,713][meta_train][INFO] - epoch_82 saved !
[2025-05-01 03:58:26,003][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6082, lr=0.0001
[2025-05-01 03:59:06,148][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 03:59:45,555][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6074, lr=0.0001
[2025-05-01 04:00:25,495][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:01:04,914][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:01:44,494][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:02:24,336][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:03:03,666][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:03:03,685][meta_train][INFO] - epoch_83 saved !
[2025-05-01 04:03:44,221][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:04:23,832][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:05:03,756][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:05:42,956][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:06:21,990][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:07:01,263][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:07:41,196][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:08:22,550][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:08:22,562][meta_train][INFO] - epoch_84 saved !
[2025-05-01 04:09:01,236][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6096, lr=0.0001
[2025-05-01 04:09:40,297][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:10:18,130][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:10:57,515][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:11:36,716][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:12:15,325][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:12:53,520][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:13:33,416][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-01 04:13:33,430][meta_train][INFO] - epoch_85 saved !
[2025-05-01 04:14:12,255][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6073, lr=0.0001
[2025-05-01 04:14:52,355][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:15:32,655][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:16:10,857][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6091, lr=0.0001
[2025-05-01 04:16:50,561][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:17:29,620][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6072, lr=0.0001
[2025-05-01 04:18:08,631][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:18:47,714][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:18:47,732][meta_train][INFO] - epoch_86 saved !
[2025-05-01 04:19:27,864][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6071, lr=0.0001
[2025-05-01 04:20:05,760][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6070, lr=0.0001
[2025-05-01 04:20:45,180][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:21:23,420][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6072, lr=0.0001
[2025-05-01 04:22:02,254][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:22:41,101][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:23:20,143][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:24:00,350][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6091, lr=0.0001
[2025-05-01 04:24:00,371][meta_train][INFO] - epoch_87 saved !
[2025-05-01 04:24:39,851][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:25:17,763][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6093, lr=0.0001
[2025-05-01 04:25:57,338][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:26:37,173][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6069, lr=0.0001
[2025-05-01 04:27:16,524][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:27:54,879][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:28:33,799][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:29:12,356][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:29:12,369][meta_train][INFO] - epoch_88 saved !
[2025-05-01 04:29:50,741][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:30:30,753][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:31:10,652][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6075, lr=0.0001
[2025-05-01 04:31:49,685][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:32:27,886][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:33:07,047][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6087, lr=0.0001
[2025-05-01 04:33:46,686][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:34:25,027][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:34:25,049][meta_train][INFO] - epoch_89 saved !
[2025-05-01 04:35:04,993][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6089, lr=0.0001
[2025-05-01 04:35:44,571][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:36:24,101][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6068, lr=0.0001
[2025-05-01 04:37:02,464][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6065, lr=0.0001
[2025-05-01 04:37:42,532][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:38:20,658][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:39:00,674][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:39:38,545][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:39:38,559][meta_train][INFO] - epoch_90 saved !
[2025-05-01 04:40:18,034][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6088, lr=0.0001
[2025-05-01 04:40:56,753][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:41:36,108][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:42:16,318][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6068, lr=0.0001
[2025-05-01 04:42:54,111][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6064, lr=0.0001
[2025-05-01 04:43:34,149][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:44:12,758][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:44:51,661][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:44:51,685][meta_train][INFO] - epoch_91 saved !
[2025-05-01 04:45:30,341][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:46:08,508][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:46:48,156][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:47:28,566][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:48:06,835][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:48:45,454][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:49:24,623][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:50:04,979][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6086, lr=0.0001
[2025-05-01 04:50:05,005][meta_train][INFO] - epoch_92 saved !
[2025-05-01 04:50:44,207][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6066, lr=0.0001
[2025-05-01 04:51:23,378][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-01 04:52:02,678][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6064, lr=0.0001
[2025-05-01 04:52:41,100][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:53:18,961][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:53:58,473][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6055, lr=0.0001
[2025-05-01 04:54:38,131][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6085, lr=0.0001
[2025-05-01 04:55:17,654][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6067, lr=0.0001
[2025-05-01 04:55:17,670][meta_train][INFO] - epoch_93 saved !
[2025-05-01 04:55:57,531][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6063, lr=0.0001
[2025-05-01 04:56:37,372][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6056, lr=0.0001
[2025-05-01 04:57:17,485][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6062, lr=0.0001
[2025-05-01 04:57:57,760][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6061, lr=0.0001
[2025-05-01 04:58:39,657][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6083, lr=0.0001
[2025-05-01 04:59:19,345][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6064, lr=0.0001
[2025-05-01 05:00:00,313][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6065, lr=0.0001
[2025-05-01 05:00:41,567][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:00:41,580][meta_train][INFO] - epoch_94 saved !
[2025-05-01 05:01:22,537][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:02:03,906][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6083, lr=0.0001
[2025-05-01 05:02:46,167][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:03:26,394][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:04:06,077][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:04:47,097][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:05:29,320][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:06:09,609][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:06:09,634][meta_train][INFO] - epoch_95 saved !
[2025-05-01 05:06:49,662][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:07:30,126][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:08:10,295][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:08:49,369][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:09:28,843][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:10:09,335][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6083, lr=0.0001
[2025-05-01 05:10:50,324][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:11:31,033][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:11:31,050][meta_train][INFO] - epoch_96 saved !
[2025-05-01 05:12:11,214][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:12:51,014][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:13:30,014][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:14:09,940][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:14:51,469][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-01 05:15:29,979][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:16:11,034][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6061, lr=0.0001
[2025-05-01 05:16:51,379][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6082, lr=0.0001
[2025-05-01 05:16:51,389][meta_train][INFO] - epoch_97 saved !
[2025-05-01 05:17:32,067][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:18:11,260][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:18:52,383][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:19:31,216][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:20:11,323][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:20:51,169][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:21:30,968][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:22:11,696][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6063, lr=0.0001
[2025-05-01 05:22:11,718][meta_train][INFO] - epoch_98 saved !
[2025-05-01 05:22:50,886][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:23:31,642][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:24:11,469][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:24:50,403][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:25:30,656][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:26:10,717][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:26:50,859][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:27:31,083][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:27:31,100][meta_train][INFO] - epoch_99 saved !
[2025-05-01 05:28:11,410][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6081, lr=0.0001
[2025-05-01 05:28:50,237][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:29:30,316][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-01 05:30:10,024][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:30:50,408][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-01 05:31:31,262][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:32:11,505][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6058, lr=0.0001
[2025-05-01 05:32:50,931][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-01 05:32:50,941][meta_train][INFO] - epoch_100 saved !
[2025-05-01 11:44:03,653][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 11:44:03,708][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 11:44:35,765][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 50
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Carol
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 11:44:35,858][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 11:45:04,993][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 11:45:13,737][train][INFO] - Epoch 1/100, Val Acc=0.6087, Val Loss=1.6476, lr=0.0100
[2025-05-01 11:45:21,996][train][INFO] - Epoch 2/100, Val Acc=0.6130, Val Loss=1.6572, lr=0.0100
[2025-05-01 11:45:30,003][train][INFO] - Epoch 3/100, Val Acc=0.6248, Val Loss=1.6061, lr=0.0100
[2025-05-01 11:45:38,062][train][INFO] - Epoch 4/100, Val Acc=0.6433, Val Loss=1.5141, lr=0.0100
[2025-05-01 11:45:46,742][train][INFO] - Epoch 5/100, Val Acc=0.6407, Val Loss=1.5735, lr=0.0100
[2025-05-01 11:45:55,036][train][INFO] - Epoch 6/100, Val Acc=0.6615, Val Loss=1.4623, lr=0.0100
[2025-05-01 11:46:02,851][train][INFO] - Epoch 7/100, Val Acc=0.6550, Val Loss=1.4965, lr=0.0100
[2025-05-01 11:46:11,013][train][INFO] - Epoch 8/100, Val Acc=0.6571, Val Loss=1.5628, lr=0.0100
[2025-05-01 11:46:19,419][train][INFO] - Epoch 9/100, Val Acc=0.6499, Val Loss=1.5558, lr=0.0100
[2025-05-01 11:46:28,489][train][INFO] - Epoch 10/100, Val Acc=0.6550, Val Loss=1.5181, lr=0.0100
[2025-05-01 11:46:37,132][train][INFO] - Epoch 11/100, Val Acc=0.6772, Val Loss=1.4299, lr=0.0100
[2025-05-01 11:46:44,946][train][INFO] - Epoch 12/100, Val Acc=0.6580, Val Loss=1.5072, lr=0.0100
[2025-05-01 11:46:53,121][train][INFO] - Epoch 13/100, Val Acc=0.6585, Val Loss=1.5412, lr=0.0100
[2025-05-01 11:47:01,551][train][INFO] - Epoch 14/100, Val Acc=0.6786, Val Loss=1.5074, lr=0.0100
[2025-05-01 11:47:09,810][train][INFO] - Epoch 15/100, Val Acc=0.6617, Val Loss=1.5728, lr=0.0100
[2025-05-01 11:47:17,732][train][INFO] - Epoch 16/100, Val Acc=0.6681, Val Loss=1.5066, lr=0.0100
[2025-05-01 11:47:24,989][train][INFO] - Epoch 17/100, Val Acc=0.6870, Val Loss=1.4066, lr=0.0100
[2025-05-01 11:47:33,295][train][INFO] - Epoch 18/100, Val Acc=0.6651, Val Loss=1.5411, lr=0.0100
[2025-05-01 11:47:41,121][train][INFO] - Epoch 19/100, Val Acc=0.6737, Val Loss=1.5166, lr=0.0100
[2025-05-01 11:47:49,993][train][INFO] - Epoch 20/100, Val Acc=0.6717, Val Loss=1.5219, lr=0.0100
[2025-05-01 11:47:57,851][train][INFO] - Epoch 21/100, Val Acc=0.6805, Val Loss=1.4347, lr=0.0100
[2025-05-01 11:48:06,058][train][INFO] - Epoch 22/100, Val Acc=0.6693, Val Loss=1.5336, lr=0.0100
[2025-05-01 11:48:13,752][train][INFO] - Epoch 23/100, Val Acc=0.6820, Val Loss=1.4631, lr=0.0100
[2025-05-01 11:48:21,648][train][INFO] - Epoch 24/100, Val Acc=0.6793, Val Loss=1.4986, lr=0.0100
[2025-05-01 11:48:30,013][train][INFO] - Epoch 25/100, Val Acc=0.6760, Val Loss=1.5220, lr=0.0100
[2025-05-01 11:48:38,525][train][INFO] - Epoch 26/100, Val Acc=0.6807, Val Loss=1.5162, lr=0.0100
[2025-05-01 11:48:46,700][train][INFO] - Epoch 27/100, Val Acc=0.6702, Val Loss=1.5688, lr=0.0100
[2025-05-01 11:48:55,079][train][INFO] - Epoch 28/100, Val Acc=0.6706, Val Loss=1.5441, lr=0.0100
[2025-05-01 11:49:03,078][train][INFO] - Epoch 29/100, Val Acc=0.6557, Val Loss=1.6561, lr=0.0100
[2025-05-01 11:49:11,447][train][INFO] - Epoch 30/100, Val Acc=0.6761, Val Loss=1.5481, lr=0.0100
[2025-05-01 11:49:18,815][train][INFO] - Epoch 31/100, Val Acc=0.6792, Val Loss=1.4999, lr=0.0100
[2025-05-01 11:49:27,488][train][INFO] - Epoch 32/100, Val Acc=0.6735, Val Loss=1.5509, lr=0.0100
[2025-05-01 11:49:35,680][train][INFO] - Epoch 33/100, Val Acc=0.6647, Val Loss=1.5593, lr=0.0100
[2025-05-01 11:49:43,982][train][INFO] - Epoch 34/100, Val Acc=0.6764, Val Loss=1.5105, lr=0.0100
[2025-05-01 11:49:52,268][train][INFO] - Epoch 35/100, Val Acc=0.6728, Val Loss=1.5446, lr=0.0100
[2025-05-01 11:50:00,616][train][INFO] - Epoch 36/100, Val Acc=0.6698, Val Loss=1.5613, lr=0.0100
[2025-05-01 11:50:09,689][train][INFO] - Epoch 37/100, Val Acc=0.6718, Val Loss=1.5142, lr=0.0100
[2025-05-01 11:50:17,077][train][INFO] - Epoch 38/100, Val Acc=0.6816, Val Loss=1.4852, lr=0.0100
[2025-05-01 11:50:24,997][train][INFO] - Epoch 39/100, Val Acc=0.6804, Val Loss=1.4926, lr=0.0100
[2025-05-01 11:50:33,021][train][INFO] - Epoch 40/100, Val Acc=0.6737, Val Loss=1.5205, lr=0.0100
[2025-05-01 11:50:41,172][train][INFO] - Epoch 41/100, Val Acc=0.6753, Val Loss=1.5343, lr=0.0100
[2025-05-01 11:50:50,005][train][INFO] - Epoch 42/100, Val Acc=0.6777, Val Loss=1.5098, lr=0.0100
[2025-05-01 11:50:58,778][train][INFO] - Epoch 43/100, Val Acc=0.6801, Val Loss=1.4731, lr=0.0100
[2025-05-01 11:51:07,830][train][INFO] - Epoch 44/100, Val Acc=0.6687, Val Loss=1.5526, lr=0.0100
[2025-05-01 11:51:16,675][train][INFO] - Epoch 45/100, Val Acc=0.6716, Val Loss=1.5366, lr=0.0100
[2025-05-01 11:51:24,822][train][INFO] - Epoch 46/100, Val Acc=0.6782, Val Loss=1.5464, lr=0.0100
[2025-05-01 11:51:32,998][train][INFO] - Epoch 47/100, Val Acc=0.6698, Val Loss=1.5436, lr=0.0100
[2025-05-01 11:51:41,674][train][INFO] - Epoch 48/100, Val Acc=0.6716, Val Loss=1.5714, lr=0.0100
[2025-05-01 11:51:49,834][train][INFO] - Epoch 49/100, Val Acc=0.6752, Val Loss=1.5529, lr=0.0100
[2025-05-01 11:51:58,524][train][INFO] - Epoch 50/100, Val Acc=0.6737, Val Loss=1.5448, lr=0.0100
[2025-05-01 11:52:07,094][train][INFO] - Epoch 51/100, Val Acc=0.6630, Val Loss=1.5604, lr=0.0100
[2025-05-01 11:52:15,814][train][INFO] - Epoch 52/100, Val Acc=0.6734, Val Loss=1.5669, lr=0.0100
[2025-05-01 11:52:23,581][train][INFO] - Epoch 53/100, Val Acc=0.6715, Val Loss=1.5753, lr=0.0100
[2025-05-01 11:52:32,049][train][INFO] - Epoch 54/100, Val Acc=0.6763, Val Loss=1.4942, lr=0.0100
[2025-05-01 11:52:40,803][train][INFO] - Epoch 55/100, Val Acc=0.6732, Val Loss=1.5552, lr=0.0100
[2025-05-01 11:52:47,727][train][INFO] - Epoch 56/100, Val Acc=0.6560, Val Loss=1.6783, lr=0.0100
[2025-05-01 11:52:55,544][train][INFO] - Epoch 57/100, Val Acc=0.6798, Val Loss=1.5230, lr=0.0100
[2025-05-01 11:53:03,538][train][INFO] - Epoch 58/100, Val Acc=0.6672, Val Loss=1.5792, lr=0.0100
[2025-05-01 11:53:11,830][train][INFO] - Epoch 59/100, Val Acc=0.6537, Val Loss=1.6794, lr=0.0100
[2025-05-01 11:53:20,005][train][INFO] - Epoch 60/100, Val Acc=0.6744, Val Loss=1.5546, lr=0.0100
[2025-05-01 11:53:28,331][train][INFO] - Epoch 61/100, Val Acc=0.7233, Val Loss=1.2964, lr=0.0010
[2025-05-01 11:53:36,453][train][INFO] - Epoch 62/100, Val Acc=0.7283, Val Loss=1.2836, lr=0.0010
[2025-05-01 11:53:44,609][train][INFO] - Epoch 63/100, Val Acc=0.7315, Val Loss=1.2998, lr=0.0010
[2025-05-01 11:53:52,713][train][INFO] - Epoch 64/100, Val Acc=0.7299, Val Loss=1.2992, lr=0.0010
[2025-05-01 11:54:00,579][train][INFO] - Epoch 65/100, Val Acc=0.7333, Val Loss=1.3034, lr=0.0010
[2025-05-01 11:54:08,639][train][INFO] - Epoch 66/100, Val Acc=0.7316, Val Loss=1.3103, lr=0.0010
[2025-05-01 11:54:17,564][train][INFO] - Epoch 67/100, Val Acc=0.7326, Val Loss=1.3113, lr=0.0010
[2025-05-01 11:54:26,117][train][INFO] - Epoch 68/100, Val Acc=0.7360, Val Loss=1.3100, lr=0.0010
[2025-05-01 11:54:34,131][train][INFO] - Epoch 69/100, Val Acc=0.7365, Val Loss=1.3156, lr=0.0010
[2025-05-01 11:54:42,453][train][INFO] - Epoch 70/100, Val Acc=0.7352, Val Loss=1.3227, lr=0.0010
[2025-05-01 11:54:51,187][train][INFO] - Epoch 71/100, Val Acc=0.7338, Val Loss=1.3248, lr=0.0010
[2025-05-01 11:54:59,941][train][INFO] - Epoch 72/100, Val Acc=0.7364, Val Loss=1.3299, lr=0.0010
[2025-05-01 11:55:08,663][train][INFO] - Epoch 73/100, Val Acc=0.7375, Val Loss=1.3243, lr=0.0010
[2025-05-01 11:55:16,844][train][INFO] - Epoch 74/100, Val Acc=0.7360, Val Loss=1.3221, lr=0.0010
[2025-05-01 11:55:25,313][train][INFO] - Epoch 75/100, Val Acc=0.7367, Val Loss=1.3240, lr=0.0010
[2025-05-01 11:55:32,840][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3159, lr=0.0010
[2025-05-01 11:55:40,645][train][INFO] - Epoch 77/100, Val Acc=0.7374, Val Loss=1.3225, lr=0.0010
[2025-05-01 11:55:47,929][train][INFO] - Epoch 78/100, Val Acc=0.7384, Val Loss=1.3189, lr=0.0010
[2025-05-01 11:55:56,711][train][INFO] - Epoch 79/100, Val Acc=0.7368, Val Loss=1.3276, lr=0.0010
[2025-05-01 11:56:05,062][train][INFO] - Epoch 80/100, Val Acc=0.7372, Val Loss=1.3189, lr=0.0010
[2025-05-01 11:56:13,306][train][INFO] - Epoch 81/100, Val Acc=0.7384, Val Loss=1.3231, lr=0.0010
[2025-05-01 11:56:21,893][train][INFO] - Epoch 82/100, Val Acc=0.7413, Val Loss=1.3198, lr=0.0010
[2025-05-01 11:56:30,096][train][INFO] - Epoch 83/100, Val Acc=0.7402, Val Loss=1.3208, lr=0.0010
[2025-05-01 11:56:38,058][train][INFO] - Epoch 84/100, Val Acc=0.7401, Val Loss=1.3150, lr=0.0010
[2025-05-01 11:56:46,048][train][INFO] - Epoch 85/100, Val Acc=0.7398, Val Loss=1.3182, lr=0.0010
[2025-05-01 11:56:53,466][train][INFO] - Epoch 86/100, Val Acc=0.7413, Val Loss=1.3171, lr=0.0010
[2025-05-01 11:57:01,499][train][INFO] - Epoch 87/100, Val Acc=0.7414, Val Loss=1.3109, lr=0.0010
[2025-05-01 11:57:09,772][train][INFO] - Epoch 88/100, Val Acc=0.7393, Val Loss=1.3140, lr=0.0010
[2025-05-01 11:57:17,559][train][INFO] - Epoch 89/100, Val Acc=0.7399, Val Loss=1.3115, lr=0.0010
[2025-05-01 11:57:25,450][train][INFO] - Epoch 90/100, Val Acc=0.7383, Val Loss=1.3233, lr=0.0010
[2025-05-01 11:57:34,073][train][INFO] - Epoch 91/100, Val Acc=0.7389, Val Loss=1.3172, lr=0.0001
[2025-05-01 11:57:42,388][train][INFO] - Epoch 92/100, Val Acc=0.7400, Val Loss=1.3199, lr=0.0001
[2025-05-01 11:57:50,539][train][INFO] - Epoch 93/100, Val Acc=0.7388, Val Loss=1.3140, lr=0.0001
[2025-05-01 11:57:58,680][train][INFO] - Epoch 94/100, Val Acc=0.7409, Val Loss=1.3118, lr=0.0001
[2025-05-01 11:58:06,320][train][INFO] - Epoch 95/100, Val Acc=0.7386, Val Loss=1.3203, lr=0.0001
[2025-05-01 11:58:13,664][train][INFO] - Epoch 96/100, Val Acc=0.7392, Val Loss=1.3186, lr=0.0001
[2025-05-01 11:58:21,681][train][INFO] - Epoch 97/100, Val Acc=0.7399, Val Loss=1.3162, lr=0.0001
[2025-05-01 11:58:29,618][train][INFO] - Epoch 98/100, Val Acc=0.7415, Val Loss=1.3137, lr=0.0001
[2025-05-01 11:58:37,572][train][INFO] - Epoch 99/100, Val Acc=0.7400, Val Loss=1.3172, lr=0.0001
[2025-05-01 11:58:45,360][train][INFO] - Epoch 100/100, Val Acc=0.7378, Val Loss=1.3207, lr=0.0001
[2025-05-01 11:58:50,371][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7415
[2025-05-01 11:58:50,375][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 12:00:42,276][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 12:02:38,328][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 12:02:38,770][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 12:41:43,706][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-01 12:41:43,800][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 12:41:43,801][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 12:41:43,801][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 12:42:26,009][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=4.4928, lr=0.001
[2025-05-01 12:43:03,076][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=3.8054, lr=0.001
[2025-05-01 12:43:40,218][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.6650, lr=0.001
[2025-05-01 12:44:16,062][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=1.8170, lr=0.001
[2025-05-01 12:44:53,968][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=1.8789, lr=0.001
[2025-05-01 12:45:31,266][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.9001, lr=0.001
[2025-05-01 12:46:08,701][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7399, lr=0.001
[2025-05-01 12:46:44,856][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4222, lr=0.001
[2025-05-01 12:46:44,875][meta_train][INFO] - epoch_1 saved !
[2025-05-01 12:47:22,711][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3554, lr=0.001
[2025-05-01 12:47:58,328][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.1076, lr=0.001
[2025-05-01 12:48:35,269][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.1257, lr=0.001
[2025-05-01 12:49:12,852][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.2335, lr=0.001
[2025-05-01 12:49:51,119][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0825, lr=0.001
[2025-05-01 12:50:26,337][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0752, lr=0.001
[2025-05-01 12:51:03,951][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0667, lr=0.001
[2025-05-01 12:51:41,392][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.0571, lr=0.001
[2025-05-01 12:51:41,412][meta_train][INFO] - epoch_2 saved !
[2025-05-01 12:52:18,085][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.0852, lr=0.001
[2025-05-01 12:52:55,070][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.0791, lr=0.001
[2025-05-01 12:53:32,082][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.0776, lr=0.001
[2025-05-01 12:54:07,838][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.0982, lr=0.001
[2025-05-01 12:54:45,627][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2242, lr=0.001
[2025-05-01 12:55:22,755][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.2048, lr=0.001
[2025-05-01 12:56:00,035][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.1049, lr=0.001
[2025-05-01 12:56:36,746][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.1000, lr=0.001
[2025-05-01 12:56:36,759][meta_train][INFO] - epoch_3 saved !
[2025-05-01 12:57:13,349][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.1212, lr=0.001
[2025-05-01 12:57:50,034][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.1225, lr=0.001
[2025-05-01 12:58:27,797][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.2522, lr=0.001
[2025-05-01 12:59:04,304][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.1173, lr=0.001
[2025-05-01 12:59:43,071][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.1231, lr=0.001
[2025-05-01 13:00:18,635][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=0.2112, lr=0.001
[2025-05-01 13:00:55,677][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=0.3869, lr=0.001
[2025-05-01 13:01:32,154][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=0.1797, lr=0.001
[2025-05-01 13:01:32,177][meta_train][INFO] - epoch_4 saved !
[2025-05-01 13:02:09,330][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=0.3443, lr=0.001
[2025-05-01 13:02:47,350][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=0.1748, lr=0.001
[2025-05-01 13:03:25,371][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=0.2491, lr=0.001
[2025-05-01 13:04:01,849][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=0.2513, lr=0.001
[2025-05-01 13:04:39,355][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=0.6399, lr=0.001
[2025-05-01 13:05:15,925][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=0.3194, lr=0.001
[2025-05-01 13:05:52,318][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=0.4219, lr=0.001
[2025-05-01 13:06:28,903][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=0.3403, lr=0.001
[2025-05-01 13:06:28,913][meta_train][INFO] - epoch_5 saved !
[2025-05-01 13:07:05,091][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=0.7997, lr=0.001
[2025-05-01 13:07:43,255][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=0.2902, lr=0.001
[2025-05-01 13:08:19,456][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=0.4564, lr=0.001
[2025-05-01 13:08:56,945][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=0.5632, lr=0.001
[2025-05-01 13:09:33,749][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=0.3177, lr=0.001
[2025-05-01 13:10:10,331][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=0.3453, lr=0.001
[2025-05-01 13:10:47,686][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=0.3072, lr=0.001
[2025-05-01 13:11:25,543][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=0.3339, lr=0.001
[2025-05-01 13:11:25,564][meta_train][INFO] - epoch_6 saved !
[2025-05-01 13:12:01,330][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=0.5760, lr=0.001
[2025-05-01 13:12:39,162][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=0.6666, lr=0.001
[2025-05-01 13:13:16,504][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=0.3024, lr=0.001
[2025-05-01 13:13:53,049][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=0.4275, lr=0.001
[2025-05-01 13:14:29,088][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=0.2487, lr=0.001
[2025-05-01 13:15:06,942][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=0.2335, lr=0.001
[2025-05-01 13:15:45,173][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=0.2636, lr=0.001
[2025-05-01 13:16:21,547][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=0.2809, lr=0.001
[2025-05-01 13:16:21,559][meta_train][INFO] - epoch_7 saved !
[2025-05-01 13:16:58,601][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=0.2743, lr=0.001
[2025-05-01 13:17:35,394][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=0.2842, lr=0.001
[2025-05-01 13:18:12,806][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=0.2406, lr=0.001
[2025-05-01 13:18:49,918][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=0.5674, lr=0.001
[2025-05-01 13:19:27,015][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=0.2337, lr=0.001
[2025-05-01 13:20:04,811][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=0.2148, lr=0.001
[2025-05-01 13:20:40,831][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=0.4072, lr=0.001
[2025-05-01 13:21:18,725][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=0.4274, lr=0.001
[2025-05-01 13:21:18,737][meta_train][INFO] - epoch_8 saved !
[2025-05-01 13:21:54,992][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=0.2075, lr=0.001
[2025-05-01 13:22:32,408][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=0.2202, lr=0.001
[2025-05-01 13:23:08,687][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=0.1966, lr=0.001
[2025-05-01 13:23:45,485][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=0.4453, lr=0.001
[2025-05-01 13:24:22,035][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=0.5933, lr=0.001
[2025-05-01 13:24:58,557][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=0.4373, lr=0.001
[2025-05-01 13:25:36,918][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=0.2809, lr=0.001
[2025-05-01 13:26:14,274][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=0.2327, lr=0.001
[2025-05-01 13:26:14,290][meta_train][INFO] - epoch_9 saved !
[2025-05-01 13:26:50,389][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=0.3388, lr=0.001
[2025-05-01 13:27:28,385][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=0.3388, lr=0.001
[2025-05-01 13:28:04,381][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=0.4107, lr=0.001
[2025-05-01 13:28:42,033][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=0.8359, lr=0.001
[2025-05-01 13:29:19,318][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=0.6126, lr=0.001
[2025-05-01 13:29:54,916][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=1.0799, lr=0.001
[2025-05-01 13:30:32,593][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=0.8904, lr=0.001
[2025-05-01 13:31:10,406][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=1.5186, lr=0.001
[2025-05-01 13:31:10,430][meta_train][INFO] - epoch_10 saved !
[2025-05-01 13:31:46,904][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=0.8725, lr=0.001
[2025-05-01 13:32:23,193][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=1.6354, lr=0.001
[2025-05-01 13:33:01,370][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=0.8063, lr=0.001
[2025-05-01 13:33:38,553][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=1.0392, lr=0.001
[2025-05-01 13:34:14,975][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=1.4816, lr=0.001
[2025-05-01 13:34:52,200][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=1.6638, lr=0.001
[2025-05-01 13:35:27,856][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=0.9407, lr=0.001
[2025-05-01 13:36:05,681][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=1.3799, lr=0.001
[2025-05-01 13:36:05,697][meta_train][INFO] - epoch_11 saved !
[2025-05-01 13:36:42,732][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=1.3544, lr=0.001
[2025-05-01 13:37:19,970][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=1.2919, lr=0.001
[2025-05-01 13:37:57,402][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=1.9023, lr=0.001
[2025-05-01 13:38:35,124][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=2.7865, lr=0.001
[2025-05-01 13:39:11,595][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=2.8045, lr=0.001
[2025-05-01 13:39:48,370][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=2.2700, lr=0.001
[2025-05-01 13:40:25,926][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=2.7282, lr=0.001
[2025-05-01 13:41:02,399][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=2.2081, lr=0.001
[2025-05-01 13:41:02,419][meta_train][INFO] - epoch_12 saved !
[2025-05-01 13:41:38,983][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=2.0904, lr=0.001
[2025-05-01 13:42:16,736][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=2.5145, lr=0.001
[2025-05-01 13:42:53,651][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=2.5717, lr=0.001
[2025-05-01 13:43:31,483][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=2.8387, lr=0.001
[2025-05-01 13:44:08,666][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=3.1814, lr=0.001
[2025-05-01 13:44:44,883][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=3.2589, lr=0.001
[2025-05-01 13:45:21,333][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=3.6104, lr=0.001
[2025-05-01 13:45:59,431][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=3.7792, lr=0.001
[2025-05-01 13:45:59,452][meta_train][INFO] - epoch_13 saved !
[2025-05-01 13:46:35,907][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.1598, lr=0.001
[2025-05-01 13:47:12,889][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.3716, lr=0.001
[2025-05-01 13:47:50,413][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.5737, lr=0.001
[2025-05-01 13:48:26,294][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6633, lr=0.001
[2025-05-01 13:49:03,879][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.7552, lr=0.001
[2025-05-01 13:49:42,229][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.6567, lr=0.001
[2025-05-01 13:50:18,900][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=4.6530, lr=0.001
[2025-05-01 13:50:54,371][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6751, lr=0.001
[2025-05-01 13:50:54,393][meta_train][INFO] - epoch_14 saved !
[2025-05-01 13:51:32,651][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.7296, lr=0.001
[2025-05-01 13:52:07,773][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6930, lr=0.001
[2025-05-01 13:52:45,289][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=4.6514, lr=0.001
[2025-05-01 13:53:21,098][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.6469, lr=0.001
[2025-05-01 13:53:58,155][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.6493, lr=0.001
[2025-05-01 13:54:34,925][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6447, lr=0.001
[2025-05-01 13:55:12,382][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.6477, lr=0.001
[2025-05-01 13:55:50,767][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6472, lr=0.001
[2025-05-01 13:55:50,777][meta_train][INFO] - epoch_15 saved !
[2025-05-01 13:56:27,430][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.6455, lr=0.001
[2025-05-01 13:57:03,526][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6372, lr=0.001
[2025-05-01 13:57:40,830][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.6421, lr=0.001
[2025-05-01 13:58:19,006][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6471, lr=0.001
[2025-05-01 13:58:54,739][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=4.6346, lr=0.001
[2025-05-01 13:59:31,554][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.6225, lr=0.001
[2025-05-01 14:00:09,082][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.6210, lr=0.001
[2025-05-01 14:00:45,266][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6440, lr=0.001
[2025-05-01 14:00:45,290][meta_train][INFO] - epoch_16 saved !
[2025-05-01 14:01:22,907][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.6338, lr=0.001
[2025-05-01 14:02:00,766][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.6254, lr=0.001
[2025-05-01 14:02:36,232][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6414, lr=0.001
[2025-05-01 14:03:13,461][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=4.6267, lr=0.001
[2025-05-01 14:03:51,259][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.6175, lr=0.001
[2025-05-01 14:04:28,571][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6334, lr=0.001
[2025-05-01 14:05:06,508][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.6388, lr=0.001
[2025-05-01 14:05:42,291][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6354, lr=0.001
[2025-05-01 14:05:42,312][meta_train][INFO] - epoch_17 saved !
[2025-05-01 14:06:19,669][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6271, lr=0.001
[2025-05-01 14:06:56,353][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.6171, lr=0.001
[2025-05-01 14:07:33,402][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6315, lr=0.001
[2025-05-01 14:08:10,779][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6221, lr=0.001
[2025-05-01 14:08:48,093][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.6317, lr=0.001
[2025-05-01 14:09:23,266][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6253, lr=0.001
[2025-05-01 14:10:00,994][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.6143, lr=0.001
[2025-05-01 14:10:38,738][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.6250, lr=0.001
[2025-05-01 14:10:38,759][meta_train][INFO] - epoch_18 saved !
[2025-05-01 14:11:15,987][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6252, lr=0.001
[2025-05-01 14:11:52,807][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6181, lr=0.001
[2025-05-01 14:12:29,008][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.6213, lr=0.001
[2025-05-01 14:13:05,211][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6245, lr=0.001
[2025-05-01 14:13:42,023][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.6179, lr=0.001
[2025-05-01 14:14:19,756][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.6283, lr=0.001
[2025-05-01 14:14:55,869][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6267, lr=0.001
[2025-05-01 14:15:33,083][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.6121, lr=0.001
[2025-05-01 14:15:33,092][meta_train][INFO] - epoch_19 saved !
[2025-05-01 14:16:08,785][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.6273, lr=0.001
[2025-05-01 14:16:46,375][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.6119, lr=0.001
[2025-05-01 14:17:23,824][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6157, lr=0.001
[2025-05-01 14:18:00,927][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6176, lr=0.001
[2025-05-01 14:18:37,195][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6194, lr=0.001
[2025-05-01 14:19:13,585][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.6154, lr=0.001
[2025-05-01 14:19:50,539][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.6186, lr=0.001
[2025-05-01 14:20:26,145][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6234, lr=0.001
[2025-05-01 14:20:26,154][meta_train][INFO] - epoch_20 saved !
[2025-05-01 14:21:02,944][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.6177, lr=0.001
[2025-05-01 14:21:40,164][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6161, lr=0.001
[2025-05-01 14:22:17,332][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.6104, lr=0.001
[2025-05-01 14:22:55,088][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6139, lr=0.001
[2025-05-01 14:23:31,636][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.6207, lr=0.001
[2025-05-01 14:24:08,611][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6158, lr=0.001
[2025-05-01 14:24:44,409][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6138, lr=0.001
[2025-05-01 14:25:21,790][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6206, lr=0.001
[2025-05-01 14:25:21,800][meta_train][INFO] - epoch_21 saved !
[2025-05-01 14:25:58,275][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6202, lr=0.001
[2025-05-01 14:26:34,754][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6097, lr=0.001
[2025-05-01 14:27:12,079][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6127, lr=0.001
[2025-05-01 14:27:48,439][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6118, lr=0.001
[2025-05-01 14:28:24,293][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6150, lr=0.001
[2025-05-01 14:29:00,228][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.6143, lr=0.001
[2025-05-01 14:29:38,167][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6132, lr=0.001
[2025-05-01 14:30:15,106][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6177, lr=0.001
[2025-05-01 14:30:15,122][meta_train][INFO] - epoch_22 saved !
[2025-05-01 14:30:51,118][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6115, lr=0.001
[2025-05-01 14:31:29,038][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6089, lr=0.001
[2025-05-01 14:32:06,361][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6169, lr=0.001
[2025-05-01 14:32:43,525][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6176, lr=0.001
[2025-05-01 14:33:19,310][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6131, lr=0.001
[2025-05-01 14:33:56,609][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6122, lr=0.001
[2025-05-01 14:34:33,898][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6110, lr=0.001
[2025-05-01 14:35:09,750][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.6119, lr=0.001
[2025-05-01 14:35:09,775][meta_train][INFO] - epoch_23 saved !
[2025-05-01 14:35:47,606][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6106, lr=0.001
[2025-05-01 14:36:23,267][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6119, lr=0.001
[2025-05-01 14:37:00,036][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6155, lr=0.001
[2025-05-01 14:37:37,511][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6140, lr=0.001
[2025-05-01 14:38:14,641][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6106, lr=0.001
[2025-05-01 14:38:50,389][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6088, lr=0.001
[2025-05-01 14:39:26,939][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.6102, lr=0.001
[2025-05-01 14:40:04,504][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6074, lr=0.001
[2025-05-01 14:40:04,514][meta_train][INFO] - epoch_24 saved !
[2025-05-01 14:40:42,559][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6092, lr=0.001
[2025-05-01 14:41:19,489][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-01 14:41:55,048][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.6094, lr=0.001
[2025-05-01 14:42:33,489][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6092, lr=0.001
[2025-05-01 14:43:09,219][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6094, lr=0.001
[2025-05-01 14:43:45,277][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6126, lr=0.001
[2025-05-01 14:44:22,810][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6075, lr=0.001
[2025-05-01 14:44:59,475][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6108, lr=0.001
[2025-05-01 14:44:59,501][meta_train][INFO] - epoch_25 saved !
[2025-05-01 14:45:35,703][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6088, lr=0.001
[2025-05-01 14:46:11,779][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6118, lr=0.001
[2025-05-01 14:46:49,036][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.6081, lr=0.001
[2025-05-01 14:47:24,471][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6078, lr=0.001
[2025-05-01 14:48:01,807][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6079, lr=0.001
[2025-05-01 14:48:38,526][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6064, lr=0.001
[2025-05-01 14:49:15,576][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6095, lr=0.001
[2025-05-01 14:49:52,301][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6068, lr=0.001
[2025-05-01 14:49:52,322][meta_train][INFO] - epoch_26 saved !
[2025-05-01 14:50:28,754][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6067, lr=0.001
[2025-05-01 14:51:05,896][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6104, lr=0.001
[2025-05-01 14:51:42,550][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6073, lr=0.001
[2025-05-01 14:52:19,242][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.6072, lr=0.001
[2025-05-01 14:52:54,946][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6074, lr=0.001
[2025-05-01 14:53:32,187][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 14:54:08,445][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6084, lr=0.001
[2025-05-01 14:54:46,034][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6069, lr=0.001
[2025-05-01 14:54:46,052][meta_train][INFO] - epoch_27 saved !
[2025-05-01 14:55:22,285][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6095, lr=0.001
[2025-05-01 14:55:59,252][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6059, lr=0.001
[2025-05-01 14:56:36,960][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.6067, lr=0.001
[2025-05-01 14:57:13,833][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6067, lr=0.001
[2025-05-01 14:57:50,430][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6061, lr=0.001
[2025-05-01 14:58:26,350][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6066, lr=0.001
[2025-05-01 14:59:03,960][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6077, lr=0.001
[2025-05-01 14:59:38,730][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6067, lr=0.001
[2025-05-01 14:59:38,740][meta_train][INFO] - epoch_28 saved !
[2025-05-01 15:00:16,200][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6065, lr=0.001
[2025-05-01 15:00:53,089][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6060, lr=0.001
[2025-05-01 15:01:29,205][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6063, lr=0.001
[2025-05-01 15:02:06,705][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6085, lr=0.001
[2025-05-01 15:02:42,570][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 15:03:19,098][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6064, lr=0.001
[2025-05-01 15:03:57,037][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6072, lr=0.001
[2025-05-01 15:04:33,469][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6062, lr=0.001
[2025-05-01 15:04:33,478][meta_train][INFO] - epoch_29 saved !
[2025-05-01 15:05:10,419][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6082, lr=0.001
[2025-05-01 15:05:46,976][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6063, lr=0.001
[2025-05-01 15:06:23,287][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 15:07:01,214][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6061, lr=0.001
[2025-05-01 15:07:37,678][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6070, lr=0.001
[2025-05-01 15:08:14,189][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 15:08:50,971][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 15:09:29,008][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6060, lr=0.001
[2025-05-01 15:09:29,033][meta_train][INFO] - epoch_30 saved !
[2025-05-01 15:10:05,221][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 15:10:42,589][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6077, lr=0.001
[2025-05-01 15:11:18,695][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 15:11:56,089][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6068, lr=0.001
[2025-05-01 15:12:32,706][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6060, lr=0.001
[2025-05-01 15:13:09,535][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6060, lr=0.001
[2025-05-01 15:13:46,280][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6059, lr=0.001
[2025-05-01 15:14:22,878][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 15:14:22,888][meta_train][INFO] - epoch_31 saved !
[2025-05-01 15:15:00,032][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6060, lr=0.001
[2025-05-01 15:15:35,962][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6058, lr=0.001
[2025-05-01 15:16:13,642][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:16:50,488][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6059, lr=0.001
[2025-05-01 15:17:27,173][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 15:18:02,950][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6059, lr=0.001
[2025-05-01 15:18:40,378][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6065, lr=0.001
[2025-05-01 15:19:08,038][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 15:19:08,094][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 15:19:17,161][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6072, lr=0.001
[2025-05-01 15:19:17,171][meta_train][INFO] - epoch_32 saved !
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 15:19:37,397][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 15:19:45,829][train][INFO] - Epoch 1/100, Val Acc=0.0706, Val Loss=3.8937, lr=0.0100
[2025-05-01 15:19:54,245][train][INFO] - Epoch 2/100, Val Acc=0.2108, Val Loss=2.9731, lr=0.0100
[2025-05-01 15:19:55,122][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:20:02,808][train][INFO] - Epoch 3/100, Val Acc=0.2912, Val Loss=2.7967, lr=0.0100
[2025-05-01 15:20:10,383][train][INFO] - Epoch 4/100, Val Acc=0.4286, Val Loss=2.0857, lr=0.0100
[2025-05-01 15:20:18,538][train][INFO] - Epoch 5/100, Val Acc=0.4561, Val Loss=2.0563, lr=0.0100
[2025-05-01 15:20:26,692][train][INFO] - Epoch 6/100, Val Acc=0.4436, Val Loss=2.2707, lr=0.0100
[2025-05-01 15:20:32,310][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6071, lr=0.001
[2025-05-01 15:20:34,626][train][INFO] - Epoch 7/100, Val Acc=0.5218, Val Loss=1.8155, lr=0.0100
[2025-05-01 15:20:42,686][train][INFO] - Epoch 8/100, Val Acc=0.5249, Val Loss=1.8638, lr=0.0100
[2025-05-01 15:20:50,737][train][INFO] - Epoch 9/100, Val Acc=0.5352, Val Loss=1.8255, lr=0.0100
[2025-05-01 15:20:58,713][train][INFO] - Epoch 10/100, Val Acc=0.5553, Val Loss=1.7265, lr=0.0100
[2025-05-01 15:21:05,980][train][INFO] - Epoch 11/100, Val Acc=0.5912, Val Loss=1.5787, lr=0.0100
[2025-05-01 15:21:09,159][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 15:21:14,328][train][INFO] - Epoch 12/100, Val Acc=0.5757, Val Loss=1.6837, lr=0.0100
[2025-05-01 15:21:22,581][train][INFO] - Epoch 13/100, Val Acc=0.5847, Val Loss=1.6419, lr=0.0100
[2025-05-01 15:21:30,294][train][INFO] - Epoch 14/100, Val Acc=0.5962, Val Loss=1.5629, lr=0.0100
[2025-05-01 15:21:38,149][train][INFO] - Epoch 15/100, Val Acc=0.5978, Val Loss=1.6183, lr=0.0100
[2025-05-01 15:21:45,728][train][INFO] - Epoch 16/100, Val Acc=0.6105, Val Loss=1.5315, lr=0.0100
[2025-05-01 15:21:47,502][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.6064, lr=0.001
[2025-05-01 15:21:53,607][train][INFO] - Epoch 17/100, Val Acc=0.5738, Val Loss=1.7595, lr=0.0100
[2025-05-01 15:22:01,604][train][INFO] - Epoch 18/100, Val Acc=0.6279, Val Loss=1.4818, lr=0.0100
[2025-05-01 15:22:09,744][train][INFO] - Epoch 19/100, Val Acc=0.6344, Val Loss=1.4927, lr=0.0100
[2025-05-01 15:22:18,443][train][INFO] - Epoch 20/100, Val Acc=0.6238, Val Loss=1.5212, lr=0.0100
[2025-05-01 15:22:24,099][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 15:22:26,322][train][INFO] - Epoch 21/100, Val Acc=0.6147, Val Loss=1.5916, lr=0.0100
[2025-05-01 15:22:34,596][train][INFO] - Epoch 22/100, Val Acc=0.6151, Val Loss=1.6332, lr=0.0100
[2025-05-01 15:22:42,173][train][INFO] - Epoch 23/100, Val Acc=0.6109, Val Loss=1.6300, lr=0.0100
[2025-05-01 15:22:49,759][train][INFO] - Epoch 24/100, Val Acc=0.6447, Val Loss=1.4446, lr=0.0100
[2025-05-01 15:22:58,539][train][INFO] - Epoch 25/100, Val Acc=0.6389, Val Loss=1.5132, lr=0.0100
[2025-05-01 15:23:02,665][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 15:23:06,318][train][INFO] - Epoch 26/100, Val Acc=0.6126, Val Loss=1.6543, lr=0.0100
[2025-05-01 15:23:14,199][train][INFO] - Epoch 27/100, Val Acc=0.6025, Val Loss=1.7044, lr=0.0100
[2025-05-01 15:23:22,300][train][INFO] - Epoch 28/100, Val Acc=0.6349, Val Loss=1.5484, lr=0.0100
[2025-05-01 15:23:30,486][train][INFO] - Epoch 29/100, Val Acc=0.6474, Val Loss=1.4652, lr=0.0100
[2025-05-01 15:23:38,319][train][INFO] - Epoch 30/100, Val Acc=0.6550, Val Loss=1.4441, lr=0.0100
[2025-05-01 15:23:39,996][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 15:23:46,871][train][INFO] - Epoch 31/100, Val Acc=0.6458, Val Loss=1.5034, lr=0.0100
[2025-05-01 15:23:55,201][train][INFO] - Epoch 32/100, Val Acc=0.6276, Val Loss=1.5984, lr=0.0100
[2025-05-01 15:24:03,175][train][INFO] - Epoch 33/100, Val Acc=0.6379, Val Loss=1.5567, lr=0.0100
[2025-05-01 15:24:11,262][train][INFO] - Epoch 34/100, Val Acc=0.6523, Val Loss=1.4781, lr=0.0100
[2025-05-01 15:24:18,029][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 15:24:18,049][meta_train][INFO] - epoch_33 saved !
[2025-05-01 15:24:19,600][train][INFO] - Epoch 35/100, Val Acc=0.6443, Val Loss=1.5522, lr=0.0100
[2025-05-01 15:24:28,213][train][INFO] - Epoch 36/100, Val Acc=0.6421, Val Loss=1.5500, lr=0.0100
[2025-05-01 15:24:36,069][train][INFO] - Epoch 37/100, Val Acc=0.6285, Val Loss=1.6178, lr=0.0100
[2025-05-01 15:24:44,011][train][INFO] - Epoch 38/100, Val Acc=0.6208, Val Loss=1.6405, lr=0.0100
[2025-05-01 15:24:51,525][train][INFO] - Epoch 39/100, Val Acc=0.6448, Val Loss=1.5211, lr=0.0100
[2025-05-01 15:24:55,271][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 15:24:59,268][train][INFO] - Epoch 40/100, Val Acc=0.6589, Val Loss=1.4578, lr=0.0100
[2025-05-01 15:25:07,592][train][INFO] - Epoch 41/100, Val Acc=0.6410, Val Loss=1.5647, lr=0.0100
[2025-05-01 15:25:15,903][train][INFO] - Epoch 42/100, Val Acc=0.6371, Val Loss=1.5811, lr=0.0100
[2025-05-01 15:25:23,999][train][INFO] - Epoch 43/100, Val Acc=0.6444, Val Loss=1.5672, lr=0.0100
[2025-05-01 15:25:32,052][train][INFO] - Epoch 44/100, Val Acc=0.6448, Val Loss=1.5721, lr=0.0100
[2025-05-01 15:25:32,282][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:25:39,935][train][INFO] - Epoch 45/100, Val Acc=0.6455, Val Loss=1.5733, lr=0.0100
[2025-05-01 15:25:47,952][train][INFO] - Epoch 46/100, Val Acc=0.6416, Val Loss=1.5996, lr=0.0100
[2025-05-01 15:25:56,332][train][INFO] - Epoch 47/100, Val Acc=0.6398, Val Loss=1.6223, lr=0.0100
[2025-05-01 15:26:04,401][train][INFO] - Epoch 48/100, Val Acc=0.6481, Val Loss=1.5288, lr=0.0100
[2025-05-01 15:26:09,721][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 15:26:12,319][train][INFO] - Epoch 49/100, Val Acc=0.6611, Val Loss=1.4779, lr=0.0100
[2025-05-01 15:26:18,971][train][INFO] - Epoch 50/100, Val Acc=0.6411, Val Loss=1.6265, lr=0.0100
[2025-05-01 15:26:27,337][train][INFO] - Epoch 51/100, Val Acc=0.6561, Val Loss=1.5558, lr=0.0100
[2025-05-01 15:26:35,762][train][INFO] - Epoch 52/100, Val Acc=0.6450, Val Loss=1.6309, lr=0.0100
[2025-05-01 15:26:43,537][train][INFO] - Epoch 53/100, Val Acc=0.6504, Val Loss=1.5771, lr=0.0100
[2025-05-01 15:26:47,002][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6068, lr=0.001
[2025-05-01 15:26:50,589][train][INFO] - Epoch 54/100, Val Acc=0.6460, Val Loss=1.6231, lr=0.0100
[2025-05-01 15:26:58,834][train][INFO] - Epoch 55/100, Val Acc=0.6514, Val Loss=1.5778, lr=0.0100
[2025-05-01 15:27:07,084][train][INFO] - Epoch 56/100, Val Acc=0.6452, Val Loss=1.6444, lr=0.0100
[2025-05-01 15:27:15,128][train][INFO] - Epoch 57/100, Val Acc=0.6499, Val Loss=1.5883, lr=0.0100
[2025-05-01 15:27:22,791][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.5571, lr=0.0100
[2025-05-01 15:27:24,667][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.6062, lr=0.001
[2025-05-01 15:27:30,333][train][INFO] - Epoch 59/100, Val Acc=0.6471, Val Loss=1.5725, lr=0.0100
[2025-05-01 15:27:38,216][train][INFO] - Epoch 60/100, Val Acc=0.6504, Val Loss=1.5868, lr=0.0100
[2025-05-01 15:27:45,655][train][INFO] - Epoch 61/100, Val Acc=0.7129, Val Loss=1.2725, lr=0.0010
[2025-05-01 15:27:53,743][train][INFO] - Epoch 62/100, Val Acc=0.7158, Val Loss=1.2676, lr=0.0010
[2025-05-01 15:28:01,847][train][INFO] - Epoch 63/100, Val Acc=0.7183, Val Loss=1.2778, lr=0.0010
[2025-05-01 15:28:02,342][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 15:28:10,128][train][INFO] - Epoch 64/100, Val Acc=0.7201, Val Loss=1.2846, lr=0.0010
[2025-05-01 15:28:18,338][train][INFO] - Epoch 65/100, Val Acc=0.7185, Val Loss=1.2964, lr=0.0010
[2025-05-01 15:28:26,657][train][INFO] - Epoch 66/100, Val Acc=0.7193, Val Loss=1.3128, lr=0.0010
[2025-05-01 15:28:35,082][train][INFO] - Epoch 67/100, Val Acc=0.7189, Val Loss=1.3188, lr=0.0010
[2025-05-01 15:28:38,432][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 15:28:43,025][train][INFO] - Epoch 68/100, Val Acc=0.7205, Val Loss=1.3176, lr=0.0010
[2025-05-01 15:28:50,791][train][INFO] - Epoch 69/100, Val Acc=0.7195, Val Loss=1.3333, lr=0.0010
[2025-05-01 15:28:58,603][train][INFO] - Epoch 70/100, Val Acc=0.7197, Val Loss=1.3369, lr=0.0010
[2025-05-01 15:29:06,585][train][INFO] - Epoch 71/100, Val Acc=0.7191, Val Loss=1.3453, lr=0.0010
[2025-05-01 15:29:14,347][train][INFO] - Epoch 72/100, Val Acc=0.7189, Val Loss=1.3444, lr=0.0010
[2025-05-01 15:29:16,155][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 15:29:16,178][meta_train][INFO] - epoch_34 saved !
[2025-05-01 15:29:22,859][train][INFO] - Epoch 73/100, Val Acc=0.7194, Val Loss=1.3543, lr=0.0010
[2025-05-01 15:29:31,513][train][INFO] - Epoch 74/100, Val Acc=0.7216, Val Loss=1.3619, lr=0.0010
[2025-05-01 15:29:39,181][train][INFO] - Epoch 75/100, Val Acc=0.7204, Val Loss=1.3636, lr=0.0010
[2025-05-01 15:29:47,377][train][INFO] - Epoch 76/100, Val Acc=0.7190, Val Loss=1.3655, lr=0.0010
[2025-05-01 15:29:54,189][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:29:55,370][train][INFO] - Epoch 77/100, Val Acc=0.7213, Val Loss=1.3802, lr=0.0010
[2025-05-01 15:30:03,574][train][INFO] - Epoch 78/100, Val Acc=0.7216, Val Loss=1.3769, lr=0.0010
[2025-05-01 15:30:11,289][train][INFO] - Epoch 79/100, Val Acc=0.7207, Val Loss=1.3812, lr=0.0010
[2025-05-01 15:30:19,208][train][INFO] - Epoch 80/100, Val Acc=0.7197, Val Loss=1.3875, lr=0.0010
[2025-05-01 15:30:26,802][train][INFO] - Epoch 81/100, Val Acc=0.7200, Val Loss=1.3970, lr=0.0010
[2025-05-01 15:30:31,323][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6066, lr=0.001
[2025-05-01 15:30:34,811][train][INFO] - Epoch 82/100, Val Acc=0.7223, Val Loss=1.3973, lr=0.0010
[2025-05-01 15:30:43,212][train][INFO] - Epoch 83/100, Val Acc=0.7222, Val Loss=1.3847, lr=0.0010
[2025-05-01 15:30:51,075][train][INFO] - Epoch 84/100, Val Acc=0.7229, Val Loss=1.3986, lr=0.0010
[2025-05-01 15:30:58,769][train][INFO] - Epoch 85/100, Val Acc=0.7237, Val Loss=1.4124, lr=0.0010
[2025-05-01 15:31:07,138][train][INFO] - Epoch 86/100, Val Acc=0.7230, Val Loss=1.4058, lr=0.0010
[2025-05-01 15:31:08,479][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 15:31:14,437][train][INFO] - Epoch 87/100, Val Acc=0.7249, Val Loss=1.4100, lr=0.0010
[2025-05-01 15:31:22,542][train][INFO] - Epoch 88/100, Val Acc=0.7224, Val Loss=1.4000, lr=0.0010
[2025-05-01 15:31:30,774][train][INFO] - Epoch 89/100, Val Acc=0.7242, Val Loss=1.4086, lr=0.0010
[2025-05-01 15:31:38,610][train][INFO] - Epoch 90/100, Val Acc=0.7213, Val Loss=1.4144, lr=0.0010
[2025-05-01 15:31:46,732][train][INFO] - Epoch 91/100, Val Acc=0.7226, Val Loss=1.4094, lr=0.0001
[2025-05-01 15:31:46,993][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 15:31:55,167][train][INFO] - Epoch 92/100, Val Acc=0.7237, Val Loss=1.4149, lr=0.0001
[2025-05-01 15:32:03,354][train][INFO] - Epoch 93/100, Val Acc=0.7230, Val Loss=1.4141, lr=0.0001
[2025-05-01 15:32:11,246][train][INFO] - Epoch 94/100, Val Acc=0.7241, Val Loss=1.4118, lr=0.0001
[2025-05-01 15:32:19,846][train][INFO] - Epoch 95/100, Val Acc=0.7234, Val Loss=1.4121, lr=0.0001
[2025-05-01 15:32:23,457][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.6060, lr=0.001
[2025-05-01 15:32:27,640][train][INFO] - Epoch 96/100, Val Acc=0.7232, Val Loss=1.4080, lr=0.0001
[2025-05-01 15:32:35,817][train][INFO] - Epoch 97/100, Val Acc=0.7237, Val Loss=1.4129, lr=0.0001
[2025-05-01 15:32:43,944][train][INFO] - Epoch 98/100, Val Acc=0.7242, Val Loss=1.4058, lr=0.0001
[2025-05-01 15:32:52,394][train][INFO] - Epoch 99/100, Val Acc=0.7238, Val Loss=1.4111, lr=0.0001
[2025-05-01 15:33:00,495][train][INFO] - Epoch 100/100, Val Acc=0.7246, Val Loss=1.4087, lr=0.0001
[2025-05-01 15:33:02,458][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 15:33:05,602][train][INFO] - After training : Train Acc=0.9963  Val Acc=0.7249
[2025-05-01 15:33:05,607][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 15:33:39,356][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 15:34:18,621][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 15:34:18,633][meta_train][INFO] - epoch_35 saved !
[2025-05-01 15:34:56,339][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:34:57,996][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 15:35:34,822][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:36:13,015][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:36:51,356][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 15:37:28,669][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 15:37:31,038][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 15:37:31,500][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 15:38:06,885][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:38:43,661][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 15:39:20,723][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6062, lr=0.001
[2025-05-01 15:39:20,742][meta_train][INFO] - epoch_36 saved !
[2025-05-01 15:39:58,484][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 15:40:36,432][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 15:41:12,583][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 15:41:49,768][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 15:42:27,083][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6061, lr=0.001
[2025-05-01 15:43:03,223][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 15:43:40,232][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 15:44:17,980][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 15:44:17,989][meta_train][INFO] - epoch_37 saved !
[2025-05-01 15:44:53,448][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 15:45:30,493][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6060, lr=0.001
[2025-05-01 15:46:07,257][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 15:46:43,787][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 15:47:21,681][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 15:47:56,981][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:48:33,819][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 15:49:11,390][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 15:49:11,399][meta_train][INFO] - epoch_38 saved !
[2025-05-01 15:49:48,283][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 15:50:25,846][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 15:51:01,726][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 15:51:39,527][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 15:52:15,957][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6059, lr=0.001
[2025-05-01 15:52:54,085][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 15:53:30,989][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 15:54:07,274][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 15:54:07,284][meta_train][INFO] - epoch_39 saved !
[2025-05-01 15:54:43,697][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 15:55:21,065][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 15:55:57,138][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 15:56:34,885][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 15:57:10,722][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 15:57:47,926][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 15:58:24,868][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 15:59:02,000][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 15:59:02,019][meta_train][INFO] - epoch_40 saved !
[2025-05-01 15:59:39,706][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 16:00:17,157][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 16:00:53,071][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:01:29,704][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:02:06,950][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:02:44,347][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:19,990][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:56,847][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:03:56,868][meta_train][INFO] - epoch_41 saved !
[2025-05-01 16:04:33,788][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:05:10,197][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:05:47,655][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:06:23,142][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 16:07:00,270][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 16:07:38,103][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:14,175][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:50,922][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:08:50,932][meta_train][INFO] - epoch_42 saved !
[2025-05-01 16:09:27,032][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:10:03,923][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:10:40,191][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:11:17,480][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:11:42,868][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 16:11:42,922][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 16:11:55,262][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6053, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=50']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 122, in main
    metanetwork = load_metanetwork(index)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 106, in load_metanetwork
    raise ValueError(f"no metanetwork found with index {index}")
ValueError: no metanetwork found with index 50

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-01 16:12:31,247][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:13:08,179][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 16:13:45,588][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:13:45,608][meta_train][INFO] - epoch_43 saved !
[2025-05-01 16:14:22,881][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:14:59,897][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 16:15:37,516][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 16:16:13,378][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:16:50,279][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:17:27,423][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:03,614][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:41,395][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:18:41,405][meta_train][INFO] - epoch_44 saved !
[2025-05-01 16:19:18,855][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 16:19:54,140][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:20:31,298][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:21:09,094][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:21:45,471][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:22:21,482][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:22:59,192][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 16:23:36,571][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:23:36,581][meta_train][INFO] - epoch_45 saved !
[2025-05-01 16:24:13,622][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:24:49,607][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:25:26,723][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:26:04,524][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 16:26:41,488][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:27:18,098][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:27:54,701][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:28:31,588][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 16:28:31,598][meta_train][INFO] - epoch_46 saved !
[2025-05-01 16:29:09,125][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:29:46,054][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:30:22,471][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:30:58,481][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:31:35,229][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:32:13,247][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 16:32:50,746][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 16:33:26,595][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:33:26,614][meta_train][INFO] - epoch_47 saved !
[2025-05-01 16:34:03,859][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:34:41,647][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:35:18,596][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:35:54,731][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 16:36:31,785][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:37:08,260][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:37:45,184][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:38:21,637][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 16:38:21,648][meta_train][INFO] - epoch_48 saved !
[2025-05-01 16:38:59,270][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:39:34,973][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:40:11,717][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 16:40:49,179][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:41:26,041][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:42:03,051][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-01 16:42:39,667][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:43:15,677][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-01 16:43:15,711][meta_train][INFO] - epoch_49 saved !
[2025-05-01 16:43:53,498][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:44:28,596][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:45:06,086][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-01 16:45:43,154][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:46:19,739][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 16:46:57,311][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:47:33,912][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:48:10,020][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:48:10,034][meta_train][INFO] - epoch_50 saved !
[2025-05-01 16:48:46,980][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:49:24,630][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:50:01,187][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 16:50:37,772][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:51:14,809][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-01 16:51:52,657][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 16:52:28,293][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:53:05,589][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:53:05,599][meta_train][INFO] - epoch_51 saved !
[2025-05-01 16:53:42,418][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:54:18,698][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 16:54:56,001][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-01 16:55:33,391][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 16:56:09,763][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 16:56:47,059][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 16:57:24,127][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 16:58:00,136][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 16:58:00,154][meta_train][INFO] - epoch_52 saved !
[2025-05-01 16:58:37,834][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 16:59:14,628][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 16:59:50,192][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:00:27,849][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 17:01:03,439][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:01:41,608][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:02:18,541][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-01 17:02:55,282][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:02:55,301][meta_train][INFO] - epoch_53 saved !
[2025-05-01 17:03:30,994][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:04:07,817][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:04:44,909][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:05:21,811][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:05:57,927][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:06:35,101][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-01 17:07:12,708][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:07:48,399][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:07:48,408][meta_train][INFO] - epoch_54 saved !
[2025-05-01 17:08:24,721][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:09:02,554][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:09:39,224][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:10:15,531][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:10:53,102][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-01 17:11:28,921][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:12:06,048][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:12:42,768][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:12:42,777][meta_train][INFO] - epoch_55 saved !
[2025-05-01 17:13:19,202][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:13:56,227][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:14:32,386][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:15:09,760][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:15:46,027][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:16:23,124][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:00,988][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:38,009][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:17:38,032][meta_train][INFO] - epoch_56 saved !
[2025-05-01 17:18:14,125][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:18:51,468][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:19:27,555][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:20:04,630][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:20:40,247][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:21:17,616][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:21:54,887][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:22:33,111][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:22:33,126][meta_train][INFO] - epoch_57 saved !
[2025-05-01 17:23:08,204][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:23:46,445][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:24:21,985][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:24:59,745][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:25:36,712][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:26:12,252][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:26:49,375][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:27:26,911][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:27:26,920][meta_train][INFO] - epoch_58 saved !
[2025-05-01 17:28:04,075][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:28:40,367][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:29:16,332][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:29:53,392][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:30:31,290][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:31:08,287][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:31:44,978][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:32:21,327][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:32:21,340][meta_train][INFO] - epoch_59 saved !
[2025-05-01 17:32:58,296][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:33:34,449][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:34:11,256][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:34:47,809][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:35:25,052][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:36:02,978][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 17:36:38,825][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:37:16,275][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:37:16,285][meta_train][INFO] - epoch_60 saved !
[2025-05-01 17:37:54,729][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:38:32,029][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:39:08,019][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:39:45,459][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:40:22,609][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:40:58,134][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:41:35,112][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:42:11,670][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:42:11,679][meta_train][INFO] - epoch_61 saved !
[2025-05-01 17:42:49,265][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:43:26,518][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:44:03,307][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:44:40,515][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:45:16,865][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:45:53,634][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-01 17:46:31,384][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-01 17:47:08,684][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:47:08,702][meta_train][INFO] - epoch_62 saved !
[2025-05-01 17:47:45,297][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 17:48:21,209][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:48:58,549][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:49:35,500][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 17:50:11,570][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 17:50:48,711][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 17:51:26,262][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:52:02,920][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 17:52:02,930][meta_train][INFO] - epoch_63 saved !
[2025-05-01 17:52:38,586][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:53:16,221][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-01 17:53:51,498][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-01 17:54:28,973][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 17:55:06,819][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 17:55:42,777][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 17:56:20,014][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 17:56:56,891][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6053, lr=0.001
[2025-05-01 17:56:56,901][meta_train][INFO] - epoch_64 saved !
[2025-05-01 17:57:33,637][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 17:58:10,248][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 17:58:46,571][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 17:59:22,392][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-01 18:00:00,368][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 18:00:37,261][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:01:13,935][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:01:50,123][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:01:50,144][meta_train][INFO] - epoch_65 saved !
[2025-05-01 18:02:28,097][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 18:03:04,506][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:03:40,890][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:04:18,431][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 18:04:54,567][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-01 18:05:31,659][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:07,789][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:44,762][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:06:44,783][meta_train][INFO] - epoch_66 saved !
[2025-05-01 18:07:21,218][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 18:07:57,813][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:08:34,826][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:09:11,394][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-01 18:09:48,388][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:10:25,203][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:11:01,396][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:11:39,345][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:11:39,365][meta_train][INFO] - epoch_67 saved !
[2025-05-01 18:12:15,509][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6053, lr=0.001
[2025-05-01 18:12:52,656][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:13:29,857][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6054, lr=0.001
[2025-05-01 18:14:06,715][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:14:42,874][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:15:18,477][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:15:55,719][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:16:32,891][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6054, lr=0.001
[2025-05-01 18:16:32,900][meta_train][INFO] - epoch_68 saved !
[2025-05-01 18:17:09,145][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 18:17:44,747][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6054, lr=0.001
[2025-05-01 18:18:21,876][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:18:57,986][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:19:35,258][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 18:20:12,176][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:20:48,205][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:21:24,616][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:21:24,625][meta_train][INFO] - epoch_69 saved !
[2025-05-01 18:22:01,000][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:22:39,049][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:23:15,841][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:23:51,476][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:24:28,459][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6054, lr=0.001
[2025-05-01 18:25:04,886][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-01 18:25:40,894][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:26:17,047][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:26:17,056][meta_train][INFO] - epoch_70 saved !
[2025-05-01 18:26:54,054][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:27:30,763][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:28:06,833][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:28:43,998][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:29:19,806][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:29:56,029][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:30:33,542][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6054, lr=0.001
[2025-05-01 18:31:10,876][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:31:10,886][meta_train][INFO] - epoch_71 saved !
[2025-05-01 18:31:47,459][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:32:24,283][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 18:33:01,741][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 18:33:38,558][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 18:34:14,230][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:34:50,961][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:35:28,878][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 18:36:05,713][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:36:05,723][meta_train][INFO] - epoch_72 saved !
[2025-05-01 18:36:42,878][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6054, lr=0.001
[2025-05-01 18:37:19,102][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:37:56,824][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:38:32,877][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:39:10,116][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:39:45,917][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 18:40:22,617][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:41:00,195][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 18:41:00,215][meta_train][INFO] - epoch_73 saved !
[2025-05-01 18:41:37,044][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:42:13,666][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:42:49,269][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:43:26,625][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6055, lr=0.001
[2025-05-01 18:44:03,694][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 18:44:39,390][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:45:16,740][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:45:54,020][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:45:54,029][meta_train][INFO] - epoch_74 saved !
[2025-05-01 18:46:30,471][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:47:08,046][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 18:47:43,873][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:48:21,044][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 18:48:57,369][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:49:33,705][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:50:10,524][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:50:47,493][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:50:47,516][meta_train][INFO] - epoch_75 saved !
[2025-05-01 18:51:23,880][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 18:51:59,878][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 18:52:37,698][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 18:53:13,998][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 18:53:50,452][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:54:27,473][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6055, lr=0.001
[2025-05-01 18:55:05,455][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 18:55:41,838][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 18:55:41,848][meta_train][INFO] - epoch_76 saved !
[2025-05-01 18:56:17,817][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 18:56:54,323][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 18:57:30,534][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 18:58:08,322][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 18:58:45,219][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 18:59:21,002][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 18:59:58,190][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:00:34,286][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:00:34,297][meta_train][INFO] - epoch_77 saved !
[2025-05-01 19:01:11,334][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:01:47,026][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:02:23,859][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:03:01,091][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:03:37,241][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:04:14,553][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:04:52,038][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 19:05:30,031][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:05:30,054][meta_train][INFO] - epoch_78 saved !
[2025-05-01 19:06:06,837][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:06:43,422][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:07:19,186][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:07:57,509][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:08:34,252][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:09:10,541][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:09:47,971][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:10:24,654][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6058, lr=0.001
[2025-05-01 19:10:24,670][meta_train][INFO] - epoch_79 saved !
[2025-05-01 19:11:01,157][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:11:38,787][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:12:14,547][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:12:51,578][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:13:28,330][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 19:14:06,167][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:14:41,797][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:15:19,516][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 19:15:19,542][meta_train][INFO] - epoch_80 saved !
[2025-05-01 19:15:55,624][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 19:16:33,149][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:17:09,395][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:17:46,299][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:18:22,955][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:18:59,823][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 19:19:37,536][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:20:14,859][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:20:14,869][meta_train][INFO] - epoch_81 saved !
[2025-05-01 19:20:50,062][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:21:27,761][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:22:03,438][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:22:40,315][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:23:16,680][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:23:53,325][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 19:24:31,311][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:25:07,079][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 19:25:07,099][meta_train][INFO] - epoch_82 saved !
[2025-05-01 19:25:45,074][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6058, lr=0.001
[2025-05-01 19:26:21,547][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:26:57,874][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:27:33,642][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:28:10,715][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 19:28:47,227][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:29:24,635][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:30:02,267][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:30:02,287][meta_train][INFO] - epoch_83 saved !
[2025-05-01 19:30:39,361][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:31:16,037][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:31:52,866][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:32:28,257][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:33:05,944][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:33:42,888][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:34:18,636][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:34:56,442][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:34:56,452][meta_train][INFO] - epoch_84 saved !
[2025-05-01 19:35:32,482][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:36:09,438][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:36:45,392][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 19:37:23,047][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 19:38:00,072][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:38:36,647][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:39:12,413][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:39:50,040][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:39:50,055][meta_train][INFO] - epoch_85 saved !
[2025-05-01 19:40:26,012][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:41:03,529][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:41:40,123][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:42:17,613][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:42:54,557][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:43:31,002][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 19:44:07,232][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 19:44:44,737][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 19:44:44,760][meta_train][INFO] - epoch_86 saved !
[2025-05-01 19:45:20,702][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:45:57,974][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 19:46:35,162][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6058, lr=0.001
[2025-05-01 19:47:11,043][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 19:47:47,439][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:48:23,844][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:49:01,439][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 19:49:38,556][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:49:38,582][meta_train][INFO] - epoch_87 saved !
[2025-05-01 19:50:15,190][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 19:50:51,282][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 19:51:28,896][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:52:05,239][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 19:52:41,085][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 19:53:18,840][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:53:55,310][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 19:54:31,450][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:54:31,459][meta_train][INFO] - epoch_88 saved !
[2025-05-01 19:55:08,565][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 19:55:44,438][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 19:56:22,080][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 19:56:59,560][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 19:57:35,598][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 19:58:12,887][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 19:58:48,649][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 19:59:25,647][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 19:59:25,666][meta_train][INFO] - epoch_89 saved !
[2025-05-01 20:00:03,332][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6055, lr=0.001
[2025-05-01 20:00:41,029][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:01:17,144][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:01:54,038][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:02:29,320][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:03:06,592][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:03:44,613][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:04:19,910][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:04:19,920][meta_train][INFO] - epoch_90 saved !
[2025-05-01 20:04:57,024][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:05:34,438][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:06:11,777][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-01 20:06:48,253][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:07:26,309][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:08:02,997][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:08:38,416][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-01 20:09:15,332][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:09:15,353][meta_train][INFO] - epoch_91 saved !
[2025-05-01 20:09:52,059][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:10:27,837][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:11:05,172][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:11:42,009][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:12:17,848][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 20:12:55,147][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:13:30,764][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:14:08,281][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:14:08,292][meta_train][INFO] - epoch_92 saved !
[2025-05-01 20:14:45,949][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:15:22,152][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-01 20:15:58,570][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:16:36,705][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:17:13,127][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6055, lr=0.001
[2025-05-01 20:17:49,900][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-01 20:18:25,911][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:19:02,884][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:19:02,898][meta_train][INFO] - epoch_93 saved !
[2025-05-01 20:19:39,633][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:20:16,233][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:20:52,499][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:21:29,217][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:22:06,341][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:22:43,330][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:23:19,156][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:23:57,089][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-01 20:23:57,098][meta_train][INFO] - epoch_94 saved !
[2025-05-01 20:24:33,341][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:25:11,164][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:25:48,129][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:26:23,557][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:27:01,291][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:27:37,540][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:28:14,731][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:28:50,208][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:28:50,224][meta_train][INFO] - epoch_95 saved !
[2025-05-01 20:29:27,674][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:30:03,901][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6056, lr=0.001
[2025-05-01 20:30:40,871][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:31:17,602][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:31:54,072][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6058, lr=0.001
[2025-05-01 20:32:30,946][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6056, lr=0.001
[2025-05-01 20:33:07,145][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:33:45,269][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:33:45,279][meta_train][INFO] - epoch_96 saved !
[2025-05-01 20:34:21,591][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:34:58,748][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:35:36,507][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:36:12,105][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:36:49,557][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:37:25,859][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:38:02,139][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6056, lr=0.001
[2025-05-01 20:38:39,909][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:38:39,927][meta_train][INFO] - epoch_97 saved !
[2025-05-01 20:39:16,669][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:39:54,282][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:40:31,815][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6056, lr=0.001
[2025-05-01 20:41:07,011][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6057, lr=0.001
[2025-05-01 20:41:44,158][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:42:21,281][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:42:59,315][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6058, lr=0.001
[2025-05-01 20:43:35,218][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:43:35,229][meta_train][INFO] - epoch_98 saved !
[2025-05-01 20:44:13,165][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6057, lr=0.001
[2025-05-01 20:44:49,116][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:45:27,200][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:46:04,226][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6056, lr=0.001
[2025-05-01 20:46:40,604][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-01 20:47:17,095][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:47:53,652][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:48:31,635][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6056, lr=0.001
[2025-05-01 20:48:31,645][meta_train][INFO] - epoch_99 saved !
[2025-05-01 20:49:08,531][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-01 20:49:45,487][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-01 20:50:21,583][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6057, lr=0.001
[2025-05-01 20:50:57,985][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6058, lr=0.001
[2025-05-01 20:51:36,453][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6056, lr=0.001
[2025-05-01 20:52:13,209][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6057, lr=0.001
[2025-05-01 20:52:50,208][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6057, lr=0.001
[2025-05-01 20:53:26,109][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6057, lr=0.001
[2025-05-01 20:53:26,127][meta_train][INFO] - epoch_100 saved !
[2025-05-01 22:20:40,762][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:20:40,854][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 22:20:53,489][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:20:53,544][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:10,082][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:21:16,936][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6071, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:23,776][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:21:25,433][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-01 22:21:32,176][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-01 22:21:32,723][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:21:32,787][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 22:21:33,443][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:21:39,791][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:21:41,720][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:21:47,943][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:21:50,247][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:21:56,542][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:21:58,823][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-01 22:22:04,088][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:22:04,326][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-01 22:22:06,441][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:11,849][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:22:12,081][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-01 22:22:13,889][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:19,542][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:19,755][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-01 22:22:21,360][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:27,102][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6067, lr=0.0100
[2025-05-01 22:22:27,251][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-01 22:22:29,358][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:35,081][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-01 22:22:35,109][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:22:37,256][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:42,853][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:22:42,882][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-01 22:22:44,938][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:50,436][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-01 22:22:50,618][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:22:52,882][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:22:58,231][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:22:58,279][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:23:00,536][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:05,959][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-01 22:23:06,168][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:08,492][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:13,636][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:13,709][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-01 22:23:15,951][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:21,287][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:21,810][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:23:23,826][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:29,079][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-01 22:23:29,501][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-01 22:23:31,580][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:36,816][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:37,123][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:23:39,512][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:44,096][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:44,886][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:47,280][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:51,711][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:23:52,535][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-01 22:23:54,903][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:23:59,054][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:00,285][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-01 22:24:02,597][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:06,603][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:08,078][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-01 22:24:10,092][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:14,330][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:15,862][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:17,948][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:22,126][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:23,531][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:25,638][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:29,927][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:31,461][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:33,340][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:37,428][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:39,354][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-01 22:24:40,955][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:24:45,225][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:47,014][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:48,825][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:52,688][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:24:54,836][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:24:56,375][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:00,405][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:02,361][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:04,351][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:08,378][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:10,051][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:11,556][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:16,277][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:18,052][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:19,420][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:24,085][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:25,619][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-01 22:25:27,140][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:31,636][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:33,191][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:34,782][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:39,288][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:40,921][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:42,657][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:46,664][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:48,792][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:50,437][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:54,164][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:56,802][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:25:58,430][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:01,678][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:04,139][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:06,157][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:09,706][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:11,799][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:14,047][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:17,674][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:19,592][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:21,758][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:25,103][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:26,936][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:29,586][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:32,753][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:34,608][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:37,735][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:40,372][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:42,315][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:45,885][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:48,151][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:50,274][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:53,841][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:55,812][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:26:57,958][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:01,580][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:03,417][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:05,788][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:09,080][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:11,444][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:13,524][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:17,124][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:18,881][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:21,343][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:24,490][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:26,242][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:28,774][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:32,161][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:34,356][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:36,496][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:39,818][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:41,864][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:44,045][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:47,604][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:49,566][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:51,899][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:55,589][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:57,327][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:27:59,844][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:03,491][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:04,963][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:07,634][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:11,296][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:12,336][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:15,704][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:19,063][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:20,057][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:23,484][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:26,827][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:27,799][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:31,171][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:34,047][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:35,678][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:38,897][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:42,044][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:43,606][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:46,525][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:49,327][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:51,277][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:54,500][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:57,086][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:28:59,116][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:01,990][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:05,165][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:06,971][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:09,898][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:12,424][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:14,472][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:17,535][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:20,154][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:22,277][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:25,251][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:28,085][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:29,979][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:32,655][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:35,937][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:37,417][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:39,926][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:43,664][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:44,970][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:47,506][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-01 22:29:51,305][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:52,714][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:54,954][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:58,859][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:29:59,716][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:02,838][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:06,423][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:07,437][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:10,664][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:13,717][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:15,241][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:17,953][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:21,477][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:23,015][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:25,676][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:29,448][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:30,269][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:33,295][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:37,045][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:37,738][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:40,981][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:44,911][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:45,686][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:48,580][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:52,658][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:53,378][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:30:56,362][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:00,475][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:01,099][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:04,028][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:08,011][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:08,631][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:11,550][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:15,596][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:16,453][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:19,278][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:23,291][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:24,255][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:26,768][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:30,711][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:31,853][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:34,004][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:38,254][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:39,304][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:41,552][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:46,060][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:47,070][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:49,408][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:53,455][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:54,640][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:31:57,145][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:01,225][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:02,395][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:04,871][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:08,834][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:09,625][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:12,260][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:16,090][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:16,669][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:19,403][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:23,246][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:23,736][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:26,687][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:30,511][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:30,862][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:34,041][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:37,929][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:38,148][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:41,378][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:45,194][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:45,298][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:48,582][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:52,352][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:52,445][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:32:55,967][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:32:59,603][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:32:59,707][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:03,154][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:06,848][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:07,074][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:10,475][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:13,841][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:14,282][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:17,514][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:20,891][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:21,561][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:24,743][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:27,741][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:28,549][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:31,931][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-01 22:33:34,695][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:35,925][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:39,276][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:41,566][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:43,162][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:46,501][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:48,710][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:50,475][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:53,864][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:55,660][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:33:58,064][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:01,092][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:02,967][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:03,494][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:03,500][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:34:08,243][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:08,248][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:34:08,763][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:16,487][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:24,260][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:31,931][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:39,897][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:47,626][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-01 22:34:52,848][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:34:52,856][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 22:36:04,917][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:36:05,466][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:36:47,864][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 22:38:03,496][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:04,024][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 22:38:11,144][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:11,664][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 22:38:44,167][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 22:38:44,633][Visualize acc speed up curve][INFO] - End visualizing
Could not override 'pruning_index'.
To append to your config use +pruning_index=3.0
Key 'pruning_index' is not in struct
    full_key: pruning_index
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-01 22:55:57,798][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 22:55:57,854][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 22:56:27,487][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 22:56:35,449][train][INFO] - Epoch 1/100, Val Acc=0.0706, Val Loss=3.8937, lr=0.0100
[2025-05-01 22:56:43,649][train][INFO] - Epoch 2/100, Val Acc=0.2108, Val Loss=2.9731, lr=0.0100
[2025-05-01 22:56:51,633][train][INFO] - Epoch 3/100, Val Acc=0.2912, Val Loss=2.7967, lr=0.0100
[2025-05-01 22:56:59,007][train][INFO] - Epoch 4/100, Val Acc=0.4286, Val Loss=2.0857, lr=0.0100
[2025-05-01 22:57:06,790][train][INFO] - Epoch 5/100, Val Acc=0.4561, Val Loss=2.0563, lr=0.0100
[2025-05-01 22:57:14,624][train][INFO] - Epoch 6/100, Val Acc=0.4436, Val Loss=2.2707, lr=0.0100
[2025-05-01 22:57:22,444][train][INFO] - Epoch 7/100, Val Acc=0.5218, Val Loss=1.8155, lr=0.0100
[2025-05-01 22:57:30,925][train][INFO] - Epoch 8/100, Val Acc=0.5249, Val Loss=1.8638, lr=0.0100
[2025-05-01 22:57:39,140][train][INFO] - Epoch 9/100, Val Acc=0.5352, Val Loss=1.8255, lr=0.0100
[2025-05-01 22:57:47,381][train][INFO] - Epoch 10/100, Val Acc=0.5553, Val Loss=1.7265, lr=0.0100
[2025-05-01 22:57:55,171][train][INFO] - Epoch 11/100, Val Acc=0.5912, Val Loss=1.5787, lr=0.0100
[2025-05-01 22:58:02,764][train][INFO] - Epoch 12/100, Val Acc=0.5757, Val Loss=1.6837, lr=0.0100
[2025-05-01 22:58:10,359][train][INFO] - Epoch 13/100, Val Acc=0.5847, Val Loss=1.6419, lr=0.0100
[2025-05-01 22:58:18,590][train][INFO] - Epoch 14/100, Val Acc=0.5962, Val Loss=1.5629, lr=0.0100
[2025-05-01 22:58:26,410][train][INFO] - Epoch 15/100, Val Acc=0.5978, Val Loss=1.6183, lr=0.0100
[2025-05-01 22:58:34,433][train][INFO] - Epoch 16/100, Val Acc=0.6105, Val Loss=1.5315, lr=0.0100
[2025-05-01 22:58:42,313][train][INFO] - Epoch 17/100, Val Acc=0.5738, Val Loss=1.7595, lr=0.0100
[2025-05-01 22:58:49,462][train][INFO] - Epoch 18/100, Val Acc=0.6279, Val Loss=1.4818, lr=0.0100
[2025-05-01 22:58:57,267][train][INFO] - Epoch 19/100, Val Acc=0.6344, Val Loss=1.4927, lr=0.0100
[2025-05-01 22:59:05,442][train][INFO] - Epoch 20/100, Val Acc=0.6238, Val Loss=1.5212, lr=0.0100
[2025-05-01 22:59:13,539][train][INFO] - Epoch 21/100, Val Acc=0.6147, Val Loss=1.5916, lr=0.0100
[2025-05-01 22:59:21,252][train][INFO] - Epoch 22/100, Val Acc=0.6151, Val Loss=1.6332, lr=0.0100
[2025-05-01 22:59:29,180][train][INFO] - Epoch 23/100, Val Acc=0.6109, Val Loss=1.6300, lr=0.0100
[2025-05-01 22:59:36,781][train][INFO] - Epoch 24/100, Val Acc=0.6447, Val Loss=1.4446, lr=0.0100
[2025-05-01 22:59:44,274][train][INFO] - Epoch 25/100, Val Acc=0.6389, Val Loss=1.5132, lr=0.0100
[2025-05-01 22:59:51,807][train][INFO] - Epoch 26/100, Val Acc=0.6126, Val Loss=1.6543, lr=0.0100
[2025-05-01 22:59:59,487][train][INFO] - Epoch 27/100, Val Acc=0.6025, Val Loss=1.7044, lr=0.0100
[2025-05-01 23:00:07,736][train][INFO] - Epoch 28/100, Val Acc=0.6349, Val Loss=1.5484, lr=0.0100
[2025-05-01 23:00:10,220][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Dave
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-01 23:00:10,278][get_dataset_model_loader][INFO] - ==================================================
[2025-05-01 23:00:16,546][train][INFO] - Epoch 29/100, Val Acc=0.6474, Val Loss=1.4652, lr=0.0100
[2025-05-01 23:00:24,669][train][INFO] - Epoch 30/100, Val Acc=0.6550, Val Loss=1.4441, lr=0.0100
[2025-05-01 23:00:32,698][train][INFO] - Epoch 31/100, Val Acc=0.6458, Val Loss=1.5034, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-01 23:00:40,273][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 23:00:40,892][train][INFO] - Epoch 32/100, Val Acc=0.6276, Val Loss=1.5984, lr=0.0100
[2025-05-01 23:00:48,770][train][INFO] - Epoch 1/100, Val Acc=0.0294, Val Loss=4.5471, lr=0.0100
[2025-05-01 23:00:49,111][train][INFO] - Epoch 33/100, Val Acc=0.6379, Val Loss=1.5567, lr=0.0100
[2025-05-01 23:00:56,685][train][INFO] - Epoch 34/100, Val Acc=0.6523, Val Loss=1.4781, lr=0.0100
[2025-05-01 23:00:57,194][train][INFO] - Epoch 2/100, Val Acc=0.0856, Val Loss=3.8208, lr=0.0100
[2025-05-01 23:01:05,169][train][INFO] - Epoch 35/100, Val Acc=0.6443, Val Loss=1.5522, lr=0.0100
[2025-05-01 23:01:05,316][train][INFO] - Epoch 3/100, Val Acc=0.1140, Val Loss=3.6978, lr=0.0100
[2025-05-01 23:01:13,271][train][INFO] - Epoch 36/100, Val Acc=0.6421, Val Loss=1.5500, lr=0.0100
[2025-05-01 23:01:13,910][train][INFO] - Epoch 4/100, Val Acc=0.1550, Val Loss=3.3267, lr=0.0100
[2025-05-01 23:01:21,534][train][INFO] - Epoch 37/100, Val Acc=0.6285, Val Loss=1.6178, lr=0.0100
[2025-05-01 23:01:22,283][train][INFO] - Epoch 5/100, Val Acc=0.2230, Val Loss=2.9118, lr=0.0100
[2025-05-01 23:01:29,626][train][INFO] - Epoch 38/100, Val Acc=0.6208, Val Loss=1.6405, lr=0.0100
[2025-05-01 23:01:30,125][train][INFO] - Epoch 6/100, Val Acc=0.2245, Val Loss=2.9727, lr=0.0100
[2025-05-01 23:01:38,242][train][INFO] - Epoch 39/100, Val Acc=0.6448, Val Loss=1.5211, lr=0.0100
[2025-05-01 23:01:38,722][train][INFO] - Epoch 7/100, Val Acc=0.2385, Val Loss=2.9828, lr=0.0100
[2025-05-01 23:01:46,550][train][INFO] - Epoch 40/100, Val Acc=0.6589, Val Loss=1.4578, lr=0.0100
[2025-05-01 23:01:46,741][train][INFO] - Epoch 8/100, Val Acc=0.3038, Val Loss=2.5710, lr=0.0100
[2025-05-01 23:01:54,865][train][INFO] - Epoch 41/100, Val Acc=0.6410, Val Loss=1.5647, lr=0.0100
[2025-05-01 23:01:54,917][train][INFO] - Epoch 9/100, Val Acc=0.3250, Val Loss=2.5166, lr=0.0100
[2025-05-01 23:02:02,935][train][INFO] - Epoch 10/100, Val Acc=0.3479, Val Loss=2.4564, lr=0.0100
[2025-05-01 23:02:03,336][train][INFO] - Epoch 42/100, Val Acc=0.6371, Val Loss=1.5811, lr=0.0100
[2025-05-01 23:02:11,288][train][INFO] - Epoch 43/100, Val Acc=0.6444, Val Loss=1.5672, lr=0.0100
[2025-05-01 23:02:11,399][train][INFO] - Epoch 11/100, Val Acc=0.3325, Val Loss=2.5834, lr=0.0100
[2025-05-01 23:02:19,467][train][INFO] - Epoch 12/100, Val Acc=0.3833, Val Loss=2.2904, lr=0.0100
[2025-05-01 23:02:19,556][train][INFO] - Epoch 44/100, Val Acc=0.6448, Val Loss=1.5721, lr=0.0100
[2025-05-01 23:02:27,499][train][INFO] - Epoch 13/100, Val Acc=0.4030, Val Loss=2.2425, lr=0.0100
[2025-05-01 23:02:28,009][train][INFO] - Epoch 45/100, Val Acc=0.6455, Val Loss=1.5733, lr=0.0100
[2025-05-01 23:02:36,067][train][INFO] - Epoch 14/100, Val Acc=0.4293, Val Loss=2.1352, lr=0.0100
[2025-05-01 23:02:36,354][train][INFO] - Epoch 46/100, Val Acc=0.6416, Val Loss=1.5996, lr=0.0100
[2025-05-01 23:02:43,933][train][INFO] - Epoch 15/100, Val Acc=0.4002, Val Loss=2.3065, lr=0.0100
[2025-05-01 23:02:44,956][train][INFO] - Epoch 47/100, Val Acc=0.6398, Val Loss=1.6223, lr=0.0100
[2025-05-01 23:02:52,124][train][INFO] - Epoch 16/100, Val Acc=0.4199, Val Loss=2.2373, lr=0.0100
[2025-05-01 23:02:53,384][train][INFO] - Epoch 48/100, Val Acc=0.6481, Val Loss=1.5288, lr=0.0100
[2025-05-01 23:02:59,995][train][INFO] - Epoch 17/100, Val Acc=0.4732, Val Loss=1.9590, lr=0.0100
[2025-05-01 23:03:01,678][train][INFO] - Epoch 49/100, Val Acc=0.6611, Val Loss=1.4779, lr=0.0100
[2025-05-01 23:03:07,843][train][INFO] - Epoch 18/100, Val Acc=0.4517, Val Loss=2.1348, lr=0.0100
[2025-05-01 23:03:10,269][train][INFO] - Epoch 50/100, Val Acc=0.6411, Val Loss=1.6265, lr=0.0100
[2025-05-01 23:03:15,877][train][INFO] - Epoch 19/100, Val Acc=0.4934, Val Loss=1.8773, lr=0.0100
[2025-05-01 23:03:18,809][train][INFO] - Epoch 51/100, Val Acc=0.6561, Val Loss=1.5558, lr=0.0100
[2025-05-01 23:03:23,799][train][INFO] - Epoch 20/100, Val Acc=0.5124, Val Loss=1.7831, lr=0.0100
[2025-05-01 23:03:27,009][train][INFO] - Epoch 52/100, Val Acc=0.6450, Val Loss=1.6309, lr=0.0100
[2025-05-01 23:03:32,136][train][INFO] - Epoch 21/100, Val Acc=0.5039, Val Loss=1.8466, lr=0.0100
[2025-05-01 23:03:35,600][train][INFO] - Epoch 53/100, Val Acc=0.6504, Val Loss=1.5771, lr=0.0100
[2025-05-01 23:03:40,003][train][INFO] - Epoch 22/100, Val Acc=0.5157, Val Loss=1.8648, lr=0.0100
[2025-05-01 23:03:43,672][train][INFO] - Epoch 54/100, Val Acc=0.6460, Val Loss=1.6231, lr=0.0100
[2025-05-01 23:03:47,776][train][INFO] - Epoch 23/100, Val Acc=0.5083, Val Loss=1.8836, lr=0.0100
[2025-05-01 23:03:52,205][train][INFO] - Epoch 55/100, Val Acc=0.6514, Val Loss=1.5778, lr=0.0100
[2025-05-01 23:03:55,770][train][INFO] - Epoch 24/100, Val Acc=0.5194, Val Loss=1.8245, lr=0.0100
[2025-05-01 23:04:00,692][train][INFO] - Epoch 56/100, Val Acc=0.6452, Val Loss=1.6444, lr=0.0100
[2025-05-01 23:04:03,851][train][INFO] - Epoch 25/100, Val Acc=0.5575, Val Loss=1.6480, lr=0.0100
[2025-05-01 23:04:08,811][train][INFO] - Epoch 57/100, Val Acc=0.6499, Val Loss=1.5883, lr=0.0100
[2025-05-01 23:04:11,193][train][INFO] - Epoch 26/100, Val Acc=0.5416, Val Loss=1.7187, lr=0.0100
[2025-05-01 23:04:17,331][train][INFO] - Epoch 58/100, Val Acc=0.6525, Val Loss=1.5571, lr=0.0100
[2025-05-01 23:04:19,180][train][INFO] - Epoch 27/100, Val Acc=0.5269, Val Loss=1.7866, lr=0.0100
[2025-05-01 23:04:25,218][train][INFO] - Epoch 59/100, Val Acc=0.6471, Val Loss=1.5725, lr=0.0100
[2025-05-01 23:04:26,831][train][INFO] - Epoch 28/100, Val Acc=0.5291, Val Loss=1.8330, lr=0.0100
[2025-05-01 23:04:33,583][train][INFO] - Epoch 60/100, Val Acc=0.6504, Val Loss=1.5868, lr=0.0100
[2025-05-01 23:04:34,822][train][INFO] - Epoch 29/100, Val Acc=0.5462, Val Loss=1.7363, lr=0.0100
[2025-05-01 23:04:41,937][train][INFO] - Epoch 61/100, Val Acc=0.7129, Val Loss=1.2725, lr=0.0010
[2025-05-01 23:04:42,747][train][INFO] - Epoch 30/100, Val Acc=0.5812, Val Loss=1.5910, lr=0.0100
[2025-05-01 23:04:49,965][train][INFO] - Epoch 62/100, Val Acc=0.7158, Val Loss=1.2676, lr=0.0010
[2025-05-01 23:04:51,144][train][INFO] - Epoch 31/100, Val Acc=0.5492, Val Loss=1.7281, lr=0.0100
[2025-05-01 23:04:57,882][train][INFO] - Epoch 63/100, Val Acc=0.7183, Val Loss=1.2778, lr=0.0010
[2025-05-01 23:04:59,167][train][INFO] - Epoch 32/100, Val Acc=0.5605, Val Loss=1.6805, lr=0.0100
[2025-05-01 23:05:05,763][train][INFO] - Epoch 64/100, Val Acc=0.7201, Val Loss=1.2846, lr=0.0010
[2025-05-01 23:05:07,125][train][INFO] - Epoch 33/100, Val Acc=0.5724, Val Loss=1.6247, lr=0.0100
[2025-05-01 23:05:14,002][train][INFO] - Epoch 65/100, Val Acc=0.7185, Val Loss=1.2964, lr=0.0010
[2025-05-01 23:05:14,848][train][INFO] - Epoch 34/100, Val Acc=0.5814, Val Loss=1.6101, lr=0.0100
[2025-05-01 23:05:22,605][train][INFO] - Epoch 66/100, Val Acc=0.7193, Val Loss=1.3128, lr=0.0010
[2025-05-01 23:05:23,282][train][INFO] - Epoch 35/100, Val Acc=0.5657, Val Loss=1.7024, lr=0.0100
[2025-05-01 23:05:30,682][train][INFO] - Epoch 67/100, Val Acc=0.7189, Val Loss=1.3188, lr=0.0010
[2025-05-01 23:05:31,409][train][INFO] - Epoch 36/100, Val Acc=0.5633, Val Loss=1.7350, lr=0.0100
[2025-05-01 23:05:38,963][train][INFO] - Epoch 68/100, Val Acc=0.7205, Val Loss=1.3176, lr=0.0010
[2025-05-01 23:05:39,576][train][INFO] - Epoch 37/100, Val Acc=0.5837, Val Loss=1.6230, lr=0.0100
[2025-05-01 23:05:46,706][train][INFO] - Epoch 69/100, Val Acc=0.7195, Val Loss=1.3333, lr=0.0010
[2025-05-01 23:05:47,496][train][INFO] - Epoch 38/100, Val Acc=0.5669, Val Loss=1.6805, lr=0.0100
[2025-05-01 23:05:54,881][train][INFO] - Epoch 70/100, Val Acc=0.7197, Val Loss=1.3369, lr=0.0010
[2025-05-01 23:05:55,310][train][INFO] - Epoch 39/100, Val Acc=0.5559, Val Loss=1.7881, lr=0.0100
[2025-05-01 23:06:02,655][train][INFO] - Epoch 71/100, Val Acc=0.7191, Val Loss=1.3453, lr=0.0010
[2025-05-01 23:06:03,608][train][INFO] - Epoch 40/100, Val Acc=0.5763, Val Loss=1.7011, lr=0.0100
[2025-05-01 23:06:10,934][train][INFO] - Epoch 72/100, Val Acc=0.7189, Val Loss=1.3444, lr=0.0010
[2025-05-01 23:06:11,809][train][INFO] - Epoch 41/100, Val Acc=0.5834, Val Loss=1.7062, lr=0.0100
[2025-05-01 23:06:19,490][train][INFO] - Epoch 73/100, Val Acc=0.7194, Val Loss=1.3543, lr=0.0010
[2025-05-01 23:06:20,149][train][INFO] - Epoch 42/100, Val Acc=0.5766, Val Loss=1.6730, lr=0.0100
[2025-05-01 23:06:28,256][train][INFO] - Epoch 74/100, Val Acc=0.7216, Val Loss=1.3619, lr=0.0010
[2025-05-01 23:06:28,490][train][INFO] - Epoch 43/100, Val Acc=0.5826, Val Loss=1.6590, lr=0.0100
[2025-05-01 23:06:36,371][train][INFO] - Epoch 44/100, Val Acc=0.5792, Val Loss=1.6753, lr=0.0100
[2025-05-01 23:06:36,668][train][INFO] - Epoch 75/100, Val Acc=0.7204, Val Loss=1.3636, lr=0.0010
[2025-05-01 23:06:44,473][train][INFO] - Epoch 45/100, Val Acc=0.5828, Val Loss=1.6957, lr=0.0100
[2025-05-01 23:06:44,777][train][INFO] - Epoch 76/100, Val Acc=0.7190, Val Loss=1.3655, lr=0.0010
[2025-05-01 23:06:52,046][train][INFO] - Epoch 46/100, Val Acc=0.5956, Val Loss=1.6198, lr=0.0100
[2025-05-01 23:06:52,840][train][INFO] - Epoch 77/100, Val Acc=0.7213, Val Loss=1.3802, lr=0.0010
[2025-05-01 23:07:00,432][train][INFO] - Epoch 47/100, Val Acc=0.6048, Val Loss=1.5809, lr=0.0100
[2025-05-01 23:07:00,889][train][INFO] - Epoch 78/100, Val Acc=0.7216, Val Loss=1.3769, lr=0.0010
[2025-05-01 23:07:08,491][train][INFO] - Epoch 79/100, Val Acc=0.7207, Val Loss=1.3812, lr=0.0010
[2025-05-01 23:07:08,493][train][INFO] - Epoch 48/100, Val Acc=0.6090, Val Loss=1.5786, lr=0.0100
[2025-05-01 23:07:16,691][train][INFO] - Epoch 80/100, Val Acc=0.7197, Val Loss=1.3875, lr=0.0010
[2025-05-01 23:07:16,725][train][INFO] - Epoch 49/100, Val Acc=0.6058, Val Loss=1.5649, lr=0.0100
[2025-05-01 23:07:24,812][train][INFO] - Epoch 81/100, Val Acc=0.7200, Val Loss=1.3970, lr=0.0010
[2025-05-01 23:07:25,066][train][INFO] - Epoch 50/100, Val Acc=0.6052, Val Loss=1.5704, lr=0.0100
[2025-05-01 23:07:32,921][train][INFO] - Epoch 82/100, Val Acc=0.7223, Val Loss=1.3973, lr=0.0010
[2025-05-01 23:07:33,064][train][INFO] - Epoch 51/100, Val Acc=0.6037, Val Loss=1.6158, lr=0.0100
[2025-05-01 23:07:40,735][train][INFO] - Epoch 52/100, Val Acc=0.6006, Val Loss=1.6191, lr=0.0100
[2025-05-01 23:07:41,114][train][INFO] - Epoch 83/100, Val Acc=0.7222, Val Loss=1.3847, lr=0.0010
[2025-05-01 23:07:48,526][train][INFO] - Epoch 53/100, Val Acc=0.6043, Val Loss=1.5945, lr=0.0100
[2025-05-01 23:07:48,594][train][INFO] - Epoch 84/100, Val Acc=0.7229, Val Loss=1.3986, lr=0.0010
[2025-05-01 23:07:55,875][train][INFO] - Epoch 85/100, Val Acc=0.7237, Val Loss=1.4124, lr=0.0010
[2025-05-01 23:07:56,230][train][INFO] - Epoch 54/100, Val Acc=0.5996, Val Loss=1.6636, lr=0.0100
[2025-05-01 23:08:03,712][train][INFO] - Epoch 86/100, Val Acc=0.7230, Val Loss=1.4058, lr=0.0010
[2025-05-01 23:08:03,976][train][INFO] - Epoch 55/100, Val Acc=0.6140, Val Loss=1.5015, lr=0.0100
[2025-05-01 23:08:11,467][train][INFO] - Epoch 87/100, Val Acc=0.7249, Val Loss=1.4100, lr=0.0010
[2025-05-01 23:08:12,032][train][INFO] - Epoch 56/100, Val Acc=0.6129, Val Loss=1.5736, lr=0.0100
[2025-05-01 23:08:19,915][train][INFO] - Epoch 88/100, Val Acc=0.7224, Val Loss=1.4000, lr=0.0010
[2025-05-01 23:08:19,976][train][INFO] - Epoch 57/100, Val Acc=0.5853, Val Loss=1.7358, lr=0.0100
[2025-05-01 23:08:27,769][train][INFO] - Epoch 89/100, Val Acc=0.7242, Val Loss=1.4086, lr=0.0010
[2025-05-01 23:08:28,345][train][INFO] - Epoch 58/100, Val Acc=0.6109, Val Loss=1.5894, lr=0.0100
[2025-05-01 23:08:36,295][train][INFO] - Epoch 90/100, Val Acc=0.7213, Val Loss=1.4144, lr=0.0010
[2025-05-01 23:08:36,437][train][INFO] - Epoch 59/100, Val Acc=0.6199, Val Loss=1.5124, lr=0.0100
[2025-05-01 23:08:43,566][train][INFO] - Epoch 60/100, Val Acc=0.6216, Val Loss=1.5584, lr=0.0100
[2025-05-01 23:08:44,079][train][INFO] - Epoch 91/100, Val Acc=0.7226, Val Loss=1.4094, lr=0.0001
[2025-05-01 23:08:51,447][train][INFO] - Epoch 61/100, Val Acc=0.6754, Val Loss=1.2923, lr=0.0010
[2025-05-01 23:08:52,382][train][INFO] - Epoch 92/100, Val Acc=0.7237, Val Loss=1.4149, lr=0.0001
[2025-05-01 23:08:59,609][train][INFO] - Epoch 62/100, Val Acc=0.6826, Val Loss=1.2875, lr=0.0010
[2025-05-01 23:09:00,333][train][INFO] - Epoch 93/100, Val Acc=0.7230, Val Loss=1.4141, lr=0.0001
[2025-05-01 23:09:07,782][train][INFO] - Epoch 63/100, Val Acc=0.6840, Val Loss=1.2946, lr=0.0010
[2025-05-01 23:09:08,514][train][INFO] - Epoch 94/100, Val Acc=0.7241, Val Loss=1.4118, lr=0.0001
[2025-05-01 23:09:15,862][train][INFO] - Epoch 64/100, Val Acc=0.6818, Val Loss=1.3046, lr=0.0010
[2025-05-01 23:09:16,245][train][INFO] - Epoch 95/100, Val Acc=0.7234, Val Loss=1.4121, lr=0.0001
[2025-05-01 23:09:23,621][train][INFO] - Epoch 65/100, Val Acc=0.6831, Val Loss=1.3007, lr=0.0010
[2025-05-01 23:09:24,499][train][INFO] - Epoch 96/100, Val Acc=0.7232, Val Loss=1.4080, lr=0.0001
[2025-05-01 23:09:31,850][train][INFO] - Epoch 66/100, Val Acc=0.6834, Val Loss=1.3195, lr=0.0010
[2025-05-01 23:09:32,641][train][INFO] - Epoch 97/100, Val Acc=0.7237, Val Loss=1.4129, lr=0.0001
[2025-05-01 23:09:39,694][train][INFO] - Epoch 67/100, Val Acc=0.6832, Val Loss=1.3202, lr=0.0010
[2025-05-01 23:09:41,237][train][INFO] - Epoch 98/100, Val Acc=0.7242, Val Loss=1.4058, lr=0.0001
[2025-05-01 23:09:48,079][train][INFO] - Epoch 68/100, Val Acc=0.6850, Val Loss=1.3252, lr=0.0010
[2025-05-01 23:09:49,397][train][INFO] - Epoch 99/100, Val Acc=0.7238, Val Loss=1.4111, lr=0.0001
[2025-05-01 23:09:56,045][train][INFO] - Epoch 69/100, Val Acc=0.6862, Val Loss=1.3308, lr=0.0010
[2025-05-01 23:09:57,731][train][INFO] - Epoch 100/100, Val Acc=0.7246, Val Loss=1.4087, lr=0.0001
[2025-05-01 23:10:02,885][train][INFO] - After training : Train Acc=0.9963  Val Acc=0.7249
[2025-05-01 23:10:04,177][train][INFO] - Epoch 70/100, Val Acc=0.6844, Val Loss=1.3419, lr=0.0010
[2025-05-01 23:10:12,496][train][INFO] - Epoch 71/100, Val Acc=0.6822, Val Loss=1.3559, lr=0.0010
[2025-05-01 23:10:13,667][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-01 23:10:13,668][Progressive pruning][INFO] - Current speed up: 2.28
[2025-05-01 23:10:18,812][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-01 23:10:20,898][train][INFO] - Epoch 72/100, Val Acc=0.6820, Val Loss=1.3745, lr=0.0010
[2025-05-01 23:10:27,230][train][INFO] - Epoch 1/140, Val Acc=0.5282, Val Loss=2.1740, lr=0.0100
[2025-05-01 23:10:28,403][train][INFO] - Epoch 73/100, Val Acc=0.6848, Val Loss=1.3495, lr=0.0010
[2025-05-01 23:10:35,727][train][INFO] - Epoch 2/140, Val Acc=0.5519, Val Loss=2.0892, lr=0.0100
[2025-05-01 23:10:36,193][train][INFO] - Epoch 74/100, Val Acc=0.6853, Val Loss=1.3607, lr=0.0010
[2025-05-01 23:10:44,118][train][INFO] - Epoch 3/140, Val Acc=0.6038, Val Loss=1.7326, lr=0.0100
[2025-05-01 23:10:44,608][train][INFO] - Epoch 75/100, Val Acc=0.6852, Val Loss=1.3720, lr=0.0010
[2025-05-01 23:10:52,291][train][INFO] - Epoch 4/140, Val Acc=0.5981, Val Loss=1.7900, lr=0.0100
[2025-05-01 23:10:53,029][train][INFO] - Epoch 76/100, Val Acc=0.6881, Val Loss=1.3673, lr=0.0010
[2025-05-01 23:11:00,026][train][INFO] - Epoch 5/140, Val Acc=0.6090, Val Loss=1.7011, lr=0.0100
[2025-05-01 23:11:01,372][train][INFO] - Epoch 77/100, Val Acc=0.6854, Val Loss=1.3936, lr=0.0010
[2025-05-01 23:11:07,958][train][INFO] - Epoch 6/140, Val Acc=0.6190, Val Loss=1.7214, lr=0.0100
[2025-05-01 23:11:09,989][train][INFO] - Epoch 78/100, Val Acc=0.6810, Val Loss=1.3901, lr=0.0010
[2025-05-01 23:11:16,499][train][INFO] - Epoch 7/140, Val Acc=0.6441, Val Loss=1.5628, lr=0.0100
[2025-05-01 23:11:18,139][train][INFO] - Epoch 79/100, Val Acc=0.6870, Val Loss=1.4041, lr=0.0010
[2025-05-01 23:11:25,092][train][INFO] - Epoch 8/140, Val Acc=0.6165, Val Loss=1.7210, lr=0.0100
[2025-05-01 23:11:26,010][train][INFO] - Epoch 80/100, Val Acc=0.6851, Val Loss=1.4087, lr=0.0010
[2025-05-01 23:11:33,404][train][INFO] - Epoch 9/140, Val Acc=0.6123, Val Loss=1.7184, lr=0.0100
[2025-05-01 23:11:33,547][train][INFO] - Epoch 81/100, Val Acc=0.6820, Val Loss=1.4197, lr=0.0010
[2025-05-01 23:11:41,199][train][INFO] - Epoch 82/100, Val Acc=0.6856, Val Loss=1.4154, lr=0.0010
[2025-05-01 23:11:42,190][train][INFO] - Epoch 10/140, Val Acc=0.6404, Val Loss=1.5901, lr=0.0100
[2025-05-01 23:11:49,426][train][INFO] - Epoch 83/100, Val Acc=0.6814, Val Loss=1.4278, lr=0.0010
[2025-05-01 23:11:50,268][train][INFO] - Epoch 11/140, Val Acc=0.6406, Val Loss=1.6072, lr=0.0100
[2025-05-01 23:11:57,082][train][INFO] - Epoch 84/100, Val Acc=0.6829, Val Loss=1.4447, lr=0.0010
[2025-05-01 23:11:58,128][train][INFO] - Epoch 12/140, Val Acc=0.6338, Val Loss=1.6312, lr=0.0100
[2025-05-01 23:12:05,516][train][INFO] - Epoch 85/100, Val Acc=0.6854, Val Loss=1.4329, lr=0.0010
[2025-05-01 23:12:05,551][train][INFO] - Epoch 13/140, Val Acc=0.6244, Val Loss=1.6705, lr=0.0100
[2025-05-01 23:12:13,975][train][INFO] - Epoch 86/100, Val Acc=0.6820, Val Loss=1.4432, lr=0.0010
[2025-05-01 23:12:14,245][train][INFO] - Epoch 14/140, Val Acc=0.6256, Val Loss=1.6830, lr=0.0100
[2025-05-01 23:12:21,070][train][INFO] - Epoch 87/100, Val Acc=0.6816, Val Loss=1.4503, lr=0.0010
[2025-05-01 23:12:22,415][train][INFO] - Epoch 15/140, Val Acc=0.6267, Val Loss=1.7233, lr=0.0100
[2025-05-01 23:12:29,450][train][INFO] - Epoch 88/100, Val Acc=0.6818, Val Loss=1.4579, lr=0.0010
[2025-05-01 23:12:30,966][train][INFO] - Epoch 16/140, Val Acc=0.6362, Val Loss=1.6747, lr=0.0100
[2025-05-01 23:12:37,850][train][INFO] - Epoch 89/100, Val Acc=0.6789, Val Loss=1.4684, lr=0.0010
[2025-05-01 23:12:39,462][train][INFO] - Epoch 17/140, Val Acc=0.6363, Val Loss=1.6340, lr=0.0100
[2025-05-01 23:12:45,616][train][INFO] - Epoch 90/100, Val Acc=0.6844, Val Loss=1.4764, lr=0.0010
[2025-05-01 23:12:47,697][train][INFO] - Epoch 18/140, Val Acc=0.6438, Val Loss=1.6118, lr=0.0100
[2025-05-01 23:12:53,794][train][INFO] - Epoch 91/100, Val Acc=0.6841, Val Loss=1.4570, lr=0.0001
[2025-05-01 23:12:55,595][train][INFO] - Epoch 19/140, Val Acc=0.6346, Val Loss=1.6836, lr=0.0100
[2025-05-01 23:13:01,712][train][INFO] - Epoch 92/100, Val Acc=0.6841, Val Loss=1.4638, lr=0.0001
[2025-05-01 23:13:04,132][train][INFO] - Epoch 20/140, Val Acc=0.6437, Val Loss=1.6113, lr=0.0100
[2025-05-01 23:13:09,744][train][INFO] - Epoch 93/100, Val Acc=0.6857, Val Loss=1.4591, lr=0.0001
[2025-05-01 23:13:12,546][train][INFO] - Epoch 21/140, Val Acc=0.6310, Val Loss=1.7069, lr=0.0100
[2025-05-01 23:13:16,803][train][INFO] - Epoch 94/100, Val Acc=0.6878, Val Loss=1.4511, lr=0.0001
[2025-05-01 23:13:20,696][train][INFO] - Epoch 22/140, Val Acc=0.6355, Val Loss=1.7047, lr=0.0100
[2025-05-01 23:13:24,854][train][INFO] - Epoch 95/100, Val Acc=0.6865, Val Loss=1.4601, lr=0.0001
[2025-05-01 23:13:28,701][train][INFO] - Epoch 23/140, Val Acc=0.6420, Val Loss=1.6657, lr=0.0100
[2025-05-01 23:13:33,355][train][INFO] - Epoch 96/100, Val Acc=0.6874, Val Loss=1.4536, lr=0.0001
[2025-05-01 23:13:37,145][train][INFO] - Epoch 24/140, Val Acc=0.6280, Val Loss=1.7396, lr=0.0100
[2025-05-01 23:13:41,763][train][INFO] - Epoch 97/100, Val Acc=0.6855, Val Loss=1.4601, lr=0.0001
[2025-05-01 23:13:45,582][train][INFO] - Epoch 25/140, Val Acc=0.6282, Val Loss=1.7342, lr=0.0100
[2025-05-01 23:13:50,437][train][INFO] - Epoch 98/100, Val Acc=0.6859, Val Loss=1.4594, lr=0.0001
[2025-05-01 23:13:53,996][train][INFO] - Epoch 26/140, Val Acc=0.6417, Val Loss=1.6490, lr=0.0100
[2025-05-01 23:13:58,726][train][INFO] - Epoch 99/100, Val Acc=0.6884, Val Loss=1.4637, lr=0.0001
[2025-05-01 23:14:02,424][train][INFO] - Epoch 27/140, Val Acc=0.6360, Val Loss=1.6876, lr=0.0100
[2025-05-01 23:14:06,532][train][INFO] - Epoch 100/100, Val Acc=0.6860, Val Loss=1.4632, lr=0.0001
[2025-05-01 23:14:10,765][train][INFO] - Epoch 28/140, Val Acc=0.6390, Val Loss=1.6520, lr=0.0100
[2025-05-01 23:14:11,781][train][INFO] - After training : Train Acc=0.9632  Val Acc=0.6884
[2025-05-01 23:14:11,790][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-01 23:14:18,852][train][INFO] - Epoch 29/140, Val Acc=0.6502, Val Loss=1.5822, lr=0.0100
[2025-05-01 23:14:27,408][train][INFO] - Epoch 30/140, Val Acc=0.6428, Val Loss=1.6443, lr=0.0100
[2025-05-01 23:14:35,868][train][INFO] - Epoch 31/140, Val Acc=0.6311, Val Loss=1.7504, lr=0.0100
[2025-05-01 23:14:44,151][train][INFO] - Epoch 32/140, Val Acc=0.6478, Val Loss=1.6185, lr=0.0100
[2025-05-01 23:14:52,489][train][INFO] - Epoch 33/140, Val Acc=0.6503, Val Loss=1.6151, lr=0.0100
[2025-05-01 23:15:00,630][train][INFO] - Epoch 34/140, Val Acc=0.6361, Val Loss=1.7393, lr=0.0100
[2025-05-01 23:15:08,894][train][INFO] - Epoch 35/140, Val Acc=0.6071, Val Loss=1.8943, lr=0.0100
[2025-05-01 23:15:16,920][train][INFO] - Epoch 36/140, Val Acc=0.6549, Val Loss=1.5716, lr=0.0100
[2025-05-01 23:15:24,956][train][INFO] - Epoch 37/140, Val Acc=0.6398, Val Loss=1.6666, lr=0.0100
[2025-05-01 23:15:32,692][train][INFO] - Epoch 38/140, Val Acc=0.6483, Val Loss=1.6383, lr=0.0100
[2025-05-01 23:15:41,128][train][INFO] - Epoch 39/140, Val Acc=0.6314, Val Loss=1.7582, lr=0.0100
[2025-05-01 23:15:48,636][train][INFO] - Epoch 40/140, Val Acc=0.6456, Val Loss=1.6652, lr=0.0100
[2025-05-01 23:15:56,720][train][INFO] - Epoch 41/140, Val Acc=0.6392, Val Loss=1.6786, lr=0.0100
[2025-05-01 23:16:02,069][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-01 23:16:04,927][train][INFO] - Epoch 42/140, Val Acc=0.6460, Val Loss=1.6137, lr=0.0100
[2025-05-01 23:16:13,247][train][INFO] - Epoch 43/140, Val Acc=0.6219, Val Loss=1.7683, lr=0.0100
[2025-05-01 23:16:21,350][train][INFO] - Epoch 44/140, Val Acc=0.6516, Val Loss=1.6147, lr=0.0100
[2025-05-01 23:16:29,610][train][INFO] - Epoch 45/140, Val Acc=0.6260, Val Loss=1.7713, lr=0.0100
[2025-05-01 23:16:37,975][train][INFO] - Epoch 46/140, Val Acc=0.6402, Val Loss=1.6494, lr=0.0100
[2025-05-01 23:16:45,721][train][INFO] - Epoch 47/140, Val Acc=0.6399, Val Loss=1.7253, lr=0.0100
[2025-05-01 23:16:54,144][train][INFO] - Epoch 48/140, Val Acc=0.6345, Val Loss=1.7356, lr=0.0100
[2025-05-01 23:17:01,772][train][INFO] - Epoch 49/140, Val Acc=0.6541, Val Loss=1.6278, lr=0.0100
[2025-05-01 23:17:10,225][train][INFO] - Epoch 50/140, Val Acc=0.6169, Val Loss=1.8158, lr=0.0100
[2025-05-01 23:17:17,938][train][INFO] - Epoch 51/140, Val Acc=0.6379, Val Loss=1.7416, lr=0.0100
[2025-05-01 23:17:26,320][train][INFO] - Epoch 52/140, Val Acc=0.6299, Val Loss=1.7691, lr=0.0100
[2025-05-01 23:17:34,447][train][INFO] - Epoch 53/140, Val Acc=0.6317, Val Loss=1.7385, lr=0.0100
[2025-05-01 23:17:42,816][train][INFO] - Epoch 54/140, Val Acc=0.6300, Val Loss=1.7757, lr=0.0100
[2025-05-01 23:17:50,947][train][INFO] - Epoch 55/140, Val Acc=0.6337, Val Loss=1.7563, lr=0.0100
[2025-05-01 23:17:59,437][train][INFO] - Epoch 56/140, Val Acc=0.6413, Val Loss=1.6504, lr=0.0100
[2025-05-01 23:18:07,250][train][INFO] - Epoch 57/140, Val Acc=0.6327, Val Loss=1.7381, lr=0.0100
[2025-05-01 23:18:15,580][train][INFO] - Epoch 58/140, Val Acc=0.6369, Val Loss=1.7281, lr=0.0100
[2025-05-01 23:18:23,684][train][INFO] - Epoch 59/140, Val Acc=0.6137, Val Loss=1.8401, lr=0.0100
[2025-05-01 23:18:24,057][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-01 23:18:24,528][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-01 23:18:30,662][train][INFO] - Epoch 60/140, Val Acc=0.6358, Val Loss=1.7031, lr=0.0100
[2025-05-01 23:18:38,818][train][INFO] - Epoch 61/140, Val Acc=0.6495, Val Loss=1.6334, lr=0.0100
[2025-05-01 23:18:46,899][train][INFO] - Epoch 62/140, Val Acc=0.6495, Val Loss=1.6509, lr=0.0100
[2025-05-01 23:18:55,184][train][INFO] - Epoch 63/140, Val Acc=0.6517, Val Loss=1.6168, lr=0.0100
[2025-05-01 23:19:03,330][train][INFO] - Epoch 64/140, Val Acc=0.6411, Val Loss=1.6671, lr=0.0100
[2025-05-01 23:19:11,493][train][INFO] - Epoch 65/140, Val Acc=0.6460, Val Loss=1.7068, lr=0.0100
[2025-05-01 23:19:18,817][train][INFO] - Epoch 66/140, Val Acc=0.6397, Val Loss=1.7072, lr=0.0100
[2025-05-01 23:19:26,829][train][INFO] - Epoch 67/140, Val Acc=0.6275, Val Loss=1.7786, lr=0.0100
[2025-05-01 23:19:34,667][train][INFO] - Epoch 68/140, Val Acc=0.6337, Val Loss=1.7595, lr=0.0100
[2025-05-01 23:19:42,507][train][INFO] - Epoch 69/140, Val Acc=0.6524, Val Loss=1.6624, lr=0.0100
[2025-05-01 23:19:49,849][train][INFO] - Epoch 70/140, Val Acc=0.6445, Val Loss=1.7186, lr=0.0100
[2025-05-01 23:19:58,442][train][INFO] - Epoch 71/140, Val Acc=0.6274, Val Loss=1.7966, lr=0.0100
[2025-05-01 23:20:06,127][train][INFO] - Epoch 72/140, Val Acc=0.6466, Val Loss=1.6838, lr=0.0100
[2025-05-01 23:20:14,760][train][INFO] - Epoch 73/140, Val Acc=0.6384, Val Loss=1.7065, lr=0.0100
[2025-05-01 23:20:22,856][train][INFO] - Epoch 74/140, Val Acc=0.6459, Val Loss=1.6645, lr=0.0100
[2025-05-01 23:20:30,914][train][INFO] - Epoch 75/140, Val Acc=0.6449, Val Loss=1.7158, lr=0.0100
[2025-05-01 23:20:39,532][train][INFO] - Epoch 76/140, Val Acc=0.6282, Val Loss=1.7950, lr=0.0100
[2025-05-01 23:20:47,589][train][INFO] - Epoch 77/140, Val Acc=0.6449, Val Loss=1.6657, lr=0.0100
[2025-05-01 23:20:54,919][train][INFO] - Epoch 78/140, Val Acc=0.6361, Val Loss=1.7484, lr=0.0100
[2025-05-01 23:21:03,376][train][INFO] - Epoch 79/140, Val Acc=0.6442, Val Loss=1.7153, lr=0.0100
[2025-05-01 23:21:11,975][train][INFO] - Epoch 80/140, Val Acc=0.6453, Val Loss=1.6753, lr=0.0100
[2025-05-01 23:21:20,170][train][INFO] - Epoch 81/140, Val Acc=0.7000, Val Loss=1.4090, lr=0.0010
[2025-05-01 23:21:27,901][train][INFO] - Epoch 82/140, Val Acc=0.7071, Val Loss=1.4032, lr=0.0010
[2025-05-01 23:21:36,079][train][INFO] - Epoch 83/140, Val Acc=0.7090, Val Loss=1.4028, lr=0.0010
[2025-05-01 23:21:44,224][train][INFO] - Epoch 84/140, Val Acc=0.7117, Val Loss=1.4092, lr=0.0010
[2025-05-01 23:21:52,587][train][INFO] - Epoch 85/140, Val Acc=0.7114, Val Loss=1.4108, lr=0.0010
[2025-05-01 23:22:00,413][train][INFO] - Epoch 86/140, Val Acc=0.7092, Val Loss=1.4225, lr=0.0010
[2025-05-01 23:22:08,342][train][INFO] - Epoch 87/140, Val Acc=0.7133, Val Loss=1.4238, lr=0.0010
[2025-05-01 23:22:16,927][train][INFO] - Epoch 88/140, Val Acc=0.7139, Val Loss=1.4265, lr=0.0010
[2025-05-01 23:22:25,306][train][INFO] - Epoch 89/140, Val Acc=0.7121, Val Loss=1.4306, lr=0.0010
[2025-05-01 23:22:33,562][train][INFO] - Epoch 90/140, Val Acc=0.7124, Val Loss=1.4282, lr=0.0010
[2025-05-01 23:22:42,061][train][INFO] - Epoch 91/140, Val Acc=0.7128, Val Loss=1.4452, lr=0.0010
[2025-05-01 23:22:49,747][train][INFO] - Epoch 92/140, Val Acc=0.7131, Val Loss=1.4448, lr=0.0010
[2025-05-01 23:22:57,120][train][INFO] - Epoch 93/140, Val Acc=0.7155, Val Loss=1.4389, lr=0.0010
[2025-05-01 23:23:04,495][train][INFO] - Epoch 94/140, Val Acc=0.7148, Val Loss=1.4505, lr=0.0010
[2025-05-01 23:23:13,048][train][INFO] - Epoch 95/140, Val Acc=0.7160, Val Loss=1.4436, lr=0.0010
[2025-05-01 23:23:20,866][train][INFO] - Epoch 96/140, Val Acc=0.7153, Val Loss=1.4532, lr=0.0010
[2025-05-01 23:23:29,458][train][INFO] - Epoch 97/140, Val Acc=0.7139, Val Loss=1.4556, lr=0.0010
[2025-05-01 23:23:38,481][train][INFO] - Epoch 98/140, Val Acc=0.7110, Val Loss=1.4601, lr=0.0010
[2025-05-01 23:23:46,896][train][INFO] - Epoch 99/140, Val Acc=0.7130, Val Loss=1.4652, lr=0.0010
[2025-05-01 23:23:55,345][train][INFO] - Epoch 100/140, Val Acc=0.7140, Val Loss=1.4580, lr=0.0010
[2025-05-01 23:24:02,779][train][INFO] - Epoch 101/140, Val Acc=0.7119, Val Loss=1.4597, lr=0.0010
[2025-05-01 23:24:10,952][train][INFO] - Epoch 102/140, Val Acc=0.7130, Val Loss=1.4700, lr=0.0010
[2025-05-01 23:24:18,750][train][INFO] - Epoch 103/140, Val Acc=0.7162, Val Loss=1.4610, lr=0.0010
[2025-05-01 23:24:26,921][train][INFO] - Epoch 104/140, Val Acc=0.7125, Val Loss=1.4768, lr=0.0010
[2025-05-01 23:24:35,271][train][INFO] - Epoch 105/140, Val Acc=0.7151, Val Loss=1.4718, lr=0.0010
[2025-05-01 23:24:43,255][train][INFO] - Epoch 106/140, Val Acc=0.7138, Val Loss=1.4777, lr=0.0010
[2025-05-01 23:24:51,957][train][INFO] - Epoch 107/140, Val Acc=0.7160, Val Loss=1.4711, lr=0.0010
[2025-05-01 23:25:00,021][train][INFO] - Epoch 108/140, Val Acc=0.7141, Val Loss=1.4705, lr=0.0010
[2025-05-01 23:25:08,648][train][INFO] - Epoch 109/140, Val Acc=0.7171, Val Loss=1.4748, lr=0.0010
[2025-05-01 23:25:16,804][train][INFO] - Epoch 110/140, Val Acc=0.7164, Val Loss=1.4820, lr=0.0010
[2025-05-01 23:25:25,022][train][INFO] - Epoch 111/140, Val Acc=0.7203, Val Loss=1.4690, lr=0.0010
[2025-05-01 23:25:32,887][train][INFO] - Epoch 112/140, Val Acc=0.7159, Val Loss=1.4744, lr=0.0010
[2025-05-01 23:25:41,279][train][INFO] - Epoch 113/140, Val Acc=0.7159, Val Loss=1.4743, lr=0.0010
[2025-05-01 23:25:49,946][train][INFO] - Epoch 114/140, Val Acc=0.7155, Val Loss=1.4780, lr=0.0010
[2025-05-01 23:25:58,415][train][INFO] - Epoch 115/140, Val Acc=0.7168, Val Loss=1.4809, lr=0.0010
[2025-05-01 23:26:06,753][train][INFO] - Epoch 116/140, Val Acc=0.7161, Val Loss=1.4745, lr=0.0010
[2025-05-01 23:26:15,018][train][INFO] - Epoch 117/140, Val Acc=0.7164, Val Loss=1.4848, lr=0.0010
[2025-05-01 23:26:23,409][train][INFO] - Epoch 118/140, Val Acc=0.7149, Val Loss=1.4896, lr=0.0010
[2025-05-01 23:26:31,396][train][INFO] - Epoch 119/140, Val Acc=0.7145, Val Loss=1.4853, lr=0.0010
[2025-05-01 23:26:40,074][train][INFO] - Epoch 120/140, Val Acc=0.7134, Val Loss=1.4819, lr=0.0010
[2025-05-01 23:26:48,722][train][INFO] - Epoch 121/140, Val Acc=0.7158, Val Loss=1.4747, lr=0.0001
[2025-05-01 23:26:57,072][train][INFO] - Epoch 122/140, Val Acc=0.7146, Val Loss=1.4761, lr=0.0001
[2025-05-01 23:27:05,106][train][INFO] - Epoch 123/140, Val Acc=0.7160, Val Loss=1.4739, lr=0.0001
[2025-05-01 23:27:13,515][train][INFO] - Epoch 124/140, Val Acc=0.7162, Val Loss=1.4723, lr=0.0001
[2025-05-01 23:27:21,061][train][INFO] - Epoch 125/140, Val Acc=0.7168, Val Loss=1.4753, lr=0.0001
[2025-05-01 23:27:29,302][train][INFO] - Epoch 126/140, Val Acc=0.7188, Val Loss=1.4737, lr=0.0001
[2025-05-01 23:27:37,817][train][INFO] - Epoch 127/140, Val Acc=0.7178, Val Loss=1.4845, lr=0.0001
[2025-05-01 23:27:45,142][train][INFO] - Epoch 128/140, Val Acc=0.7181, Val Loss=1.4718, lr=0.0001
[2025-05-01 23:27:53,511][train][INFO] - Epoch 129/140, Val Acc=0.7169, Val Loss=1.4699, lr=0.0001
[2025-05-01 23:28:01,470][train][INFO] - Epoch 130/140, Val Acc=0.7173, Val Loss=1.4747, lr=0.0001
[2025-05-01 23:28:09,861][train][INFO] - Epoch 131/140, Val Acc=0.7161, Val Loss=1.4793, lr=0.0001
[2025-05-01 23:28:18,090][train][INFO] - Epoch 132/140, Val Acc=0.7160, Val Loss=1.4821, lr=0.0001
[2025-05-01 23:28:26,021][train][INFO] - Epoch 133/140, Val Acc=0.7181, Val Loss=1.4772, lr=0.0001
[2025-05-01 23:28:34,082][train][INFO] - Epoch 134/140, Val Acc=0.7184, Val Loss=1.4754, lr=0.0001
[2025-05-01 23:28:40,918][train][INFO] - Epoch 135/140, Val Acc=0.7173, Val Loss=1.4791, lr=0.0001
[2025-05-01 23:28:49,347][train][INFO] - Epoch 136/140, Val Acc=0.7180, Val Loss=1.4764, lr=0.0001
[2025-05-01 23:28:58,043][train][INFO] - Epoch 137/140, Val Acc=0.7172, Val Loss=1.4801, lr=0.0001
[2025-05-01 23:29:06,194][train][INFO] - Epoch 138/140, Val Acc=0.7192, Val Loss=1.4760, lr=0.0001
[2025-05-01 23:29:14,286][train][INFO] - Epoch 139/140, Val Acc=0.7174, Val Loss=1.4773, lr=0.0001
[2025-05-01 23:29:22,791][train][INFO] - Epoch 140/140, Val Acc=0.7172, Val Loss=1.4812, lr=0.0001
[2025-05-01 23:29:28,092][train][INFO] - After training : Train Acc=0.9984  Val Acc=0.7203
[2025-05-01 23:29:28,126][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(9, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(51, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(120, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(254, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(252, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(122, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(38, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(5, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(3, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(41, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(19, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(40, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(115, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=127, out_features=100, bias=True)
)
[2025-05-01 23:29:28,126][Pruning][INFO] - Origin val acc : 0.736799955368042 Final val acc : 0.7202999591827393
                      Speed up: 2.28   Final speed up: 3.03
[2025-05-02 11:23:14,997][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 11:23:15,088][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 11:23:15,088][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 11:23:15,088][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 11:23:31,638][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.0562, lr=0.001
[2025-05-02 11:23:45,991][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0449, lr=0.001
[2025-05-02 11:23:50,364][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Fog
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 11:23:50,442][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 11:23:50,442][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 11:23:50,442][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 11:23:59,763][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=0.0407, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 11:24:07,505][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.0562, lr=0.001
[2025-05-02 11:24:13,182][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=0.0289, lr=0.001
[2025-05-02 11:24:21,892][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0451, lr=0.001
[2025-05-02 11:24:27,116][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.0314, lr=0.001
[2025-05-02 11:24:35,409][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=0.0409, lr=0.001
[2025-05-02 11:25:34,986][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 11:25:35,066][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 11:25:35,066][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 11:25:35,066][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 11:26:04,948][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.4607, lr=0.001
[2025-05-02 11:26:34,210][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.1458, lr=0.001
[2025-05-02 11:27:02,249][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.0314, lr=0.001
[2025-05-02 11:27:30,067][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=3.8544, lr=0.001
[2025-05-02 11:27:58,357][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=3.1021, lr=0.001
[2025-05-02 11:28:25,810][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=1.6475, lr=0.001
[2025-05-02 11:28:53,506][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.3742, lr=0.001
[2025-05-02 11:29:20,417][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.1555, lr=0.001
[2025-05-02 11:29:20,435][meta_train][INFO] - epoch_1 saved !
[2025-05-02 11:29:48,429][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.9050, lr=0.001
[2025-05-02 11:30:17,176][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=1.3046, lr=0.001
[2025-05-02 11:30:41,814][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Fog
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 11:30:41,864][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 11:30:41,864][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 11:30:41,864][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 11:30:42,583][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2674, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 11:31:11,011][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.7373, lr=0.001
[2025-05-02 11:31:12,021][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.4607, lr=0.001
[2025-05-02 11:31:38,554][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.2503, lr=0.001
[2025-05-02 11:31:41,473][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0946, lr=0.001
[2025-05-02 11:32:06,619][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0964, lr=0.001
[2025-05-02 11:32:09,880][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=2.9467, lr=0.001
[2025-05-02 11:32:34,518][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.1076, lr=0.001
[2025-05-02 11:32:37,846][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.5056, lr=0.001
[2025-05-02 11:33:02,685][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.3012, lr=0.001
[2025-05-02 11:33:02,716][meta_train][INFO] - epoch_2 saved !
[2025-05-02 11:33:06,171][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=5.4703, lr=0.001
[2025-05-02 11:33:31,294][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1181, lr=0.001
[2025-05-02 11:33:33,948][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=11.4654, lr=0.001
[2025-05-02 11:33:58,601][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.6351, lr=0.001
[2025-05-02 11:34:02,173][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=6.6688, lr=0.001
[2025-05-02 11:34:27,946][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.2543, lr=0.001
[2025-05-02 11:34:29,323][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=9.3204, lr=0.001
[2025-05-02 11:34:29,354][meta_train][INFO] - epoch_1 saved !
[2025-05-02 11:34:53,282][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.4597, lr=0.001
[2025-05-02 11:34:57,490][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=5.7365, lr=0.001
[2025-05-02 11:35:21,673][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.9475, lr=0.001
[2025-05-02 11:35:26,319][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=6.1993, lr=0.001
[2025-05-02 11:35:49,344][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.7869, lr=0.001
[2025-05-02 11:35:51,461][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=8.1061, lr=0.001
[2025-05-02 11:36:17,220][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=1.1619, lr=0.001
[2025-05-02 11:36:19,707][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=7.0797, lr=0.001
[2025-05-02 11:36:45,820][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.0314, lr=0.001
[2025-05-02 11:36:45,851][meta_train][INFO] - epoch_3 saved !
[2025-05-02 11:36:46,804][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=6.3408, lr=0.001
[2025-05-02 11:37:10,816][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.2556, lr=0.001
[2025-05-02 11:37:14,498][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=5.1323, lr=0.001
[2025-05-02 11:37:39,127][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=2.6427, lr=0.001
[2025-05-02 11:37:42,621][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=3.8494, lr=0.001
[2025-05-02 11:38:06,832][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=3.1537, lr=0.001
[2025-05-02 11:38:10,763][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=2.9449, lr=0.001
[2025-05-02 11:38:10,780][meta_train][INFO] - epoch_2 saved !
[2025-05-02 11:38:35,294][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=2.7230, lr=0.001
[2025-05-02 11:38:38,598][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.5558, lr=0.001
[2025-05-02 11:39:02,493][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=3.3904, lr=0.001
[2025-05-02 11:39:05,962][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.6098, lr=0.001
[2025-05-02 11:39:30,879][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=2.7695, lr=0.001
[2025-05-02 11:39:34,719][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.2055, lr=0.001
[2025-05-02 11:39:59,143][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=3.3043, lr=0.001
[2025-05-02 11:40:00,500][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.5017, lr=0.001
[2025-05-02 11:40:27,759][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=2.9793, lr=0.001
[2025-05-02 11:40:27,776][meta_train][INFO] - epoch_4 saved !
[2025-05-02 11:40:29,168][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=2.0260, lr=0.001
[2025-05-02 11:40:56,219][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=4.4179, lr=0.001
[2025-05-02 11:40:57,220][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=1.3506, lr=0.001
[2025-05-02 11:41:23,864][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=5.0778, lr=0.001
[2025-05-02 11:41:24,839][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=1.5071, lr=0.001
[2025-05-02 11:41:51,474][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=5.7876, lr=0.001
[2025-05-02 11:41:52,999][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.3800, lr=0.001
[2025-05-02 11:41:53,029][meta_train][INFO] - epoch_3 saved !
[2025-05-02 11:42:17,085][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=5.5441, lr=0.001
[2025-05-02 11:42:18,460][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.7167, lr=0.001
[2025-05-02 11:42:45,453][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.2800, lr=0.001
[2025-05-02 11:42:46,609][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=3.8470, lr=0.001
[2025-05-02 11:43:14,559][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=4.1674, lr=0.001
[2025-05-02 11:43:14,849][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=4.7156, lr=0.001
[2025-05-02 11:43:42,956][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=4.2322, lr=0.001
[2025-05-02 11:43:43,031][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9035, lr=0.001
[2025-05-02 11:44:10,189][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=5.3267, lr=0.001
[2025-05-02 11:44:11,882][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=5.1222, lr=0.001
[2025-05-02 11:44:11,911][meta_train][INFO] - epoch_5 saved !
[2025-05-02 11:44:38,116][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=4.0706, lr=0.001
[2025-05-02 11:44:40,459][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.5111, lr=0.001
[2025-05-02 11:45:06,672][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=5.8082, lr=0.001
[2025-05-02 11:45:07,514][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=10.2048, lr=0.001
[2025-05-02 11:45:35,428][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=5.0274, lr=0.001
[2025-05-02 11:45:35,460][meta_train][INFO] - epoch_4 saved !
[2025-05-02 11:45:35,637][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.9290, lr=0.001
[2025-05-02 11:46:03,683][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=5.5819, lr=0.001
[2025-05-02 11:46:03,998][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.4971, lr=0.001
[2025-05-02 11:46:28,921][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=7.1170, lr=0.001
[2025-05-02 11:46:30,608][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=10.6244, lr=0.001
[2025-05-02 11:46:56,862][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=8.2432, lr=0.001
[2025-05-02 11:46:58,477][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=8.0458, lr=0.001
[2025-05-02 11:47:23,835][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=7.1405, lr=0.001
[2025-05-02 11:47:25,353][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=4.9893, lr=0.001
[2025-05-02 11:47:52,248][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=6.7915, lr=0.001
[2025-05-02 11:47:54,808][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=5.1023, lr=0.001
[2025-05-02 11:47:54,836][meta_train][INFO] - epoch_6 saved !
[2025-05-02 11:48:21,413][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=5.1377, lr=0.001
[2025-05-02 11:48:22,785][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=5.6438, lr=0.001
[2025-05-02 11:48:49,652][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.7746, lr=0.001
[2025-05-02 11:48:51,402][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=6.5005, lr=0.001
[2025-05-02 11:49:18,179][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=5.2040, lr=0.001
[2025-05-02 11:49:18,207][meta_train][INFO] - epoch_5 saved !
[2025-05-02 11:49:20,518][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=5.0397, lr=0.001
[2025-05-02 11:49:46,362][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.8117, lr=0.001
[2025-05-02 11:49:49,348][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7975, lr=0.001
[2025-05-02 11:50:13,552][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=11.9378, lr=0.001
[2025-05-02 11:50:17,469][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=4.8604, lr=0.001
[2025-05-02 11:50:41,491][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.7543, lr=0.001
[2025-05-02 11:50:44,429][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=12.2208, lr=0.001
[2025-05-02 11:51:09,768][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.8489, lr=0.001
[2025-05-02 11:51:09,924][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=8.3269, lr=0.001
[2025-05-02 11:51:34,848][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=8.2592, lr=0.001
[2025-05-02 11:51:37,629][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=10.0150, lr=0.001
[2025-05-02 11:51:37,658][meta_train][INFO] - epoch_7 saved !
[2025-05-02 11:52:02,786][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=9.7886, lr=0.001
[2025-05-02 11:52:03,738][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=8.4753, lr=0.001
[2025-05-02 11:52:31,239][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=4.8716, lr=0.001
[2025-05-02 11:52:31,623][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=10.1347, lr=0.001
[2025-05-02 11:53:00,072][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=5.0304, lr=0.001
[2025-05-02 11:53:00,092][meta_train][INFO] - epoch_6 saved !
[2025-05-02 11:53:00,189][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.7570, lr=0.001
[2025-05-02 11:53:28,148][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=5.9764, lr=0.001
[2025-05-02 11:53:28,808][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=5.9930, lr=0.001
[2025-05-02 11:53:56,957][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=6.8052, lr=0.001
[2025-05-02 11:53:57,367][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=4.9076, lr=0.001
[2025-05-02 11:54:24,269][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=12.7764, lr=0.001
[2025-05-02 11:54:26,244][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=4.9666, lr=0.001
[2025-05-02 11:54:52,236][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7490, lr=0.001
[2025-05-02 11:54:54,388][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7309, lr=0.001
[2025-05-02 11:55:21,192][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=6.3033, lr=0.001
[2025-05-02 11:55:21,229][meta_train][INFO] - epoch_8 saved !
[2025-05-02 11:55:22,590][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=4.7443, lr=0.001
[2025-05-02 11:55:48,541][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=12.7128, lr=0.001
[2025-05-02 11:55:49,579][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=13.5279, lr=0.001
[2025-05-02 11:56:13,900][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=8.7420, lr=0.001
[2025-05-02 11:56:15,431][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=9.2545, lr=0.001
[2025-05-02 11:56:42,730][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=4.8459, lr=0.001
[2025-05-02 11:56:43,241][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=10.6588, lr=0.001
[2025-05-02 11:56:43,270][meta_train][INFO] - epoch_7 saved !
[2025-05-02 11:57:09,159][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=9.2959, lr=0.001
[2025-05-02 11:57:10,964][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7330, lr=0.001
[2025-05-02 11:57:36,692][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=10.6095, lr=0.001
[2025-05-02 11:57:39,932][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=6.0187, lr=0.001
[2025-05-02 11:58:05,540][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.6922, lr=0.001
[2025-05-02 11:58:08,342][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=6.0979, lr=0.001
[2025-05-02 11:58:33,404][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=6.1500, lr=0.001
[2025-05-02 11:58:35,912][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=9.6521, lr=0.001
[2025-05-02 11:59:02,276][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=4.8086, lr=0.001
[2025-05-02 11:59:05,006][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.6718, lr=0.001
[2025-05-02 11:59:05,033][meta_train][INFO] - epoch_9 saved !
[2025-05-02 11:59:29,574][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=14.1738, lr=0.001
[2025-05-02 11:59:32,057][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=12.1961, lr=0.001
[2025-05-02 11:59:58,149][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.6985, lr=0.001
[2025-05-02 12:00:01,132][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=4.7635, lr=0.001
[2025-05-02 12:00:26,686][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=6.2217, lr=0.001
[2025-05-02 12:00:26,718][meta_train][INFO] - epoch_8 saved !
[2025-05-02 12:00:29,213][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.6649, lr=0.001
[2025-05-02 12:00:53,584][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=14.3105, lr=0.001
[2025-05-02 12:00:58,044][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=5.8856, lr=0.001
[2025-05-02 12:01:18,811][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=8.9944, lr=0.001
[2025-05-02 12:01:23,199][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=8.2227, lr=0.001
[2025-05-02 12:01:47,973][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=4.7559, lr=0.001
[2025-05-02 12:01:51,611][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.7052, lr=0.001
[2025-05-02 12:02:15,821][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.6817, lr=0.001
[2025-05-02 12:02:20,214][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=8.7187, lr=0.001
[2025-05-02 12:02:43,855][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=6.0396, lr=0.001
[2025-05-02 12:02:48,047][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=5.7738, lr=0.001
[2025-05-02 12:02:48,072][meta_train][INFO] - epoch_10 saved !
[2025-05-02 12:03:12,264][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=5.8867, lr=0.001
[2025-05-02 12:03:13,932][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=7.7967, lr=0.001
[2025-05-02 12:03:40,055][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=9.4982, lr=0.001
[2025-05-02 12:03:41,863][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=5.7514, lr=0.001
[2025-05-02 12:04:08,061][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.6570, lr=0.001
[2025-05-02 12:04:08,087][meta_train][INFO] - epoch_9 saved !
[2025-05-02 12:04:11,131][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=4.7376, lr=0.001
[2025-05-02 12:04:35,007][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=13.9486, lr=0.001
[2025-05-02 12:04:39,013][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=8.1947, lr=0.001
[2025-05-02 12:05:04,462][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=4.7299, lr=0.001
[2025-05-02 12:05:07,825][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=5.6045, lr=0.001
[2025-05-02 12:05:32,670][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.6522, lr=0.001
[2025-05-02 12:05:36,145][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6855, lr=0.001
[2025-05-02 12:06:00,953][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=5.6773, lr=0.001
[2025-05-02 12:06:04,622][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.6524, lr=0.001
[2025-05-02 12:06:26,777][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=8.0917, lr=0.001
[2025-05-02 12:06:31,946][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=11.7189, lr=0.001
[2025-05-02 12:06:31,974][meta_train][INFO] - epoch_11 saved !
[2025-05-02 12:06:55,134][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.6587, lr=0.001
[2025-05-02 12:06:57,407][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=7.2768, lr=0.001
[2025-05-02 12:07:22,493][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=8.4100, lr=0.001
[2025-05-02 12:07:26,483][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=4.7305, lr=0.001
[2025-05-02 12:07:50,997][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=5.7996, lr=0.001
[2025-05-02 12:07:51,029][meta_train][INFO] - epoch_10 saved !
[2025-05-02 12:07:54,283][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=7.5423, lr=0.001
[2025-05-02 12:08:16,625][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=7.6606, lr=0.001
[2025-05-02 12:08:22,759][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=5.5889, lr=0.001
[2025-05-02 12:08:44,298][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=5.7379, lr=0.001
[2025-05-02 12:08:51,111][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.6775, lr=0.001
[2025-05-02 12:09:13,681][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=4.7018, lr=0.001
[2025-05-02 12:09:19,683][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.6478, lr=0.001
[2025-05-02 12:09:41,054][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=7.8370, lr=0.001
[2025-05-02 12:09:47,971][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=5.4027, lr=0.001
[2025-05-02 12:10:09,443][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=5.3764, lr=0.001
[2025-05-02 12:10:15,318][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=11.0756, lr=0.001
[2025-05-02 12:10:15,338][meta_train][INFO] - epoch_12 saved !
[2025-05-02 12:10:37,917][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6459, lr=0.001
[2025-05-02 12:10:40,595][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=6.7945, lr=0.001
[2025-05-02 12:11:06,160][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.6376, lr=0.001
[2025-05-02 12:11:09,068][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=5.3469, lr=0.001
[2025-05-02 12:11:33,155][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=12.6936, lr=0.001
[2025-05-02 12:11:33,177][meta_train][INFO] - epoch_11 saved !
[2025-05-02 12:11:36,294][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=10.8840, lr=0.001
[2025-05-02 12:11:58,797][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=7.0802, lr=0.001
[2025-05-02 12:12:04,363][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.6454, lr=0.001
[2025-05-02 12:12:28,033][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=4.6865, lr=0.001
[2025-05-02 12:12:33,184][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=5.4379, lr=0.001
[2025-05-02 12:12:55,921][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=7.1537, lr=0.001
[2025-05-02 12:13:01,056][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=6.7597, lr=0.001
[2025-05-02 12:13:24,109][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=5.5591, lr=0.001
[2025-05-02 12:13:29,316][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.6682, lr=0.001
[2025-05-02 12:13:52,047][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.6377, lr=0.001
[2025-05-02 12:13:58,514][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=4.7036, lr=0.001
[2025-05-02 12:13:58,544][meta_train][INFO] - epoch_13 saved !
[2025-05-02 12:14:20,263][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.6323, lr=0.001
[2025-05-02 12:14:25,532][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=10.2465, lr=0.001
[2025-05-02 12:14:48,986][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=5.1690, lr=0.001
[2025-05-02 12:14:53,500][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.6418, lr=0.001
[2025-05-02 12:15:15,797][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=11.8306, lr=0.001
[2025-05-02 12:15:15,818][meta_train][INFO] - epoch_12 saved !
[2025-05-02 12:15:21,637][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=5.3606, lr=0.001
[2025-05-02 12:15:41,471][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=6.6569, lr=0.001
[2025-05-02 12:15:50,078][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6699, lr=0.001
[2025-05-02 12:16:09,508][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=5.1195, lr=0.001
[2025-05-02 12:16:18,587][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=5.1938, lr=0.001
[2025-05-02 12:16:36,964][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=11.4616, lr=0.001
[2025-05-02 12:16:46,285][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=6.3137, lr=0.001
[2025-05-02 12:17:04,822][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.6283, lr=0.001
[2025-05-02 12:17:11,945][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=6.0917, lr=0.001
[2025-05-02 12:17:32,880][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=5.4161, lr=0.001
[2025-05-02 12:17:40,671][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6917, lr=0.001
[2025-05-02 12:17:40,702][meta_train][INFO] - epoch_14 saved !
[2025-05-02 12:18:00,977][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=6.4490, lr=0.001
[2025-05-02 12:18:09,821][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=5.1735, lr=0.001
[2025-05-02 12:18:29,085][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.6283, lr=0.001
[2025-05-02 12:18:37,853][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6650, lr=0.001
[2025-05-02 12:18:58,127][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=4.6555, lr=0.001
[2025-05-02 12:18:58,159][meta_train][INFO] - epoch_13 saved !
[2025-05-02 12:19:03,501][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=5.9503, lr=0.001
[2025-05-02 12:19:25,331][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=10.5397, lr=0.001
[2025-05-02 12:19:31,770][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=5.2549, lr=0.001
[2025-05-02 12:19:53,823][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.6241, lr=0.001
[2025-05-02 12:20:00,372][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=5.8936, lr=0.001
[2025-05-02 12:20:21,988][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=5.2870, lr=0.001
[2025-05-02 12:20:28,809][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6431, lr=0.001
[2025-05-02 12:20:50,147][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6244, lr=0.001
[2025-05-02 12:20:55,833][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=9.1565, lr=0.001
[2025-05-02 12:21:18,120][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.9331, lr=0.001
[2025-05-02 12:21:24,948][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6864, lr=0.001
[2025-05-02 12:21:24,974][meta_train][INFO] - epoch_15 saved !
[2025-05-02 12:21:46,605][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=5.9115, lr=0.001
[2025-05-02 12:21:53,198][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=5.0773, lr=0.001
[2025-05-02 12:22:11,657][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=5.9104, lr=0.001
[2025-05-02 12:22:21,721][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6385, lr=0.001
[2025-05-02 12:22:41,163][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6369, lr=0.001
[2025-05-02 12:22:41,182][meta_train][INFO] - epoch_14 saved !
[2025-05-02 12:22:48,982][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=8.8046, lr=0.001
[2025-05-02 12:23:09,141][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.8764, lr=0.001
[2025-05-02 12:23:17,871][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6824, lr=0.001
[2025-05-02 12:23:37,366][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6203, lr=0.001
[2025-05-02 12:23:43,162][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=5.6191, lr=0.001
[2025-05-02 12:24:03,258][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=5.7781, lr=0.001
[2025-05-02 12:24:11,684][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=5.1268, lr=0.001
[2025-05-02 12:24:31,029][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=5.1367, lr=0.001
[2025-05-02 12:24:39,751][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=5.4714, lr=0.001
[2025-05-02 12:24:58,958][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=5.4683, lr=0.001
[2025-05-02 12:25:08,006][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6588, lr=0.001
[2025-05-02 12:25:08,034][meta_train][INFO] - epoch_16 saved !
[2025-05-02 12:25:27,201][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6151, lr=0.001
[2025-05-02 12:25:36,270][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=5.0065, lr=0.001
[2025-05-02 12:25:54,422][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=8.9998, lr=0.001
[2025-05-02 12:26:04,833][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=5.0966, lr=0.001
[2025-05-02 12:26:23,050][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6228, lr=0.001
[2025-05-02 12:26:23,078][meta_train][INFO] - epoch_15 saved !
[2025-05-02 12:26:32,799][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6538, lr=0.001
[2025-05-02 12:26:51,597][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.7867, lr=0.001
[2025-05-02 12:26:57,942][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=5.4439, lr=0.001
[2025-05-02 12:27:19,844][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6120, lr=0.001
[2025-05-02 12:27:26,306][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=5.3092, lr=0.001
[2025-05-02 12:27:46,831][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=8.2377, lr=0.001
[2025-05-02 12:27:54,898][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6343, lr=0.001
[2025-05-02 12:28:16,156][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6162, lr=0.001
[2025-05-02 12:28:21,946][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=7.9481, lr=0.001
[2025-05-02 12:28:41,706][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=5.3948, lr=0.001
[2025-05-02 12:28:51,595][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6682, lr=0.001
[2025-05-02 12:28:51,622][meta_train][INFO] - epoch_17 saved !
[2025-05-02 12:29:09,974][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=5.0101, lr=0.001
[2025-05-02 12:29:20,509][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6656, lr=0.001
[2025-05-02 12:29:37,643][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=5.2195, lr=0.001
[2025-05-02 12:29:48,329][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=5.0377, lr=0.001
[2025-05-02 12:30:05,956][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6085, lr=0.001
[2025-05-02 12:30:05,987][meta_train][INFO] - epoch_16 saved !
[2025-05-02 12:30:17,061][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6337, lr=0.001
[2025-05-02 12:30:34,099][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.7187, lr=0.001
[2025-05-02 12:30:45,390][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.9330, lr=0.001
[2025-05-02 12:31:02,126][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.9518, lr=0.001
[2025-05-02 12:31:12,604][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=7.5687, lr=0.001
[2025-05-02 12:31:30,299][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6069, lr=0.001
[2025-05-02 12:31:40,521][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6510, lr=0.001
[2025-05-02 12:31:56,163][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=5.1929, lr=0.001
[2025-05-02 12:32:08,942][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=5.0867, lr=0.001
[2025-05-02 12:32:23,842][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=5.0845, lr=0.001
[2025-05-02 12:32:34,381][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=5.2336, lr=0.001
[2025-05-02 12:32:34,403][meta_train][INFO] - epoch_18 saved !
[2025-05-02 12:32:52,447][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6061, lr=0.001
[2025-05-02 12:33:03,560][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6548, lr=0.001
[2025-05-02 12:33:19,410][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=6.7872, lr=0.001
[2025-05-02 12:33:31,767][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.8873, lr=0.001
[2025-05-02 12:33:48,140][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6074, lr=0.001
[2025-05-02 12:33:48,170][meta_train][INFO] - epoch_17 saved !
[2025-05-02 12:33:57,628][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=5.1890, lr=0.001
[2025-05-02 12:34:17,699][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6071, lr=0.001
[2025-05-02 12:34:26,021][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6477, lr=0.001
[2025-05-02 12:34:45,708][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.8504, lr=0.001
[2025-05-02 12:34:53,894][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.9577, lr=0.001
[2025-05-02 12:35:13,353][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6055, lr=0.001
[2025-05-02 12:35:20,877][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=6.9769, lr=0.001
[2025-05-02 12:35:42,166][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6584, lr=0.001
[2025-05-02 12:35:48,972][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6266, lr=0.001
[2025-05-02 12:36:09,741][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=6.2057, lr=0.001
[2025-05-02 12:36:17,122][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.9320, lr=0.001
[2025-05-02 12:36:17,141][meta_train][INFO] - epoch_19 saved !
[2025-05-02 12:36:38,092][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-02 12:36:44,419][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=6.7985, lr=0.001
[2025-05-02 12:37:05,786][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.8758, lr=0.001
[2025-05-02 12:37:12,364][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.9042, lr=0.001
[2025-05-02 12:37:31,339][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.9704, lr=0.001
[2025-05-02 12:37:31,359][meta_train][INFO] - epoch_18 saved !
[2025-05-02 12:37:40,867][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.8416, lr=0.001
[2025-05-02 12:37:59,858][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-02 12:38:10,014][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6463, lr=0.001
[2025-05-02 12:38:28,252][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6371, lr=0.001
[2025-05-02 12:38:38,882][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6454, lr=0.001
[2025-05-02 12:38:54,301][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.9327, lr=0.001
[2025-05-02 12:39:07,445][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.8998, lr=0.001
[2025-05-02 12:39:22,273][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-02 12:39:32,645][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=5.0338, lr=0.001
[2025-05-02 12:39:50,380][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.7639, lr=0.001
[2025-05-02 12:40:00,827][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6241, lr=0.001
[2025-05-02 12:40:00,850][meta_train][INFO] - epoch_20 saved !
[2025-05-02 12:40:17,193][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=5.5906, lr=0.001
[2025-05-02 12:40:27,102][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=5.0089, lr=0.001
[2025-05-02 12:40:46,176][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-02 12:40:56,500][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6374, lr=0.001
[2025-05-02 12:41:13,819][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.7829, lr=0.001
[2025-05-02 12:41:13,835][meta_train][INFO] - epoch_19 saved !
[2025-05-02 12:41:24,105][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.8196, lr=0.001
[2025-05-02 12:41:40,660][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=5.4609, lr=0.001
[2025-05-02 12:41:52,691][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.8619, lr=0.001
[2025-05-02 12:42:09,111][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.7567, lr=0.001
[2025-05-02 12:42:20,018][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=6.2300, lr=0.001
[2025-05-02 12:42:37,672][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6211, lr=0.001
[2025-05-02 12:42:48,165][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6383, lr=0.001
[2025-05-02 12:43:06,307][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-02 12:43:16,895][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.7809, lr=0.001
[2025-05-02 12:43:34,767][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-02 12:43:45,568][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6224, lr=0.001
[2025-05-02 12:43:45,600][meta_train][INFO] - epoch_21 saved !
[2025-05-02 12:44:03,158][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.7173, lr=0.001
[2025-05-02 12:44:13,628][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6209, lr=0.001
[2025-05-02 12:44:28,530][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.8188, lr=0.001
[2025-05-02 12:44:41,858][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.7580, lr=0.001
[2025-05-02 12:44:56,268][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-02 12:44:56,296][meta_train][INFO] - epoch_20 saved !
[2025-05-02 12:45:10,128][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.7655, lr=0.001
[2025-05-02 12:45:21,610][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.8044, lr=0.001
[2025-05-02 12:45:38,443][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.8199, lr=0.001
[2025-05-02 12:45:50,530][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6053, lr=0.001
[2025-05-02 12:46:06,359][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6297, lr=0.001
[2025-05-02 12:46:18,950][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.7022, lr=0.001
[2025-05-02 12:46:32,021][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.9064, lr=0.001
[2025-05-02 12:46:46,992][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6923, lr=0.001
[2025-05-02 12:47:00,903][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6278, lr=0.001
[2025-05-02 12:47:13,684][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=5.0130, lr=0.001
[2025-05-02 12:47:27,988][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=5.8244, lr=0.001
[2025-05-02 12:47:28,016][meta_train][INFO] - epoch_22 saved !
[2025-05-02 12:47:42,533][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-02 12:47:56,707][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.7970, lr=0.001
[2025-05-02 12:48:10,845][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6120, lr=0.001
[2025-05-02 12:48:24,456][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.7159, lr=0.001
[2025-05-02 12:48:38,750][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-02 12:48:38,771][meta_train][INFO] - epoch_21 saved !
[2025-05-02 12:48:51,598][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=5.7072, lr=0.001
[2025-05-02 12:49:07,043][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-02 12:49:19,958][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6168, lr=0.001
[2025-05-02 12:49:34,807][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6806, lr=0.001
[2025-05-02 12:49:48,127][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6293, lr=0.001
[2025-05-02 12:50:03,789][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6099, lr=0.001
[2025-05-02 12:50:17,288][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6320, lr=0.001
[2025-05-02 12:50:31,905][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6703, lr=0.001
[2025-05-02 12:50:45,376][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.7185, lr=0.001
[2025-05-02 12:51:00,155][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-02 12:51:11,338][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.8376, lr=0.001
[2025-05-02 12:51:11,365][meta_train][INFO] - epoch_23 saved !
[2025-05-02 12:51:26,114][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.7253, lr=0.001
[2025-05-02 12:51:40,047][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.7183, lr=0.001
[2025-05-02 12:51:54,861][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-02 12:52:08,264][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6220, lr=0.001
[2025-05-02 12:52:22,219][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.7769, lr=0.001
[2025-05-02 12:52:22,248][meta_train][INFO] - epoch_22 saved !
[2025-05-02 12:52:36,312][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6157, lr=0.001
[2025-05-02 12:52:50,760][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6590, lr=0.001
[2025-05-02 12:53:03,436][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=5.4718, lr=0.001
[2025-05-02 12:53:18,539][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6535, lr=0.001
[2025-05-02 12:53:32,562][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6195, lr=0.001
[2025-05-02 12:53:45,282][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.7513, lr=0.001
[2025-05-02 12:54:00,919][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.7542, lr=0.001
[2025-05-02 12:54:14,374][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-02 12:54:26,909][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.7999, lr=0.001
[2025-05-02 12:54:42,316][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-02 12:54:54,849][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6684, lr=0.001
[2025-05-02 12:54:54,880][meta_train][INFO] - epoch_24 saved !
[2025-05-02 12:55:11,766][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6053, lr=0.001
[2025-05-02 12:55:23,275][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6962, lr=0.001
[2025-05-02 12:55:39,954][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6078, lr=0.001
[2025-05-02 12:55:51,482][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6659, lr=0.001
[2025-05-02 12:56:05,188][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.6767, lr=0.001
[2025-05-02 12:56:05,219][meta_train][INFO] - epoch_23 saved !
[2025-05-02 12:56:17,060][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.7854, lr=0.001
[2025-05-02 12:56:33,731][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6073, lr=0.001
[2025-05-02 12:56:46,170][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6193, lr=0.001
[2025-05-02 12:57:01,822][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-02 12:57:14,305][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6192, lr=0.001
[2025-05-02 12:57:30,182][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6053, lr=0.001
[2025-05-02 12:57:42,760][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6125, lr=0.001
[2025-05-02 12:57:57,344][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.7036, lr=0.001
[2025-05-02 12:58:10,943][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.7297, lr=0.001
[2025-05-02 12:58:26,391][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-02 12:58:38,058][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=5.3149, lr=0.001
[2025-05-02 12:58:38,082][meta_train][INFO] - epoch_25 saved !
[2025-05-02 12:58:54,188][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6306, lr=0.001
[2025-05-02 12:59:06,607][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6197, lr=0.001
[2025-05-02 12:59:19,983][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.6684, lr=0.001
[2025-05-02 12:59:34,690][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6129, lr=0.001
[2025-05-02 12:59:47,591][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6345, lr=0.001
[2025-05-02 12:59:47,622][meta_train][INFO] - epoch_24 saved !
[2025-05-02 13:00:00,373][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.7536, lr=0.001
[2025-05-02 13:00:16,156][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6067, lr=0.001
[2025-05-02 13:00:28,988][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6770, lr=0.001
[2025-05-02 13:00:44,392][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6283, lr=0.001
[2025-05-02 13:00:57,725][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6178, lr=0.001
[2025-05-02 13:01:09,753][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.6664, lr=0.001
[2025-05-02 13:01:25,720][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6418, lr=0.001
[2025-05-02 13:01:38,860][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6054, lr=0.001
[2025-05-02 13:01:52,883][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=5.1794, lr=0.001
[2025-05-02 13:02:07,181][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-02 13:02:21,474][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.7072, lr=0.001
[2025-05-02 13:02:21,502][meta_train][INFO] - epoch_26 saved !
[2025-05-02 13:02:35,732][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6059, lr=0.001
[2025-05-02 13:02:49,545][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.7042, lr=0.001
[2025-05-02 13:03:03,877][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6332, lr=0.001
[2025-05-02 13:03:17,551][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6114, lr=0.001
[2025-05-02 13:03:30,575][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6788, lr=0.001
[2025-05-02 13:03:30,599][meta_train][INFO] - epoch_25 saved !
[2025-05-02 13:03:46,576][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6163, lr=0.001
[2025-05-02 13:03:59,056][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-02 13:04:12,344][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.7245, lr=0.001
[2025-05-02 13:04:27,409][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6062, lr=0.001
[2025-05-02 13:04:41,337][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6165, lr=0.001
[2025-05-02 13:04:52,462][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.6585, lr=0.001
[2025-05-02 13:05:08,710][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6322, lr=0.001
[2025-05-02 13:05:21,056][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6063, lr=0.001
[2025-05-02 13:05:36,376][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=5.0930, lr=0.001
[2025-05-02 13:05:50,275][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6057, lr=0.001
[2025-05-02 13:06:05,065][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6589, lr=0.001
[2025-05-02 13:06:05,094][meta_train][INFO] - epoch_27 saved !
[2025-05-02 13:06:18,254][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6219, lr=0.001
[2025-05-02 13:06:33,100][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6104, lr=0.001
[2025-05-02 13:06:45,295][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6622, lr=0.001
[2025-05-02 13:07:00,983][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6282, lr=0.001
[2025-05-02 13:07:13,329][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6255, lr=0.001
[2025-05-02 13:07:13,348][meta_train][INFO] - epoch_26 saved !
[2025-05-02 13:07:26,688][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.7092, lr=0.001
[2025-05-02 13:07:41,805][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6255, lr=0.001
[2025-05-02 13:07:55,938][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6141, lr=0.001
[2025-05-02 13:08:10,089][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-02 13:08:24,044][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6836, lr=0.001
[2025-05-02 13:08:38,893][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6062, lr=0.001
[2025-05-02 13:08:52,164][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6521, lr=0.001
[2025-05-02 13:09:04,644][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.6448, lr=0.001
[2025-05-02 13:09:19,207][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=5.0195, lr=0.001
[2025-05-02 13:09:33,222][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-02 13:09:47,686][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6148, lr=0.001
[2025-05-02 13:09:47,717][meta_train][INFO] - epoch_28 saved !
[2025-05-02 13:10:00,750][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6181, lr=0.001
[2025-05-02 13:10:16,896][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6134, lr=0.001
[2025-05-02 13:10:27,708][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6479, lr=0.001
[2025-05-02 13:10:45,094][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6776, lr=0.001
[2025-05-02 13:10:56,427][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6062, lr=0.001
[2025-05-02 13:10:56,452][meta_train][INFO] - epoch_27 saved !
[2025-05-02 13:11:10,662][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6912, lr=0.001
[2025-05-02 13:11:24,582][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6083, lr=0.001
[2025-05-02 13:11:38,955][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6100, lr=0.001
[2025-05-02 13:11:52,103][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6156, lr=0.001
[2025-05-02 13:12:07,142][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6207, lr=0.001
[2025-05-02 13:12:17,876][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.6374, lr=0.001
[2025-05-02 13:12:35,879][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6136, lr=0.001
[2025-05-02 13:12:47,246][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6073, lr=0.001
[2025-05-02 13:13:02,100][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.9510, lr=0.001
[2025-05-02 13:13:15,551][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6220, lr=0.001
[2025-05-02 13:13:30,868][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6428, lr=0.001
[2025-05-02 13:13:30,895][meta_train][INFO] - epoch_29 saved !
[2025-05-02 13:13:44,105][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6064, lr=0.001
[2025-05-02 13:13:59,237][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6093, lr=0.001
[2025-05-02 13:14:11,123][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6379, lr=0.001
[2025-05-02 13:14:27,721][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6131, lr=0.001
[2025-05-02 13:14:39,152][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6055, lr=0.001
[2025-05-02 13:14:39,182][meta_train][INFO] - epoch_28 saved !
[2025-05-02 13:14:55,426][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6189, lr=0.001
[2025-05-02 13:15:08,305][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6081, lr=0.001
[2025-05-02 13:15:23,898][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6402, lr=0.001
[2025-05-02 13:15:36,163][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6180, lr=0.001
[2025-05-02 13:15:50,854][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.9154, lr=0.001
[2025-05-02 13:16:01,727][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6312, lr=0.001
[2025-05-02 13:16:16,588][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6752, lr=0.001
[2025-05-02 13:16:29,797][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6101, lr=0.001
[2025-05-02 13:16:44,323][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6624, lr=0.001
[2025-05-02 13:16:57,921][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6127, lr=0.001
[2025-05-02 13:17:13,752][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6115, lr=0.001
[2025-05-02 13:17:13,783][meta_train][INFO] - epoch_30 saved !
[2025-05-02 13:17:26,002][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-02 13:17:42,403][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6592, lr=0.001
[2025-05-02 13:17:52,882][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6364, lr=0.001
[2025-05-02 13:18:10,615][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6089, lr=0.001
[2025-05-02 13:18:21,748][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6068, lr=0.001
[2025-05-02 13:18:21,764][meta_train][INFO] - epoch_29 saved !
[2025-05-02 13:18:38,471][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6163, lr=0.001
[2025-05-02 13:18:49,813][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6110, lr=0.001
[2025-05-02 13:19:05,338][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.8771, lr=0.001
[2025-05-02 13:19:18,143][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6060, lr=0.001
[2025-05-02 13:19:34,764][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6114, lr=0.001
[2025-05-02 13:19:46,003][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6115, lr=0.001
[2025-05-02 13:20:02,672][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6121, lr=0.001
[2025-05-02 13:20:14,151][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6069, lr=0.001
[2025-05-02 13:20:31,283][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6330, lr=0.001
[2025-05-02 13:20:41,439][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6345, lr=0.001
[2025-05-02 13:20:56,962][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6616, lr=0.001
[2025-05-02 13:20:56,979][meta_train][INFO] - epoch_31 saved !
[2025-05-02 13:21:07,158][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6279, lr=0.001
[2025-05-02 13:21:24,930][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6117, lr=0.001
[2025-05-02 13:21:35,343][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6185, lr=0.001
[2025-05-02 13:21:50,796][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6588, lr=0.001
[2025-05-02 13:22:03,898][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6112, lr=0.001
[2025-05-02 13:22:03,926][meta_train][INFO] - epoch_30 saved !
[2025-05-02 13:22:18,502][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6154, lr=0.001
[2025-05-02 13:22:32,016][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6181, lr=0.001
[2025-05-02 13:22:47,571][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6110, lr=0.001
[2025-05-02 13:23:00,783][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6120, lr=0.001
[2025-05-02 13:23:15,853][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6485, lr=0.001
[2025-05-02 13:23:28,759][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6110, lr=0.001
[2025-05-02 13:23:44,990][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6283, lr=0.001
[2025-05-02 13:23:55,597][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6327, lr=0.001
[2025-05-02 13:24:11,868][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.8296, lr=0.001
[2025-05-02 13:24:24,662][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6119, lr=0.001
[2025-05-02 13:24:40,376][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6087, lr=0.001
[2025-05-02 13:24:40,402][meta_train][INFO] - epoch_32 saved !
[2025-05-02 13:24:53,310][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6070, lr=0.001
[2025-05-02 13:25:08,990][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6464, lr=0.001
[2025-05-02 13:25:21,546][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6076, lr=0.001
[2025-05-02 13:25:37,090][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6087, lr=0.001
[2025-05-02 13:25:47,871][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6242, lr=0.001
[2025-05-02 13:25:47,900][meta_train][INFO] - epoch_31 saved !
[2025-05-02 13:26:02,739][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6527, lr=0.001
[2025-05-02 13:26:15,946][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6075, lr=0.001
[2025-05-02 13:26:29,527][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.8073, lr=0.001
[2025-05-02 13:26:41,570][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6234, lr=0.001
[2025-05-02 13:26:58,856][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6110, lr=0.001
[2025-05-02 13:27:10,158][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6110, lr=0.001
[2025-05-02 13:27:26,716][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6145, lr=0.001
[2025-05-02 13:27:39,006][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6134, lr=0.001
[2025-05-02 13:27:55,532][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6265, lr=0.001
[2025-05-02 13:28:07,311][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6163, lr=0.001
[2025-05-02 13:28:23,889][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6111, lr=0.001
[2025-05-02 13:28:23,919][meta_train][INFO] - epoch_33 saved !
[2025-05-02 13:28:35,402][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6081, lr=0.001
[2025-05-02 13:28:52,074][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6108, lr=0.001
[2025-05-02 13:29:02,774][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6281, lr=0.001
[2025-05-02 13:29:19,885][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6144, lr=0.001
[2025-05-02 13:29:31,032][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6143, lr=0.001
[2025-05-02 13:29:31,062][meta_train][INFO] - epoch_32 saved !
[2025-05-02 13:29:48,328][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6256, lr=0.001
[2025-05-02 13:29:59,444][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6161, lr=0.001
[2025-05-02 13:30:16,851][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6085, lr=0.001
[2025-05-02 13:30:27,594][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6138, lr=0.001
[2025-05-02 13:30:43,778][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.7919, lr=0.001
[2025-05-02 13:30:52,600][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6213, lr=0.001
[2025-05-02 13:31:12,424][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6439, lr=0.001
[2025-05-02 13:31:19,925][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.6249, lr=0.001
[2025-05-02 13:31:41,144][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6108, lr=0.001
[2025-05-02 13:31:49,326][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6150, lr=0.001
[2025-05-02 13:32:06,655][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6459, lr=0.001
[2025-05-02 13:32:06,675][meta_train][INFO] - epoch_34 saved !
[2025-05-02 13:32:17,126][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6116, lr=0.001
[2025-05-02 13:32:36,064][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6108, lr=0.001
[2025-05-02 13:32:45,677][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6087, lr=0.001
[2025-05-02 13:33:04,004][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6084, lr=0.001
[2025-05-02 13:33:14,006][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6089, lr=0.001
[2025-05-02 13:33:14,038][meta_train][INFO] - epoch_33 saved !
[2025-05-02 13:33:32,290][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6140, lr=0.001
[2025-05-02 13:33:42,384][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6091, lr=0.001
[2025-05-02 13:33:57,728][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6460, lr=0.001
[2025-05-02 13:34:10,495][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6113, lr=0.001
[2025-05-02 13:34:24,578][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.7791, lr=0.001
[2025-05-02 13:34:39,087][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6089, lr=0.001
[2025-05-02 13:34:53,740][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6240, lr=0.001
[2025-05-02 13:35:06,840][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6139, lr=0.001
[2025-05-02 13:35:21,636][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6108, lr=0.001
[2025-05-02 13:35:33,712][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.6227, lr=0.001
[2025-05-02 13:35:49,663][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6388, lr=0.001
[2025-05-02 13:35:49,693][meta_train][INFO] - epoch_35 saved !
[2025-05-02 13:36:02,024][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6156, lr=0.001
[2025-05-02 13:36:18,116][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6110, lr=0.001
[2025-05-02 13:36:31,525][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6149, lr=0.001
[2025-05-02 13:36:46,064][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6145, lr=0.001
[2025-05-02 13:36:56,801][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6196, lr=0.001
[2025-05-02 13:36:56,821][meta_train][INFO] - epoch_34 saved !
[2025-05-02 13:37:14,966][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6101, lr=0.001
[2025-05-02 13:37:25,973][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6159, lr=0.001
[2025-05-02 13:37:43,862][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6361, lr=0.001
[2025-05-02 13:37:53,990][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6143, lr=0.001
[2025-05-02 13:38:12,335][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6210, lr=0.001
[2025-05-02 13:38:22,090][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6115, lr=0.001
[2025-05-02 13:38:37,831][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6397, lr=0.001
[2025-05-02 13:38:48,151][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6194, lr=0.001
[2025-05-02 13:39:04,812][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.7489, lr=0.001
[2025-05-02 13:39:14,861][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.6216, lr=0.001
[2025-05-02 13:39:33,111][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6086, lr=0.001
[2025-05-02 13:39:33,141][meta_train][INFO] - epoch_36 saved !
[2025-05-02 13:39:43,952][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6091, lr=0.001
[2025-05-02 13:40:00,018][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.7429, lr=0.001
[2025-05-02 13:40:11,879][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6094, lr=0.001
[2025-05-02 13:40:27,996][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6106, lr=0.001
[2025-05-02 13:40:39,897][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6154, lr=0.001
[2025-05-02 13:40:39,921][meta_train][INFO] - epoch_35 saved !
[2025-05-02 13:40:56,675][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6213, lr=0.001
[2025-05-02 13:41:08,162][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6099, lr=0.001
[2025-05-02 13:41:25,496][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6108, lr=0.001
[2025-05-02 13:41:36,012][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6132, lr=0.001
[2025-05-02 13:41:54,243][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6085, lr=0.001
[2025-05-02 13:42:04,779][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6162, lr=0.001
[2025-05-02 13:42:19,741][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6368, lr=0.001
[2025-05-02 13:42:33,601][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6145, lr=0.001
[2025-05-02 13:42:47,642][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6357, lr=0.001
[2025-05-02 13:43:02,055][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6100, lr=0.001
[2025-05-02 13:43:15,524][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6134, lr=0.001
[2025-05-02 13:43:15,552][meta_train][INFO] - epoch_37 saved !
[2025-05-02 13:43:27,674][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6180, lr=0.001
[2025-05-02 13:43:44,351][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6351, lr=0.001
[2025-05-02 13:43:54,630][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.6187, lr=0.001
[2025-05-02 13:44:12,241][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6083, lr=0.001
[2025-05-02 13:44:23,036][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6144, lr=0.001
[2025-05-02 13:44:23,067][meta_train][INFO] - epoch_36 saved !
[2025-05-02 13:44:40,848][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6098, lr=0.001
[2025-05-02 13:44:50,055][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.6183, lr=0.001
[2025-05-02 13:45:07,969][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.7277, lr=0.001
[2025-05-02 13:45:18,018][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6102, lr=0.001
[2025-05-02 13:45:33,268][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6377, lr=0.001
[2025-05-02 13:45:46,563][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6098, lr=0.001
[2025-05-02 13:46:02,176][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6106, lr=0.001
[2025-05-02 13:46:15,433][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6148, lr=0.001
[2025-05-02 13:46:30,219][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6134, lr=0.001
[2025-05-02 13:46:44,087][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6123, lr=0.001
[2025-05-02 13:46:59,032][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6199, lr=0.001
[2025-05-02 13:46:59,063][meta_train][INFO] - epoch_38 saved !
[2025-05-02 13:47:09,268][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6166, lr=0.001
[2025-05-02 13:47:25,762][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.7101, lr=0.001
[2025-05-02 13:47:37,041][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6135, lr=0.001
[2025-05-02 13:47:54,859][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6199, lr=0.001
[2025-05-02 13:48:04,794][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6097, lr=0.001
[2025-05-02 13:48:04,825][meta_train][INFO] - epoch_37 saved !
[2025-05-02 13:48:22,781][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6291, lr=0.001
[2025-05-02 13:48:33,626][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6143, lr=0.001
[2025-05-02 13:48:50,983][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6143, lr=0.001
[2025-05-02 13:49:01,461][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6106, lr=0.001
[2025-05-02 13:49:19,467][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6087, lr=0.001
[2025-05-02 13:49:30,049][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6084, lr=0.001
[2025-05-02 13:49:47,450][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6097, lr=0.001
[2025-05-02 13:49:57,300][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6169, lr=0.001
[2025-05-02 13:50:16,397][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6100, lr=0.001
[2025-05-02 13:50:22,743][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6163, lr=0.001
[2025-05-02 13:50:42,158][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6342, lr=0.001
[2025-05-02 13:50:42,187][meta_train][INFO] - epoch_39 saved !
[2025-05-02 13:50:51,756][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6128, lr=0.001
[2025-05-02 13:51:11,004][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6183, lr=0.001
[2025-05-02 13:51:19,701][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6116, lr=0.001
[2025-05-02 13:51:36,946][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6326, lr=0.001
[2025-05-02 13:51:48,484][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6097, lr=0.001
[2025-05-02 13:51:48,516][meta_train][INFO] - epoch_38 saved !
[2025-05-02 13:52:04,769][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6131, lr=0.001
[2025-05-02 13:52:15,329][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6165, lr=0.001
[2025-05-02 13:52:33,417][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6306, lr=0.001
[2025-05-02 13:52:44,086][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6094, lr=0.001
[2025-05-02 13:53:01,821][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6098, lr=0.001
[2025-05-02 13:53:12,051][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6141, lr=0.001
[2025-05-02 13:53:30,919][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6106, lr=0.001
[2025-05-02 13:53:40,212][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6122, lr=0.001
[2025-05-02 13:53:59,237][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6085, lr=0.001
[2025-05-02 13:54:08,630][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6112, lr=0.001
[2025-05-02 13:54:26,740][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6933, lr=0.001
[2025-05-02 13:54:26,769][meta_train][INFO] - epoch_40 saved !
[2025-05-02 13:54:36,505][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6087, lr=0.001
[2025-05-02 13:54:55,506][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6082, lr=0.001
[2025-05-02 13:55:05,444][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6103, lr=0.001
[2025-05-02 13:55:22,756][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6900, lr=0.001
[2025-05-02 13:55:31,245][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6155, lr=0.001
[2025-05-02 13:55:31,276][meta_train][INFO] - epoch_39 saved !
[2025-05-02 13:55:50,772][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6303, lr=0.001
[2025-05-02 13:56:00,103][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6080, lr=0.001
[2025-05-02 13:56:19,608][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6186, lr=0.001
[2025-05-02 13:56:25,890][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6148, lr=0.001
[2025-05-02 13:56:48,817][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6104, lr=0.001
[2025-05-02 13:56:53,442][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6101, lr=0.001
[2025-05-02 13:57:16,496][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6133, lr=0.001
[2025-05-02 13:57:21,956][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6135, lr=0.001
[2025-05-02 13:57:42,190][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6299, lr=0.001
[2025-05-02 13:57:50,428][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6096, lr=0.001
[2025-05-02 13:58:10,539][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6098, lr=0.001
[2025-05-02 13:58:10,569][meta_train][INFO] - epoch_41 saved !
[2025-05-02 13:58:19,453][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6135, lr=0.001
[2025-05-02 13:58:38,703][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6130, lr=0.001
[2025-05-02 13:58:47,742][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6109, lr=0.001
[2025-05-02 13:59:03,996][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6276, lr=0.001
[2025-05-02 13:59:15,160][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6152, lr=0.001
[2025-05-02 13:59:15,187][meta_train][INFO] - epoch_40 saved !
[2025-05-02 13:59:32,806][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6264, lr=0.001
[2025-05-02 13:59:43,781][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6083, lr=0.001
[2025-05-02 14:00:00,787][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6079, lr=0.001
[2025-05-02 14:00:10,786][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6147, lr=0.001
[2025-05-02 14:00:27,931][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6827, lr=0.001
[2025-05-02 14:00:38,628][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6129, lr=0.001
[2025-05-02 14:00:56,134][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6094, lr=0.001
[2025-05-02 14:01:07,496][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6068, lr=0.001
[2025-05-02 14:01:25,557][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6099, lr=0.001
[2025-05-02 14:01:36,592][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6077, lr=0.001
[2025-05-02 14:01:54,440][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6165, lr=0.001
[2025-05-02 14:01:54,468][meta_train][INFO] - epoch_42 saved !
[2025-05-02 14:02:04,208][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6100, lr=0.001
[2025-05-02 14:02:19,545][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6261, lr=0.001
[2025-05-02 14:02:29,658][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6138, lr=0.001
[2025-05-02 14:02:49,034][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6109, lr=0.001
[2025-05-02 14:02:57,935][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6108, lr=0.001
[2025-05-02 14:02:57,952][meta_train][INFO] - epoch_41 saved !
[2025-05-02 14:03:16,974][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6102, lr=0.001
[2025-05-02 14:03:26,241][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6139, lr=0.001
[2025-05-02 14:03:44,545][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6665, lr=0.001
[2025-05-02 14:03:51,400][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6141, lr=0.001
[2025-05-02 14:04:12,994][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6165, lr=0.001
[2025-05-02 14:04:20,098][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6135, lr=0.001
[2025-05-02 14:04:41,330][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6239, lr=0.001
[2025-05-02 14:04:48,050][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6103, lr=0.001
[2025-05-02 14:05:09,990][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6085, lr=0.001
[2025-05-02 14:05:15,152][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6142, lr=0.001
[2025-05-02 14:05:37,581][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6122, lr=0.001
[2025-05-02 14:05:37,611][meta_train][INFO] - epoch_43 saved !
[2025-05-02 14:05:43,279][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6070, lr=0.001
[2025-05-02 14:06:06,132][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6089, lr=0.001
[2025-05-02 14:06:12,778][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6076, lr=0.001
[2025-05-02 14:06:33,038][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6657, lr=0.001
[2025-05-02 14:06:41,719][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6078, lr=0.001
[2025-05-02 14:06:41,745][meta_train][INFO] - epoch_42 saved !
[2025-05-02 14:07:01,711][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6076, lr=0.001
[2025-05-02 14:07:06,869][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6128, lr=0.001
[2025-05-02 14:07:29,688][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6116, lr=0.001
[2025-05-02 14:07:36,485][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6092, lr=0.001
[2025-05-02 14:07:58,423][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6102, lr=0.001
[2025-05-02 14:08:04,527][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6086, lr=0.001
[2025-05-02 14:08:27,304][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6230, lr=0.001
[2025-05-02 14:08:32,022][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6124, lr=0.001
[2025-05-02 14:08:55,529][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6161, lr=0.001
[2025-05-02 14:09:00,522][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6116, lr=0.001
[2025-05-02 14:09:21,503][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6229, lr=0.001
[2025-05-02 14:09:21,536][meta_train][INFO] - epoch_44 saved !
[2025-05-02 14:09:28,811][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6129, lr=0.001
[2025-05-02 14:09:48,317][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6622, lr=0.001
[2025-05-02 14:09:57,475][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6104, lr=0.001
[2025-05-02 14:10:14,297][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6223, lr=0.001
[2025-05-02 14:10:25,019][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6111, lr=0.001
[2025-05-02 14:10:25,036][meta_train][INFO] - epoch_43 saved !
[2025-05-02 14:10:42,449][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6158, lr=0.001
[2025-05-02 14:10:54,440][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6077, lr=0.001
[2025-05-02 14:11:15,551][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6109, lr=0.001
[2025-05-02 14:11:29,717][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6130, lr=0.001
[2025-05-02 14:11:52,581][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6097, lr=0.001
[2025-05-02 14:12:07,123][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6059, lr=0.001
[2025-05-02 14:12:26,915][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6125, lr=0.001
[2025-05-02 14:12:35,894][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6079, lr=0.001
[2025-05-02 14:12:55,448][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6076, lr=0.001
[2025-05-02 14:13:04,483][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6090, lr=0.001
[2025-05-02 14:13:23,524][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6225, lr=0.001
[2025-05-02 14:13:23,555][meta_train][INFO] - epoch_45 saved !
[2025-05-02 14:13:33,255][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6123, lr=0.001
[2025-05-02 14:13:52,940][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6089, lr=0.001
[2025-05-02 14:14:01,470][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6114, lr=0.001
[2025-05-02 14:14:21,475][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6108, lr=0.001
[2025-05-02 14:14:28,140][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6129, lr=0.001
[2025-05-02 14:14:28,162][meta_train][INFO] - epoch_44 saved !
[2025-05-02 14:14:50,847][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6152, lr=0.001
[2025-05-02 14:14:52,063][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-02 14:14:52,119][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 14:14:52,119][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 14:14:52,119][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 14:14:55,427][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6119, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 14:15:09,143][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 14:15:16,656][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6122, lr=0.0100
[2025-05-02 14:15:18,996][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6485, lr=0.001
[2025-05-02 14:15:21,917][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6131, lr=0.001
[2025-05-02 14:15:23,995][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6120, lr=0.0100
[2025-05-02 14:15:31,045][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6104, lr=0.0100
[2025-05-02 14:15:38,256][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6106, lr=0.0100
[2025-05-02 14:15:45,046][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6214, lr=0.001
[2025-05-02 14:15:45,362][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6105, lr=0.0100
[2025-05-02 14:15:51,076][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6143, lr=0.001
[2025-05-02 14:15:52,834][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6111, lr=0.0100
[2025-05-02 14:16:00,546][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6091, lr=0.0100
[2025-05-02 14:16:08,802][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6088, lr=0.0100
[2025-05-02 14:16:14,182][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6208, lr=0.001
[2025-05-02 14:16:17,112][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6086, lr=0.0100
[2025-05-02 14:16:21,020][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6160, lr=0.001
[2025-05-02 14:16:24,945][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6081, lr=0.0100
[2025-05-02 14:16:33,299][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6083, lr=0.0100
[2025-05-02 14:16:42,158][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6081, lr=0.0100
[2025-05-02 14:16:44,749][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6113, lr=0.001
[2025-05-02 14:16:51,233][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6074, lr=0.0100
[2025-05-02 14:16:51,258][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6124, lr=0.001
[2025-05-02 14:17:00,839][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6075, lr=0.0100
[2025-05-02 14:17:10,548][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6078, lr=0.0100
[2025-05-02 14:17:19,984][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6075, lr=0.0100
[2025-05-02 14:17:22,920][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6095, lr=0.001
[2025-05-02 14:17:22,951][meta_train][INFO] - epoch_46 saved !
[2025-05-02 14:17:28,403][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6127, lr=0.001
[2025-05-02 14:17:28,835][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-02 14:17:38,995][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6068, lr=0.0100
[2025-05-02 14:17:49,372][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-02 14:17:58,750][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-02 14:18:01,119][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6156, lr=0.001
[2025-05-02 14:18:05,825][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6063, lr=0.0100
[2025-05-02 14:18:06,522][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6081, lr=0.001
[2025-05-02 14:18:14,021][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-02 14:18:22,310][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6062, lr=0.0100
[2025-05-02 14:18:30,657][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6059, lr=0.0100
[2025-05-02 14:18:31,786][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6101, lr=0.001
[2025-05-02 14:18:35,074][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6118, lr=0.001
[2025-05-02 14:18:35,102][meta_train][INFO] - epoch_45 saved !
[2025-05-02 14:18:38,935][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-02 14:18:47,191][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-02 14:18:54,678][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-02 14:19:00,565][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6138, lr=0.001
[2025-05-02 14:19:03,208][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-02 14:19:04,611][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6065, lr=0.001
[2025-05-02 14:19:11,474][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-02 14:19:19,276][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-02 14:19:27,756][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-02 14:19:29,430][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6084, lr=0.001
[2025-05-02 14:19:32,998][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6075, lr=0.001
[2025-05-02 14:19:36,038][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-02 14:19:43,475][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-02 14:19:51,575][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-02 14:19:57,883][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6219, lr=0.001
[2025-05-02 14:20:00,148][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:02,486][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6072, lr=0.001
[2025-05-02 14:20:08,196][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:17,172][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:26,119][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6600, lr=0.001
[2025-05-02 14:20:26,298][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:32,353][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6114, lr=0.001
[2025-05-02 14:20:34,947][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:44,355][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:20:53,583][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:21:02,846][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:21:03,289][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6074, lr=0.001
[2025-05-02 14:21:06,672][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6116, lr=0.001
[2025-05-02 14:21:11,789][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:21:21,601][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:21:31,224][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:21:39,091][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6213, lr=0.001
[2025-05-02 14:21:39,144][meta_train][INFO] - epoch_47 saved !
[2025-05-02 14:21:41,220][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:21:45,378][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6123, lr=0.001
[2025-05-02 14:21:50,754][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:02,499][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:12,929][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:19,752][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6120, lr=0.001
[2025-05-02 14:22:22,518][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:26,079][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6121, lr=0.001
[2025-05-02 14:22:31,711][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:43,046][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:22:53,196][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:00,487][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6198, lr=0.001
[2025-05-02 14:23:02,957][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:05,793][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6124, lr=0.001
[2025-05-02 14:23:05,841][meta_train][INFO] - epoch_46 saved !
[2025-05-02 14:23:12,872][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:24,168][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:34,767][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:37,422][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6195, lr=0.001
[2025-05-02 14:23:44,319][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:23:46,282][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6150, lr=0.001
[2025-05-02 14:23:54,350][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:24:05,064][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:24:15,287][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:24:17,990][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6088, lr=0.001
[2025-05-02 14:24:25,493][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:24:28,225][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6125, lr=0.001
[2025-05-02 14:24:35,844][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:24:45,944][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:24:55,305][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:24:58,528][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6107, lr=0.001
[2025-05-02 14:25:04,358][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:25:08,824][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6102, lr=0.001
[2025-05-02 14:25:13,883][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:25:23,676][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:25:32,936][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:25:37,769][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6141, lr=0.001
[2025-05-02 14:25:42,057][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:25:46,357][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6069, lr=0.001
[2025-05-02 14:25:51,531][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:00,175][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:07,691][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:13,768][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6095, lr=0.001
[2025-05-02 14:26:15,335][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:20,960][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6114, lr=0.001
[2025-05-02 14:26:23,536][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:30,706][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:38,626][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:41,715][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6447, lr=0.001
[2025-05-02 14:26:41,733][meta_train][INFO] - epoch_48 saved !
[2025-05-02 14:26:46,878][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:26:48,651][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6114, lr=0.001
[2025-05-02 14:26:54,988][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:02,624][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:08,870][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6444, lr=0.001
[2025-05-02 14:27:10,411][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:17,544][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6062, lr=0.001
[2025-05-02 14:27:18,565][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:25,958][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:34,445][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:37,764][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6090, lr=0.001
[2025-05-02 14:27:42,732][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:43,920][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6111, lr=0.001
[2025-05-02 14:27:43,945][meta_train][INFO] - epoch_47 saved !
[2025-05-02 14:27:50,931][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:27:59,294][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:28:06,784][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:28:06,864][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6076, lr=0.001
[2025-05-02 14:28:12,131][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6088, lr=0.001
[2025-05-02 14:28:14,334][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:28:22,976][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:28:30,898][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:28:35,664][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6186, lr=0.001
[2025-05-02 14:28:38,635][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:28:40,735][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6117, lr=0.001
[2025-05-02 14:28:47,053][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:28:54,455][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:02,613][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:04,362][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6135, lr=0.001
[2025-05-02 14:29:06,948][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6113, lr=0.001
[2025-05-02 14:29:10,421][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:18,925][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:26,979][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:32,765][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6106, lr=0.001
[2025-05-02 14:29:35,250][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:35,330][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6096, lr=0.001
[2025-05-02 14:29:42,977][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:29:47,900][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 14:29:47,911][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 14:30:02,647][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6093, lr=0.001
[2025-05-02 14:30:05,261][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6117, lr=0.001
[2025-05-02 14:30:17,320][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 14:30:28,843][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6177, lr=0.001
[2025-05-02 14:30:28,873][meta_train][INFO] - epoch_49 saved !
[2025-05-02 14:30:34,406][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6111, lr=0.001
[2025-05-02 14:30:46,597][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 14:30:47,077][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 14:30:58,052][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6135, lr=0.001
[2025-05-02 14:31:03,316][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6082, lr=0.001
[2025-05-02 14:31:25,997][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6094, lr=0.001
[2025-05-02 14:31:30,612][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6110, lr=0.001
[2025-05-02 14:31:30,639][meta_train][INFO] - epoch_48 saved !
[2025-05-02 14:31:54,509][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6118, lr=0.001
[2025-05-02 14:31:57,487][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6109, lr=0.001
[2025-05-02 14:32:19,962][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6180, lr=0.001
[2025-05-02 14:32:25,706][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6071, lr=0.001
[2025-05-02 14:32:47,959][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6080, lr=0.001
[2025-05-02 14:32:54,281][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6068, lr=0.001
[2025-05-02 14:33:16,935][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6095, lr=0.001
[2025-05-02 14:33:22,227][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6110, lr=0.001
[2025-05-02 14:33:44,100][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6446, lr=0.001
[2025-05-02 14:33:50,725][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6093, lr=0.001
[2025-05-02 14:34:12,769][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6178, lr=0.001
[2025-05-02 14:34:12,786][meta_train][INFO] - epoch_50 saved !
[2025-05-02 14:34:18,499][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6100, lr=0.001
[2025-05-02 14:34:41,060][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6177, lr=0.001
[2025-05-02 14:34:47,818][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6091, lr=0.001
[2025-05-02 14:35:09,165][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6130, lr=0.001
[2025-05-02 14:35:13,176][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6111, lr=0.001
[2025-05-02 14:35:13,204][meta_train][INFO] - epoch_49 saved !
[2025-05-02 14:35:36,523][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6422, lr=0.001
[2025-05-02 14:35:41,350][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6101, lr=0.001
[2025-05-02 14:36:02,230][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6171, lr=0.001
[2025-05-02 14:36:09,501][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6081, lr=0.001
[2025-05-02 14:36:29,981][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6111, lr=0.001
[2025-05-02 14:36:37,460][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6098, lr=0.001
[2025-05-02 14:36:58,808][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6078, lr=0.001
[2025-05-02 14:37:02,735][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6108, lr=0.001
[2025-05-02 14:37:27,005][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6091, lr=0.001
[2025-05-02 14:37:31,327][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6075, lr=0.001
[2025-05-02 14:37:56,017][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6095, lr=0.001
[2025-05-02 14:37:56,038][meta_train][INFO] - epoch_51 saved !
[2025-05-02 14:38:00,290][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6083, lr=0.001
[2025-05-02 14:38:04,334][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-02 14:38:04,385][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 14:38:04,385][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 14:38:04,385][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 14:38:24,913][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6160, lr=0.001
[2025-05-02 14:38:28,349][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6102, lr=0.001
[2025-05-02 14:38:38,719][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-02 14:38:38,817][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 14:38:38,817][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 14:38:38,817][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 14:39:02,470][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6077, lr=0.001
[2025-05-02 14:39:05,189][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6112, lr=0.001
[2025-05-02 14:39:05,225][meta_train][INFO] - epoch_50 saved !
[2025-05-02 14:39:07,237][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 14:39:17,673][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6109, lr=0.0100
[2025-05-02 14:39:31,116][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6107, lr=0.0100
[2025-05-02 14:39:42,574][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6093, lr=0.0100
[2025-05-02 14:39:44,586][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6113, lr=0.001
[2025-05-02 14:39:48,561][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6112, lr=0.001
[2025-05-02 14:39:53,261][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6095, lr=0.0100
[2025-05-02 14:40:07,109][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6094, lr=0.0100
[2025-05-02 14:40:19,772][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6100, lr=0.0100
[2025-05-02 14:40:29,595][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6380, lr=0.001
[2025-05-02 14:40:31,665][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6084, lr=0.0100
[2025-05-02 14:40:35,746][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6094, lr=0.001
[2025-05-02 14:40:41,592][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6080, lr=0.0100
[2025-05-02 14:40:55,889][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6080, lr=0.0100
[2025-05-02 14:41:08,202][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6075, lr=0.0100
[2025-05-02 14:41:13,727][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6162, lr=0.001
[2025-05-02 14:41:19,276][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6076, lr=0.0100
[2025-05-02 14:41:22,309][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6103, lr=0.001
[2025-05-02 14:41:30,618][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6074, lr=0.0100
[2025-05-02 14:41:42,998][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-02 14:41:54,245][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-02 14:41:57,840][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6091, lr=0.001
[2025-05-02 14:42:03,544][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6108, lr=0.001
[2025-05-02 14:42:05,322][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6072, lr=0.0100
[2025-05-02 14:42:16,664][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-02 14:42:28,613][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6063, lr=0.0100
[2025-05-02 14:42:39,498][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6063, lr=0.0100
[2025-05-02 14:42:41,430][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6088, lr=0.001
[2025-05-02 14:42:46,739][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6099, lr=0.001
[2025-05-02 14:42:49,351][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6062, lr=0.0100
[2025-05-02 14:43:00,542][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-02 14:43:12,961][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-02 14:43:23,556][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6131, lr=0.001
[2025-05-02 14:43:23,607][meta_train][INFO] - epoch_52 saved !
[2025-05-02 14:43:24,503][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-02 14:43:29,623][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6074, lr=0.001
[2025-05-02 14:43:34,367][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-02 14:43:45,504][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-02 14:43:52,230][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-02 14:44:00,675][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-02 14:44:00,995][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6130, lr=0.001
[2025-05-02 14:44:07,563][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6080, lr=0.001
[2025-05-02 14:44:08,951][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-02 14:44:17,239][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-02 14:44:25,580][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-02 14:44:27,078][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6158, lr=0.001
[2025-05-02 14:44:34,078][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-02 14:44:37,089][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6085, lr=0.001
[2025-05-02 14:44:37,122][meta_train][INFO] - epoch_51 saved !
[2025-05-02 14:44:42,516][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-02 14:44:50,841][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:44:55,942][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6093, lr=0.001
[2025-05-02 14:45:00,154][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:05,960][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6113, lr=0.001
[2025-05-02 14:45:08,362][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:16,031][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:24,210][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:25,122][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6077, lr=0.001
[2025-05-02 14:45:32,138][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:35,266][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6073, lr=0.001
[2025-05-02 14:45:40,877][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:49,393][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-02 14:45:54,291][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6154, lr=0.001
[2025-05-02 14:45:58,069][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:03,469][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6104, lr=0.001
[2025-05-02 14:46:05,810][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:13,873][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:21,621][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:21,722][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6361, lr=0.001
[2025-05-02 14:46:30,127][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:31,046][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6101, lr=0.001
[2025-05-02 14:46:37,726][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:46,137][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:50,268][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6106, lr=0.001
[2025-05-02 14:46:54,367][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:46:57,000][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6107, lr=0.001
[2025-05-02 14:47:02,936][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:11,067][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:19,309][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:20,024][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6092, lr=0.001
[2025-05-02 14:47:20,042][meta_train][INFO] - epoch_53 saved !
[2025-05-02 14:47:26,596][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6080, lr=0.001
[2025-05-02 14:47:27,684][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:36,107][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:43,989][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:48,502][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6087, lr=0.001
[2025-05-02 14:47:52,082][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:47:55,120][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6075, lr=0.001
[2025-05-02 14:48:00,185][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:08,168][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:15,875][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:18,206][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6129, lr=0.001
[2025-05-02 14:48:24,412][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:24,745][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6101, lr=0.001
[2025-05-02 14:48:24,771][meta_train][INFO] - epoch_52 saved !
[2025-05-02 14:48:32,657][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:40,625][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-02 14:48:46,657][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6156, lr=0.001
[2025-05-02 14:48:48,836][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:48:53,816][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6104, lr=0.001
[2025-05-02 14:48:57,211][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:05,052][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:13,040][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:16,640][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6094, lr=0.001
[2025-05-02 14:49:19,437][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6108, lr=0.001
[2025-05-02 14:49:20,746][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:29,082][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:36,626][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:43,745][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6332, lr=0.001
[2025-05-02 14:49:44,015][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:49:48,682][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6088, lr=0.001
[2025-05-02 14:49:52,578][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:01,009][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:09,446][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:12,475][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6112, lr=0.001
[2025-05-02 14:50:17,498][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6079, lr=0.001
[2025-05-02 14:50:17,845][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:25,810][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:34,213][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:41,113][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6077, lr=0.001
[2025-05-02 14:50:42,599][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:45,943][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6113, lr=0.001
[2025-05-02 14:50:50,524][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:50:59,002][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:06,988][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:07,066][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6149, lr=0.001
[2025-05-02 14:51:07,085][meta_train][INFO] - epoch_54 saved !
[2025-05-02 14:51:14,157][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6101, lr=0.001
[2025-05-02 14:51:15,145][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:23,015][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:31,458][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:32,920][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6148, lr=0.001
[2025-05-02 14:51:39,679][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:42,241][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6101, lr=0.001
[2025-05-02 14:51:47,694][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:51:56,004][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:01,517][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6152, lr=0.001
[2025-05-02 14:52:04,293][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:11,714][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6084, lr=0.001
[2025-05-02 14:52:11,744][meta_train][INFO] - epoch_53 saved !
[2025-05-02 14:52:12,532][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:20,968][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:29,537][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:30,840][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6123, lr=0.001
[2025-05-02 14:52:37,871][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:40,889][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6073, lr=0.001
[2025-05-02 14:52:45,209][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-02 14:52:52,924][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:00,166][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6092, lr=0.001
[2025-05-02 14:53:00,778][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:08,608][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:09,502][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6092, lr=0.001
[2025-05-02 14:53:17,527][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:25,812][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:28,533][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6103, lr=0.001
[2025-05-02 14:53:34,688][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:38,061][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6109, lr=0.001
[2025-05-02 14:53:42,468][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:50,564][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:53:56,472][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6321, lr=0.001
[2025-05-02 14:53:57,401][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:54:05,951][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-02 14:54:07,823][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6082, lr=0.001
[2025-05-02 14:54:10,902][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 14:54:10,907][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 14:54:25,146][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6088, lr=0.001
[2025-05-02 14:54:35,454][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6100, lr=0.001
[2025-05-02 14:54:54,701][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6075, lr=0.001
[2025-05-02 14:54:54,718][meta_train][INFO] - epoch_55 saved !
[2025-05-02 14:55:04,302][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6108, lr=0.001
[2025-05-02 14:55:23,494][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6078, lr=0.001
[2025-05-02 14:55:23,884][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 14:55:33,039][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6075, lr=0.001
[2025-05-02 14:55:52,618][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6093, lr=0.001
[2025-05-02 14:55:59,493][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6106, lr=0.001
[2025-05-02 14:55:59,509][meta_train][INFO] - epoch_54 saved !
[2025-05-02 14:56:20,962][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6290, lr=0.001
[2025-05-02 14:56:25,534][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6106, lr=0.001
[2025-05-02 14:56:42,815][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 14:56:43,220][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 14:56:49,559][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6148, lr=0.001
[2025-05-02 14:56:54,679][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6111, lr=0.001
[2025-05-02 14:57:18,301][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6127, lr=0.001
[2025-05-02 14:57:22,885][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6102, lr=0.001
[2025-05-02 14:57:46,182][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6105, lr=0.001
[2025-05-02 14:57:52,465][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6088, lr=0.001
[2025-05-02 14:58:11,603][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6142, lr=0.001
[2025-05-02 14:58:20,098][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6099, lr=0.001
[2025-05-02 14:58:40,709][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6090, lr=0.001
[2025-05-02 14:58:40,725][meta_train][INFO] - epoch_56 saved !
[2025-05-02 14:58:47,618][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6098, lr=0.001
[2025-05-02 14:59:08,724][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6141, lr=0.001
[2025-05-02 14:59:15,949][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6071, lr=0.001
[2025-05-02 14:59:29,606][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-02 14:59:29,676][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 14:59:29,676][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 14:59:29,676][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 14:59:37,091][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6096, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 14:59:44,275][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6066, lr=0.001
[2025-05-02 14:59:44,305][meta_train][INFO] - epoch_55 saved !
[2025-05-02 14:59:46,487][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 14:59:54,671][train][INFO] - Epoch 1/100, Val Acc=0.0578, Val Loss=4.1819, lr=0.0100
[2025-05-02 15:00:01,544][train][INFO] - Epoch 2/100, Val Acc=0.1358, Val Loss=3.5425, lr=0.0100
[2025-05-02 15:00:09,208][train][INFO] - Epoch 3/100, Val Acc=0.2123, Val Loss=2.9723, lr=0.0100
[2025-05-02 15:00:16,666][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 5

[2025-05-02 15:00:16,717][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 15:00:16,717][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 15:00:16,717][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 15:00:16,857][train][INFO] - Epoch 4/100, Val Acc=0.1693, Val Loss=3.4425, lr=0.0100
[2025-05-02 15:00:25,058][train][INFO] - Epoch 5/100, Val Acc=0.2502, Val Loss=2.7819, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 15:00:33,168][train][INFO] - Epoch 6/100, Val Acc=0.3128, Val Loss=2.5486, lr=0.0100
[2025-05-02 15:00:33,806][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 15:00:41,727][train][INFO] - Epoch 7/100, Val Acc=0.3576, Val Loss=2.3545, lr=0.0100
[2025-05-02 15:00:42,185][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Eva
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 7

[2025-05-02 15:00:42,242][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 15:00:42,242][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 15:00:42,242][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 15:00:42,382][train][INFO] - Epoch 1/100, Val Acc=0.6036, Val Loss=1.6686, lr=0.0100
[2025-05-02 15:00:48,396][train][INFO] - Epoch 8/100, Val Acc=0.3494, Val Loss=2.4588, lr=0.0100
[2025-05-02 15:00:50,527][train][INFO] - Epoch 2/100, Val Acc=0.5945, Val Loss=1.7711, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 15:00:56,688][train][INFO] - Epoch 9/100, Val Acc=0.3477, Val Loss=2.5675, lr=0.0100
[2025-05-02 15:00:58,624][train][INFO] - Epoch 3/100, Val Acc=0.5988, Val Loss=1.7642, lr=0.0100
[2025-05-02 15:00:59,540][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 15:01:04,391][train][INFO] - Epoch 10/100, Val Acc=0.3874, Val Loss=2.2990, lr=0.0100
[2025-05-02 15:01:06,345][train][INFO] - Epoch 4/100, Val Acc=0.6490, Val Loss=1.5439, lr=0.0100
[2025-05-02 15:01:07,211][train][INFO] - Epoch 1/100, Val Acc=0.3856, Val Loss=2.3375, lr=0.0100
[2025-05-02 15:01:11,503][train][INFO] - Epoch 11/100, Val Acc=0.4231, Val Loss=2.1541, lr=0.0100
[2025-05-02 15:01:13,686][train][INFO] - Epoch 5/100, Val Acc=0.6376, Val Loss=1.5785, lr=0.0100
[2025-05-02 15:01:14,105][train][INFO] - Epoch 2/100, Val Acc=0.5662, Val Loss=1.6655, lr=0.0100
[2025-05-02 15:01:19,091][train][INFO] - Epoch 12/100, Val Acc=0.4454, Val Loss=2.0634, lr=0.0100
[2025-05-02 15:01:21,114][train][INFO] - Epoch 3/100, Val Acc=0.5836, Val Loss=1.6852, lr=0.0100
[2025-05-02 15:01:21,602][train][INFO] - Epoch 6/100, Val Acc=0.6466, Val Loss=1.5672, lr=0.0100
[2025-05-02 15:01:26,969][train][INFO] - Epoch 13/100, Val Acc=0.4065, Val Loss=2.3094, lr=0.0100
[2025-05-02 15:01:28,528][train][INFO] - Epoch 4/100, Val Acc=0.6226, Val Loss=1.4611, lr=0.0100
[2025-05-02 15:01:29,260][train][INFO] - Epoch 7/100, Val Acc=0.6549, Val Loss=1.5086, lr=0.0100
[2025-05-02 15:01:34,657][train][INFO] - Epoch 14/100, Val Acc=0.3858, Val Loss=2.4622, lr=0.0100
[2025-05-02 15:01:36,172][train][INFO] - Epoch 5/100, Val Acc=0.6154, Val Loss=1.5116, lr=0.0100
[2025-05-02 15:01:36,890][train][INFO] - Epoch 8/100, Val Acc=0.6544, Val Loss=1.5439, lr=0.0100
[2025-05-02 15:01:42,293][train][INFO] - Epoch 15/100, Val Acc=0.4579, Val Loss=2.0224, lr=0.0100
[2025-05-02 15:01:43,563][train][INFO] - Epoch 6/100, Val Acc=0.6193, Val Loss=1.5755, lr=0.0100
[2025-05-02 15:01:44,672][train][INFO] - Epoch 9/100, Val Acc=0.6316, Val Loss=1.7157, lr=0.0100
[2025-05-02 15:01:50,446][train][INFO] - Epoch 16/100, Val Acc=0.4660, Val Loss=2.0022, lr=0.0100
[2025-05-02 15:01:51,202][train][INFO] - Epoch 7/100, Val Acc=0.6239, Val Loss=1.5283, lr=0.0100
[2025-05-02 15:01:52,625][train][INFO] - Epoch 10/100, Val Acc=0.6465, Val Loss=1.5666, lr=0.0100
[2025-05-02 15:01:57,779][train][INFO] - Epoch 17/100, Val Acc=0.4950, Val Loss=1.8631, lr=0.0100
[2025-05-02 15:01:58,567][train][INFO] - Epoch 8/100, Val Acc=0.6444, Val Loss=1.4660, lr=0.0100
[2025-05-02 15:02:00,394][train][INFO] - Epoch 11/100, Val Acc=0.6216, Val Loss=1.7312, lr=0.0100
[2025-05-02 15:02:05,607][train][INFO] - Epoch 18/100, Val Acc=0.4694, Val Loss=2.0349, lr=0.0100
[2025-05-02 15:02:05,780][train][INFO] - Epoch 9/100, Val Acc=0.6394, Val Loss=1.4724, lr=0.0100
[2025-05-02 15:02:08,272][train][INFO] - Epoch 12/100, Val Acc=0.6412, Val Loss=1.6202, lr=0.0100
[2025-05-02 15:02:13,320][train][INFO] - Epoch 19/100, Val Acc=0.4669, Val Loss=2.0106, lr=0.0100
[2025-05-02 15:02:13,444][train][INFO] - Epoch 10/100, Val Acc=0.6121, Val Loss=1.6571, lr=0.0100
[2025-05-02 15:02:16,481][train][INFO] - Epoch 13/100, Val Acc=0.6456, Val Loss=1.6443, lr=0.0100
[2025-05-02 15:02:20,956][train][INFO] - Epoch 11/100, Val Acc=0.6248, Val Loss=1.5491, lr=0.0100
[2025-05-02 15:02:20,980][train][INFO] - Epoch 20/100, Val Acc=0.5272, Val Loss=1.7421, lr=0.0100
[2025-05-02 15:02:23,651][train][INFO] - Epoch 14/100, Val Acc=0.6615, Val Loss=1.5858, lr=0.0100
[2025-05-02 15:02:28,261][train][INFO] - Epoch 12/100, Val Acc=0.6501, Val Loss=1.4611, lr=0.0100
[2025-05-02 15:02:28,705][train][INFO] - Epoch 21/100, Val Acc=0.4443, Val Loss=2.1905, lr=0.0100
[2025-05-02 15:02:31,476][train][INFO] - Epoch 15/100, Val Acc=0.6416, Val Loss=1.6713, lr=0.0100
[2025-05-02 15:02:35,775][train][INFO] - Epoch 22/100, Val Acc=0.5161, Val Loss=1.8357, lr=0.0100
[2025-05-02 15:02:35,933][train][INFO] - Epoch 13/100, Val Acc=0.6419, Val Loss=1.4775, lr=0.0100
[2025-05-02 15:02:38,926][train][INFO] - Epoch 16/100, Val Acc=0.6533, Val Loss=1.5601, lr=0.0100
[2025-05-02 15:02:43,201][train][INFO] - Epoch 23/100, Val Acc=0.5256, Val Loss=1.7673, lr=0.0100
[2025-05-02 15:02:43,497][train][INFO] - Epoch 14/100, Val Acc=0.6417, Val Loss=1.5455, lr=0.0100
[2025-05-02 15:02:46,001][train][INFO] - Epoch 17/100, Val Acc=0.6473, Val Loss=1.6009, lr=0.0100
[2025-05-02 15:02:50,920][train][INFO] - Epoch 24/100, Val Acc=0.5273, Val Loss=1.7672, lr=0.0100
[2025-05-02 15:02:51,098][train][INFO] - Epoch 15/100, Val Acc=0.6354, Val Loss=1.5409, lr=0.0100
[2025-05-02 15:02:53,717][train][INFO] - Epoch 18/100, Val Acc=0.6625, Val Loss=1.5229, lr=0.0100
[2025-05-02 15:02:58,608][train][INFO] - Epoch 16/100, Val Acc=0.6453, Val Loss=1.5355, lr=0.0100
[2025-05-02 15:02:58,617][train][INFO] - Epoch 25/100, Val Acc=0.5381, Val Loss=1.7377, lr=0.0100
[2025-05-02 15:03:01,363][train][INFO] - Epoch 19/100, Val Acc=0.6562, Val Loss=1.5655, lr=0.0100
[2025-05-02 15:03:06,019][train][INFO] - Epoch 17/100, Val Acc=0.6551, Val Loss=1.4968, lr=0.0100
[2025-05-02 15:03:06,252][train][INFO] - Epoch 26/100, Val Acc=0.4931, Val Loss=2.0282, lr=0.0100
[2025-05-02 15:03:08,997][train][INFO] - Epoch 20/100, Val Acc=0.6548, Val Loss=1.6071, lr=0.0100
[2025-05-02 15:03:13,527][train][INFO] - Epoch 18/100, Val Acc=0.6610, Val Loss=1.4622, lr=0.0100
[2025-05-02 15:03:14,000][train][INFO] - Epoch 27/100, Val Acc=0.5327, Val Loss=1.7722, lr=0.0100
[2025-05-02 15:03:16,854][train][INFO] - Epoch 21/100, Val Acc=0.6623, Val Loss=1.5437, lr=0.0100
[2025-05-02 15:03:20,867][train][INFO] - Epoch 19/100, Val Acc=0.6433, Val Loss=1.5450, lr=0.0100
[2025-05-02 15:03:21,507][train][INFO] - Epoch 28/100, Val Acc=0.4841, Val Loss=2.0869, lr=0.0100
[2025-05-02 15:03:23,902][train][INFO] - Epoch 22/100, Val Acc=0.6606, Val Loss=1.5826, lr=0.0100
[2025-05-02 15:03:28,463][train][INFO] - Epoch 20/100, Val Acc=0.6432, Val Loss=1.5442, lr=0.0100
[2025-05-02 15:03:29,075][train][INFO] - Epoch 29/100, Val Acc=0.5148, Val Loss=1.8430, lr=0.0100
[2025-05-02 15:03:31,289][train][INFO] - Epoch 23/100, Val Acc=0.6585, Val Loss=1.5884, lr=0.0100
[2025-05-02 15:03:36,124][train][INFO] - Epoch 21/100, Val Acc=0.6518, Val Loss=1.5337, lr=0.0100
[2025-05-02 15:03:37,043][train][INFO] - Epoch 30/100, Val Acc=0.5169, Val Loss=1.8812, lr=0.0100
[2025-05-02 15:03:39,015][train][INFO] - Epoch 24/100, Val Acc=0.6517, Val Loss=1.6621, lr=0.0100
[2025-05-02 15:03:43,726][train][INFO] - Epoch 22/100, Val Acc=0.6560, Val Loss=1.4851, lr=0.0100
[2025-05-02 15:03:44,452][train][INFO] - Epoch 31/100, Val Acc=0.5356, Val Loss=1.7682, lr=0.0100
[2025-05-02 15:03:46,621][train][INFO] - Epoch 25/100, Val Acc=0.6575, Val Loss=1.5861, lr=0.0100
[2025-05-02 15:03:51,130][train][INFO] - Epoch 23/100, Val Acc=0.6642, Val Loss=1.4812, lr=0.0100
[2025-05-02 15:03:52,004][train][INFO] - Epoch 32/100, Val Acc=0.5539, Val Loss=1.6986, lr=0.0100
[2025-05-02 15:03:54,055][train][INFO] - Epoch 26/100, Val Acc=0.6639, Val Loss=1.5866, lr=0.0100
[2025-05-02 15:03:58,334][train][INFO] - Epoch 24/100, Val Acc=0.6588, Val Loss=1.5469, lr=0.0100
[2025-05-02 15:03:59,527][train][INFO] - Epoch 33/100, Val Acc=0.5545, Val Loss=1.6932, lr=0.0100
[2025-05-02 15:04:01,651][train][INFO] - Epoch 27/100, Val Acc=0.6656, Val Loss=1.5704, lr=0.0100
[2025-05-02 15:04:05,519][train][INFO] - Epoch 25/100, Val Acc=0.6661, Val Loss=1.4928, lr=0.0100
[2025-05-02 15:04:06,756][train][INFO] - Epoch 34/100, Val Acc=0.5626, Val Loss=1.6524, lr=0.0100
[2025-05-02 15:04:09,060][train][INFO] - Epoch 28/100, Val Acc=0.6548, Val Loss=1.6433, lr=0.0100
[2025-05-02 15:04:12,871][train][INFO] - Epoch 26/100, Val Acc=0.6552, Val Loss=1.5588, lr=0.0100
[2025-05-02 15:04:13,861][train][INFO] - Epoch 35/100, Val Acc=0.5481, Val Loss=1.7254, lr=0.0100
[2025-05-02 15:04:16,654][train][INFO] - Epoch 29/100, Val Acc=0.6743, Val Loss=1.5050, lr=0.0100
[2025-05-02 15:04:20,651][train][INFO] - Epoch 27/100, Val Acc=0.6649, Val Loss=1.4875, lr=0.0100
[2025-05-02 15:04:21,508][train][INFO] - Epoch 36/100, Val Acc=0.5184, Val Loss=1.8540, lr=0.0100
[2025-05-02 15:04:23,997][train][INFO] - Epoch 30/100, Val Acc=0.6622, Val Loss=1.6046, lr=0.0100
[2025-05-02 15:04:27,777][train][INFO] - Epoch 28/100, Val Acc=0.6517, Val Loss=1.5890, lr=0.0100
[2025-05-02 15:04:29,013][train][INFO] - Epoch 37/100, Val Acc=0.5517, Val Loss=1.7189, lr=0.0100
[2025-05-02 15:04:31,555][train][INFO] - Epoch 31/100, Val Acc=0.6504, Val Loss=1.6174, lr=0.0100
[2025-05-02 15:04:35,005][train][INFO] - Epoch 29/100, Val Acc=0.6589, Val Loss=1.5208, lr=0.0100
[2025-05-02 15:04:36,587][train][INFO] - Epoch 38/100, Val Acc=0.5602, Val Loss=1.6926, lr=0.0100
[2025-05-02 15:04:39,281][train][INFO] - Epoch 32/100, Val Acc=0.6568, Val Loss=1.6162, lr=0.0100
[2025-05-02 15:04:42,792][train][INFO] - Epoch 30/100, Val Acc=0.6615, Val Loss=1.5165, lr=0.0100
[2025-05-02 15:04:44,088][train][INFO] - Epoch 39/100, Val Acc=0.5505, Val Loss=1.7246, lr=0.0100
[2025-05-02 15:04:46,914][train][INFO] - Epoch 33/100, Val Acc=0.6516, Val Loss=1.6467, lr=0.0100
[2025-05-02 15:04:50,095][train][INFO] - Epoch 31/100, Val Acc=0.6501, Val Loss=1.6004, lr=0.0100
[2025-05-02 15:04:51,531][train][INFO] - Epoch 40/100, Val Acc=0.5451, Val Loss=1.8188, lr=0.0100
[2025-05-02 15:04:54,722][train][INFO] - Epoch 34/100, Val Acc=0.6521, Val Loss=1.6180, lr=0.0100
[2025-05-02 15:04:57,890][train][INFO] - Epoch 32/100, Val Acc=0.6402, Val Loss=1.6516, lr=0.0100
[2025-05-02 15:04:59,017][train][INFO] - Epoch 41/100, Val Acc=0.5666, Val Loss=1.7021, lr=0.0100
[2025-05-02 15:05:02,210][train][INFO] - Epoch 35/100, Val Acc=0.6615, Val Loss=1.5951, lr=0.0100
[2025-05-02 15:05:05,348][train][INFO] - Epoch 33/100, Val Acc=0.6648, Val Loss=1.5215, lr=0.0100
[2025-05-02 15:05:06,877][train][INFO] - Epoch 42/100, Val Acc=0.5252, Val Loss=1.9208, lr=0.0100
[2025-05-02 15:05:09,464][train][INFO] - Epoch 36/100, Val Acc=0.6486, Val Loss=1.6895, lr=0.0100
[2025-05-02 15:05:12,958][train][INFO] - Epoch 34/100, Val Acc=0.6616, Val Loss=1.5678, lr=0.0100
[2025-05-02 15:05:14,404][train][INFO] - Epoch 43/100, Val Acc=0.5515, Val Loss=1.7644, lr=0.0100
[2025-05-02 15:05:17,043][train][INFO] - Epoch 37/100, Val Acc=0.6513, Val Loss=1.6401, lr=0.0100
[2025-05-02 15:05:20,486][train][INFO] - Epoch 35/100, Val Acc=0.6496, Val Loss=1.5906, lr=0.0100
[2025-05-02 15:05:21,695][train][INFO] - Epoch 44/100, Val Acc=0.5594, Val Loss=1.7331, lr=0.0100
[2025-05-02 15:05:24,563][train][INFO] - Epoch 38/100, Val Acc=0.6544, Val Loss=1.6591, lr=0.0100
[2025-05-02 15:05:28,381][train][INFO] - Epoch 36/100, Val Acc=0.6334, Val Loss=1.7260, lr=0.0100
[2025-05-02 15:05:29,343][train][INFO] - Epoch 45/100, Val Acc=0.5734, Val Loss=1.6893, lr=0.0100
[2025-05-02 15:05:32,534][train][INFO] - Epoch 39/100, Val Acc=0.6519, Val Loss=1.6703, lr=0.0100
[2025-05-02 15:05:35,929][train][INFO] - Epoch 37/100, Val Acc=0.6620, Val Loss=1.5492, lr=0.0100
[2025-05-02 15:05:37,057][train][INFO] - Epoch 46/100, Val Acc=0.5659, Val Loss=1.7129, lr=0.0100
[2025-05-02 15:05:39,889][train][INFO] - Epoch 40/100, Val Acc=0.6573, Val Loss=1.6069, lr=0.0100
[2025-05-02 15:05:43,533][train][INFO] - Epoch 38/100, Val Acc=0.6658, Val Loss=1.5345, lr=0.0100
[2025-05-02 15:05:44,330][train][INFO] - Epoch 47/100, Val Acc=0.5783, Val Loss=1.6588, lr=0.0100
[2025-05-02 15:05:47,544][train][INFO] - Epoch 41/100, Val Acc=0.6646, Val Loss=1.5532, lr=0.0100
[2025-05-02 15:05:50,912][train][INFO] - Epoch 39/100, Val Acc=0.6484, Val Loss=1.6163, lr=0.0100
[2025-05-02 15:05:51,786][train][INFO] - Epoch 48/100, Val Acc=0.5633, Val Loss=1.7076, lr=0.0100
[2025-05-02 15:05:54,993][train][INFO] - Epoch 42/100, Val Acc=0.6564, Val Loss=1.6667, lr=0.0100
[2025-05-02 15:05:58,555][train][INFO] - Epoch 40/100, Val Acc=0.6577, Val Loss=1.5859, lr=0.0100
[2025-05-02 15:05:59,227][train][INFO] - Epoch 49/100, Val Acc=0.5589, Val Loss=1.7965, lr=0.0100
[2025-05-02 15:06:02,389][train][INFO] - Epoch 43/100, Val Acc=0.6487, Val Loss=1.6860, lr=0.0100
[2025-05-02 15:06:06,023][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.5300, lr=0.0100
[2025-05-02 15:06:06,590][train][INFO] - Epoch 50/100, Val Acc=0.5662, Val Loss=1.7374, lr=0.0100
[2025-05-02 15:06:09,352][train][INFO] - Epoch 44/100, Val Acc=0.6470, Val Loss=1.7242, lr=0.0100
[2025-05-02 15:06:13,317][train][INFO] - Epoch 42/100, Val Acc=0.6581, Val Loss=1.5897, lr=0.0100
[2025-05-02 15:06:13,328][train][INFO] - Epoch 51/100, Val Acc=0.5792, Val Loss=1.6537, lr=0.0100
[2025-05-02 15:06:17,370][train][INFO] - Epoch 45/100, Val Acc=0.6573, Val Loss=1.6349, lr=0.0100
[2025-05-02 15:06:20,507][train][INFO] - Epoch 52/100, Val Acc=0.5620, Val Loss=1.7980, lr=0.0100
[2025-05-02 15:06:21,074][train][INFO] - Epoch 43/100, Val Acc=0.6587, Val Loss=1.5612, lr=0.0100
[2025-05-02 15:06:24,877][train][INFO] - Epoch 46/100, Val Acc=0.6629, Val Loss=1.6029, lr=0.0100
[2025-05-02 15:06:27,868][train][INFO] - Epoch 53/100, Val Acc=0.5879, Val Loss=1.6413, lr=0.0100
[2025-05-02 15:06:28,542][train][INFO] - Epoch 44/100, Val Acc=0.6561, Val Loss=1.5998, lr=0.0100
[2025-05-02 15:06:32,650][train][INFO] - Epoch 47/100, Val Acc=0.6523, Val Loss=1.6293, lr=0.0100
[2025-05-02 15:06:35,110][train][INFO] - Epoch 54/100, Val Acc=0.5793, Val Loss=1.6752, lr=0.0100
[2025-05-02 15:06:35,945][train][INFO] - Epoch 45/100, Val Acc=0.6646, Val Loss=1.5554, lr=0.0100
[2025-05-02 15:06:39,967][train][INFO] - Epoch 48/100, Val Acc=0.6566, Val Loss=1.6138, lr=0.0100
[2025-05-02 15:06:42,928][train][INFO] - Epoch 55/100, Val Acc=0.5829, Val Loss=1.6479, lr=0.0100
[2025-05-02 15:06:43,452][train][INFO] - Epoch 46/100, Val Acc=0.6692, Val Loss=1.5260, lr=0.0100
[2025-05-02 15:06:47,486][train][INFO] - Epoch 49/100, Val Acc=0.6619, Val Loss=1.6321, lr=0.0100
[2025-05-02 15:06:50,246][train][INFO] - Epoch 56/100, Val Acc=0.5686, Val Loss=1.7581, lr=0.0100
[2025-05-02 15:06:51,262][train][INFO] - Epoch 47/100, Val Acc=0.6585, Val Loss=1.5821, lr=0.0100
[2025-05-02 15:06:55,209][train][INFO] - Epoch 50/100, Val Acc=0.6578, Val Loss=1.5980, lr=0.0100
[2025-05-02 15:06:57,849][train][INFO] - Epoch 57/100, Val Acc=0.5666, Val Loss=1.7558, lr=0.0100
[2025-05-02 15:06:58,809][train][INFO] - Epoch 48/100, Val Acc=0.6606, Val Loss=1.5985, lr=0.0100
[2025-05-02 15:07:03,199][train][INFO] - Epoch 51/100, Val Acc=0.6567, Val Loss=1.6566, lr=0.0100
[2025-05-02 15:07:05,425][train][INFO] - Epoch 58/100, Val Acc=0.5751, Val Loss=1.6981, lr=0.0100
[2025-05-02 15:07:06,409][train][INFO] - Epoch 49/100, Val Acc=0.6605, Val Loss=1.5883, lr=0.0100
[2025-05-02 15:07:10,738][train][INFO] - Epoch 52/100, Val Acc=0.6614, Val Loss=1.6319, lr=0.0100
[2025-05-02 15:07:13,067][train][INFO] - Epoch 59/100, Val Acc=0.5562, Val Loss=1.8184, lr=0.0100
[2025-05-02 15:07:13,843][train][INFO] - Epoch 50/100, Val Acc=0.6623, Val Loss=1.5857, lr=0.0100
[2025-05-02 15:07:18,061][train][INFO] - Epoch 53/100, Val Acc=0.6654, Val Loss=1.6063, lr=0.0100
[2025-05-02 15:07:20,446][train][INFO] - Epoch 60/100, Val Acc=0.5683, Val Loss=1.8019, lr=0.0100
[2025-05-02 15:07:21,640][train][INFO] - Epoch 51/100, Val Acc=0.6565, Val Loss=1.6672, lr=0.0100
[2025-05-02 15:07:25,625][train][INFO] - Epoch 54/100, Val Acc=0.6643, Val Loss=1.5877, lr=0.0100
[2025-05-02 15:07:28,173][train][INFO] - Epoch 61/100, Val Acc=0.6406, Val Loss=1.4126, lr=0.0010
[2025-05-02 15:07:29,350][train][INFO] - Epoch 52/100, Val Acc=0.6486, Val Loss=1.6913, lr=0.0100
[2025-05-02 15:07:33,096][train][INFO] - Epoch 55/100, Val Acc=0.6563, Val Loss=1.6073, lr=0.0100
[2025-05-02 15:07:35,265][train][INFO] - Epoch 62/100, Val Acc=0.6449, Val Loss=1.4076, lr=0.0010
[2025-05-02 15:07:36,600][train][INFO] - Epoch 53/100, Val Acc=0.6603, Val Loss=1.5873, lr=0.0100
[2025-05-02 15:07:40,647][train][INFO] - Epoch 56/100, Val Acc=0.6632, Val Loss=1.5843, lr=0.0100
[2025-05-02 15:07:42,795][train][INFO] - Epoch 63/100, Val Acc=0.6463, Val Loss=1.4144, lr=0.0010
[2025-05-02 15:07:43,808][train][INFO] - Epoch 54/100, Val Acc=0.6591, Val Loss=1.5746, lr=0.0100
[2025-05-02 15:07:48,358][train][INFO] - Epoch 57/100, Val Acc=0.6655, Val Loss=1.5763, lr=0.0100
[2025-05-02 15:07:50,740][train][INFO] - Epoch 64/100, Val Acc=0.6453, Val Loss=1.4120, lr=0.0010
[2025-05-02 15:07:51,428][train][INFO] - Epoch 55/100, Val Acc=0.6618, Val Loss=1.5869, lr=0.0100
[2025-05-02 15:07:56,082][train][INFO] - Epoch 58/100, Val Acc=0.6624, Val Loss=1.5967, lr=0.0100
[2025-05-02 15:07:58,271][train][INFO] - Epoch 65/100, Val Acc=0.6428, Val Loss=1.4325, lr=0.0010
[2025-05-02 15:07:59,036][train][INFO] - Epoch 56/100, Val Acc=0.6474, Val Loss=1.6644, lr=0.0100
[2025-05-02 15:08:03,773][train][INFO] - Epoch 59/100, Val Acc=0.6456, Val Loss=1.6947, lr=0.0100
[2025-05-02 15:08:05,895][train][INFO] - Epoch 66/100, Val Acc=0.6469, Val Loss=1.4303, lr=0.0010
[2025-05-02 15:08:06,795][train][INFO] - Epoch 57/100, Val Acc=0.6570, Val Loss=1.6274, lr=0.0100
[2025-05-02 15:08:11,403][train][INFO] - Epoch 60/100, Val Acc=0.6505, Val Loss=1.6979, lr=0.0100
[2025-05-02 15:08:13,096][train][INFO] - Epoch 67/100, Val Acc=0.6468, Val Loss=1.4410, lr=0.0010
[2025-05-02 15:08:14,258][train][INFO] - Epoch 58/100, Val Acc=0.6529, Val Loss=1.6180, lr=0.0100
[2025-05-02 15:08:18,657][train][INFO] - Epoch 61/100, Val Acc=0.7144, Val Loss=1.3410, lr=0.0010
[2025-05-02 15:08:20,824][train][INFO] - Epoch 68/100, Val Acc=0.6494, Val Loss=1.4500, lr=0.0010
[2025-05-02 15:08:21,422][train][INFO] - Epoch 59/100, Val Acc=0.6516, Val Loss=1.6030, lr=0.0100
[2025-05-02 15:08:26,297][train][INFO] - Epoch 62/100, Val Acc=0.7184, Val Loss=1.3288, lr=0.0010
[2025-05-02 15:08:28,249][train][INFO] - Epoch 69/100, Val Acc=0.6506, Val Loss=1.4493, lr=0.0010
[2025-05-02 15:08:28,971][train][INFO] - Epoch 60/100, Val Acc=0.6554, Val Loss=1.5805, lr=0.0100
[2025-05-02 15:08:33,696][train][INFO] - Epoch 63/100, Val Acc=0.7222, Val Loss=1.3325, lr=0.0010
[2025-05-02 15:08:35,867][train][INFO] - Epoch 70/100, Val Acc=0.6497, Val Loss=1.4549, lr=0.0010
[2025-05-02 15:08:36,667][train][INFO] - Epoch 61/100, Val Acc=0.7123, Val Loss=1.3072, lr=0.0010
[2025-05-02 15:08:41,257][train][INFO] - Epoch 64/100, Val Acc=0.7224, Val Loss=1.3358, lr=0.0010
[2025-05-02 15:08:43,688][train][INFO] - Epoch 71/100, Val Acc=0.6491, Val Loss=1.4620, lr=0.0010
[2025-05-02 15:08:43,738][train][INFO] - Epoch 62/100, Val Acc=0.7176, Val Loss=1.3015, lr=0.0010
[2025-05-02 15:08:48,991][train][INFO] - Epoch 65/100, Val Acc=0.7233, Val Loss=1.3364, lr=0.0010
[2025-05-02 15:08:51,170][train][INFO] - Epoch 72/100, Val Acc=0.6498, Val Loss=1.4786, lr=0.0010
[2025-05-02 15:08:51,254][train][INFO] - Epoch 63/100, Val Acc=0.7206, Val Loss=1.3092, lr=0.0010
[2025-05-02 15:08:56,339][train][INFO] - Epoch 66/100, Val Acc=0.7232, Val Loss=1.3425, lr=0.0010
[2025-05-02 15:08:58,749][train][INFO] - Epoch 64/100, Val Acc=0.7199, Val Loss=1.3215, lr=0.0010
[2025-05-02 15:08:59,002][train][INFO] - Epoch 73/100, Val Acc=0.6466, Val Loss=1.4586, lr=0.0010
[2025-05-02 15:09:04,063][train][INFO] - Epoch 67/100, Val Acc=0.7231, Val Loss=1.3443, lr=0.0010
[2025-05-02 15:09:06,315][train][INFO] - Epoch 65/100, Val Acc=0.7232, Val Loss=1.3205, lr=0.0010
[2025-05-02 15:09:06,374][train][INFO] - Epoch 74/100, Val Acc=0.6499, Val Loss=1.4744, lr=0.0010
[2025-05-02 15:09:11,121][train][INFO] - Epoch 68/100, Val Acc=0.7227, Val Loss=1.3412, lr=0.0010
[2025-05-02 15:09:13,545][train][INFO] - Epoch 66/100, Val Acc=0.7218, Val Loss=1.3241, lr=0.0010
[2025-05-02 15:09:13,591][train][INFO] - Epoch 75/100, Val Acc=0.6458, Val Loss=1.4826, lr=0.0010
[2025-05-02 15:09:19,097][train][INFO] - Epoch 69/100, Val Acc=0.7214, Val Loss=1.3535, lr=0.0010
[2025-05-02 15:09:21,009][train][INFO] - Epoch 76/100, Val Acc=0.6486, Val Loss=1.4903, lr=0.0010
[2025-05-02 15:09:21,181][train][INFO] - Epoch 67/100, Val Acc=0.7235, Val Loss=1.3301, lr=0.0010
[2025-05-02 15:09:26,945][train][INFO] - Epoch 70/100, Val Acc=0.7237, Val Loss=1.3493, lr=0.0010
[2025-05-02 15:09:28,666][train][INFO] - Epoch 68/100, Val Acc=0.7234, Val Loss=1.3224, lr=0.0010
[2025-05-02 15:09:29,109][train][INFO] - Epoch 77/100, Val Acc=0.6472, Val Loss=1.4971, lr=0.0010
[2025-05-02 15:09:34,021][train][INFO] - Epoch 71/100, Val Acc=0.7234, Val Loss=1.3502, lr=0.0010
[2025-05-02 15:09:36,282][train][INFO] - Epoch 78/100, Val Acc=0.6463, Val Loss=1.5066, lr=0.0010
[2025-05-02 15:09:36,333][train][INFO] - Epoch 69/100, Val Acc=0.7253, Val Loss=1.3337, lr=0.0010
[2025-05-02 15:09:41,671][train][INFO] - Epoch 72/100, Val Acc=0.7227, Val Loss=1.3477, lr=0.0010
[2025-05-02 15:09:43,679][train][INFO] - Epoch 79/100, Val Acc=0.6484, Val Loss=1.5150, lr=0.0010
[2025-05-02 15:09:44,113][train][INFO] - Epoch 70/100, Val Acc=0.7242, Val Loss=1.3403, lr=0.0010
[2025-05-02 15:09:49,451][train][INFO] - Epoch 73/100, Val Acc=0.7271, Val Loss=1.3459, lr=0.0010
[2025-05-02 15:09:51,211][train][INFO] - Epoch 80/100, Val Acc=0.6478, Val Loss=1.5328, lr=0.0010
[2025-05-02 15:09:51,380][train][INFO] - Epoch 71/100, Val Acc=0.7238, Val Loss=1.3491, lr=0.0010
[2025-05-02 15:09:57,422][train][INFO] - Epoch 74/100, Val Acc=0.7259, Val Loss=1.3562, lr=0.0010
[2025-05-02 15:09:58,865][train][INFO] - Epoch 72/100, Val Acc=0.7222, Val Loss=1.3470, lr=0.0010
[2025-05-02 15:09:59,127][train][INFO] - Epoch 81/100, Val Acc=0.6486, Val Loss=1.5331, lr=0.0010
[2025-05-02 15:10:05,474][train][INFO] - Epoch 75/100, Val Acc=0.7260, Val Loss=1.3556, lr=0.0010
[2025-05-02 15:10:06,569][train][INFO] - Epoch 73/100, Val Acc=0.7237, Val Loss=1.3435, lr=0.0010
[2025-05-02 15:10:06,968][train][INFO] - Epoch 82/100, Val Acc=0.6456, Val Loss=1.5357, lr=0.0010
[2025-05-02 15:10:13,235][train][INFO] - Epoch 76/100, Val Acc=0.7282, Val Loss=1.3618, lr=0.0010
[2025-05-02 15:10:14,054][train][INFO] - Epoch 74/100, Val Acc=0.7233, Val Loss=1.3415, lr=0.0010
[2025-05-02 15:10:14,736][train][INFO] - Epoch 83/100, Val Acc=0.6457, Val Loss=1.5404, lr=0.0010
[2025-05-02 15:10:20,607][train][INFO] - Epoch 77/100, Val Acc=0.7254, Val Loss=1.3624, lr=0.0010
[2025-05-02 15:10:21,331][train][INFO] - Epoch 75/100, Val Acc=0.7229, Val Loss=1.3431, lr=0.0010
[2025-05-02 15:10:22,133][train][INFO] - Epoch 84/100, Val Acc=0.6468, Val Loss=1.5470, lr=0.0010
[2025-05-02 15:10:28,340][train][INFO] - Epoch 78/100, Val Acc=0.7262, Val Loss=1.3564, lr=0.0010
[2025-05-02 15:10:28,457][train][INFO] - Epoch 76/100, Val Acc=0.7220, Val Loss=1.3414, lr=0.0010
[2025-05-02 15:10:29,685][train][INFO] - Epoch 85/100, Val Acc=0.6483, Val Loss=1.5478, lr=0.0010
[2025-05-02 15:10:35,275][train][INFO] - Epoch 77/100, Val Acc=0.7247, Val Loss=1.3492, lr=0.0010
[2025-05-02 15:10:36,591][train][INFO] - Epoch 79/100, Val Acc=0.7258, Val Loss=1.3614, lr=0.0010
[2025-05-02 15:10:37,163][train][INFO] - Epoch 86/100, Val Acc=0.6469, Val Loss=1.5616, lr=0.0010
[2025-05-02 15:10:42,430][train][INFO] - Epoch 78/100, Val Acc=0.7238, Val Loss=1.3439, lr=0.0010
[2025-05-02 15:10:44,375][train][INFO] - Epoch 80/100, Val Acc=0.7258, Val Loss=1.3567, lr=0.0010
[2025-05-02 15:10:44,401][train][INFO] - Epoch 87/100, Val Acc=0.6446, Val Loss=1.5670, lr=0.0010
[2025-05-02 15:10:50,019][train][INFO] - Epoch 79/100, Val Acc=0.7255, Val Loss=1.3560, lr=0.0010
[2025-05-02 15:10:51,842][train][INFO] - Epoch 88/100, Val Acc=0.6462, Val Loss=1.5625, lr=0.0010
[2025-05-02 15:10:51,968][train][INFO] - Epoch 81/100, Val Acc=0.7264, Val Loss=1.3577, lr=0.0010
[2025-05-02 15:10:57,910][train][INFO] - Epoch 80/100, Val Acc=0.7235, Val Loss=1.3578, lr=0.0010
[2025-05-02 15:10:59,421][train][INFO] - Epoch 89/100, Val Acc=0.6495, Val Loss=1.5640, lr=0.0010
[2025-05-02 15:11:00,131][train][INFO] - Epoch 82/100, Val Acc=0.7269, Val Loss=1.3590, lr=0.0010
[2025-05-02 15:11:05,194][train][INFO] - Epoch 81/100, Val Acc=0.7265, Val Loss=1.3601, lr=0.0010
[2025-05-02 15:11:07,023][train][INFO] - Epoch 90/100, Val Acc=0.6435, Val Loss=1.5906, lr=0.0010
[2025-05-02 15:11:07,711][train][INFO] - Epoch 83/100, Val Acc=0.7247, Val Loss=1.3560, lr=0.0010
[2025-05-02 15:11:12,606][train][INFO] - Epoch 82/100, Val Acc=0.7279, Val Loss=1.3542, lr=0.0010
[2025-05-02 15:11:14,553][train][INFO] - Epoch 91/100, Val Acc=0.6497, Val Loss=1.5703, lr=0.0001
[2025-05-02 15:11:15,196][train][INFO] - Epoch 84/100, Val Acc=0.7272, Val Loss=1.3554, lr=0.0010
[2025-05-02 15:11:20,017][train][INFO] - Epoch 83/100, Val Acc=0.7254, Val Loss=1.3593, lr=0.0010
[2025-05-02 15:11:21,986][train][INFO] - Epoch 92/100, Val Acc=0.6468, Val Loss=1.5752, lr=0.0001
[2025-05-02 15:11:23,045][train][INFO] - Epoch 85/100, Val Acc=0.7263, Val Loss=1.3582, lr=0.0010
[2025-05-02 15:11:27,152][train][INFO] - Epoch 84/100, Val Acc=0.7239, Val Loss=1.3647, lr=0.0010
[2025-05-02 15:11:29,856][train][INFO] - Epoch 93/100, Val Acc=0.6504, Val Loss=1.5685, lr=0.0001
[2025-05-02 15:11:31,057][train][INFO] - Epoch 86/100, Val Acc=0.7268, Val Loss=1.3592, lr=0.0010
[2025-05-02 15:11:34,091][train][INFO] - Epoch 85/100, Val Acc=0.7257, Val Loss=1.3590, lr=0.0010
[2025-05-02 15:11:37,307][train][INFO] - Epoch 94/100, Val Acc=0.6507, Val Loss=1.5605, lr=0.0001
[2025-05-02 15:11:38,997][train][INFO] - Epoch 87/100, Val Acc=0.7289, Val Loss=1.3533, lr=0.0010
[2025-05-02 15:11:41,775][train][INFO] - Epoch 86/100, Val Acc=0.7277, Val Loss=1.3576, lr=0.0010
[2025-05-02 15:11:44,882][train][INFO] - Epoch 95/100, Val Acc=0.6507, Val Loss=1.5669, lr=0.0001
[2025-05-02 15:11:46,867][train][INFO] - Epoch 88/100, Val Acc=0.7287, Val Loss=1.3558, lr=0.0010
[2025-05-02 15:11:49,489][train][INFO] - Epoch 87/100, Val Acc=0.7279, Val Loss=1.3543, lr=0.0010
[2025-05-02 15:11:52,553][train][INFO] - Epoch 96/100, Val Acc=0.6505, Val Loss=1.5633, lr=0.0001
[2025-05-02 15:11:54,182][train][INFO] - Epoch 89/100, Val Acc=0.7277, Val Loss=1.3547, lr=0.0010
[2025-05-02 15:11:57,263][train][INFO] - Epoch 88/100, Val Acc=0.7286, Val Loss=1.3475, lr=0.0010
[2025-05-02 15:12:00,339][train][INFO] - Epoch 97/100, Val Acc=0.6537, Val Loss=1.5711, lr=0.0001
[2025-05-02 15:12:01,819][train][INFO] - Epoch 90/100, Val Acc=0.7279, Val Loss=1.3617, lr=0.0010
[2025-05-02 15:12:04,698][train][INFO] - Epoch 89/100, Val Acc=0.7266, Val Loss=1.3580, lr=0.0010
[2025-05-02 15:12:07,781][train][INFO] - Epoch 98/100, Val Acc=0.6531, Val Loss=1.5665, lr=0.0001
[2025-05-02 15:12:09,606][train][INFO] - Epoch 91/100, Val Acc=0.7277, Val Loss=1.3573, lr=0.0001
[2025-05-02 15:12:12,070][train][INFO] - Epoch 90/100, Val Acc=0.7279, Val Loss=1.3591, lr=0.0010
[2025-05-02 15:12:15,442][train][INFO] - Epoch 99/100, Val Acc=0.6530, Val Loss=1.5684, lr=0.0001
[2025-05-02 15:12:17,396][train][INFO] - Epoch 92/100, Val Acc=0.7278, Val Loss=1.3595, lr=0.0001
[2025-05-02 15:12:19,356][train][INFO] - Epoch 91/100, Val Acc=0.7291, Val Loss=1.3547, lr=0.0001
[2025-05-02 15:12:22,806][train][INFO] - Epoch 100/100, Val Acc=0.6511, Val Loss=1.5724, lr=0.0001
[2025-05-02 15:12:24,944][train][INFO] - Epoch 93/100, Val Acc=0.7280, Val Loss=1.3563, lr=0.0001
[2025-05-02 15:12:27,006][train][INFO] - Epoch 92/100, Val Acc=0.7264, Val Loss=1.3565, lr=0.0001
[2025-05-02 15:12:28,004][train][INFO] - After training : Train Acc=0.9294  Val Acc=0.6537
[2025-05-02 15:12:28,009][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 15:12:33,059][train][INFO] - Epoch 94/100, Val Acc=0.7265, Val Loss=1.3527, lr=0.0001
[2025-05-02 15:12:34,642][train][INFO] - Epoch 93/100, Val Acc=0.7279, Val Loss=1.3537, lr=0.0001
[2025-05-02 15:12:40,978][train][INFO] - Epoch 95/100, Val Acc=0.7280, Val Loss=1.3592, lr=0.0001
[2025-05-02 15:12:42,339][train][INFO] - Epoch 94/100, Val Acc=0.7271, Val Loss=1.3503, lr=0.0001
[2025-05-02 15:12:48,371][train][INFO] - Epoch 96/100, Val Acc=0.7278, Val Loss=1.3575, lr=0.0001
[2025-05-02 15:12:49,931][train][INFO] - Epoch 95/100, Val Acc=0.7275, Val Loss=1.3574, lr=0.0001
[2025-05-02 15:12:56,420][train][INFO] - Epoch 97/100, Val Acc=0.7281, Val Loss=1.3543, lr=0.0001
[2025-05-02 15:12:57,587][train][INFO] - Epoch 96/100, Val Acc=0.7271, Val Loss=1.3545, lr=0.0001
[2025-05-02 15:13:04,107][train][INFO] - Epoch 98/100, Val Acc=0.7266, Val Loss=1.3555, lr=0.0001
[2025-05-02 15:13:05,098][train][INFO] - Epoch 97/100, Val Acc=0.7278, Val Loss=1.3514, lr=0.0001
[2025-05-02 15:13:12,092][train][INFO] - Epoch 99/100, Val Acc=0.7280, Val Loss=1.3557, lr=0.0001
[2025-05-02 15:13:12,552][train][INFO] - Epoch 98/100, Val Acc=0.7270, Val Loss=1.3532, lr=0.0001
[2025-05-02 15:13:19,658][train][INFO] - Epoch 100/100, Val Acc=0.7283, Val Loss=1.3512, lr=0.0001
[2025-05-02 15:13:20,264][train][INFO] - Epoch 99/100, Val Acc=0.7265, Val Loss=1.3528, lr=0.0001
[2025-05-02 15:13:24,987][train][INFO] - After training : Train Acc=0.9987  Val Acc=0.7289
[2025-05-02 15:13:24,992][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 15:13:27,842][train][INFO] - Epoch 100/100, Val Acc=0.7301, Val Loss=1.3509, lr=0.0001
[2025-05-02 15:13:32,963][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.7301
[2025-05-02 15:13:32,968][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 15:13:46,781][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 15:14:45,154][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 15:14:49,058][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 15:16:05,998][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 15:16:06,476][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 15:16:10,842][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 15:16:11,313][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 15:16:14,678][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 15:16:15,104][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 15:51:15,207][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 15:51:15,259][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 15:51:15,259][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 15:51:15,259][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 15:51:25,425][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 100
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 15:51:25,518][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 15:51:25,518][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 15:51:25,518][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 15:52:04,581][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-02 15:52:04,631][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 15:52:04,632][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 15:52:04,632][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 15:52:34,665][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.4607, lr=0.001
[2025-05-02 15:53:04,208][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.1458, lr=0.001
[2025-05-02 15:53:32,686][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.0314, lr=0.001
[2025-05-02 15:54:00,574][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=3.8544, lr=0.001
[2025-05-02 15:54:29,111][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=3.1020, lr=0.001
[2025-05-02 15:54:56,820][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=1.6474, lr=0.001
[2025-05-02 15:55:25,138][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.3742, lr=0.001
[2025-05-02 15:55:52,396][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.1555, lr=0.001
[2025-05-02 15:55:52,434][meta_train][INFO] - epoch_1 saved !
[2025-05-02 15:56:20,665][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.9050, lr=0.001
[2025-05-02 15:56:49,587][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=1.3046, lr=0.001
[2025-05-02 15:57:14,898][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2675, lr=0.001
[2025-05-02 15:57:43,227][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.7373, lr=0.001
[2025-05-02 15:58:10,695][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.2503, lr=0.001
[2025-05-02 15:58:38,759][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0964, lr=0.001
[2025-05-02 15:59:06,750][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.1076, lr=0.001
[2025-05-02 15:59:34,952][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.3012, lr=0.001
[2025-05-02 15:59:34,993][meta_train][INFO] - epoch_2 saved !
[2025-05-02 16:00:03,412][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1181, lr=0.001
[2025-05-02 16:00:30,857][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.6351, lr=0.001
[2025-05-02 16:01:00,146][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.2543, lr=0.001
[2025-05-02 16:01:25,554][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.4597, lr=0.001
[2025-05-02 16:01:54,035][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.9475, lr=0.001
[2025-05-02 16:02:21,962][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.7869, lr=0.001
[2025-05-02 16:02:49,914][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=1.1619, lr=0.001
[2025-05-02 16:03:18,601][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.0314, lr=0.001
[2025-05-02 16:03:18,623][meta_train][INFO] - epoch_3 saved !
[2025-05-02 16:03:43,708][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.2556, lr=0.001
[2025-05-02 16:04:12,187][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=2.6427, lr=0.001
[2025-05-02 16:04:39,965][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=3.1537, lr=0.001
[2025-05-02 16:05:08,635][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=2.7230, lr=0.001
[2025-05-02 16:05:35,739][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=3.3904, lr=0.001
[2025-05-02 16:06:04,074][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=2.7695, lr=0.001
[2025-05-02 16:06:32,355][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=3.3043, lr=0.001
[2025-05-02 16:07:00,730][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=2.9793, lr=0.001
[2025-05-02 16:07:00,759][meta_train][INFO] - epoch_4 saved !
[2025-05-02 16:07:29,110][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=4.4179, lr=0.001
[2025-05-02 16:07:56,581][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=5.0779, lr=0.001
[2025-05-02 16:08:24,115][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=5.7876, lr=0.001
[2025-05-02 16:08:49,689][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=5.5440, lr=0.001
[2025-05-02 16:09:18,053][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.2800, lr=0.001
[2025-05-02 16:09:47,618][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=4.7156, lr=0.001
[2025-05-02 16:10:15,755][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9035, lr=0.001
[2025-05-02 16:10:44,561][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=5.1222, lr=0.001
[2025-05-02 16:10:44,583][meta_train][INFO] - epoch_5 saved !
[2025-05-02 16:11:12,999][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.5111, lr=0.0001
[2025-05-02 16:11:39,940][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=9.8943, lr=0.0001
[2025-05-02 16:12:07,975][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.9330, lr=0.0001
[2025-05-02 16:12:36,176][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.4086, lr=0.0001
[2025-05-02 16:13:01,167][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=6.6856, lr=0.0001
[2025-05-02 16:13:28,969][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=7.4841, lr=0.0001
[2025-05-02 16:13:57,438][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=5.1235, lr=0.0001
[2025-05-02 16:14:26,698][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=5.0866, lr=0.0001
[2025-05-02 16:14:26,719][meta_train][INFO] - epoch_6 saved !
[2025-05-02 16:14:54,467][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=5.4253, lr=0.0001
[2025-05-02 16:15:22,952][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=6.4800, lr=0.0001
[2025-05-02 16:15:51,861][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=5.0864, lr=0.0001
[2025-05-02 16:16:20,538][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.9200, lr=0.0001
[2025-05-02 16:16:48,513][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=5.0936, lr=0.0001
[2025-05-02 16:17:15,217][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=10.4239, lr=0.0001
[2025-05-02 16:17:40,402][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=6.8795, lr=0.0001
[2025-05-02 16:18:07,951][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=7.7977, lr=0.0001
[2025-05-02 16:18:07,981][meta_train][INFO] - epoch_7 saved !
[2025-05-02 16:18:33,740][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=6.9051, lr=0.0001
[2025-05-02 16:19:01,596][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=7.8292, lr=0.0001
[2025-05-02 16:19:30,187][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=5.0684, lr=0.0001
[2025-05-02 16:19:58,139][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=5.4787, lr=0.0001
[2025-05-02 16:20:27,113][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=5.0757, lr=0.0001
[2025-05-02 16:20:54,023][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=10.7392, lr=0.0001
[2025-05-02 16:21:22,165][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.8836, lr=0.0001
[2025-05-02 16:21:51,289][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=6.5203, lr=0.0001
[2025-05-02 16:21:51,315][meta_train][INFO] - epoch_8 saved !
[2025-05-02 16:22:18,484][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=10.7339, lr=0.0001
[2025-05-02 16:22:43,808][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=6.9835, lr=0.0001
[2025-05-02 16:23:12,648][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=5.1088, lr=0.0001
[2025-05-02 16:23:40,703][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.8900, lr=0.0001
[2025-05-02 16:24:09,439][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=5.5060, lr=0.0001
[2025-05-02 16:24:37,863][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=6.5205, lr=0.0001
[2025-05-02 16:25:05,697][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=8.0075, lr=0.0001
[2025-05-02 16:25:34,617][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=5.0517, lr=0.0001
[2025-05-02 16:25:34,647][meta_train][INFO] - epoch_9 saved !
[2025-05-02 16:26:01,599][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=10.9595, lr=0.0001
[2025-05-02 16:26:30,526][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=5.0805, lr=0.0001
[2025-05-02 16:26:58,699][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=5.0317, lr=0.0001
[2025-05-02 16:27:27,182][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=6.5267, lr=0.0001
[2025-05-02 16:27:52,500][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=7.1330, lr=0.0001
[2025-05-02 16:28:20,873][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.8474, lr=0.0001
[2025-05-02 16:28:49,405][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=8.2155, lr=0.0001
[2025-05-02 16:29:17,011][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=5.5486, lr=0.0001
[2025-05-02 16:29:17,028][meta_train][INFO] - epoch_10 saved !
[2025-05-02 16:29:42,949][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=7.1884, lr=0.0001
[2025-05-02 16:30:10,916][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=5.5544, lr=0.0001
[2025-05-02 16:30:39,973][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=5.0767, lr=0.0001
[2025-05-02 16:31:07,778][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=8.3184, lr=0.0001
[2025-05-02 16:31:36,405][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=6.5233, lr=0.0001
[2025-05-02 16:32:04,744][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.8290, lr=0.0001
[2025-05-02 16:32:33,177][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.9876, lr=0.0001
[2025-05-02 16:33:00,458][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=11.3326, lr=0.0001
[2025-05-02 16:33:00,486][meta_train][INFO] - epoch_11 saved !
[2025-05-02 16:33:25,839][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=7.2855, lr=0.0001
[2025-05-02 16:33:37,672][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-02 16:33:37,751][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 16:33:37,751][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 16:33:37,751][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 16:33:54,379][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 16:33:55,093][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=5.0664, lr=0.0001
[2025-05-02 16:34:02,713][train][INFO] - Epoch 1/100, Val Acc=0.5908, Val Loss=1.7380, lr=0.0100
[2025-05-02 16:34:10,436][train][INFO] - Epoch 2/100, Val Acc=0.5877, Val Loss=1.7753, lr=0.0100
[2025-05-02 16:34:18,593][train][INFO] - Epoch 3/100, Val Acc=0.6302, Val Loss=1.5736, lr=0.0100
[2025-05-02 16:34:23,351][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=8.4687, lr=0.0001
[2025-05-02 16:34:26,789][train][INFO] - Epoch 4/100, Val Acc=0.6402, Val Loss=1.5307, lr=0.0100
[2025-05-02 16:34:35,435][train][INFO] - Epoch 5/100, Val Acc=0.6478, Val Loss=1.5551, lr=0.0100
[2025-05-02 16:34:43,540][train][INFO] - Epoch 6/100, Val Acc=0.6536, Val Loss=1.4881, lr=0.0100
[2025-05-02 16:34:51,490][train][INFO] - Epoch 7/100, Val Acc=0.6437, Val Loss=1.5982, lr=0.0100
[2025-05-02 16:34:52,188][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=5.5885, lr=0.0001
[2025-05-02 16:34:59,628][train][INFO] - Epoch 8/100, Val Acc=0.6569, Val Loss=1.5151, lr=0.0100
[2025-05-02 16:35:07,984][train][INFO] - Epoch 9/100, Val Acc=0.6468, Val Loss=1.5903, lr=0.0100
[2025-05-02 16:35:15,898][train][INFO] - Epoch 10/100, Val Acc=0.6501, Val Loss=1.5467, lr=0.0100
[2025-05-02 16:35:20,782][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.8208, lr=0.0001
[2025-05-02 16:35:24,288][train][INFO] - Epoch 11/100, Val Acc=0.6369, Val Loss=1.6240, lr=0.0100
[2025-05-02 16:35:32,671][train][INFO] - Epoch 12/100, Val Acc=0.6544, Val Loss=1.5477, lr=0.0100
[2025-05-02 16:35:41,183][train][INFO] - Epoch 13/100, Val Acc=0.6452, Val Loss=1.5844, lr=0.0100
[2025-05-02 16:35:49,388][train][INFO] - Epoch 14/100, Val Acc=0.6497, Val Loss=1.6447, lr=0.0100
[2025-05-02 16:35:49,779][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.9736, lr=0.0001
[2025-05-02 16:35:58,141][train][INFO] - Epoch 15/100, Val Acc=0.6540, Val Loss=1.5651, lr=0.0100
[2025-05-02 16:36:06,222][train][INFO] - Epoch 16/100, Val Acc=0.6383, Val Loss=1.6248, lr=0.0100
[2025-05-02 16:36:13,504][train][INFO] - Epoch 17/100, Val Acc=0.6524, Val Loss=1.5779, lr=0.0100
[2025-05-02 16:36:18,271][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=6.5177, lr=0.0001
[2025-05-02 16:36:22,040][train][INFO] - Epoch 18/100, Val Acc=0.6567, Val Loss=1.6247, lr=0.0100
[2025-05-02 16:36:30,225][train][INFO] - Epoch 19/100, Val Acc=0.6512, Val Loss=1.6076, lr=0.0100
[2025-05-02 16:36:38,304][train][INFO] - Epoch 20/100, Val Acc=0.6623, Val Loss=1.5451, lr=0.0100
[2025-05-02 16:36:45,709][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=11.4757, lr=0.0001
[2025-05-02 16:36:45,726][meta_train][INFO] - epoch_12 saved !
[2025-05-02 16:36:46,644][train][INFO] - Epoch 21/100, Val Acc=0.6575, Val Loss=1.6028, lr=0.0100
[2025-05-02 16:36:54,820][train][INFO] - Epoch 22/100, Val Acc=0.6604, Val Loss=1.5442, lr=0.0100
[2025-05-02 16:37:02,163][train][INFO] - Epoch 23/100, Val Acc=0.6469, Val Loss=1.6872, lr=0.0100
[2025-05-02 16:37:09,849][train][INFO] - Epoch 24/100, Val Acc=0.6553, Val Loss=1.6051, lr=0.0100
[2025-05-02 16:37:11,340][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=7.3851, lr=0.0001
[2025-05-02 16:37:17,952][train][INFO] - Epoch 25/100, Val Acc=0.6586, Val Loss=1.6122, lr=0.0100
[2025-05-02 16:37:26,221][train][INFO] - Epoch 26/100, Val Acc=0.6633, Val Loss=1.5768, lr=0.0100
[2025-05-02 16:37:34,192][train][INFO] - Epoch 27/100, Val Acc=0.6449, Val Loss=1.6581, lr=0.0100
[2025-05-02 16:37:40,258][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=6.5153, lr=0.0001
[2025-05-02 16:37:42,087][train][INFO] - Epoch 28/100, Val Acc=0.6659, Val Loss=1.5631, lr=0.0100
[2025-05-02 16:37:50,358][train][INFO] - Epoch 29/100, Val Acc=0.6575, Val Loss=1.5756, lr=0.0100
[2025-05-02 16:37:58,699][train][INFO] - Epoch 30/100, Val Acc=0.6636, Val Loss=1.5988, lr=0.0100
[2025-05-02 16:38:06,918][train][INFO] - Epoch 31/100, Val Acc=0.6588, Val Loss=1.6083, lr=0.0100
[2025-05-02 16:38:07,878][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=11.5287, lr=0.0001
[2025-05-02 16:38:14,778][train][INFO] - Epoch 32/100, Val Acc=0.6558, Val Loss=1.6439, lr=0.0100
[2025-05-02 16:38:23,183][train][INFO] - Epoch 33/100, Val Acc=0.6631, Val Loss=1.5660, lr=0.0100
[2025-05-02 16:38:31,344][train][INFO] - Epoch 34/100, Val Acc=0.6502, Val Loss=1.6113, lr=0.0100
[2025-05-02 16:38:36,084][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.9551, lr=0.0001
[2025-05-02 16:38:38,935][train][INFO] - Epoch 35/100, Val Acc=0.6563, Val Loss=1.6251, lr=0.0100
[2025-05-02 16:38:47,493][train][INFO] - Epoch 36/100, Val Acc=0.6480, Val Loss=1.7021, lr=0.0100
[2025-05-02 16:38:55,327][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.6049, lr=0.0100
[2025-05-02 16:39:03,828][train][INFO] - Epoch 38/100, Val Acc=0.6637, Val Loss=1.5806, lr=0.0100
[2025-05-02 16:39:05,216][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=5.6229, lr=0.0001
[2025-05-02 16:39:11,958][train][INFO] - Epoch 39/100, Val Acc=0.6489, Val Loss=1.6526, lr=0.0100
[2025-05-02 16:39:20,130][train][INFO] - Epoch 40/100, Val Acc=0.6501, Val Loss=1.6547, lr=0.0100
[2025-05-02 16:39:28,290][train][INFO] - Epoch 41/100, Val Acc=0.6677, Val Loss=1.5612, lr=0.0100
[2025-05-02 16:39:33,109][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=8.7180, lr=0.0001
[2025-05-02 16:39:36,939][train][INFO] - Epoch 42/100, Val Acc=0.6617, Val Loss=1.6170, lr=0.0100
[2025-05-02 16:39:44,330][train][INFO] - Epoch 43/100, Val Acc=0.6331, Val Loss=1.7134, lr=0.0100
[2025-05-02 16:39:52,902][train][INFO] - Epoch 44/100, Val Acc=0.6536, Val Loss=1.6501, lr=0.0100
[2025-05-02 16:40:00,916][train][INFO] - Epoch 45/100, Val Acc=0.6590, Val Loss=1.6196, lr=0.0100
[2025-05-02 16:40:01,649][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.8073, lr=0.0001
[2025-05-02 16:40:09,095][train][INFO] - Epoch 46/100, Val Acc=0.6465, Val Loss=1.7018, lr=0.0100
[2025-05-02 16:40:16,628][train][INFO] - Epoch 47/100, Val Acc=0.6536, Val Loss=1.6523, lr=0.0100
[2025-05-02 16:40:23,811][train][INFO] - Epoch 48/100, Val Acc=0.6587, Val Loss=1.6277, lr=0.0100
[2025-05-02 16:40:30,906][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=5.0555, lr=0.0001
[2025-05-02 16:40:30,934][meta_train][INFO] - epoch_13 saved !
[2025-05-02 16:40:31,697][train][INFO] - Epoch 49/100, Val Acc=0.6568, Val Loss=1.6326, lr=0.0100
[2025-05-02 16:40:39,008][train][INFO] - Epoch 50/100, Val Acc=0.6613, Val Loss=1.5752, lr=0.0100
[2025-05-02 16:40:46,578][train][INFO] - Epoch 51/100, Val Acc=0.6645, Val Loss=1.6002, lr=0.0100
[2025-05-02 16:40:54,602][train][INFO] - Epoch 52/100, Val Acc=0.6382, Val Loss=1.7603, lr=0.0100
[2025-05-02 16:40:58,169][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=11.6173, lr=0.0001
[2025-05-02 16:41:02,217][train][INFO] - Epoch 53/100, Val Acc=0.6519, Val Loss=1.6552, lr=0.0100
[2025-05-02 16:41:10,162][train][INFO] - Epoch 54/100, Val Acc=0.6523, Val Loss=1.6146, lr=0.0100
[2025-05-02 16:41:18,575][train][INFO] - Epoch 55/100, Val Acc=0.6611, Val Loss=1.6201, lr=0.0100
[2025-05-02 16:41:26,468][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.9330, lr=0.0001
[2025-05-02 16:41:26,555][train][INFO] - Epoch 56/100, Val Acc=0.6550, Val Loss=1.6206, lr=0.0100
[2025-05-02 16:41:35,270][train][INFO] - Epoch 57/100, Val Acc=0.6563, Val Loss=1.6383, lr=0.0100
[2025-05-02 16:41:43,189][train][INFO] - Epoch 58/100, Val Acc=0.6495, Val Loss=1.6862, lr=0.0100
[2025-05-02 16:41:51,420][train][INFO] - Epoch 59/100, Val Acc=0.6406, Val Loss=1.7080, lr=0.0100
[2025-05-02 16:41:54,835][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=5.6447, lr=0.0001
[2025-05-02 16:41:59,411][train][INFO] - Epoch 60/100, Val Acc=0.6542, Val Loss=1.6282, lr=0.0100
[2025-05-02 16:42:07,379][train][INFO] - Epoch 61/100, Val Acc=0.7136, Val Loss=1.3330, lr=0.0010
[2025-05-02 16:42:15,874][train][INFO] - Epoch 62/100, Val Acc=0.7180, Val Loss=1.3326, lr=0.0010
[2025-05-02 16:42:23,599][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.8019, lr=0.0001
[2025-05-02 16:42:23,902][train][INFO] - Epoch 63/100, Val Acc=0.7172, Val Loss=1.3385, lr=0.0010
[2025-05-02 16:42:32,185][train][INFO] - Epoch 64/100, Val Acc=0.7222, Val Loss=1.3368, lr=0.0010
[2025-05-02 16:42:39,604][train][INFO] - Epoch 65/100, Val Acc=0.7201, Val Loss=1.3456, lr=0.0010
[2025-05-02 16:42:47,852][train][INFO] - Epoch 66/100, Val Acc=0.7191, Val Loss=1.3601, lr=0.0010
[2025-05-02 16:42:52,645][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=6.5073, lr=0.0001
[2025-05-02 16:42:55,531][train][INFO] - Epoch 67/100, Val Acc=0.7211, Val Loss=1.3567, lr=0.0010
[2025-05-02 16:43:03,025][train][INFO] - Epoch 68/100, Val Acc=0.7211, Val Loss=1.3554, lr=0.0010
[2025-05-02 16:43:10,678][train][INFO] - Epoch 69/100, Val Acc=0.7236, Val Loss=1.3615, lr=0.0010
[2025-05-02 16:43:18,725][train][INFO] - Epoch 70/100, Val Acc=0.7235, Val Loss=1.3642, lr=0.0010
[2025-05-02 16:43:20,567][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=8.8772, lr=0.0001
[2025-05-02 16:43:26,272][train][INFO] - Epoch 71/100, Val Acc=0.7234, Val Loss=1.3688, lr=0.0010
[2025-05-02 16:43:34,159][train][INFO] - Epoch 72/100, Val Acc=0.7257, Val Loss=1.3688, lr=0.0010
[2025-05-02 16:43:42,115][train][INFO] - Epoch 73/100, Val Acc=0.7239, Val Loss=1.3677, lr=0.0010
[2025-05-02 16:43:46,794][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=7.5875, lr=0.0001
[2025-05-02 16:43:50,011][train][INFO] - Epoch 74/100, Val Acc=0.7259, Val Loss=1.3652, lr=0.0010
[2025-05-02 16:43:56,647][train][INFO] - Epoch 75/100, Val Acc=0.7250, Val Loss=1.3649, lr=0.0010
[2025-05-02 16:44:04,614][train][INFO] - Epoch 76/100, Val Acc=0.7254, Val Loss=1.3649, lr=0.0010
[2025-05-02 16:44:12,940][train][INFO] - Epoch 77/100, Val Acc=0.7248, Val Loss=1.3644, lr=0.0010
[2025-05-02 16:44:15,835][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=5.0549, lr=0.0001
[2025-05-02 16:44:15,861][meta_train][INFO] - epoch_14 saved !
[2025-05-02 16:44:20,440][train][INFO] - Epoch 78/100, Val Acc=0.7230, Val Loss=1.3711, lr=0.0010
[2025-05-02 16:44:28,196][train][INFO] - Epoch 79/100, Val Acc=0.7241, Val Loss=1.3771, lr=0.0010
[2025-05-02 16:44:35,969][train][INFO] - Epoch 80/100, Val Acc=0.7243, Val Loss=1.3744, lr=0.0010
[2025-05-02 16:44:44,332][train][INFO] - Epoch 81/100, Val Acc=0.7244, Val Loss=1.3769, lr=0.0010
[2025-05-02 16:44:45,363][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=6.5038, lr=0.0001
[2025-05-02 16:44:52,630][train][INFO] - Epoch 82/100, Val Acc=0.7238, Val Loss=1.3755, lr=0.0010
[2025-05-02 16:45:00,885][train][INFO] - Epoch 83/100, Val Acc=0.7248, Val Loss=1.3792, lr=0.0010
[2025-05-02 16:45:09,535][train][INFO] - Epoch 84/100, Val Acc=0.7237, Val Loss=1.3777, lr=0.0010
[2025-05-02 16:45:13,548][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.7974, lr=0.0001
[2025-05-02 16:45:17,196][train][INFO] - Epoch 85/100, Val Acc=0.7265, Val Loss=1.3731, lr=0.0010
[2025-05-02 16:45:24,340][train][INFO] - Epoch 86/100, Val Acc=0.7247, Val Loss=1.3744, lr=0.0010
[2025-05-02 16:45:32,567][train][INFO] - Epoch 87/100, Val Acc=0.7263, Val Loss=1.3737, lr=0.0010
[2025-05-02 16:45:39,105][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=7.6389, lr=0.0001
[2025-05-02 16:45:40,574][train][INFO] - Epoch 88/100, Val Acc=0.7248, Val Loss=1.3719, lr=0.0010
[2025-05-02 16:45:48,251][train][INFO] - Epoch 89/100, Val Acc=0.7258, Val Loss=1.3689, lr=0.0010
[2025-05-02 16:45:56,285][train][INFO] - Epoch 90/100, Val Acc=0.7260, Val Loss=1.3761, lr=0.0010
[2025-05-02 16:46:03,938][train][INFO] - Epoch 91/100, Val Acc=0.7249, Val Loss=1.3727, lr=0.0001
[2025-05-02 16:46:07,617][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=5.6800, lr=0.0001
[2025-05-02 16:46:11,745][train][INFO] - Epoch 92/100, Val Acc=0.7258, Val Loss=1.3771, lr=0.0001
[2025-05-02 16:46:19,031][train][INFO] - Epoch 93/100, Val Acc=0.7270, Val Loss=1.3697, lr=0.0001
[2025-05-02 16:46:27,435][train][INFO] - Epoch 94/100, Val Acc=0.7250, Val Loss=1.3682, lr=0.0001
[2025-05-02 16:46:35,267][train][INFO] - Epoch 95/100, Val Acc=0.7270, Val Loss=1.3717, lr=0.0001
[2025-05-02 16:46:36,483][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=9.0207, lr=0.0001
[2025-05-02 16:46:43,043][train][INFO] - Epoch 96/100, Val Acc=0.7276, Val Loss=1.3674, lr=0.0001
[2025-05-02 16:46:50,797][train][INFO] - Epoch 97/100, Val Acc=0.7264, Val Loss=1.3639, lr=0.0001
[2025-05-02 16:46:58,478][train][INFO] - Epoch 98/100, Val Acc=0.7256, Val Loss=1.3685, lr=0.0001
[2025-05-02 16:47:05,225][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.9036, lr=0.0001
[2025-05-02 16:47:06,316][train][INFO] - Epoch 99/100, Val Acc=0.7287, Val Loss=1.3654, lr=0.0001
[2025-05-02 16:47:14,309][train][INFO] - Epoch 100/100, Val Acc=0.7262, Val Loss=1.3627, lr=0.0001
[2025-05-02 16:47:19,204][train][INFO] - After training : Train Acc=0.9991  Val Acc=0.7287
[2025-05-02 16:47:19,213][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 16:47:32,528][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=11.7998, lr=0.0001
[2025-05-02 16:48:02,364][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=5.0455, lr=0.0001
[2025-05-02 16:48:02,394][meta_train][INFO] - epoch_15 saved !
[2025-05-02 16:48:29,075][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 16:48:31,063][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=6.4975, lr=0.0001
[2025-05-02 16:49:00,349][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.8933, lr=0.0001
[2025-05-02 16:49:28,590][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=11.8522, lr=0.0001
[2025-05-02 16:49:39,910][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 16:49:40,377][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 16:49:58,144][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=5.0403, lr=0.0001
[2025-05-02 16:50:23,254][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=7.7739, lr=0.0001
[2025-05-02 16:50:51,421][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=5.7183, lr=0.0001
[2025-05-02 16:51:19,415][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=9.2048, lr=0.0001
[2025-05-02 16:51:47,506][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.7870, lr=0.0001
[2025-05-02 16:51:47,523][meta_train][INFO] - epoch_16 saved !
[2025-05-02 16:52:15,508][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=6.4871, lr=0.0001
[2025-05-02 16:52:43,935][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=5.7316, lr=0.0001
[2025-05-02 16:53:11,865][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.7838, lr=0.0001
[2025-05-02 16:53:37,015][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=7.8652, lr=0.0001
[2025-05-02 16:54:05,033][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=9.3105, lr=0.0001
[2025-05-02 16:54:33,416][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.8639, lr=0.0001
[2025-05-02 16:55:00,197][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=11.9591, lr=0.0001
[2025-05-02 16:55:29,301][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=5.0300, lr=0.0001
[2025-05-02 16:55:29,318][meta_train][INFO] - epoch_17 saved !
[2025-05-02 16:55:58,070][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=5.0285, lr=0.0001
[2025-05-02 16:56:25,548][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=5.7606, lr=0.0001
[2025-05-02 16:56:54,145][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.8519, lr=0.0001
[2025-05-02 16:57:22,499][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=6.4777, lr=0.0001
[2025-05-02 16:57:49,615][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=12.0008, lr=0.0001
[2025-05-02 16:58:17,366][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.7770, lr=0.0001
[2025-05-02 16:58:45,698][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=9.4690, lr=0.0001
[2025-05-02 16:59:10,908][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=8.0103, lr=0.0001
[2025-05-02 16:59:10,925][meta_train][INFO] - epoch_18 saved !
[2025-05-02 16:59:39,963][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=5.0222, lr=0.0001
[2025-05-02 17:00:07,979][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=6.4730, lr=0.0001
[2025-05-02 17:00:33,619][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=8.0346, lr=0.0001
[2025-05-02 17:01:01,934][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.7759, lr=0.0001
[2025-05-02 17:01:29,601][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=5.7958, lr=0.0001
[2025-05-02 17:01:56,788][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=12.0483, lr=0.0001
[2025-05-02 17:02:24,746][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.8268, lr=0.0001
[2025-05-02 17:02:52,754][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=9.5827, lr=0.0001
[2025-05-02 17:02:52,779][meta_train][INFO] - epoch_19 saved !
[2025-05-02 17:03:19,897][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=12.0635, lr=0.0001
[2025-05-02 17:03:47,993][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=9.6083, lr=0.0001
[2025-05-02 17:04:16,198][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=6.4642, lr=0.0001
[2025-05-02 17:04:45,214][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=5.0070, lr=0.0001
[2025-05-02 17:05:13,934][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.7725, lr=0.0001
[2025-05-02 17:05:42,280][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=5.8211, lr=0.0001
[2025-05-02 17:06:07,175][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=8.1484, lr=0.0001
[2025-05-02 17:06:35,387][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.8134, lr=0.0001
[2025-05-02 17:06:35,415][meta_train][INFO] - epoch_20 saved !
[2025-05-02 17:07:01,288][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=8.1692, lr=0.0001
[2025-05-02 17:07:30,599][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.9993, lr=0.0001
[2025-05-02 17:07:58,128][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=9.6991, lr=0.0001
[2025-05-02 17:08:26,676][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=5.8394, lr=0.0001
[2025-05-02 17:08:53,602][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=12.0935, lr=0.0001
[2025-05-02 17:09:21,743][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.7691, lr=0.0001
[2025-05-02 17:09:50,473][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=6.4479, lr=0.0001
[2025-05-02 17:10:18,967][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.7968, lr=0.0001
[2025-05-02 17:10:18,985][meta_train][INFO] - epoch_21 saved !
[2025-05-02 17:10:46,953][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.7957, lr=0.0001
[2025-05-02 17:11:14,962][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=9.7488, lr=0.0001
[2025-05-02 17:11:42,909][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=6.4396, lr=0.0001
[2025-05-02 17:12:11,121][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=5.8571, lr=0.0001
[2025-05-02 17:12:39,059][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.7675, lr=0.0001
[2025-05-02 17:13:04,645][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=8.2751, lr=0.0001
[2025-05-02 17:13:33,378][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.9791, lr=0.0001
[2025-05-02 17:14:00,394][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=12.1466, lr=0.0001
[2025-05-02 17:14:00,436][meta_train][INFO] - epoch_22 saved !
[2025-05-02 17:14:28,826][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=5.8721, lr=0.0001
[2025-05-02 17:14:56,320][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=9.8148, lr=0.0001
[2025-05-02 17:15:23,229][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=12.1523, lr=0.0001
[2025-05-02 17:15:51,302][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.7775, lr=0.0001
[2025-05-02 17:16:19,206][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.7649, lr=0.0001
[2025-05-02 17:16:48,216][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.9680, lr=0.0001
[2025-05-02 17:17:16,164][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=6.4192, lr=0.0001
[2025-05-02 17:17:41,698][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=8.3350, lr=0.0001
[2025-05-02 17:17:41,714][meta_train][INFO] - epoch_23 saved !
[2025-05-02 17:18:10,110][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=6.4158, lr=0.0001
[2025-05-02 17:18:38,045][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.7634, lr=0.0001
[2025-05-02 17:19:05,987][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.7687, lr=0.0001
[2025-05-02 17:19:32,672][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=12.1731, lr=0.0001
[2025-05-02 17:20:01,816][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.9566, lr=0.0001
[2025-05-02 17:20:23,236][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-02 17:20:23,286][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 17:20:23,286][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 17:20:23,286][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 17:20:29,922][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=5.8962, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 17:20:39,843][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 17:20:48,134][train][INFO] - Epoch 1/100, Val Acc=0.5538, Val Loss=1.7850, lr=0.0100
[2025-05-02 17:20:55,044][train][INFO] - Epoch 2/100, Val Acc=0.5999, Val Loss=1.5652, lr=0.0100
[2025-05-02 17:20:56,146][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=8.3868, lr=0.0001
[2025-05-02 17:21:03,471][train][INFO] - Epoch 3/100, Val Acc=0.5973, Val Loss=1.6460, lr=0.0100
[2025-05-02 17:21:11,649][train][INFO] - Epoch 4/100, Val Acc=0.6287, Val Loss=1.5020, lr=0.0100
[2025-05-02 17:21:19,080][train][INFO] - Epoch 5/100, Val Acc=0.6402, Val Loss=1.4841, lr=0.0100
[2025-05-02 17:21:24,261][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=9.8875, lr=0.0001
[2025-05-02 17:21:24,293][meta_train][INFO] - epoch_24 saved !
[2025-05-02 17:21:27,902][train][INFO] - Epoch 6/100, Val Acc=0.6348, Val Loss=1.5308, lr=0.0100
[2025-05-02 17:21:35,465][train][INFO] - Epoch 7/100, Val Acc=0.6280, Val Loss=1.5957, lr=0.0100
[2025-05-02 17:21:43,911][train][INFO] - Epoch 8/100, Val Acc=0.6526, Val Loss=1.4590, lr=0.0100
[2025-05-02 17:21:52,228][train][INFO] - Epoch 9/100, Val Acc=0.6588, Val Loss=1.4421, lr=0.0100
[2025-05-02 17:21:52,986][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=6.4009, lr=0.0001
[2025-05-02 17:22:00,448][train][INFO] - Epoch 10/100, Val Acc=0.6603, Val Loss=1.4137, lr=0.0100
[2025-05-02 17:22:08,639][train][INFO] - Epoch 11/100, Val Acc=0.6434, Val Loss=1.5378, lr=0.0100
[2025-05-02 17:22:16,786][train][INFO] - Epoch 12/100, Val Acc=0.6506, Val Loss=1.5009, lr=0.0100
[2025-05-02 17:22:21,424][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=9.8954, lr=0.0001
[2025-05-02 17:22:25,037][train][INFO] - Epoch 13/100, Val Acc=0.6430, Val Loss=1.5503, lr=0.0100
[2025-05-02 17:22:33,381][train][INFO] - Epoch 14/100, Val Acc=0.6509, Val Loss=1.5488, lr=0.0100
[2025-05-02 17:22:41,509][train][INFO] - Epoch 15/100, Val Acc=0.6423, Val Loss=1.5919, lr=0.0100
[2025-05-02 17:22:47,361][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=8.4006, lr=0.0001
[2025-05-02 17:22:49,798][train][INFO] - Epoch 16/100, Val Acc=0.6697, Val Loss=1.4083, lr=0.0100
[2025-05-02 17:22:58,470][train][INFO] - Epoch 17/100, Val Acc=0.6508, Val Loss=1.5499, lr=0.0100
[2025-05-02 17:23:06,390][train][INFO] - Epoch 18/100, Val Acc=0.6553, Val Loss=1.5568, lr=0.0100
[2025-05-02 17:23:13,998][train][INFO] - Epoch 19/100, Val Acc=0.6572, Val Loss=1.5301, lr=0.0100
[2025-05-02 17:23:16,838][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.9493, lr=0.0001
[2025-05-02 17:23:21,796][train][INFO] - Epoch 20/100, Val Acc=0.6554, Val Loss=1.5334, lr=0.0100
[2025-05-02 17:23:29,963][train][INFO] - Epoch 21/100, Val Acc=0.6393, Val Loss=1.6601, lr=0.0100
[2025-05-02 17:23:38,309][train][INFO] - Epoch 22/100, Val Acc=0.6549, Val Loss=1.5680, lr=0.0100
[2025-05-02 17:23:45,456][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7597, lr=0.0001
[2025-05-02 17:23:46,606][train][INFO] - Epoch 23/100, Val Acc=0.6466, Val Loss=1.6353, lr=0.0100
[2025-05-02 17:23:55,020][train][INFO] - Epoch 24/100, Val Acc=0.6592, Val Loss=1.5406, lr=0.0100
[2025-05-02 17:24:02,909][train][INFO] - Epoch 25/100, Val Acc=0.6592, Val Loss=1.5483, lr=0.0100
[2025-05-02 17:24:10,598][train][INFO] - Epoch 26/100, Val Acc=0.6478, Val Loss=1.6431, lr=0.0100
[2025-05-02 17:24:14,360][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.7560, lr=0.0001
[2025-05-02 17:24:19,612][train][INFO] - Epoch 27/100, Val Acc=0.6425, Val Loss=1.6816, lr=0.0100
[2025-05-02 17:24:28,381][train][INFO] - Epoch 28/100, Val Acc=0.6412, Val Loss=1.7054, lr=0.0100
[2025-05-02 17:24:37,343][train][INFO] - Epoch 29/100, Val Acc=0.6545, Val Loss=1.6003, lr=0.0100
[2025-05-02 17:24:42,795][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=5.9093, lr=0.0001
[2025-05-02 17:24:46,051][train][INFO] - Epoch 30/100, Val Acc=0.6621, Val Loss=1.5853, lr=0.0100
[2025-05-02 17:24:53,596][train][INFO] - Epoch 31/100, Val Acc=0.6409, Val Loss=1.6786, lr=0.0100
[2025-05-02 17:25:01,588][train][INFO] - Epoch 32/100, Val Acc=0.6530, Val Loss=1.5928, lr=0.0100
[2025-05-02 17:25:09,551][train][INFO] - Epoch 33/100, Val Acc=0.6616, Val Loss=1.5435, lr=0.0100
[2025-05-02 17:25:10,165][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=12.2246, lr=0.0001
[2025-05-02 17:25:10,183][meta_train][INFO] - epoch_25 saved !
[2025-05-02 17:25:18,198][train][INFO] - Epoch 34/100, Val Acc=0.6641, Val Loss=1.5669, lr=0.0100
[2025-05-02 17:25:26,342][train][INFO] - Epoch 35/100, Val Acc=0.6590, Val Loss=1.5844, lr=0.0100
[2025-05-02 17:25:34,293][train][INFO] - Epoch 36/100, Val Acc=0.6597, Val Loss=1.5967, lr=0.0100
[2025-05-02 17:25:38,706][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.7582, lr=0.0001
[2025-05-02 17:25:42,328][train][INFO] - Epoch 37/100, Val Acc=0.6670, Val Loss=1.5394, lr=0.0100
[2025-05-02 17:25:50,684][train][INFO] - Epoch 38/100, Val Acc=0.6614, Val Loss=1.5755, lr=0.0100
[2025-05-02 17:25:58,872][train][INFO] - Epoch 39/100, Val Acc=0.6549, Val Loss=1.6364, lr=0.0100
[2025-05-02 17:26:06,957][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.7478, lr=0.0001
[2025-05-02 17:26:07,534][train][INFO] - Epoch 40/100, Val Acc=0.6550, Val Loss=1.6193, lr=0.0100
[2025-05-02 17:26:15,955][train][INFO] - Epoch 41/100, Val Acc=0.6634, Val Loss=1.5430, lr=0.0100
[2025-05-02 17:26:24,432][train][INFO] - Epoch 42/100, Val Acc=0.6581, Val Loss=1.6178, lr=0.0100
[2025-05-02 17:26:32,674][train][INFO] - Epoch 43/100, Val Acc=0.6494, Val Loss=1.6483, lr=0.0100
[2025-05-02 17:26:32,911][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=8.4376, lr=0.0001
[2025-05-02 17:26:40,201][train][INFO] - Epoch 44/100, Val Acc=0.6532, Val Loss=1.6359, lr=0.0100
[2025-05-02 17:26:48,104][train][INFO] - Epoch 45/100, Val Acc=0.6438, Val Loss=1.7025, lr=0.0100
[2025-05-02 17:26:56,366][train][INFO] - Epoch 46/100, Val Acc=0.6553, Val Loss=1.6076, lr=0.0100
[2025-05-02 17:27:01,812][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=6.3733, lr=0.0001
[2025-05-02 17:27:03,602][train][INFO] - Epoch 47/100, Val Acc=0.6505, Val Loss=1.6670, lr=0.0100
[2025-05-02 17:27:11,623][train][INFO] - Epoch 48/100, Val Acc=0.6587, Val Loss=1.6077, lr=0.0100
[2025-05-02 17:27:20,433][train][INFO] - Epoch 49/100, Val Acc=0.6487, Val Loss=1.6842, lr=0.0100
[2025-05-02 17:27:29,123][train][INFO] - Epoch 50/100, Val Acc=0.6708, Val Loss=1.5699, lr=0.0100
[2025-05-02 17:27:30,670][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.9333, lr=0.0001
[2025-05-02 17:27:38,236][train][INFO] - Epoch 51/100, Val Acc=0.6631, Val Loss=1.5860, lr=0.0100
[2025-05-02 17:27:46,568][train][INFO] - Epoch 52/100, Val Acc=0.6494, Val Loss=1.7084, lr=0.0100
[2025-05-02 17:27:54,842][train][INFO] - Epoch 53/100, Val Acc=0.6706, Val Loss=1.5407, lr=0.0100
[2025-05-02 17:27:58,788][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=9.9227, lr=0.0001
[2025-05-02 17:28:02,862][train][INFO] - Epoch 54/100, Val Acc=0.6501, Val Loss=1.6259, lr=0.0100
[2025-05-02 17:28:11,268][train][INFO] - Epoch 55/100, Val Acc=0.6601, Val Loss=1.6018, lr=0.0100
[2025-05-02 17:28:19,569][train][INFO] - Epoch 56/100, Val Acc=0.6584, Val Loss=1.6117, lr=0.0100
[2025-05-02 17:28:26,122][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=12.2506, lr=0.0001
[2025-05-02 17:28:28,448][train][INFO] - Epoch 57/100, Val Acc=0.6604, Val Loss=1.5953, lr=0.0100
[2025-05-02 17:28:36,225][train][INFO] - Epoch 58/100, Val Acc=0.6623, Val Loss=1.5964, lr=0.0100
[2025-05-02 17:28:43,168][train][INFO] - Epoch 59/100, Val Acc=0.6452, Val Loss=1.6992, lr=0.0100
[2025-05-02 17:28:50,405][train][INFO] - Epoch 60/100, Val Acc=0.6565, Val Loss=1.6356, lr=0.0100
[2025-05-02 17:28:55,102][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=5.9214, lr=0.0001
[2025-05-02 17:28:55,130][meta_train][INFO] - epoch_26 saved !
[2025-05-02 17:28:58,810][train][INFO] - Epoch 61/100, Val Acc=0.7114, Val Loss=1.3316, lr=0.0010
[2025-05-02 17:29:07,049][train][INFO] - Epoch 62/100, Val Acc=0.7166, Val Loss=1.3241, lr=0.0010
[2025-05-02 17:29:15,698][train][INFO] - Epoch 63/100, Val Acc=0.7186, Val Loss=1.3365, lr=0.0010
[2025-05-02 17:29:23,532][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=5.9229, lr=0.0001
[2025-05-02 17:29:23,586][train][INFO] - Epoch 64/100, Val Acc=0.7187, Val Loss=1.3389, lr=0.0010
[2025-05-02 17:29:31,622][train][INFO] - Epoch 65/100, Val Acc=0.7186, Val Loss=1.3492, lr=0.0010
[2025-05-02 17:29:39,505][train][INFO] - Epoch 66/100, Val Acc=0.7192, Val Loss=1.3536, lr=0.0010
[2025-05-02 17:29:47,842][train][INFO] - Epoch 67/100, Val Acc=0.7210, Val Loss=1.3579, lr=0.0010
[2025-05-02 17:29:51,599][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.7370, lr=0.0001
[2025-05-02 17:29:56,208][train][INFO] - Epoch 68/100, Val Acc=0.7188, Val Loss=1.3574, lr=0.0010
[2025-05-02 17:30:04,763][train][INFO] - Epoch 69/100, Val Acc=0.7199, Val Loss=1.3638, lr=0.0010
[2025-05-02 17:30:13,629][train][INFO] - Epoch 70/100, Val Acc=0.7198, Val Loss=1.3720, lr=0.0010
[2025-05-02 17:30:20,872][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.9162, lr=0.0001
[2025-05-02 17:30:22,441][train][INFO] - Epoch 71/100, Val Acc=0.7177, Val Loss=1.3758, lr=0.0010
[2025-05-02 17:30:30,602][train][INFO] - Epoch 72/100, Val Acc=0.7220, Val Loss=1.3735, lr=0.0010
[2025-05-02 17:30:38,653][train][INFO] - Epoch 73/100, Val Acc=0.7197, Val Loss=1.3639, lr=0.0010
[2025-05-02 17:30:46,865][train][INFO] - Epoch 74/100, Val Acc=0.7232, Val Loss=1.3705, lr=0.0010
[2025-05-02 17:30:46,868][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=8.4674, lr=0.0001
[2025-05-02 17:30:55,482][train][INFO] - Epoch 75/100, Val Acc=0.7228, Val Loss=1.3694, lr=0.0010
[2025-05-02 17:31:04,205][train][INFO] - Epoch 76/100, Val Acc=0.7240, Val Loss=1.3721, lr=0.0010
[2025-05-02 17:31:12,761][train][INFO] - Epoch 77/100, Val Acc=0.7229, Val Loss=1.3715, lr=0.0010
[2025-05-02 17:31:16,041][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.7541, lr=0.0001
[2025-05-02 17:31:20,813][train][INFO] - Epoch 78/100, Val Acc=0.7240, Val Loss=1.3697, lr=0.0010
[2025-05-02 17:31:29,084][train][INFO] - Epoch 79/100, Val Acc=0.7237, Val Loss=1.3745, lr=0.0010
[2025-05-02 17:31:36,776][train][INFO] - Epoch 80/100, Val Acc=0.7227, Val Loss=1.3748, lr=0.0010
[2025-05-02 17:31:43,533][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=9.9379, lr=0.0001
[2025-05-02 17:31:44,008][train][INFO] - Epoch 81/100, Val Acc=0.7236, Val Loss=1.3776, lr=0.0010
[2025-05-02 17:31:51,866][train][INFO] - Epoch 82/100, Val Acc=0.7260, Val Loss=1.3701, lr=0.0010
[2025-05-02 17:32:00,439][train][INFO] - Epoch 83/100, Val Acc=0.7242, Val Loss=1.3789, lr=0.0010
[2025-05-02 17:32:08,809][train][INFO] - Epoch 84/100, Val Acc=0.7254, Val Loss=1.3804, lr=0.0010
[2025-05-02 17:32:11,467][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=12.2551, lr=0.0001
[2025-05-02 17:32:17,456][train][INFO] - Epoch 85/100, Val Acc=0.7244, Val Loss=1.3768, lr=0.0010
[2025-05-02 17:32:25,634][train][INFO] - Epoch 86/100, Val Acc=0.7270, Val Loss=1.3792, lr=0.0010
[2025-05-02 17:32:34,289][train][INFO] - Epoch 87/100, Val Acc=0.7259, Val Loss=1.3763, lr=0.0010
[2025-05-02 17:32:40,522][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=6.3465, lr=0.0001
[2025-05-02 17:32:40,539][meta_train][INFO] - epoch_27 saved !
[2025-05-02 17:32:42,456][train][INFO] - Epoch 88/100, Val Acc=0.7242, Val Loss=1.3744, lr=0.0010
[2025-05-02 17:32:50,958][train][INFO] - Epoch 89/100, Val Acc=0.7241, Val Loss=1.3705, lr=0.0010
[2025-05-02 17:32:59,059][train][INFO] - Epoch 90/100, Val Acc=0.7253, Val Loss=1.3733, lr=0.0010
[2025-05-02 17:33:07,657][train][INFO] - Epoch 91/100, Val Acc=0.7259, Val Loss=1.3710, lr=0.0001
[2025-05-02 17:33:08,879][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.7303, lr=0.0001
[2025-05-02 17:33:15,297][train][INFO] - Epoch 92/100, Val Acc=0.7253, Val Loss=1.3763, lr=0.0001
[2025-05-02 17:33:22,973][train][INFO] - Epoch 93/100, Val Acc=0.7268, Val Loss=1.3715, lr=0.0001
[2025-05-02 17:33:31,246][train][INFO] - Epoch 94/100, Val Acc=0.7263, Val Loss=1.3676, lr=0.0001
[2025-05-02 17:33:36,886][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=9.9317, lr=0.0001
[2025-05-02 17:33:39,368][train][INFO] - Epoch 95/100, Val Acc=0.7259, Val Loss=1.3716, lr=0.0001
[2025-05-02 17:33:47,028][train][INFO] - Epoch 96/100, Val Acc=0.7267, Val Loss=1.3711, lr=0.0001
[2025-05-02 17:33:55,612][train][INFO] - Epoch 97/100, Val Acc=0.7259, Val Loss=1.3691, lr=0.0001
[2025-05-02 17:34:02,682][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=8.4943, lr=0.0001
[2025-05-02 17:34:03,640][train][INFO] - Epoch 98/100, Val Acc=0.7259, Val Loss=1.3707, lr=0.0001
[2025-05-02 17:34:11,926][train][INFO] - Epoch 99/100, Val Acc=0.7245, Val Loss=1.3714, lr=0.0001
[2025-05-02 17:34:20,265][train][INFO] - Epoch 100/100, Val Acc=0.7276, Val Loss=1.3681, lr=0.0001
[2025-05-02 17:34:25,337][train][INFO] - After training : Train Acc=0.9988  Val Acc=0.7276
[2025-05-02 17:34:25,342][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 17:34:32,274][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.9046, lr=0.0001
[2025-05-02 17:35:00,938][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=5.9303, lr=0.0001
[2025-05-02 17:35:29,807][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=6.3259, lr=0.0001
[2025-05-02 17:35:43,772][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 17:35:57,175][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=12.2485, lr=0.0001
[2025-05-02 17:36:26,481][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7495, lr=0.0001
[2025-05-02 17:36:26,498][meta_train][INFO] - epoch_28 saved !
[2025-05-02 17:36:56,082][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.8939, lr=0.0001
[2025-05-02 17:37:00,266][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 17:37:00,699][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 17:37:24,574][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=5.9376, lr=0.0001
[2025-05-02 17:37:49,773][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=8.5129, lr=0.0001
[2025-05-02 17:38:17,852][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.7220, lr=0.0001
[2025-05-02 17:38:45,905][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=9.9394, lr=0.0001
[2025-05-02 17:39:14,521][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.7473, lr=0.0001
[2025-05-02 17:39:40,819][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=12.2249, lr=0.0001
[2025-05-02 17:40:09,668][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=6.3005, lr=0.0001
[2025-05-02 17:40:09,699][meta_train][INFO] - epoch_29 saved !
[2025-05-02 17:40:37,909][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.7151, lr=0.0001
[2025-05-02 17:41:05,891][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7456, lr=0.0001
[2025-05-02 17:41:33,240][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=9.9324, lr=0.0001
[2025-05-02 17:42:01,474][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=6.2878, lr=0.0001
[2025-05-02 17:42:27,881][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=12.1888, lr=0.0001
[2025-05-02 17:42:53,282][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=8.5358, lr=0.0001
[2025-05-02 17:43:20,907][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=5.9459, lr=0.0001
[2025-05-02 17:43:50,040][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.8730, lr=0.0001
[2025-05-02 17:43:50,057][meta_train][INFO] - epoch_30 saved !
[2025-05-02 17:44:18,559][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=5.9481, lr=0.0001
[2025-05-02 17:44:46,530][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.7090, lr=0.0001
[2025-05-02 17:45:14,197][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=9.9148, lr=0.0001
[2025-05-02 17:45:40,872][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=12.1326, lr=0.0001
[2025-05-02 17:46:10,134][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.8702, lr=0.0001
[2025-05-02 17:46:37,989][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.7408, lr=0.0001
[2025-05-02 17:47:06,323][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=6.2573, lr=0.0001
[2025-05-02 17:47:31,846][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=8.5476, lr=0.0001
[2025-05-02 17:47:31,871][meta_train][INFO] - epoch_31 saved !
[2025-05-02 17:47:59,683][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.7395, lr=0.0001
[2025-05-02 17:48:25,482][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=8.5403, lr=0.0001
[2025-05-02 17:48:52,882][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=9.9005, lr=0.0001
[2025-05-02 17:49:21,871][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.8616, lr=0.0001
[2025-05-02 17:49:50,064][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=5.9531, lr=0.0001
[2025-05-02 17:50:18,749][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=6.2382, lr=0.0001
[2025-05-02 17:50:45,283][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=12.0876, lr=0.0001
[2025-05-02 17:51:13,797][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6980, lr=0.0001
[2025-05-02 17:51:13,815][meta_train][INFO] - epoch_32 saved !
[2025-05-02 17:51:42,168][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=5.9453, lr=0.0001
[2025-05-02 17:52:10,002][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6973, lr=0.0001
[2025-05-02 17:52:35,359][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=8.5242, lr=0.0001
[2025-05-02 17:53:01,866][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=12.0567, lr=0.0001
[2025-05-02 17:53:31,160][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.8475, lr=0.0001
[2025-05-02 17:53:58,900][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=9.8522, lr=0.0001
[2025-05-02 17:54:27,642][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=6.2116, lr=0.0001
[2025-05-02 17:54:55,860][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.7337, lr=0.0001
[2025-05-02 17:54:55,879][meta_train][INFO] - epoch_33 saved !
[2025-05-02 17:55:23,941][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.7333, lr=0.0001
[2025-05-02 17:55:51,372][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=9.8250, lr=0.0001
[2025-05-02 17:56:19,471][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=6.1970, lr=0.0001
[2025-05-02 17:56:47,901][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6925, lr=0.0001
[2025-05-02 17:57:14,754][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=11.9868, lr=0.0001
[2025-05-02 17:57:42,979][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=5.9503, lr=0.0001
[2025-05-02 17:58:11,833][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.8315, lr=0.0001
[2025-05-02 17:58:37,598][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=8.5253, lr=0.0001
[2025-05-02 17:58:37,615][meta_train][INFO] - epoch_34 saved !
[2025-05-02 17:59:06,802][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.8329, lr=0.0001
[2025-05-02 17:59:34,801][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6900, lr=0.0001
[2025-05-02 18:00:02,395][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=9.7946, lr=0.0001
[2025-05-02 18:00:27,780][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=8.5168, lr=0.0001
[2025-05-02 18:00:54,753][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=11.9177, lr=0.0001
[2025-05-02 18:01:23,366][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=6.1650, lr=0.0001
[2025-05-02 18:01:51,674][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.7281, lr=0.0001
[2025-05-02 18:02:19,239][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=5.9413, lr=0.0001
[2025-05-02 18:02:19,267][meta_train][INFO] - epoch_35 saved !
[2025-05-02 18:02:47,995][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.7274, lr=0.0001
[2025-05-02 18:03:16,032][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=9.7273, lr=0.0001
[2025-05-02 18:03:44,799][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.8217, lr=0.0001
[2025-05-02 18:04:12,944][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=5.9416, lr=0.0001
[2025-05-02 18:04:40,898][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=6.1443, lr=0.0001
[2025-05-02 18:05:06,647][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=8.4970, lr=0.0001
[2025-05-02 18:05:33,458][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=11.8283, lr=0.0001
[2025-05-02 18:06:01,676][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6823, lr=0.0001
[2025-05-02 18:06:01,698][meta_train][INFO] - epoch_36 saved !
[2025-05-02 18:06:28,740][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=11.8006, lr=0.0001
[2025-05-02 18:06:57,318][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.7239, lr=0.0001
[2025-05-02 18:07:25,538][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=6.1213, lr=0.0001
[2025-05-02 18:07:54,561][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.8097, lr=0.0001
[2025-05-02 18:08:22,590][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6807, lr=0.0001
[2025-05-02 18:08:48,544][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=8.4635, lr=0.0001
[2025-05-02 18:09:16,396][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=5.9408, lr=0.0001
[2025-05-02 18:09:44,572][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=9.6640, lr=0.0001
[2025-05-02 18:09:44,594][meta_train][INFO] - epoch_37 saved !
[2025-05-02 18:10:12,714][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=5.9430, lr=0.0001
[2025-05-02 18:10:40,691][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6794, lr=0.0001
[2025-05-02 18:11:08,732][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.7198, lr=0.0001
[2025-05-02 18:11:35,872][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=11.6417, lr=0.0001
[2025-05-02 18:12:01,212][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=8.4545, lr=0.0001
[2025-05-02 18:12:29,942][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.7991, lr=0.0001
[2025-05-02 18:12:58,485][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=9.6004, lr=0.0001
[2025-05-02 18:13:26,785][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=6.0841, lr=0.0001
[2025-05-02 18:13:26,818][meta_train][INFO] - epoch_38 saved !
[2025-05-02 18:13:53,661][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=11.5961, lr=0.0001
[2025-05-02 18:14:22,300][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=6.0769, lr=0.0001
[2025-05-02 18:14:50,760][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=5.9258, lr=0.0001
[2025-05-02 18:15:18,370][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=9.5505, lr=0.0001
[2025-05-02 18:15:46,393][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6752, lr=0.0001
[2025-05-02 18:16:15,307][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.7154, lr=0.0001
[2025-05-02 18:16:43,954][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.7933, lr=0.0001
[2025-05-02 18:17:09,731][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=8.4098, lr=0.0001
[2025-05-02 18:17:09,748][meta_train][INFO] - epoch_39 saved !
[2025-05-02 18:17:37,743][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=6.0531, lr=0.0001
[2025-05-02 18:18:03,796][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=8.4147, lr=0.0001
[2025-05-02 18:18:31,467][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=9.5113, lr=0.0001
[2025-05-02 18:18:59,173][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=5.9250, lr=0.0001
[2025-05-02 18:19:27,596][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.7127, lr=0.0001
[2025-05-02 18:19:56,647][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.7876, lr=0.0001
[2025-05-02 18:20:24,363][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6730, lr=0.0001
[2025-05-02 18:20:51,078][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=11.4339, lr=0.0001
[2025-05-02 18:20:51,095][meta_train][INFO] - epoch_40 saved !
[2025-05-02 18:21:19,771][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6720, lr=0.0001
[2025-05-02 18:21:46,388][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=11.4176, lr=0.0001
[2025-05-02 18:22:14,385][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=5.9148, lr=0.0001
[2025-05-02 18:22:42,472][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=6.0123, lr=0.0001
[2025-05-02 18:23:11,168][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.7814, lr=0.0001
[2025-05-02 18:23:39,109][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=9.4097, lr=0.0001
[2025-05-02 18:24:04,529][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=8.3390, lr=0.0001
[2025-05-02 18:24:32,716][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.7088, lr=0.0001
[2025-05-02 18:24:32,745][meta_train][INFO] - epoch_41 saved !
[2025-05-02 18:25:00,139][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=9.3974, lr=0.0001
[2025-05-02 18:25:25,595][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=8.3619, lr=0.0001
[2025-05-02 18:25:53,908][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=5.9172, lr=0.0001
[2025-05-02 18:26:22,225][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6700, lr=0.0001
[2025-05-02 18:26:48,986][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=11.2321, lr=0.0001
[2025-05-02 18:27:17,037][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.7067, lr=0.0001
[2025-05-02 18:27:45,835][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.7736, lr=0.0001
[2025-05-02 18:28:14,221][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=5.9679, lr=0.0001
[2025-05-02 18:28:14,250][meta_train][INFO] - epoch_42 saved !
[2025-05-02 18:28:39,081][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=8.2857, lr=0.0001
[2025-05-02 18:29:08,143][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.7725, lr=0.0001
[2025-05-02 18:29:36,104][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.7051, lr=0.0001
[2025-05-02 18:30:03,269][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=11.1305, lr=0.0001
[2025-05-02 18:30:31,910][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=5.9568, lr=0.0001
[2025-05-02 18:30:59,793][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=5.8902, lr=0.0001
[2025-05-02 18:31:28,782][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6672, lr=0.0001
[2025-05-02 18:31:57,420][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=9.2631, lr=0.0001
[2025-05-02 18:31:57,437][meta_train][INFO] - epoch_43 saved !
[2025-05-02 18:32:25,684][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.7033, lr=0.0001
[2025-05-02 18:32:52,644][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=11.0021, lr=0.0001
[2025-05-02 18:33:21,284][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6666, lr=0.0001
[2025-05-02 18:33:49,308][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=9.2347, lr=0.0001
[2025-05-02 18:34:18,323][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.7665, lr=0.0001
[2025-05-02 18:34:46,503][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=5.8840, lr=0.0001
[2025-05-02 18:35:15,099][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=5.9290, lr=0.0001
[2025-05-02 18:35:40,507][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=8.2147, lr=0.0001
[2025-05-02 18:35:40,542][meta_train][INFO] - epoch_44 saved !
[2025-05-02 18:36:07,791][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=10.8622, lr=0.0001
[2025-05-02 18:36:33,332][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=8.1955, lr=0.0001
[2025-05-02 18:37:01,806][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=5.9055, lr=0.0001
[2025-05-02 18:37:30,568][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.7614, lr=0.0001
[2025-05-02 18:37:58,387][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6994, lr=0.0001
[2025-05-02 18:38:26,560][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=9.1435, lr=0.0001
[2025-05-02 18:38:54,570][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6644, lr=0.0001
[2025-05-02 18:39:23,190][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=5.8711, lr=0.0001
[2025-05-02 18:39:23,218][meta_train][INFO] - epoch_45 saved !
[2025-05-02 18:39:51,907][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.7578, lr=0.0001
[2025-05-02 18:40:19,715][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=9.0917, lr=0.0001
[2025-05-02 18:40:48,570][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=5.8841, lr=0.0001
[2025-05-02 18:41:15,564][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=10.6484, lr=0.0001
[2025-05-02 18:41:40,428][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=8.1198, lr=0.0001
[2025-05-02 18:42:08,731][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=5.8495, lr=0.0001
[2025-05-02 18:42:37,121][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6963, lr=0.0001
[2025-05-02 18:43:05,223][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6625, lr=0.0001
[2025-05-02 18:43:05,254][meta_train][INFO] - epoch_46 saved !
[2025-05-02 18:43:33,421][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=9.0239, lr=0.0001
[2025-05-02 18:44:02,402][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.7540, lr=0.0001
[2025-05-02 18:44:30,778][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=5.8589, lr=0.0001
[2025-05-02 18:44:59,181][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6946, lr=0.0001
[2025-05-02 18:45:27,293][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=5.8442, lr=0.0001
[2025-05-02 18:45:54,135][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=10.4739, lr=0.0001
[2025-05-02 18:46:22,490][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6614, lr=0.0001
[2025-05-02 18:46:47,709][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=8.0480, lr=0.0001
[2025-05-02 18:46:47,740][meta_train][INFO] - epoch_47 saved !
[2025-05-02 18:47:15,386][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=8.9180, lr=0.0001
[2025-05-02 18:47:43,281][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=5.8343, lr=0.0001
[2025-05-02 18:48:09,017][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=8.0371, lr=0.0001
[2025-05-02 18:48:37,068][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6607, lr=0.0001
[2025-05-02 18:49:05,915][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.7484, lr=0.0001
[2025-05-02 18:49:34,169][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=5.8268, lr=0.0001
[2025-05-02 18:50:02,557][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6914, lr=0.0001
[2025-05-02 18:50:29,020][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=10.3230, lr=0.0001
[2025-05-02 18:50:29,047][meta_train][INFO] - epoch_48 saved !
[2025-05-02 18:50:56,769][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=10.2947, lr=0.0001
[2025-05-02 18:51:24,639][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6908, lr=0.0001
[2025-05-02 18:51:52,657][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6592, lr=0.0001
[2025-05-02 18:52:21,061][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=5.8098, lr=0.0001
[2025-05-02 18:52:49,718][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=5.8073, lr=0.0001
[2025-05-02 18:53:17,307][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=8.8097, lr=0.0001
[2025-05-02 18:53:45,953][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.7439, lr=0.0001
[2025-05-02 18:54:11,403][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=7.9564, lr=0.0001
[2025-05-02 18:54:11,421][meta_train][INFO] - epoch_49 saved !
[2025-05-02 18:54:39,849][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=5.7923, lr=0.0001
[2025-05-02 18:55:08,004][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6885, lr=0.0001
[2025-05-02 18:55:36,087][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=8.7564, lr=0.0001
[2025-05-02 18:56:01,566][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=7.9146, lr=0.0001
[2025-05-02 18:56:29,393][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6581, lr=0.0001
[2025-05-02 18:56:58,639][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.7417, lr=0.0001
[2025-05-02 18:57:25,135][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=10.0895, lr=0.0001
[2025-05-02 18:57:53,585][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=5.7947, lr=0.0001
[2025-05-02 18:57:53,627][meta_train][INFO] - epoch_50 saved !
[2025-05-02 18:58:22,080][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=5.7900, lr=0.0001
[2025-05-02 18:58:49,910][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=5.7641, lr=0.0001
[2025-05-02 18:59:17,187][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=10.0284, lr=0.0001
[2025-05-02 18:59:42,302][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=7.8340, lr=0.0001
[2025-05-02 19:00:10,286][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=8.6145, lr=0.0001
[2025-05-02 19:00:38,765][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6568, lr=0.0001
[2025-05-02 19:01:06,741][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6850, lr=0.0001
[2025-05-02 19:01:35,459][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.7389, lr=0.0001
[2025-05-02 19:01:35,475][meta_train][INFO] - epoch_51 saved !
[2025-05-02 19:02:03,299][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=5.7848, lr=0.0001
[2025-05-02 19:02:31,752][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6566, lr=0.0001
[2025-05-02 19:02:59,734][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=8.5877, lr=0.0001
[2025-05-02 19:03:26,506][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=9.8771, lr=0.0001
[2025-05-02 19:03:51,689][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=7.7758, lr=0.0001
[2025-05-02 19:04:20,341][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.7356, lr=0.0001
[2025-05-02 19:04:48,641][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6832, lr=0.0001
[2025-05-02 19:05:17,286][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=5.7237, lr=0.0001
[2025-05-02 19:05:17,307][meta_train][INFO] - epoch_52 saved !
[2025-05-02 19:05:45,802][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=5.7218, lr=0.0001
[2025-05-02 19:06:11,151][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=7.7458, lr=0.0001
[2025-05-02 19:06:38,764][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6822, lr=0.0001
[2025-05-02 19:07:07,079][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6553, lr=0.0001
[2025-05-02 19:07:35,000][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=5.7553, lr=0.0001
[2025-05-02 19:08:02,396][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=9.6929, lr=0.0001
[2025-05-02 19:08:29,975][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=8.4587, lr=0.0001
[2025-05-02 19:08:59,304][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.7334, lr=0.0001
[2025-05-02 19:08:59,327][meta_train][INFO] - epoch_53 saved !
[2025-05-02 19:09:27,325][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6808, lr=0.0001
[2025-05-02 19:09:55,333][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=5.6957, lr=0.0001
[2025-05-02 19:10:23,786][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=5.7440, lr=0.0001
[2025-05-02 19:10:52,312][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.7329, lr=0.0001
[2025-05-02 19:11:19,426][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=9.5550, lr=0.0001
[2025-05-02 19:11:47,927][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=8.3944, lr=0.0001
[2025-05-02 19:12:15,792][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6540, lr=0.0001
[2025-05-02 19:12:40,822][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=7.6547, lr=0.0001
[2025-05-02 19:12:40,849][meta_train][INFO] - epoch_54 saved !
[2025-05-02 19:13:06,030][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=7.6449, lr=0.0001
[2025-05-02 19:13:34,577][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=5.7311, lr=0.0001
[2025-05-02 19:14:02,963][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=5.6700, lr=0.0001
[2025-05-02 19:14:32,307][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.7306, lr=0.0001
[2025-05-02 19:14:59,912][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=8.3204, lr=0.0001
[2025-05-02 19:15:27,244][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=9.3202, lr=0.0001
[2025-05-02 19:15:55,268][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6773, lr=0.0001
[2025-05-02 19:16:23,831][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6530, lr=0.0001
[2025-05-02 19:16:23,848][meta_train][INFO] - epoch_55 saved !
[2025-05-02 19:16:52,393][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6530, lr=0.0001
[2025-05-02 19:17:20,132][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6766, lr=0.0001
[2025-05-02 19:17:46,754][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=9.1910, lr=0.0001
[2025-05-02 19:18:15,082][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=5.7164, lr=0.0001
[2025-05-02 19:18:43,587][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=5.6406, lr=0.0001
[2025-05-02 19:19:11,525][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=8.2307, lr=0.0001
[2025-05-02 19:19:36,939][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=7.5269, lr=0.0001
[2025-05-02 19:20:05,954][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.7266, lr=0.0001
[2025-05-02 19:20:05,980][meta_train][INFO] - epoch_56 saved !
[2025-05-02 19:20:33,798][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=5.6991, lr=0.0001
[2025-05-02 19:21:01,693][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=8.1781, lr=0.0001
[2025-05-02 19:21:29,848][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=5.6233, lr=0.0001
[2025-05-02 19:21:58,139][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6742, lr=0.0001
[2025-05-02 19:22:23,490][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=7.4999, lr=0.0001
[2025-05-02 19:22:52,907][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.7260, lr=0.0001
[2025-05-02 19:23:19,289][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=8.8980, lr=0.0001
[2025-05-02 19:23:46,748][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6513, lr=0.0001
[2025-05-02 19:23:46,765][meta_train][INFO] - epoch_57 saved !
[2025-05-02 19:24:15,463][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6729, lr=0.0001
[2025-05-02 19:24:43,318][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=8.0973, lr=0.0001
[2025-05-02 19:24:43,425][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-02 19:24:43,506][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 19:24:43,507][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 19:24:43,507][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 19:24:59,955][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 19:25:08,862][train][INFO] - Epoch 1/100, Val Acc=0.0947, Val Loss=3.8279, lr=0.0100
[2025-05-02 19:25:12,227][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.7246, lr=0.0001
[2025-05-02 19:25:16,717][train][INFO] - Epoch 2/100, Val Acc=0.2397, Val Loss=2.8117, lr=0.0100
[2025-05-02 19:25:25,136][train][INFO] - Epoch 3/100, Val Acc=0.3455, Val Loss=2.4270, lr=0.0100
[2025-05-02 19:25:32,901][train][INFO] - Epoch 4/100, Val Acc=0.3893, Val Loss=2.2631, lr=0.0100
[2025-05-02 19:25:40,889][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=5.5984, lr=0.0001
[2025-05-02 19:25:41,047][train][INFO] - Epoch 5/100, Val Acc=0.4173, Val Loss=2.2595, lr=0.0100
[2025-05-02 19:25:49,593][train][INFO] - Epoch 6/100, Val Acc=0.4231, Val Loss=2.3047, lr=0.0100
[2025-05-02 19:25:57,486][train][INFO] - Epoch 7/100, Val Acc=0.4580, Val Loss=2.0862, lr=0.0100
[2025-05-02 19:26:04,868][train][INFO] - Epoch 8/100, Val Acc=0.5155, Val Loss=1.8029, lr=0.0100
[2025-05-02 19:26:07,959][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=8.7521, lr=0.0001
[2025-05-02 19:26:13,672][train][INFO] - Epoch 9/100, Val Acc=0.5062, Val Loss=1.9032, lr=0.0100
[2025-05-02 19:26:21,212][train][INFO] - Epoch 10/100, Val Acc=0.5143, Val Loss=1.9413, lr=0.0100
[2025-05-02 19:26:28,906][train][INFO] - Epoch 11/100, Val Acc=0.5601, Val Loss=1.6663, lr=0.0100
[2025-05-02 19:26:34,042][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=7.4217, lr=0.0001
[2025-05-02 19:26:37,336][train][INFO] - Epoch 12/100, Val Acc=0.5728, Val Loss=1.6154, lr=0.0100
[2025-05-02 19:26:46,066][train][INFO] - Epoch 13/100, Val Acc=0.5560, Val Loss=1.7096, lr=0.0100
[2025-05-02 19:26:54,372][train][INFO] - Epoch 14/100, Val Acc=0.5529, Val Loss=1.7927, lr=0.0100
[2025-05-02 19:27:02,664][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=5.6741, lr=0.0001
[2025-05-02 19:27:03,167][train][INFO] - Epoch 15/100, Val Acc=0.5709, Val Loss=1.6864, lr=0.0100
[2025-05-02 19:27:11,459][train][INFO] - Epoch 16/100, Val Acc=0.5575, Val Loss=1.7715, lr=0.0100
[2025-05-02 19:27:19,877][train][INFO] - Epoch 17/100, Val Acc=0.5632, Val Loss=1.7910, lr=0.0100
[2025-05-02 19:27:28,607][train][INFO] - Epoch 18/100, Val Acc=0.5899, Val Loss=1.6480, lr=0.0100
[2025-05-02 19:27:30,881][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6503, lr=0.0001
[2025-05-02 19:27:30,901][meta_train][INFO] - epoch_58 saved !
[2025-05-02 19:27:37,156][train][INFO] - Epoch 19/100, Val Acc=0.5959, Val Loss=1.5764, lr=0.0100
[2025-05-02 19:27:45,092][train][INFO] - Epoch 20/100, Val Acc=0.5723, Val Loss=1.6749, lr=0.0100
[2025-05-02 19:27:53,328][train][INFO] - Epoch 21/100, Val Acc=0.6013, Val Loss=1.6310, lr=0.0100
[2025-05-02 19:27:58,340][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=8.5920, lr=0.0001
[2025-05-02 19:28:01,221][train][INFO] - Epoch 22/100, Val Acc=0.5959, Val Loss=1.6240, lr=0.0100
[2025-05-02 19:28:09,402][train][INFO] - Epoch 23/100, Val Acc=0.5887, Val Loss=1.6339, lr=0.0100
[2025-05-02 19:28:17,344][train][INFO] - Epoch 24/100, Val Acc=0.6156, Val Loss=1.5686, lr=0.0100
[2025-05-02 19:28:25,713][train][INFO] - Epoch 25/100, Val Acc=0.6188, Val Loss=1.4982, lr=0.0100
[2025-05-02 19:28:26,498][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6706, lr=0.0001
[2025-05-02 19:28:33,428][train][INFO] - Epoch 26/100, Val Acc=0.6196, Val Loss=1.5399, lr=0.0100
[2025-05-02 19:28:41,690][train][INFO] - Epoch 27/100, Val Acc=0.5916, Val Loss=1.6858, lr=0.0100
[2025-05-02 19:28:50,577][train][INFO] - Epoch 28/100, Val Acc=0.6145, Val Loss=1.5796, lr=0.0100
[2025-05-02 19:28:52,311][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=7.3759, lr=0.0001
[2025-05-02 19:28:59,370][train][INFO] - Epoch 29/100, Val Acc=0.6069, Val Loss=1.6413, lr=0.0100
[2025-05-02 19:29:07,429][train][INFO] - Epoch 30/100, Val Acc=0.6284, Val Loss=1.4875, lr=0.0100
[2025-05-02 19:29:16,064][train][INFO] - Epoch 31/100, Val Acc=0.6267, Val Loss=1.5125, lr=0.0100
[2025-05-02 19:29:21,558][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=5.5739, lr=0.0001
[2025-05-02 19:29:24,537][train][INFO] - Epoch 32/100, Val Acc=0.6147, Val Loss=1.5825, lr=0.0100
[2025-05-02 19:29:32,761][train][INFO] - Epoch 33/100, Val Acc=0.6228, Val Loss=1.5887, lr=0.0100
[2025-05-02 19:29:40,663][train][INFO] - Epoch 34/100, Val Acc=0.6072, Val Loss=1.6901, lr=0.0100
[2025-05-02 19:29:48,701][train][INFO] - Epoch 35/100, Val Acc=0.6041, Val Loss=1.6767, lr=0.0100
[2025-05-02 19:29:50,711][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.7217, lr=0.0001
[2025-05-02 19:29:56,634][train][INFO] - Epoch 36/100, Val Acc=0.6028, Val Loss=1.6668, lr=0.0100
[2025-05-02 19:30:05,046][train][INFO] - Epoch 37/100, Val Acc=0.6257, Val Loss=1.5896, lr=0.0100
[2025-05-02 19:30:13,078][train][INFO] - Epoch 38/100, Val Acc=0.6118, Val Loss=1.6628, lr=0.0100
[2025-05-02 19:30:19,127][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=7.9857, lr=0.0001
[2025-05-02 19:30:21,387][train][INFO] - Epoch 39/100, Val Acc=0.6225, Val Loss=1.5956, lr=0.0100
[2025-05-02 19:30:29,980][train][INFO] - Epoch 40/100, Val Acc=0.6094, Val Loss=1.6861, lr=0.0100
[2025-05-02 19:30:38,272][train][INFO] - Epoch 41/100, Val Acc=0.6320, Val Loss=1.5667, lr=0.0100
[2025-05-02 19:30:46,397][train][INFO] - Epoch 42/100, Val Acc=0.6172, Val Loss=1.6776, lr=0.0100
[2025-05-02 19:30:48,036][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=5.6597, lr=0.0001
[2025-05-02 19:30:54,806][train][INFO] - Epoch 43/100, Val Acc=0.6188, Val Loss=1.6421, lr=0.0100
[2025-05-02 19:31:03,416][train][INFO] - Epoch 44/100, Val Acc=0.6253, Val Loss=1.6098, lr=0.0100
[2025-05-02 19:31:11,211][train][INFO] - Epoch 45/100, Val Acc=0.6188, Val Loss=1.6504, lr=0.0100
[2025-05-02 19:31:16,508][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6496, lr=0.0001
[2025-05-02 19:31:16,526][meta_train][INFO] - epoch_59 saved !
[2025-05-02 19:31:18,587][train][INFO] - Epoch 46/100, Val Acc=0.6303, Val Loss=1.6046, lr=0.0100
[2025-05-02 19:31:27,256][train][INFO] - Epoch 47/100, Val Acc=0.6074, Val Loss=1.7301, lr=0.0100
[2025-05-02 19:31:35,346][train][INFO] - Epoch 48/100, Val Acc=0.6229, Val Loss=1.6260, lr=0.0100
[2025-05-02 19:31:43,782][train][INFO] - Epoch 49/100, Val Acc=0.6145, Val Loss=1.7092, lr=0.0100
[2025-05-02 19:31:45,750][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.7201, lr=0.0001
[2025-05-02 19:31:52,200][train][INFO] - Epoch 50/100, Val Acc=0.6093, Val Loss=1.7611, lr=0.0100
[2025-05-02 19:32:00,899][train][INFO] - Epoch 51/100, Val Acc=0.6438, Val Loss=1.5354, lr=0.0100
[2025-05-02 19:32:09,134][train][INFO] - Epoch 52/100, Val Acc=0.6245, Val Loss=1.6783, lr=0.0100
[2025-05-02 19:32:13,064][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=8.3460, lr=0.0001
[2025-05-02 19:32:17,345][train][INFO] - Epoch 53/100, Val Acc=0.6297, Val Loss=1.6314, lr=0.0100
[2025-05-02 19:32:25,615][train][INFO] - Epoch 54/100, Val Acc=0.6285, Val Loss=1.6383, lr=0.0100
[2025-05-02 19:32:33,624][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6296, lr=0.0100
[2025-05-02 19:32:38,733][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=7.3178, lr=0.0001
[2025-05-02 19:32:40,900][train][INFO] - Epoch 56/100, Val Acc=0.6270, Val Loss=1.6498, lr=0.0100
[2025-05-02 19:32:48,885][train][INFO] - Epoch 57/100, Val Acc=0.6315, Val Loss=1.6395, lr=0.0100
[2025-05-02 19:32:57,378][train][INFO] - Epoch 58/100, Val Acc=0.6289, Val Loss=1.6599, lr=0.0100
[2025-05-02 19:33:05,536][train][INFO] - Epoch 59/100, Val Acc=0.6210, Val Loss=1.6755, lr=0.0100
[2025-05-02 19:33:07,326][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=5.6468, lr=0.0001
[2025-05-02 19:33:13,796][train][INFO] - Epoch 60/100, Val Acc=0.6409, Val Loss=1.5719, lr=0.0100
[2025-05-02 19:33:21,544][train][INFO] - Epoch 61/100, Val Acc=0.6941, Val Loss=1.3369, lr=0.0010
[2025-05-02 19:33:29,540][train][INFO] - Epoch 62/100, Val Acc=0.6994, Val Loss=1.3290, lr=0.0010
[2025-05-02 19:33:35,553][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=7.8945, lr=0.0001
[2025-05-02 19:33:37,866][train][INFO] - Epoch 63/100, Val Acc=0.6991, Val Loss=1.3416, lr=0.0010
[2025-05-02 19:33:46,327][train][INFO] - Epoch 64/100, Val Acc=0.7002, Val Loss=1.3412, lr=0.0010
[2025-05-02 19:33:55,040][train][INFO] - Epoch 65/100, Val Acc=0.7009, Val Loss=1.3487, lr=0.0010
[2025-05-02 19:34:02,999][train][INFO] - Epoch 66/100, Val Acc=0.7021, Val Loss=1.3617, lr=0.0010
[2025-05-02 19:34:04,187][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6489, lr=0.0001
[2025-05-02 19:34:11,652][train][INFO] - Epoch 67/100, Val Acc=0.7017, Val Loss=1.3637, lr=0.0010
[2025-05-02 19:34:19,639][train][INFO] - Epoch 68/100, Val Acc=0.7037, Val Loss=1.3700, lr=0.0010
[2025-05-02 19:34:27,576][train][INFO] - Epoch 69/100, Val Acc=0.7023, Val Loss=1.3756, lr=0.0010
[2025-05-02 19:34:32,725][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6679, lr=0.0001
[2025-05-02 19:34:36,605][train][INFO] - Epoch 70/100, Val Acc=0.7046, Val Loss=1.3816, lr=0.0010
[2025-05-02 19:34:43,993][train][INFO] - Epoch 71/100, Val Acc=0.7022, Val Loss=1.3797, lr=0.0010
[2025-05-02 19:34:51,789][train][INFO] - Epoch 72/100, Val Acc=0.7041, Val Loss=1.3996, lr=0.0010
[2025-05-02 19:34:59,786][train][INFO] - Epoch 73/100, Val Acc=0.7045, Val Loss=1.3879, lr=0.0010
[2025-05-02 19:35:01,584][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=5.5418, lr=0.0001
[2025-05-02 19:35:01,615][meta_train][INFO] - epoch_60 saved !
[2025-05-02 19:35:08,068][train][INFO] - Epoch 74/100, Val Acc=0.6989, Val Loss=1.3965, lr=0.0010
[2025-05-02 19:35:15,862][train][INFO] - Epoch 75/100, Val Acc=0.7019, Val Loss=1.3962, lr=0.0010
[2025-05-02 19:35:23,494][train][INFO] - Epoch 76/100, Val Acc=0.7030, Val Loss=1.4140, lr=0.0010
[2025-05-02 19:35:28,912][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=8.1229, lr=0.0001
[2025-05-02 19:35:31,251][train][INFO] - Epoch 77/100, Val Acc=0.7036, Val Loss=1.4230, lr=0.0010
[2025-05-02 19:35:39,417][train][INFO] - Epoch 78/100, Val Acc=0.7025, Val Loss=1.4260, lr=0.0010
[2025-05-02 19:35:48,263][train][INFO] - Epoch 79/100, Val Acc=0.7032, Val Loss=1.4261, lr=0.0010
[2025-05-02 19:35:56,985][train][INFO] - Epoch 80/100, Val Acc=0.7055, Val Loss=1.4266, lr=0.0010
[2025-05-02 19:35:57,275][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6487, lr=0.0001
[2025-05-02 19:36:05,134][train][INFO] - Epoch 81/100, Val Acc=0.7030, Val Loss=1.4372, lr=0.0010
[2025-05-02 19:36:13,286][train][INFO] - Epoch 82/100, Val Acc=0.7038, Val Loss=1.4375, lr=0.0010
[2025-05-02 19:36:21,596][train][INFO] - Epoch 83/100, Val Acc=0.7027, Val Loss=1.4429, lr=0.0010
[2025-05-02 19:36:25,879][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=5.5324, lr=0.0001
[2025-05-02 19:36:29,393][train][INFO] - Epoch 84/100, Val Acc=0.7037, Val Loss=1.4480, lr=0.0010
[2025-05-02 19:36:38,187][train][INFO] - Epoch 85/100, Val Acc=0.7060, Val Loss=1.4461, lr=0.0010
[2025-05-02 19:36:46,036][train][INFO] - Epoch 86/100, Val Acc=0.7030, Val Loss=1.4595, lr=0.0010
[2025-05-02 19:36:54,144][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=5.6336, lr=0.0001
[2025-05-02 19:36:55,002][train][INFO] - Epoch 87/100, Val Acc=0.7056, Val Loss=1.4598, lr=0.0010
[2025-05-02 19:37:03,239][train][INFO] - Epoch 88/100, Val Acc=0.7040, Val Loss=1.4646, lr=0.0010
[2025-05-02 19:37:11,199][train][INFO] - Epoch 89/100, Val Acc=0.7036, Val Loss=1.4664, lr=0.0010
[2025-05-02 19:37:19,072][train][INFO] - Epoch 90/100, Val Acc=0.7038, Val Loss=1.4736, lr=0.0010
[2025-05-02 19:37:22,965][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=7.8239, lr=0.0001
[2025-05-02 19:37:27,020][train][INFO] - Epoch 91/100, Val Acc=0.7042, Val Loss=1.4667, lr=0.0001
[2025-05-02 19:37:35,192][train][INFO] - Epoch 92/100, Val Acc=0.7057, Val Loss=1.4686, lr=0.0001
[2025-05-02 19:37:43,596][train][INFO] - Epoch 93/100, Val Acc=0.7080, Val Loss=1.4640, lr=0.0001
[2025-05-02 19:37:51,385][train][INFO] - Epoch 94/100, Val Acc=0.7048, Val Loss=1.4601, lr=0.0001
[2025-05-02 19:37:51,762][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6663, lr=0.0001
[2025-05-02 19:37:58,828][train][INFO] - Epoch 95/100, Val Acc=0.7064, Val Loss=1.4648, lr=0.0001
[2025-05-02 19:38:06,451][train][INFO] - Epoch 96/100, Val Acc=0.7068, Val Loss=1.4609, lr=0.0001
[2025-05-02 19:38:14,647][train][INFO] - Epoch 97/100, Val Acc=0.7051, Val Loss=1.4686, lr=0.0001
[2025-05-02 19:38:20,901][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.7166, lr=0.0001
[2025-05-02 19:38:22,114][train][INFO] - Epoch 98/100, Val Acc=0.7064, Val Loss=1.4615, lr=0.0001
[2025-05-02 19:38:29,729][train][INFO] - Epoch 99/100, Val Acc=0.7058, Val Loss=1.4660, lr=0.0001
[2025-05-02 19:38:37,491][train][INFO] - Epoch 100/100, Val Acc=0.7058, Val Loss=1.4673, lr=0.0001
[2025-05-02 19:38:42,663][train][INFO] - After training : Train Acc=0.9902  Val Acc=0.7080
[2025-05-02 19:38:42,667][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 19:38:46,784][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=7.2270, lr=0.0001
[2025-05-02 19:38:46,808][meta_train][INFO] - epoch_61 saved !
[2025-05-02 19:39:14,689][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=7.9279, lr=0.0001
[2025-05-02 19:39:43,658][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6656, lr=0.0001
[2025-05-02 19:40:00,853][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 19:40:11,694][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=7.7772, lr=0.0001
[2025-05-02 19:40:40,879][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=5.6228, lr=0.0001
[2025-05-02 19:41:09,604][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6474, lr=0.0001
[2025-05-02 19:41:38,999][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=5.5040, lr=0.0001
[2025-05-02 19:42:04,788][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=7.1684, lr=0.0001
[2025-05-02 19:42:19,146][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 19:42:19,570][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 19:42:34,782][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.7144, lr=0.0001
[2025-05-02 19:42:34,809][meta_train][INFO] - epoch_62 saved !
[2025-05-02 19:43:02,946][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=5.4960, lr=0.0001
[2025-05-02 19:43:31,046][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=5.6107, lr=0.0001
[2025-05-02 19:43:59,141][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6638, lr=0.0001
[2025-05-02 19:44:24,572][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=7.1404, lr=0.0001
[2025-05-02 19:44:51,971][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=7.6734, lr=0.0001
[2025-05-02 19:45:20,514][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6467, lr=0.0001
[2025-05-02 19:45:47,851][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=7.7050, lr=0.0001
[2025-05-02 19:46:16,545][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.7129, lr=0.0001
[2025-05-02 19:46:16,575][meta_train][INFO] - epoch_63 saved !
[2025-05-02 19:46:45,623][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.7124, lr=0.0001
[2025-05-02 19:47:10,593][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=7.0972, lr=0.0001
[2025-05-02 19:47:38,841][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=5.5922, lr=0.0001
[2025-05-02 19:48:05,833][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=7.6257, lr=0.0001
[2025-05-02 19:48:34,057][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=5.4629, lr=0.0001
[2025-05-02 19:49:02,861][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6456, lr=0.0001
[2025-05-02 19:49:31,267][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6617, lr=0.0001
[2025-05-02 19:49:58,393][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=7.5712, lr=0.0001
[2025-05-02 19:49:58,418][meta_train][INFO] - epoch_64 saved !
[2025-05-02 19:50:27,051][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6618, lr=0.0001
[2025-05-02 19:50:55,313][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=5.4532, lr=0.0001
[2025-05-02 19:51:20,809][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=7.0374, lr=0.0001
[2025-05-02 19:51:48,906][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=5.5783, lr=0.0001
[2025-05-02 19:52:16,326][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=7.5123, lr=0.0001
[2025-05-02 19:52:45,186][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.7077, lr=0.0001
[2025-05-02 19:52:54,001][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-02 19:52:54,073][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 19:52:54,073][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 19:52:54,073][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 19:53:10,695][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 19:53:13,410][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6447, lr=0.0001
[2025-05-02 19:53:18,864][train][INFO] - Epoch 1/100, Val Acc=0.0947, Val Loss=3.8279, lr=0.0100
[2025-05-02 19:53:26,368][train][INFO] - Epoch 2/100, Val Acc=0.2397, Val Loss=2.8117, lr=0.0100
[2025-05-02 19:53:34,787][train][INFO] - Epoch 3/100, Val Acc=0.3455, Val Loss=2.4270, lr=0.0100
[2025-05-02 19:53:40,844][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=7.4167, lr=0.0001
[2025-05-02 19:53:40,861][meta_train][INFO] - epoch_65 saved !
[2025-05-02 19:53:42,454][train][INFO] - Epoch 4/100, Val Acc=0.3893, Val Loss=2.2631, lr=0.0100
[2025-05-02 19:53:50,340][train][INFO] - Epoch 5/100, Val Acc=0.4173, Val Loss=2.2595, lr=0.0100
[2025-05-02 19:53:58,172][train][INFO] - Epoch 6/100, Val Acc=0.4231, Val Loss=2.3047, lr=0.0100
[2025-05-02 19:54:06,646][train][INFO] - Epoch 7/100, Val Acc=0.4580, Val Loss=2.0862, lr=0.0100
[2025-05-02 19:54:10,061][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6450, lr=0.0001
[2025-05-02 19:54:14,797][train][INFO] - Epoch 8/100, Val Acc=0.5155, Val Loss=1.8029, lr=0.0100
[2025-05-02 19:54:22,756][train][INFO] - Epoch 9/100, Val Acc=0.5062, Val Loss=1.9032, lr=0.0100
[2025-05-02 19:54:30,428][train][INFO] - Epoch 10/100, Val Acc=0.5143, Val Loss=1.9413, lr=0.0100
[2025-05-02 19:54:38,220][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=5.5766, lr=0.0001
[2025-05-02 19:54:38,534][train][INFO] - Epoch 11/100, Val Acc=0.5601, Val Loss=1.6663, lr=0.0100
[2025-05-02 19:54:47,173][train][INFO] - Epoch 12/100, Val Acc=0.5728, Val Loss=1.6154, lr=0.0100
[2025-05-02 19:54:55,847][train][INFO] - Epoch 13/100, Val Acc=0.5560, Val Loss=1.7096, lr=0.0100
[2025-05-02 19:55:03,581][train][INFO] - Epoch 14/100, Val Acc=0.5529, Val Loss=1.7927, lr=0.0100
[2025-05-02 19:55:05,601][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=7.3526, lr=0.0001
[2025-05-02 19:55:11,993][train][INFO] - Epoch 15/100, Val Acc=0.5709, Val Loss=1.6864, lr=0.0100
[2025-05-02 19:55:19,721][train][INFO] - Epoch 16/100, Val Acc=0.5575, Val Loss=1.7715, lr=0.0100
[2025-05-02 19:55:28,122][train][INFO] - Epoch 17/100, Val Acc=0.5632, Val Loss=1.7910, lr=0.0100
[2025-05-02 19:55:33,992][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=5.4312, lr=0.0001
[2025-05-02 19:55:36,340][train][INFO] - Epoch 18/100, Val Acc=0.5899, Val Loss=1.6480, lr=0.0100
[2025-05-02 19:55:44,146][train][INFO] - Epoch 19/100, Val Acc=0.5959, Val Loss=1.5764, lr=0.0100
[2025-05-02 19:55:52,822][train][INFO] - Epoch 20/100, Val Acc=0.5723, Val Loss=1.6749, lr=0.0100
[2025-05-02 19:56:01,362][train][INFO] - Epoch 21/100, Val Acc=0.6013, Val Loss=1.6310, lr=0.0100
[2025-05-02 19:56:02,765][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=7.4354, lr=0.0001
[2025-05-02 19:56:09,578][train][INFO] - Epoch 22/100, Val Acc=0.5959, Val Loss=1.6240, lr=0.0100
[2025-05-02 19:56:17,908][train][INFO] - Epoch 23/100, Val Acc=0.5887, Val Loss=1.6339, lr=0.0100
[2025-05-02 19:56:26,339][train][INFO] - Epoch 24/100, Val Acc=0.6156, Val Loss=1.5686, lr=0.0100
[2025-05-02 19:56:28,282][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=6.9517, lr=0.0001
[2025-05-02 19:56:35,135][train][INFO] - Epoch 25/100, Val Acc=0.6188, Val Loss=1.4982, lr=0.0100
[2025-05-02 19:56:42,696][train][INFO] - Epoch 26/100, Val Acc=0.6196, Val Loss=1.5399, lr=0.0100
[2025-05-02 19:56:51,234][train][INFO] - Epoch 27/100, Val Acc=0.5916, Val Loss=1.6858, lr=0.0100
[2025-05-02 19:56:56,678][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6588, lr=0.0001
[2025-05-02 19:56:59,801][train][INFO] - Epoch 28/100, Val Acc=0.6145, Val Loss=1.5796, lr=0.0100
[2025-05-02 19:57:08,217][train][INFO] - Epoch 29/100, Val Acc=0.6069, Val Loss=1.6413, lr=0.0100
[2025-05-02 19:57:16,114][train][INFO] - Epoch 30/100, Val Acc=0.6284, Val Loss=1.4875, lr=0.0100
[2025-05-02 19:57:24,182][train][INFO] - Epoch 31/100, Val Acc=0.6267, Val Loss=1.5125, lr=0.0100
[2025-05-02 19:57:26,513][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.7063, lr=0.0001
[2025-05-02 19:57:26,534][meta_train][INFO] - epoch_66 saved !
[2025-05-02 19:57:32,662][train][INFO] - Epoch 32/100, Val Acc=0.6147, Val Loss=1.5825, lr=0.0100
[2025-05-02 19:57:41,064][train][INFO] - Epoch 33/100, Val Acc=0.6228, Val Loss=1.5887, lr=0.0100
[2025-05-02 19:57:49,158][train][INFO] - Epoch 34/100, Val Acc=0.6072, Val Loss=1.6901, lr=0.0100
[2025-05-02 19:57:54,943][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=7.3810, lr=0.0001
[2025-05-02 19:57:57,862][train][INFO] - Epoch 35/100, Val Acc=0.6041, Val Loss=1.6767, lr=0.0100
[2025-05-02 19:58:05,899][train][INFO] - Epoch 36/100, Val Acc=0.6028, Val Loss=1.6668, lr=0.0100
[2025-05-02 19:58:14,290][train][INFO] - Epoch 37/100, Val Acc=0.6257, Val Loss=1.5896, lr=0.0100
[2025-05-02 19:58:22,468][train][INFO] - Epoch 38/100, Val Acc=0.6118, Val Loss=1.6628, lr=0.0100
[2025-05-02 19:58:23,150][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6590, lr=0.0001
[2025-05-02 19:58:30,603][train][INFO] - Epoch 39/100, Val Acc=0.6225, Val Loss=1.5956, lr=0.0100
[2025-05-02 19:58:38,824][train][INFO] - Epoch 40/100, Val Acc=0.6094, Val Loss=1.6861, lr=0.0100
[2025-05-02 19:58:47,042][train][INFO] - Epoch 41/100, Val Acc=0.6320, Val Loss=1.5667, lr=0.0100
[2025-05-02 19:58:49,213][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=6.9279, lr=0.0001
[2025-05-02 19:58:54,395][train][INFO] - Epoch 42/100, Val Acc=0.6172, Val Loss=1.6776, lr=0.0100
[2025-05-02 19:59:02,190][train][INFO] - Epoch 43/100, Val Acc=0.6188, Val Loss=1.6421, lr=0.0100
[2025-05-02 19:59:10,516][train][INFO] - Epoch 44/100, Val Acc=0.6253, Val Loss=1.6098, lr=0.0100
[2025-05-02 19:59:18,284][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.7069, lr=0.0001
[2025-05-02 19:59:18,706][train][INFO] - Epoch 45/100, Val Acc=0.6188, Val Loss=1.6504, lr=0.0100
[2025-05-02 19:59:27,411][train][INFO] - Epoch 46/100, Val Acc=0.6303, Val Loss=1.6046, lr=0.0100
[2025-05-02 19:59:35,307][train][INFO] - Epoch 47/100, Val Acc=0.6074, Val Loss=1.7301, lr=0.0100
[2025-05-02 19:59:44,026][train][INFO] - Epoch 48/100, Val Acc=0.6229, Val Loss=1.6260, lr=0.0100
[2025-05-02 19:59:46,932][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6440, lr=0.0001
[2025-05-02 19:59:51,540][train][INFO] - Epoch 49/100, Val Acc=0.6145, Val Loss=1.7092, lr=0.0100
[2025-05-02 19:59:59,771][train][INFO] - Epoch 50/100, Val Acc=0.6093, Val Loss=1.7611, lr=0.0100
[2025-05-02 20:00:06,417][train][INFO] - Epoch 51/100, Val Acc=0.6438, Val Loss=1.5354, lr=0.0100
[2025-05-02 20:00:14,820][train][INFO] - Epoch 52/100, Val Acc=0.6245, Val Loss=1.6783, lr=0.0100
[2025-05-02 20:00:15,488][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=5.5473, lr=0.0001
[2025-05-02 20:00:23,795][train][INFO] - Epoch 53/100, Val Acc=0.6297, Val Loss=1.6314, lr=0.0100
[2025-05-02 20:00:31,878][train][INFO] - Epoch 54/100, Val Acc=0.6285, Val Loss=1.6383, lr=0.0100
[2025-05-02 20:00:40,123][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6296, lr=0.0100
[2025-05-02 20:00:42,824][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=7.1391, lr=0.0001
[2025-05-02 20:00:48,886][train][INFO] - Epoch 56/100, Val Acc=0.6270, Val Loss=1.6498, lr=0.0100
[2025-05-02 20:00:57,051][train][INFO] - Epoch 57/100, Val Acc=0.6315, Val Loss=1.6395, lr=0.0100
[2025-05-02 20:01:05,666][train][INFO] - Epoch 58/100, Val Acc=0.6289, Val Loss=1.6599, lr=0.0100
[2025-05-02 20:01:11,631][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=5.4004, lr=0.0001
[2025-05-02 20:01:11,661][meta_train][INFO] - epoch_67 saved !
[2025-05-02 20:01:13,284][train][INFO] - Epoch 59/100, Val Acc=0.6210, Val Loss=1.6755, lr=0.0100
[2025-05-02 20:01:20,271][train][INFO] - Epoch 60/100, Val Acc=0.6409, Val Loss=1.5719, lr=0.0100
[2025-05-02 20:01:28,553][train][INFO] - Epoch 61/100, Val Acc=0.6941, Val Loss=1.3369, lr=0.0010
[2025-05-02 20:01:36,788][train][INFO] - Epoch 62/100, Val Acc=0.6994, Val Loss=1.3290, lr=0.0010
[2025-05-02 20:01:39,894][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=7.3214, lr=0.0001
[2025-05-02 20:01:44,818][train][INFO] - Epoch 63/100, Val Acc=0.6991, Val Loss=1.3416, lr=0.0010
[2025-05-02 20:01:53,134][train][INFO] - Epoch 64/100, Val Acc=0.7002, Val Loss=1.3412, lr=0.0010
[2025-05-02 20:02:01,833][train][INFO] - Epoch 65/100, Val Acc=0.7009, Val Loss=1.3487, lr=0.0010
[2025-05-02 20:02:08,600][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6572, lr=0.0001
[2025-05-02 20:02:10,105][train][INFO] - Epoch 66/100, Val Acc=0.7021, Val Loss=1.3617, lr=0.0010
[2025-05-02 20:02:18,347][train][INFO] - Epoch 67/100, Val Acc=0.7017, Val Loss=1.3637, lr=0.0010
[2025-05-02 20:02:26,399][train][INFO] - Epoch 68/100, Val Acc=0.7037, Val Loss=1.3700, lr=0.0010
[2025-05-02 20:02:34,642][train][INFO] - Epoch 69/100, Val Acc=0.7023, Val Loss=1.3756, lr=0.0010
[2025-05-02 20:02:37,455][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=5.3932, lr=0.0001
[2025-05-02 20:02:42,300][train][INFO] - Epoch 70/100, Val Acc=0.7046, Val Loss=1.3816, lr=0.0010
[2025-05-02 20:02:50,637][train][INFO] - Epoch 71/100, Val Acc=0.7022, Val Loss=1.3797, lr=0.0010
[2025-05-02 20:02:59,194][train][INFO] - Epoch 72/100, Val Acc=0.7041, Val Loss=1.3996, lr=0.0010
[2025-05-02 20:03:06,011][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6436, lr=0.0001
[2025-05-02 20:03:07,574][train][INFO] - Epoch 73/100, Val Acc=0.7045, Val Loss=1.3879, lr=0.0010
[2025-05-02 20:03:15,832][train][INFO] - Epoch 74/100, Val Acc=0.6989, Val Loss=1.3965, lr=0.0010
[2025-05-02 20:03:24,087][train][INFO] - Epoch 75/100, Val Acc=0.7019, Val Loss=1.3962, lr=0.0010
[2025-05-02 20:03:31,842][train][INFO] - Epoch 76/100, Val Acc=0.7030, Val Loss=1.4140, lr=0.0010
[2025-05-02 20:03:33,696][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=6.9886, lr=0.0001
[2025-05-02 20:03:40,470][train][INFO] - Epoch 77/100, Val Acc=0.7036, Val Loss=1.4230, lr=0.0010
[2025-05-02 20:03:49,276][train][INFO] - Epoch 78/100, Val Acc=0.7025, Val Loss=1.4260, lr=0.0010
[2025-05-02 20:03:56,517][train][INFO] - Epoch 79/100, Val Acc=0.7032, Val Loss=1.4261, lr=0.0010
[2025-05-02 20:04:01,920][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=5.5416, lr=0.0001
[2025-05-02 20:04:05,459][train][INFO] - Epoch 80/100, Val Acc=0.7055, Val Loss=1.4266, lr=0.0010
[2025-05-02 20:04:13,404][train][INFO] - Epoch 81/100, Val Acc=0.7030, Val Loss=1.4372, lr=0.0010
[2025-05-02 20:04:21,834][train][INFO] - Epoch 82/100, Val Acc=0.7038, Val Loss=1.4375, lr=0.0010
[2025-05-02 20:04:27,854][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=6.8533, lr=0.0001
[2025-05-02 20:04:30,111][train][INFO] - Epoch 83/100, Val Acc=0.7027, Val Loss=1.4429, lr=0.0010
[2025-05-02 20:04:38,848][train][INFO] - Epoch 84/100, Val Acc=0.7037, Val Loss=1.4480, lr=0.0010
[2025-05-02 20:04:47,925][train][INFO] - Epoch 85/100, Val Acc=0.7060, Val Loss=1.4461, lr=0.0010
[2025-05-02 20:04:55,948][train][INFO] - Epoch 86/100, Val Acc=0.7030, Val Loss=1.4595, lr=0.0010
[2025-05-02 20:04:57,252][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.7022, lr=0.0001
[2025-05-02 20:04:57,271][meta_train][INFO] - epoch_68 saved !
[2025-05-02 20:05:02,971][train][INFO] - Epoch 87/100, Val Acc=0.7056, Val Loss=1.4598, lr=0.0010
[2025-05-02 20:05:11,186][train][INFO] - Epoch 88/100, Val Acc=0.7040, Val Loss=1.4646, lr=0.0010
[2025-05-02 20:05:19,316][train][INFO] - Epoch 89/100, Val Acc=0.7036, Val Loss=1.4664, lr=0.0010
[2025-05-02 20:05:24,813][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=6.9568, lr=0.0001
[2025-05-02 20:05:27,228][train][INFO] - Epoch 90/100, Val Acc=0.7038, Val Loss=1.4736, lr=0.0010
[2025-05-02 20:05:35,970][train][INFO] - Epoch 91/100, Val Acc=0.7042, Val Loss=1.4667, lr=0.0001
[2025-05-02 20:05:43,601][train][INFO] - Epoch 92/100, Val Acc=0.7057, Val Loss=1.4686, lr=0.0001
[2025-05-02 20:05:52,490][train][INFO] - Epoch 93/100, Val Acc=0.7080, Val Loss=1.4640, lr=0.0001
[2025-05-02 20:05:53,061][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=5.5207, lr=0.0001
[2025-05-02 20:06:00,383][train][INFO] - Epoch 94/100, Val Acc=0.7048, Val Loss=1.4601, lr=0.0001
[2025-05-02 20:06:07,959][train][INFO] - Epoch 95/100, Val Acc=0.7064, Val Loss=1.4648, lr=0.0001
[2025-05-02 20:06:16,393][train][INFO] - Epoch 96/100, Val Acc=0.7068, Val Loss=1.4609, lr=0.0001
[2025-05-02 20:06:21,941][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6421, lr=0.0001
[2025-05-02 20:06:24,837][train][INFO] - Epoch 97/100, Val Acc=0.7051, Val Loss=1.4686, lr=0.0001
[2025-05-02 20:06:33,322][train][INFO] - Epoch 98/100, Val Acc=0.7064, Val Loss=1.4615, lr=0.0001
[2025-05-02 20:06:41,925][train][INFO] - Epoch 99/100, Val Acc=0.7058, Val Loss=1.4660, lr=0.0001
[2025-05-02 20:06:47,231][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=6.8067, lr=0.0001
[2025-05-02 20:06:49,938][train][INFO] - Epoch 100/100, Val Acc=0.7058, Val Loss=1.4673, lr=0.0001
[2025-05-02 20:06:55,090][train][INFO] - After training : Train Acc=0.9902  Val Acc=0.7080
[2025-05-02 20:07:05,785][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 20:07:05,785][Progressive pruning][INFO] - Current speed up: 2.99
[2025-05-02 20:07:11,027][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 20:07:15,871][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=7.2240, lr=0.0001
[2025-05-02 20:07:19,614][train][INFO] - Epoch 1/140, Val Acc=0.2935, Val Loss=2.6783, lr=0.0100
[2025-05-02 20:07:27,744][train][INFO] - Epoch 2/140, Val Acc=0.3984, Val Loss=2.3037, lr=0.0100
[2025-05-02 20:07:35,968][train][INFO] - Epoch 3/140, Val Acc=0.4198, Val Loss=2.2929, lr=0.0100
[2025-05-02 20:07:44,095][train][INFO] - Epoch 4/140, Val Acc=0.4699, Val Loss=2.0696, lr=0.0100
[2025-05-02 20:07:44,552][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6560, lr=0.0001
[2025-05-02 20:07:52,097][train][INFO] - Epoch 5/140, Val Acc=0.4377, Val Loss=2.3658, lr=0.0100
[2025-05-02 20:08:00,569][train][INFO] - Epoch 6/140, Val Acc=0.5003, Val Loss=2.0077, lr=0.0100
[2025-05-02 20:08:08,853][train][INFO] - Epoch 7/140, Val Acc=0.4901, Val Loss=2.1713, lr=0.0100
[2025-05-02 20:08:14,134][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.7020, lr=0.0001
[2025-05-02 20:08:16,751][train][INFO] - Epoch 8/140, Val Acc=0.4740, Val Loss=2.2292, lr=0.0100
[2025-05-02 20:08:24,449][train][INFO] - Epoch 9/140, Val Acc=0.5344, Val Loss=1.8687, lr=0.0100
[2025-05-02 20:08:32,600][train][INFO] - Epoch 10/140, Val Acc=0.4758, Val Loss=2.1609, lr=0.0100
[2025-05-02 20:08:40,988][train][INFO] - Epoch 11/140, Val Acc=0.5368, Val Loss=1.8872, lr=0.0100
[2025-05-02 20:08:42,862][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=5.3642, lr=0.0001
[2025-05-02 20:08:42,881][meta_train][INFO] - epoch_69 saved !
[2025-05-02 20:08:49,680][train][INFO] - Epoch 12/140, Val Acc=0.5221, Val Loss=2.0578, lr=0.0100
[2025-05-02 20:08:57,613][train][INFO] - Epoch 13/140, Val Acc=0.5257, Val Loss=1.9785, lr=0.0100
[2025-05-02 20:09:05,665][train][INFO] - Epoch 14/140, Val Acc=0.5435, Val Loss=1.8672, lr=0.0100
[2025-05-02 20:09:11,141][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=7.1907, lr=0.0001
[2025-05-02 20:09:13,484][train][INFO] - Epoch 15/140, Val Acc=0.5308, Val Loss=1.9747, lr=0.0100
[2025-05-02 20:09:22,186][train][INFO] - Epoch 16/140, Val Acc=0.4956, Val Loss=2.1811, lr=0.0100
[2025-05-02 20:09:30,656][train][INFO] - Epoch 17/140, Val Acc=0.5568, Val Loss=1.8084, lr=0.0100
[2025-05-02 20:09:38,422][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=6.7509, lr=0.0001
[2025-05-02 20:09:38,769][train][INFO] - Epoch 18/140, Val Acc=0.5565, Val Loss=1.8937, lr=0.0100
[2025-05-02 20:09:46,648][train][INFO] - Epoch 19/140, Val Acc=0.5476, Val Loss=1.8882, lr=0.0100
[2025-05-02 20:09:54,883][train][INFO] - Epoch 20/140, Val Acc=0.5635, Val Loss=1.8463, lr=0.0100
[2025-05-02 20:10:03,001][train][INFO] - Epoch 21/140, Val Acc=0.5556, Val Loss=1.8672, lr=0.0100
[2025-05-02 20:10:06,783][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6416, lr=0.0001
[2025-05-02 20:10:11,358][train][INFO] - Epoch 22/140, Val Acc=0.5593, Val Loss=1.8162, lr=0.0100
[2025-05-02 20:10:18,773][train][INFO] - Epoch 23/140, Val Acc=0.5299, Val Loss=2.0380, lr=0.0100
[2025-05-02 20:10:26,749][train][INFO] - Epoch 24/140, Val Acc=0.5544, Val Loss=1.8971, lr=0.0100
[2025-05-02 20:10:34,830][train][INFO] - Epoch 25/140, Val Acc=0.5319, Val Loss=2.0540, lr=0.0100
[2025-05-02 20:10:36,641][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6992, lr=0.0001
[2025-05-02 20:10:42,724][train][INFO] - Epoch 26/140, Val Acc=0.5667, Val Loss=1.7882, lr=0.0100
[2025-05-02 20:10:51,376][train][INFO] - Epoch 27/140, Val Acc=0.5681, Val Loss=1.8030, lr=0.0100
[2025-05-02 20:10:59,876][train][INFO] - Epoch 28/140, Val Acc=0.5551, Val Loss=1.9321, lr=0.0100
[2025-05-02 20:11:05,315][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6543, lr=0.0001
[2025-05-02 20:11:08,596][train][INFO] - Epoch 29/140, Val Acc=0.5298, Val Loss=2.1193, lr=0.0100
[2025-05-02 20:11:16,583][train][INFO] - Epoch 30/140, Val Acc=0.5634, Val Loss=1.8713, lr=0.0100
[2025-05-02 20:11:24,710][train][INFO] - Epoch 31/140, Val Acc=0.5508, Val Loss=1.9802, lr=0.0100
[2025-05-02 20:11:32,980][train][INFO] - Epoch 32/140, Val Acc=0.5736, Val Loss=1.8401, lr=0.0100
[2025-05-02 20:11:34,051][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=5.5077, lr=0.0001
[2025-05-02 20:11:41,486][train][INFO] - Epoch 33/140, Val Acc=0.5805, Val Loss=1.7647, lr=0.0100
[2025-05-02 20:11:49,470][train][INFO] - Epoch 34/140, Val Acc=0.5444, Val Loss=2.0727, lr=0.0100
[2025-05-02 20:11:57,865][train][INFO] - Epoch 35/140, Val Acc=0.5587, Val Loss=1.9906, lr=0.0100
[2025-05-02 20:11:59,473][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=6.7381, lr=0.0001
[2025-05-02 20:12:04,988][train][INFO] - Epoch 36/140, Val Acc=0.5565, Val Loss=1.9037, lr=0.0100
[2025-05-02 20:12:13,668][train][INFO] - Epoch 37/140, Val Acc=0.5500, Val Loss=2.0455, lr=0.0100
[2025-05-02 20:12:21,706][train][INFO] - Epoch 38/140, Val Acc=0.5722, Val Loss=1.8272, lr=0.0100
[2025-05-02 20:12:28,673][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=5.3483, lr=0.0001
[2025-05-02 20:12:28,703][meta_train][INFO] - epoch_70 saved !
[2025-05-02 20:12:28,959][train][INFO] - Epoch 39/140, Val Acc=0.5698, Val Loss=1.8906, lr=0.0100
[2025-05-02 20:12:37,256][train][INFO] - Epoch 40/140, Val Acc=0.5695, Val Loss=1.8533, lr=0.0100
[2025-05-02 20:12:45,656][train][INFO] - Epoch 41/140, Val Acc=0.5629, Val Loss=1.9096, lr=0.0100
[2025-05-02 20:12:53,270][train][INFO] - Epoch 42/140, Val Acc=0.5256, Val Loss=2.1219, lr=0.0100
[2025-05-02 20:12:57,539][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=5.5040, lr=0.0001
[2025-05-02 20:13:01,721][train][INFO] - Epoch 43/140, Val Acc=0.5643, Val Loss=1.9837, lr=0.0100
[2025-05-02 20:13:09,563][train][INFO] - Epoch 44/140, Val Acc=0.5443, Val Loss=2.1366, lr=0.0100
[2025-05-02 20:13:17,609][train][INFO] - Epoch 45/140, Val Acc=0.5656, Val Loss=1.8752, lr=0.0100
[2025-05-02 20:13:23,327][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=6.7233, lr=0.0001
[2025-05-02 20:13:25,792][train][INFO] - Epoch 46/140, Val Acc=0.5479, Val Loss=2.0526, lr=0.0100
[2025-05-02 20:13:33,719][train][INFO] - Epoch 47/140, Val Acc=0.5676, Val Loss=1.9214, lr=0.0100
[2025-05-02 20:13:41,393][train][INFO] - Epoch 48/140, Val Acc=0.5709, Val Loss=1.8757, lr=0.0100
[2025-05-02 20:13:49,981][train][INFO] - Epoch 49/140, Val Acc=0.5569, Val Loss=2.0294, lr=0.0100
[2025-05-02 20:13:50,949][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=6.6182, lr=0.0001
[2025-05-02 20:13:58,937][train][INFO] - Epoch 50/140, Val Acc=0.5464, Val Loss=2.0572, lr=0.0100
[2025-05-02 20:14:06,873][train][INFO] - Epoch 51/140, Val Acc=0.5691, Val Loss=1.9040, lr=0.0100
[2025-05-02 20:14:15,191][train][INFO] - Epoch 52/140, Val Acc=0.5704, Val Loss=1.9233, lr=0.0100
[2025-05-02 20:14:19,871][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6976, lr=0.0001
[2025-05-02 20:14:24,113][train][INFO] - Epoch 53/140, Val Acc=0.5456, Val Loss=2.1232, lr=0.0100
[2025-05-02 20:14:31,834][train][INFO] - Epoch 54/140, Val Acc=0.5613, Val Loss=2.0010, lr=0.0100
[2025-05-02 20:14:40,315][train][INFO] - Epoch 55/140, Val Acc=0.5849, Val Loss=1.8022, lr=0.0100
[2025-05-02 20:14:48,522][train][INFO] - Epoch 56/140, Val Acc=0.5571, Val Loss=1.9801, lr=0.0100
[2025-05-02 20:14:56,601][train][INFO] - Epoch 57/140, Val Acc=0.5696, Val Loss=1.9190, lr=0.0100
[2025-05-02 20:15:04,557][train][INFO] - Epoch 58/140, Val Acc=0.5717, Val Loss=1.9175, lr=0.0100
[2025-05-02 20:15:11,376][train][INFO] - Epoch 59/140, Val Acc=0.5504, Val Loss=2.0879, lr=0.0100
[2025-05-02 20:15:19,227][train][INFO] - Epoch 60/140, Val Acc=0.5762, Val Loss=1.9090, lr=0.0100
[2025-05-02 20:15:26,594][train][INFO] - Epoch 61/140, Val Acc=0.5733, Val Loss=1.9582, lr=0.0100
[2025-05-02 20:15:34,075][train][INFO] - Epoch 62/140, Val Acc=0.5619, Val Loss=1.9954, lr=0.0100
[2025-05-02 20:15:41,422][train][INFO] - Epoch 63/140, Val Acc=0.5709, Val Loss=1.9305, lr=0.0100
[2025-05-02 20:15:49,224][train][INFO] - Epoch 64/140, Val Acc=0.5836, Val Loss=1.8608, lr=0.0100
[2025-05-02 20:15:56,154][train][INFO] - Epoch 65/140, Val Acc=0.5528, Val Loss=2.0414, lr=0.0100
[2025-05-02 20:16:04,111][train][INFO] - Epoch 66/140, Val Acc=0.5594, Val Loss=2.0378, lr=0.0100
[2025-05-02 20:16:11,837][train][INFO] - Epoch 67/140, Val Acc=0.5627, Val Loss=2.0428, lr=0.0100
[2025-05-02 20:16:19,922][train][INFO] - Epoch 68/140, Val Acc=0.5572, Val Loss=2.0139, lr=0.0100
[2025-05-02 20:16:27,851][train][INFO] - Epoch 69/140, Val Acc=0.5722, Val Loss=1.8979, lr=0.0100
[2025-05-02 20:16:35,217][train][INFO] - Epoch 70/140, Val Acc=0.5729, Val Loss=1.8698, lr=0.0100
[2025-05-02 20:16:43,144][train][INFO] - Epoch 71/140, Val Acc=0.5728, Val Loss=1.9718, lr=0.0100
[2025-05-02 20:16:48,131][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 200
        lr: 0.01
        lr_decay_milestones: 120,170
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 200
        lr: 0.01
        lr_decay_milestones: 120,170
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-02 20:16:48,183][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 20:16:48,183][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 20:16:48,183][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 20:16:51,753][train][INFO] - Epoch 72/140, Val Acc=0.5785, Val Loss=1.9253, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 20:17:00,911][train][INFO] - Epoch 73/140, Val Acc=0.5704, Val Loss=1.9862, lr=0.0100
[2025-05-02 20:17:05,178][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 20:17:08,747][train][INFO] - Epoch 74/140, Val Acc=0.5953, Val Loss=1.7635, lr=0.0100
[2025-05-02 20:17:12,844][train][INFO] - Epoch 1/200, Val Acc=0.0947, Val Loss=3.8279, lr=0.0100
[2025-05-02 20:17:16,594][train][INFO] - Epoch 75/140, Val Acc=0.5748, Val Loss=1.9706, lr=0.0100
[2025-05-02 20:17:20,942][train][INFO] - Epoch 2/200, Val Acc=0.2397, Val Loss=2.8117, lr=0.0100
[2025-05-02 20:17:24,188][train][INFO] - Epoch 76/140, Val Acc=0.5652, Val Loss=2.0039, lr=0.0100
[2025-05-02 20:17:28,292][train][INFO] - Epoch 3/200, Val Acc=0.3455, Val Loss=2.4270, lr=0.0100
[2025-05-02 20:17:31,951][train][INFO] - Epoch 77/140, Val Acc=0.5724, Val Loss=1.9474, lr=0.0100
[2025-05-02 20:17:36,593][train][INFO] - Epoch 4/200, Val Acc=0.3893, Val Loss=2.2631, lr=0.0100
[2025-05-02 20:17:39,984][train][INFO] - Epoch 78/140, Val Acc=0.5795, Val Loss=1.9675, lr=0.0100
[2025-05-02 20:17:44,625][train][INFO] - Epoch 5/200, Val Acc=0.4173, Val Loss=2.2595, lr=0.0100
[2025-05-02 20:17:47,917][train][INFO] - Epoch 79/140, Val Acc=0.5809, Val Loss=1.9066, lr=0.0100
[2025-05-02 20:17:52,652][train][INFO] - Epoch 6/200, Val Acc=0.4231, Val Loss=2.3047, lr=0.0100
[2025-05-02 20:17:56,298][train][INFO] - Epoch 80/140, Val Acc=0.5908, Val Loss=1.8325, lr=0.0100
[2025-05-02 20:17:59,989][train][INFO] - Epoch 7/200, Val Acc=0.4580, Val Loss=2.0862, lr=0.0100
[2025-05-02 20:18:03,713][train][INFO] - Epoch 81/140, Val Acc=0.6414, Val Loss=1.5475, lr=0.0010
[2025-05-02 20:18:08,073][train][INFO] - Epoch 8/200, Val Acc=0.5155, Val Loss=1.8029, lr=0.0100
[2025-05-02 20:18:11,812][train][INFO] - Epoch 82/140, Val Acc=0.6422, Val Loss=1.5558, lr=0.0010
[2025-05-02 20:18:16,283][train][INFO] - Epoch 9/200, Val Acc=0.5062, Val Loss=1.9032, lr=0.0100
[2025-05-02 20:18:19,338][train][INFO] - Epoch 83/140, Val Acc=0.6443, Val Loss=1.5715, lr=0.0010
[2025-05-02 20:18:24,640][train][INFO] - Epoch 10/200, Val Acc=0.5143, Val Loss=1.9413, lr=0.0100
[2025-05-02 20:18:27,471][train][INFO] - Epoch 84/140, Val Acc=0.6428, Val Loss=1.5817, lr=0.0010
[2025-05-02 20:18:32,760][train][INFO] - Epoch 11/200, Val Acc=0.5601, Val Loss=1.6663, lr=0.0100
[2025-05-02 20:18:35,908][train][INFO] - Epoch 85/140, Val Acc=0.6439, Val Loss=1.5797, lr=0.0010
[2025-05-02 20:18:40,862][train][INFO] - Epoch 12/200, Val Acc=0.5728, Val Loss=1.6154, lr=0.0100
[2025-05-02 20:18:43,472][train][INFO] - Epoch 86/140, Val Acc=0.6423, Val Loss=1.5949, lr=0.0010
[2025-05-02 20:18:49,174][train][INFO] - Epoch 13/200, Val Acc=0.5560, Val Loss=1.7096, lr=0.0100
[2025-05-02 20:18:51,422][train][INFO] - Epoch 87/140, Val Acc=0.6441, Val Loss=1.5951, lr=0.0010
[2025-05-02 20:18:57,673][train][INFO] - Epoch 14/200, Val Acc=0.5529, Val Loss=1.7927, lr=0.0100
[2025-05-02 20:18:59,728][train][INFO] - Epoch 88/140, Val Acc=0.6457, Val Loss=1.6019, lr=0.0010
[2025-05-02 20:19:05,856][train][INFO] - Epoch 15/200, Val Acc=0.5709, Val Loss=1.6864, lr=0.0100
[2025-05-02 20:19:08,182][train][INFO] - Epoch 89/140, Val Acc=0.6432, Val Loss=1.6219, lr=0.0010
[2025-05-02 20:19:14,148][train][INFO] - Epoch 16/200, Val Acc=0.5575, Val Loss=1.7715, lr=0.0100
[2025-05-02 20:19:16,436][train][INFO] - Epoch 90/140, Val Acc=0.6475, Val Loss=1.6127, lr=0.0010
[2025-05-02 20:19:21,983][train][INFO] - Epoch 17/200, Val Acc=0.5632, Val Loss=1.7910, lr=0.0100
[2025-05-02 20:19:24,500][train][INFO] - Epoch 91/140, Val Acc=0.6441, Val Loss=1.6313, lr=0.0010
[2025-05-02 20:19:30,215][train][INFO] - Epoch 18/200, Val Acc=0.5899, Val Loss=1.6480, lr=0.0100
[2025-05-02 20:19:32,228][train][INFO] - Epoch 92/140, Val Acc=0.6454, Val Loss=1.6193, lr=0.0010
[2025-05-02 20:19:38,902][train][INFO] - Epoch 19/200, Val Acc=0.5959, Val Loss=1.5764, lr=0.0100
[2025-05-02 20:19:40,530][train][INFO] - Epoch 93/140, Val Acc=0.6424, Val Loss=1.6268, lr=0.0010
[2025-05-02 20:19:46,497][train][INFO] - Epoch 20/200, Val Acc=0.5723, Val Loss=1.6749, lr=0.0100
[2025-05-02 20:19:48,876][train][INFO] - Epoch 94/140, Val Acc=0.6446, Val Loss=1.6529, lr=0.0010
[2025-05-02 20:19:54,720][train][INFO] - Epoch 21/200, Val Acc=0.6013, Val Loss=1.6310, lr=0.0100
[2025-05-02 20:19:56,550][train][INFO] - Epoch 95/140, Val Acc=0.6444, Val Loss=1.6488, lr=0.0010
[2025-05-02 20:20:02,552][train][INFO] - Epoch 22/200, Val Acc=0.5959, Val Loss=1.6240, lr=0.0100
[2025-05-02 20:20:04,717][train][INFO] - Epoch 96/140, Val Acc=0.6427, Val Loss=1.6587, lr=0.0010
[2025-05-02 20:20:10,446][train][INFO] - Epoch 23/200, Val Acc=0.5887, Val Loss=1.6339, lr=0.0100
[2025-05-02 20:20:12,070][train][INFO] - Epoch 97/140, Val Acc=0.6433, Val Loss=1.6698, lr=0.0010
[2025-05-02 20:20:18,430][train][INFO] - Epoch 24/200, Val Acc=0.6156, Val Loss=1.5686, lr=0.0100
[2025-05-02 20:20:20,129][train][INFO] - Epoch 98/140, Val Acc=0.6430, Val Loss=1.6682, lr=0.0010
[2025-05-02 20:20:26,691][train][INFO] - Epoch 25/200, Val Acc=0.6188, Val Loss=1.4982, lr=0.0100
[2025-05-02 20:20:28,810][train][INFO] - Epoch 99/140, Val Acc=0.6424, Val Loss=1.6888, lr=0.0010
[2025-05-02 20:20:34,369][train][INFO] - Epoch 26/200, Val Acc=0.6196, Val Loss=1.5399, lr=0.0100
[2025-05-02 20:20:36,849][train][INFO] - Epoch 100/140, Val Acc=0.6406, Val Loss=1.6963, lr=0.0010
[2025-05-02 20:20:41,971][train][INFO] - Epoch 27/200, Val Acc=0.5916, Val Loss=1.6858, lr=0.0100
[2025-05-02 20:20:45,081][train][INFO] - Epoch 101/140, Val Acc=0.6402, Val Loss=1.6932, lr=0.0010
[2025-05-02 20:20:50,395][train][INFO] - Epoch 28/200, Val Acc=0.6145, Val Loss=1.5796, lr=0.0100
[2025-05-02 20:20:53,271][train][INFO] - Epoch 102/140, Val Acc=0.6418, Val Loss=1.6933, lr=0.0010
[2025-05-02 20:20:58,054][train][INFO] - Epoch 29/200, Val Acc=0.6069, Val Loss=1.6413, lr=0.0100
[2025-05-02 20:21:01,309][train][INFO] - Epoch 103/140, Val Acc=0.6428, Val Loss=1.6996, lr=0.0010
[2025-05-02 20:21:05,928][train][INFO] - Epoch 30/200, Val Acc=0.6284, Val Loss=1.4875, lr=0.0100
[2025-05-02 20:21:09,736][train][INFO] - Epoch 104/140, Val Acc=0.6408, Val Loss=1.7051, lr=0.0010
[2025-05-02 20:21:14,715][train][INFO] - Epoch 31/200, Val Acc=0.6267, Val Loss=1.5125, lr=0.0100
[2025-05-02 20:21:17,937][train][INFO] - Epoch 105/140, Val Acc=0.6434, Val Loss=1.7152, lr=0.0010
[2025-05-02 20:21:22,873][train][INFO] - Epoch 32/200, Val Acc=0.6147, Val Loss=1.5825, lr=0.0100
[2025-05-02 20:21:25,838][train][INFO] - Epoch 106/140, Val Acc=0.6447, Val Loss=1.7194, lr=0.0010
[2025-05-02 20:21:31,035][train][INFO] - Epoch 33/200, Val Acc=0.6228, Val Loss=1.5887, lr=0.0100
[2025-05-02 20:21:34,038][train][INFO] - Epoch 107/140, Val Acc=0.6407, Val Loss=1.7365, lr=0.0010
[2025-05-02 20:21:38,940][train][INFO] - Epoch 34/200, Val Acc=0.6072, Val Loss=1.6901, lr=0.0100
[2025-05-02 20:21:41,440][train][INFO] - Epoch 108/140, Val Acc=0.6422, Val Loss=1.7197, lr=0.0010
[2025-05-02 20:21:46,583][train][INFO] - Epoch 35/200, Val Acc=0.6041, Val Loss=1.6767, lr=0.0100
[2025-05-02 20:21:49,091][train][INFO] - Epoch 109/140, Val Acc=0.6451, Val Loss=1.7419, lr=0.0010
[2025-05-02 20:21:53,649][train][INFO] - Epoch 36/200, Val Acc=0.6028, Val Loss=1.6668, lr=0.0100
[2025-05-02 20:21:56,868][train][INFO] - Epoch 110/140, Val Acc=0.6426, Val Loss=1.7409, lr=0.0010
[2025-05-02 20:22:01,763][train][INFO] - Epoch 37/200, Val Acc=0.6257, Val Loss=1.5896, lr=0.0100
[2025-05-02 20:22:05,136][train][INFO] - Epoch 111/140, Val Acc=0.6419, Val Loss=1.7487, lr=0.0010
[2025-05-02 20:22:09,942][train][INFO] - Epoch 38/200, Val Acc=0.6118, Val Loss=1.6628, lr=0.0100
[2025-05-02 20:22:13,597][train][INFO] - Epoch 112/140, Val Acc=0.6444, Val Loss=1.7463, lr=0.0010
[2025-05-02 20:22:18,041][train][INFO] - Epoch 39/200, Val Acc=0.6225, Val Loss=1.5956, lr=0.0100
[2025-05-02 20:22:21,642][train][INFO] - Epoch 113/140, Val Acc=0.6406, Val Loss=1.7587, lr=0.0010
[2025-05-02 20:22:26,388][train][INFO] - Epoch 40/200, Val Acc=0.6094, Val Loss=1.6861, lr=0.0100
[2025-05-02 20:22:28,846][train][INFO] - Epoch 114/140, Val Acc=0.6433, Val Loss=1.7690, lr=0.0010
[2025-05-02 20:22:34,215][train][INFO] - Epoch 41/200, Val Acc=0.6320, Val Loss=1.5667, lr=0.0100
[2025-05-02 20:22:37,166][train][INFO] - Epoch 115/140, Val Acc=0.6401, Val Loss=1.7814, lr=0.0010
[2025-05-02 20:22:41,952][train][INFO] - Epoch 42/200, Val Acc=0.6172, Val Loss=1.6776, lr=0.0100
[2025-05-02 20:22:45,271][train][INFO] - Epoch 116/140, Val Acc=0.6414, Val Loss=1.7821, lr=0.0010
[2025-05-02 20:22:50,003][train][INFO] - Epoch 43/200, Val Acc=0.6188, Val Loss=1.6421, lr=0.0100
[2025-05-02 20:22:53,537][train][INFO] - Epoch 117/140, Val Acc=0.6434, Val Loss=1.7764, lr=0.0010
[2025-05-02 20:22:58,386][train][INFO] - Epoch 44/200, Val Acc=0.6253, Val Loss=1.6098, lr=0.0100
[2025-05-02 20:23:01,850][train][INFO] - Epoch 118/140, Val Acc=0.6426, Val Loss=1.7815, lr=0.0010
[2025-05-02 20:23:06,540][train][INFO] - Epoch 45/200, Val Acc=0.6188, Val Loss=1.6504, lr=0.0100
[2025-05-02 20:23:09,872][train][INFO] - Epoch 119/140, Val Acc=0.6398, Val Loss=1.7892, lr=0.0010
[2025-05-02 20:23:14,584][train][INFO] - Epoch 46/200, Val Acc=0.6303, Val Loss=1.6046, lr=0.0100
[2025-05-02 20:23:17,334][train][INFO] - Epoch 120/140, Val Acc=0.6394, Val Loss=1.7905, lr=0.0010
[2025-05-02 20:23:22,437][train][INFO] - Epoch 47/200, Val Acc=0.6074, Val Loss=1.7301, lr=0.0100
[2025-05-02 20:23:25,836][train][INFO] - Epoch 121/140, Val Acc=0.6447, Val Loss=1.7794, lr=0.0001
[2025-05-02 20:23:30,803][train][INFO] - Epoch 48/200, Val Acc=0.6229, Val Loss=1.6260, lr=0.0100
[2025-05-02 20:23:33,895][train][INFO] - Epoch 122/140, Val Acc=0.6455, Val Loss=1.7865, lr=0.0001
[2025-05-02 20:23:38,793][train][INFO] - Epoch 49/200, Val Acc=0.6145, Val Loss=1.7092, lr=0.0100
[2025-05-02 20:23:41,751][train][INFO] - Epoch 123/140, Val Acc=0.6426, Val Loss=1.7791, lr=0.0001
[2025-05-02 20:23:47,171][train][INFO] - Epoch 50/200, Val Acc=0.6093, Val Loss=1.7611, lr=0.0100
[2025-05-02 20:23:50,106][train][INFO] - Epoch 124/140, Val Acc=0.6430, Val Loss=1.7803, lr=0.0001
[2025-05-02 20:23:55,098][train][INFO] - Epoch 51/200, Val Acc=0.6438, Val Loss=1.5354, lr=0.0100
[2025-05-02 20:23:57,959][train][INFO] - Epoch 125/140, Val Acc=0.6442, Val Loss=1.7780, lr=0.0001
[2025-05-02 20:24:03,016][train][INFO] - Epoch 52/200, Val Acc=0.6245, Val Loss=1.6783, lr=0.0100
[2025-05-02 20:24:05,940][train][INFO] - Epoch 126/140, Val Acc=0.6414, Val Loss=1.7868, lr=0.0001
[2025-05-02 20:24:10,862][train][INFO] - Epoch 53/200, Val Acc=0.6297, Val Loss=1.6314, lr=0.0100
[2025-05-02 20:24:13,931][train][INFO] - Epoch 127/140, Val Acc=0.6426, Val Loss=1.7880, lr=0.0001
[2025-05-02 20:24:19,250][train][INFO] - Epoch 54/200, Val Acc=0.6285, Val Loss=1.6383, lr=0.0100
[2025-05-02 20:24:22,284][train][INFO] - Epoch 128/140, Val Acc=0.6454, Val Loss=1.7827, lr=0.0001
[2025-05-02 20:24:27,122][train][INFO] - Epoch 55/200, Val Acc=0.6281, Val Loss=1.6296, lr=0.0100
[2025-05-02 20:24:30,466][train][INFO] - Epoch 129/140, Val Acc=0.6445, Val Loss=1.7895, lr=0.0001
[2025-05-02 20:24:35,566][train][INFO] - Epoch 56/200, Val Acc=0.6270, Val Loss=1.6498, lr=0.0100
[2025-05-02 20:24:38,840][train][INFO] - Epoch 130/140, Val Acc=0.6446, Val Loss=1.7784, lr=0.0001
[2025-05-02 20:24:43,954][train][INFO] - Epoch 57/200, Val Acc=0.6315, Val Loss=1.6395, lr=0.0100
[2025-05-02 20:24:47,038][train][INFO] - Epoch 131/140, Val Acc=0.6438, Val Loss=1.7892, lr=0.0001
[2025-05-02 20:24:52,149][train][INFO] - Epoch 58/200, Val Acc=0.6289, Val Loss=1.6599, lr=0.0100
[2025-05-02 20:24:55,443][train][INFO] - Epoch 132/140, Val Acc=0.6431, Val Loss=1.7936, lr=0.0001
[2025-05-02 20:25:00,295][train][INFO] - Epoch 59/200, Val Acc=0.6210, Val Loss=1.6755, lr=0.0100
[2025-05-02 20:25:02,645][train][INFO] - Epoch 133/140, Val Acc=0.6433, Val Loss=1.7885, lr=0.0001
[2025-05-02 20:25:08,506][train][INFO] - Epoch 60/200, Val Acc=0.6409, Val Loss=1.5719, lr=0.0100
[2025-05-02 20:25:10,723][train][INFO] - Epoch 134/140, Val Acc=0.6456, Val Loss=1.7915, lr=0.0001
[2025-05-02 20:25:16,334][train][INFO] - Epoch 61/200, Val Acc=0.6218, Val Loss=1.6786, lr=0.0100
[2025-05-02 20:25:19,018][train][INFO] - Epoch 135/140, Val Acc=0.6457, Val Loss=1.7827, lr=0.0001
[2025-05-02 20:25:24,565][train][INFO] - Epoch 62/200, Val Acc=0.6200, Val Loss=1.7442, lr=0.0100
[2025-05-02 20:25:27,556][train][INFO] - Epoch 136/140, Val Acc=0.6456, Val Loss=1.7898, lr=0.0001
[2025-05-02 20:25:32,602][train][INFO] - Epoch 63/200, Val Acc=0.6356, Val Loss=1.6634, lr=0.0100
[2025-05-02 20:25:35,818][train][INFO] - Epoch 137/140, Val Acc=0.6447, Val Loss=1.7864, lr=0.0001
[2025-05-02 20:25:40,758][train][INFO] - Epoch 64/200, Val Acc=0.6239, Val Loss=1.7208, lr=0.0100
[2025-05-02 20:25:43,741][train][INFO] - Epoch 138/140, Val Acc=0.6438, Val Loss=1.7877, lr=0.0001
[2025-05-02 20:25:49,358][train][INFO] - Epoch 65/200, Val Acc=0.6387, Val Loss=1.6058, lr=0.0100
[2025-05-02 20:25:52,269][train][INFO] - Epoch 139/140, Val Acc=0.6425, Val Loss=1.7929, lr=0.0001
[2025-05-02 20:25:57,383][train][INFO] - Epoch 66/200, Val Acc=0.6410, Val Loss=1.6324, lr=0.0100
[2025-05-02 20:26:00,464][train][INFO] - Epoch 140/140, Val Acc=0.6448, Val Loss=1.7970, lr=0.0001
[2025-05-02 20:26:05,801][train][INFO] - Epoch 67/200, Val Acc=0.6268, Val Loss=1.6955, lr=0.0100
[2025-05-02 20:26:05,946][train][INFO] - After training : Train Acc=0.9299  Val Acc=0.6475
[2025-05-02 20:26:05,977][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(16, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(36, 119, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(119, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(119, 227, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(227, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(227, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(160, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(79, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(10, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(7, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(10, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=36, out_features=100, bias=True)
)
[2025-05-02 20:26:05,977][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.6474999785423279
                      Speed up: 2.99   Final speed up: 9.02
[2025-05-02 20:26:14,170][train][INFO] - Epoch 68/200, Val Acc=0.6263, Val Loss=1.6649, lr=0.0100
[2025-05-02 20:26:22,359][train][INFO] - Epoch 69/200, Val Acc=0.6305, Val Loss=1.7270, lr=0.0100
[2025-05-02 20:26:30,623][train][INFO] - Epoch 70/200, Val Acc=0.6150, Val Loss=1.7712, lr=0.0100
[2025-05-02 20:26:39,022][train][INFO] - Epoch 71/200, Val Acc=0.6258, Val Loss=1.6703, lr=0.0100
[2025-05-02 20:26:46,982][train][INFO] - Epoch 72/200, Val Acc=0.6097, Val Loss=1.8233, lr=0.0100
[2025-05-02 20:26:54,698][train][INFO] - Epoch 73/200, Val Acc=0.6060, Val Loss=1.8262, lr=0.0100
[2025-05-02 20:27:02,668][train][INFO] - Epoch 74/200, Val Acc=0.6337, Val Loss=1.6643, lr=0.0100
[2025-05-02 20:27:10,655][train][INFO] - Epoch 75/200, Val Acc=0.6314, Val Loss=1.6683, lr=0.0100
[2025-05-02 20:27:18,289][train][INFO] - Epoch 76/200, Val Acc=0.6337, Val Loss=1.6722, lr=0.0100
[2025-05-02 20:27:26,387][train][INFO] - Epoch 77/200, Val Acc=0.6449, Val Loss=1.5837, lr=0.0100
[2025-05-02 20:27:34,816][train][INFO] - Epoch 78/200, Val Acc=0.6364, Val Loss=1.6736, lr=0.0100
[2025-05-02 20:27:42,558][train][INFO] - Epoch 79/200, Val Acc=0.6208, Val Loss=1.7535, lr=0.0100
[2025-05-02 20:27:50,056][train][INFO] - Epoch 80/200, Val Acc=0.6483, Val Loss=1.5722, lr=0.0100
[2025-05-02 20:27:58,241][train][INFO] - Epoch 81/200, Val Acc=0.6309, Val Loss=1.6725, lr=0.0100
[2025-05-02 20:28:05,969][train][INFO] - Epoch 82/200, Val Acc=0.6439, Val Loss=1.6242, lr=0.0100
[2025-05-02 20:28:12,471][train][INFO] - Epoch 83/200, Val Acc=0.6262, Val Loss=1.7372, lr=0.0100
[2025-05-02 20:28:20,575][train][INFO] - Epoch 84/200, Val Acc=0.6218, Val Loss=1.7634, lr=0.0100
[2025-05-02 20:28:28,403][train][INFO] - Epoch 85/200, Val Acc=0.6254, Val Loss=1.7117, lr=0.0100
[2025-05-02 20:28:36,928][train][INFO] - Epoch 86/200, Val Acc=0.6328, Val Loss=1.7010, lr=0.0100
[2025-05-02 20:28:44,101][train][INFO] - Epoch 87/200, Val Acc=0.6334, Val Loss=1.7002, lr=0.0100
[2025-05-02 20:28:52,256][train][INFO] - Epoch 88/200, Val Acc=0.6348, Val Loss=1.6759, lr=0.0100
[2025-05-02 20:29:00,567][train][INFO] - Epoch 89/200, Val Acc=0.6442, Val Loss=1.6379, lr=0.0100
[2025-05-02 20:29:08,682][train][INFO] - Epoch 90/200, Val Acc=0.6447, Val Loss=1.6156, lr=0.0100
[2025-05-02 20:29:15,764][train][INFO] - Epoch 91/200, Val Acc=0.6360, Val Loss=1.6675, lr=0.0100
[2025-05-02 20:29:24,710][train][INFO] - Epoch 92/200, Val Acc=0.6386, Val Loss=1.6762, lr=0.0100
[2025-05-02 20:29:32,376][train][INFO] - Epoch 93/200, Val Acc=0.6386, Val Loss=1.6856, lr=0.0100
[2025-05-02 20:29:40,441][train][INFO] - Epoch 94/200, Val Acc=0.6410, Val Loss=1.6526, lr=0.0100
[2025-05-02 20:29:47,876][train][INFO] - Epoch 95/200, Val Acc=0.6352, Val Loss=1.7044, lr=0.0100
[2025-05-02 20:29:56,148][train][INFO] - Epoch 96/200, Val Acc=0.6267, Val Loss=1.7475, lr=0.0100
[2025-05-02 20:30:04,057][train][INFO] - Epoch 97/200, Val Acc=0.6402, Val Loss=1.6419, lr=0.0100
[2025-05-02 20:30:12,462][train][INFO] - Epoch 98/200, Val Acc=0.6160, Val Loss=1.8147, lr=0.0100
[2025-05-02 20:30:20,650][train][INFO] - Epoch 99/200, Val Acc=0.6366, Val Loss=1.6950, lr=0.0100
[2025-05-02 20:30:28,246][train][INFO] - Epoch 100/200, Val Acc=0.6427, Val Loss=1.6523, lr=0.0100
[2025-05-02 20:30:35,903][train][INFO] - Epoch 101/200, Val Acc=0.6382, Val Loss=1.7025, lr=0.0100
[2025-05-02 20:30:44,428][train][INFO] - Epoch 102/200, Val Acc=0.6374, Val Loss=1.6674, lr=0.0100
[2025-05-02 20:30:52,957][train][INFO] - Epoch 103/200, Val Acc=0.6177, Val Loss=1.7661, lr=0.0100
[2025-05-02 20:31:00,467][train][INFO] - Epoch 104/200, Val Acc=0.6304, Val Loss=1.7447, lr=0.0100
[2025-05-02 20:31:08,555][train][INFO] - Epoch 105/200, Val Acc=0.6376, Val Loss=1.6993, lr=0.0100
[2025-05-02 20:31:16,074][train][INFO] - Epoch 106/200, Val Acc=0.6329, Val Loss=1.6957, lr=0.0100
[2025-05-02 20:31:23,656][train][INFO] - Epoch 107/200, Val Acc=0.6406, Val Loss=1.6905, lr=0.0100
[2025-05-02 20:31:31,552][train][INFO] - Epoch 108/200, Val Acc=0.6409, Val Loss=1.6547, lr=0.0100
[2025-05-02 20:31:39,233][train][INFO] - Epoch 109/200, Val Acc=0.6352, Val Loss=1.6938, lr=0.0100
[2025-05-02 20:31:47,186][train][INFO] - Epoch 110/200, Val Acc=0.6382, Val Loss=1.6675, lr=0.0100
[2025-05-02 20:31:54,193][train][INFO] - Epoch 111/200, Val Acc=0.6349, Val Loss=1.7077, lr=0.0100
[2025-05-02 20:32:02,513][train][INFO] - Epoch 112/200, Val Acc=0.6404, Val Loss=1.7001, lr=0.0100
[2025-05-02 20:32:10,483][train][INFO] - Epoch 113/200, Val Acc=0.6271, Val Loss=1.7549, lr=0.0100
[2025-05-02 20:32:18,572][train][INFO] - Epoch 114/200, Val Acc=0.6353, Val Loss=1.6917, lr=0.0100
[2025-05-02 20:32:26,706][train][INFO] - Epoch 115/200, Val Acc=0.6280, Val Loss=1.7499, lr=0.0100
[2025-05-02 20:32:33,731][train][INFO] - Epoch 116/200, Val Acc=0.6450, Val Loss=1.6397, lr=0.0100
[2025-05-02 20:32:41,573][train][INFO] - Epoch 117/200, Val Acc=0.6391, Val Loss=1.7217, lr=0.0100
[2025-05-02 20:32:49,166][train][INFO] - Epoch 118/200, Val Acc=0.6283, Val Loss=1.7746, lr=0.0100
[2025-05-02 20:32:56,858][train][INFO] - Epoch 119/200, Val Acc=0.6376, Val Loss=1.7106, lr=0.0100
[2025-05-02 20:33:04,516][train][INFO] - Epoch 120/200, Val Acc=0.6472, Val Loss=1.6169, lr=0.0100
[2025-05-02 20:33:13,103][train][INFO] - Epoch 121/200, Val Acc=0.6953, Val Loss=1.3833, lr=0.0010
[2025-05-02 20:33:21,392][train][INFO] - Epoch 122/200, Val Acc=0.6945, Val Loss=1.3965, lr=0.0010
[2025-05-02 20:33:29,267][train][INFO] - Epoch 123/200, Val Acc=0.7004, Val Loss=1.3949, lr=0.0010
[2025-05-02 20:33:36,787][train][INFO] - Epoch 124/200, Val Acc=0.7005, Val Loss=1.3932, lr=0.0010
[2025-05-02 20:33:44,639][train][INFO] - Epoch 125/200, Val Acc=0.7061, Val Loss=1.4003, lr=0.0010
[2025-05-02 20:33:52,100][train][INFO] - Epoch 126/200, Val Acc=0.7042, Val Loss=1.4038, lr=0.0010
[2025-05-02 20:34:00,710][train][INFO] - Epoch 127/200, Val Acc=0.7044, Val Loss=1.4078, lr=0.0010
[2025-05-02 20:34:08,675][train][INFO] - Epoch 128/200, Val Acc=0.7056, Val Loss=1.4049, lr=0.0010
[2025-05-02 20:34:16,620][train][INFO] - Epoch 129/200, Val Acc=0.7042, Val Loss=1.4144, lr=0.0010
[2025-05-02 20:34:23,355][train][INFO] - Epoch 130/200, Val Acc=0.7056, Val Loss=1.4169, lr=0.0010
[2025-05-02 20:34:31,396][train][INFO] - Epoch 131/200, Val Acc=0.7053, Val Loss=1.4286, lr=0.0010
[2025-05-02 20:34:38,815][train][INFO] - Epoch 132/200, Val Acc=0.7070, Val Loss=1.4260, lr=0.0010
[2025-05-02 20:34:46,640][train][INFO] - Epoch 133/200, Val Acc=0.7070, Val Loss=1.4303, lr=0.0010
[2025-05-02 20:34:54,042][train][INFO] - Epoch 134/200, Val Acc=0.7073, Val Loss=1.4371, lr=0.0010
[2025-05-02 20:35:00,368][train][INFO] - Epoch 135/200, Val Acc=0.7088, Val Loss=1.4337, lr=0.0010
[2025-05-02 20:35:08,960][train][INFO] - Epoch 136/200, Val Acc=0.7072, Val Loss=1.4455, lr=0.0010
[2025-05-02 20:35:17,509][train][INFO] - Epoch 137/200, Val Acc=0.7040, Val Loss=1.4510, lr=0.0010
[2025-05-02 20:35:25,472][train][INFO] - Epoch 138/200, Val Acc=0.7067, Val Loss=1.4462, lr=0.0010
[2025-05-02 20:35:34,145][train][INFO] - Epoch 139/200, Val Acc=0.7060, Val Loss=1.4553, lr=0.0010
[2025-05-02 20:35:41,685][train][INFO] - Epoch 140/200, Val Acc=0.7067, Val Loss=1.4495, lr=0.0010
[2025-05-02 20:35:49,616][train][INFO] - Epoch 141/200, Val Acc=0.7071, Val Loss=1.4537, lr=0.0010
[2025-05-02 20:35:57,751][train][INFO] - Epoch 142/200, Val Acc=0.7066, Val Loss=1.4557, lr=0.0010
[2025-05-02 20:36:06,255][train][INFO] - Epoch 143/200, Val Acc=0.7040, Val Loss=1.4692, lr=0.0010
[2025-05-02 20:36:13,299][train][INFO] - Epoch 144/200, Val Acc=0.7072, Val Loss=1.4538, lr=0.0010
[2025-05-02 20:36:21,786][train][INFO] - Epoch 145/200, Val Acc=0.7063, Val Loss=1.4646, lr=0.0010
[2025-05-02 20:36:30,480][train][INFO] - Epoch 146/200, Val Acc=0.7040, Val Loss=1.4669, lr=0.0010
[2025-05-02 20:36:38,722][train][INFO] - Epoch 147/200, Val Acc=0.7048, Val Loss=1.4733, lr=0.0010
[2025-05-02 20:36:46,747][train][INFO] - Epoch 148/200, Val Acc=0.7074, Val Loss=1.4730, lr=0.0010
[2025-05-02 20:36:55,032][train][INFO] - Epoch 149/200, Val Acc=0.7065, Val Loss=1.4794, lr=0.0010
[2025-05-02 20:37:02,451][train][INFO] - Epoch 150/200, Val Acc=0.7064, Val Loss=1.4707, lr=0.0010
[2025-05-02 20:37:09,757][train][INFO] - Epoch 151/200, Val Acc=0.7073, Val Loss=1.4672, lr=0.0010
[2025-05-02 20:37:16,850][train][INFO] - Epoch 152/200, Val Acc=0.7069, Val Loss=1.4739, lr=0.0010
[2025-05-02 20:37:24,808][train][INFO] - Epoch 153/200, Val Acc=0.7062, Val Loss=1.4755, lr=0.0010
[2025-05-02 20:37:32,775][train][INFO] - Epoch 154/200, Val Acc=0.7080, Val Loss=1.4735, lr=0.0010
[2025-05-02 20:37:40,885][train][INFO] - Epoch 155/200, Val Acc=0.7090, Val Loss=1.4669, lr=0.0010
[2025-05-02 20:37:49,005][train][INFO] - Epoch 156/200, Val Acc=0.7111, Val Loss=1.4703, lr=0.0010
[2025-05-02 20:37:56,472][train][INFO] - Epoch 157/200, Val Acc=0.7071, Val Loss=1.4795, lr=0.0010
[2025-05-02 20:38:04,632][train][INFO] - Epoch 158/200, Val Acc=0.7075, Val Loss=1.4830, lr=0.0010
[2025-05-02 20:38:11,886][train][INFO] - Epoch 159/200, Val Acc=0.7089, Val Loss=1.4838, lr=0.0010
[2025-05-02 20:38:20,195][train][INFO] - Epoch 160/200, Val Acc=0.7079, Val Loss=1.4821, lr=0.0010
[2025-05-02 20:38:27,759][train][INFO] - Epoch 161/200, Val Acc=0.7097, Val Loss=1.4815, lr=0.0010
[2025-05-02 20:38:34,299][train][INFO] - Epoch 162/200, Val Acc=0.7081, Val Loss=1.4822, lr=0.0010
[2025-05-02 20:38:42,194][train][INFO] - Epoch 163/200, Val Acc=0.7102, Val Loss=1.4772, lr=0.0010
[2025-05-02 20:38:48,439][train][INFO] - Epoch 164/200, Val Acc=0.7099, Val Loss=1.4836, lr=0.0010
[2025-05-02 20:38:56,798][train][INFO] - Epoch 165/200, Val Acc=0.7094, Val Loss=1.4856, lr=0.0010
[2025-05-02 20:39:04,054][train][INFO] - Epoch 166/200, Val Acc=0.7092, Val Loss=1.4862, lr=0.0010
[2025-05-02 20:39:11,493][train][INFO] - Epoch 167/200, Val Acc=0.7095, Val Loss=1.4894, lr=0.0010
[2025-05-02 20:39:18,946][train][INFO] - Epoch 168/200, Val Acc=0.7088, Val Loss=1.4916, lr=0.0010
[2025-05-02 20:39:26,783][train][INFO] - Epoch 169/200, Val Acc=0.7067, Val Loss=1.5007, lr=0.0010
[2025-05-02 20:39:34,402][train][INFO] - Epoch 170/200, Val Acc=0.7083, Val Loss=1.4959, lr=0.0010
[2025-05-02 20:39:42,533][train][INFO] - Epoch 171/200, Val Acc=0.7097, Val Loss=1.4923, lr=0.0001
[2025-05-02 20:39:51,156][train][INFO] - Epoch 172/200, Val Acc=0.7110, Val Loss=1.4894, lr=0.0001
[2025-05-02 20:39:58,725][train][INFO] - Epoch 173/200, Val Acc=0.7107, Val Loss=1.4909, lr=0.0001
[2025-05-02 20:40:05,682][train][INFO] - Epoch 174/200, Val Acc=0.7107, Val Loss=1.4885, lr=0.0001
[2025-05-02 20:40:14,366][train][INFO] - Epoch 175/200, Val Acc=0.7102, Val Loss=1.4897, lr=0.0001
[2025-05-02 20:40:20,900][train][INFO] - Epoch 176/200, Val Acc=0.7119, Val Loss=1.4881, lr=0.0001
[2025-05-02 20:40:28,919][train][INFO] - Epoch 177/200, Val Acc=0.7097, Val Loss=1.4901, lr=0.0001
[2025-05-02 20:40:37,044][train][INFO] - Epoch 178/200, Val Acc=0.7097, Val Loss=1.4905, lr=0.0001
[2025-05-02 20:40:44,396][train][INFO] - Epoch 179/200, Val Acc=0.7105, Val Loss=1.4860, lr=0.0001
[2025-05-02 20:40:52,600][train][INFO] - Epoch 180/200, Val Acc=0.7097, Val Loss=1.4913, lr=0.0001
[2025-05-02 20:41:00,456][train][INFO] - Epoch 181/200, Val Acc=0.7115, Val Loss=1.4874, lr=0.0001
[2025-05-02 20:41:08,314][train][INFO] - Epoch 182/200, Val Acc=0.7101, Val Loss=1.4887, lr=0.0001
[2025-05-02 20:41:16,767][train][INFO] - Epoch 183/200, Val Acc=0.7117, Val Loss=1.4873, lr=0.0001
[2025-05-02 20:41:24,562][train][INFO] - Epoch 184/200, Val Acc=0.7117, Val Loss=1.4902, lr=0.0001
[2025-05-02 20:41:32,565][train][INFO] - Epoch 185/200, Val Acc=0.7104, Val Loss=1.4885, lr=0.0001
[2025-05-02 20:41:40,996][train][INFO] - Epoch 186/200, Val Acc=0.7115, Val Loss=1.4875, lr=0.0001
[2025-05-02 20:41:48,622][train][INFO] - Epoch 187/200, Val Acc=0.7120, Val Loss=1.4875, lr=0.0001
[2025-05-02 20:41:57,169][train][INFO] - Epoch 188/200, Val Acc=0.7111, Val Loss=1.4879, lr=0.0001
[2025-05-02 20:42:05,354][train][INFO] - Epoch 189/200, Val Acc=0.7103, Val Loss=1.4917, lr=0.0001
[2025-05-02 20:42:12,870][train][INFO] - Epoch 190/200, Val Acc=0.7112, Val Loss=1.4935, lr=0.0001
[2025-05-02 20:42:20,967][train][INFO] - Epoch 191/200, Val Acc=0.7111, Val Loss=1.4898, lr=0.0001
[2025-05-02 20:42:28,799][train][INFO] - Epoch 192/200, Val Acc=0.7117, Val Loss=1.4848, lr=0.0001
[2025-05-02 20:42:36,858][train][INFO] - Epoch 193/200, Val Acc=0.7107, Val Loss=1.4896, lr=0.0001
[2025-05-02 20:42:45,175][train][INFO] - Epoch 194/200, Val Acc=0.7110, Val Loss=1.4886, lr=0.0001
[2025-05-02 20:42:53,284][train][INFO] - Epoch 195/200, Val Acc=0.7127, Val Loss=1.4901, lr=0.0001
[2025-05-02 20:43:01,227][train][INFO] - Epoch 196/200, Val Acc=0.7114, Val Loss=1.4882, lr=0.0001
[2025-05-02 20:43:09,281][train][INFO] - Epoch 197/200, Val Acc=0.7104, Val Loss=1.4889, lr=0.0001
[2025-05-02 20:43:18,200][train][INFO] - Epoch 198/200, Val Acc=0.7139, Val Loss=1.4873, lr=0.0001
[2025-05-02 20:43:25,675][train][INFO] - Epoch 199/200, Val Acc=0.7111, Val Loss=1.4901, lr=0.0001
[2025-05-02 20:43:34,448][train][INFO] - Epoch 200/200, Val Acc=0.7111, Val Loss=1.4858, lr=0.0001
[2025-05-02 20:43:39,353][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7139
[2025-05-02 20:43:48,843][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 20:43:48,843][Progressive pruning][INFO] - Current speed up: 3.02
[2025-05-02 20:43:53,676][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 20:44:01,456][train][INFO] - Epoch 1/200, Val Acc=0.1884, Val Loss=3.0812, lr=0.0100
[2025-05-02 20:44:09,191][train][INFO] - Epoch 2/200, Val Acc=0.2750, Val Loss=2.7734, lr=0.0100
[2025-05-02 20:44:16,810][train][INFO] - Epoch 3/200, Val Acc=0.3298, Val Loss=2.5721, lr=0.0100
[2025-05-02 20:44:24,942][train][INFO] - Epoch 4/200, Val Acc=0.3730, Val Loss=2.3851, lr=0.0100
[2025-05-02 20:44:33,217][train][INFO] - Epoch 5/200, Val Acc=0.4299, Val Loss=2.1977, lr=0.0100
[2025-05-02 20:44:40,964][train][INFO] - Epoch 6/200, Val Acc=0.3976, Val Loss=2.3729, lr=0.0100
[2025-05-02 20:44:48,421][train][INFO] - Epoch 7/200, Val Acc=0.4331, Val Loss=2.1923, lr=0.0100
[2025-05-02 20:44:55,827][train][INFO] - Epoch 8/200, Val Acc=0.4377, Val Loss=2.2480, lr=0.0100
[2025-05-02 20:45:02,560][train][INFO] - Epoch 9/200, Val Acc=0.4570, Val Loss=2.1268, lr=0.0100
[2025-05-02 20:45:10,296][train][INFO] - Epoch 10/200, Val Acc=0.4791, Val Loss=2.0106, lr=0.0100
[2025-05-02 20:45:17,173][train][INFO] - Epoch 11/200, Val Acc=0.4448, Val Loss=2.1991, lr=0.0100
[2025-05-02 20:45:24,816][train][INFO] - Epoch 12/200, Val Acc=0.4667, Val Loss=2.0640, lr=0.0100
[2025-05-02 20:45:32,646][train][INFO] - Epoch 13/200, Val Acc=0.4871, Val Loss=2.0130, lr=0.0100
[2025-05-02 20:45:39,813][train][INFO] - Epoch 14/200, Val Acc=0.4867, Val Loss=2.0944, lr=0.0100
[2025-05-02 20:45:47,382][train][INFO] - Epoch 15/200, Val Acc=0.4573, Val Loss=2.2374, lr=0.0100
[2025-05-02 20:45:54,713][train][INFO] - Epoch 16/200, Val Acc=0.4603, Val Loss=2.1993, lr=0.0100
[2025-05-02 20:46:02,644][train][INFO] - Epoch 17/200, Val Acc=0.4916, Val Loss=2.1013, lr=0.0100
[2025-05-02 20:46:10,006][train][INFO] - Epoch 18/200, Val Acc=0.4821, Val Loss=2.0974, lr=0.0100
[2025-05-02 20:46:16,742][train][INFO] - Epoch 19/200, Val Acc=0.5131, Val Loss=1.9528, lr=0.0100
[2025-05-02 20:46:24,793][train][INFO] - Epoch 20/200, Val Acc=0.4620, Val Loss=2.2824, lr=0.0100
[2025-05-02 20:46:32,057][train][INFO] - Epoch 21/200, Val Acc=0.5186, Val Loss=1.9096, lr=0.0100
[2025-05-02 20:46:39,363][train][INFO] - Epoch 22/200, Val Acc=0.4371, Val Loss=2.4002, lr=0.0100
[2025-05-02 20:46:47,066][train][INFO] - Epoch 23/200, Val Acc=0.5169, Val Loss=1.9251, lr=0.0100
[2025-05-02 20:46:54,691][train][INFO] - Epoch 24/200, Val Acc=0.5203, Val Loss=1.8965, lr=0.0100
[2025-05-02 20:47:02,232][train][INFO] - Epoch 25/200, Val Acc=0.4762, Val Loss=2.2209, lr=0.0100
[2025-05-02 20:47:09,819][train][INFO] - Epoch 26/200, Val Acc=0.5154, Val Loss=2.0292, lr=0.0100
[2025-05-02 20:47:17,524][train][INFO] - Epoch 27/200, Val Acc=0.4988, Val Loss=2.1063, lr=0.0100
[2025-05-02 20:47:25,114][train][INFO] - Epoch 28/200, Val Acc=0.4883, Val Loss=2.1542, lr=0.0100
[2025-05-02 20:47:32,614][train][INFO] - Epoch 29/200, Val Acc=0.5333, Val Loss=1.8912, lr=0.0100
[2025-05-02 20:47:40,358][train][INFO] - Epoch 30/200, Val Acc=0.5048, Val Loss=2.0770, lr=0.0100
[2025-05-02 20:47:46,989][train][INFO] - Epoch 31/200, Val Acc=0.5173, Val Loss=2.0048, lr=0.0100
[2025-05-02 20:47:54,505][train][INFO] - Epoch 32/200, Val Acc=0.5319, Val Loss=1.9292, lr=0.0100
[2025-05-02 20:48:01,612][train][INFO] - Epoch 33/200, Val Acc=0.4973, Val Loss=2.0787, lr=0.0100
[2025-05-02 20:48:09,012][train][INFO] - Epoch 34/200, Val Acc=0.5080, Val Loss=2.0905, lr=0.0100
[2025-05-02 20:48:16,307][train][INFO] - Epoch 35/200, Val Acc=0.4999, Val Loss=2.1992, lr=0.0100
[2025-05-02 20:48:24,618][train][INFO] - Epoch 36/200, Val Acc=0.5131, Val Loss=2.0110, lr=0.0100
[2025-05-02 20:48:32,464][train][INFO] - Epoch 37/200, Val Acc=0.5251, Val Loss=1.9596, lr=0.0100
[2025-05-02 20:48:40,189][train][INFO] - Epoch 38/200, Val Acc=0.5276, Val Loss=1.9430, lr=0.0100
[2025-05-02 20:48:48,695][train][INFO] - Epoch 39/200, Val Acc=0.5302, Val Loss=1.9635, lr=0.0100
[2025-05-02 20:48:56,315][train][INFO] - Epoch 40/200, Val Acc=0.5427, Val Loss=1.9018, lr=0.0100
[2025-05-02 20:49:04,553][train][INFO] - Epoch 41/200, Val Acc=0.5080, Val Loss=2.0472, lr=0.0100
[2025-05-02 20:49:12,390][train][INFO] - Epoch 42/200, Val Acc=0.4945, Val Loss=2.2357, lr=0.0100
[2025-05-02 20:49:20,143][train][INFO] - Epoch 43/200, Val Acc=0.5416, Val Loss=1.9191, lr=0.0100
[2025-05-02 20:49:27,963][train][INFO] - Epoch 44/200, Val Acc=0.5619, Val Loss=1.7897, lr=0.0100
[2025-05-02 20:49:36,105][train][INFO] - Epoch 45/200, Val Acc=0.5500, Val Loss=1.8434, lr=0.0100
[2025-05-02 20:49:43,553][train][INFO] - Epoch 46/200, Val Acc=0.5378, Val Loss=1.9510, lr=0.0100
[2025-05-02 20:49:50,682][train][INFO] - Epoch 47/200, Val Acc=0.5053, Val Loss=2.1545, lr=0.0100
[2025-05-02 20:49:58,607][train][INFO] - Epoch 48/200, Val Acc=0.5228, Val Loss=2.0204, lr=0.0100
[2025-05-02 20:50:06,399][train][INFO] - Epoch 49/200, Val Acc=0.5258, Val Loss=2.0277, lr=0.0100
[2025-05-02 20:50:14,090][train][INFO] - Epoch 50/200, Val Acc=0.5565, Val Loss=1.8206, lr=0.0100
[2025-05-02 20:50:22,371][train][INFO] - Epoch 51/200, Val Acc=0.5417, Val Loss=1.8598, lr=0.0100
[2025-05-02 20:50:30,344][train][INFO] - Epoch 52/200, Val Acc=0.5372, Val Loss=1.9856, lr=0.0100
[2025-05-02 20:50:37,976][train][INFO] - Epoch 53/200, Val Acc=0.5461, Val Loss=1.9313, lr=0.0100
[2025-05-02 20:50:45,963][train][INFO] - Epoch 54/200, Val Acc=0.5361, Val Loss=1.9690, lr=0.0100
[2025-05-02 20:50:54,145][train][INFO] - Epoch 55/200, Val Acc=0.5342, Val Loss=2.0032, lr=0.0100
[2025-05-02 20:51:00,497][train][INFO] - Epoch 56/200, Val Acc=0.5440, Val Loss=1.8944, lr=0.0100
[2025-05-02 20:51:08,819][train][INFO] - Epoch 57/200, Val Acc=0.5047, Val Loss=2.1362, lr=0.0100
[2025-05-02 20:51:16,513][train][INFO] - Epoch 58/200, Val Acc=0.5256, Val Loss=2.0507, lr=0.0100
[2025-05-02 20:51:24,150][train][INFO] - Epoch 59/200, Val Acc=0.5541, Val Loss=1.8930, lr=0.0100
[2025-05-02 20:51:31,380][train][INFO] - Epoch 60/200, Val Acc=0.5432, Val Loss=1.9469, lr=0.0100
[2025-05-02 20:51:38,079][train][INFO] - Epoch 61/200, Val Acc=0.5500, Val Loss=1.8875, lr=0.0100
[2025-05-02 20:51:46,364][train][INFO] - Epoch 62/200, Val Acc=0.5218, Val Loss=2.1041, lr=0.0100
[2025-05-02 20:51:54,840][train][INFO] - Epoch 63/200, Val Acc=0.5216, Val Loss=2.0873, lr=0.0100
[2025-05-02 20:52:01,979][train][INFO] - Epoch 64/200, Val Acc=0.5400, Val Loss=1.9353, lr=0.0100
[2025-05-02 20:52:10,117][train][INFO] - Epoch 65/200, Val Acc=0.5339, Val Loss=1.9847, lr=0.0100
[2025-05-02 20:52:18,056][train][INFO] - Epoch 66/200, Val Acc=0.5221, Val Loss=2.0969, lr=0.0100
[2025-05-02 20:52:25,418][train][INFO] - Epoch 67/200, Val Acc=0.5069, Val Loss=2.1509, lr=0.0100
[2025-05-02 20:52:32,655][train][INFO] - Epoch 68/200, Val Acc=0.5391, Val Loss=1.9850, lr=0.0100
[2025-05-02 20:52:40,031][train][INFO] - Epoch 69/200, Val Acc=0.5450, Val Loss=1.9126, lr=0.0100
[2025-05-02 20:52:47,623][train][INFO] - Epoch 70/200, Val Acc=0.5428, Val Loss=1.9414, lr=0.0100
[2025-05-02 20:52:55,185][train][INFO] - Epoch 71/200, Val Acc=0.5351, Val Loss=1.9721, lr=0.0100
[2025-05-02 20:53:02,647][train][INFO] - Epoch 72/200, Val Acc=0.5426, Val Loss=1.9436, lr=0.0100
[2025-05-02 20:53:10,501][train][INFO] - Epoch 73/200, Val Acc=0.5504, Val Loss=1.8642, lr=0.0100
[2025-05-02 20:53:17,466][train][INFO] - Epoch 74/200, Val Acc=0.5605, Val Loss=1.8008, lr=0.0100
[2025-05-02 20:53:25,128][train][INFO] - Epoch 75/200, Val Acc=0.5439, Val Loss=1.9310, lr=0.0100
[2025-05-02 20:53:32,520][train][INFO] - Epoch 76/200, Val Acc=0.5519, Val Loss=1.9198, lr=0.0100
[2025-05-02 20:53:40,443][train][INFO] - Epoch 77/200, Val Acc=0.5338, Val Loss=1.9438, lr=0.0100
[2025-05-02 20:53:48,627][train][INFO] - Epoch 78/200, Val Acc=0.5569, Val Loss=1.8436, lr=0.0100
[2025-05-02 20:53:56,539][train][INFO] - Epoch 79/200, Val Acc=0.5079, Val Loss=2.2162, lr=0.0100
[2025-05-02 20:54:03,544][train][INFO] - Epoch 80/200, Val Acc=0.5393, Val Loss=1.9682, lr=0.0100
[2025-05-02 20:54:11,395][train][INFO] - Epoch 81/200, Val Acc=0.5386, Val Loss=1.9789, lr=0.0100
[2025-05-02 20:54:19,111][train][INFO] - Epoch 82/200, Val Acc=0.5268, Val Loss=2.0533, lr=0.0100
[2025-05-02 20:54:26,640][train][INFO] - Epoch 83/200, Val Acc=0.5525, Val Loss=1.8970, lr=0.0100
[2025-05-02 20:54:33,507][train][INFO] - Epoch 84/200, Val Acc=0.5473, Val Loss=1.9079, lr=0.0100
[2025-05-02 20:54:40,448][train][INFO] - Epoch 85/200, Val Acc=0.5333, Val Loss=1.9985, lr=0.0100
[2025-05-02 20:54:47,637][train][INFO] - Epoch 86/200, Val Acc=0.5407, Val Loss=1.9941, lr=0.0100
[2025-05-02 20:54:55,474][train][INFO] - Epoch 87/200, Val Acc=0.5616, Val Loss=1.8380, lr=0.0100
[2025-05-02 20:55:02,957][train][INFO] - Epoch 88/200, Val Acc=0.5555, Val Loss=1.9220, lr=0.0100
[2025-05-02 20:55:10,025][train][INFO] - Epoch 89/200, Val Acc=0.5664, Val Loss=1.8414, lr=0.0100
[2025-05-02 20:55:17,843][train][INFO] - Epoch 90/200, Val Acc=0.5420, Val Loss=2.0166, lr=0.0100
[2025-05-02 20:55:25,190][train][INFO] - Epoch 91/200, Val Acc=0.5295, Val Loss=2.0573, lr=0.0100
[2025-05-02 20:55:32,636][train][INFO] - Epoch 92/200, Val Acc=0.5470, Val Loss=1.9133, lr=0.0100
[2025-05-02 20:55:40,120][train][INFO] - Epoch 93/200, Val Acc=0.5443, Val Loss=1.9968, lr=0.0100
[2025-05-02 20:55:47,178][train][INFO] - Epoch 94/200, Val Acc=0.5487, Val Loss=1.9587, lr=0.0100
[2025-05-02 20:55:54,799][train][INFO] - Epoch 95/200, Val Acc=0.5508, Val Loss=1.9384, lr=0.0100
[2025-05-02 20:56:02,121][train][INFO] - Epoch 96/200, Val Acc=0.5437, Val Loss=1.9930, lr=0.0100
[2025-05-02 20:56:09,474][train][INFO] - Epoch 97/200, Val Acc=0.5415, Val Loss=1.9424, lr=0.0100
[2025-05-02 20:56:17,275][train][INFO] - Epoch 98/200, Val Acc=0.5245, Val Loss=2.0357, lr=0.0100
[2025-05-02 20:56:24,350][train][INFO] - Epoch 99/200, Val Acc=0.5541, Val Loss=1.9093, lr=0.0100
[2025-05-02 20:56:32,399][train][INFO] - Epoch 100/200, Val Acc=0.4934, Val Loss=2.2576, lr=0.0100
[2025-05-02 20:56:39,555][train][INFO] - Epoch 101/200, Val Acc=0.5530, Val Loss=1.9356, lr=0.0100
[2025-05-02 20:56:47,267][train][INFO] - Epoch 102/200, Val Acc=0.5417, Val Loss=1.9568, lr=0.0100
[2025-05-02 20:56:55,037][train][INFO] - Epoch 103/200, Val Acc=0.5448, Val Loss=1.9135, lr=0.0100
[2025-05-02 20:57:03,109][train][INFO] - Epoch 104/200, Val Acc=0.5458, Val Loss=1.9531, lr=0.0100
[2025-05-02 20:57:10,365][train][INFO] - Epoch 105/200, Val Acc=0.5725, Val Loss=1.8331, lr=0.0100
[2025-05-02 20:57:18,047][train][INFO] - Epoch 106/200, Val Acc=0.5361, Val Loss=2.0242, lr=0.0100
[2025-05-02 20:57:25,374][train][INFO] - Epoch 107/200, Val Acc=0.5236, Val Loss=2.1421, lr=0.0100
[2025-05-02 20:57:32,984][train][INFO] - Epoch 108/200, Val Acc=0.5290, Val Loss=2.0812, lr=0.0100
[2025-05-02 20:57:40,591][train][INFO] - Epoch 109/200, Val Acc=0.5343, Val Loss=2.0109, lr=0.0100
[2025-05-02 20:57:47,730][train][INFO] - Epoch 110/200, Val Acc=0.5398, Val Loss=2.0157, lr=0.0100
[2025-05-02 20:57:55,280][train][INFO] - Epoch 111/200, Val Acc=0.5328, Val Loss=1.9987, lr=0.0100
[2025-05-02 20:58:02,407][train][INFO] - Epoch 112/200, Val Acc=0.5383, Val Loss=1.9706, lr=0.0100
[2025-05-02 20:58:10,397][train][INFO] - Epoch 113/200, Val Acc=0.5216, Val Loss=2.1093, lr=0.0100
[2025-05-02 20:58:18,293][train][INFO] - Epoch 114/200, Val Acc=0.5202, Val Loss=2.1755, lr=0.0100
[2025-05-02 20:58:25,071][train][INFO] - Epoch 115/200, Val Acc=0.5302, Val Loss=2.0797, lr=0.0100
[2025-05-02 20:58:32,591][train][INFO] - Epoch 116/200, Val Acc=0.5478, Val Loss=1.9909, lr=0.0100
[2025-05-02 20:58:40,543][train][INFO] - Epoch 117/200, Val Acc=0.5656, Val Loss=1.8656, lr=0.0100
[2025-05-02 20:58:48,274][train][INFO] - Epoch 118/200, Val Acc=0.5362, Val Loss=2.0424, lr=0.0100
[2025-05-02 20:58:56,745][train][INFO] - Epoch 119/200, Val Acc=0.5565, Val Loss=1.9117, lr=0.0100
[2025-05-02 20:59:03,795][train][INFO] - Epoch 120/200, Val Acc=0.5418, Val Loss=2.0099, lr=0.0100
[2025-05-02 20:59:11,469][train][INFO] - Epoch 121/200, Val Acc=0.6190, Val Loss=1.5814, lr=0.0010
[2025-05-02 20:59:18,416][train][INFO] - Epoch 122/200, Val Acc=0.6241, Val Loss=1.5889, lr=0.0010
[2025-05-02 20:59:26,652][train][INFO] - Epoch 123/200, Val Acc=0.6241, Val Loss=1.5991, lr=0.0010
[2025-05-02 20:59:33,649][train][INFO] - Epoch 124/200, Val Acc=0.6244, Val Loss=1.6008, lr=0.0010
[2025-05-02 20:59:41,274][train][INFO] - Epoch 125/200, Val Acc=0.6244, Val Loss=1.6140, lr=0.0010
[2025-05-02 20:59:48,512][train][INFO] - Epoch 126/200, Val Acc=0.6269, Val Loss=1.6072, lr=0.0010
[2025-05-02 20:59:56,029][train][INFO] - Epoch 127/200, Val Acc=0.6247, Val Loss=1.6156, lr=0.0010
[2025-05-02 21:00:03,377][train][INFO] - Epoch 128/200, Val Acc=0.6260, Val Loss=1.6216, lr=0.0010
[2025-05-02 21:00:11,321][train][INFO] - Epoch 129/200, Val Acc=0.6281, Val Loss=1.6296, lr=0.0010
[2025-05-02 21:00:18,543][train][INFO] - Epoch 130/200, Val Acc=0.6269, Val Loss=1.6393, lr=0.0010
[2025-05-02 21:00:26,331][train][INFO] - Epoch 131/200, Val Acc=0.6268, Val Loss=1.6478, lr=0.0010
[2025-05-02 21:00:33,659][train][INFO] - Epoch 132/200, Val Acc=0.6252, Val Loss=1.6471, lr=0.0010
[2025-05-02 21:00:40,916][train][INFO] - Epoch 133/200, Val Acc=0.6279, Val Loss=1.6555, lr=0.0010
[2025-05-02 21:00:48,443][train][INFO] - Epoch 134/200, Val Acc=0.6257, Val Loss=1.6660, lr=0.0010
[2025-05-02 21:00:56,026][train][INFO] - Epoch 135/200, Val Acc=0.6292, Val Loss=1.6701, lr=0.0010
[2025-05-02 21:01:03,329][train][INFO] - Epoch 136/200, Val Acc=0.6263, Val Loss=1.6717, lr=0.0010
[2025-05-02 21:01:10,974][train][INFO] - Epoch 137/200, Val Acc=0.6280, Val Loss=1.6866, lr=0.0010
[2025-05-02 21:01:18,053][train][INFO] - Epoch 138/200, Val Acc=0.6221, Val Loss=1.6735, lr=0.0010
[2025-05-02 21:01:25,986][train][INFO] - Epoch 139/200, Val Acc=0.6247, Val Loss=1.6915, lr=0.0010
[2025-05-02 21:01:33,247][train][INFO] - Epoch 140/200, Val Acc=0.6258, Val Loss=1.6847, lr=0.0010
[2025-05-02 21:01:40,928][train][INFO] - Epoch 141/200, Val Acc=0.6237, Val Loss=1.7010, lr=0.0010
[2025-05-02 21:01:48,425][train][INFO] - Epoch 142/200, Val Acc=0.6234, Val Loss=1.7091, lr=0.0010
[2025-05-02 21:01:56,031][train][INFO] - Epoch 143/200, Val Acc=0.6231, Val Loss=1.7178, lr=0.0010
[2025-05-02 21:02:03,213][train][INFO] - Epoch 144/200, Val Acc=0.6252, Val Loss=1.7287, lr=0.0010
[2025-05-02 21:02:10,139][train][INFO] - Epoch 145/200, Val Acc=0.6240, Val Loss=1.7323, lr=0.0010
[2025-05-02 21:02:17,061][train][INFO] - Epoch 146/200, Val Acc=0.6267, Val Loss=1.7361, lr=0.0010
[2025-05-02 21:02:24,230][train][INFO] - Epoch 147/200, Val Acc=0.6225, Val Loss=1.7428, lr=0.0010
[2025-05-02 21:02:32,093][train][INFO] - Epoch 148/200, Val Acc=0.6245, Val Loss=1.7346, lr=0.0010
[2025-05-02 21:02:39,720][train][INFO] - Epoch 149/200, Val Acc=0.6237, Val Loss=1.7340, lr=0.0010
[2025-05-02 21:02:46,906][train][INFO] - Epoch 150/200, Val Acc=0.6239, Val Loss=1.7573, lr=0.0010
[2025-05-02 21:02:54,144][train][INFO] - Epoch 151/200, Val Acc=0.6261, Val Loss=1.7363, lr=0.0010
[2025-05-02 21:03:01,716][train][INFO] - Epoch 152/200, Val Acc=0.6245, Val Loss=1.7621, lr=0.0010
[2025-05-02 21:03:09,802][train][INFO] - Epoch 153/200, Val Acc=0.6257, Val Loss=1.7648, lr=0.0010
[2025-05-02 21:03:17,828][train][INFO] - Epoch 154/200, Val Acc=0.6251, Val Loss=1.7770, lr=0.0010
[2025-05-02 21:03:25,520][train][INFO] - Epoch 155/200, Val Acc=0.6250, Val Loss=1.7680, lr=0.0010
[2025-05-02 21:03:26,281][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 6.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 200
        lr: 0.01
        lr_decay_milestones: 120,170
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 50

[2025-05-02 21:03:26,337][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 21:03:26,337][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 21:03:26,337][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 21:03:33,615][train][INFO] - Epoch 156/200, Val Acc=0.6209, Val Loss=1.7754, lr=0.0010
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 21:03:42,167][train][INFO] - Epoch 157/200, Val Acc=0.6229, Val Loss=1.7890, lr=0.0010
[2025-05-02 21:03:43,591][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 21:03:50,179][train][INFO] - Epoch 158/200, Val Acc=0.6224, Val Loss=1.7837, lr=0.0010
[2025-05-02 21:03:51,913][train][INFO] - Epoch 1/100, Val Acc=0.0947, Val Loss=3.8279, lr=0.0100
[2025-05-02 21:03:58,129][train][INFO] - Epoch 159/200, Val Acc=0.6248, Val Loss=1.8034, lr=0.0010
[2025-05-02 21:04:00,374][train][INFO] - Epoch 2/100, Val Acc=0.2397, Val Loss=2.8117, lr=0.0100
[2025-05-02 21:04:08,275][train][INFO] - Epoch 3/100, Val Acc=0.3455, Val Loss=2.4270, lr=0.0100
[2025-05-02 21:04:17,085][train][INFO] - Epoch 4/100, Val Acc=0.3893, Val Loss=2.2631, lr=0.0100
[2025-05-02 21:04:24,895][train][INFO] - Epoch 5/100, Val Acc=0.4173, Val Loss=2.2595, lr=0.0100
[2025-05-02 21:04:26,531][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 6.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 200
        lr: 0.01
        lr_decay_milestones: 120,170
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-02 21:04:26,583][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 21:04:26,583][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 21:04:26,583][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 21:04:34,149][train][INFO] - Epoch 6/100, Val Acc=0.4231, Val Loss=2.3047, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 21:04:42,057][train][INFO] - Epoch 7/100, Val Acc=0.4580, Val Loss=2.0862, lr=0.0100
[2025-05-02 21:04:43,517][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 21:04:49,909][train][INFO] - Epoch 8/100, Val Acc=0.5155, Val Loss=1.8029, lr=0.0100
[2025-05-02 21:04:52,193][train][INFO] - Epoch 1/100, Val Acc=0.1656, Val Loss=3.1948, lr=0.0100
[2025-05-02 21:04:56,673][train][INFO] - Epoch 9/100, Val Acc=0.5062, Val Loss=1.9032, lr=0.0100
[2025-05-02 21:04:59,961][train][INFO] - Epoch 2/100, Val Acc=0.3536, Val Loss=2.3640, lr=0.0100
[2025-05-02 21:05:03,681][train][INFO] - Epoch 10/100, Val Acc=0.5143, Val Loss=1.9413, lr=0.0100
[2025-05-02 21:05:07,965][train][INFO] - Epoch 3/100, Val Acc=0.4319, Val Loss=2.1507, lr=0.0100
[2025-05-02 21:05:12,241][train][INFO] - Epoch 11/100, Val Acc=0.5601, Val Loss=1.6663, lr=0.0100
[2025-05-02 21:05:16,608][train][INFO] - Epoch 4/100, Val Acc=0.4925, Val Loss=1.8823, lr=0.0100
[2025-05-02 21:05:21,044][train][INFO] - Epoch 12/100, Val Acc=0.5728, Val Loss=1.6154, lr=0.0100
[2025-05-02 21:05:24,677][train][INFO] - Epoch 5/100, Val Acc=0.5224, Val Loss=1.8290, lr=0.0100
[2025-05-02 21:05:29,029][train][INFO] - Epoch 13/100, Val Acc=0.5560, Val Loss=1.7096, lr=0.0100
[2025-05-02 21:05:32,836][train][INFO] - Epoch 6/100, Val Acc=0.5208, Val Loss=1.8555, lr=0.0100
[2025-05-02 21:05:37,110][train][INFO] - Epoch 14/100, Val Acc=0.5529, Val Loss=1.7927, lr=0.0100
[2025-05-02 21:05:40,754][train][INFO] - Epoch 7/100, Val Acc=0.5505, Val Loss=1.7337, lr=0.0100
[2025-05-02 21:05:45,457][train][INFO] - Epoch 15/100, Val Acc=0.5709, Val Loss=1.6864, lr=0.0100
[2025-05-02 21:05:49,118][train][INFO] - Epoch 8/100, Val Acc=0.5731, Val Loss=1.6407, lr=0.0100
[2025-05-02 21:05:53,705][train][INFO] - Epoch 16/100, Val Acc=0.5575, Val Loss=1.7715, lr=0.0100
[2025-05-02 21:05:57,417][train][INFO] - Epoch 9/100, Val Acc=0.5858, Val Loss=1.5636, lr=0.0100
[2025-05-02 21:06:01,457][train][INFO] - Epoch 17/100, Val Acc=0.5632, Val Loss=1.7910, lr=0.0100
[2025-05-02 21:06:05,489][train][INFO] - Epoch 10/100, Val Acc=0.6031, Val Loss=1.5387, lr=0.0100
[2025-05-02 21:06:09,815][train][INFO] - Epoch 18/100, Val Acc=0.5899, Val Loss=1.6480, lr=0.0100
[2025-05-02 21:06:13,820][train][INFO] - Epoch 11/100, Val Acc=0.6026, Val Loss=1.5312, lr=0.0100
[2025-05-02 21:06:17,268][train][INFO] - Epoch 19/100, Val Acc=0.5959, Val Loss=1.5764, lr=0.0100
[2025-05-02 21:06:22,256][train][INFO] - Epoch 12/100, Val Acc=0.6125, Val Loss=1.5101, lr=0.0100
[2025-05-02 21:06:25,172][train][INFO] - Epoch 20/100, Val Acc=0.5723, Val Loss=1.6749, lr=0.0100
[2025-05-02 21:06:30,136][train][INFO] - Epoch 13/100, Val Acc=0.5865, Val Loss=1.6591, lr=0.0100
[2025-05-02 21:06:33,319][train][INFO] - Epoch 21/100, Val Acc=0.6013, Val Loss=1.6310, lr=0.0100
[2025-05-02 21:06:38,214][train][INFO] - Epoch 14/100, Val Acc=0.6221, Val Loss=1.4760, lr=0.0100
[2025-05-02 21:06:41,337][train][INFO] - Epoch 22/100, Val Acc=0.5959, Val Loss=1.6240, lr=0.0100
[2025-05-02 21:06:46,545][train][INFO] - Epoch 15/100, Val Acc=0.6008, Val Loss=1.5581, lr=0.0100
[2025-05-02 21:06:49,239][train][INFO] - Epoch 23/100, Val Acc=0.5887, Val Loss=1.6339, lr=0.0100
[2025-05-02 21:06:55,006][train][INFO] - Epoch 16/100, Val Acc=0.5950, Val Loss=1.6448, lr=0.0100
[2025-05-02 21:06:57,391][train][INFO] - Epoch 24/100, Val Acc=0.6156, Val Loss=1.5686, lr=0.0100
[2025-05-02 21:07:03,091][train][INFO] - Epoch 17/100, Val Acc=0.6048, Val Loss=1.5769, lr=0.0100
[2025-05-02 21:07:05,186][train][INFO] - Epoch 25/100, Val Acc=0.6188, Val Loss=1.4982, lr=0.0100
[2025-05-02 21:07:11,222][train][INFO] - Epoch 18/100, Val Acc=0.6307, Val Loss=1.4623, lr=0.0100
[2025-05-02 21:07:12,871][train][INFO] - Epoch 26/100, Val Acc=0.6196, Val Loss=1.5399, lr=0.0100
[2025-05-02 21:07:19,508][train][INFO] - Epoch 19/100, Val Acc=0.6108, Val Loss=1.5797, lr=0.0100
[2025-05-02 21:07:21,539][train][INFO] - Epoch 27/100, Val Acc=0.5916, Val Loss=1.6858, lr=0.0100
[2025-05-02 21:07:27,719][train][INFO] - Epoch 20/100, Val Acc=0.6146, Val Loss=1.5706, lr=0.0100
[2025-05-02 21:07:29,695][train][INFO] - Epoch 28/100, Val Acc=0.6145, Val Loss=1.5796, lr=0.0100
[2025-05-02 21:07:36,246][train][INFO] - Epoch 21/100, Val Acc=0.6322, Val Loss=1.4814, lr=0.0100
[2025-05-02 21:07:37,980][train][INFO] - Epoch 29/100, Val Acc=0.6069, Val Loss=1.6413, lr=0.0100
[2025-05-02 21:07:44,644][train][INFO] - Epoch 22/100, Val Acc=0.6236, Val Loss=1.5283, lr=0.0100
[2025-05-02 21:07:45,438][train][INFO] - Epoch 30/100, Val Acc=0.6284, Val Loss=1.4875, lr=0.0100
[2025-05-02 21:07:53,121][train][INFO] - Epoch 23/100, Val Acc=0.6347, Val Loss=1.4687, lr=0.0100
[2025-05-02 21:07:53,387][train][INFO] - Epoch 31/100, Val Acc=0.6267, Val Loss=1.5125, lr=0.0100
[2025-05-02 21:08:01,799][train][INFO] - Epoch 24/100, Val Acc=0.6452, Val Loss=1.4568, lr=0.0100
[2025-05-02 21:08:01,912][train][INFO] - Epoch 32/100, Val Acc=0.6147, Val Loss=1.5825, lr=0.0100
[2025-05-02 21:08:09,845][train][INFO] - Epoch 25/100, Val Acc=0.6310, Val Loss=1.5355, lr=0.0100
[2025-05-02 21:08:09,924][train][INFO] - Epoch 33/100, Val Acc=0.6228, Val Loss=1.5887, lr=0.0100
[2025-05-02 21:08:18,175][train][INFO] - Epoch 34/100, Val Acc=0.6072, Val Loss=1.6901, lr=0.0100
[2025-05-02 21:08:18,386][train][INFO] - Epoch 26/100, Val Acc=0.6261, Val Loss=1.5884, lr=0.0100
[2025-05-02 21:08:26,025][train][INFO] - Epoch 27/100, Val Acc=0.6376, Val Loss=1.4824, lr=0.0100
[2025-05-02 21:08:26,709][train][INFO] - Epoch 35/100, Val Acc=0.6041, Val Loss=1.6767, lr=0.0100
[2025-05-02 21:08:33,945][train][INFO] - Epoch 36/100, Val Acc=0.6028, Val Loss=1.6668, lr=0.0100
[2025-05-02 21:08:34,074][train][INFO] - Epoch 28/100, Val Acc=0.6306, Val Loss=1.5536, lr=0.0100
[2025-05-02 21:08:41,794][train][INFO] - Epoch 37/100, Val Acc=0.6257, Val Loss=1.5896, lr=0.0100
[2025-05-02 21:08:42,825][train][INFO] - Epoch 29/100, Val Acc=0.6305, Val Loss=1.5611, lr=0.0100
[2025-05-02 21:08:50,565][train][INFO] - Epoch 38/100, Val Acc=0.6118, Val Loss=1.6628, lr=0.0100
[2025-05-02 21:08:50,764][train][INFO] - Epoch 30/100, Val Acc=0.6494, Val Loss=1.4854, lr=0.0100
[2025-05-02 21:08:58,554][train][INFO] - Epoch 39/100, Val Acc=0.6225, Val Loss=1.5956, lr=0.0100
[2025-05-02 21:08:59,008][train][INFO] - Epoch 31/100, Val Acc=0.6348, Val Loss=1.5276, lr=0.0100
[2025-05-02 21:09:06,718][train][INFO] - Epoch 40/100, Val Acc=0.6094, Val Loss=1.6861, lr=0.0100
[2025-05-02 21:09:07,340][train][INFO] - Epoch 32/100, Val Acc=0.6472, Val Loss=1.5131, lr=0.0100
[2025-05-02 21:09:15,353][train][INFO] - Epoch 33/100, Val Acc=0.6351, Val Loss=1.5556, lr=0.0100
[2025-05-02 21:09:15,420][train][INFO] - Epoch 41/100, Val Acc=0.6320, Val Loss=1.5667, lr=0.0100
[2025-05-02 21:09:23,771][train][INFO] - Epoch 42/100, Val Acc=0.6172, Val Loss=1.6776, lr=0.0100
[2025-05-02 21:09:23,964][train][INFO] - Epoch 34/100, Val Acc=0.6468, Val Loss=1.4801, lr=0.0100
[2025-05-02 21:09:32,068][train][INFO] - Epoch 35/100, Val Acc=0.6452, Val Loss=1.5242, lr=0.0100
[2025-05-02 21:09:32,377][train][INFO] - Epoch 43/100, Val Acc=0.6188, Val Loss=1.6421, lr=0.0100
[2025-05-02 21:09:40,606][train][INFO] - Epoch 36/100, Val Acc=0.6477, Val Loss=1.4958, lr=0.0100
[2025-05-02 21:09:40,673][train][INFO] - Epoch 44/100, Val Acc=0.6253, Val Loss=1.6098, lr=0.0100
[2025-05-02 21:09:49,125][train][INFO] - Epoch 37/100, Val Acc=0.6431, Val Loss=1.5379, lr=0.0100
[2025-05-02 21:09:49,593][train][INFO] - Epoch 45/100, Val Acc=0.6188, Val Loss=1.6504, lr=0.0100
[2025-05-02 21:09:57,657][train][INFO] - Epoch 38/100, Val Acc=0.6431, Val Loss=1.5372, lr=0.0100
[2025-05-02 21:09:57,719][train][INFO] - Epoch 46/100, Val Acc=0.6303, Val Loss=1.6046, lr=0.0100
[2025-05-02 21:10:05,434][train][INFO] - Epoch 47/100, Val Acc=0.6074, Val Loss=1.7301, lr=0.0100
[2025-05-02 21:10:06,135][train][INFO] - Epoch 39/100, Val Acc=0.6412, Val Loss=1.5501, lr=0.0100
[2025-05-02 21:10:13,487][train][INFO] - Epoch 40/100, Val Acc=0.6363, Val Loss=1.5587, lr=0.0100
[2025-05-02 21:10:14,093][train][INFO] - Epoch 48/100, Val Acc=0.6229, Val Loss=1.6260, lr=0.0100
[2025-05-02 21:10:21,490][train][INFO] - Epoch 41/100, Val Acc=0.6514, Val Loss=1.5202, lr=0.0100
[2025-05-02 21:10:22,679][train][INFO] - Epoch 49/100, Val Acc=0.6145, Val Loss=1.7092, lr=0.0100
[2025-05-02 21:10:30,025][train][INFO] - Epoch 42/100, Val Acc=0.6327, Val Loss=1.5960, lr=0.0100
[2025-05-02 21:10:30,487][train][INFO] - Epoch 50/100, Val Acc=0.6093, Val Loss=1.7611, lr=0.0100
[2025-05-02 21:10:38,300][train][INFO] - Epoch 43/100, Val Acc=0.6315, Val Loss=1.6271, lr=0.0100
[2025-05-02 21:10:38,556][train][INFO] - Epoch 51/100, Val Acc=0.6438, Val Loss=1.5354, lr=0.0100
[2025-05-02 21:10:45,710][train][INFO] - Epoch 44/100, Val Acc=0.6359, Val Loss=1.5788, lr=0.0100
[2025-05-02 21:10:47,117][train][INFO] - Epoch 52/100, Val Acc=0.6245, Val Loss=1.6783, lr=0.0100
[2025-05-02 21:10:54,179][train][INFO] - Epoch 45/100, Val Acc=0.6437, Val Loss=1.5394, lr=0.0100
[2025-05-02 21:10:55,628][train][INFO] - Epoch 53/100, Val Acc=0.6297, Val Loss=1.6314, lr=0.0100
[2025-05-02 21:11:02,274][train][INFO] - Epoch 46/100, Val Acc=0.6422, Val Loss=1.5754, lr=0.0100
[2025-05-02 21:11:03,873][train][INFO] - Epoch 54/100, Val Acc=0.6285, Val Loss=1.6383, lr=0.0100
[2025-05-02 21:11:09,914][train][INFO] - Epoch 47/100, Val Acc=0.6510, Val Loss=1.5401, lr=0.0100
[2025-05-02 21:11:11,289][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6296, lr=0.0100
[2025-05-02 21:11:18,182][train][INFO] - Epoch 48/100, Val Acc=0.6352, Val Loss=1.6443, lr=0.0100
[2025-05-02 21:11:19,056][train][INFO] - Epoch 56/100, Val Acc=0.6270, Val Loss=1.6498, lr=0.0100
[2025-05-02 21:11:25,763][train][INFO] - Epoch 57/100, Val Acc=0.6315, Val Loss=1.6395, lr=0.0100
[2025-05-02 21:11:26,598][train][INFO] - Epoch 49/100, Val Acc=0.6451, Val Loss=1.5788, lr=0.0100
[2025-05-02 21:11:34,494][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.5818, lr=0.0100
[2025-05-02 21:11:34,603][train][INFO] - Epoch 58/100, Val Acc=0.6289, Val Loss=1.6599, lr=0.0100
[2025-05-02 21:11:43,063][train][INFO] - Epoch 59/100, Val Acc=0.6210, Val Loss=1.6755, lr=0.0100
[2025-05-02 21:11:43,172][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6248, lr=0.0100
[2025-05-02 21:11:50,921][train][INFO] - Epoch 60/100, Val Acc=0.6409, Val Loss=1.5719, lr=0.0100
[2025-05-02 21:11:51,378][train][INFO] - Epoch 52/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-02 21:11:58,676][train][INFO] - Epoch 61/100, Val Acc=0.6941, Val Loss=1.3369, lr=0.0010
[2025-05-02 21:11:59,551][train][INFO] - Epoch 53/100, Val Acc=0.6353, Val Loss=1.6055, lr=0.0100
[2025-05-02 21:12:07,080][train][INFO] - Epoch 62/100, Val Acc=0.6994, Val Loss=1.3290, lr=0.0010
[2025-05-02 21:12:07,371][train][INFO] - Epoch 54/100, Val Acc=0.6573, Val Loss=1.5031, lr=0.0100
[2025-05-02 21:12:15,442][train][INFO] - Epoch 63/100, Val Acc=0.6991, Val Loss=1.3416, lr=0.0010
[2025-05-02 21:12:15,611][train][INFO] - Epoch 55/100, Val Acc=0.6309, Val Loss=1.6423, lr=0.0100
[2025-05-02 21:12:23,568][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.5747, lr=0.0100
[2025-05-02 21:12:23,903][train][INFO] - Epoch 64/100, Val Acc=0.7002, Val Loss=1.3412, lr=0.0010
[2025-05-02 21:12:31,437][train][INFO] - Epoch 65/100, Val Acc=0.7009, Val Loss=1.3487, lr=0.0010
[2025-05-02 21:12:32,271][train][INFO] - Epoch 57/100, Val Acc=0.6449, Val Loss=1.5515, lr=0.0100
[2025-05-02 21:12:40,087][train][INFO] - Epoch 66/100, Val Acc=0.7021, Val Loss=1.3617, lr=0.0010
[2025-05-02 21:12:40,719][train][INFO] - Epoch 58/100, Val Acc=0.6418, Val Loss=1.5486, lr=0.0100
[2025-05-02 21:12:48,181][train][INFO] - Epoch 67/100, Val Acc=0.7017, Val Loss=1.3637, lr=0.0010
[2025-05-02 21:12:48,652][train][INFO] - Epoch 59/100, Val Acc=0.6442, Val Loss=1.5707, lr=0.0100
[2025-05-02 21:12:56,224][train][INFO] - Epoch 68/100, Val Acc=0.7037, Val Loss=1.3700, lr=0.0010
[2025-05-02 21:12:56,919][train][INFO] - Epoch 60/100, Val Acc=0.6509, Val Loss=1.5362, lr=0.0100
[2025-05-02 21:13:04,324][train][INFO] - Epoch 69/100, Val Acc=0.7023, Val Loss=1.3756, lr=0.0010
[2025-05-02 21:13:04,447][train][INFO] - Epoch 61/100, Val Acc=0.7079, Val Loss=1.2767, lr=0.0010
[2025-05-02 21:13:12,862][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.2703, lr=0.0010
[2025-05-02 21:13:12,926][train][INFO] - Epoch 70/100, Val Acc=0.7046, Val Loss=1.3816, lr=0.0010
[2025-05-02 21:13:21,003][train][INFO] - Epoch 63/100, Val Acc=0.7131, Val Loss=1.2779, lr=0.0010
[2025-05-02 21:13:21,218][train][INFO] - Epoch 71/100, Val Acc=0.7022, Val Loss=1.3797, lr=0.0010
[2025-05-02 21:13:28,809][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.2761, lr=0.0010
[2025-05-02 21:13:29,584][train][INFO] - Epoch 72/100, Val Acc=0.7041, Val Loss=1.3996, lr=0.0010
[2025-05-02 21:13:36,376][train][INFO] - Epoch 65/100, Val Acc=0.7156, Val Loss=1.2928, lr=0.0010
[2025-05-02 21:13:37,968][train][INFO] - Epoch 73/100, Val Acc=0.7045, Val Loss=1.3879, lr=0.0010
[2025-05-02 21:13:44,583][train][INFO] - Epoch 66/100, Val Acc=0.7151, Val Loss=1.2978, lr=0.0010
[2025-05-02 21:13:46,123][train][INFO] - Epoch 74/100, Val Acc=0.6989, Val Loss=1.3965, lr=0.0010
[2025-05-02 21:13:52,875][train][INFO] - Epoch 67/100, Val Acc=0.7164, Val Loss=1.3072, lr=0.0010
[2025-05-02 21:13:53,855][train][INFO] - Epoch 75/100, Val Acc=0.7019, Val Loss=1.3962, lr=0.0010
[2025-05-02 21:14:01,432][train][INFO] - Epoch 68/100, Val Acc=0.7168, Val Loss=1.3068, lr=0.0010
[2025-05-02 21:14:01,981][train][INFO] - Epoch 76/100, Val Acc=0.7030, Val Loss=1.4140, lr=0.0010
[2025-05-02 21:14:09,778][train][INFO] - Epoch 69/100, Val Acc=0.7144, Val Loss=1.3241, lr=0.0010
[2025-05-02 21:14:10,362][train][INFO] - Epoch 77/100, Val Acc=0.7036, Val Loss=1.4230, lr=0.0010
[2025-05-02 21:14:18,359][train][INFO] - Epoch 70/100, Val Acc=0.7165, Val Loss=1.3250, lr=0.0010
[2025-05-02 21:14:18,759][train][INFO] - Epoch 78/100, Val Acc=0.7025, Val Loss=1.4260, lr=0.0010
[2025-05-02 21:14:26,446][train][INFO] - Epoch 79/100, Val Acc=0.7032, Val Loss=1.4261, lr=0.0010
[2025-05-02 21:14:27,206][train][INFO] - Epoch 71/100, Val Acc=0.7167, Val Loss=1.3229, lr=0.0010
[2025-05-02 21:14:33,876][train][INFO] - Epoch 80/100, Val Acc=0.7055, Val Loss=1.4266, lr=0.0010
[2025-05-02 21:14:35,288][train][INFO] - Epoch 72/100, Val Acc=0.7132, Val Loss=1.3359, lr=0.0010
[2025-05-02 21:14:42,140][train][INFO] - Epoch 81/100, Val Acc=0.7030, Val Loss=1.4372, lr=0.0010
[2025-05-02 21:14:43,199][train][INFO] - Epoch 73/100, Val Acc=0.7162, Val Loss=1.3324, lr=0.0010
[2025-05-02 21:14:50,558][train][INFO] - Epoch 82/100, Val Acc=0.7038, Val Loss=1.4375, lr=0.0010
[2025-05-02 21:14:51,373][train][INFO] - Epoch 74/100, Val Acc=0.7167, Val Loss=1.3352, lr=0.0010
[2025-05-02 21:14:59,021][train][INFO] - Epoch 83/100, Val Acc=0.7027, Val Loss=1.4429, lr=0.0010
[2025-05-02 21:14:59,492][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3429, lr=0.0010
[2025-05-02 21:15:07,839][train][INFO] - Epoch 84/100, Val Acc=0.7037, Val Loss=1.4480, lr=0.0010
[2025-05-02 21:15:08,121][train][INFO] - Epoch 76/100, Val Acc=0.7170, Val Loss=1.3423, lr=0.0010
[2025-05-02 21:15:16,274][train][INFO] - Epoch 77/100, Val Acc=0.7174, Val Loss=1.3497, lr=0.0010
[2025-05-02 21:15:16,411][train][INFO] - Epoch 85/100, Val Acc=0.7060, Val Loss=1.4461, lr=0.0010
[2025-05-02 21:15:23,890][train][INFO] - Epoch 86/100, Val Acc=0.7030, Val Loss=1.4595, lr=0.0010
[2025-05-02 21:15:24,629][train][INFO] - Epoch 78/100, Val Acc=0.7168, Val Loss=1.3545, lr=0.0010
[2025-05-02 21:15:32,293][train][INFO] - Epoch 79/100, Val Acc=0.7159, Val Loss=1.3617, lr=0.0010
[2025-05-02 21:15:32,369][train][INFO] - Epoch 87/100, Val Acc=0.7056, Val Loss=1.4598, lr=0.0010
[2025-05-02 21:15:40,739][train][INFO] - Epoch 80/100, Val Acc=0.7180, Val Loss=1.3606, lr=0.0010
[2025-05-02 21:15:40,797][train][INFO] - Epoch 88/100, Val Acc=0.7040, Val Loss=1.4646, lr=0.0010
[2025-05-02 21:15:48,862][train][INFO] - Epoch 89/100, Val Acc=0.7036, Val Loss=1.4664, lr=0.0010
[2025-05-02 21:15:48,896][train][INFO] - Epoch 81/100, Val Acc=0.7171, Val Loss=1.3624, lr=0.0010
[2025-05-02 21:15:56,701][train][INFO] - Epoch 90/100, Val Acc=0.7038, Val Loss=1.4736, lr=0.0010
[2025-05-02 21:15:57,167][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3650, lr=0.0010
[2025-05-02 21:16:04,788][train][INFO] - Epoch 91/100, Val Acc=0.7042, Val Loss=1.4667, lr=0.0001
[2025-05-02 21:16:05,407][train][INFO] - Epoch 83/100, Val Acc=0.7136, Val Loss=1.3734, lr=0.0010
[2025-05-02 21:16:11,619][train][INFO] - Epoch 92/100, Val Acc=0.7057, Val Loss=1.4686, lr=0.0001
[2025-05-02 21:16:13,593][train][INFO] - Epoch 84/100, Val Acc=0.7159, Val Loss=1.3737, lr=0.0010
[2025-05-02 21:16:19,509][train][INFO] - Epoch 93/100, Val Acc=0.7080, Val Loss=1.4640, lr=0.0001
[2025-05-02 21:16:21,862][train][INFO] - Epoch 85/100, Val Acc=0.7164, Val Loss=1.3736, lr=0.0010
[2025-05-02 21:16:27,803][train][INFO] - Epoch 94/100, Val Acc=0.7048, Val Loss=1.4601, lr=0.0001
[2025-05-02 21:16:30,318][train][INFO] - Epoch 86/100, Val Acc=0.7165, Val Loss=1.3791, lr=0.0010
[2025-05-02 21:16:36,575][train][INFO] - Epoch 95/100, Val Acc=0.7064, Val Loss=1.4648, lr=0.0001
[2025-05-02 21:16:39,109][train][INFO] - Epoch 87/100, Val Acc=0.7163, Val Loss=1.3816, lr=0.0010
[2025-05-02 21:16:44,474][train][INFO] - Epoch 96/100, Val Acc=0.7068, Val Loss=1.4609, lr=0.0001
[2025-05-02 21:16:47,857][train][INFO] - Epoch 88/100, Val Acc=0.7138, Val Loss=1.3874, lr=0.0010
[2025-05-02 21:16:51,167][train][INFO] - Epoch 97/100, Val Acc=0.7051, Val Loss=1.4686, lr=0.0001
[2025-05-02 21:16:56,289][train][INFO] - Epoch 89/100, Val Acc=0.7137, Val Loss=1.3880, lr=0.0010
[2025-05-02 21:16:59,929][train][INFO] - Epoch 98/100, Val Acc=0.7064, Val Loss=1.4615, lr=0.0001
[2025-05-02 21:17:04,587][train][INFO] - Epoch 90/100, Val Acc=0.7168, Val Loss=1.3966, lr=0.0010
[2025-05-02 21:17:08,456][train][INFO] - Epoch 99/100, Val Acc=0.7058, Val Loss=1.4660, lr=0.0001
[2025-05-02 21:17:12,927][train][INFO] - Epoch 91/100, Val Acc=0.7166, Val Loss=1.3906, lr=0.0001
[2025-05-02 21:17:16,516][train][INFO] - Epoch 100/100, Val Acc=0.7058, Val Loss=1.4673, lr=0.0001
[2025-05-02 21:17:20,698][train][INFO] - Epoch 92/100, Val Acc=0.7174, Val Loss=1.3933, lr=0.0001
[2025-05-02 21:17:21,865][train][INFO] - After training : Train Acc=0.9902  Val Acc=0.7080
[2025-05-02 21:17:28,817][train][INFO] - Epoch 93/100, Val Acc=0.7186, Val Loss=1.3870, lr=0.0001
[2025-05-02 21:17:32,129][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 21:17:32,129][Progressive pruning][INFO] - Current speed up: 2.00
[2025-05-02 21:17:37,080][train][INFO] - Epoch 94/100, Val Acc=0.7185, Val Loss=1.3837, lr=0.0001
[2025-05-02 21:17:37,600][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 21:17:45,449][train][INFO] - Epoch 1/200, Val Acc=0.5186, Val Loss=1.9460, lr=0.0100
[2025-05-02 21:17:45,552][train][INFO] - Epoch 95/100, Val Acc=0.7181, Val Loss=1.3843, lr=0.0001
[2025-05-02 21:17:53,983][train][INFO] - Epoch 96/100, Val Acc=0.7180, Val Loss=1.3841, lr=0.0001
[2025-05-02 21:17:54,258][train][INFO] - Epoch 2/200, Val Acc=0.5477, Val Loss=1.8238, lr=0.0100
[2025-05-02 21:18:01,887][train][INFO] - Epoch 97/100, Val Acc=0.7174, Val Loss=1.3861, lr=0.0001
[2025-05-02 21:18:02,464][train][INFO] - Epoch 3/200, Val Acc=0.5379, Val Loss=1.9763, lr=0.0100
[2025-05-02 21:18:09,959][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3830, lr=0.0001
[2025-05-02 21:18:10,516][train][INFO] - Epoch 4/200, Val Acc=0.5578, Val Loss=1.8650, lr=0.0100
[2025-05-02 21:18:18,104][train][INFO] - Epoch 99/100, Val Acc=0.7174, Val Loss=1.3896, lr=0.0001
[2025-05-02 21:18:19,023][train][INFO] - Epoch 5/200, Val Acc=0.5595, Val Loss=1.8490, lr=0.0100
[2025-05-02 21:18:26,291][train][INFO] - Epoch 100/100, Val Acc=0.7183, Val Loss=1.3838, lr=0.0001
[2025-05-02 21:18:26,804][train][INFO] - Epoch 6/200, Val Acc=0.5707, Val Loss=1.8173, lr=0.0100
[2025-05-02 21:18:31,540][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7193
[2025-05-02 21:18:31,545][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-02 21:18:34,910][train][INFO] - Epoch 7/200, Val Acc=0.5745, Val Loss=1.8405, lr=0.0100
[2025-05-02 21:18:43,013][train][INFO] - Epoch 8/200, Val Acc=0.5840, Val Loss=1.8099, lr=0.0100
[2025-05-02 21:18:51,334][train][INFO] - Epoch 9/200, Val Acc=0.5895, Val Loss=1.7648, lr=0.0100
[2025-05-02 21:18:59,114][train][INFO] - Epoch 10/200, Val Acc=0.5839, Val Loss=1.8269, lr=0.0100
[2025-05-02 21:19:07,203][train][INFO] - Epoch 11/200, Val Acc=0.5802, Val Loss=1.7967, lr=0.0100
[2025-05-02 21:19:15,513][train][INFO] - Epoch 12/200, Val Acc=0.6020, Val Loss=1.7148, lr=0.0100
[2025-05-02 21:19:23,305][train][INFO] - Epoch 13/200, Val Acc=0.5933, Val Loss=1.7640, lr=0.0100
[2025-05-02 21:19:31,020][train][INFO] - Epoch 14/200, Val Acc=0.6055, Val Loss=1.7174, lr=0.0100
[2025-05-02 21:19:38,655][train][INFO] - Epoch 15/200, Val Acc=0.6002, Val Loss=1.7632, lr=0.0100
[2025-05-02 21:19:46,956][train][INFO] - Epoch 16/200, Val Acc=0.5955, Val Loss=1.7856, lr=0.0100
[2025-05-02 21:19:49,830][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-02 21:19:55,045][train][INFO] - Epoch 17/200, Val Acc=0.6052, Val Loss=1.7530, lr=0.0100
[2025-05-02 21:20:02,798][train][INFO] - Epoch 18/200, Val Acc=0.6110, Val Loss=1.6791, lr=0.0100
[2025-05-02 21:20:10,544][train][INFO] - Epoch 19/200, Val Acc=0.5599, Val Loss=2.0500, lr=0.0100
[2025-05-02 21:20:18,439][train][INFO] - Epoch 20/200, Val Acc=0.6033, Val Loss=1.7324, lr=0.0100
[2025-05-02 21:20:25,877][train][INFO] - Epoch 21/200, Val Acc=0.6028, Val Loss=1.7392, lr=0.0100
[2025-05-02 21:20:34,203][train][INFO] - Epoch 22/200, Val Acc=0.5969, Val Loss=1.8122, lr=0.0100
[2025-05-02 21:20:41,970][train][INFO] - Epoch 23/200, Val Acc=0.5829, Val Loss=1.9362, lr=0.0100
[2025-05-02 21:20:49,921][train][INFO] - Epoch 24/200, Val Acc=0.5949, Val Loss=1.8254, lr=0.0100
[2025-05-02 21:20:58,280][train][INFO] - Epoch 25/200, Val Acc=0.5958, Val Loss=1.8631, lr=0.0100
[2025-05-02 21:21:06,247][train][INFO] - Epoch 26/200, Val Acc=0.5807, Val Loss=1.9520, lr=0.0100
[2025-05-02 21:21:14,117][train][INFO] - Epoch 27/200, Val Acc=0.6008, Val Loss=1.8226, lr=0.0100
[2025-05-02 21:21:21,856][train][INFO] - Epoch 28/200, Val Acc=0.6046, Val Loss=1.7215, lr=0.0100
[2025-05-02 21:21:30,285][train][INFO] - Epoch 29/200, Val Acc=0.6155, Val Loss=1.7293, lr=0.0100
[2025-05-02 21:21:38,338][train][INFO] - Epoch 30/200, Val Acc=0.6117, Val Loss=1.7700, lr=0.0100
[2025-05-02 21:21:46,588][train][INFO] - Epoch 31/200, Val Acc=0.5855, Val Loss=1.9482, lr=0.0100
[2025-05-02 21:21:54,407][train][INFO] - Epoch 32/200, Val Acc=0.6056, Val Loss=1.7692, lr=0.0100
[2025-05-02 21:22:02,647][train][INFO] - Epoch 33/200, Val Acc=0.6027, Val Loss=1.8264, lr=0.0100
[2025-05-02 21:22:05,093][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-02 21:22:05,524][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-02 21:22:10,351][train][INFO] - Epoch 34/200, Val Acc=0.5959, Val Loss=1.9143, lr=0.0100
[2025-05-02 21:22:17,565][train][INFO] - Epoch 35/200, Val Acc=0.6028, Val Loss=1.8047, lr=0.0100
[2025-05-02 21:22:25,577][train][INFO] - Epoch 36/200, Val Acc=0.5843, Val Loss=1.9405, lr=0.0100
[2025-05-02 21:22:33,015][train][INFO] - Epoch 37/200, Val Acc=0.6090, Val Loss=1.7457, lr=0.0100
[2025-05-02 21:22:41,220][train][INFO] - Epoch 38/200, Val Acc=0.5991, Val Loss=1.8460, lr=0.0100
[2025-05-02 21:22:48,893][train][INFO] - Epoch 39/200, Val Acc=0.5962, Val Loss=1.8952, lr=0.0100
[2025-05-02 21:22:56,256][train][INFO] - Epoch 40/200, Val Acc=0.6071, Val Loss=1.8353, lr=0.0100
[2025-05-02 21:23:04,313][train][INFO] - Epoch 41/200, Val Acc=0.6197, Val Loss=1.7482, lr=0.0100
[2025-05-02 21:23:12,599][train][INFO] - Epoch 42/200, Val Acc=0.5934, Val Loss=1.9148, lr=0.0100
[2025-05-02 21:23:20,067][train][INFO] - Epoch 43/200, Val Acc=0.5930, Val Loss=1.9683, lr=0.0100
[2025-05-02 21:23:28,755][train][INFO] - Epoch 44/200, Val Acc=0.6006, Val Loss=1.8794, lr=0.0100
[2025-05-02 21:23:36,918][train][INFO] - Epoch 45/200, Val Acc=0.6091, Val Loss=1.7738, lr=0.0100
[2025-05-02 21:23:44,651][train][INFO] - Epoch 46/200, Val Acc=0.5973, Val Loss=1.9144, lr=0.0100
[2025-05-02 21:23:52,185][train][INFO] - Epoch 47/200, Val Acc=0.6068, Val Loss=1.8635, lr=0.0100
[2025-05-02 21:23:59,896][train][INFO] - Epoch 48/200, Val Acc=0.5975, Val Loss=1.9126, lr=0.0100
[2025-05-02 21:24:08,351][train][INFO] - Epoch 49/200, Val Acc=0.6048, Val Loss=1.8852, lr=0.0100
[2025-05-02 21:24:16,264][train][INFO] - Epoch 50/200, Val Acc=0.5963, Val Loss=1.9077, lr=0.0100
[2025-05-02 21:24:24,390][train][INFO] - Epoch 51/200, Val Acc=0.6002, Val Loss=1.9168, lr=0.0100
[2025-05-02 21:24:32,523][train][INFO] - Epoch 52/200, Val Acc=0.6175, Val Loss=1.8028, lr=0.0100
[2025-05-02 21:24:40,671][train][INFO] - Epoch 53/200, Val Acc=0.5998, Val Loss=1.8763, lr=0.0100
[2025-05-02 21:24:47,875][train][INFO] - Epoch 54/200, Val Acc=0.6012, Val Loss=1.8862, lr=0.0100
[2025-05-02 21:24:55,985][train][INFO] - Epoch 55/200, Val Acc=0.6138, Val Loss=1.8950, lr=0.0100
[2025-05-02 21:25:03,249][train][INFO] - Epoch 56/200, Val Acc=0.6053, Val Loss=1.8909, lr=0.0100
[2025-05-02 21:25:11,364][train][INFO] - Epoch 57/200, Val Acc=0.6142, Val Loss=1.7856, lr=0.0100
[2025-05-02 21:25:19,324][train][INFO] - Epoch 58/200, Val Acc=0.6124, Val Loss=1.8061, lr=0.0100
[2025-05-02 21:25:27,195][train][INFO] - Epoch 59/200, Val Acc=0.6047, Val Loss=1.8708, lr=0.0100
[2025-05-02 21:25:34,729][train][INFO] - Epoch 60/200, Val Acc=0.5985, Val Loss=1.8669, lr=0.0100
[2025-05-02 21:25:42,693][train][INFO] - Epoch 61/200, Val Acc=0.6193, Val Loss=1.7552, lr=0.0100
[2025-05-02 21:25:50,641][train][INFO] - Epoch 62/200, Val Acc=0.6040, Val Loss=1.8845, lr=0.0100
[2025-05-02 21:25:58,056][train][INFO] - Epoch 63/200, Val Acc=0.5892, Val Loss=2.0048, lr=0.0100
[2025-05-02 21:26:06,281][train][INFO] - Epoch 64/200, Val Acc=0.6224, Val Loss=1.7570, lr=0.0100
[2025-05-02 21:26:13,521][train][INFO] - Epoch 65/200, Val Acc=0.6049, Val Loss=1.9091, lr=0.0100
[2025-05-02 21:26:21,322][train][INFO] - Epoch 66/200, Val Acc=0.6177, Val Loss=1.8307, lr=0.0100
[2025-05-02 21:26:29,007][train][INFO] - Epoch 67/200, Val Acc=0.6090, Val Loss=1.8768, lr=0.0100
[2025-05-02 21:26:36,663][train][INFO] - Epoch 68/200, Val Acc=0.6007, Val Loss=1.9378, lr=0.0100
[2025-05-02 21:26:44,503][train][INFO] - Epoch 69/200, Val Acc=0.6115, Val Loss=1.8215, lr=0.0100
[2025-05-02 21:26:51,156][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 6.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 200
        lr: 0.01
        lr_decay_milestones: 120,170
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-02 21:26:51,245][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 21:26:51,245][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 21:26:51,245][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 21:26:52,228][train][INFO] - Epoch 70/200, Val Acc=0.6272, Val Loss=1.7242, lr=0.0100
[2025-05-02 21:27:00,852][train][INFO] - Epoch 71/200, Val Acc=0.6153, Val Loss=1.7985, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 21:27:07,949][train][INFO] - Epoch 72/200, Val Acc=0.5992, Val Loss=1.9076, lr=0.0100
[2025-05-02 21:27:08,407][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 21:27:16,425][train][INFO] - Epoch 73/200, Val Acc=0.6091, Val Loss=1.8366, lr=0.0100
[2025-05-02 21:27:16,992][train][INFO] - Epoch 1/100, Val Acc=0.1656, Val Loss=3.1948, lr=0.0100
[2025-05-02 21:27:24,818][train][INFO] - Epoch 74/200, Val Acc=0.6077, Val Loss=1.8327, lr=0.0100
[2025-05-02 21:27:25,368][train][INFO] - Epoch 2/100, Val Acc=0.3536, Val Loss=2.3640, lr=0.0100
[2025-05-02 21:27:33,526][train][INFO] - Epoch 75/200, Val Acc=0.6135, Val Loss=1.8713, lr=0.0100
[2025-05-02 21:27:33,935][train][INFO] - Epoch 3/100, Val Acc=0.4319, Val Loss=2.1507, lr=0.0100
[2025-05-02 21:27:41,540][train][INFO] - Epoch 76/200, Val Acc=0.6165, Val Loss=1.8289, lr=0.0100
[2025-05-02 21:27:41,908][train][INFO] - Epoch 4/100, Val Acc=0.4925, Val Loss=1.8823, lr=0.0100
[2025-05-02 21:27:49,790][train][INFO] - Epoch 77/200, Val Acc=0.5933, Val Loss=1.9063, lr=0.0100
[2025-05-02 21:27:50,266][train][INFO] - Epoch 5/100, Val Acc=0.5224, Val Loss=1.8290, lr=0.0100
[2025-05-02 21:27:58,497][train][INFO] - Epoch 6/100, Val Acc=0.5208, Val Loss=1.8555, lr=0.0100
[2025-05-02 21:27:58,775][train][INFO] - Epoch 78/200, Val Acc=0.6027, Val Loss=1.8598, lr=0.0100
[2025-05-02 21:28:06,604][train][INFO] - Epoch 79/200, Val Acc=0.6109, Val Loss=1.8485, lr=0.0100
[2025-05-02 21:28:07,207][train][INFO] - Epoch 7/100, Val Acc=0.5505, Val Loss=1.7337, lr=0.0100
[2025-05-02 21:28:14,601][train][INFO] - Epoch 80/200, Val Acc=0.5888, Val Loss=2.0327, lr=0.0100
[2025-05-02 21:28:15,322][train][INFO] - Epoch 8/100, Val Acc=0.5731, Val Loss=1.6407, lr=0.0100
[2025-05-02 21:28:22,756][train][INFO] - Epoch 81/200, Val Acc=0.6124, Val Loss=1.8352, lr=0.0100
[2025-05-02 21:28:23,521][train][INFO] - Epoch 9/100, Val Acc=0.5858, Val Loss=1.5636, lr=0.0100
[2025-05-02 21:28:30,932][train][INFO] - Epoch 82/200, Val Acc=0.6045, Val Loss=1.9269, lr=0.0100
[2025-05-02 21:28:31,704][train][INFO] - Epoch 10/100, Val Acc=0.6031, Val Loss=1.5387, lr=0.0100
[2025-05-02 21:28:39,243][train][INFO] - Epoch 83/200, Val Acc=0.6130, Val Loss=1.8440, lr=0.0100
[2025-05-02 21:28:40,068][train][INFO] - Epoch 11/100, Val Acc=0.6026, Val Loss=1.5312, lr=0.0100
[2025-05-02 21:28:46,941][train][INFO] - Epoch 12/100, Val Acc=0.6125, Val Loss=1.5101, lr=0.0100
[2025-05-02 21:28:47,695][train][INFO] - Epoch 84/200, Val Acc=0.6156, Val Loss=1.8527, lr=0.0100
[2025-05-02 21:28:55,439][train][INFO] - Epoch 13/100, Val Acc=0.5865, Val Loss=1.6591, lr=0.0100
[2025-05-02 21:28:56,184][train][INFO] - Epoch 85/200, Val Acc=0.6103, Val Loss=1.8208, lr=0.0100
[2025-05-02 21:29:03,404][train][INFO] - Epoch 14/100, Val Acc=0.6221, Val Loss=1.4760, lr=0.0100
[2025-05-02 21:29:04,678][train][INFO] - Epoch 86/200, Val Acc=0.6091, Val Loss=1.8598, lr=0.0100
[2025-05-02 21:29:11,444][train][INFO] - Epoch 15/100, Val Acc=0.6008, Val Loss=1.5581, lr=0.0100
[2025-05-02 21:29:12,955][train][INFO] - Epoch 87/200, Val Acc=0.6055, Val Loss=1.9059, lr=0.0100
[2025-05-02 21:29:19,249][train][INFO] - Epoch 16/100, Val Acc=0.5950, Val Loss=1.6448, lr=0.0100
[2025-05-02 21:29:21,413][train][INFO] - Epoch 88/200, Val Acc=0.6080, Val Loss=1.9101, lr=0.0100
[2025-05-02 21:29:27,632][train][INFO] - Epoch 17/100, Val Acc=0.6048, Val Loss=1.5769, lr=0.0100
[2025-05-02 21:29:29,540][train][INFO] - Epoch 89/200, Val Acc=0.6107, Val Loss=1.8515, lr=0.0100
[2025-05-02 21:29:35,966][train][INFO] - Epoch 18/100, Val Acc=0.6307, Val Loss=1.4623, lr=0.0100
[2025-05-02 21:29:37,710][train][INFO] - Epoch 90/200, Val Acc=0.6152, Val Loss=1.8768, lr=0.0100
[2025-05-02 21:29:44,190][train][INFO] - Epoch 19/100, Val Acc=0.6108, Val Loss=1.5797, lr=0.0100
[2025-05-02 21:29:46,191][train][INFO] - Epoch 91/200, Val Acc=0.6166, Val Loss=1.8539, lr=0.0100
[2025-05-02 21:29:52,428][train][INFO] - Epoch 20/100, Val Acc=0.6146, Val Loss=1.5706, lr=0.0100
[2025-05-02 21:29:54,469][train][INFO] - Epoch 92/200, Val Acc=0.6002, Val Loss=1.9830, lr=0.0100
[2025-05-02 21:30:00,719][train][INFO] - Epoch 21/100, Val Acc=0.6322, Val Loss=1.4814, lr=0.0100
[2025-05-02 21:30:02,800][train][INFO] - Epoch 93/200, Val Acc=0.6149, Val Loss=1.8426, lr=0.0100
[2025-05-02 21:30:09,172][train][INFO] - Epoch 22/100, Val Acc=0.6236, Val Loss=1.5283, lr=0.0100
[2025-05-02 21:30:10,834][train][INFO] - Epoch 94/200, Val Acc=0.6139, Val Loss=1.8351, lr=0.0100
[2025-05-02 21:30:17,096][train][INFO] - Epoch 23/100, Val Acc=0.6347, Val Loss=1.4687, lr=0.0100
[2025-05-02 21:30:18,643][train][INFO] - Epoch 95/200, Val Acc=0.5826, Val Loss=2.0821, lr=0.0100
[2025-05-02 21:30:24,986][train][INFO] - Epoch 24/100, Val Acc=0.6452, Val Loss=1.4568, lr=0.0100
[2025-05-02 21:30:27,017][train][INFO] - Epoch 96/200, Val Acc=0.6120, Val Loss=1.8553, lr=0.0100
[2025-05-02 21:30:33,220][train][INFO] - Epoch 25/100, Val Acc=0.6310, Val Loss=1.5355, lr=0.0100
[2025-05-02 21:30:35,602][train][INFO] - Epoch 97/200, Val Acc=0.6108, Val Loss=1.9365, lr=0.0100
[2025-05-02 21:30:41,635][train][INFO] - Epoch 26/100, Val Acc=0.6261, Val Loss=1.5884, lr=0.0100
[2025-05-02 21:30:43,875][train][INFO] - Epoch 98/200, Val Acc=0.6174, Val Loss=1.8208, lr=0.0100
[2025-05-02 21:30:49,824][train][INFO] - Epoch 27/100, Val Acc=0.6376, Val Loss=1.4824, lr=0.0100
[2025-05-02 21:30:51,966][train][INFO] - Epoch 99/200, Val Acc=0.6200, Val Loss=1.8542, lr=0.0100
[2025-05-02 21:30:57,124][train][INFO] - Epoch 28/100, Val Acc=0.6306, Val Loss=1.5536, lr=0.0100
[2025-05-02 21:31:00,127][train][INFO] - Epoch 100/200, Val Acc=0.6102, Val Loss=1.8968, lr=0.0100
[2025-05-02 21:31:05,329][train][INFO] - Epoch 29/100, Val Acc=0.6305, Val Loss=1.5611, lr=0.0100
[2025-05-02 21:31:08,833][train][INFO] - Epoch 101/200, Val Acc=0.6166, Val Loss=1.8603, lr=0.0100
[2025-05-02 21:31:13,366][train][INFO] - Epoch 30/100, Val Acc=0.6494, Val Loss=1.4854, lr=0.0100
[2025-05-02 21:31:16,839][train][INFO] - Epoch 102/200, Val Acc=0.6055, Val Loss=1.9502, lr=0.0100
[2025-05-02 21:31:21,432][train][INFO] - Epoch 31/100, Val Acc=0.6348, Val Loss=1.5276, lr=0.0100
[2025-05-02 21:31:24,455][train][INFO] - Epoch 103/200, Val Acc=0.5999, Val Loss=1.9304, lr=0.0100
[2025-05-02 21:31:29,517][train][INFO] - Epoch 32/100, Val Acc=0.6472, Val Loss=1.5131, lr=0.0100
[2025-05-02 21:31:32,454][train][INFO] - Epoch 104/200, Val Acc=0.6111, Val Loss=1.8921, lr=0.0100
[2025-05-02 21:31:37,867][train][INFO] - Epoch 33/100, Val Acc=0.6351, Val Loss=1.5556, lr=0.0100
[2025-05-02 21:31:40,446][train][INFO] - Epoch 105/200, Val Acc=0.6133, Val Loss=1.8617, lr=0.0100
[2025-05-02 21:31:46,360][train][INFO] - Epoch 34/100, Val Acc=0.6468, Val Loss=1.4801, lr=0.0100
[2025-05-02 21:31:48,255][train][INFO] - Epoch 106/200, Val Acc=0.6243, Val Loss=1.7774, lr=0.0100
[2025-05-02 21:31:54,801][train][INFO] - Epoch 35/100, Val Acc=0.6452, Val Loss=1.5242, lr=0.0100
[2025-05-02 21:31:56,510][train][INFO] - Epoch 107/200, Val Acc=0.6146, Val Loss=1.8923, lr=0.0100
[2025-05-02 21:32:02,932][train][INFO] - Epoch 36/100, Val Acc=0.6477, Val Loss=1.4958, lr=0.0100
[2025-05-02 21:32:04,398][train][INFO] - Epoch 108/200, Val Acc=0.6151, Val Loss=1.8497, lr=0.0100
[2025-05-02 21:32:11,389][train][INFO] - Epoch 37/100, Val Acc=0.6431, Val Loss=1.5379, lr=0.0100
[2025-05-02 21:32:13,021][train][INFO] - Epoch 109/200, Val Acc=0.6029, Val Loss=1.9145, lr=0.0100
[2025-05-02 21:32:19,847][train][INFO] - Epoch 38/100, Val Acc=0.6431, Val Loss=1.5372, lr=0.0100
[2025-05-02 21:32:20,768][train][INFO] - Epoch 110/200, Val Acc=0.6043, Val Loss=1.9354, lr=0.0100
[2025-05-02 21:32:27,660][train][INFO] - Epoch 39/100, Val Acc=0.6412, Val Loss=1.5501, lr=0.0100
[2025-05-02 21:32:29,149][train][INFO] - Epoch 111/200, Val Acc=0.6305, Val Loss=1.7811, lr=0.0100
[2025-05-02 21:32:36,118][train][INFO] - Epoch 40/100, Val Acc=0.6363, Val Loss=1.5587, lr=0.0100
[2025-05-02 21:32:36,995][train][INFO] - Epoch 112/200, Val Acc=0.5989, Val Loss=2.0223, lr=0.0100
[2025-05-02 21:32:44,537][train][INFO] - Epoch 41/100, Val Acc=0.6514, Val Loss=1.5202, lr=0.0100
[2025-05-02 21:32:45,343][train][INFO] - Epoch 113/200, Val Acc=0.6070, Val Loss=1.9024, lr=0.0100
[2025-05-02 21:32:53,402][train][INFO] - Epoch 42/100, Val Acc=0.6327, Val Loss=1.5960, lr=0.0100
[2025-05-02 21:32:53,623][train][INFO] - Epoch 114/200, Val Acc=0.6047, Val Loss=1.9325, lr=0.0100
[2025-05-02 21:33:01,783][train][INFO] - Epoch 115/200, Val Acc=0.6138, Val Loss=1.9249, lr=0.0100
[2025-05-02 21:33:01,836][train][INFO] - Epoch 43/100, Val Acc=0.6315, Val Loss=1.6271, lr=0.0100
[2025-05-02 21:33:09,997][train][INFO] - Epoch 44/100, Val Acc=0.6359, Val Loss=1.5788, lr=0.0100
[2025-05-02 21:33:10,115][train][INFO] - Epoch 116/200, Val Acc=0.6119, Val Loss=1.8841, lr=0.0100
[2025-05-02 21:33:18,054][train][INFO] - Epoch 117/200, Val Acc=0.6169, Val Loss=1.8715, lr=0.0100
[2025-05-02 21:33:18,219][train][INFO] - Epoch 45/100, Val Acc=0.6437, Val Loss=1.5394, lr=0.0100
[2025-05-02 21:33:25,652][train][INFO] - Epoch 118/200, Val Acc=0.6186, Val Loss=1.8366, lr=0.0100
[2025-05-02 21:33:26,452][train][INFO] - Epoch 46/100, Val Acc=0.6422, Val Loss=1.5754, lr=0.0100
[2025-05-02 21:33:34,028][train][INFO] - Epoch 119/200, Val Acc=0.6039, Val Loss=1.9013, lr=0.0100
[2025-05-02 21:33:34,841][train][INFO] - Epoch 47/100, Val Acc=0.6510, Val Loss=1.5401, lr=0.0100
[2025-05-02 21:33:42,261][train][INFO] - Epoch 120/200, Val Acc=0.6030, Val Loss=1.9589, lr=0.0100
[2025-05-02 21:33:43,235][train][INFO] - Epoch 48/100, Val Acc=0.6352, Val Loss=1.6443, lr=0.0100
[2025-05-02 21:33:50,343][train][INFO] - Epoch 121/200, Val Acc=0.6695, Val Loss=1.5555, lr=0.0010
[2025-05-02 21:33:51,335][train][INFO] - Epoch 49/100, Val Acc=0.6451, Val Loss=1.5788, lr=0.0100
[2025-05-02 21:33:58,380][train][INFO] - Epoch 122/200, Val Acc=0.6721, Val Loss=1.5632, lr=0.0010
[2025-05-02 21:33:59,045][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.5818, lr=0.0100
[2025-05-02 21:34:06,998][train][INFO] - Epoch 123/200, Val Acc=0.6738, Val Loss=1.5673, lr=0.0010
[2025-05-02 21:34:07,623][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6248, lr=0.0100
[2025-05-02 21:34:15,494][train][INFO] - Epoch 124/200, Val Acc=0.6721, Val Loss=1.5719, lr=0.0010
[2025-05-02 21:34:15,953][train][INFO] - Epoch 52/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-02 21:34:23,707][train][INFO] - Epoch 125/200, Val Acc=0.6739, Val Loss=1.5760, lr=0.0010
[2025-05-02 21:34:24,326][train][INFO] - Epoch 53/100, Val Acc=0.6353, Val Loss=1.6055, lr=0.0100
[2025-05-02 21:34:32,376][train][INFO] - Epoch 126/200, Val Acc=0.6742, Val Loss=1.5876, lr=0.0010
[2025-05-02 21:34:33,006][train][INFO] - Epoch 54/100, Val Acc=0.6573, Val Loss=1.5031, lr=0.0100
[2025-05-02 21:34:40,592][train][INFO] - Epoch 127/200, Val Acc=0.6756, Val Loss=1.5843, lr=0.0010
[2025-05-02 21:34:41,453][train][INFO] - Epoch 55/100, Val Acc=0.6309, Val Loss=1.6423, lr=0.0100
[2025-05-02 21:34:49,046][train][INFO] - Epoch 128/200, Val Acc=0.6759, Val Loss=1.5912, lr=0.0010
[2025-05-02 21:34:49,645][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.5747, lr=0.0100
[2025-05-02 21:34:56,361][train][INFO] - Epoch 129/200, Val Acc=0.6745, Val Loss=1.6024, lr=0.0010
[2025-05-02 21:34:58,188][train][INFO] - Epoch 57/100, Val Acc=0.6449, Val Loss=1.5515, lr=0.0100
[2025-05-02 21:35:04,387][train][INFO] - Epoch 130/200, Val Acc=0.6745, Val Loss=1.5911, lr=0.0010
[2025-05-02 21:35:06,387][train][INFO] - Epoch 58/100, Val Acc=0.6418, Val Loss=1.5486, lr=0.0100
[2025-05-02 21:35:12,618][train][INFO] - Epoch 131/200, Val Acc=0.6765, Val Loss=1.6127, lr=0.0010
[2025-05-02 21:35:14,160][train][INFO] - Epoch 59/100, Val Acc=0.6442, Val Loss=1.5707, lr=0.0100
[2025-05-02 21:35:20,942][train][INFO] - Epoch 132/200, Val Acc=0.6752, Val Loss=1.6014, lr=0.0010
[2025-05-02 21:35:22,688][train][INFO] - Epoch 60/100, Val Acc=0.6509, Val Loss=1.5362, lr=0.0100
[2025-05-02 21:35:29,416][train][INFO] - Epoch 133/200, Val Acc=0.6760, Val Loss=1.6135, lr=0.0010
[2025-05-02 21:35:30,873][train][INFO] - Epoch 61/100, Val Acc=0.7079, Val Loss=1.2767, lr=0.0010
[2025-05-02 21:35:37,546][train][INFO] - Epoch 134/200, Val Acc=0.6771, Val Loss=1.6109, lr=0.0010
[2025-05-02 21:35:39,275][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.2703, lr=0.0010
[2025-05-02 21:35:45,218][train][INFO] - Epoch 135/200, Val Acc=0.6768, Val Loss=1.6119, lr=0.0010
[2025-05-02 21:35:47,213][train][INFO] - Epoch 63/100, Val Acc=0.7131, Val Loss=1.2779, lr=0.0010
[2025-05-02 21:35:53,241][train][INFO] - Epoch 136/200, Val Acc=0.6759, Val Loss=1.6078, lr=0.0010
[2025-05-02 21:35:55,481][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.2761, lr=0.0010
[2025-05-02 21:36:01,280][train][INFO] - Epoch 137/200, Val Acc=0.6767, Val Loss=1.6214, lr=0.0010
[2025-05-02 21:36:03,891][train][INFO] - Epoch 65/100, Val Acc=0.7156, Val Loss=1.2928, lr=0.0010
[2025-05-02 21:36:09,693][train][INFO] - Epoch 138/200, Val Acc=0.6775, Val Loss=1.6273, lr=0.0010
[2025-05-02 21:36:11,079][train][INFO] - Epoch 66/100, Val Acc=0.7151, Val Loss=1.2978, lr=0.0010
[2025-05-02 21:36:17,485][train][INFO] - Epoch 139/200, Val Acc=0.6750, Val Loss=1.6340, lr=0.0010
[2025-05-02 21:36:19,472][train][INFO] - Epoch 67/100, Val Acc=0.7164, Val Loss=1.3072, lr=0.0010
[2025-05-02 21:36:26,073][train][INFO] - Epoch 140/200, Val Acc=0.6753, Val Loss=1.6419, lr=0.0010
[2025-05-02 21:36:27,776][train][INFO] - Epoch 68/100, Val Acc=0.7168, Val Loss=1.3068, lr=0.0010
[2025-05-02 21:36:34,494][train][INFO] - Epoch 141/200, Val Acc=0.6796, Val Loss=1.6373, lr=0.0010
[2025-05-02 21:36:35,872][train][INFO] - Epoch 69/100, Val Acc=0.7144, Val Loss=1.3241, lr=0.0010
[2025-05-02 21:36:43,236][train][INFO] - Epoch 142/200, Val Acc=0.6792, Val Loss=1.6403, lr=0.0010
[2025-05-02 21:36:44,012][train][INFO] - Epoch 70/100, Val Acc=0.7165, Val Loss=1.3250, lr=0.0010
[2025-05-02 21:36:51,101][train][INFO] - Epoch 143/200, Val Acc=0.6783, Val Loss=1.6479, lr=0.0010
[2025-05-02 21:36:52,167][train][INFO] - Epoch 71/100, Val Acc=0.7167, Val Loss=1.3229, lr=0.0010
[2025-05-02 21:36:59,792][train][INFO] - Epoch 144/200, Val Acc=0.6784, Val Loss=1.6556, lr=0.0010
[2025-05-02 21:37:00,542][train][INFO] - Epoch 72/100, Val Acc=0.7132, Val Loss=1.3359, lr=0.0010
[2025-05-02 21:37:07,861][train][INFO] - Epoch 73/100, Val Acc=0.7162, Val Loss=1.3324, lr=0.0010
[2025-05-02 21:37:08,069][train][INFO] - Epoch 145/200, Val Acc=0.6763, Val Loss=1.6480, lr=0.0010
[2025-05-02 21:37:15,711][train][INFO] - Epoch 74/100, Val Acc=0.7167, Val Loss=1.3352, lr=0.0010
[2025-05-02 21:37:15,908][train][INFO] - Epoch 146/200, Val Acc=0.6808, Val Loss=1.6533, lr=0.0010
[2025-05-02 21:37:23,605][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3429, lr=0.0010
[2025-05-02 21:37:23,857][train][INFO] - Epoch 147/200, Val Acc=0.6793, Val Loss=1.6536, lr=0.0010
[2025-05-02 21:37:31,943][train][INFO] - Epoch 76/100, Val Acc=0.7170, Val Loss=1.3423, lr=0.0010
[2025-05-02 21:37:32,417][train][INFO] - Epoch 148/200, Val Acc=0.6798, Val Loss=1.6643, lr=0.0010
[2025-05-02 21:37:40,317][train][INFO] - Epoch 77/100, Val Acc=0.7174, Val Loss=1.3497, lr=0.0010
[2025-05-02 21:37:40,400][train][INFO] - Epoch 149/200, Val Acc=0.6803, Val Loss=1.6574, lr=0.0010
[2025-05-02 21:37:48,425][train][INFO] - Epoch 150/200, Val Acc=0.6780, Val Loss=1.6552, lr=0.0010
[2025-05-02 21:37:48,490][train][INFO] - Epoch 78/100, Val Acc=0.7168, Val Loss=1.3545, lr=0.0010
[2025-05-02 21:37:56,816][train][INFO] - Epoch 79/100, Val Acc=0.7159, Val Loss=1.3617, lr=0.0010
[2025-05-02 21:37:56,962][train][INFO] - Epoch 151/200, Val Acc=0.6767, Val Loss=1.6686, lr=0.0010
[2025-05-02 21:38:05,288][train][INFO] - Epoch 152/200, Val Acc=0.6793, Val Loss=1.6643, lr=0.0010
[2025-05-02 21:38:05,513][train][INFO] - Epoch 80/100, Val Acc=0.7180, Val Loss=1.3606, lr=0.0010
[2025-05-02 21:38:13,583][train][INFO] - Epoch 153/200, Val Acc=0.6794, Val Loss=1.6609, lr=0.0010
[2025-05-02 21:38:13,911][train][INFO] - Epoch 81/100, Val Acc=0.7171, Val Loss=1.3624, lr=0.0010
[2025-05-02 21:38:21,818][train][INFO] - Epoch 154/200, Val Acc=0.6803, Val Loss=1.6661, lr=0.0010
[2025-05-02 21:38:21,915][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3650, lr=0.0010
[2025-05-02 21:38:29,663][train][INFO] - Epoch 155/200, Val Acc=0.6778, Val Loss=1.6673, lr=0.0010
[2025-05-02 21:38:29,710][train][INFO] - Epoch 83/100, Val Acc=0.7136, Val Loss=1.3734, lr=0.0010
[2025-05-02 21:38:36,639][train][INFO] - Epoch 156/200, Val Acc=0.6801, Val Loss=1.6676, lr=0.0010
[2025-05-02 21:38:37,907][train][INFO] - Epoch 84/100, Val Acc=0.7159, Val Loss=1.3737, lr=0.0010
[2025-05-02 21:38:44,803][train][INFO] - Epoch 157/200, Val Acc=0.6796, Val Loss=1.6741, lr=0.0010
[2025-05-02 21:38:45,746][train][INFO] - Epoch 85/100, Val Acc=0.7164, Val Loss=1.3736, lr=0.0010
[2025-05-02 21:38:52,880][train][INFO] - Epoch 158/200, Val Acc=0.6804, Val Loss=1.6735, lr=0.0010
[2025-05-02 21:38:54,084][train][INFO] - Epoch 86/100, Val Acc=0.7165, Val Loss=1.3791, lr=0.0010
[2025-05-02 21:39:01,201][train][INFO] - Epoch 159/200, Val Acc=0.6779, Val Loss=1.6793, lr=0.0010
[2025-05-02 21:39:02,398][train][INFO] - Epoch 87/100, Val Acc=0.7163, Val Loss=1.3816, lr=0.0010
[2025-05-02 21:39:09,527][train][INFO] - Epoch 160/200, Val Acc=0.6802, Val Loss=1.6877, lr=0.0010
[2025-05-02 21:39:10,446][train][INFO] - Epoch 88/100, Val Acc=0.7138, Val Loss=1.3874, lr=0.0010
[2025-05-02 21:39:17,651][train][INFO] - Epoch 161/200, Val Acc=0.6813, Val Loss=1.6793, lr=0.0010
[2025-05-02 21:39:19,182][train][INFO] - Epoch 89/100, Val Acc=0.7137, Val Loss=1.3880, lr=0.0010
[2025-05-02 21:39:26,253][train][INFO] - Epoch 162/200, Val Acc=0.6793, Val Loss=1.6864, lr=0.0010
[2025-05-02 21:39:27,491][train][INFO] - Epoch 90/100, Val Acc=0.7168, Val Loss=1.3966, lr=0.0010
[2025-05-02 21:39:34,375][train][INFO] - Epoch 163/200, Val Acc=0.6783, Val Loss=1.6814, lr=0.0010
[2025-05-02 21:39:35,106][train][INFO] - Epoch 91/100, Val Acc=0.7166, Val Loss=1.3906, lr=0.0001
[2025-05-02 21:39:42,998][train][INFO] - Epoch 164/200, Val Acc=0.6807, Val Loss=1.6816, lr=0.0010
[2025-05-02 21:39:43,585][train][INFO] - Epoch 92/100, Val Acc=0.7174, Val Loss=1.3933, lr=0.0001
[2025-05-02 21:39:51,103][train][INFO] - Epoch 93/100, Val Acc=0.7186, Val Loss=1.3870, lr=0.0001
[2025-05-02 21:39:51,591][train][INFO] - Epoch 165/200, Val Acc=0.6802, Val Loss=1.6882, lr=0.0010
[2025-05-02 21:39:59,383][train][INFO] - Epoch 94/100, Val Acc=0.7185, Val Loss=1.3837, lr=0.0001
[2025-05-02 21:40:00,170][train][INFO] - Epoch 166/200, Val Acc=0.6780, Val Loss=1.6859, lr=0.0010
[2025-05-02 21:40:07,398][train][INFO] - Epoch 95/100, Val Acc=0.7181, Val Loss=1.3843, lr=0.0001
[2025-05-02 21:40:08,345][train][INFO] - Epoch 167/200, Val Acc=0.6775, Val Loss=1.6944, lr=0.0010
[2025-05-02 21:40:14,648][train][INFO] - Epoch 96/100, Val Acc=0.7180, Val Loss=1.3841, lr=0.0001
[2025-05-02 21:40:16,774][train][INFO] - Epoch 168/200, Val Acc=0.6786, Val Loss=1.7017, lr=0.0010
[2025-05-02 21:40:22,576][train][INFO] - Epoch 97/100, Val Acc=0.7174, Val Loss=1.3861, lr=0.0001
[2025-05-02 21:40:24,971][train][INFO] - Epoch 169/200, Val Acc=0.6825, Val Loss=1.6911, lr=0.0010
[2025-05-02 21:40:30,901][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3830, lr=0.0001
[2025-05-02 21:40:33,133][train][INFO] - Epoch 170/200, Val Acc=0.6783, Val Loss=1.7016, lr=0.0010
[2025-05-02 21:40:38,819][train][INFO] - Epoch 99/100, Val Acc=0.7174, Val Loss=1.3896, lr=0.0001
[2025-05-02 21:40:41,094][train][INFO] - Epoch 171/200, Val Acc=0.6796, Val Loss=1.6969, lr=0.0001
[2025-05-02 21:40:47,136][train][INFO] - Epoch 100/100, Val Acc=0.7183, Val Loss=1.3838, lr=0.0001
[2025-05-02 21:40:49,680][train][INFO] - Epoch 172/200, Val Acc=0.6796, Val Loss=1.6882, lr=0.0001
[2025-05-02 21:40:52,399][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7193
[2025-05-02 21:40:56,945][train][INFO] - Epoch 173/200, Val Acc=0.6786, Val Loss=1.6940, lr=0.0001
[2025-05-02 21:41:01,676][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 21:41:01,676][Progressive pruning][INFO] - Current speed up: 2.01
[2025-05-02 21:41:04,953][train][INFO] - Epoch 174/200, Val Acc=0.6783, Val Loss=1.6954, lr=0.0001
[2025-05-02 21:41:07,016][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 21:41:12,958][train][INFO] - Epoch 175/200, Val Acc=0.6789, Val Loss=1.6957, lr=0.0001
[2025-05-02 21:41:15,164][train][INFO] - Epoch 1/200, Val Acc=0.4570, Val Loss=2.2472, lr=0.0100
[2025-05-02 21:41:21,239][train][INFO] - Epoch 176/200, Val Acc=0.6812, Val Loss=1.6942, lr=0.0001
[2025-05-02 21:41:23,451][train][INFO] - Epoch 2/200, Val Acc=0.5241, Val Loss=1.9460, lr=0.0100
[2025-05-02 21:41:28,895][train][INFO] - Epoch 177/200, Val Acc=0.6805, Val Loss=1.6933, lr=0.0001
[2025-05-02 21:41:31,219][train][INFO] - Epoch 3/200, Val Acc=0.5379, Val Loss=1.9382, lr=0.0100
[2025-05-02 21:41:36,824][train][INFO] - Epoch 178/200, Val Acc=0.6805, Val Loss=1.6942, lr=0.0001
[2025-05-02 21:41:39,253][train][INFO] - Epoch 4/200, Val Acc=0.5208, Val Loss=2.0504, lr=0.0100
[2025-05-02 21:41:45,234][train][INFO] - Epoch 179/200, Val Acc=0.6799, Val Loss=1.6965, lr=0.0001
[2025-05-02 21:41:47,510][train][INFO] - Epoch 5/200, Val Acc=0.5584, Val Loss=1.8864, lr=0.0100
[2025-05-02 21:41:53,694][train][INFO] - Epoch 180/200, Val Acc=0.6809, Val Loss=1.6878, lr=0.0001
[2025-05-02 21:41:55,153][train][INFO] - Epoch 6/200, Val Acc=0.5743, Val Loss=1.8308, lr=0.0100
[2025-05-02 21:42:01,121][train][INFO] - Epoch 181/200, Val Acc=0.6810, Val Loss=1.6913, lr=0.0001
[2025-05-02 21:42:03,272][train][INFO] - Epoch 7/200, Val Acc=0.5906, Val Loss=1.7226, lr=0.0100
[2025-05-02 21:42:09,296][train][INFO] - Epoch 182/200, Val Acc=0.6822, Val Loss=1.6988, lr=0.0001
[2025-05-02 21:42:10,963][train][INFO] - Epoch 8/200, Val Acc=0.5891, Val Loss=1.7450, lr=0.0100
[2025-05-02 21:42:17,940][train][INFO] - Epoch 183/200, Val Acc=0.6805, Val Loss=1.6917, lr=0.0001
[2025-05-02 21:42:19,268][train][INFO] - Epoch 9/200, Val Acc=0.5843, Val Loss=1.7750, lr=0.0100
[2025-05-02 21:42:25,594][train][INFO] - Epoch 184/200, Val Acc=0.6810, Val Loss=1.6926, lr=0.0001
[2025-05-02 21:42:27,614][train][INFO] - Epoch 10/200, Val Acc=0.6002, Val Loss=1.6878, lr=0.0100
[2025-05-02 21:42:33,869][train][INFO] - Epoch 185/200, Val Acc=0.6808, Val Loss=1.6944, lr=0.0001
[2025-05-02 21:42:35,716][train][INFO] - Epoch 11/200, Val Acc=0.5940, Val Loss=1.6556, lr=0.0100
[2025-05-02 21:42:42,145][train][INFO] - Epoch 186/200, Val Acc=0.6806, Val Loss=1.6876, lr=0.0001
[2025-05-02 21:42:43,403][train][INFO] - Epoch 12/200, Val Acc=0.5876, Val Loss=1.7747, lr=0.0100
[2025-05-02 21:42:50,505][train][INFO] - Epoch 187/200, Val Acc=0.6804, Val Loss=1.6892, lr=0.0001
[2025-05-02 21:42:51,830][train][INFO] - Epoch 13/200, Val Acc=0.5901, Val Loss=1.8052, lr=0.0100
[2025-05-02 21:42:58,337][train][INFO] - Epoch 188/200, Val Acc=0.6818, Val Loss=1.6872, lr=0.0001
[2025-05-02 21:42:59,695][train][INFO] - Epoch 14/200, Val Acc=0.6157, Val Loss=1.6221, lr=0.0100
[2025-05-02 21:43:06,789][train][INFO] - Epoch 189/200, Val Acc=0.6794, Val Loss=1.6935, lr=0.0001
[2025-05-02 21:43:08,011][train][INFO] - Epoch 15/200, Val Acc=0.5862, Val Loss=1.8437, lr=0.0100
[2025-05-02 21:43:14,850][train][INFO] - Epoch 190/200, Val Acc=0.6823, Val Loss=1.6915, lr=0.0001
[2025-05-02 21:43:15,699][train][INFO] - Epoch 16/200, Val Acc=0.6022, Val Loss=1.7187, lr=0.0100
[2025-05-02 21:43:22,855][train][INFO] - Epoch 191/200, Val Acc=0.6803, Val Loss=1.6937, lr=0.0001
[2025-05-02 21:43:23,982][train][INFO] - Epoch 17/200, Val Acc=0.6193, Val Loss=1.6110, lr=0.0100
[2025-05-02 21:43:31,292][train][INFO] - Epoch 192/200, Val Acc=0.6800, Val Loss=1.6977, lr=0.0001
[2025-05-02 21:43:32,142][train][INFO] - Epoch 18/200, Val Acc=0.6150, Val Loss=1.6520, lr=0.0100
[2025-05-02 21:43:39,647][train][INFO] - Epoch 193/200, Val Acc=0.6815, Val Loss=1.6934, lr=0.0001
[2025-05-02 21:43:40,493][train][INFO] - Epoch 19/200, Val Acc=0.5972, Val Loss=1.7275, lr=0.0100
[2025-05-02 21:43:47,185][train][INFO] - Epoch 194/200, Val Acc=0.6808, Val Loss=1.6934, lr=0.0001
[2025-05-02 21:43:48,610][train][INFO] - Epoch 20/200, Val Acc=0.6054, Val Loss=1.7399, lr=0.0100
[2025-05-02 21:43:55,051][train][INFO] - Epoch 195/200, Val Acc=0.6799, Val Loss=1.6941, lr=0.0001
[2025-05-02 21:43:56,876][train][INFO] - Epoch 21/200, Val Acc=0.5969, Val Loss=1.8507, lr=0.0100
[2025-05-02 21:44:03,211][train][INFO] - Epoch 196/200, Val Acc=0.6811, Val Loss=1.6900, lr=0.0001
[2025-05-02 21:44:05,761][train][INFO] - Epoch 22/200, Val Acc=0.6020, Val Loss=1.7681, lr=0.0100
[2025-05-02 21:44:11,015][train][INFO] - Epoch 197/200, Val Acc=0.6812, Val Loss=1.6981, lr=0.0001
[2025-05-02 21:44:13,612][train][INFO] - Epoch 23/200, Val Acc=0.5847, Val Loss=1.9206, lr=0.0100
[2025-05-02 21:44:19,452][train][INFO] - Epoch 198/200, Val Acc=0.6818, Val Loss=1.6973, lr=0.0001
[2025-05-02 21:44:21,195][train][INFO] - Epoch 24/200, Val Acc=0.6217, Val Loss=1.6659, lr=0.0100
[2025-05-02 21:44:27,778][train][INFO] - Epoch 199/200, Val Acc=0.6807, Val Loss=1.6951, lr=0.0001
[2025-05-02 21:44:28,215][train][INFO] - Epoch 25/200, Val Acc=0.6207, Val Loss=1.6672, lr=0.0100
[2025-05-02 21:44:35,733][train][INFO] - Epoch 200/200, Val Acc=0.6817, Val Loss=1.6935, lr=0.0001
[2025-05-02 21:44:36,248][train][INFO] - Epoch 26/200, Val Acc=0.6180, Val Loss=1.6793, lr=0.0100
[2025-05-02 21:44:41,205][train][INFO] - After training : Train Acc=0.9946  Val Acc=0.6825
[2025-05-02 21:44:41,241][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(29, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(72, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(124, 233, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(233, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(233, 197, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(197, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(197, 111, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(111, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(111, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(23, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(10, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(10, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(11, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=59, out_features=100, bias=True)
)
[2025-05-02 21:44:41,241][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.6825000047683716
                      Speed up: 2.00   Final speed up: 6.01
[2025-05-02 21:44:44,504][train][INFO] - Epoch 27/200, Val Acc=0.6118, Val Loss=1.7367, lr=0.0100
[2025-05-02 21:44:52,145][train][INFO] - Epoch 28/200, Val Acc=0.6121, Val Loss=1.7146, lr=0.0100
[2025-05-02 21:44:59,729][train][INFO] - Epoch 29/200, Val Acc=0.6153, Val Loss=1.7232, lr=0.0100
[2025-05-02 21:45:08,032][train][INFO] - Epoch 30/200, Val Acc=0.6216, Val Loss=1.6590, lr=0.0100
[2025-05-02 21:45:15,855][train][INFO] - Epoch 31/200, Val Acc=0.6168, Val Loss=1.7242, lr=0.0100
[2025-05-02 21:45:23,754][train][INFO] - Epoch 32/200, Val Acc=0.6090, Val Loss=1.7436, lr=0.0100
[2025-05-02 21:45:31,221][train][INFO] - Epoch 33/200, Val Acc=0.6071, Val Loss=1.7722, lr=0.0100
[2025-05-02 21:45:38,841][train][INFO] - Epoch 34/200, Val Acc=0.6034, Val Loss=1.7449, lr=0.0100
[2025-05-02 21:45:46,288][train][INFO] - Epoch 35/200, Val Acc=0.6131, Val Loss=1.7263, lr=0.0100
[2025-05-02 21:45:53,301][train][INFO] - Epoch 36/200, Val Acc=0.6024, Val Loss=1.7947, lr=0.0100
[2025-05-02 21:46:00,890][train][INFO] - Epoch 37/200, Val Acc=0.6199, Val Loss=1.7024, lr=0.0100
[2025-05-02 21:46:09,342][train][INFO] - Epoch 38/200, Val Acc=0.6147, Val Loss=1.7307, lr=0.0100
[2025-05-02 21:46:17,295][train][INFO] - Epoch 39/200, Val Acc=0.6173, Val Loss=1.7136, lr=0.0100
[2025-05-02 21:46:24,910][train][INFO] - Epoch 40/200, Val Acc=0.6170, Val Loss=1.7604, lr=0.0100
[2025-05-02 21:46:32,576][train][INFO] - Epoch 41/200, Val Acc=0.6165, Val Loss=1.7165, lr=0.0100
[2025-05-02 21:46:41,169][train][INFO] - Epoch 42/200, Val Acc=0.5980, Val Loss=1.7953, lr=0.0100
[2025-05-02 21:46:48,969][train][INFO] - Epoch 43/200, Val Acc=0.6221, Val Loss=1.7500, lr=0.0100
[2025-05-02 21:46:56,700][train][INFO] - Epoch 44/200, Val Acc=0.6127, Val Loss=1.7762, lr=0.0100
[2025-05-02 21:47:04,517][train][INFO] - Epoch 45/200, Val Acc=0.6012, Val Loss=1.8429, lr=0.0100
[2025-05-02 21:47:11,241][train][INFO] - Epoch 46/200, Val Acc=0.6182, Val Loss=1.7642, lr=0.0100
[2025-05-02 21:47:18,400][train][INFO] - Epoch 47/200, Val Acc=0.5971, Val Loss=1.8991, lr=0.0100
[2025-05-02 21:47:26,386][train][INFO] - Epoch 48/200, Val Acc=0.6060, Val Loss=1.7546, lr=0.0100
[2025-05-02 21:47:34,343][train][INFO] - Epoch 49/200, Val Acc=0.5889, Val Loss=1.9231, lr=0.0100
[2025-05-02 21:47:41,298][train][INFO] - Epoch 50/200, Val Acc=0.6081, Val Loss=1.7846, lr=0.0100
[2025-05-02 21:47:49,031][train][INFO] - Epoch 51/200, Val Acc=0.6143, Val Loss=1.8028, lr=0.0100
[2025-05-02 21:47:56,000][train][INFO] - Epoch 52/200, Val Acc=0.6182, Val Loss=1.7157, lr=0.0100
[2025-05-02 21:48:03,185][train][INFO] - Epoch 53/200, Val Acc=0.6174, Val Loss=1.7347, lr=0.0100
[2025-05-02 21:48:11,851][train][INFO] - Epoch 54/200, Val Acc=0.6164, Val Loss=1.7565, lr=0.0100
[2025-05-02 21:48:19,458][train][INFO] - Epoch 55/200, Val Acc=0.6187, Val Loss=1.7683, lr=0.0100
[2025-05-02 21:48:27,643][train][INFO] - Epoch 56/200, Val Acc=0.6204, Val Loss=1.7548, lr=0.0100
[2025-05-02 21:48:35,138][train][INFO] - Epoch 57/200, Val Acc=0.6216, Val Loss=1.7056, lr=0.0100
[2025-05-02 21:48:43,269][train][INFO] - Epoch 58/200, Val Acc=0.6227, Val Loss=1.6998, lr=0.0100
[2025-05-02 21:48:50,942][train][INFO] - Epoch 59/200, Val Acc=0.6050, Val Loss=1.8355, lr=0.0100
[2025-05-02 21:48:58,695][train][INFO] - Epoch 60/200, Val Acc=0.6146, Val Loss=1.8062, lr=0.0100
[2025-05-02 21:49:05,946][train][INFO] - Epoch 61/200, Val Acc=0.6191, Val Loss=1.7513, lr=0.0100
[2025-05-02 21:49:13,869][train][INFO] - Epoch 62/200, Val Acc=0.6047, Val Loss=1.8208, lr=0.0100
[2025-05-02 21:49:21,427][train][INFO] - Epoch 63/200, Val Acc=0.6100, Val Loss=1.8138, lr=0.0100
[2025-05-02 21:49:28,357][train][INFO] - Epoch 64/200, Val Acc=0.6197, Val Loss=1.7032, lr=0.0100
[2025-05-02 21:49:36,573][train][INFO] - Epoch 65/200, Val Acc=0.6257, Val Loss=1.7116, lr=0.0100
[2025-05-02 21:49:44,043][train][INFO] - Epoch 66/200, Val Acc=0.6102, Val Loss=1.8012, lr=0.0100
[2025-05-02 21:49:51,303][train][INFO] - Epoch 67/200, Val Acc=0.6206, Val Loss=1.7648, lr=0.0100
[2025-05-02 21:49:58,812][train][INFO] - Epoch 68/200, Val Acc=0.6218, Val Loss=1.7229, lr=0.0100
[2025-05-02 21:50:05,918][train][INFO] - Epoch 69/200, Val Acc=0.6181, Val Loss=1.7604, lr=0.0100
[2025-05-02 21:50:13,445][train][INFO] - Epoch 70/200, Val Acc=0.6343, Val Loss=1.7093, lr=0.0100
[2025-05-02 21:50:21,233][train][INFO] - Epoch 71/200, Val Acc=0.6181, Val Loss=1.7802, lr=0.0100
[2025-05-02 21:50:29,351][train][INFO] - Epoch 72/200, Val Acc=0.6149, Val Loss=1.7823, lr=0.0100
[2025-05-02 21:50:37,221][train][INFO] - Epoch 73/200, Val Acc=0.6048, Val Loss=1.8453, lr=0.0100
[2025-05-02 21:50:44,808][train][INFO] - Epoch 74/200, Val Acc=0.6241, Val Loss=1.7427, lr=0.0100
[2025-05-02 21:50:52,321][train][INFO] - Epoch 75/200, Val Acc=0.6269, Val Loss=1.7568, lr=0.0100
[2025-05-02 21:50:59,875][train][INFO] - Epoch 76/200, Val Acc=0.6135, Val Loss=1.8080, lr=0.0100
[2025-05-02 21:51:07,795][train][INFO] - Epoch 77/200, Val Acc=0.6206, Val Loss=1.7639, lr=0.0100
[2025-05-02 21:51:16,015][train][INFO] - Epoch 78/200, Val Acc=0.6174, Val Loss=1.7679, lr=0.0100
[2025-05-02 21:51:24,016][train][INFO] - Epoch 79/200, Val Acc=0.6011, Val Loss=1.8495, lr=0.0100
[2025-05-02 21:51:32,144][train][INFO] - Epoch 80/200, Val Acc=0.6091, Val Loss=1.8958, lr=0.0100
[2025-05-02 21:51:39,673][train][INFO] - Epoch 81/200, Val Acc=0.6182, Val Loss=1.7999, lr=0.0100
[2025-05-02 21:51:47,621][train][INFO] - Epoch 82/200, Val Acc=0.6252, Val Loss=1.7467, lr=0.0100
[2025-05-02 21:51:55,512][train][INFO] - Epoch 83/200, Val Acc=0.6184, Val Loss=1.7718, lr=0.0100
[2025-05-02 21:52:02,436][train][INFO] - Epoch 84/200, Val Acc=0.6184, Val Loss=1.8119, lr=0.0100
[2025-05-02 21:52:10,854][train][INFO] - Epoch 85/200, Val Acc=0.6386, Val Loss=1.6381, lr=0.0100
[2025-05-02 21:52:18,414][train][INFO] - Epoch 86/200, Val Acc=0.6179, Val Loss=1.7579, lr=0.0100
[2025-05-02 21:52:26,063][train][INFO] - Epoch 87/200, Val Acc=0.6263, Val Loss=1.6977, lr=0.0100
[2025-05-02 21:52:34,258][train][INFO] - Epoch 88/200, Val Acc=0.6187, Val Loss=1.7538, lr=0.0100
[2025-05-02 21:52:41,197][train][INFO] - Epoch 89/200, Val Acc=0.6199, Val Loss=1.7285, lr=0.0100
[2025-05-02 21:52:48,106][train][INFO] - Epoch 90/200, Val Acc=0.6115, Val Loss=1.8380, lr=0.0100
[2025-05-02 21:52:55,677][train][INFO] - Epoch 91/200, Val Acc=0.6187, Val Loss=1.7786, lr=0.0100
[2025-05-02 21:53:03,558][train][INFO] - Epoch 92/200, Val Acc=0.6062, Val Loss=1.8836, lr=0.0100
[2025-05-02 21:53:11,699][train][INFO] - Epoch 93/200, Val Acc=0.6196, Val Loss=1.7888, lr=0.0100
[2025-05-02 21:53:20,134][train][INFO] - Epoch 94/200, Val Acc=0.6084, Val Loss=1.8070, lr=0.0100
[2025-05-02 21:53:27,386][train][INFO] - Epoch 95/200, Val Acc=0.6132, Val Loss=1.7615, lr=0.0100
[2025-05-02 21:53:35,330][train][INFO] - Epoch 96/200, Val Acc=0.6157, Val Loss=1.7420, lr=0.0100
[2025-05-02 21:53:42,552][train][INFO] - Epoch 97/200, Val Acc=0.6032, Val Loss=1.9019, lr=0.0100
[2025-05-02 21:53:50,139][train][INFO] - Epoch 98/200, Val Acc=0.6088, Val Loss=1.8441, lr=0.0100
[2025-05-02 21:53:58,020][train][INFO] - Epoch 99/200, Val Acc=0.6218, Val Loss=1.7716, lr=0.0100
[2025-05-02 21:54:05,965][train][INFO] - Epoch 100/200, Val Acc=0.6161, Val Loss=1.7968, lr=0.0100
[2025-05-02 21:54:13,890][train][INFO] - Epoch 101/200, Val Acc=0.6331, Val Loss=1.7238, lr=0.0100
[2025-05-02 21:54:21,324][train][INFO] - Epoch 102/200, Val Acc=0.6257, Val Loss=1.7563, lr=0.0100
[2025-05-02 21:54:28,943][train][INFO] - Epoch 103/200, Val Acc=0.6253, Val Loss=1.7414, lr=0.0100
[2025-05-02 21:54:37,060][train][INFO] - Epoch 104/200, Val Acc=0.6187, Val Loss=1.7913, lr=0.0100
[2025-05-02 21:54:45,294][train][INFO] - Epoch 105/200, Val Acc=0.6208, Val Loss=1.7415, lr=0.0100
[2025-05-02 21:54:52,349][train][INFO] - Epoch 106/200, Val Acc=0.6238, Val Loss=1.7834, lr=0.0100
[2025-05-02 21:55:00,151][train][INFO] - Epoch 107/200, Val Acc=0.6177, Val Loss=1.8153, lr=0.0100
[2025-05-02 21:55:08,129][train][INFO] - Epoch 108/200, Val Acc=0.6049, Val Loss=1.8491, lr=0.0100
[2025-05-02 21:55:15,303][train][INFO] - Epoch 109/200, Val Acc=0.6200, Val Loss=1.7989, lr=0.0100
[2025-05-02 21:55:23,145][train][INFO] - Epoch 110/200, Val Acc=0.6132, Val Loss=1.8104, lr=0.0100
[2025-05-02 21:55:31,386][train][INFO] - Epoch 111/200, Val Acc=0.6136, Val Loss=1.8304, lr=0.0100
[2025-05-02 21:55:39,480][train][INFO] - Epoch 112/200, Val Acc=0.6136, Val Loss=1.7941, lr=0.0100
[2025-05-02 21:55:47,233][train][INFO] - Epoch 113/200, Val Acc=0.6277, Val Loss=1.7281, lr=0.0100
[2025-05-02 21:55:55,748][train][INFO] - Epoch 114/200, Val Acc=0.6228, Val Loss=1.7800, lr=0.0100
[2025-05-02 21:56:03,870][train][INFO] - Epoch 115/200, Val Acc=0.6115, Val Loss=1.8445, lr=0.0100
[2025-05-02 21:56:11,796][train][INFO] - Epoch 116/200, Val Acc=0.6178, Val Loss=1.7500, lr=0.0100
[2025-05-02 21:56:19,936][train][INFO] - Epoch 117/200, Val Acc=0.6166, Val Loss=1.8315, lr=0.0100
[2025-05-02 21:56:27,172][train][INFO] - Epoch 118/200, Val Acc=0.6230, Val Loss=1.7821, lr=0.0100
[2025-05-02 21:56:34,715][train][INFO] - Epoch 119/200, Val Acc=0.6165, Val Loss=1.8382, lr=0.0100
[2025-05-02 21:56:43,212][train][INFO] - Epoch 120/200, Val Acc=0.6037, Val Loss=1.8508, lr=0.0100
[2025-05-02 21:56:50,655][train][INFO] - Epoch 121/200, Val Acc=0.6772, Val Loss=1.4787, lr=0.0010
[2025-05-02 21:56:58,227][train][INFO] - Epoch 122/200, Val Acc=0.6826, Val Loss=1.4822, lr=0.0010
[2025-05-02 21:57:06,144][train][INFO] - Epoch 123/200, Val Acc=0.6838, Val Loss=1.4798, lr=0.0010
[2025-05-02 21:57:13,382][train][INFO] - Epoch 124/200, Val Acc=0.6845, Val Loss=1.4809, lr=0.0010
[2025-05-02 21:57:21,254][train][INFO] - Epoch 125/200, Val Acc=0.6855, Val Loss=1.4927, lr=0.0010
[2025-05-02 21:57:29,021][train][INFO] - Epoch 126/200, Val Acc=0.6838, Val Loss=1.4948, lr=0.0010
[2025-05-02 21:57:36,800][train][INFO] - Epoch 127/200, Val Acc=0.6846, Val Loss=1.5095, lr=0.0010
[2025-05-02 21:57:43,388][train][INFO] - Epoch 128/200, Val Acc=0.6845, Val Loss=1.4955, lr=0.0010
[2025-05-02 21:57:50,930][train][INFO] - Epoch 129/200, Val Acc=0.6855, Val Loss=1.5073, lr=0.0010
[2025-05-02 21:57:58,545][train][INFO] - Epoch 130/200, Val Acc=0.6850, Val Loss=1.5019, lr=0.0010
[2025-05-02 21:58:05,741][train][INFO] - Epoch 131/200, Val Acc=0.6819, Val Loss=1.5239, lr=0.0010
[2025-05-02 21:58:13,890][train][INFO] - Epoch 132/200, Val Acc=0.6836, Val Loss=1.5207, lr=0.0010
[2025-05-02 21:58:21,905][train][INFO] - Epoch 133/200, Val Acc=0.6836, Val Loss=1.5287, lr=0.0010
[2025-05-02 21:58:29,928][train][INFO] - Epoch 134/200, Val Acc=0.6853, Val Loss=1.5353, lr=0.0010
[2025-05-02 21:58:37,921][train][INFO] - Epoch 135/200, Val Acc=0.6829, Val Loss=1.5308, lr=0.0010
[2025-05-02 21:58:45,296][train][INFO] - Epoch 136/200, Val Acc=0.6869, Val Loss=1.5337, lr=0.0010
[2025-05-02 21:58:53,603][train][INFO] - Epoch 137/200, Val Acc=0.6840, Val Loss=1.5463, lr=0.0010
[2025-05-02 21:59:00,953][train][INFO] - Epoch 138/200, Val Acc=0.6852, Val Loss=1.5440, lr=0.0010
[2025-05-02 21:59:09,166][train][INFO] - Epoch 139/200, Val Acc=0.6871, Val Loss=1.5476, lr=0.0010
[2025-05-02 21:59:16,976][train][INFO] - Epoch 140/200, Val Acc=0.6831, Val Loss=1.5551, lr=0.0010
[2025-05-02 21:59:24,451][train][INFO] - Epoch 141/200, Val Acc=0.6864, Val Loss=1.5534, lr=0.0010
[2025-05-02 21:59:32,395][train][INFO] - Epoch 142/200, Val Acc=0.6854, Val Loss=1.5756, lr=0.0010
[2025-05-02 21:59:40,075][train][INFO] - Epoch 143/200, Val Acc=0.6832, Val Loss=1.5662, lr=0.0010
[2025-05-02 21:59:47,432][train][INFO] - Epoch 144/200, Val Acc=0.6838, Val Loss=1.5688, lr=0.0010
[2025-05-02 21:59:54,525][train][INFO] - Epoch 145/200, Val Acc=0.6861, Val Loss=1.5677, lr=0.0010
[2025-05-02 22:00:02,469][train][INFO] - Epoch 146/200, Val Acc=0.6844, Val Loss=1.5801, lr=0.0010
[2025-05-02 22:00:10,334][train][INFO] - Epoch 147/200, Val Acc=0.6854, Val Loss=1.5778, lr=0.0010
[2025-05-02 22:00:18,259][train][INFO] - Epoch 148/200, Val Acc=0.6856, Val Loss=1.5691, lr=0.0010
[2025-05-02 22:00:25,917][train][INFO] - Epoch 149/200, Val Acc=0.6828, Val Loss=1.5808, lr=0.0010
[2025-05-02 22:00:34,095][train][INFO] - Epoch 150/200, Val Acc=0.6874, Val Loss=1.5792, lr=0.0010
[2025-05-02 22:00:41,779][train][INFO] - Epoch 151/200, Val Acc=0.6839, Val Loss=1.5849, lr=0.0010
[2025-05-02 22:00:49,704][train][INFO] - Epoch 152/200, Val Acc=0.6855, Val Loss=1.5864, lr=0.0010
[2025-05-02 22:00:57,749][train][INFO] - Epoch 153/200, Val Acc=0.6848, Val Loss=1.5928, lr=0.0010
[2025-05-02 22:01:05,514][train][INFO] - Epoch 154/200, Val Acc=0.6888, Val Loss=1.5955, lr=0.0010
[2025-05-02 22:01:13,408][train][INFO] - Epoch 155/200, Val Acc=0.6841, Val Loss=1.5912, lr=0.0010
[2025-05-02 22:01:21,209][train][INFO] - Epoch 156/200, Val Acc=0.6851, Val Loss=1.5959, lr=0.0010
[2025-05-02 22:01:28,435][train][INFO] - Epoch 157/200, Val Acc=0.6853, Val Loss=1.6004, lr=0.0010
[2025-05-02 22:01:36,288][train][INFO] - Epoch 158/200, Val Acc=0.6853, Val Loss=1.6059, lr=0.0010
[2025-05-02 22:01:43,825][train][INFO] - Epoch 159/200, Val Acc=0.6849, Val Loss=1.6097, lr=0.0010
[2025-05-02 22:01:51,833][train][INFO] - Epoch 160/200, Val Acc=0.6845, Val Loss=1.6061, lr=0.0010
[2025-05-02 22:01:59,075][train][INFO] - Epoch 161/200, Val Acc=0.6870, Val Loss=1.6028, lr=0.0010
[2025-05-02 22:02:06,674][train][INFO] - Epoch 162/200, Val Acc=0.6862, Val Loss=1.5969, lr=0.0010
[2025-05-02 22:02:14,475][train][INFO] - Epoch 163/200, Val Acc=0.6882, Val Loss=1.5982, lr=0.0010
[2025-05-02 22:02:21,954][train][INFO] - Epoch 164/200, Val Acc=0.6835, Val Loss=1.6090, lr=0.0010
[2025-05-02 22:02:30,355][train][INFO] - Epoch 165/200, Val Acc=0.6858, Val Loss=1.6117, lr=0.0010
[2025-05-02 22:02:38,890][train][INFO] - Epoch 166/200, Val Acc=0.6850, Val Loss=1.6140, lr=0.0010
[2025-05-02 22:02:46,630][train][INFO] - Epoch 167/200, Val Acc=0.6861, Val Loss=1.6176, lr=0.0010
[2025-05-02 22:02:54,238][train][INFO] - Epoch 168/200, Val Acc=0.6861, Val Loss=1.6157, lr=0.0010
[2025-05-02 22:03:02,976][train][INFO] - Epoch 169/200, Val Acc=0.6869, Val Loss=1.6039, lr=0.0010
[2025-05-02 22:03:10,912][train][INFO] - Epoch 170/200, Val Acc=0.6853, Val Loss=1.6200, lr=0.0010
[2025-05-02 22:03:18,653][train][INFO] - Epoch 171/200, Val Acc=0.6838, Val Loss=1.6202, lr=0.0001
[2025-05-02 22:03:27,229][train][INFO] - Epoch 172/200, Val Acc=0.6847, Val Loss=1.6122, lr=0.0001
[2025-05-02 22:03:35,003][train][INFO] - Epoch 173/200, Val Acc=0.6849, Val Loss=1.6084, lr=0.0001
[2025-05-02 22:03:42,577][train][INFO] - Epoch 174/200, Val Acc=0.6865, Val Loss=1.6108, lr=0.0001
[2025-05-02 22:03:50,616][train][INFO] - Epoch 175/200, Val Acc=0.6846, Val Loss=1.6173, lr=0.0001
[2025-05-02 22:03:58,048][train][INFO] - Epoch 176/200, Val Acc=0.6847, Val Loss=1.6147, lr=0.0001
[2025-05-02 22:04:06,117][train][INFO] - Epoch 177/200, Val Acc=0.6845, Val Loss=1.6109, lr=0.0001
[2025-05-02 22:04:14,216][train][INFO] - Epoch 178/200, Val Acc=0.6835, Val Loss=1.6088, lr=0.0001
[2025-05-02 22:04:22,050][train][INFO] - Epoch 179/200, Val Acc=0.6835, Val Loss=1.6156, lr=0.0001
[2025-05-02 22:04:29,480][train][INFO] - Epoch 180/200, Val Acc=0.6845, Val Loss=1.6080, lr=0.0001
[2025-05-02 22:04:37,604][train][INFO] - Epoch 181/200, Val Acc=0.6852, Val Loss=1.6135, lr=0.0001
[2025-05-02 22:04:44,963][train][INFO] - Epoch 182/200, Val Acc=0.6842, Val Loss=1.6125, lr=0.0001
[2025-05-02 22:04:52,460][train][INFO] - Epoch 183/200, Val Acc=0.6860, Val Loss=1.6113, lr=0.0001
[2025-05-02 22:05:01,183][train][INFO] - Epoch 184/200, Val Acc=0.6860, Val Loss=1.6099, lr=0.0001
[2025-05-02 22:05:08,767][train][INFO] - Epoch 185/200, Val Acc=0.6867, Val Loss=1.6100, lr=0.0001
[2025-05-02 22:05:16,098][train][INFO] - Epoch 186/200, Val Acc=0.6860, Val Loss=1.6081, lr=0.0001
[2025-05-02 22:05:24,349][train][INFO] - Epoch 187/200, Val Acc=0.6866, Val Loss=1.6094, lr=0.0001
[2025-05-02 22:05:31,778][train][INFO] - Epoch 188/200, Val Acc=0.6854, Val Loss=1.6112, lr=0.0001
[2025-05-02 22:05:40,085][train][INFO] - Epoch 189/200, Val Acc=0.6863, Val Loss=1.6096, lr=0.0001
[2025-05-02 22:05:47,481][train][INFO] - Epoch 190/200, Val Acc=0.6852, Val Loss=1.6150, lr=0.0001
[2025-05-02 22:05:54,614][train][INFO] - Epoch 191/200, Val Acc=0.6841, Val Loss=1.6176, lr=0.0001
[2025-05-02 22:06:02,420][train][INFO] - Epoch 192/200, Val Acc=0.6851, Val Loss=1.6130, lr=0.0001
[2025-05-02 22:06:10,289][train][INFO] - Epoch 193/200, Val Acc=0.6858, Val Loss=1.6105, lr=0.0001
[2025-05-02 22:06:18,377][train][INFO] - Epoch 194/200, Val Acc=0.6857, Val Loss=1.6124, lr=0.0001
[2025-05-02 22:06:26,477][train][INFO] - Epoch 195/200, Val Acc=0.6865, Val Loss=1.6115, lr=0.0001
[2025-05-02 22:06:33,704][train][INFO] - Epoch 196/200, Val Acc=0.6863, Val Loss=1.6100, lr=0.0001
[2025-05-02 22:06:41,151][train][INFO] - Epoch 197/200, Val Acc=0.6840, Val Loss=1.6217, lr=0.0001
[2025-05-02 22:06:49,149][train][INFO] - Epoch 198/200, Val Acc=0.6855, Val Loss=1.6169, lr=0.0001
[2025-05-02 22:06:56,605][train][INFO] - Epoch 199/200, Val Acc=0.6853, Val Loss=1.6180, lr=0.0001
[2025-05-02 22:07:04,387][train][INFO] - Epoch 200/200, Val Acc=0.6851, Val Loss=1.6168, lr=0.0001
[2025-05-02 22:07:09,576][train][INFO] - After training : Train Acc=0.9915  Val Acc=0.6888
[2025-05-02 22:07:09,598][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(21, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(58, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(124, 243, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(243, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(186, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(114, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(114, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(11, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(4, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(14, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(4, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(6, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(17, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=31, out_features=100, bias=True)
)
[2025-05-02 22:07:09,598][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.6887999773025513
                      Speed up: 2.01   Final speed up: 6.05
[2025-05-02 22:28:41,085][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 5.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-02 22:28:41,136][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 22:28:41,136][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 22:28:41,136][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 22:28:57,816][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 22:29:06,682][train][INFO] - Epoch 1/100, Val Acc=0.1656, Val Loss=3.1948, lr=0.0100
[2025-05-02 22:29:14,904][train][INFO] - Epoch 2/100, Val Acc=0.3536, Val Loss=2.3640, lr=0.0100
[2025-05-02 22:29:23,101][train][INFO] - Epoch 3/100, Val Acc=0.4319, Val Loss=2.1507, lr=0.0100
[2025-05-02 22:29:30,973][train][INFO] - Epoch 4/100, Val Acc=0.4925, Val Loss=1.8823, lr=0.0100
[2025-05-02 22:29:38,705][train][INFO] - Epoch 5/100, Val Acc=0.5224, Val Loss=1.8290, lr=0.0100
[2025-05-02 22:29:47,570][train][INFO] - Epoch 6/100, Val Acc=0.5208, Val Loss=1.8555, lr=0.0100
[2025-05-02 22:29:56,058][train][INFO] - Epoch 7/100, Val Acc=0.5505, Val Loss=1.7337, lr=0.0100
[2025-05-02 22:30:03,087][train][INFO] - Epoch 8/100, Val Acc=0.5731, Val Loss=1.6407, lr=0.0100
[2025-05-02 22:30:05,335][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 5.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-02 22:30:05,387][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 22:30:05,387][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 22:30:05,387][get_dataset_model_loader][INFO] - ==================================================
[2025-05-02 22:30:11,396][train][INFO] - Epoch 9/100, Val Acc=0.5858, Val Loss=1.5636, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 22:30:20,071][train][INFO] - Epoch 10/100, Val Acc=0.6031, Val Loss=1.5387, lr=0.0100
[2025-05-02 22:30:22,654][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 22:30:28,491][train][INFO] - Epoch 11/100, Val Acc=0.6026, Val Loss=1.5312, lr=0.0100
[2025-05-02 22:30:29,310][train][INFO] - Epoch 1/100, Val Acc=0.1656, Val Loss=3.1948, lr=0.0100
[2025-05-02 22:30:34,827][train][INFO] - Epoch 12/100, Val Acc=0.6125, Val Loss=1.5101, lr=0.0100
[2025-05-02 22:30:37,922][train][INFO] - Epoch 2/100, Val Acc=0.3536, Val Loss=2.3640, lr=0.0100
[2025-05-02 22:30:43,205][train][INFO] - Epoch 13/100, Val Acc=0.5865, Val Loss=1.6591, lr=0.0100
[2025-05-02 22:30:45,985][train][INFO] - Epoch 3/100, Val Acc=0.4319, Val Loss=2.1507, lr=0.0100
[2025-05-02 22:30:51,236][train][INFO] - Epoch 14/100, Val Acc=0.6221, Val Loss=1.4760, lr=0.0100
[2025-05-02 22:30:53,928][train][INFO] - Epoch 4/100, Val Acc=0.4925, Val Loss=1.8823, lr=0.0100
[2025-05-02 22:30:59,442][train][INFO] - Epoch 15/100, Val Acc=0.6008, Val Loss=1.5581, lr=0.0100
[2025-05-02 22:31:02,717][train][INFO] - Epoch 5/100, Val Acc=0.5224, Val Loss=1.8290, lr=0.0100
[2025-05-02 22:31:07,529][train][INFO] - Epoch 16/100, Val Acc=0.5950, Val Loss=1.6448, lr=0.0100
[2025-05-02 22:31:11,168][train][INFO] - Epoch 6/100, Val Acc=0.5208, Val Loss=1.8555, lr=0.0100
[2025-05-02 22:31:16,043][train][INFO] - Epoch 17/100, Val Acc=0.6048, Val Loss=1.5769, lr=0.0100
[2025-05-02 22:31:18,896][train][INFO] - Epoch 7/100, Val Acc=0.5505, Val Loss=1.7337, lr=0.0100
[2025-05-02 22:31:24,289][train][INFO] - Epoch 18/100, Val Acc=0.6307, Val Loss=1.4623, lr=0.0100
[2025-05-02 22:31:27,264][train][INFO] - Epoch 8/100, Val Acc=0.5731, Val Loss=1.6407, lr=0.0100
[2025-05-02 22:31:32,088][train][INFO] - Epoch 19/100, Val Acc=0.6108, Val Loss=1.5797, lr=0.0100
[2025-05-02 22:31:35,236][train][INFO] - Epoch 9/100, Val Acc=0.5858, Val Loss=1.5636, lr=0.0100
[2025-05-02 22:31:40,443][train][INFO] - Epoch 20/100, Val Acc=0.6146, Val Loss=1.5706, lr=0.0100
[2025-05-02 22:31:43,456][train][INFO] - Epoch 10/100, Val Acc=0.6031, Val Loss=1.5387, lr=0.0100
[2025-05-02 22:31:48,479][train][INFO] - Epoch 21/100, Val Acc=0.6322, Val Loss=1.4814, lr=0.0100
[2025-05-02 22:31:51,491][train][INFO] - Epoch 11/100, Val Acc=0.6026, Val Loss=1.5312, lr=0.0100
[2025-05-02 22:31:56,375][train][INFO] - Epoch 22/100, Val Acc=0.6236, Val Loss=1.5283, lr=0.0100
[2025-05-02 22:31:59,021][train][INFO] - Epoch 12/100, Val Acc=0.6125, Val Loss=1.5101, lr=0.0100
[2025-05-02 22:32:04,692][train][INFO] - Epoch 23/100, Val Acc=0.6347, Val Loss=1.4687, lr=0.0100
[2025-05-02 22:32:07,405][train][INFO] - Epoch 13/100, Val Acc=0.5865, Val Loss=1.6591, lr=0.0100
[2025-05-02 22:32:13,222][train][INFO] - Epoch 24/100, Val Acc=0.6452, Val Loss=1.4568, lr=0.0100
[2025-05-02 22:32:15,880][train][INFO] - Epoch 14/100, Val Acc=0.6221, Val Loss=1.4760, lr=0.0100
[2025-05-02 22:32:21,550][train][INFO] - Epoch 25/100, Val Acc=0.6310, Val Loss=1.5355, lr=0.0100
[2025-05-02 22:32:24,197][train][INFO] - Epoch 15/100, Val Acc=0.6008, Val Loss=1.5581, lr=0.0100
[2025-05-02 22:32:29,480][train][INFO] - Epoch 26/100, Val Acc=0.6261, Val Loss=1.5884, lr=0.0100
[2025-05-02 22:32:32,470][train][INFO] - Epoch 16/100, Val Acc=0.5950, Val Loss=1.6448, lr=0.0100
[2025-05-02 22:32:37,949][train][INFO] - Epoch 27/100, Val Acc=0.6376, Val Loss=1.4824, lr=0.0100
[2025-05-02 22:32:41,097][train][INFO] - Epoch 17/100, Val Acc=0.6048, Val Loss=1.5769, lr=0.0100
[2025-05-02 22:32:45,921][train][INFO] - Epoch 28/100, Val Acc=0.6306, Val Loss=1.5536, lr=0.0100
[2025-05-02 22:32:49,041][train][INFO] - Epoch 18/100, Val Acc=0.6307, Val Loss=1.4623, lr=0.0100
[2025-05-02 22:32:54,507][train][INFO] - Epoch 29/100, Val Acc=0.6305, Val Loss=1.5611, lr=0.0100
[2025-05-02 22:32:57,347][train][INFO] - Epoch 19/100, Val Acc=0.6108, Val Loss=1.5797, lr=0.0100
[2025-05-02 22:33:02,479][train][INFO] - Epoch 30/100, Val Acc=0.6494, Val Loss=1.4854, lr=0.0100
[2025-05-02 22:33:05,521][train][INFO] - Epoch 20/100, Val Acc=0.6146, Val Loss=1.5706, lr=0.0100
[2025-05-02 22:33:10,290][train][INFO] - Epoch 31/100, Val Acc=0.6348, Val Loss=1.5276, lr=0.0100
[2025-05-02 22:33:13,375][train][INFO] - Epoch 21/100, Val Acc=0.6322, Val Loss=1.4814, lr=0.0100
[2025-05-02 22:33:18,105][train][INFO] - Epoch 32/100, Val Acc=0.6472, Val Loss=1.5131, lr=0.0100
[2025-05-02 22:33:21,279][train][INFO] - Epoch 22/100, Val Acc=0.6236, Val Loss=1.5283, lr=0.0100
[2025-05-02 22:33:25,747][train][INFO] - Epoch 33/100, Val Acc=0.6351, Val Loss=1.5556, lr=0.0100
[2025-05-02 22:33:29,715][train][INFO] - Epoch 23/100, Val Acc=0.6347, Val Loss=1.4687, lr=0.0100
[2025-05-02 22:33:34,409][train][INFO] - Epoch 34/100, Val Acc=0.6468, Val Loss=1.4801, lr=0.0100
[2025-05-02 22:33:37,769][train][INFO] - Epoch 24/100, Val Acc=0.6452, Val Loss=1.4568, lr=0.0100
[2025-05-02 22:33:42,850][train][INFO] - Epoch 35/100, Val Acc=0.6452, Val Loss=1.5242, lr=0.0100
[2025-05-02 22:33:46,168][train][INFO] - Epoch 25/100, Val Acc=0.6310, Val Loss=1.5355, lr=0.0100
[2025-05-02 22:33:51,036][train][INFO] - Epoch 36/100, Val Acc=0.6477, Val Loss=1.4958, lr=0.0100
[2025-05-02 22:33:54,294][train][INFO] - Epoch 26/100, Val Acc=0.6261, Val Loss=1.5884, lr=0.0100
[2025-05-02 22:33:59,319][train][INFO] - Epoch 37/100, Val Acc=0.6431, Val Loss=1.5379, lr=0.0100
[2025-05-02 22:34:02,377][train][INFO] - Epoch 27/100, Val Acc=0.6376, Val Loss=1.4824, lr=0.0100
[2025-05-02 22:34:06,635][train][INFO] - Epoch 38/100, Val Acc=0.6431, Val Loss=1.5372, lr=0.0100
[2025-05-02 22:34:10,771][train][INFO] - Epoch 28/100, Val Acc=0.6306, Val Loss=1.5536, lr=0.0100
[2025-05-02 22:34:15,221][train][INFO] - Epoch 39/100, Val Acc=0.6412, Val Loss=1.5501, lr=0.0100
[2025-05-02 22:34:17,718][train][INFO] - Epoch 29/100, Val Acc=0.6305, Val Loss=1.5611, lr=0.0100
[2025-05-02 22:34:23,032][train][INFO] - Epoch 40/100, Val Acc=0.6363, Val Loss=1.5587, lr=0.0100
[2025-05-02 22:34:26,166][train][INFO] - Epoch 30/100, Val Acc=0.6494, Val Loss=1.4854, lr=0.0100
[2025-05-02 22:34:31,609][train][INFO] - Epoch 41/100, Val Acc=0.6514, Val Loss=1.5202, lr=0.0100
[2025-05-02 22:34:34,551][train][INFO] - Epoch 31/100, Val Acc=0.6348, Val Loss=1.5276, lr=0.0100
[2025-05-02 22:34:40,291][train][INFO] - Epoch 42/100, Val Acc=0.6327, Val Loss=1.5960, lr=0.0100
[2025-05-02 22:34:42,958][train][INFO] - Epoch 32/100, Val Acc=0.6472, Val Loss=1.5131, lr=0.0100
[2025-05-02 22:34:48,668][train][INFO] - Epoch 43/100, Val Acc=0.6315, Val Loss=1.6271, lr=0.0100
[2025-05-02 22:34:50,583][train][INFO] - Epoch 33/100, Val Acc=0.6351, Val Loss=1.5556, lr=0.0100
[2025-05-02 22:34:57,427][train][INFO] - Epoch 44/100, Val Acc=0.6359, Val Loss=1.5788, lr=0.0100
[2025-05-02 22:34:59,039][train][INFO] - Epoch 34/100, Val Acc=0.6468, Val Loss=1.4801, lr=0.0100
[2025-05-02 22:35:05,648][train][INFO] - Epoch 45/100, Val Acc=0.6437, Val Loss=1.5394, lr=0.0100
[2025-05-02 22:35:06,781][train][INFO] - Epoch 35/100, Val Acc=0.6452, Val Loss=1.5242, lr=0.0100
[2025-05-02 22:35:14,050][train][INFO] - Epoch 46/100, Val Acc=0.6422, Val Loss=1.5754, lr=0.0100
[2025-05-02 22:35:14,894][train][INFO] - Epoch 36/100, Val Acc=0.6477, Val Loss=1.4958, lr=0.0100
[2025-05-02 22:35:22,502][train][INFO] - Epoch 47/100, Val Acc=0.6510, Val Loss=1.5401, lr=0.0100
[2025-05-02 22:35:23,165][train][INFO] - Epoch 37/100, Val Acc=0.6431, Val Loss=1.5379, lr=0.0100
[2025-05-02 22:35:30,706][train][INFO] - Epoch 48/100, Val Acc=0.6352, Val Loss=1.6443, lr=0.0100
[2025-05-02 22:35:31,347][train][INFO] - Epoch 38/100, Val Acc=0.6431, Val Loss=1.5372, lr=0.0100
[2025-05-02 22:35:39,069][train][INFO] - Epoch 49/100, Val Acc=0.6451, Val Loss=1.5788, lr=0.0100
[2025-05-02 22:35:39,130][train][INFO] - Epoch 39/100, Val Acc=0.6412, Val Loss=1.5501, lr=0.0100
[2025-05-02 22:35:46,982][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.5818, lr=0.0100
[2025-05-02 22:35:47,218][train][INFO] - Epoch 40/100, Val Acc=0.6363, Val Loss=1.5587, lr=0.0100
[2025-05-02 22:35:54,709][train][INFO] - Epoch 41/100, Val Acc=0.6514, Val Loss=1.5202, lr=0.0100
[2025-05-02 22:35:55,449][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6248, lr=0.0100
[2025-05-02 22:36:02,396][train][INFO] - Epoch 42/100, Val Acc=0.6327, Val Loss=1.5960, lr=0.0100
[2025-05-02 22:36:04,077][train][INFO] - Epoch 52/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-02 22:36:10,463][train][INFO] - Epoch 43/100, Val Acc=0.6315, Val Loss=1.6271, lr=0.0100
[2025-05-02 22:36:11,750][train][INFO] - Epoch 53/100, Val Acc=0.6353, Val Loss=1.6055, lr=0.0100
[2025-05-02 22:36:18,716][train][INFO] - Epoch 44/100, Val Acc=0.6359, Val Loss=1.5788, lr=0.0100
[2025-05-02 22:36:19,302][train][INFO] - Epoch 54/100, Val Acc=0.6573, Val Loss=1.5031, lr=0.0100
[2025-05-02 22:36:26,492][train][INFO] - Epoch 45/100, Val Acc=0.6437, Val Loss=1.5394, lr=0.0100
[2025-05-02 22:36:27,327][train][INFO] - Epoch 55/100, Val Acc=0.6309, Val Loss=1.6423, lr=0.0100
[2025-05-02 22:36:35,280][train][INFO] - Epoch 46/100, Val Acc=0.6422, Val Loss=1.5754, lr=0.0100
[2025-05-02 22:36:35,670][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.5747, lr=0.0100
[2025-05-02 22:36:43,849][train][INFO] - Epoch 47/100, Val Acc=0.6510, Val Loss=1.5401, lr=0.0100
[2025-05-02 22:36:43,968][train][INFO] - Epoch 57/100, Val Acc=0.6449, Val Loss=1.5515, lr=0.0100
[2025-05-02 22:36:51,418][train][INFO] - Epoch 48/100, Val Acc=0.6352, Val Loss=1.6443, lr=0.0100
[2025-05-02 22:36:51,687][train][INFO] - Epoch 58/100, Val Acc=0.6418, Val Loss=1.5486, lr=0.0100
[2025-05-02 22:36:58,433][train][INFO] - Epoch 49/100, Val Acc=0.6451, Val Loss=1.5788, lr=0.0100
[2025-05-02 22:37:00,033][train][INFO] - Epoch 59/100, Val Acc=0.6442, Val Loss=1.5707, lr=0.0100
[2025-05-02 22:37:06,404][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.5818, lr=0.0100
[2025-05-02 22:37:07,896][train][INFO] - Epoch 60/100, Val Acc=0.6509, Val Loss=1.5362, lr=0.0100
[2025-05-02 22:37:14,250][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6248, lr=0.0100
[2025-05-02 22:37:16,258][train][INFO] - Epoch 61/100, Val Acc=0.7079, Val Loss=1.2767, lr=0.0010
[2025-05-02 22:37:22,650][train][INFO] - Epoch 52/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-02 22:37:24,981][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.2703, lr=0.0010
[2025-05-02 22:37:30,920][train][INFO] - Epoch 53/100, Val Acc=0.6353, Val Loss=1.6055, lr=0.0100
[2025-05-02 22:37:32,926][train][INFO] - Epoch 63/100, Val Acc=0.7131, Val Loss=1.2779, lr=0.0010
[2025-05-02 22:37:39,018][train][INFO] - Epoch 54/100, Val Acc=0.6573, Val Loss=1.5031, lr=0.0100
[2025-05-02 22:37:40,621][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.2761, lr=0.0010
[2025-05-02 22:37:46,560][train][INFO] - Epoch 55/100, Val Acc=0.6309, Val Loss=1.6423, lr=0.0100
[2025-05-02 22:37:48,500][train][INFO] - Epoch 65/100, Val Acc=0.7156, Val Loss=1.2928, lr=0.0010
[2025-05-02 22:37:54,708][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.5747, lr=0.0100
[2025-05-02 22:37:56,346][train][INFO] - Epoch 66/100, Val Acc=0.7151, Val Loss=1.2978, lr=0.0010
[2025-05-02 22:38:02,764][train][INFO] - Epoch 57/100, Val Acc=0.6449, Val Loss=1.5515, lr=0.0100
[2025-05-02 22:38:04,420][train][INFO] - Epoch 67/100, Val Acc=0.7164, Val Loss=1.3072, lr=0.0010
[2025-05-02 22:38:11,454][train][INFO] - Epoch 58/100, Val Acc=0.6418, Val Loss=1.5486, lr=0.0100
[2025-05-02 22:38:13,132][train][INFO] - Epoch 68/100, Val Acc=0.7168, Val Loss=1.3068, lr=0.0010
[2025-05-02 22:38:19,298][train][INFO] - Epoch 59/100, Val Acc=0.6442, Val Loss=1.5707, lr=0.0100
[2025-05-02 22:38:21,538][train][INFO] - Epoch 69/100, Val Acc=0.7144, Val Loss=1.3241, lr=0.0010
[2025-05-02 22:38:27,319][train][INFO] - Epoch 60/100, Val Acc=0.6509, Val Loss=1.5362, lr=0.0100
[2025-05-02 22:38:29,963][train][INFO] - Epoch 70/100, Val Acc=0.7165, Val Loss=1.3250, lr=0.0010
[2025-05-02 22:38:35,691][train][INFO] - Epoch 61/100, Val Acc=0.7079, Val Loss=1.2767, lr=0.0010
[2025-05-02 22:38:38,175][train][INFO] - Epoch 71/100, Val Acc=0.7167, Val Loss=1.3229, lr=0.0010
[2025-05-02 22:38:43,903][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.2703, lr=0.0010
[2025-05-02 22:38:45,547][train][INFO] - Epoch 72/100, Val Acc=0.7132, Val Loss=1.3359, lr=0.0010
[2025-05-02 22:38:51,933][train][INFO] - Epoch 63/100, Val Acc=0.7131, Val Loss=1.2779, lr=0.0010
[2025-05-02 22:38:54,050][train][INFO] - Epoch 73/100, Val Acc=0.7162, Val Loss=1.3324, lr=0.0010
[2025-05-02 22:39:00,133][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.2761, lr=0.0010
[2025-05-02 22:39:02,410][train][INFO] - Epoch 74/100, Val Acc=0.7167, Val Loss=1.3352, lr=0.0010
[2025-05-02 22:39:08,882][train][INFO] - Epoch 65/100, Val Acc=0.7156, Val Loss=1.2928, lr=0.0010
[2025-05-02 22:39:08,944][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3429, lr=0.0010
[2025-05-02 22:39:17,044][train][INFO] - Epoch 76/100, Val Acc=0.7170, Val Loss=1.3423, lr=0.0010
[2025-05-02 22:39:17,188][train][INFO] - Epoch 66/100, Val Acc=0.7151, Val Loss=1.2978, lr=0.0010
[2025-05-02 22:39:24,619][train][INFO] - Epoch 77/100, Val Acc=0.7174, Val Loss=1.3497, lr=0.0010
[2025-05-02 22:39:25,509][train][INFO] - Epoch 67/100, Val Acc=0.7164, Val Loss=1.3072, lr=0.0010
[2025-05-02 22:39:33,081][train][INFO] - Epoch 78/100, Val Acc=0.7168, Val Loss=1.3545, lr=0.0010
[2025-05-02 22:39:33,842][train][INFO] - Epoch 68/100, Val Acc=0.7168, Val Loss=1.3068, lr=0.0010
[2025-05-02 22:39:41,068][train][INFO] - Epoch 79/100, Val Acc=0.7159, Val Loss=1.3617, lr=0.0010
[2025-05-02 22:39:41,856][train][INFO] - Epoch 69/100, Val Acc=0.7144, Val Loss=1.3241, lr=0.0010
[2025-05-02 22:39:49,383][train][INFO] - Epoch 80/100, Val Acc=0.7180, Val Loss=1.3606, lr=0.0010
[2025-05-02 22:39:50,603][train][INFO] - Epoch 70/100, Val Acc=0.7165, Val Loss=1.3250, lr=0.0010
[2025-05-02 22:39:56,779][train][INFO] - Epoch 81/100, Val Acc=0.7171, Val Loss=1.3624, lr=0.0010
[2025-05-02 22:39:58,518][train][INFO] - Epoch 71/100, Val Acc=0.7167, Val Loss=1.3229, lr=0.0010
[2025-05-02 22:40:05,217][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3650, lr=0.0010
[2025-05-02 22:40:06,871][train][INFO] - Epoch 72/100, Val Acc=0.7132, Val Loss=1.3359, lr=0.0010
[2025-05-02 22:40:13,357][train][INFO] - Epoch 83/100, Val Acc=0.7136, Val Loss=1.3734, lr=0.0010
[2025-05-02 22:40:15,482][train][INFO] - Epoch 73/100, Val Acc=0.7162, Val Loss=1.3324, lr=0.0010
[2025-05-02 22:40:21,519][train][INFO] - Epoch 84/100, Val Acc=0.7159, Val Loss=1.3737, lr=0.0010
[2025-05-02 22:40:22,970][train][INFO] - Epoch 74/100, Val Acc=0.7167, Val Loss=1.3352, lr=0.0010
[2025-05-02 22:40:29,785][train][INFO] - Epoch 85/100, Val Acc=0.7164, Val Loss=1.3736, lr=0.0010
[2025-05-02 22:40:31,186][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3429, lr=0.0010
[2025-05-02 22:40:38,138][train][INFO] - Epoch 86/100, Val Acc=0.7165, Val Loss=1.3791, lr=0.0010
[2025-05-02 22:40:39,103][train][INFO] - Epoch 76/100, Val Acc=0.7170, Val Loss=1.3423, lr=0.0010
[2025-05-02 22:40:46,584][train][INFO] - Epoch 87/100, Val Acc=0.7163, Val Loss=1.3816, lr=0.0010
[2025-05-02 22:40:47,074][train][INFO] - Epoch 77/100, Val Acc=0.7174, Val Loss=1.3497, lr=0.0010
[2025-05-02 22:40:55,247][train][INFO] - Epoch 88/100, Val Acc=0.7138, Val Loss=1.3874, lr=0.0010
[2025-05-02 22:40:55,260][train][INFO] - Epoch 78/100, Val Acc=0.7168, Val Loss=1.3545, lr=0.0010
[2025-05-02 22:41:02,971][train][INFO] - Epoch 79/100, Val Acc=0.7159, Val Loss=1.3617, lr=0.0010
[2025-05-02 22:41:03,651][train][INFO] - Epoch 89/100, Val Acc=0.7137, Val Loss=1.3880, lr=0.0010
[2025-05-02 22:41:11,484][train][INFO] - Epoch 80/100, Val Acc=0.7180, Val Loss=1.3606, lr=0.0010
[2025-05-02 22:41:12,405][train][INFO] - Epoch 90/100, Val Acc=0.7168, Val Loss=1.3966, lr=0.0010
[2025-05-02 22:41:19,996][train][INFO] - Epoch 81/100, Val Acc=0.7171, Val Loss=1.3624, lr=0.0010
[2025-05-02 22:41:20,523][train][INFO] - Epoch 91/100, Val Acc=0.7166, Val Loss=1.3906, lr=0.0001
[2025-05-02 22:41:28,105][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3650, lr=0.0010
[2025-05-02 22:41:29,068][train][INFO] - Epoch 92/100, Val Acc=0.7174, Val Loss=1.3933, lr=0.0001
[2025-05-02 22:41:36,236][train][INFO] - Epoch 83/100, Val Acc=0.7136, Val Loss=1.3734, lr=0.0010
[2025-05-02 22:41:37,105][train][INFO] - Epoch 93/100, Val Acc=0.7186, Val Loss=1.3870, lr=0.0001
[2025-05-02 22:41:44,373][train][INFO] - Epoch 84/100, Val Acc=0.7159, Val Loss=1.3737, lr=0.0010
[2025-05-02 22:41:45,553][train][INFO] - Epoch 94/100, Val Acc=0.7185, Val Loss=1.3837, lr=0.0001
[2025-05-02 22:41:52,557][train][INFO] - Epoch 85/100, Val Acc=0.7164, Val Loss=1.3736, lr=0.0010
[2025-05-02 22:41:53,951][train][INFO] - Epoch 95/100, Val Acc=0.7181, Val Loss=1.3843, lr=0.0001
[2025-05-02 22:42:00,005][train][INFO] - Epoch 86/100, Val Acc=0.7165, Val Loss=1.3791, lr=0.0010
[2025-05-02 22:42:02,449][train][INFO] - Epoch 96/100, Val Acc=0.7180, Val Loss=1.3841, lr=0.0001
[2025-05-02 22:42:08,328][train][INFO] - Epoch 87/100, Val Acc=0.7163, Val Loss=1.3816, lr=0.0010
[2025-05-02 22:42:10,559][train][INFO] - Epoch 97/100, Val Acc=0.7174, Val Loss=1.3861, lr=0.0001
[2025-05-02 22:42:16,483][train][INFO] - Epoch 88/100, Val Acc=0.7138, Val Loss=1.3874, lr=0.0010
[2025-05-02 22:42:18,838][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3830, lr=0.0001
[2025-05-02 22:42:24,725][train][INFO] - Epoch 89/100, Val Acc=0.7137, Val Loss=1.3880, lr=0.0010
[2025-05-02 22:42:27,372][train][INFO] - Epoch 99/100, Val Acc=0.7174, Val Loss=1.3896, lr=0.0001
[2025-05-02 22:42:32,799][train][INFO] - Epoch 90/100, Val Acc=0.7168, Val Loss=1.3966, lr=0.0010
[2025-05-02 22:42:35,865][train][INFO] - Epoch 100/100, Val Acc=0.7183, Val Loss=1.3838, lr=0.0001
[2025-05-02 22:42:41,168][train][INFO] - Epoch 91/100, Val Acc=0.7166, Val Loss=1.3906, lr=0.0001
[2025-05-02 22:42:41,179][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7193
[2025-05-02 22:42:50,170][train][INFO] - Epoch 92/100, Val Acc=0.7174, Val Loss=1.3933, lr=0.0001
[2025-05-02 22:42:50,330][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 22:42:50,330][Progressive pruning][INFO] - Current speed up: 1.85
[2025-05-02 22:42:55,639][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 22:42:58,426][train][INFO] - Epoch 93/100, Val Acc=0.7186, Val Loss=1.3870, lr=0.0001
[2025-05-02 22:43:03,617][train][INFO] - Epoch 1/140, Val Acc=0.4744, Val Loss=2.2418, lr=0.0100
[2025-05-02 22:43:06,745][train][INFO] - Epoch 94/100, Val Acc=0.7185, Val Loss=1.3837, lr=0.0001
[2025-05-02 22:43:11,544][train][INFO] - Epoch 2/140, Val Acc=0.5562, Val Loss=1.8404, lr=0.0100
[2025-05-02 22:43:14,599][train][INFO] - Epoch 95/100, Val Acc=0.7181, Val Loss=1.3843, lr=0.0001
[2025-05-02 22:43:19,746][train][INFO] - Epoch 3/140, Val Acc=0.5639, Val Loss=1.8296, lr=0.0100
[2025-05-02 22:43:22,463][train][INFO] - Epoch 96/100, Val Acc=0.7180, Val Loss=1.3841, lr=0.0001
[2025-05-02 22:43:27,864][train][INFO] - Epoch 4/140, Val Acc=0.5573, Val Loss=1.8825, lr=0.0100
[2025-05-02 22:43:30,013][train][INFO] - Epoch 97/100, Val Acc=0.7174, Val Loss=1.3861, lr=0.0001
[2025-05-02 22:43:36,154][train][INFO] - Epoch 5/140, Val Acc=0.5879, Val Loss=1.7359, lr=0.0100
[2025-05-02 22:43:38,574][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3830, lr=0.0001
[2025-05-02 22:43:44,942][train][INFO] - Epoch 6/140, Val Acc=0.5483, Val Loss=1.9606, lr=0.0100
[2025-05-02 22:43:46,592][train][INFO] - Epoch 99/100, Val Acc=0.7174, Val Loss=1.3896, lr=0.0001
[2025-05-02 22:43:52,859][train][INFO] - Epoch 7/140, Val Acc=0.5949, Val Loss=1.6913, lr=0.0100
[2025-05-02 22:43:54,635][train][INFO] - Epoch 100/100, Val Acc=0.7183, Val Loss=1.3838, lr=0.0001
[2025-05-02 22:43:59,863][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7193
[2025-05-02 22:44:00,777][train][INFO] - Epoch 8/140, Val Acc=0.5872, Val Loss=1.8268, lr=0.0100
[2025-05-02 22:44:09,321][train][INFO] - Epoch 9/140, Val Acc=0.5986, Val Loss=1.7391, lr=0.0100
[2025-05-02 22:44:09,344][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-02 22:44:09,344][Progressive pruning][INFO] - Current speed up: 1.68
[2025-05-02 22:44:14,565][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 22:44:17,278][train][INFO] - Epoch 10/140, Val Acc=0.5899, Val Loss=1.8303, lr=0.0100
[2025-05-02 22:44:22,999][train][INFO] - Epoch 1/140, Val Acc=0.5433, Val Loss=1.9046, lr=0.0100
[2025-05-02 22:44:25,728][train][INFO] - Epoch 11/140, Val Acc=0.5809, Val Loss=1.8316, lr=0.0100
[2025-05-02 22:44:30,826][train][INFO] - Epoch 2/140, Val Acc=0.5464, Val Loss=1.9754, lr=0.0100
[2025-05-02 22:44:34,067][train][INFO] - Epoch 12/140, Val Acc=0.6056, Val Loss=1.6995, lr=0.0100
[2025-05-02 22:44:38,550][train][INFO] - Epoch 3/140, Val Acc=0.5812, Val Loss=1.7725, lr=0.0100
[2025-05-02 22:44:41,846][train][INFO] - Epoch 13/140, Val Acc=0.6124, Val Loss=1.7418, lr=0.0100
[2025-05-02 22:44:46,618][train][INFO] - Epoch 4/140, Val Acc=0.5900, Val Loss=1.7424, lr=0.0100
[2025-05-02 22:44:50,188][train][INFO] - Epoch 14/140, Val Acc=0.6164, Val Loss=1.6388, lr=0.0100
[2025-05-02 22:44:54,721][train][INFO] - Epoch 5/140, Val Acc=0.5689, Val Loss=1.9149, lr=0.0100
[2025-05-02 22:44:58,562][train][INFO] - Epoch 15/140, Val Acc=0.6140, Val Loss=1.6583, lr=0.0100
[2025-05-02 22:45:02,639][train][INFO] - Epoch 6/140, Val Acc=0.5928, Val Loss=1.7669, lr=0.0100
[2025-05-02 22:45:06,126][train][INFO] - Epoch 16/140, Val Acc=0.6096, Val Loss=1.7148, lr=0.0100
[2025-05-02 22:45:10,851][train][INFO] - Epoch 7/140, Val Acc=0.5975, Val Loss=1.7019, lr=0.0100
[2025-05-02 22:45:14,086][train][INFO] - Epoch 17/140, Val Acc=0.5824, Val Loss=1.8777, lr=0.0100
[2025-05-02 22:45:18,544][train][INFO] - Epoch 8/140, Val Acc=0.6187, Val Loss=1.6619, lr=0.0100
[2025-05-02 22:45:22,639][train][INFO] - Epoch 18/140, Val Acc=0.6029, Val Loss=1.8371, lr=0.0100
[2025-05-02 22:45:26,403][train][INFO] - Epoch 9/140, Val Acc=0.6168, Val Loss=1.6673, lr=0.0100
[2025-05-02 22:45:30,747][train][INFO] - Epoch 19/140, Val Acc=0.6011, Val Loss=1.7721, lr=0.0100
[2025-05-02 22:45:33,924][train][INFO] - Epoch 10/140, Val Acc=0.6161, Val Loss=1.6499, lr=0.0100
[2025-05-02 22:45:38,835][train][INFO] - Epoch 20/140, Val Acc=0.6096, Val Loss=1.7565, lr=0.0100
[2025-05-02 22:45:41,659][train][INFO] - Epoch 11/140, Val Acc=0.6130, Val Loss=1.6969, lr=0.0100
[2025-05-02 22:45:47,131][train][INFO] - Epoch 21/140, Val Acc=0.6072, Val Loss=1.7941, lr=0.0100
[2025-05-02 22:45:49,478][train][INFO] - Epoch 12/140, Val Acc=0.6155, Val Loss=1.6812, lr=0.0100
[2025-05-02 22:45:55,245][train][INFO] - Epoch 22/140, Val Acc=0.6108, Val Loss=1.7409, lr=0.0100
[2025-05-02 22:45:57,428][train][INFO] - Epoch 13/140, Val Acc=0.6261, Val Loss=1.6068, lr=0.0100
[2025-05-02 22:46:03,615][train][INFO] - Epoch 23/140, Val Acc=0.6068, Val Loss=1.7265, lr=0.0100
[2025-05-02 22:46:04,590][train][INFO] - Epoch 14/140, Val Acc=0.6166, Val Loss=1.7106, lr=0.0100
[2025-05-02 22:46:11,284][train][INFO] - Epoch 24/140, Val Acc=0.6193, Val Loss=1.7302, lr=0.0100
[2025-05-02 22:46:12,844][train][INFO] - Epoch 15/140, Val Acc=0.6082, Val Loss=1.7554, lr=0.0100
[2025-05-02 22:46:18,727][train][INFO] - Epoch 25/140, Val Acc=0.6113, Val Loss=1.7250, lr=0.0100
[2025-05-02 22:46:21,183][train][INFO] - Epoch 16/140, Val Acc=0.6152, Val Loss=1.6861, lr=0.0100
[2025-05-02 22:46:26,826][train][INFO] - Epoch 26/140, Val Acc=0.6208, Val Loss=1.6860, lr=0.0100
[2025-05-02 22:46:29,844][train][INFO] - Epoch 17/140, Val Acc=0.6346, Val Loss=1.6156, lr=0.0100
[2025-05-02 22:46:34,753][train][INFO] - Epoch 27/140, Val Acc=0.6108, Val Loss=1.7833, lr=0.0100
[2025-05-02 22:46:37,741][train][INFO] - Epoch 18/140, Val Acc=0.6121, Val Loss=1.6953, lr=0.0100
[2025-05-02 22:46:42,575][train][INFO] - Epoch 28/140, Val Acc=0.6124, Val Loss=1.7741, lr=0.0100
[2025-05-02 22:46:45,286][train][INFO] - Epoch 19/140, Val Acc=0.6169, Val Loss=1.6913, lr=0.0100
[2025-05-02 22:46:50,495][train][INFO] - Epoch 29/140, Val Acc=0.6242, Val Loss=1.6774, lr=0.0100
[2025-05-02 22:46:53,363][train][INFO] - Epoch 20/140, Val Acc=0.6211, Val Loss=1.6560, lr=0.0100
[2025-05-02 22:46:58,199][train][INFO] - Epoch 30/140, Val Acc=0.6127, Val Loss=1.7990, lr=0.0100
[2025-05-02 22:47:01,975][train][INFO] - Epoch 21/140, Val Acc=0.6303, Val Loss=1.6454, lr=0.0100
[2025-05-02 22:47:05,353][train][INFO] - Epoch 31/140, Val Acc=0.6187, Val Loss=1.7196, lr=0.0100
[2025-05-02 22:47:09,993][train][INFO] - Epoch 22/140, Val Acc=0.6234, Val Loss=1.6964, lr=0.0100
[2025-05-02 22:47:13,722][train][INFO] - Epoch 32/140, Val Acc=0.6128, Val Loss=1.7552, lr=0.0100
[2025-05-02 22:47:18,003][train][INFO] - Epoch 23/140, Val Acc=0.6236, Val Loss=1.6625, lr=0.0100
[2025-05-02 22:47:21,606][train][INFO] - Epoch 33/140, Val Acc=0.6143, Val Loss=1.7268, lr=0.0100
[2025-05-02 22:47:26,134][train][INFO] - Epoch 24/140, Val Acc=0.6264, Val Loss=1.7031, lr=0.0100
[2025-05-02 22:47:29,651][train][INFO] - Epoch 34/140, Val Acc=0.6290, Val Loss=1.6322, lr=0.0100
[2025-05-02 22:47:33,911][train][INFO] - Epoch 25/140, Val Acc=0.6171, Val Loss=1.7307, lr=0.0100
[2025-05-02 22:47:37,745][train][INFO] - Epoch 35/140, Val Acc=0.5989, Val Loss=1.8189, lr=0.0100
[2025-05-02 22:47:41,290][train][INFO] - Epoch 26/140, Val Acc=0.6197, Val Loss=1.7317, lr=0.0100
[2025-05-02 22:47:46,247][train][INFO] - Epoch 36/140, Val Acc=0.6241, Val Loss=1.6930, lr=0.0100
[2025-05-02 22:47:49,314][train][INFO] - Epoch 27/140, Val Acc=0.6271, Val Loss=1.6480, lr=0.0100
[2025-05-02 22:47:54,148][train][INFO] - Epoch 37/140, Val Acc=0.6289, Val Loss=1.6366, lr=0.0100
[2025-05-02 22:47:57,304][train][INFO] - Epoch 28/140, Val Acc=0.6334, Val Loss=1.6519, lr=0.0100
[2025-05-02 22:48:01,798][train][INFO] - Epoch 38/140, Val Acc=0.6333, Val Loss=1.6564, lr=0.0100
[2025-05-02 22:48:05,667][train][INFO] - Epoch 29/140, Val Acc=0.6291, Val Loss=1.6461, lr=0.0100
[2025-05-02 22:48:09,906][train][INFO] - Epoch 39/140, Val Acc=0.6156, Val Loss=1.7858, lr=0.0100
[2025-05-02 22:48:13,702][train][INFO] - Epoch 30/140, Val Acc=0.6265, Val Loss=1.6739, lr=0.0100
[2025-05-02 22:48:17,764][train][INFO] - Epoch 40/140, Val Acc=0.5990, Val Loss=1.8686, lr=0.0100
[2025-05-02 22:48:21,658][train][INFO] - Epoch 31/140, Val Acc=0.6247, Val Loss=1.6713, lr=0.0100
[2025-05-02 22:48:26,308][train][INFO] - Epoch 41/140, Val Acc=0.6036, Val Loss=1.8160, lr=0.0100
[2025-05-02 22:48:29,891][train][INFO] - Epoch 32/140, Val Acc=0.6150, Val Loss=1.7765, lr=0.0100
[2025-05-02 22:48:33,769][train][INFO] - Epoch 42/140, Val Acc=0.6181, Val Loss=1.6931, lr=0.0100
[2025-05-02 22:48:37,699][train][INFO] - Epoch 33/140, Val Acc=0.6170, Val Loss=1.7225, lr=0.0100
[2025-05-02 22:48:41,904][train][INFO] - Epoch 43/140, Val Acc=0.6251, Val Loss=1.7293, lr=0.0100
[2025-05-02 22:48:45,692][train][INFO] - Epoch 34/140, Val Acc=0.6324, Val Loss=1.6476, lr=0.0100
[2025-05-02 22:48:49,877][train][INFO] - Epoch 44/140, Val Acc=0.6198, Val Loss=1.7637, lr=0.0100
[2025-05-02 22:48:53,197][train][INFO] - Epoch 35/140, Val Acc=0.6183, Val Loss=1.7572, lr=0.0100
[2025-05-02 22:48:57,814][train][INFO] - Epoch 45/140, Val Acc=0.6132, Val Loss=1.7964, lr=0.0100
[2025-05-02 22:49:01,551][train][INFO] - Epoch 36/140, Val Acc=0.6296, Val Loss=1.6799, lr=0.0100
[2025-05-02 22:49:06,000][train][INFO] - Epoch 46/140, Val Acc=0.6056, Val Loss=1.7777, lr=0.0100
[2025-05-02 22:49:09,378][train][INFO] - Epoch 37/140, Val Acc=0.6287, Val Loss=1.7049, lr=0.0100
[2025-05-02 22:49:13,870][train][INFO] - Epoch 47/140, Val Acc=0.6109, Val Loss=1.7664, lr=0.0100
[2025-05-02 22:49:17,315][train][INFO] - Epoch 38/140, Val Acc=0.6157, Val Loss=1.7458, lr=0.0100
[2025-05-02 22:49:21,535][train][INFO] - Epoch 48/140, Val Acc=0.6169, Val Loss=1.8053, lr=0.0100
[2025-05-02 22:49:25,951][train][INFO] - Epoch 39/140, Val Acc=0.6254, Val Loss=1.6903, lr=0.0100
[2025-05-02 22:49:30,112][train][INFO] - Epoch 49/140, Val Acc=0.6096, Val Loss=1.8131, lr=0.0100
[2025-05-02 22:49:33,686][train][INFO] - Epoch 40/140, Val Acc=0.6180, Val Loss=1.7871, lr=0.0100
[2025-05-02 22:49:38,282][train][INFO] - Epoch 50/140, Val Acc=0.6273, Val Loss=1.7011, lr=0.0100
[2025-05-02 22:49:41,573][train][INFO] - Epoch 41/140, Val Acc=0.6281, Val Loss=1.7136, lr=0.0100
[2025-05-02 22:49:46,706][train][INFO] - Epoch 51/140, Val Acc=0.6216, Val Loss=1.7168, lr=0.0100
[2025-05-02 22:49:49,862][train][INFO] - Epoch 42/140, Val Acc=0.6314, Val Loss=1.6930, lr=0.0100
[2025-05-02 22:49:54,847][train][INFO] - Epoch 52/140, Val Acc=0.6343, Val Loss=1.6403, lr=0.0100
[2025-05-02 22:49:57,283][train][INFO] - Epoch 43/140, Val Acc=0.6198, Val Loss=1.7934, lr=0.0100
[2025-05-02 22:50:01,949][train][INFO] - Epoch 53/140, Val Acc=0.6293, Val Loss=1.7141, lr=0.0100
[2025-05-02 22:50:05,548][train][INFO] - Epoch 44/140, Val Acc=0.6223, Val Loss=1.7483, lr=0.0100
[2025-05-02 22:50:09,274][train][INFO] - Epoch 54/140, Val Acc=0.6224, Val Loss=1.7529, lr=0.0100
[2025-05-02 22:50:13,948][train][INFO] - Epoch 45/140, Val Acc=0.6244, Val Loss=1.7128, lr=0.0100
[2025-05-02 22:50:17,408][train][INFO] - Epoch 55/140, Val Acc=0.6226, Val Loss=1.7115, lr=0.0100
[2025-05-02 22:50:22,626][train][INFO] - Epoch 46/140, Val Acc=0.6121, Val Loss=1.7555, lr=0.0100
[2025-05-02 22:50:26,000][train][INFO] - Epoch 56/140, Val Acc=0.6201, Val Loss=1.7116, lr=0.0100
[2025-05-02 22:50:30,877][train][INFO] - Epoch 47/140, Val Acc=0.6247, Val Loss=1.7135, lr=0.0100
[2025-05-02 22:50:33,913][train][INFO] - Epoch 57/140, Val Acc=0.6157, Val Loss=1.7412, lr=0.0100
[2025-05-02 22:50:39,352][train][INFO] - Epoch 48/140, Val Acc=0.6231, Val Loss=1.7450, lr=0.0100
[2025-05-02 22:50:42,429][train][INFO] - Epoch 58/140, Val Acc=0.6127, Val Loss=1.8071, lr=0.0100
[2025-05-02 22:50:47,292][train][INFO] - Epoch 49/140, Val Acc=0.6145, Val Loss=1.8149, lr=0.0100
[2025-05-02 22:50:50,730][train][INFO] - Epoch 59/140, Val Acc=0.6216, Val Loss=1.7201, lr=0.0100
[2025-05-02 22:50:55,675][train][INFO] - Epoch 50/140, Val Acc=0.6277, Val Loss=1.7569, lr=0.0100
[2025-05-02 22:50:58,934][train][INFO] - Epoch 60/140, Val Acc=0.6285, Val Loss=1.7139, lr=0.0100
[2025-05-02 22:51:03,559][train][INFO] - Epoch 51/140, Val Acc=0.6395, Val Loss=1.6452, lr=0.0100
[2025-05-02 22:51:06,974][train][INFO] - Epoch 61/140, Val Acc=0.6310, Val Loss=1.7312, lr=0.0100
[2025-05-02 22:51:10,644][train][INFO] - Epoch 52/140, Val Acc=0.6083, Val Loss=1.7891, lr=0.0100
[2025-05-02 22:51:15,387][train][INFO] - Epoch 62/140, Val Acc=0.6129, Val Loss=1.7672, lr=0.0100
[2025-05-02 22:51:17,909][train][INFO] - Epoch 53/140, Val Acc=0.6366, Val Loss=1.6342, lr=0.0100
[2025-05-02 22:51:23,911][train][INFO] - Epoch 63/140, Val Acc=0.6255, Val Loss=1.7754, lr=0.0100
[2025-05-02 22:51:26,196][train][INFO] - Epoch 54/140, Val Acc=0.6251, Val Loss=1.7207, lr=0.0100
[2025-05-02 22:51:31,631][train][INFO] - Epoch 64/140, Val Acc=0.6245, Val Loss=1.7118, lr=0.0100
[2025-05-02 22:51:34,541][train][INFO] - Epoch 55/140, Val Acc=0.6254, Val Loss=1.7242, lr=0.0100
[2025-05-02 22:51:40,093][train][INFO] - Epoch 65/140, Val Acc=0.6252, Val Loss=1.7440, lr=0.0100
[2025-05-02 22:51:41,955][train][INFO] - Epoch 56/140, Val Acc=0.6171, Val Loss=1.7716, lr=0.0100
[2025-05-02 22:51:48,244][train][INFO] - Epoch 66/140, Val Acc=0.6164, Val Loss=1.8085, lr=0.0100
[2025-05-02 22:51:49,951][train][INFO] - Epoch 57/140, Val Acc=0.6119, Val Loss=1.8373, lr=0.0100
[2025-05-02 22:51:56,195][train][INFO] - Epoch 67/140, Val Acc=0.6246, Val Loss=1.7630, lr=0.0100
[2025-05-02 22:51:58,289][train][INFO] - Epoch 58/140, Val Acc=0.6295, Val Loss=1.6953, lr=0.0100
[2025-05-02 22:52:02,804][train][INFO] - Epoch 68/140, Val Acc=0.6152, Val Loss=1.7831, lr=0.0100
[2025-05-02 22:52:06,980][train][INFO] - Epoch 59/140, Val Acc=0.6110, Val Loss=1.7635, lr=0.0100
[2025-05-02 22:52:10,880][train][INFO] - Epoch 69/140, Val Acc=0.6177, Val Loss=1.8135, lr=0.0100
[2025-05-02 22:52:14,870][train][INFO] - Epoch 60/140, Val Acc=0.6193, Val Loss=1.8051, lr=0.0100
[2025-05-02 22:52:18,497][train][INFO] - Epoch 70/140, Val Acc=0.6112, Val Loss=1.7836, lr=0.0100
[2025-05-02 22:52:23,182][train][INFO] - Epoch 61/140, Val Acc=0.6280, Val Loss=1.7056, lr=0.0100
[2025-05-02 22:52:27,058][train][INFO] - Epoch 71/140, Val Acc=0.6192, Val Loss=1.7800, lr=0.0100
[2025-05-02 22:52:30,431][train][INFO] - Epoch 62/140, Val Acc=0.6176, Val Loss=1.7450, lr=0.0100
[2025-05-02 22:52:34,905][train][INFO] - Epoch 72/140, Val Acc=0.6209, Val Loss=1.7660, lr=0.0100
[2025-05-02 22:52:38,828][train][INFO] - Epoch 63/140, Val Acc=0.6199, Val Loss=1.7944, lr=0.0100
[2025-05-02 22:52:43,351][train][INFO] - Epoch 73/140, Val Acc=0.6259, Val Loss=1.7165, lr=0.0100
[2025-05-02 22:52:46,926][train][INFO] - Epoch 64/140, Val Acc=0.6291, Val Loss=1.7562, lr=0.0100
[2025-05-02 22:52:50,713][train][INFO] - Epoch 74/140, Val Acc=0.6259, Val Loss=1.7299, lr=0.0100
[2025-05-02 22:52:55,130][train][INFO] - Epoch 65/140, Val Acc=0.6107, Val Loss=1.8335, lr=0.0100
[2025-05-02 22:52:59,155][train][INFO] - Epoch 75/140, Val Acc=0.6301, Val Loss=1.7047, lr=0.0100
[2025-05-02 22:53:03,186][train][INFO] - Epoch 66/140, Val Acc=0.6217, Val Loss=1.7290, lr=0.0100
[2025-05-02 22:53:07,151][train][INFO] - Epoch 76/140, Val Acc=0.6240, Val Loss=1.7409, lr=0.0100
[2025-05-02 22:53:11,384][train][INFO] - Epoch 67/140, Val Acc=0.6111, Val Loss=1.8483, lr=0.0100
[2025-05-02 22:53:15,483][train][INFO] - Epoch 77/140, Val Acc=0.6081, Val Loss=1.8265, lr=0.0100
[2025-05-02 22:53:19,459][train][INFO] - Epoch 68/140, Val Acc=0.6278, Val Loss=1.7379, lr=0.0100
[2025-05-02 22:53:24,056][train][INFO] - Epoch 78/140, Val Acc=0.6288, Val Loss=1.7376, lr=0.0100
[2025-05-02 22:53:27,431][train][INFO] - Epoch 69/140, Val Acc=0.6328, Val Loss=1.6763, lr=0.0100
[2025-05-02 22:53:32,051][train][INFO] - Epoch 79/140, Val Acc=0.6259, Val Loss=1.7121, lr=0.0100
[2025-05-02 22:53:35,971][train][INFO] - Epoch 70/140, Val Acc=0.6316, Val Loss=1.6884, lr=0.0100
[2025-05-02 22:53:40,570][train][INFO] - Epoch 80/140, Val Acc=0.6085, Val Loss=1.8846, lr=0.0100
[2025-05-02 22:53:43,842][train][INFO] - Epoch 71/140, Val Acc=0.6368, Val Loss=1.6776, lr=0.0100
[2025-05-02 22:53:48,839][train][INFO] - Epoch 81/140, Val Acc=0.6798, Val Loss=1.4455, lr=0.0010
[2025-05-02 22:53:52,017][train][INFO] - Epoch 72/140, Val Acc=0.6318, Val Loss=1.7129, lr=0.0100
[2025-05-02 22:53:56,608][train][INFO] - Epoch 82/140, Val Acc=0.6816, Val Loss=1.4494, lr=0.0010
[2025-05-02 22:54:00,007][train][INFO] - Epoch 73/140, Val Acc=0.6258, Val Loss=1.7252, lr=0.0100
[2025-05-02 22:54:04,415][train][INFO] - Epoch 83/140, Val Acc=0.6847, Val Loss=1.4504, lr=0.0010
[2025-05-02 22:54:07,609][train][INFO] - Epoch 74/140, Val Acc=0.6241, Val Loss=1.7238, lr=0.0100
[2025-05-02 22:54:12,661][train][INFO] - Epoch 84/140, Val Acc=0.6884, Val Loss=1.4465, lr=0.0010
[2025-05-02 22:54:15,845][train][INFO] - Epoch 75/140, Val Acc=0.6274, Val Loss=1.8204, lr=0.0100
[2025-05-02 22:54:20,673][train][INFO] - Epoch 85/140, Val Acc=0.6879, Val Loss=1.4610, lr=0.0010
[2025-05-02 22:54:24,133][train][INFO] - Epoch 76/140, Val Acc=0.6170, Val Loss=1.7968, lr=0.0100
[2025-05-02 22:54:28,532][train][INFO] - Epoch 86/140, Val Acc=0.6871, Val Loss=1.4638, lr=0.0010
[2025-05-02 22:54:32,313][train][INFO] - Epoch 77/140, Val Acc=0.6276, Val Loss=1.7376, lr=0.0100
[2025-05-02 22:54:35,838][train][INFO] - Epoch 87/140, Val Acc=0.6879, Val Loss=1.4651, lr=0.0010
[2025-05-02 22:54:40,109][train][INFO] - Epoch 78/140, Val Acc=0.6275, Val Loss=1.6721, lr=0.0100
[2025-05-02 22:54:43,576][train][INFO] - Epoch 88/140, Val Acc=0.6873, Val Loss=1.4784, lr=0.0010
[2025-05-02 22:54:48,444][train][INFO] - Epoch 79/140, Val Acc=0.6265, Val Loss=1.7276, lr=0.0100
[2025-05-02 22:54:51,510][train][INFO] - Epoch 89/140, Val Acc=0.6882, Val Loss=1.4833, lr=0.0010
[2025-05-02 22:54:56,066][train][INFO] - Epoch 80/140, Val Acc=0.6308, Val Loss=1.7071, lr=0.0100
[2025-05-02 22:54:59,399][train][INFO] - Epoch 90/140, Val Acc=0.6891, Val Loss=1.4796, lr=0.0010
[2025-05-02 22:55:04,019][train][INFO] - Epoch 81/140, Val Acc=0.6843, Val Loss=1.4030, lr=0.0010
[2025-05-02 22:55:07,511][train][INFO] - Epoch 91/140, Val Acc=0.6863, Val Loss=1.5048, lr=0.0010
[2025-05-02 22:55:12,331][train][INFO] - Epoch 82/140, Val Acc=0.6911, Val Loss=1.4033, lr=0.0010
[2025-05-02 22:55:15,686][train][INFO] - Epoch 92/140, Val Acc=0.6855, Val Loss=1.5005, lr=0.0010
[2025-05-02 22:55:20,356][train][INFO] - Epoch 83/140, Val Acc=0.6945, Val Loss=1.4007, lr=0.0010
[2025-05-02 22:55:23,611][train][INFO] - Epoch 93/140, Val Acc=0.6888, Val Loss=1.4906, lr=0.0010
[2025-05-02 22:55:28,700][train][INFO] - Epoch 84/140, Val Acc=0.6980, Val Loss=1.4029, lr=0.0010
[2025-05-02 22:55:31,855][train][INFO] - Epoch 94/140, Val Acc=0.6883, Val Loss=1.5006, lr=0.0010
[2025-05-02 22:55:36,868][train][INFO] - Epoch 85/140, Val Acc=0.6961, Val Loss=1.4078, lr=0.0010
[2025-05-02 22:55:40,455][train][INFO] - Epoch 95/140, Val Acc=0.6881, Val Loss=1.5026, lr=0.0010
[2025-05-02 22:55:44,508][train][INFO] - Epoch 86/140, Val Acc=0.6960, Val Loss=1.4097, lr=0.0010
[2025-05-02 22:55:48,804][train][INFO] - Epoch 96/140, Val Acc=0.6870, Val Loss=1.5135, lr=0.0010
[2025-05-02 22:55:51,733][train][INFO] - Epoch 87/140, Val Acc=0.6961, Val Loss=1.4137, lr=0.0010
[2025-05-02 22:55:56,202][train][INFO] - Epoch 97/140, Val Acc=0.6856, Val Loss=1.5176, lr=0.0010
[2025-05-02 22:55:59,655][train][INFO] - Epoch 88/140, Val Acc=0.6963, Val Loss=1.4277, lr=0.0010
[2025-05-02 22:56:04,418][train][INFO] - Epoch 98/140, Val Acc=0.6869, Val Loss=1.5258, lr=0.0010
[2025-05-02 22:56:08,058][train][INFO] - Epoch 89/140, Val Acc=0.6987, Val Loss=1.4215, lr=0.0010
[2025-05-02 22:56:12,566][train][INFO] - Epoch 99/140, Val Acc=0.6864, Val Loss=1.5285, lr=0.0010
[2025-05-02 22:56:15,902][train][INFO] - Epoch 90/140, Val Acc=0.6950, Val Loss=1.4363, lr=0.0010
[2025-05-02 22:56:21,079][train][INFO] - Epoch 100/140, Val Acc=0.6857, Val Loss=1.5294, lr=0.0010
[2025-05-02 22:56:24,240][train][INFO] - Epoch 91/140, Val Acc=0.6962, Val Loss=1.4429, lr=0.0010
[2025-05-02 22:56:29,090][train][INFO] - Epoch 101/140, Val Acc=0.6853, Val Loss=1.5220, lr=0.0010
[2025-05-02 22:56:32,192][train][INFO] - Epoch 92/140, Val Acc=0.6991, Val Loss=1.4372, lr=0.0010
[2025-05-02 22:56:37,291][train][INFO] - Epoch 102/140, Val Acc=0.6882, Val Loss=1.5255, lr=0.0010
[2025-05-02 22:56:40,158][train][INFO] - Epoch 93/140, Val Acc=0.6996, Val Loss=1.4420, lr=0.0010
[2025-05-02 22:56:45,493][train][INFO] - Epoch 103/140, Val Acc=0.6886, Val Loss=1.5277, lr=0.0010
[2025-05-02 22:56:47,931][train][INFO] - Epoch 94/140, Val Acc=0.6961, Val Loss=1.4465, lr=0.0010
[2025-05-02 22:56:53,630][train][INFO] - Epoch 104/140, Val Acc=0.6892, Val Loss=1.5311, lr=0.0010
[2025-05-02 22:56:55,568][train][INFO] - Epoch 95/140, Val Acc=0.6974, Val Loss=1.4497, lr=0.0010
[2025-05-02 22:57:01,828][train][INFO] - Epoch 105/140, Val Acc=0.6906, Val Loss=1.5336, lr=0.0010
[2025-05-02 22:57:04,009][train][INFO] - Epoch 96/140, Val Acc=0.6971, Val Loss=1.4572, lr=0.0010
[2025-05-02 22:57:10,135][train][INFO] - Epoch 106/140, Val Acc=0.6886, Val Loss=1.5434, lr=0.0010
[2025-05-02 22:57:12,028][train][INFO] - Epoch 97/140, Val Acc=0.6968, Val Loss=1.4593, lr=0.0010
[2025-05-02 22:57:18,169][train][INFO] - Epoch 107/140, Val Acc=0.6895, Val Loss=1.5405, lr=0.0010
[2025-05-02 22:57:19,935][train][INFO] - Epoch 98/140, Val Acc=0.6990, Val Loss=1.4496, lr=0.0010
[2025-05-02 22:57:26,068][train][INFO] - Epoch 108/140, Val Acc=0.6879, Val Loss=1.5395, lr=0.0010
[2025-05-02 22:57:27,900][train][INFO] - Epoch 99/140, Val Acc=0.6974, Val Loss=1.4575, lr=0.0010
[2025-05-02 22:57:34,398][train][INFO] - Epoch 109/140, Val Acc=0.6874, Val Loss=1.5433, lr=0.0010
[2025-05-02 22:57:35,493][train][INFO] - Epoch 100/140, Val Acc=0.6975, Val Loss=1.4686, lr=0.0010
[2025-05-02 22:57:43,041][train][INFO] - Epoch 110/140, Val Acc=0.6849, Val Loss=1.5537, lr=0.0010
[2025-05-02 22:57:43,756][train][INFO] - Epoch 101/140, Val Acc=0.6952, Val Loss=1.4657, lr=0.0010
[2025-05-02 22:57:50,299][train][INFO] - Epoch 111/140, Val Acc=0.6848, Val Loss=1.5469, lr=0.0010
[2025-05-02 22:57:51,909][train][INFO] - Epoch 102/140, Val Acc=0.6987, Val Loss=1.4583, lr=0.0010
[2025-05-02 22:57:58,465][train][INFO] - Epoch 112/140, Val Acc=0.6885, Val Loss=1.5555, lr=0.0010
[2025-05-02 22:58:00,687][train][INFO] - Epoch 103/140, Val Acc=0.7031, Val Loss=1.4596, lr=0.0010
[2025-05-02 22:58:07,179][train][INFO] - Epoch 113/140, Val Acc=0.6888, Val Loss=1.5537, lr=0.0010
[2025-05-02 22:58:08,946][train][INFO] - Epoch 104/140, Val Acc=0.6995, Val Loss=1.4680, lr=0.0010
[2025-05-02 22:58:14,896][train][INFO] - Epoch 114/140, Val Acc=0.6884, Val Loss=1.5526, lr=0.0010
[2025-05-02 22:58:16,566][train][INFO] - Epoch 105/140, Val Acc=0.6982, Val Loss=1.4690, lr=0.0010
[2025-05-02 22:58:23,293][train][INFO] - Epoch 115/140, Val Acc=0.6886, Val Loss=1.5600, lr=0.0010
[2025-05-02 22:58:24,965][train][INFO] - Epoch 106/140, Val Acc=0.6986, Val Loss=1.4744, lr=0.0010
[2025-05-02 22:58:31,256][train][INFO] - Epoch 116/140, Val Acc=0.6920, Val Loss=1.5502, lr=0.0010
[2025-05-02 22:58:32,954][train][INFO] - Epoch 107/140, Val Acc=0.6968, Val Loss=1.4708, lr=0.0010
[2025-05-02 22:58:38,753][train][INFO] - Epoch 117/140, Val Acc=0.6881, Val Loss=1.5641, lr=0.0010
[2025-05-02 22:58:40,906][train][INFO] - Epoch 108/140, Val Acc=0.6970, Val Loss=1.4684, lr=0.0010
[2025-05-02 22:58:46,879][train][INFO] - Epoch 118/140, Val Acc=0.6887, Val Loss=1.5566, lr=0.0010
[2025-05-02 22:58:49,180][train][INFO] - Epoch 109/140, Val Acc=0.6967, Val Loss=1.4761, lr=0.0010
[2025-05-02 22:58:54,834][train][INFO] - Epoch 119/140, Val Acc=0.6877, Val Loss=1.5740, lr=0.0010
[2025-05-02 22:58:57,261][train][INFO] - Epoch 110/140, Val Acc=0.6978, Val Loss=1.4759, lr=0.0010
[2025-05-02 22:59:03,425][train][INFO] - Epoch 120/140, Val Acc=0.6879, Val Loss=1.5649, lr=0.0010
[2025-05-02 22:59:05,230][train][INFO] - Epoch 111/140, Val Acc=0.6997, Val Loss=1.4788, lr=0.0010
[2025-05-02 22:59:11,390][train][INFO] - Epoch 121/140, Val Acc=0.6892, Val Loss=1.5529, lr=0.0001
[2025-05-02 22:59:13,410][train][INFO] - Epoch 112/140, Val Acc=0.6987, Val Loss=1.4811, lr=0.0010
[2025-05-02 22:59:19,430][train][INFO] - Epoch 122/140, Val Acc=0.6866, Val Loss=1.5595, lr=0.0001
[2025-05-02 22:59:21,062][train][INFO] - Epoch 113/140, Val Acc=0.6972, Val Loss=1.4837, lr=0.0010
[2025-05-02 22:59:27,404][train][INFO] - Epoch 123/140, Val Acc=0.6900, Val Loss=1.5553, lr=0.0001
[2025-05-02 22:59:29,079][train][INFO] - Epoch 114/140, Val Acc=0.6991, Val Loss=1.4823, lr=0.0010
[2025-05-02 22:59:35,681][train][INFO] - Epoch 124/140, Val Acc=0.6900, Val Loss=1.5548, lr=0.0001
[2025-05-02 22:59:37,481][train][INFO] - Epoch 115/140, Val Acc=0.6981, Val Loss=1.4852, lr=0.0010
[2025-05-02 22:59:43,750][train][INFO] - Epoch 125/140, Val Acc=0.6889, Val Loss=1.5630, lr=0.0001
[2025-05-02 22:59:45,280][train][INFO] - Epoch 116/140, Val Acc=0.6972, Val Loss=1.4888, lr=0.0010
[2025-05-02 22:59:52,094][train][INFO] - Epoch 126/140, Val Acc=0.6883, Val Loss=1.5583, lr=0.0001
[2025-05-02 22:59:53,275][train][INFO] - Epoch 117/140, Val Acc=0.6995, Val Loss=1.4894, lr=0.0010
[2025-05-02 22:59:59,802][train][INFO] - Epoch 127/140, Val Acc=0.6891, Val Loss=1.5646, lr=0.0001
[2025-05-02 23:00:01,597][train][INFO] - Epoch 118/140, Val Acc=0.6998, Val Loss=1.4900, lr=0.0010
[2025-05-02 23:00:08,066][train][INFO] - Epoch 128/140, Val Acc=0.6900, Val Loss=1.5572, lr=0.0001
[2025-05-02 23:00:09,464][train][INFO] - Epoch 119/140, Val Acc=0.6978, Val Loss=1.4987, lr=0.0010
[2025-05-02 23:00:15,937][train][INFO] - Epoch 129/140, Val Acc=0.6874, Val Loss=1.5630, lr=0.0001
[2025-05-02 23:00:17,507][train][INFO] - Epoch 120/140, Val Acc=0.6973, Val Loss=1.5002, lr=0.0010
[2025-05-02 23:00:24,048][train][INFO] - Epoch 130/140, Val Acc=0.6895, Val Loss=1.5556, lr=0.0001
[2025-05-02 23:00:25,427][train][INFO] - Epoch 121/140, Val Acc=0.6979, Val Loss=1.4891, lr=0.0001
[2025-05-02 23:00:32,282][train][INFO] - Epoch 131/140, Val Acc=0.6893, Val Loss=1.5660, lr=0.0001
[2025-05-02 23:00:33,457][train][INFO] - Epoch 122/140, Val Acc=0.6992, Val Loss=1.4907, lr=0.0001
[2025-05-02 23:00:40,729][train][INFO] - Epoch 132/140, Val Acc=0.6889, Val Loss=1.5625, lr=0.0001
[2025-05-02 23:00:42,005][train][INFO] - Epoch 123/140, Val Acc=0.6983, Val Loss=1.4880, lr=0.0001
[2025-05-02 23:00:48,383][train][INFO] - Epoch 133/140, Val Acc=0.6892, Val Loss=1.5591, lr=0.0001
[2025-05-02 23:00:50,300][train][INFO] - Epoch 124/140, Val Acc=0.6979, Val Loss=1.4903, lr=0.0001
[2025-05-02 23:00:56,581][train][INFO] - Epoch 134/140, Val Acc=0.6907, Val Loss=1.5615, lr=0.0001
[2025-05-02 23:00:58,140][train][INFO] - Epoch 125/140, Val Acc=0.6978, Val Loss=1.4965, lr=0.0001
[2025-05-02 23:01:05,103][train][INFO] - Epoch 135/140, Val Acc=0.6884, Val Loss=1.5595, lr=0.0001
[2025-05-02 23:01:06,300][train][INFO] - Epoch 126/140, Val Acc=0.6978, Val Loss=1.4907, lr=0.0001
[2025-05-02 23:01:12,250][train][INFO] - Epoch 136/140, Val Acc=0.6899, Val Loss=1.5621, lr=0.0001
[2025-05-02 23:01:14,620][train][INFO] - Epoch 127/140, Val Acc=0.6970, Val Loss=1.4927, lr=0.0001
[2025-05-02 23:01:20,663][train][INFO] - Epoch 137/140, Val Acc=0.6890, Val Loss=1.5610, lr=0.0001
[2025-05-02 23:01:22,303][train][INFO] - Epoch 128/140, Val Acc=0.6996, Val Loss=1.4852, lr=0.0001
[2025-05-02 23:01:29,246][train][INFO] - Epoch 138/140, Val Acc=0.6892, Val Loss=1.5651, lr=0.0001
[2025-05-02 23:01:30,136][train][INFO] - Epoch 129/140, Val Acc=0.7020, Val Loss=1.4926, lr=0.0001
[2025-05-02 23:01:36,969][train][INFO] - Epoch 139/140, Val Acc=0.6892, Val Loss=1.5642, lr=0.0001
[2025-05-02 23:01:38,572][train][INFO] - Epoch 130/140, Val Acc=0.6996, Val Loss=1.4869, lr=0.0001
[2025-05-02 23:01:45,218][train][INFO] - Epoch 140/140, Val Acc=0.6882, Val Loss=1.5638, lr=0.0001
[2025-05-02 23:01:46,854][train][INFO] - Epoch 131/140, Val Acc=0.6975, Val Loss=1.4949, lr=0.0001
[2025-05-02 23:01:50,645][train][INFO] - After training : Train Acc=0.9938  Val Acc=0.6920
[2025-05-02 23:01:50,669][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(22, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(124, 246, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(246, 197, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(197, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(197, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(124, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(115, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(14, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(5, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(14, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(4, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(6, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(21, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=36, out_features=100, bias=True)
)
[2025-05-02 23:01:50,669][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.6919999718666077
                      Speed up: 1.85   Final speed up: 5.59
[2025-05-02 23:01:53,946][train][INFO] - Epoch 132/140, Val Acc=0.6985, Val Loss=1.4885, lr=0.0001
[2025-05-02 23:02:01,554][train][INFO] - Epoch 133/140, Val Acc=0.7005, Val Loss=1.4926, lr=0.0001
[2025-05-02 23:02:08,930][train][INFO] - Epoch 134/140, Val Acc=0.6996, Val Loss=1.4910, lr=0.0001
[2025-05-02 23:02:16,813][train][INFO] - Epoch 135/140, Val Acc=0.6986, Val Loss=1.4915, lr=0.0001
[2025-05-02 23:02:24,473][train][INFO] - Epoch 136/140, Val Acc=0.6985, Val Loss=1.4854, lr=0.0001
[2025-05-02 23:02:32,131][train][INFO] - Epoch 137/140, Val Acc=0.6993, Val Loss=1.4894, lr=0.0001
[2025-05-02 23:02:39,948][train][INFO] - Epoch 138/140, Val Acc=0.6984, Val Loss=1.4887, lr=0.0001
[2025-05-02 23:02:47,781][train][INFO] - Epoch 139/140, Val Acc=0.6979, Val Loss=1.4901, lr=0.0001
[2025-05-02 23:02:55,677][train][INFO] - Epoch 140/140, Val Acc=0.6999, Val Loss=1.4948, lr=0.0001
[2025-05-02 23:03:00,837][train][INFO] - After training : Train Acc=0.9923  Val Acc=0.7031
[2025-05-02 23:03:00,868][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(26, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(76, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(124, 246, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(246, 207, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(207, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(207, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(134, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(122, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(6, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(15, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(6, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(22, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=44, out_features=100, bias=True)
)
[2025-05-02 23:03:00,868][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.7030999660491943
                      Speed up: 1.68   Final speed up: 5.05
[2025-05-02 23:24:11,426][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-02 23:24:11,515][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-02 23:24:11,515][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-02 23:24:11,515][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-02 23:24:36,573][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-02 23:24:45,614][train][INFO] - Epoch 1/100, Val Acc=0.1656, Val Loss=3.1948, lr=0.0100
[2025-05-02 23:24:54,526][train][INFO] - Epoch 2/100, Val Acc=0.3536, Val Loss=2.3640, lr=0.0100
[2025-05-02 23:25:03,384][train][INFO] - Epoch 3/100, Val Acc=0.4319, Val Loss=2.1507, lr=0.0100
[2025-05-02 23:25:12,389][train][INFO] - Epoch 4/100, Val Acc=0.4925, Val Loss=1.8823, lr=0.0100
[2025-05-02 23:25:21,186][train][INFO] - Epoch 5/100, Val Acc=0.5224, Val Loss=1.8290, lr=0.0100
[2025-05-02 23:25:29,498][train][INFO] - Epoch 6/100, Val Acc=0.5208, Val Loss=1.8555, lr=0.0100
[2025-05-02 23:25:37,855][train][INFO] - Epoch 7/100, Val Acc=0.5505, Val Loss=1.7337, lr=0.0100
[2025-05-02 23:25:46,181][train][INFO] - Epoch 8/100, Val Acc=0.5731, Val Loss=1.6407, lr=0.0100
[2025-05-02 23:25:54,154][train][INFO] - Epoch 9/100, Val Acc=0.5858, Val Loss=1.5636, lr=0.0100
[2025-05-02 23:26:02,916][train][INFO] - Epoch 10/100, Val Acc=0.6031, Val Loss=1.5387, lr=0.0100
[2025-05-02 23:26:11,670][train][INFO] - Epoch 11/100, Val Acc=0.6026, Val Loss=1.5312, lr=0.0100
[2025-05-02 23:26:20,662][train][INFO] - Epoch 12/100, Val Acc=0.6125, Val Loss=1.5101, lr=0.0100
[2025-05-02 23:26:29,489][train][INFO] - Epoch 13/100, Val Acc=0.5865, Val Loss=1.6591, lr=0.0100
[2025-05-02 23:26:38,327][train][INFO] - Epoch 14/100, Val Acc=0.6221, Val Loss=1.4760, lr=0.0100
[2025-05-02 23:26:47,115][train][INFO] - Epoch 15/100, Val Acc=0.6008, Val Loss=1.5581, lr=0.0100
[2025-05-02 23:26:55,937][train][INFO] - Epoch 16/100, Val Acc=0.5950, Val Loss=1.6448, lr=0.0100
[2025-05-02 23:27:04,846][train][INFO] - Epoch 17/100, Val Acc=0.6048, Val Loss=1.5769, lr=0.0100
[2025-05-02 23:27:13,334][train][INFO] - Epoch 18/100, Val Acc=0.6307, Val Loss=1.4623, lr=0.0100
[2025-05-02 23:27:21,416][train][INFO] - Epoch 19/100, Val Acc=0.6108, Val Loss=1.5797, lr=0.0100
[2025-05-02 23:27:29,442][train][INFO] - Epoch 20/100, Val Acc=0.6146, Val Loss=1.5706, lr=0.0100
[2025-05-02 23:27:37,154][train][INFO] - Epoch 21/100, Val Acc=0.6322, Val Loss=1.4814, lr=0.0100
[2025-05-02 23:27:45,144][train][INFO] - Epoch 22/100, Val Acc=0.6236, Val Loss=1.5283, lr=0.0100
[2025-05-02 23:27:53,205][train][INFO] - Epoch 23/100, Val Acc=0.6347, Val Loss=1.4687, lr=0.0100
[2025-05-02 23:28:00,271][train][INFO] - Epoch 24/100, Val Acc=0.6452, Val Loss=1.4568, lr=0.0100
[2025-05-02 23:28:08,458][train][INFO] - Epoch 25/100, Val Acc=0.6310, Val Loss=1.5355, lr=0.0100
[2025-05-02 23:28:16,477][train][INFO] - Epoch 26/100, Val Acc=0.6261, Val Loss=1.5884, lr=0.0100
[2025-05-02 23:28:24,709][train][INFO] - Epoch 27/100, Val Acc=0.6376, Val Loss=1.4824, lr=0.0100
[2025-05-02 23:28:33,201][train][INFO] - Epoch 28/100, Val Acc=0.6306, Val Loss=1.5536, lr=0.0100
[2025-05-02 23:28:42,175][train][INFO] - Epoch 29/100, Val Acc=0.6305, Val Loss=1.5611, lr=0.0100
[2025-05-02 23:28:51,200][train][INFO] - Epoch 30/100, Val Acc=0.6494, Val Loss=1.4854, lr=0.0100
[2025-05-02 23:29:00,112][train][INFO] - Epoch 31/100, Val Acc=0.6348, Val Loss=1.5276, lr=0.0100
[2025-05-02 23:29:09,027][train][INFO] - Epoch 32/100, Val Acc=0.6472, Val Loss=1.5131, lr=0.0100
[2025-05-02 23:29:17,965][train][INFO] - Epoch 33/100, Val Acc=0.6351, Val Loss=1.5556, lr=0.0100
[2025-05-02 23:29:26,854][train][INFO] - Epoch 34/100, Val Acc=0.6468, Val Loss=1.4801, lr=0.0100
[2025-05-02 23:29:35,507][train][INFO] - Epoch 35/100, Val Acc=0.6452, Val Loss=1.5242, lr=0.0100
[2025-05-02 23:29:44,509][train][INFO] - Epoch 36/100, Val Acc=0.6477, Val Loss=1.4958, lr=0.0100
[2025-05-02 23:29:53,405][train][INFO] - Epoch 37/100, Val Acc=0.6431, Val Loss=1.5379, lr=0.0100
[2025-05-02 23:30:01,982][train][INFO] - Epoch 38/100, Val Acc=0.6431, Val Loss=1.5372, lr=0.0100
[2025-05-02 23:30:09,868][train][INFO] - Epoch 39/100, Val Acc=0.6412, Val Loss=1.5501, lr=0.0100
[2025-05-02 23:30:18,430][train][INFO] - Epoch 40/100, Val Acc=0.6363, Val Loss=1.5587, lr=0.0100
[2025-05-02 23:30:26,744][train][INFO] - Epoch 41/100, Val Acc=0.6514, Val Loss=1.5202, lr=0.0100
[2025-05-02 23:30:34,418][train][INFO] - Epoch 42/100, Val Acc=0.6327, Val Loss=1.5960, lr=0.0100
[2025-05-02 23:30:42,178][train][INFO] - Epoch 43/100, Val Acc=0.6315, Val Loss=1.6271, lr=0.0100
[2025-05-02 23:30:50,190][train][INFO] - Epoch 44/100, Val Acc=0.6359, Val Loss=1.5788, lr=0.0100
[2025-05-02 23:30:57,895][train][INFO] - Epoch 45/100, Val Acc=0.6437, Val Loss=1.5394, lr=0.0100
[2025-05-02 23:31:06,344][train][INFO] - Epoch 46/100, Val Acc=0.6422, Val Loss=1.5754, lr=0.0100
[2025-05-02 23:31:14,953][train][INFO] - Epoch 47/100, Val Acc=0.6510, Val Loss=1.5401, lr=0.0100
[2025-05-02 23:31:23,468][train][INFO] - Epoch 48/100, Val Acc=0.6352, Val Loss=1.6443, lr=0.0100
[2025-05-02 23:31:32,201][train][INFO] - Epoch 49/100, Val Acc=0.6451, Val Loss=1.5788, lr=0.0100
[2025-05-02 23:31:40,856][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.5818, lr=0.0100
[2025-05-02 23:31:49,603][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6248, lr=0.0100
[2025-05-02 23:31:58,431][train][INFO] - Epoch 52/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-02 23:32:07,357][train][INFO] - Epoch 53/100, Val Acc=0.6353, Val Loss=1.6055, lr=0.0100
[2025-05-02 23:32:16,217][train][INFO] - Epoch 54/100, Val Acc=0.6573, Val Loss=1.5031, lr=0.0100
[2025-05-02 23:32:25,158][train][INFO] - Epoch 55/100, Val Acc=0.6309, Val Loss=1.6423, lr=0.0100
[2025-05-02 23:32:32,352][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.5747, lr=0.0100
[2025-05-02 23:32:40,228][train][INFO] - Epoch 57/100, Val Acc=0.6449, Val Loss=1.5515, lr=0.0100
[2025-05-02 23:32:48,618][train][INFO] - Epoch 58/100, Val Acc=0.6418, Val Loss=1.5486, lr=0.0100
[2025-05-02 23:32:56,215][train][INFO] - Epoch 59/100, Val Acc=0.6442, Val Loss=1.5707, lr=0.0100
[2025-05-02 23:33:04,061][train][INFO] - Epoch 60/100, Val Acc=0.6509, Val Loss=1.5362, lr=0.0100
[2025-05-02 23:33:12,293][train][INFO] - Epoch 61/100, Val Acc=0.7079, Val Loss=1.2767, lr=0.0010
[2025-05-02 23:33:20,076][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.2703, lr=0.0010
[2025-05-02 23:33:27,820][train][INFO] - Epoch 63/100, Val Acc=0.7131, Val Loss=1.2779, lr=0.0010
[2025-05-02 23:33:35,590][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.2761, lr=0.0010
[2025-05-02 23:33:44,118][train][INFO] - Epoch 65/100, Val Acc=0.7156, Val Loss=1.2928, lr=0.0010
[2025-05-02 23:33:51,350][train][INFO] - Epoch 66/100, Val Acc=0.7151, Val Loss=1.2978, lr=0.0010
[2025-05-02 23:33:59,046][train][INFO] - Epoch 67/100, Val Acc=0.7164, Val Loss=1.3072, lr=0.0010
[2025-05-02 23:34:07,419][train][INFO] - Epoch 68/100, Val Acc=0.7168, Val Loss=1.3068, lr=0.0010
[2025-05-02 23:34:14,833][train][INFO] - Epoch 69/100, Val Acc=0.7144, Val Loss=1.3241, lr=0.0010
[2025-05-02 23:34:22,881][train][INFO] - Epoch 70/100, Val Acc=0.7165, Val Loss=1.3250, lr=0.0010
[2025-05-02 23:34:30,362][train][INFO] - Epoch 71/100, Val Acc=0.7167, Val Loss=1.3229, lr=0.0010
[2025-05-02 23:34:38,789][train][INFO] - Epoch 72/100, Val Acc=0.7132, Val Loss=1.3359, lr=0.0010
[2025-05-02 23:34:47,189][train][INFO] - Epoch 73/100, Val Acc=0.7162, Val Loss=1.3324, lr=0.0010
[2025-05-02 23:34:55,715][train][INFO] - Epoch 74/100, Val Acc=0.7167, Val Loss=1.3352, lr=0.0010
[2025-05-02 23:35:03,981][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3429, lr=0.0010
[2025-05-02 23:35:12,567][train][INFO] - Epoch 76/100, Val Acc=0.7170, Val Loss=1.3423, lr=0.0010
[2025-05-02 23:35:20,543][train][INFO] - Epoch 77/100, Val Acc=0.7174, Val Loss=1.3497, lr=0.0010
[2025-05-02 23:35:28,765][train][INFO] - Epoch 78/100, Val Acc=0.7168, Val Loss=1.3545, lr=0.0010
[2025-05-02 23:35:36,703][train][INFO] - Epoch 79/100, Val Acc=0.7159, Val Loss=1.3617, lr=0.0010
[2025-05-02 23:35:44,568][train][INFO] - Epoch 80/100, Val Acc=0.7180, Val Loss=1.3606, lr=0.0010
[2025-05-02 23:35:52,421][train][INFO] - Epoch 81/100, Val Acc=0.7171, Val Loss=1.3624, lr=0.0010
[2025-05-02 23:35:59,849][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3650, lr=0.0010
[2025-05-02 23:36:07,592][train][INFO] - Epoch 83/100, Val Acc=0.7136, Val Loss=1.3734, lr=0.0010
[2025-05-02 23:36:15,703][train][INFO] - Epoch 84/100, Val Acc=0.7159, Val Loss=1.3737, lr=0.0010
[2025-05-02 23:36:23,782][train][INFO] - Epoch 85/100, Val Acc=0.7164, Val Loss=1.3736, lr=0.0010
[2025-05-02 23:36:32,218][train][INFO] - Epoch 86/100, Val Acc=0.7165, Val Loss=1.3791, lr=0.0010
[2025-05-02 23:36:40,407][train][INFO] - Epoch 87/100, Val Acc=0.7163, Val Loss=1.3816, lr=0.0010
[2025-05-02 23:36:48,867][train][INFO] - Epoch 88/100, Val Acc=0.7138, Val Loss=1.3874, lr=0.0010
[2025-05-02 23:36:57,550][train][INFO] - Epoch 89/100, Val Acc=0.7137, Val Loss=1.3880, lr=0.0010
[2025-05-02 23:37:05,318][train][INFO] - Epoch 90/100, Val Acc=0.7168, Val Loss=1.3966, lr=0.0010
[2025-05-02 23:37:13,189][train][INFO] - Epoch 91/100, Val Acc=0.7166, Val Loss=1.3906, lr=0.0001
[2025-05-02 23:37:21,039][train][INFO] - Epoch 92/100, Val Acc=0.7174, Val Loss=1.3933, lr=0.0001
[2025-05-02 23:37:29,292][train][INFO] - Epoch 93/100, Val Acc=0.7186, Val Loss=1.3870, lr=0.0001
[2025-05-02 23:37:37,033][train][INFO] - Epoch 94/100, Val Acc=0.7185, Val Loss=1.3837, lr=0.0001
[2025-05-02 23:37:45,181][train][INFO] - Epoch 95/100, Val Acc=0.7181, Val Loss=1.3843, lr=0.0001
[2025-05-02 23:37:53,921][train][INFO] - Epoch 96/100, Val Acc=0.7180, Val Loss=1.3841, lr=0.0001
[2025-05-02 23:38:01,875][train][INFO] - Epoch 97/100, Val Acc=0.7174, Val Loss=1.3861, lr=0.0001
[2025-05-02 23:38:10,361][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3830, lr=0.0001
[2025-05-02 23:38:18,288][train][INFO] - Epoch 99/100, Val Acc=0.7174, Val Loss=1.3896, lr=0.0001
[2025-05-02 23:38:26,834][train][INFO] - Epoch 100/100, Val Acc=0.7183, Val Loss=1.3838, lr=0.0001
[2025-05-02 23:38:32,239][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7193
[2025-05-02 23:38:41,309][Progressive pruning][INFO] - Train acc : 0.010979999788105488   Val acc : 0.011399999260902405
[2025-05-02 23:38:41,309][Progressive pruning][INFO] - Current speed up: 1.50
[2025-05-02 23:38:46,457][train][INFO] - Before training : Train Acc=0.0111  Val Acc=0.0114
[2025-05-02 23:38:54,824][train][INFO] - Epoch 1/140, Val Acc=0.5988, Val Loss=1.6603, lr=0.0100
[2025-05-02 23:39:03,176][train][INFO] - Epoch 2/140, Val Acc=0.6066, Val Loss=1.6681, lr=0.0100
[2025-05-02 23:39:11,469][train][INFO] - Epoch 3/140, Val Acc=0.5976, Val Loss=1.7092, lr=0.0100
[2025-05-02 23:39:19,716][train][INFO] - Epoch 4/140, Val Acc=0.5917, Val Loss=1.8070, lr=0.0100
[2025-05-02 23:39:27,921][train][INFO] - Epoch 5/140, Val Acc=0.5946, Val Loss=1.8112, lr=0.0100
[2025-05-02 23:39:35,717][train][INFO] - Epoch 6/140, Val Acc=0.6085, Val Loss=1.7330, lr=0.0100
[2025-05-02 23:39:43,515][train][INFO] - Epoch 7/140, Val Acc=0.6143, Val Loss=1.6301, lr=0.0100
[2025-05-02 23:39:51,503][train][INFO] - Epoch 8/140, Val Acc=0.6276, Val Loss=1.6583, lr=0.0100
[2025-05-02 23:39:59,795][train][INFO] - Epoch 9/140, Val Acc=0.6258, Val Loss=1.6316, lr=0.0100
[2025-05-02 23:40:07,097][train][INFO] - Epoch 10/140, Val Acc=0.6157, Val Loss=1.7388, lr=0.0100
[2025-05-02 23:40:15,111][train][INFO] - Epoch 11/140, Val Acc=0.6131, Val Loss=1.7257, lr=0.0100
[2025-05-02 23:40:23,103][train][INFO] - Epoch 12/140, Val Acc=0.6124, Val Loss=1.7843, lr=0.0100
[2025-05-02 23:40:31,285][train][INFO] - Epoch 13/140, Val Acc=0.5880, Val Loss=1.8623, lr=0.0100
[2025-05-02 23:40:39,024][train][INFO] - Epoch 14/140, Val Acc=0.6248, Val Loss=1.6596, lr=0.0100
[2025-05-02 23:40:47,114][train][INFO] - Epoch 15/140, Val Acc=0.6425, Val Loss=1.5606, lr=0.0100
[2025-05-02 23:40:55,360][train][INFO] - Epoch 16/140, Val Acc=0.6389, Val Loss=1.6380, lr=0.0100
[2025-05-02 23:41:03,976][train][INFO] - Epoch 17/140, Val Acc=0.6228, Val Loss=1.6786, lr=0.0100
[2025-05-02 23:41:12,727][train][INFO] - Epoch 18/140, Val Acc=0.6252, Val Loss=1.6816, lr=0.0100
[2025-05-02 23:41:20,642][train][INFO] - Epoch 19/140, Val Acc=0.6255, Val Loss=1.6596, lr=0.0100
[2025-05-02 23:41:28,180][train][INFO] - Epoch 20/140, Val Acc=0.6465, Val Loss=1.5570, lr=0.0100
[2025-05-02 23:41:36,896][train][INFO] - Epoch 21/140, Val Acc=0.6334, Val Loss=1.6583, lr=0.0100
[2025-05-02 23:41:45,565][train][INFO] - Epoch 22/140, Val Acc=0.6407, Val Loss=1.6248, lr=0.0100
[2025-05-02 23:41:53,257][train][INFO] - Epoch 23/140, Val Acc=0.6224, Val Loss=1.7131, lr=0.0100
[2025-05-02 23:42:00,065][train][INFO] - Epoch 24/140, Val Acc=0.6367, Val Loss=1.6465, lr=0.0100
[2025-05-02 23:42:06,772][train][INFO] - Epoch 25/140, Val Acc=0.6168, Val Loss=1.7561, lr=0.0100
[2025-05-02 23:42:13,831][train][INFO] - Epoch 26/140, Val Acc=0.6199, Val Loss=1.7185, lr=0.0100
[2025-05-02 23:42:21,633][train][INFO] - Epoch 27/140, Val Acc=0.6280, Val Loss=1.6555, lr=0.0100
[2025-05-02 23:42:29,751][train][INFO] - Epoch 28/140, Val Acc=0.6393, Val Loss=1.6006, lr=0.0100
[2025-05-02 23:42:38,325][train][INFO] - Epoch 29/140, Val Acc=0.6212, Val Loss=1.7161, lr=0.0100
[2025-05-02 23:42:45,883][train][INFO] - Epoch 30/140, Val Acc=0.6284, Val Loss=1.7636, lr=0.0100
[2025-05-02 23:42:54,664][train][INFO] - Epoch 31/140, Val Acc=0.6204, Val Loss=1.7500, lr=0.0100
[2025-05-02 23:43:02,486][train][INFO] - Epoch 32/140, Val Acc=0.6297, Val Loss=1.6900, lr=0.0100
[2025-05-02 23:43:10,795][train][INFO] - Epoch 33/140, Val Acc=0.6273, Val Loss=1.7261, lr=0.0100
[2025-05-02 23:43:18,957][train][INFO] - Epoch 34/140, Val Acc=0.6309, Val Loss=1.6828, lr=0.0100
[2025-05-02 23:43:27,014][train][INFO] - Epoch 35/140, Val Acc=0.6348, Val Loss=1.6456, lr=0.0100
[2025-05-02 23:43:35,261][train][INFO] - Epoch 36/140, Val Acc=0.6296, Val Loss=1.6664, lr=0.0100
[2025-05-02 23:43:42,840][train][INFO] - Epoch 37/140, Val Acc=0.6344, Val Loss=1.6504, lr=0.0100
[2025-05-02 23:43:51,310][train][INFO] - Epoch 38/140, Val Acc=0.6360, Val Loss=1.6327, lr=0.0100
[2025-05-02 23:43:59,656][train][INFO] - Epoch 39/140, Val Acc=0.6298, Val Loss=1.7012, lr=0.0100
[2025-05-02 23:44:07,729][train][INFO] - Epoch 40/140, Val Acc=0.6120, Val Loss=1.8681, lr=0.0100
[2025-05-02 23:44:16,077][train][INFO] - Epoch 41/140, Val Acc=0.6318, Val Loss=1.7151, lr=0.0100
[2025-05-02 23:44:24,177][train][INFO] - Epoch 42/140, Val Acc=0.6290, Val Loss=1.7242, lr=0.0100
[2025-05-02 23:44:32,346][train][INFO] - Epoch 43/140, Val Acc=0.6303, Val Loss=1.7090, lr=0.0100
[2025-05-02 23:44:39,992][train][INFO] - Epoch 44/140, Val Acc=0.6459, Val Loss=1.6294, lr=0.0100
[2025-05-02 23:44:46,800][train][INFO] - Epoch 45/140, Val Acc=0.6233, Val Loss=1.7620, lr=0.0100
[2025-05-02 23:44:55,298][train][INFO] - Epoch 46/140, Val Acc=0.6230, Val Loss=1.7830, lr=0.0100
[2025-05-02 23:45:03,489][train][INFO] - Epoch 47/140, Val Acc=0.6280, Val Loss=1.7183, lr=0.0100
[2025-05-02 23:45:12,195][train][INFO] - Epoch 48/140, Val Acc=0.6175, Val Loss=1.7591, lr=0.0100
[2025-05-02 23:45:20,049][train][INFO] - Epoch 49/140, Val Acc=0.6264, Val Loss=1.7728, lr=0.0100
[2025-05-02 23:45:27,109][train][INFO] - Epoch 50/140, Val Acc=0.6402, Val Loss=1.6772, lr=0.0100
[2025-05-02 23:45:35,505][train][INFO] - Epoch 51/140, Val Acc=0.6337, Val Loss=1.6836, lr=0.0100
[2025-05-02 23:45:43,554][train][INFO] - Epoch 52/140, Val Acc=0.6238, Val Loss=1.7757, lr=0.0100
[2025-05-02 23:45:52,057][train][INFO] - Epoch 53/140, Val Acc=0.6298, Val Loss=1.6965, lr=0.0100
[2025-05-02 23:46:00,074][train][INFO] - Epoch 54/140, Val Acc=0.6283, Val Loss=1.7162, lr=0.0100
[2025-05-02 23:46:07,747][train][INFO] - Epoch 55/140, Val Acc=0.6439, Val Loss=1.6446, lr=0.0100
[2025-05-02 23:46:15,755][train][INFO] - Epoch 56/140, Val Acc=0.6197, Val Loss=1.7788, lr=0.0100
[2025-05-02 23:46:23,555][train][INFO] - Epoch 57/140, Val Acc=0.6254, Val Loss=1.7220, lr=0.0100
[2025-05-02 23:46:31,691][train][INFO] - Epoch 58/140, Val Acc=0.6351, Val Loss=1.6742, lr=0.0100
[2025-05-02 23:46:39,552][train][INFO] - Epoch 59/140, Val Acc=0.6421, Val Loss=1.6551, lr=0.0100
[2025-05-02 23:46:46,676][train][INFO] - Epoch 60/140, Val Acc=0.6397, Val Loss=1.7040, lr=0.0100
[2025-05-02 23:46:54,685][train][INFO] - Epoch 61/140, Val Acc=0.6166, Val Loss=1.7775, lr=0.0100
[2025-05-02 23:47:02,878][train][INFO] - Epoch 62/140, Val Acc=0.6409, Val Loss=1.6615, lr=0.0100
[2025-05-02 23:47:11,229][train][INFO] - Epoch 63/140, Val Acc=0.6399, Val Loss=1.7031, lr=0.0100
[2025-05-02 23:47:19,867][train][INFO] - Epoch 64/140, Val Acc=0.6226, Val Loss=1.7818, lr=0.0100
[2025-05-02 23:47:27,775][train][INFO] - Epoch 65/140, Val Acc=0.6368, Val Loss=1.6851, lr=0.0100
[2025-05-02 23:47:34,820][train][INFO] - Epoch 66/140, Val Acc=0.6098, Val Loss=1.8129, lr=0.0100
[2025-05-02 23:47:42,879][train][INFO] - Epoch 67/140, Val Acc=0.6352, Val Loss=1.7045, lr=0.0100
[2025-05-02 23:47:51,434][train][INFO] - Epoch 68/140, Val Acc=0.6325, Val Loss=1.6644, lr=0.0100
[2025-05-02 23:48:00,158][train][INFO] - Epoch 69/140, Val Acc=0.6426, Val Loss=1.6696, lr=0.0100
[2025-05-02 23:48:08,434][train][INFO] - Epoch 70/140, Val Acc=0.6314, Val Loss=1.7994, lr=0.0100
[2025-05-02 23:48:16,804][train][INFO] - Epoch 71/140, Val Acc=0.6315, Val Loss=1.6885, lr=0.0100
[2025-05-02 23:48:24,724][train][INFO] - Epoch 72/140, Val Acc=0.6317, Val Loss=1.7138, lr=0.0100
[2025-05-02 23:48:32,749][train][INFO] - Epoch 73/140, Val Acc=0.6274, Val Loss=1.7102, lr=0.0100
[2025-05-02 23:48:40,787][train][INFO] - Epoch 74/140, Val Acc=0.6326, Val Loss=1.7109, lr=0.0100
[2025-05-02 23:48:48,573][train][INFO] - Epoch 75/140, Val Acc=0.6370, Val Loss=1.6684, lr=0.0100
[2025-05-02 23:48:56,750][train][INFO] - Epoch 76/140, Val Acc=0.6308, Val Loss=1.7468, lr=0.0100
[2025-05-02 23:49:04,807][train][INFO] - Epoch 77/140, Val Acc=0.6401, Val Loss=1.6604, lr=0.0100
[2025-05-02 23:49:12,734][train][INFO] - Epoch 78/140, Val Acc=0.6267, Val Loss=1.7380, lr=0.0100
[2025-05-02 23:49:20,244][train][INFO] - Epoch 79/140, Val Acc=0.6138, Val Loss=1.8038, lr=0.0100
[2025-05-02 23:49:28,331][train][INFO] - Epoch 80/140, Val Acc=0.6466, Val Loss=1.6251, lr=0.0100
[2025-05-02 23:49:36,848][train][INFO] - Epoch 81/140, Val Acc=0.6889, Val Loss=1.3915, lr=0.0010
[2025-05-02 23:49:45,012][train][INFO] - Epoch 82/140, Val Acc=0.6930, Val Loss=1.3854, lr=0.0010
[2025-05-02 23:49:53,493][train][INFO] - Epoch 83/140, Val Acc=0.6973, Val Loss=1.3947, lr=0.0010
[2025-05-02 23:50:01,574][train][INFO] - Epoch 84/140, Val Acc=0.6960, Val Loss=1.3943, lr=0.0010
[2025-05-02 23:50:09,851][train][INFO] - Epoch 85/140, Val Acc=0.6976, Val Loss=1.3941, lr=0.0010
[2025-05-02 23:50:17,762][train][INFO] - Epoch 86/140, Val Acc=0.6950, Val Loss=1.4015, lr=0.0010
[2025-05-02 23:50:25,217][train][INFO] - Epoch 87/140, Val Acc=0.6976, Val Loss=1.4004, lr=0.0010
[2025-05-02 23:50:32,856][train][INFO] - Epoch 88/140, Val Acc=0.6974, Val Loss=1.4016, lr=0.0010
[2025-05-02 23:50:41,190][train][INFO] - Epoch 89/140, Val Acc=0.6962, Val Loss=1.4108, lr=0.0010
[2025-05-02 23:50:49,448][train][INFO] - Epoch 90/140, Val Acc=0.6972, Val Loss=1.4104, lr=0.0010
[2025-05-02 23:50:57,402][train][INFO] - Epoch 91/140, Val Acc=0.6978, Val Loss=1.4196, lr=0.0010
[2025-05-02 23:51:05,417][train][INFO] - Epoch 92/140, Val Acc=0.6984, Val Loss=1.4145, lr=0.0010
[2025-05-02 23:51:13,554][train][INFO] - Epoch 93/140, Val Acc=0.6976, Val Loss=1.4120, lr=0.0010
[2025-05-02 23:51:21,803][train][INFO] - Epoch 94/140, Val Acc=0.6986, Val Loss=1.4104, lr=0.0010
[2025-05-02 23:51:30,028][train][INFO] - Epoch 95/140, Val Acc=0.7022, Val Loss=1.4171, lr=0.0010
[2025-05-02 23:51:38,244][train][INFO] - Epoch 96/140, Val Acc=0.7036, Val Loss=1.4251, lr=0.0010
[2025-05-02 23:51:46,342][train][INFO] - Epoch 97/140, Val Acc=0.7001, Val Loss=1.4291, lr=0.0010
[2025-05-02 23:51:53,920][train][INFO] - Epoch 98/140, Val Acc=0.7007, Val Loss=1.4305, lr=0.0010
[2025-05-02 23:52:02,437][train][INFO] - Epoch 99/140, Val Acc=0.7008, Val Loss=1.4301, lr=0.0010
[2025-05-02 23:52:11,067][train][INFO] - Epoch 100/140, Val Acc=0.7012, Val Loss=1.4315, lr=0.0010
[2025-05-02 23:52:19,230][train][INFO] - Epoch 101/140, Val Acc=0.6983, Val Loss=1.4329, lr=0.0010
[2025-05-02 23:52:27,625][train][INFO] - Epoch 102/140, Val Acc=0.7003, Val Loss=1.4311, lr=0.0010
[2025-05-02 23:52:36,030][train][INFO] - Epoch 103/140, Val Acc=0.6999, Val Loss=1.4350, lr=0.0010
[2025-05-02 23:52:44,196][train][INFO] - Epoch 104/140, Val Acc=0.6980, Val Loss=1.4357, lr=0.0010
[2025-05-02 23:52:52,222][train][INFO] - Epoch 105/140, Val Acc=0.7022, Val Loss=1.4365, lr=0.0010
[2025-05-02 23:52:59,811][train][INFO] - Epoch 106/140, Val Acc=0.6990, Val Loss=1.4440, lr=0.0010
[2025-05-02 23:53:08,137][train][INFO] - Epoch 107/140, Val Acc=0.6989, Val Loss=1.4401, lr=0.0010
[2025-05-02 23:53:15,957][train][INFO] - Epoch 108/140, Val Acc=0.7015, Val Loss=1.4398, lr=0.0010
[2025-05-02 23:53:24,507][train][INFO] - Epoch 109/140, Val Acc=0.6996, Val Loss=1.4455, lr=0.0010
[2025-05-02 23:53:32,124][train][INFO] - Epoch 110/140, Val Acc=0.6976, Val Loss=1.4478, lr=0.0010
[2025-05-02 23:53:40,140][train][INFO] - Epoch 111/140, Val Acc=0.6991, Val Loss=1.4438, lr=0.0010
[2025-05-02 23:53:48,403][train][INFO] - Epoch 112/140, Val Acc=0.7014, Val Loss=1.4499, lr=0.0010
[2025-05-02 23:53:56,462][train][INFO] - Epoch 113/140, Val Acc=0.7011, Val Loss=1.4515, lr=0.0010
[2025-05-02 23:54:04,365][train][INFO] - Epoch 114/140, Val Acc=0.7016, Val Loss=1.4511, lr=0.0010
[2025-05-02 23:54:11,661][train][INFO] - Epoch 115/140, Val Acc=0.7019, Val Loss=1.4525, lr=0.0010
[2025-05-02 23:54:20,299][train][INFO] - Epoch 116/140, Val Acc=0.7010, Val Loss=1.4600, lr=0.0010
[2025-05-02 23:54:28,894][train][INFO] - Epoch 117/140, Val Acc=0.7012, Val Loss=1.4557, lr=0.0010
[2025-05-02 23:54:37,400][train][INFO] - Epoch 118/140, Val Acc=0.6997, Val Loss=1.4567, lr=0.0010
[2025-05-02 23:54:45,506][train][INFO] - Epoch 119/140, Val Acc=0.7008, Val Loss=1.4601, lr=0.0010
[2025-05-02 23:54:53,434][train][INFO] - Epoch 120/140, Val Acc=0.7022, Val Loss=1.4618, lr=0.0010
[2025-05-02 23:55:01,183][train][INFO] - Epoch 121/140, Val Acc=0.7020, Val Loss=1.4543, lr=0.0001
[2025-05-02 23:55:09,473][train][INFO] - Epoch 122/140, Val Acc=0.7012, Val Loss=1.4564, lr=0.0001
[2025-05-02 23:55:17,433][train][INFO] - Epoch 123/140, Val Acc=0.7021, Val Loss=1.4514, lr=0.0001
[2025-05-02 23:55:25,652][train][INFO] - Epoch 124/140, Val Acc=0.7014, Val Loss=1.4504, lr=0.0001
[2025-05-02 23:55:33,726][train][INFO] - Epoch 125/140, Val Acc=0.7026, Val Loss=1.4532, lr=0.0001
[2025-05-02 23:55:41,308][train][INFO] - Epoch 126/140, Val Acc=0.7018, Val Loss=1.4516, lr=0.0001
[2025-05-02 23:55:49,663][train][INFO] - Epoch 127/140, Val Acc=0.7020, Val Loss=1.4524, lr=0.0001
[2025-05-02 23:55:57,625][train][INFO] - Epoch 128/140, Val Acc=0.7014, Val Loss=1.4499, lr=0.0001
[2025-05-02 23:56:05,514][train][INFO] - Epoch 129/140, Val Acc=0.7006, Val Loss=1.4538, lr=0.0001
[2025-05-02 23:56:13,452][train][INFO] - Epoch 130/140, Val Acc=0.7009, Val Loss=1.4525, lr=0.0001
[2025-05-02 23:56:21,421][train][INFO] - Epoch 131/140, Val Acc=0.7042, Val Loss=1.4571, lr=0.0001
[2025-05-02 23:56:29,561][train][INFO] - Epoch 132/140, Val Acc=0.7028, Val Loss=1.4542, lr=0.0001
[2025-05-02 23:56:38,282][train][INFO] - Epoch 133/140, Val Acc=0.7027, Val Loss=1.4522, lr=0.0001
[2025-05-02 23:56:46,161][train][INFO] - Epoch 134/140, Val Acc=0.7037, Val Loss=1.4510, lr=0.0001
[2025-05-02 23:56:54,980][train][INFO] - Epoch 135/140, Val Acc=0.7022, Val Loss=1.4539, lr=0.0001
[2025-05-02 23:57:03,397][train][INFO] - Epoch 136/140, Val Acc=0.7041, Val Loss=1.4515, lr=0.0001
[2025-05-02 23:57:11,217][train][INFO] - Epoch 137/140, Val Acc=0.7026, Val Loss=1.4529, lr=0.0001
[2025-05-02 23:57:19,408][train][INFO] - Epoch 138/140, Val Acc=0.7035, Val Loss=1.4504, lr=0.0001
[2025-05-02 23:57:27,954][train][INFO] - Epoch 139/140, Val Acc=0.7022, Val Loss=1.4494, lr=0.0001
[2025-05-02 23:57:35,763][train][INFO] - Epoch 140/140, Val Acc=0.7027, Val Loss=1.4561, lr=0.0001
[2025-05-02 23:57:41,034][train][INFO] - After training : Train Acc=0.9979  Val Acc=0.7042
[2025-05-02 23:57:41,058][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(36, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(82, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(127, 247, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(247, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(247, 217, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(217, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(217, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(144, 141, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(141, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(141, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(24, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(6, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(18, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(4, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(12, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(23, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=68, out_features=100, bias=True)
)
[2025-05-02 23:57:41,058][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.7041999697685242
                      Speed up: 1.50   Final speed up: 4.52
[2025-05-03 00:09:09,468][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 0
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Gatsby
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-03 00:09:09,519][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 00:09:09,520][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 00:09:09,520][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 00:09:26,149][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 00:09:31,156][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 00:09:36,937][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-03 00:09:36,938][Progressive pruning][INFO] - Current speed up: 1.50
[2025-05-03 00:09:41,815][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 00:09:50,202][train][INFO] - Epoch 1/140, Val Acc=0.0719, Val Loss=3.8557, lr=0.0100
[2025-05-03 00:09:57,776][train][INFO] - Epoch 2/140, Val Acc=0.2165, Val Loss=2.9316, lr=0.0100
[2025-05-03 00:10:05,760][train][INFO] - Epoch 3/140, Val Acc=0.2757, Val Loss=2.6974, lr=0.0100
[2025-05-03 00:10:13,790][train][INFO] - Epoch 4/140, Val Acc=0.2712, Val Loss=2.8634, lr=0.0100
[2025-05-03 00:10:22,257][train][INFO] - Epoch 5/140, Val Acc=0.3665, Val Loss=2.3790, lr=0.0100
[2025-05-03 00:10:30,780][train][INFO] - Epoch 6/140, Val Acc=0.4179, Val Loss=2.1644, lr=0.0100
[2025-05-03 00:10:39,895][train][INFO] - Epoch 7/140, Val Acc=0.4245, Val Loss=2.1471, lr=0.0100
[2025-05-03 00:10:48,584][train][INFO] - Epoch 8/140, Val Acc=0.4077, Val Loss=2.2998, lr=0.0100
[2025-05-03 00:10:57,220][train][INFO] - Epoch 9/140, Val Acc=0.4454, Val Loss=2.1174, lr=0.0100
[2025-05-03 00:11:03,949][train][INFO] - Epoch 10/140, Val Acc=0.4564, Val Loss=2.0201, lr=0.0100
[2025-05-03 00:11:10,701][train][INFO] - Epoch 11/140, Val Acc=0.4547, Val Loss=2.0974, lr=0.0100
[2025-05-03 00:11:17,871][train][INFO] - Epoch 12/140, Val Acc=0.4511, Val Loss=2.1183, lr=0.0100
[2025-05-03 00:11:25,889][train][INFO] - Epoch 13/140, Val Acc=0.4871, Val Loss=1.9732, lr=0.0100
[2025-05-03 00:11:33,950][train][INFO] - Epoch 14/140, Val Acc=0.4937, Val Loss=1.9048, lr=0.0100
[2025-05-03 00:11:41,921][train][INFO] - Epoch 15/140, Val Acc=0.5229, Val Loss=1.7677, lr=0.0100
[2025-05-03 00:11:50,943][train][INFO] - Epoch 16/140, Val Acc=0.4841, Val Loss=1.9641, lr=0.0100
[2025-05-03 00:11:59,365][train][INFO] - Epoch 17/140, Val Acc=0.5477, Val Loss=1.6579, lr=0.0100
[2025-05-03 00:12:08,034][train][INFO] - Epoch 18/140, Val Acc=0.5515, Val Loss=1.6598, lr=0.0100
[2025-05-03 00:12:16,774][train][INFO] - Epoch 19/140, Val Acc=0.5276, Val Loss=1.7803, lr=0.0100
[2025-05-03 00:12:25,142][train][INFO] - Epoch 20/140, Val Acc=0.5436, Val Loss=1.7133, lr=0.0100
[2025-05-03 00:12:33,418][train][INFO] - Epoch 21/140, Val Acc=0.5514, Val Loss=1.6747, lr=0.0100
[2025-05-03 00:12:42,029][train][INFO] - Epoch 22/140, Val Acc=0.5604, Val Loss=1.6520, lr=0.0100
[2025-05-03 00:12:50,161][train][INFO] - Epoch 23/140, Val Acc=0.5566, Val Loss=1.6447, lr=0.0100
[2025-05-03 00:12:58,121][train][INFO] - Epoch 24/140, Val Acc=0.5647, Val Loss=1.6319, lr=0.0100
[2025-05-03 00:13:05,876][train][INFO] - Epoch 25/140, Val Acc=0.5435, Val Loss=1.7487, lr=0.0100
[2025-05-03 00:13:14,244][train][INFO] - Epoch 26/140, Val Acc=0.5671, Val Loss=1.6231, lr=0.0100
[2025-05-03 00:13:22,528][train][INFO] - Epoch 27/140, Val Acc=0.5546, Val Loss=1.7154, lr=0.0100
[2025-05-03 00:13:30,947][train][INFO] - Epoch 28/140, Val Acc=0.5706, Val Loss=1.6356, lr=0.0100
[2025-05-03 00:13:39,224][train][INFO] - Epoch 29/140, Val Acc=0.5737, Val Loss=1.6308, lr=0.0100
[2025-05-03 00:13:47,623][train][INFO] - Epoch 30/140, Val Acc=0.5748, Val Loss=1.6421, lr=0.0100
[2025-05-03 00:13:55,721][train][INFO] - Epoch 31/140, Val Acc=0.5737, Val Loss=1.6185, lr=0.0100
[2025-05-03 00:14:03,938][train][INFO] - Epoch 32/140, Val Acc=0.5862, Val Loss=1.5676, lr=0.0100
[2025-05-03 00:14:12,137][train][INFO] - Epoch 33/140, Val Acc=0.5835, Val Loss=1.5517, lr=0.0100
[2025-05-03 00:14:20,164][train][INFO] - Epoch 34/140, Val Acc=0.5807, Val Loss=1.5878, lr=0.0100
[2025-05-03 00:14:28,507][train][INFO] - Epoch 35/140, Val Acc=0.5850, Val Loss=1.5888, lr=0.0100
[2025-05-03 00:14:36,839][train][INFO] - Epoch 36/140, Val Acc=0.5660, Val Loss=1.6603, lr=0.0100
[2025-05-03 00:14:45,290][train][INFO] - Epoch 37/140, Val Acc=0.5830, Val Loss=1.5908, lr=0.0100
[2025-05-03 00:14:53,420][train][INFO] - Epoch 38/140, Val Acc=0.5690, Val Loss=1.6643, lr=0.0100
[2025-05-03 00:15:01,840][train][INFO] - Epoch 39/140, Val Acc=0.5811, Val Loss=1.6446, lr=0.0100
[2025-05-03 00:15:09,960][train][INFO] - Epoch 40/140, Val Acc=0.5697, Val Loss=1.6941, lr=0.0100
[2025-05-03 00:15:17,790][train][INFO] - Epoch 41/140, Val Acc=0.5735, Val Loss=1.6430, lr=0.0100
[2025-05-03 00:15:25,971][train][INFO] - Epoch 42/140, Val Acc=0.5765, Val Loss=1.6684, lr=0.0100
[2025-05-03 00:15:34,388][train][INFO] - Epoch 43/140, Val Acc=0.5857, Val Loss=1.6260, lr=0.0100
[2025-05-03 00:15:42,959][train][INFO] - Epoch 44/140, Val Acc=0.5888, Val Loss=1.6010, lr=0.0100
[2025-05-03 00:15:51,137][train][INFO] - Epoch 45/140, Val Acc=0.5917, Val Loss=1.5678, lr=0.0100
[2025-05-03 00:15:59,006][train][INFO] - Epoch 46/140, Val Acc=0.5627, Val Loss=1.7657, lr=0.0100
[2025-05-03 00:16:07,060][train][INFO] - Epoch 47/140, Val Acc=0.5907, Val Loss=1.5919, lr=0.0100
[2025-05-03 00:16:15,447][train][INFO] - Epoch 48/140, Val Acc=0.5770, Val Loss=1.6903, lr=0.0100
[2025-05-03 00:16:23,562][train][INFO] - Epoch 49/140, Val Acc=0.5856, Val Loss=1.6184, lr=0.0100
[2025-05-03 00:16:31,584][train][INFO] - Epoch 50/140, Val Acc=0.5871, Val Loss=1.6246, lr=0.0100
[2025-05-03 00:16:39,774][train][INFO] - Epoch 51/140, Val Acc=0.5662, Val Loss=1.7584, lr=0.0100
[2025-05-03 00:16:47,920][train][INFO] - Epoch 52/140, Val Acc=0.5934, Val Loss=1.5830, lr=0.0100
[2025-05-03 00:16:56,069][train][INFO] - Epoch 53/140, Val Acc=0.5852, Val Loss=1.6423, lr=0.0100
[2025-05-03 00:17:04,027][train][INFO] - Epoch 54/140, Val Acc=0.5828, Val Loss=1.6396, lr=0.0100
[2025-05-03 00:17:11,595][train][INFO] - Epoch 55/140, Val Acc=0.5738, Val Loss=1.7316, lr=0.0100
[2025-05-03 00:17:19,659][train][INFO] - Epoch 56/140, Val Acc=0.5830, Val Loss=1.6733, lr=0.0100
[2025-05-03 00:17:27,870][train][INFO] - Epoch 57/140, Val Acc=0.5970, Val Loss=1.5978, lr=0.0100
[2025-05-03 00:17:35,508][train][INFO] - Epoch 58/140, Val Acc=0.5685, Val Loss=1.7737, lr=0.0100
[2025-05-03 00:17:44,095][train][INFO] - Epoch 59/140, Val Acc=0.5800, Val Loss=1.6621, lr=0.0100
[2025-05-03 00:17:52,547][train][INFO] - Epoch 60/140, Val Acc=0.6036, Val Loss=1.5636, lr=0.0100
[2025-05-03 00:18:00,441][train][INFO] - Epoch 61/140, Val Acc=0.5948, Val Loss=1.6228, lr=0.0100
[2025-05-03 00:18:08,404][train][INFO] - Epoch 62/140, Val Acc=0.5941, Val Loss=1.6243, lr=0.0100
[2025-05-03 00:18:16,524][train][INFO] - Epoch 63/140, Val Acc=0.6014, Val Loss=1.5375, lr=0.0100
[2025-05-03 00:18:24,825][train][INFO] - Epoch 64/140, Val Acc=0.6011, Val Loss=1.6026, lr=0.0100
[2025-05-03 00:18:33,120][train][INFO] - Epoch 65/140, Val Acc=0.5792, Val Loss=1.7155, lr=0.0100
[2025-05-03 00:18:41,421][train][INFO] - Epoch 66/140, Val Acc=0.5923, Val Loss=1.6465, lr=0.0100
[2025-05-03 00:18:49,708][train][INFO] - Epoch 67/140, Val Acc=0.6010, Val Loss=1.5983, lr=0.0100
[2025-05-03 00:18:58,230][train][INFO] - Epoch 68/140, Val Acc=0.6048, Val Loss=1.5648, lr=0.0100
[2025-05-03 00:19:05,825][train][INFO] - Epoch 69/140, Val Acc=0.6089, Val Loss=1.5732, lr=0.0100
[2025-05-03 00:19:13,489][train][INFO] - Epoch 70/140, Val Acc=0.5902, Val Loss=1.6746, lr=0.0100
[2025-05-03 00:19:21,441][train][INFO] - Epoch 71/140, Val Acc=0.5758, Val Loss=1.7315, lr=0.0100
[2025-05-03 00:19:29,544][train][INFO] - Epoch 72/140, Val Acc=0.5867, Val Loss=1.6950, lr=0.0100
[2025-05-03 00:19:37,844][train][INFO] - Epoch 73/140, Val Acc=0.6031, Val Loss=1.5885, lr=0.0100
[2025-05-03 00:19:46,298][train][INFO] - Epoch 74/140, Val Acc=0.6119, Val Loss=1.5540, lr=0.0100
[2025-05-03 00:19:54,332][train][INFO] - Epoch 75/140, Val Acc=0.6179, Val Loss=1.5414, lr=0.0100
[2025-05-03 00:20:02,552][train][INFO] - Epoch 76/140, Val Acc=0.6005, Val Loss=1.5912, lr=0.0100
[2025-05-03 00:20:10,961][train][INFO] - Epoch 77/140, Val Acc=0.5872, Val Loss=1.7430, lr=0.0100
[2025-05-03 00:20:18,819][train][INFO] - Epoch 78/140, Val Acc=0.6133, Val Loss=1.5511, lr=0.0100
[2025-05-03 00:20:26,497][train][INFO] - Epoch 79/140, Val Acc=0.5864, Val Loss=1.7421, lr=0.0100
[2025-05-03 00:20:34,920][train][INFO] - Epoch 80/140, Val Acc=0.6084, Val Loss=1.5634, lr=0.0100
[2025-05-03 00:20:43,012][train][INFO] - Epoch 81/140, Val Acc=0.6674, Val Loss=1.3042, lr=0.0010
[2025-05-03 00:20:50,917][train][INFO] - Epoch 82/140, Val Acc=0.6654, Val Loss=1.3083, lr=0.0010
[2025-05-03 00:20:59,352][train][INFO] - Epoch 83/140, Val Acc=0.6648, Val Loss=1.3138, lr=0.0010
[2025-05-03 00:21:07,561][train][INFO] - Epoch 84/140, Val Acc=0.6663, Val Loss=1.3078, lr=0.0010
[2025-05-03 00:21:15,520][train][INFO] - Epoch 85/140, Val Acc=0.6674, Val Loss=1.3173, lr=0.0010
[2025-05-03 00:21:23,594][train][INFO] - Epoch 86/140, Val Acc=0.6669, Val Loss=1.3194, lr=0.0010
[2025-05-03 00:21:32,189][train][INFO] - Epoch 87/140, Val Acc=0.6671, Val Loss=1.3286, lr=0.0010
[2025-05-03 00:21:40,490][train][INFO] - Epoch 88/140, Val Acc=0.6672, Val Loss=1.3313, lr=0.0010
[2025-05-03 00:21:48,931][train][INFO] - Epoch 89/140, Val Acc=0.6682, Val Loss=1.3412, lr=0.0010
[2025-05-03 00:21:57,232][train][INFO] - Epoch 90/140, Val Acc=0.6659, Val Loss=1.3527, lr=0.0010
[2025-05-03 00:22:05,505][train][INFO] - Epoch 91/140, Val Acc=0.6690, Val Loss=1.3573, lr=0.0010
[2025-05-03 00:22:13,567][train][INFO] - Epoch 92/140, Val Acc=0.6704, Val Loss=1.3526, lr=0.0010
[2025-05-03 00:22:21,339][train][INFO] - Epoch 93/140, Val Acc=0.6682, Val Loss=1.3700, lr=0.0010
[2025-05-03 00:22:28,707][train][INFO] - Epoch 94/140, Val Acc=0.6680, Val Loss=1.3717, lr=0.0010
[2025-05-03 00:22:36,072][train][INFO] - Epoch 95/140, Val Acc=0.6690, Val Loss=1.3820, lr=0.0010
[2025-05-03 00:22:43,682][train][INFO] - Epoch 96/140, Val Acc=0.6667, Val Loss=1.3827, lr=0.0010
[2025-05-03 00:22:51,391][train][INFO] - Epoch 97/140, Val Acc=0.6673, Val Loss=1.3993, lr=0.0010
[2025-05-03 00:22:59,110][train][INFO] - Epoch 98/140, Val Acc=0.6662, Val Loss=1.3931, lr=0.0010
[2025-05-03 00:23:07,219][train][INFO] - Epoch 99/140, Val Acc=0.6708, Val Loss=1.4049, lr=0.0010
[2025-05-03 00:23:14,820][train][INFO] - Epoch 100/140, Val Acc=0.6690, Val Loss=1.4057, lr=0.0010
[2025-05-03 00:23:22,724][train][INFO] - Epoch 101/140, Val Acc=0.6679, Val Loss=1.4149, lr=0.0010
[2025-05-03 00:23:30,649][train][INFO] - Epoch 102/140, Val Acc=0.6688, Val Loss=1.4216, lr=0.0010
[2025-05-03 00:23:38,449][train][INFO] - Epoch 103/140, Val Acc=0.6632, Val Loss=1.4390, lr=0.0010
[2025-05-03 00:23:46,219][train][INFO] - Epoch 104/140, Val Acc=0.6653, Val Loss=1.4323, lr=0.0010
[2025-05-03 00:23:54,272][train][INFO] - Epoch 105/140, Val Acc=0.6686, Val Loss=1.4298, lr=0.0010
[2025-05-03 00:24:02,186][train][INFO] - Epoch 106/140, Val Acc=0.6658, Val Loss=1.4467, lr=0.0010
[2025-05-03 00:24:10,174][train][INFO] - Epoch 107/140, Val Acc=0.6680, Val Loss=1.4396, lr=0.0010
[2025-05-03 00:24:18,056][train][INFO] - Epoch 108/140, Val Acc=0.6698, Val Loss=1.4476, lr=0.0010
[2025-05-03 00:24:26,162][train][INFO] - Epoch 109/140, Val Acc=0.6693, Val Loss=1.4567, lr=0.0010
[2025-05-03 00:24:33,865][train][INFO] - Epoch 110/140, Val Acc=0.6665, Val Loss=1.4617, lr=0.0010
[2025-05-03 00:24:41,970][train][INFO] - Epoch 111/140, Val Acc=0.6627, Val Loss=1.4634, lr=0.0010
[2025-05-03 00:24:49,880][train][INFO] - Epoch 112/140, Val Acc=0.6689, Val Loss=1.4653, lr=0.0010
[2025-05-03 00:24:57,843][train][INFO] - Epoch 113/140, Val Acc=0.6650, Val Loss=1.4800, lr=0.0010
[2025-05-03 00:25:06,114][train][INFO] - Epoch 114/140, Val Acc=0.6678, Val Loss=1.4915, lr=0.0010
[2025-05-03 00:25:14,452][train][INFO] - Epoch 115/140, Val Acc=0.6664, Val Loss=1.4836, lr=0.0010
[2025-05-03 00:25:22,357][train][INFO] - Epoch 116/140, Val Acc=0.6643, Val Loss=1.4909, lr=0.0010
[2025-05-03 00:25:30,425][train][INFO] - Epoch 117/140, Val Acc=0.6668, Val Loss=1.4808, lr=0.0010
[2025-05-03 00:25:38,631][train][INFO] - Epoch 118/140, Val Acc=0.6620, Val Loss=1.5011, lr=0.0010
[2025-05-03 00:25:46,177][train][INFO] - Epoch 119/140, Val Acc=0.6678, Val Loss=1.4921, lr=0.0010
[2025-05-03 00:25:53,338][train][INFO] - Epoch 120/140, Val Acc=0.6638, Val Loss=1.5086, lr=0.0010
[2025-05-03 00:26:01,164][train][INFO] - Epoch 121/140, Val Acc=0.6655, Val Loss=1.4864, lr=0.0001
[2025-05-03 00:26:08,989][train][INFO] - Epoch 122/140, Val Acc=0.6672, Val Loss=1.4875, lr=0.0001
[2025-05-03 00:26:17,096][train][INFO] - Epoch 123/140, Val Acc=0.6668, Val Loss=1.4847, lr=0.0001
[2025-05-03 00:26:24,928][train][INFO] - Epoch 124/140, Val Acc=0.6684, Val Loss=1.4860, lr=0.0001
[2025-05-03 00:26:33,324][train][INFO] - Epoch 125/140, Val Acc=0.6668, Val Loss=1.4913, lr=0.0001
[2025-05-03 00:26:41,945][train][INFO] - Epoch 126/140, Val Acc=0.6647, Val Loss=1.4881, lr=0.0001
[2025-05-03 00:26:50,230][train][INFO] - Epoch 127/140, Val Acc=0.6657, Val Loss=1.4943, lr=0.0001
[2025-05-03 00:26:58,351][train][INFO] - Epoch 128/140, Val Acc=0.6636, Val Loss=1.4893, lr=0.0001
[2025-05-03 00:27:06,293][train][INFO] - Epoch 129/140, Val Acc=0.6665, Val Loss=1.4953, lr=0.0001
[2025-05-03 00:27:14,217][train][INFO] - Epoch 130/140, Val Acc=0.6705, Val Loss=1.4942, lr=0.0001
[2025-05-03 00:27:22,912][train][INFO] - Epoch 131/140, Val Acc=0.6678, Val Loss=1.4995, lr=0.0001
[2025-05-03 00:27:30,803][train][INFO] - Epoch 132/140, Val Acc=0.6691, Val Loss=1.5002, lr=0.0001
[2025-05-03 00:27:38,798][train][INFO] - Epoch 133/140, Val Acc=0.6698, Val Loss=1.5013, lr=0.0001
[2025-05-03 00:27:46,920][train][INFO] - Epoch 134/140, Val Acc=0.6682, Val Loss=1.5010, lr=0.0001
[2025-05-03 00:27:55,139][train][INFO] - Epoch 135/140, Val Acc=0.6685, Val Loss=1.5039, lr=0.0001
[2025-05-03 00:28:02,949][train][INFO] - Epoch 136/140, Val Acc=0.6685, Val Loss=1.5026, lr=0.0001
[2025-05-03 00:28:11,066][train][INFO] - Epoch 137/140, Val Acc=0.6677, Val Loss=1.5007, lr=0.0001
[2025-05-03 00:28:19,022][train][INFO] - Epoch 138/140, Val Acc=0.6679, Val Loss=1.5011, lr=0.0001
[2025-05-03 00:28:27,530][train][INFO] - Epoch 139/140, Val Acc=0.6671, Val Loss=1.5025, lr=0.0001
[2025-05-03 00:28:36,354][train][INFO] - Epoch 140/140, Val Acc=0.6675, Val Loss=1.5058, lr=0.0001
[2025-05-03 00:28:41,490][train][INFO] - After training : Train Acc=0.9306  Val Acc=0.6708
[2025-05-03 00:28:41,562][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(39, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(84, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(250, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(52, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(38, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(256, 464, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(464, 354, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(354, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(354, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(51, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(5, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(8, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(41, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(62, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=135, out_features=100, bias=True)
)
[2025-05-03 00:28:41,562][Pruning][INFO] - Origin val acc : 0.7263999581336975 Final val acc : 0.670799970626831
                      Speed up: 1.50   Final speed up: 4.52
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 14, in <module>
    import torch_geometric
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/__init__.py", line 6, in <module>
    import torch_geometric.datasets
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/datasets/__init__.py", line 76, in <module>
    from .sbm_dataset import StochasticBlockModelDataset
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/datasets/sbm_dataset.py", line 118, in <module>
    class RandomPartitionGraphDataset(StochasticBlockModelDataset):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/abc.py", line 106, in __new__
    cls = super().__new__(mcls, name, bases, namespace, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/typing.py", line 1007, in __init_subclass__
    def __init_subclass__(cls, *args, **kwargs):
KeyboardInterrupt
[2025-05-03 12:17:11,138][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 12:17:11,224][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 12:17:11,224][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 12:17:11,224][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 90, in main
    metanetwork = meta_train(metanetwork, model_train_loader, big_train_loader, small_train_loader, cfg.meta_train, log=log,
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 189, in meta_train
    onetrainstep()
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 150, in onetrainstep
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 230, in forward
    out = scatter(x, index, 0, dim_size, reduce=reduce)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 732.00 MiB (GPU 0; 23.65 GiB total capacity; 22.27 GiB already allocated; 561.62 MiB free; 22.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-03 12:18:30,170][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 48
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 12:18:30,220][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 12:18:30,220][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 12:18:30,220][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 12:19:07,262][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.7785, lr=0.001
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 90, in main
    metanetwork = meta_train(metanetwork, model_train_loader, big_train_loader, small_train_loader, cfg.meta_train, log=log,
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 189, in meta_train
    onetrainstep()
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 150, in onetrainstep
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 47, in forward
    ret_node1, ret_edge1 = self.convs[i].forward(self.norm(hidden), edge_index, edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 23.65 GiB total capacity; 16.21 GiB already allocated; 547.62 MiB free; 22.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-03 12:19:35,080][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 12:19:35,130][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 12:19:35,130][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 12:19:35,130][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 12:20:07,363][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.1667, lr=0.001
[2025-05-03 12:20:34,400][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0139, lr=0.001
[2025-05-03 12:21:01,882][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=0.0210, lr=0.001
[2025-05-03 12:21:27,964][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=0.1583, lr=0.001
[2025-05-03 12:21:54,818][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.6060, lr=0.001
[2025-05-03 12:22:21,944][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=1.2982, lr=0.001
[2025-05-03 12:22:48,622][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=1.8115, lr=0.001
[2025-05-03 12:23:16,078][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=1.3921, lr=0.001
[2025-05-03 12:23:16,103][meta_train][INFO] - epoch_1 saved !
[2025-05-03 12:23:43,303][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.6723, lr=0.001
[2025-05-03 12:24:10,016][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.4667, lr=0.001
[2025-05-03 12:24:37,483][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.2690, lr=0.001
[2025-05-03 12:24:51,563][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 1

[2025-05-03 12:24:51,639][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 12:24:51,639][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 12:24:51,639][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 12:25:04,445][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.1658, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 12:25:11,000][train][INFO] - Before training : Train Acc=0.8469  Val Acc=0.5935
[2025-05-03 12:25:18,933][train][INFO] - Epoch 1/100, Val Acc=0.6441, Val Loss=1.7113, lr=0.0100
[2025-05-03 12:25:26,396][train][INFO] - Epoch 2/100, Val Acc=0.6432, Val Loss=1.6717, lr=0.0100
[2025-05-03 12:25:32,612][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.1281, lr=0.001
[2025-05-03 12:25:34,124][train][INFO] - Epoch 3/100, Val Acc=0.6397, Val Loss=1.6895, lr=0.0100
[2025-05-03 12:25:41,860][train][INFO] - Epoch 4/100, Val Acc=0.6540, Val Loss=1.5968, lr=0.0100
[2025-05-03 12:25:49,475][train][INFO] - Epoch 5/100, Val Acc=0.6538, Val Loss=1.6270, lr=0.0100
[2025-05-03 12:25:56,497][train][INFO] - Epoch 6/100, Val Acc=0.6648, Val Loss=1.5907, lr=0.0100
[2025-05-03 12:25:59,153][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.1605, lr=0.001
[2025-05-03 12:26:04,528][train][INFO] - Epoch 7/100, Val Acc=0.6602, Val Loss=1.5705, lr=0.0100
[2025-05-03 12:26:11,618][train][INFO] - Epoch 8/100, Val Acc=0.6631, Val Loss=1.5933, lr=0.0100
[2025-05-03 12:26:19,749][train][INFO] - Epoch 9/100, Val Acc=0.6602, Val Loss=1.6165, lr=0.0100
[2025-05-03 12:26:27,069][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.2213, lr=0.001
[2025-05-03 12:26:27,306][train][INFO] - Epoch 10/100, Val Acc=0.6657, Val Loss=1.6318, lr=0.0100
[2025-05-03 12:26:34,819][train][INFO] - Epoch 11/100, Val Acc=0.6665, Val Loss=1.5989, lr=0.0100
[2025-05-03 12:26:43,191][train][INFO] - Epoch 12/100, Val Acc=0.6430, Val Loss=1.7243, lr=0.0100
[2025-05-03 12:26:51,548][train][INFO] - Epoch 13/100, Val Acc=0.6534, Val Loss=1.6935, lr=0.0100
[2025-05-03 12:26:55,131][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.5584, lr=0.001
[2025-05-03 12:26:55,154][meta_train][INFO] - epoch_2 saved !
[2025-05-03 12:26:59,117][train][INFO] - Epoch 14/100, Val Acc=0.6615, Val Loss=1.6014, lr=0.0100
[2025-05-03 12:27:06,557][train][INFO] - Epoch 15/100, Val Acc=0.6706, Val Loss=1.5813, lr=0.0100
[2025-05-03 12:27:14,290][train][INFO] - Epoch 16/100, Val Acc=0.6571, Val Loss=1.6195, lr=0.0100
[2025-05-03 12:27:21,372][train][INFO] - Epoch 17/100, Val Acc=0.6618, Val Loss=1.5816, lr=0.0100
[2025-05-03 12:27:21,568][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.9923, lr=0.001
[2025-05-03 12:27:28,543][train][INFO] - Epoch 18/100, Val Acc=0.6678, Val Loss=1.5768, lr=0.0100
[2025-05-03 12:27:36,635][train][INFO] - Epoch 19/100, Val Acc=0.6579, Val Loss=1.6203, lr=0.0100
[2025-05-03 12:27:44,365][train][INFO] - Epoch 20/100, Val Acc=0.6541, Val Loss=1.6287, lr=0.0100
[2025-05-03 12:27:48,864][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=1.3833, lr=0.001
[2025-05-03 12:27:52,266][train][INFO] - Epoch 21/100, Val Acc=0.6623, Val Loss=1.5981, lr=0.0100
[2025-05-03 12:27:59,911][train][INFO] - Epoch 22/100, Val Acc=0.6580, Val Loss=1.6743, lr=0.0100
[2025-05-03 12:28:07,341][train][INFO] - Epoch 23/100, Val Acc=0.6638, Val Loss=1.6256, lr=0.0100
[2025-05-03 12:28:15,388][train][INFO] - Epoch 24/100, Val Acc=0.6668, Val Loss=1.5819, lr=0.0100
[2025-05-03 12:28:16,871][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=1.9676, lr=0.001
[2025-05-03 12:28:22,817][train][INFO] - Epoch 25/100, Val Acc=0.6615, Val Loss=1.6109, lr=0.0100
[2025-05-03 12:28:30,816][train][INFO] - Epoch 26/100, Val Acc=0.6563, Val Loss=1.6334, lr=0.0100
[2025-05-03 12:28:38,750][train][INFO] - Epoch 27/100, Val Acc=0.6622, Val Loss=1.6552, lr=0.0100
[2025-05-03 12:28:44,197][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=2.6425, lr=0.001
[2025-05-03 12:28:46,627][train][INFO] - Epoch 28/100, Val Acc=0.6771, Val Loss=1.5372, lr=0.0100
[2025-05-03 12:28:54,174][train][INFO] - Epoch 29/100, Val Acc=0.6616, Val Loss=1.5988, lr=0.0100
[2025-05-03 12:29:02,268][train][INFO] - Epoch 30/100, Val Acc=0.6793, Val Loss=1.5269, lr=0.0100
[2025-05-03 12:29:10,117][train][INFO] - Epoch 31/100, Val Acc=0.6577, Val Loss=1.6382, lr=0.0100
[2025-05-03 12:29:12,440][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=1.7414, lr=0.001
[2025-05-03 12:29:18,086][train][INFO] - Epoch 32/100, Val Acc=0.6569, Val Loss=1.6338, lr=0.0100
[2025-05-03 12:29:25,923][train][INFO] - Epoch 33/100, Val Acc=0.6737, Val Loss=1.5537, lr=0.0100
[2025-05-03 12:29:33,632][train][INFO] - Epoch 34/100, Val Acc=0.6692, Val Loss=1.6214, lr=0.0100
[2025-05-03 12:29:39,848][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=2.6572, lr=0.001
[2025-05-03 12:29:41,016][train][INFO] - Epoch 35/100, Val Acc=0.6639, Val Loss=1.5848, lr=0.0100
[2025-05-03 12:29:48,469][train][INFO] - Epoch 36/100, Val Acc=0.6690, Val Loss=1.5402, lr=0.0100
[2025-05-03 12:29:56,250][train][INFO] - Epoch 37/100, Val Acc=0.6546, Val Loss=1.6490, lr=0.0100
[2025-05-03 12:30:04,358][train][INFO] - Epoch 38/100, Val Acc=0.6637, Val Loss=1.6125, lr=0.0100
[2025-05-03 12:30:07,223][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=3.1153, lr=0.001
[2025-05-03 12:30:12,336][train][INFO] - Epoch 39/100, Val Acc=0.6644, Val Loss=1.6207, lr=0.0100
[2025-05-03 12:30:19,594][train][INFO] - Epoch 40/100, Val Acc=0.6623, Val Loss=1.6249, lr=0.0100
[2025-05-03 12:30:28,270][train][INFO] - Epoch 41/100, Val Acc=0.6542, Val Loss=1.6901, lr=0.0100
[2025-05-03 12:30:35,638][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.3983, lr=0.001
[2025-05-03 12:30:35,654][meta_train][INFO] - epoch_3 saved !
[2025-05-03 12:30:35,854][train][INFO] - Epoch 42/100, Val Acc=0.6541, Val Loss=1.7268, lr=0.0100
[2025-05-03 12:30:43,463][train][INFO] - Epoch 43/100, Val Acc=0.6622, Val Loss=1.6390, lr=0.0100
[2025-05-03 12:30:51,477][train][INFO] - Epoch 44/100, Val Acc=0.6613, Val Loss=1.6359, lr=0.0100
[2025-05-03 12:30:59,450][train][INFO] - Epoch 45/100, Val Acc=0.6617, Val Loss=1.6497, lr=0.0100
[2025-05-03 12:31:02,475][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.2166, lr=0.001
[2025-05-03 12:31:07,071][train][INFO] - Epoch 46/100, Val Acc=0.6611, Val Loss=1.6782, lr=0.0100
[2025-05-03 12:31:14,752][train][INFO] - Epoch 47/100, Val Acc=0.6648, Val Loss=1.5992, lr=0.0100
[2025-05-03 12:31:22,715][train][INFO] - Epoch 48/100, Val Acc=0.6566, Val Loss=1.6474, lr=0.0100
[2025-05-03 12:31:30,494][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.7794, lr=0.001
[2025-05-03 12:31:30,706][train][INFO] - Epoch 49/100, Val Acc=0.6693, Val Loss=1.5810, lr=0.0100
[2025-05-03 12:31:39,339][train][INFO] - Epoch 50/100, Val Acc=0.6693, Val Loss=1.5854, lr=0.0100
[2025-05-03 12:31:47,481][train][INFO] - Epoch 51/100, Val Acc=0.6590, Val Loss=1.6810, lr=0.0100
[2025-05-03 12:31:55,163][train][INFO] - Epoch 52/100, Val Acc=0.6760, Val Loss=1.5411, lr=0.0100
[2025-05-03 12:31:57,309][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.3844, lr=0.001
[2025-05-03 12:32:03,235][train][INFO] - Epoch 53/100, Val Acc=0.6736, Val Loss=1.5511, lr=0.0100
[2025-05-03 12:32:11,484][train][INFO] - Epoch 54/100, Val Acc=0.6665, Val Loss=1.6238, lr=0.0100
[2025-05-03 12:32:18,769][train][INFO] - Epoch 55/100, Val Acc=0.6668, Val Loss=1.6217, lr=0.0100
[2025-05-03 12:32:25,322][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.6649, lr=0.001
[2025-05-03 12:32:26,417][train][INFO] - Epoch 56/100, Val Acc=0.6668, Val Loss=1.6098, lr=0.0100
[2025-05-03 12:32:34,745][train][INFO] - Epoch 57/100, Val Acc=0.6616, Val Loss=1.6165, lr=0.0100
[2025-05-03 12:32:43,227][train][INFO] - Epoch 58/100, Val Acc=0.6519, Val Loss=1.6844, lr=0.0100
[2025-05-03 12:32:51,695][train][INFO] - Epoch 59/100, Val Acc=0.6568, Val Loss=1.6833, lr=0.0100
[2025-05-03 12:32:53,243][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.8475, lr=0.001
[2025-05-03 12:32:59,925][train][INFO] - Epoch 60/100, Val Acc=0.6688, Val Loss=1.5942, lr=0.0100
[2025-05-03 12:33:07,792][train][INFO] - Epoch 61/100, Val Acc=0.7238, Val Loss=1.3286, lr=0.0010
[2025-05-03 12:33:14,869][train][INFO] - Epoch 62/100, Val Acc=0.7258, Val Loss=1.3305, lr=0.0010
[2025-05-03 12:33:20,189][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=1.3174, lr=0.001
[2025-05-03 12:33:23,290][train][INFO] - Epoch 63/100, Val Acc=0.7308, Val Loss=1.3316, lr=0.0010
[2025-05-03 12:33:31,676][train][INFO] - Epoch 64/100, Val Acc=0.7291, Val Loss=1.3387, lr=0.0010
[2025-05-03 12:33:39,658][train][INFO] - Epoch 65/100, Val Acc=0.7334, Val Loss=1.3410, lr=0.0010
[2025-05-03 12:33:47,485][train][INFO] - Epoch 66/100, Val Acc=0.7328, Val Loss=1.3385, lr=0.0010
[2025-05-03 12:33:47,675][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=1.9756, lr=0.001
[2025-05-03 12:33:55,864][train][INFO] - Epoch 67/100, Val Acc=0.7350, Val Loss=1.3415, lr=0.0010
[2025-05-03 12:34:03,464][train][INFO] - Epoch 68/100, Val Acc=0.7329, Val Loss=1.3393, lr=0.0010
[2025-05-03 12:34:10,733][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.3508, lr=0.0010
[2025-05-03 12:34:15,647][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=2.3198, lr=0.001
[2025-05-03 12:34:15,663][meta_train][INFO] - epoch_4 saved !
[2025-05-03 12:34:18,841][train][INFO] - Epoch 70/100, Val Acc=0.7316, Val Loss=1.3609, lr=0.0010
[2025-05-03 12:34:26,938][train][INFO] - Epoch 71/100, Val Acc=0.7330, Val Loss=1.3547, lr=0.0010
[2025-05-03 12:34:34,856][train][INFO] - Epoch 72/100, Val Acc=0.7345, Val Loss=1.3538, lr=0.0010
[2025-05-03 12:34:42,641][train][INFO] - Epoch 73/100, Val Acc=0.7324, Val Loss=1.3534, lr=0.0010
[2025-05-03 12:34:43,425][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=2.5160, lr=0.001
[2025-05-03 12:34:49,300][train][INFO] - Epoch 74/100, Val Acc=0.7358, Val Loss=1.3499, lr=0.0010
[2025-05-03 12:34:56,931][train][INFO] - Epoch 75/100, Val Acc=0.7356, Val Loss=1.3600, lr=0.0010
[2025-05-03 12:35:03,810][train][INFO] - Epoch 76/100, Val Acc=0.7341, Val Loss=1.3623, lr=0.0010
[2025-05-03 12:35:10,985][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.6670, lr=0.001
[2025-05-03 12:35:11,386][train][INFO] - Epoch 77/100, Val Acc=0.7348, Val Loss=1.3643, lr=0.0010
[2025-05-03 12:35:19,390][train][INFO] - Epoch 78/100, Val Acc=0.7356, Val Loss=1.3631, lr=0.0010
[2025-05-03 12:35:27,356][train][INFO] - Epoch 79/100, Val Acc=0.7357, Val Loss=1.3637, lr=0.0010
[2025-05-03 12:35:35,067][train][INFO] - Epoch 80/100, Val Acc=0.7342, Val Loss=1.3605, lr=0.0010
[2025-05-03 12:35:39,111][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=3.5625, lr=0.001
[2025-05-03 12:35:42,658][train][INFO] - Epoch 81/100, Val Acc=0.7353, Val Loss=1.3578, lr=0.0010
[2025-05-03 12:35:50,313][train][INFO] - Epoch 82/100, Val Acc=0.7347, Val Loss=1.3575, lr=0.0010
[2025-05-03 12:35:58,702][train][INFO] - Epoch 83/100, Val Acc=0.7383, Val Loss=1.3588, lr=0.0010
[2025-05-03 12:36:06,549][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=4.3347, lr=0.001
[2025-05-03 12:36:06,782][train][INFO] - Epoch 84/100, Val Acc=0.7354, Val Loss=1.3608, lr=0.0010
[2025-05-03 12:36:15,009][train][INFO] - Epoch 85/100, Val Acc=0.7346, Val Loss=1.3566, lr=0.0010
[2025-05-03 12:36:22,634][train][INFO] - Epoch 86/100, Val Acc=0.7355, Val Loss=1.3592, lr=0.0010
[2025-05-03 12:36:30,473][train][INFO] - Epoch 87/100, Val Acc=0.7331, Val Loss=1.3541, lr=0.0010
[2025-05-03 12:36:34,178][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=4.6479, lr=0.001
[2025-05-03 12:36:38,957][train][INFO] - Epoch 88/100, Val Acc=0.7353, Val Loss=1.3581, lr=0.0010
[2025-05-03 12:36:47,237][train][INFO] - Epoch 89/100, Val Acc=0.7349, Val Loss=1.3518, lr=0.0010
[2025-05-03 12:36:55,660][train][INFO] - Epoch 90/100, Val Acc=0.7367, Val Loss=1.3642, lr=0.0010
[2025-05-03 12:37:01,878][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=4.7402, lr=0.001
[2025-05-03 12:37:03,363][train][INFO] - Epoch 91/100, Val Acc=0.7359, Val Loss=1.3576, lr=0.0001
[2025-05-03 12:37:11,908][train][INFO] - Epoch 92/100, Val Acc=0.7368, Val Loss=1.3590, lr=0.0001
[2025-05-03 12:37:20,264][train][INFO] - Epoch 93/100, Val Acc=0.7363, Val Loss=1.3576, lr=0.0001
[2025-05-03 12:37:27,923][train][INFO] - Epoch 94/100, Val Acc=0.7375, Val Loss=1.3563, lr=0.0001
[2025-05-03 12:37:28,720][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9025, lr=0.001
[2025-05-03 12:37:35,979][train][INFO] - Epoch 95/100, Val Acc=0.7351, Val Loss=1.3632, lr=0.0001
[2025-05-03 12:37:43,701][train][INFO] - Epoch 96/100, Val Acc=0.7352, Val Loss=1.3540, lr=0.0001
[2025-05-03 12:37:51,875][train][INFO] - Epoch 97/100, Val Acc=0.7345, Val Loss=1.3545, lr=0.0001
[2025-05-03 12:37:56,422][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.8421, lr=0.001
[2025-05-03 12:37:56,447][meta_train][INFO] - epoch_5 saved !
[2025-05-03 12:37:59,422][train][INFO] - Epoch 98/100, Val Acc=0.7365, Val Loss=1.3568, lr=0.0001
[2025-05-03 12:38:07,456][train][INFO] - Epoch 99/100, Val Acc=0.7338, Val Loss=1.3551, lr=0.0001
[2025-05-03 12:38:15,663][train][INFO] - Epoch 100/100, Val Acc=0.7359, Val Loss=1.3556, lr=0.0001
[2025-05-03 12:38:20,558][train][INFO] - After training : Train Acc=0.9990  Val Acc=0.7383
[2025-05-03 12:38:20,563][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 12:38:25,005][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=4.7108, lr=0.0001
[2025-05-03 12:38:52,686][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=4.7874, lr=0.0001
[2025-05-03 12:39:19,645][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.8318, lr=0.0001
[2025-05-03 12:39:47,398][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=4.7555, lr=0.0001
[2025-05-03 12:40:02,149][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 12:40:15,365][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=4.7096, lr=0.0001
[2025-05-03 12:40:44,343][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=4.7522, lr=0.0001
[2025-05-03 12:41:13,274][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=4.8811, lr=0.0001
[2025-05-03 12:41:40,866][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=4.8535, lr=0.0001
[2025-05-03 12:41:40,888][meta_train][INFO] - epoch_6 saved !
[2025-05-03 12:41:42,057][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 12:41:42,493][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 12:42:08,240][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.7482, lr=0.0001
[2025-05-03 12:42:35,903][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=4.7019, lr=0.0001
[2025-05-03 12:43:02,927][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=4.8554, lr=0.0001
[2025-05-03 12:43:28,875][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7924, lr=0.0001
[2025-05-03 12:43:56,460][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=4.8831, lr=0.0001
[2025-05-03 12:44:23,220][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=4.8031, lr=0.0001
[2025-05-03 12:44:50,401][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=4.7186, lr=0.0001
[2025-05-03 12:45:16,738][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=4.7488, lr=0.0001
[2025-05-03 12:45:16,753][meta_train][INFO] - epoch_7 saved !
[2025-05-03 12:45:43,520][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=4.7191, lr=0.0001
[2025-05-03 12:46:11,059][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=4.7463, lr=0.0001
[2025-05-03 12:46:39,109][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.8831, lr=0.0001
[2025-05-03 12:47:05,572][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.7404, lr=0.0001
[2025-05-03 12:47:33,373][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=4.8633, lr=0.0001
[2025-05-03 12:48:00,716][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=4.8054, lr=0.0001
[2025-05-03 12:48:26,185][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7480, lr=0.0001
[2025-05-03 12:48:53,510][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=4.6858, lr=0.0001
[2025-05-03 12:48:53,537][meta_train][INFO] - epoch_8 saved !
[2025-05-03 12:49:20,208][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=4.8033, lr=0.0001
[2025-05-03 12:49:46,894][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=4.7015, lr=0.0001
[2025-05-03 12:50:14,452][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=4.8656, lr=0.0001
[2025-05-03 12:50:39,641][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.6808, lr=0.0001
[2025-05-03 12:51:06,544][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.6728, lr=0.0001
[2025-05-03 12:51:33,732][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=4.6443, lr=0.0001
[2025-05-03 12:52:01,368][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=4.6712, lr=0.0001
[2025-05-03 12:52:28,176][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.8925, lr=0.0001
[2025-05-03 12:52:28,191][meta_train][INFO] - epoch_9 saved !
[2025-05-03 12:52:55,573][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=4.7944, lr=0.0001
[2025-05-03 12:53:22,633][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=4.8527, lr=0.0001
[2025-05-03 12:53:48,882][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.8910, lr=0.0001
[2025-05-03 12:54:16,317][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=4.6371, lr=0.0001
[2025-05-03 12:54:43,496][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=4.6929, lr=0.0001
[2025-05-03 12:55:09,238][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.6591, lr=0.0001
[2025-05-03 12:55:36,846][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=4.6868, lr=0.0001
[2025-05-03 12:56:03,502][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.6633, lr=0.0001
[2025-05-03 12:56:03,522][meta_train][INFO] - epoch_10 saved !
[2025-05-03 12:56:30,781][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=4.7015, lr=0.0001
[2025-05-03 12:56:57,638][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.6681, lr=0.0001
[2025-05-03 12:57:25,325][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=4.8557, lr=0.0001
[2025-05-03 12:57:52,150][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=4.7068, lr=0.0001
[2025-05-03 12:58:19,181][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=4.6667, lr=0.0001
[2025-05-03 12:58:45,278][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6950, lr=0.0001
[2025-05-03 12:59:13,045][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.8998, lr=0.0001
[2025-05-03 12:59:39,931][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=4.7942, lr=0.0001
[2025-05-03 12:59:39,946][meta_train][INFO] - epoch_11 saved !
[2025-05-03 13:00:06,865][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=4.7200, lr=0.0001
[2025-05-03 13:00:34,395][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=4.8592, lr=0.0001
[2025-05-03 13:01:00,973][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=4.7291, lr=0.0001
[2025-05-03 13:01:28,070][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.6951, lr=0.0001
[2025-05-03 13:01:54,383][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.7279, lr=0.0001
[2025-05-03 13:02:21,833][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.8943, lr=0.0001
[2025-05-03 13:02:49,135][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=4.6973, lr=0.0001
[2025-05-03 13:03:16,099][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=4.7858, lr=0.0001
[2025-05-03 13:03:16,123][meta_train][INFO] - epoch_12 saved !
[2025-05-03 13:03:42,619][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=4.7254, lr=0.0001
[2025-05-03 13:04:09,390][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=4.7037, lr=0.0001
[2025-05-03 13:04:37,106][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=4.7821, lr=0.0001
[2025-05-03 13:05:04,538][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.8835, lr=0.0001
[2025-05-03 13:05:31,184][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.7089, lr=0.0001
[2025-05-03 13:05:58,404][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=4.7565, lr=0.0001
[2025-05-03 13:06:24,530][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.7601, lr=0.0001
[2025-05-03 13:06:51,770][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=4.8459, lr=0.0001
[2025-05-03 13:06:51,786][meta_train][INFO] - epoch_13 saved !
[2025-05-03 13:07:18,742][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.7759, lr=0.0001
[2025-05-03 13:07:46,636][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.8788, lr=0.0001
[2025-05-03 13:08:13,083][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.7125, lr=0.0001
[2025-05-03 13:08:39,514][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.7648, lr=0.0001
[2025-05-03 13:09:06,992][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.7181, lr=0.0001
[2025-05-03 13:09:34,385][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.7653, lr=0.0001
[2025-05-03 13:10:01,136][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=4.7316, lr=0.0001
[2025-05-03 13:10:28,880][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.8400, lr=0.0001
[2025-05-03 13:10:28,904][meta_train][INFO] - epoch_14 saved !
[2025-05-03 13:10:56,419][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.7198, lr=0.0001
[2025-05-03 13:11:22,259][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.7653, lr=0.0001
[2025-05-03 13:11:48,801][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=4.7326, lr=0.0001
[2025-05-03 13:11:50,393][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-03 13:11:50,461][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 13:11:50,461][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 13:11:50,461][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 13:12:09,552][train][INFO] - Before training : Train Acc=0.0201  Val Acc=0.0219
[2025-05-03 13:12:16,462][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.7109, lr=0.0001
[2025-05-03 13:12:17,167][train][INFO] - Epoch 1/100, Val Acc=0.6073, Val Loss=1.6816, lr=0.0100
[2025-05-03 13:12:24,323][train][INFO] - Epoch 2/100, Val Acc=0.6368, Val Loss=1.5502, lr=0.0100
[2025-05-03 13:12:31,924][train][INFO] - Epoch 3/100, Val Acc=0.6216, Val Loss=1.6692, lr=0.0100
[2025-05-03 13:12:39,879][train][INFO] - Epoch 4/100, Val Acc=0.6534, Val Loss=1.5207, lr=0.0100
[2025-05-03 13:12:44,422][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.7703, lr=0.0001
[2025-05-03 13:12:47,662][train][INFO] - Epoch 5/100, Val Acc=0.6532, Val Loss=1.5414, lr=0.0100
[2025-05-03 13:12:55,560][train][INFO] - Epoch 6/100, Val Acc=0.6510, Val Loss=1.5741, lr=0.0100
[2025-05-03 13:13:03,484][train][INFO] - Epoch 7/100, Val Acc=0.6535, Val Loss=1.5925, lr=0.0100
[2025-05-03 13:13:11,089][train][INFO] - Epoch 8/100, Val Acc=0.6540, Val Loss=1.5358, lr=0.0100
[2025-05-03 13:13:12,388][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.8753, lr=0.0001
[2025-05-03 13:13:19,234][train][INFO] - Epoch 9/100, Val Acc=0.6614, Val Loss=1.5292, lr=0.0100
[2025-05-03 13:13:27,275][train][INFO] - Epoch 10/100, Val Acc=0.6493, Val Loss=1.5673, lr=0.0100
[2025-05-03 13:13:35,224][train][INFO] - Epoch 11/100, Val Acc=0.6711, Val Loss=1.4955, lr=0.0100
[2025-05-03 13:13:39,521][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.7652, lr=0.0001
[2025-05-03 13:13:43,419][train][INFO] - Epoch 12/100, Val Acc=0.6689, Val Loss=1.5152, lr=0.0100
[2025-05-03 13:13:50,905][train][INFO] - Epoch 13/100, Val Acc=0.6661, Val Loss=1.5764, lr=0.0100
[2025-05-03 13:13:59,174][train][INFO] - Epoch 14/100, Val Acc=0.6538, Val Loss=1.6397, lr=0.0100
[2025-05-03 13:14:07,375][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.8314, lr=0.0001
[2025-05-03 13:14:07,385][train][INFO] - Epoch 15/100, Val Acc=0.6610, Val Loss=1.6200, lr=0.0100
[2025-05-03 13:14:07,402][meta_train][INFO] - epoch_15 saved !
[2025-05-03 13:14:14,950][train][INFO] - Epoch 16/100, Val Acc=0.6263, Val Loss=1.7780, lr=0.0100
[2025-05-03 13:14:22,658][train][INFO] - Epoch 17/100, Val Acc=0.6565, Val Loss=1.5840, lr=0.0100
[2025-05-03 13:14:30,456][train][INFO] - Epoch 18/100, Val Acc=0.6737, Val Loss=1.5479, lr=0.0100
[2025-05-03 13:14:35,441][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.7279, lr=0.0001
[2025-05-03 13:14:38,825][train][INFO] - Epoch 19/100, Val Acc=0.6733, Val Loss=1.5543, lr=0.0100
[2025-05-03 13:14:46,912][train][INFO] - Epoch 20/100, Val Acc=0.6629, Val Loss=1.5616, lr=0.0100
[2025-05-03 13:14:55,080][train][INFO] - Epoch 21/100, Val Acc=0.6742, Val Loss=1.5229, lr=0.0100
[2025-05-03 13:15:02,865][train][INFO] - Epoch 22/100, Val Acc=0.6415, Val Loss=1.7293, lr=0.0100
[2025-05-03 13:15:03,291][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.8660, lr=0.0001
[2025-05-03 13:15:10,908][train][INFO] - Epoch 23/100, Val Acc=0.6668, Val Loss=1.5796, lr=0.0100
[2025-05-03 13:15:19,325][train][INFO] - Epoch 24/100, Val Acc=0.6712, Val Loss=1.5593, lr=0.0100
[2025-05-03 13:15:26,774][train][INFO] - Epoch 25/100, Val Acc=0.6583, Val Loss=1.6462, lr=0.0100
[2025-05-03 13:15:31,085][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.7603, lr=0.0001
[2025-05-03 13:15:34,981][train][INFO] - Epoch 26/100, Val Acc=0.6610, Val Loss=1.6032, lr=0.0100
[2025-05-03 13:15:42,178][train][INFO] - Epoch 27/100, Val Acc=0.6787, Val Loss=1.5131, lr=0.0100
[2025-05-03 13:15:49,644][train][INFO] - Epoch 28/100, Val Acc=0.6687, Val Loss=1.5661, lr=0.0100
[2025-05-03 13:15:56,538][train][INFO] - Epoch 29/100, Val Acc=0.6695, Val Loss=1.5507, lr=0.0100
[2025-05-03 13:15:58,895][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.8256, lr=0.0001
[2025-05-03 13:16:04,649][train][INFO] - Epoch 30/100, Val Acc=0.6594, Val Loss=1.6386, lr=0.0100
[2025-05-03 13:16:12,288][train][INFO] - Epoch 31/100, Val Acc=0.6744, Val Loss=1.5355, lr=0.0100
[2025-05-03 13:16:20,209][train][INFO] - Epoch 32/100, Val Acc=0.6592, Val Loss=1.6367, lr=0.0100
[2025-05-03 13:16:26,785][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=4.7346, lr=0.0001
[2025-05-03 13:16:27,534][train][INFO] - Epoch 33/100, Val Acc=0.6620, Val Loss=1.6131, lr=0.0100
[2025-05-03 13:16:35,219][train][INFO] - Epoch 34/100, Val Acc=0.6747, Val Loss=1.5514, lr=0.0100
[2025-05-03 13:16:43,235][train][INFO] - Epoch 35/100, Val Acc=0.6558, Val Loss=1.6731, lr=0.0100
[2025-05-03 13:16:50,147][train][INFO] - Epoch 36/100, Val Acc=0.6526, Val Loss=1.6594, lr=0.0100
[2025-05-03 13:16:54,366][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.7225, lr=0.0001
[2025-05-03 13:16:58,171][train][INFO] - Epoch 37/100, Val Acc=0.6608, Val Loss=1.6149, lr=0.0100
[2025-05-03 13:17:05,243][train][INFO] - Epoch 38/100, Val Acc=0.6632, Val Loss=1.6206, lr=0.0100
[2025-05-03 13:17:13,060][train][INFO] - Epoch 39/100, Val Acc=0.6515, Val Loss=1.6853, lr=0.0100
[2025-05-03 13:17:21,095][train][INFO] - Epoch 40/100, Val Acc=0.6639, Val Loss=1.6261, lr=0.0100
[2025-05-03 13:17:22,421][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.7895, lr=0.0001
[2025-05-03 13:17:29,242][train][INFO] - Epoch 41/100, Val Acc=0.6760, Val Loss=1.5429, lr=0.0100
[2025-05-03 13:17:37,372][train][INFO] - Epoch 42/100, Val Acc=0.6717, Val Loss=1.5568, lr=0.0100
[2025-05-03 13:17:45,450][train][INFO] - Epoch 43/100, Val Acc=0.6686, Val Loss=1.6156, lr=0.0100
[2025-05-03 13:17:48,897][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.7905, lr=0.0001
[2025-05-03 13:17:48,925][meta_train][INFO] - epoch_16 saved !
[2025-05-03 13:17:53,580][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.6411, lr=0.0100
[2025-05-03 13:18:01,236][train][INFO] - Epoch 45/100, Val Acc=0.6716, Val Loss=1.5652, lr=0.0100
[2025-05-03 13:18:08,686][train][INFO] - Epoch 46/100, Val Acc=0.6613, Val Loss=1.6681, lr=0.0100
[2025-05-03 13:18:16,281][train][INFO] - Epoch 47/100, Val Acc=0.6561, Val Loss=1.6667, lr=0.0100
[2025-05-03 13:18:16,678][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.7369, lr=0.0001
[2025-05-03 13:18:24,341][train][INFO] - Epoch 48/100, Val Acc=0.6576, Val Loss=1.6122, lr=0.0100
[2025-05-03 13:18:32,421][train][INFO] - Epoch 49/100, Val Acc=0.6556, Val Loss=1.6423, lr=0.0100
[2025-05-03 13:18:40,084][train][INFO] - Epoch 50/100, Val Acc=0.6707, Val Loss=1.5534, lr=0.0100
[2025-05-03 13:18:44,333][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.7217, lr=0.0001
[2025-05-03 13:18:48,281][train][INFO] - Epoch 51/100, Val Acc=0.6711, Val Loss=1.5699, lr=0.0100
[2025-05-03 13:18:56,026][train][INFO] - Epoch 52/100, Val Acc=0.6784, Val Loss=1.5671, lr=0.0100
[2025-05-03 13:19:04,410][train][INFO] - Epoch 53/100, Val Acc=0.6746, Val Loss=1.5666, lr=0.0100
[2025-05-03 13:19:10,626][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.7875, lr=0.0001
[2025-05-03 13:19:12,407][train][INFO] - Epoch 54/100, Val Acc=0.6698, Val Loss=1.5642, lr=0.0100
[2025-05-03 13:19:20,495][train][INFO] - Epoch 55/100, Val Acc=0.6528, Val Loss=1.7079, lr=0.0100
[2025-05-03 13:19:28,685][train][INFO] - Epoch 56/100, Val Acc=0.6683, Val Loss=1.6282, lr=0.0100
[2025-05-03 13:19:36,601][train][INFO] - Epoch 57/100, Val Acc=0.6668, Val Loss=1.6382, lr=0.0100
[2025-05-03 13:19:37,891][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=4.7363, lr=0.0001
[2025-05-03 13:19:45,147][train][INFO] - Epoch 58/100, Val Acc=0.6695, Val Loss=1.6370, lr=0.0100
[2025-05-03 13:19:53,349][train][INFO] - Epoch 59/100, Val Acc=0.6701, Val Loss=1.5641, lr=0.0100
[2025-05-03 13:20:01,025][train][INFO] - Epoch 60/100, Val Acc=0.6694, Val Loss=1.5965, lr=0.0100
[2025-05-03 13:20:05,228][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.7894, lr=0.0001
[2025-05-03 13:20:08,643][train][INFO] - Epoch 61/100, Val Acc=0.7204, Val Loss=1.3408, lr=0.0010
[2025-05-03 13:20:15,944][train][INFO] - Epoch 62/100, Val Acc=0.7229, Val Loss=1.3288, lr=0.0010
[2025-05-03 13:20:23,965][train][INFO] - Epoch 63/100, Val Acc=0.7245, Val Loss=1.3354, lr=0.0010
[2025-05-03 13:20:31,971][train][INFO] - Epoch 64/100, Val Acc=0.7259, Val Loss=1.3433, lr=0.0010
[2025-05-03 13:20:33,793][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.8600, lr=0.0001
[2025-05-03 13:20:39,486][train][INFO] - Epoch 65/100, Val Acc=0.7262, Val Loss=1.3533, lr=0.0010
[2025-05-03 13:20:47,677][train][INFO] - Epoch 66/100, Val Acc=0.7279, Val Loss=1.3617, lr=0.0010
[2025-05-03 13:20:54,945][train][INFO] - Epoch 67/100, Val Acc=0.7304, Val Loss=1.3562, lr=0.0010
[2025-05-03 13:21:00,583][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.7509, lr=0.0001
[2025-05-03 13:21:02,626][train][INFO] - Epoch 68/100, Val Acc=0.7319, Val Loss=1.3474, lr=0.0010
[2025-05-03 13:21:10,882][train][INFO] - Epoch 69/100, Val Acc=0.7311, Val Loss=1.3630, lr=0.0010
[2025-05-03 13:21:18,063][train][INFO] - Epoch 70/100, Val Acc=0.7313, Val Loss=1.3605, lr=0.0010
[2025-05-03 13:21:25,713][train][INFO] - Epoch 71/100, Val Acc=0.7316, Val Loss=1.3654, lr=0.0010
[2025-05-03 13:21:29,034][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.8166, lr=0.0001
[2025-05-03 13:21:29,064][meta_train][INFO] - epoch_17 saved !
[2025-05-03 13:21:34,166][train][INFO] - Epoch 72/100, Val Acc=0.7314, Val Loss=1.3654, lr=0.0010
[2025-05-03 13:21:42,102][train][INFO] - Epoch 73/100, Val Acc=0.7322, Val Loss=1.3625, lr=0.0010
[2025-05-03 13:21:49,964][train][INFO] - Epoch 74/100, Val Acc=0.7331, Val Loss=1.3641, lr=0.0010
[2025-05-03 13:21:56,543][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.8152, lr=0.0001
[2025-05-03 13:21:58,173][train][INFO] - Epoch 75/100, Val Acc=0.7317, Val Loss=1.3646, lr=0.0010
[2025-05-03 13:22:05,729][train][INFO] - Epoch 76/100, Val Acc=0.7309, Val Loss=1.3592, lr=0.0010
[2025-05-03 13:22:13,492][train][INFO] - Epoch 77/100, Val Acc=0.7334, Val Loss=1.3688, lr=0.0010
[2025-05-03 13:22:21,717][train][INFO] - Epoch 78/100, Val Acc=0.7325, Val Loss=1.3655, lr=0.0010
[2025-05-03 13:22:24,097][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.7236, lr=0.0001
[2025-05-03 13:22:30,143][train][INFO] - Epoch 79/100, Val Acc=0.7330, Val Loss=1.3683, lr=0.0010
[2025-05-03 13:22:38,490][train][INFO] - Epoch 80/100, Val Acc=0.7334, Val Loss=1.3613, lr=0.0010
[2025-05-03 13:22:46,305][train][INFO] - Epoch 81/100, Val Acc=0.7329, Val Loss=1.3634, lr=0.0010
[2025-05-03 13:22:52,475][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.8502, lr=0.0001
[2025-05-03 13:22:53,896][train][INFO] - Epoch 82/100, Val Acc=0.7348, Val Loss=1.3618, lr=0.0010
[2025-05-03 13:23:01,531][train][INFO] - Epoch 83/100, Val Acc=0.7343, Val Loss=1.3632, lr=0.0010
[2025-05-03 13:23:09,169][train][INFO] - Epoch 84/100, Val Acc=0.7364, Val Loss=1.3594, lr=0.0010
[2025-05-03 13:23:16,984][train][INFO] - Epoch 85/100, Val Acc=0.7362, Val Loss=1.3562, lr=0.0010
[2025-05-03 13:23:20,386][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.7438, lr=0.0001
[2025-05-03 13:23:25,200][train][INFO] - Epoch 86/100, Val Acc=0.7338, Val Loss=1.3674, lr=0.0010
[2025-05-03 13:23:32,786][train][INFO] - Epoch 87/100, Val Acc=0.7345, Val Loss=1.3651, lr=0.0010
[2025-05-03 13:23:40,693][train][INFO] - Epoch 88/100, Val Acc=0.7349, Val Loss=1.3662, lr=0.0010
[2025-05-03 13:23:47,339][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.7411, lr=0.0001
[2025-05-03 13:23:47,889][train][INFO] - Epoch 89/100, Val Acc=0.7331, Val Loss=1.3606, lr=0.0010
[2025-05-03 13:23:55,695][train][INFO] - Epoch 90/100, Val Acc=0.7310, Val Loss=1.3681, lr=0.0010
[2025-05-03 13:24:03,586][train][INFO] - Epoch 91/100, Val Acc=0.7344, Val Loss=1.3638, lr=0.0001
[2025-05-03 13:24:11,313][train][INFO] - Epoch 92/100, Val Acc=0.7322, Val Loss=1.3663, lr=0.0001
[2025-05-03 13:24:13,903][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.8064, lr=0.0001
[2025-05-03 13:24:19,114][train][INFO] - Epoch 93/100, Val Acc=0.7334, Val Loss=1.3612, lr=0.0001
[2025-05-03 13:24:26,727][train][INFO] - Epoch 94/100, Val Acc=0.7334, Val Loss=1.3590, lr=0.0001
[2025-05-03 13:24:34,659][train][INFO] - Epoch 95/100, Val Acc=0.7331, Val Loss=1.3661, lr=0.0001
[2025-05-03 13:24:41,972][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.8076, lr=0.0001
[2025-05-03 13:24:42,617][train][INFO] - Epoch 96/100, Val Acc=0.7321, Val Loss=1.3608, lr=0.0001
[2025-05-03 13:24:48,916][train][INFO] - Epoch 97/100, Val Acc=0.7328, Val Loss=1.3616, lr=0.0001
[2025-05-03 13:24:57,295][train][INFO] - Epoch 98/100, Val Acc=0.7348, Val Loss=1.3584, lr=0.0001
[2025-05-03 13:25:05,008][train][INFO] - Epoch 99/100, Val Acc=0.7333, Val Loss=1.3596, lr=0.0001
[2025-05-03 13:25:09,738][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.7393, lr=0.0001
[2025-05-03 13:25:09,759][meta_train][INFO] - epoch_18 saved !
[2025-05-03 13:25:13,373][train][INFO] - Epoch 100/100, Val Acc=0.7341, Val Loss=1.3581, lr=0.0001
[2025-05-03 13:25:18,178][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.7364
[2025-05-03 13:25:18,183][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 13:25:37,760][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.8003, lr=0.0001
[2025-05-03 13:26:05,801][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.7466, lr=0.0001
[2025-05-03 13:26:33,770][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.7396, lr=0.0001
[2025-05-03 13:26:57,490][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 13:27:01,280][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.8065, lr=0.0001
[2025-05-03 13:27:29,500][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.7274, lr=0.0001
[2025-05-03 13:27:57,040][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.7336, lr=0.0001
[2025-05-03 13:28:26,009][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.8395, lr=0.0001
[2025-05-03 13:28:37,560][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 13:28:38,012][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 13:28:53,882][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.8104, lr=0.0001
[2025-05-03 13:28:53,903][meta_train][INFO] - epoch_19 saved !
[2025-05-03 13:29:20,407][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.7307, lr=0.0001
[2025-05-03 13:29:47,793][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.8135, lr=0.0001
[2025-05-03 13:30:15,626][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.7485, lr=0.0001
[2025-05-03 13:30:42,904][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.7853, lr=0.0001
[2025-05-03 13:31:08,990][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.8146, lr=0.0001
[2025-05-03 13:31:36,491][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.7319, lr=0.0001
[2025-05-03 13:32:02,569][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.7408, lr=0.0001
[2025-05-03 13:32:30,163][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.8235, lr=0.0001
[2025-05-03 13:32:30,186][meta_train][INFO] - epoch_20 saved !
[2025-05-03 13:32:57,557][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.7411, lr=0.0001
[2025-05-03 13:33:24,981][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.7744, lr=0.0001
[2025-05-03 13:33:52,187][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.8209, lr=0.0001
[2025-05-03 13:34:19,275][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.7303, lr=0.0001
[2025-05-03 13:34:46,485][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.7124, lr=0.0001
[2025-05-03 13:35:12,514][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.8144, lr=0.0001
[2025-05-03 13:35:39,760][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.7474, lr=0.0001
[2025-05-03 13:36:06,733][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.8172, lr=0.0001
[2025-05-03 13:36:06,758][meta_train][INFO] - epoch_21 saved !
[2025-05-03 13:36:34,442][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.8151, lr=0.0001
[2025-05-03 13:37:01,613][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.8229, lr=0.0001
[2025-05-03 13:37:29,276][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.7449, lr=0.0001
[2025-05-03 13:37:34,961][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-03 13:37:35,012][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 13:37:35,012][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 13:37:35,012][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 13:37:54,657][train][INFO] - Before training : Train Acc=0.0112  Val Acc=0.0105
[2025-05-03 13:37:56,015][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.7292, lr=0.0001
[2025-05-03 13:38:03,109][train][INFO] - Epoch 1/100, Val Acc=0.5703, Val Loss=1.8861, lr=0.0100
[2025-05-03 13:38:10,592][train][INFO] - Epoch 2/100, Val Acc=0.6295, Val Loss=1.5339, lr=0.0100
[2025-05-03 13:38:18,377][train][INFO] - Epoch 3/100, Val Acc=0.6279, Val Loss=1.5995, lr=0.0100
[2025-05-03 13:38:22,726][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.8140, lr=0.0001
[2025-05-03 13:38:25,744][train][INFO] - Epoch 4/100, Val Acc=0.6305, Val Loss=1.5990, lr=0.0100
[2025-05-03 13:38:33,750][train][INFO] - Epoch 5/100, Val Acc=0.6518, Val Loss=1.5271, lr=0.0100
[2025-05-03 13:38:41,490][train][INFO] - Epoch 6/100, Val Acc=0.6529, Val Loss=1.5291, lr=0.0100
[2025-05-03 13:38:49,631][train][INFO] - Epoch 7/100, Val Acc=0.6527, Val Loss=1.5194, lr=0.0100
[2025-05-03 13:38:49,915][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.7389, lr=0.0001
[2025-05-03 13:38:56,744][train][INFO] - Epoch 8/100, Val Acc=0.6608, Val Loss=1.4880, lr=0.0100
[2025-05-03 13:39:04,597][train][INFO] - Epoch 9/100, Val Acc=0.6623, Val Loss=1.5188, lr=0.0100
[2025-05-03 13:39:12,304][train][INFO] - Epoch 10/100, Val Acc=0.6560, Val Loss=1.5502, lr=0.0100
[2025-05-03 13:39:17,954][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.7459, lr=0.0001
[2025-05-03 13:39:19,851][train][INFO] - Epoch 11/100, Val Acc=0.6593, Val Loss=1.5167, lr=0.0100
[2025-05-03 13:39:27,807][train][INFO] - Epoch 12/100, Val Acc=0.6547, Val Loss=1.5610, lr=0.0100
[2025-05-03 13:39:35,461][train][INFO] - Epoch 13/100, Val Acc=0.6538, Val Loss=1.5848, lr=0.0100
[2025-05-03 13:39:43,441][train][INFO] - Epoch 14/100, Val Acc=0.6539, Val Loss=1.6309, lr=0.0100
[2025-05-03 13:39:45,933][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6936, lr=0.0001
[2025-05-03 13:39:45,949][meta_train][INFO] - epoch_22 saved !
[2025-05-03 13:39:49,929][train][INFO] - Epoch 15/100, Val Acc=0.6728, Val Loss=1.5194, lr=0.0100
[2025-05-03 13:39:57,094][train][INFO] - Epoch 16/100, Val Acc=0.6629, Val Loss=1.5200, lr=0.0100
[2025-05-03 13:40:05,395][train][INFO] - Epoch 17/100, Val Acc=0.6666, Val Loss=1.5131, lr=0.0100
[2025-05-03 13:40:12,935][train][INFO] - Epoch 18/100, Val Acc=0.6607, Val Loss=1.6064, lr=0.0100
[2025-05-03 13:40:13,313][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.7272, lr=0.0001
[2025-05-03 13:40:20,620][train][INFO] - Epoch 19/100, Val Acc=0.6769, Val Loss=1.4799, lr=0.0100
[2025-05-03 13:40:28,421][train][INFO] - Epoch 20/100, Val Acc=0.6714, Val Loss=1.5317, lr=0.0100
[2025-05-03 13:40:35,741][train][INFO] - Epoch 21/100, Val Acc=0.6456, Val Loss=1.7090, lr=0.0100
[2025-05-03 13:40:41,392][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.8233, lr=0.0001
[2025-05-03 13:40:43,775][train][INFO] - Epoch 22/100, Val Acc=0.6505, Val Loss=1.6629, lr=0.0100
[2025-05-03 13:40:52,057][train][INFO] - Epoch 23/100, Val Acc=0.6277, Val Loss=1.8215, lr=0.0100
[2025-05-03 13:40:59,701][train][INFO] - Epoch 24/100, Val Acc=0.6707, Val Loss=1.5110, lr=0.0100
[2025-05-03 13:41:07,765][train][INFO] - Epoch 25/100, Val Acc=0.6679, Val Loss=1.5532, lr=0.0100
[2025-05-03 13:41:08,699][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6906, lr=0.0001
[2025-05-03 13:41:15,968][train][INFO] - Epoch 26/100, Val Acc=0.6597, Val Loss=1.6347, lr=0.0100
[2025-05-03 13:41:23,963][train][INFO] - Epoch 27/100, Val Acc=0.6627, Val Loss=1.5870, lr=0.0100
[2025-05-03 13:41:31,894][train][INFO] - Epoch 28/100, Val Acc=0.6651, Val Loss=1.5916, lr=0.0100
[2025-05-03 13:41:37,005][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.7978, lr=0.0001
[2025-05-03 13:41:39,424][train][INFO] - Epoch 29/100, Val Acc=0.6586, Val Loss=1.6777, lr=0.0100
[2025-05-03 13:41:46,944][train][INFO] - Epoch 30/100, Val Acc=0.6694, Val Loss=1.5839, lr=0.0100
[2025-05-03 13:41:55,009][train][INFO] - Epoch 31/100, Val Acc=0.6632, Val Loss=1.6073, lr=0.0100
[2025-05-03 13:42:03,335][train][INFO] - Epoch 32/100, Val Acc=0.6708, Val Loss=1.5814, lr=0.0100
[2025-05-03 13:42:03,450][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.8092, lr=0.0001
[2025-05-03 13:42:11,276][train][INFO] - Epoch 33/100, Val Acc=0.6710, Val Loss=1.5806, lr=0.0100
[2025-05-03 13:42:18,398][train][INFO] - Epoch 34/100, Val Acc=0.6678, Val Loss=1.6231, lr=0.0100
[2025-05-03 13:42:26,449][train][INFO] - Epoch 35/100, Val Acc=0.6642, Val Loss=1.5866, lr=0.0100
[2025-05-03 13:42:31,340][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.7321, lr=0.0001
[2025-05-03 13:42:33,922][train][INFO] - Epoch 36/100, Val Acc=0.6662, Val Loss=1.5979, lr=0.0100
[2025-05-03 13:42:42,053][train][INFO] - Epoch 37/100, Val Acc=0.6594, Val Loss=1.6617, lr=0.0100
[2025-05-03 13:42:50,395][train][INFO] - Epoch 38/100, Val Acc=0.6671, Val Loss=1.5735, lr=0.0100
[2025-05-03 13:42:57,286][train][INFO] - Epoch 39/100, Val Acc=0.6724, Val Loss=1.5667, lr=0.0100
[2025-05-03 13:42:58,697][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.7376, lr=0.0001
[2025-05-03 13:43:05,505][train][INFO] - Epoch 40/100, Val Acc=0.6623, Val Loss=1.6227, lr=0.0100
[2025-05-03 13:43:13,341][train][INFO] - Epoch 41/100, Val Acc=0.6606, Val Loss=1.6159, lr=0.0100
[2025-05-03 13:43:21,635][train][INFO] - Epoch 42/100, Val Acc=0.6695, Val Loss=1.5599, lr=0.0100
[2025-05-03 13:43:26,475][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.7366, lr=0.0001
[2025-05-03 13:43:26,492][meta_train][INFO] - epoch_23 saved !
[2025-05-03 13:43:29,493][train][INFO] - Epoch 43/100, Val Acc=0.6644, Val Loss=1.6067, lr=0.0100
[2025-05-03 13:43:37,215][train][INFO] - Epoch 44/100, Val Acc=0.6664, Val Loss=1.6250, lr=0.0100
[2025-05-03 13:43:45,267][train][INFO] - Epoch 45/100, Val Acc=0.6740, Val Loss=1.5466, lr=0.0100
[2025-05-03 13:43:52,558][train][INFO] - Epoch 46/100, Val Acc=0.6590, Val Loss=1.6738, lr=0.0100
[2025-05-03 13:43:54,346][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.7359, lr=0.0001
[2025-05-03 13:43:59,872][train][INFO] - Epoch 47/100, Val Acc=0.6668, Val Loss=1.6072, lr=0.0100
[2025-05-03 13:44:06,603][train][INFO] - Epoch 48/100, Val Acc=0.6656, Val Loss=1.6401, lr=0.0100
[2025-05-03 13:44:14,522][train][INFO] - Epoch 49/100, Val Acc=0.6656, Val Loss=1.6030, lr=0.0100
[2025-05-03 13:44:20,860][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.8054, lr=0.0001
[2025-05-03 13:44:22,448][train][INFO] - Epoch 50/100, Val Acc=0.6608, Val Loss=1.6751, lr=0.0100
[2025-05-03 13:44:30,742][train][INFO] - Epoch 51/100, Val Acc=0.6603, Val Loss=1.6347, lr=0.0100
[2025-05-03 13:44:38,717][train][INFO] - Epoch 52/100, Val Acc=0.6563, Val Loss=1.6584, lr=0.0100
[2025-05-03 13:44:46,236][train][INFO] - Epoch 53/100, Val Acc=0.6547, Val Loss=1.6691, lr=0.0100
[2025-05-03 13:44:48,665][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.7855, lr=0.0001
[2025-05-03 13:44:54,413][train][INFO] - Epoch 54/100, Val Acc=0.6673, Val Loss=1.5818, lr=0.0100
[2025-05-03 13:45:02,702][train][INFO] - Epoch 55/100, Val Acc=0.6735, Val Loss=1.5706, lr=0.0100
[2025-05-03 13:45:10,568][train][INFO] - Epoch 56/100, Val Acc=0.6732, Val Loss=1.5685, lr=0.0100
[2025-05-03 13:45:16,470][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6766, lr=0.0001
[2025-05-03 13:45:18,421][train][INFO] - Epoch 57/100, Val Acc=0.6669, Val Loss=1.5817, lr=0.0100
[2025-05-03 13:45:25,998][train][INFO] - Epoch 58/100, Val Acc=0.6708, Val Loss=1.5360, lr=0.0100
[2025-05-03 13:45:33,973][train][INFO] - Epoch 59/100, Val Acc=0.6737, Val Loss=1.5550, lr=0.0100
[2025-05-03 13:45:41,808][train][INFO] - Epoch 60/100, Val Acc=0.6733, Val Loss=1.5633, lr=0.0100
[2025-05-03 13:45:44,785][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.7154, lr=0.0001
[2025-05-03 13:45:49,475][train][INFO] - Epoch 61/100, Val Acc=0.7192, Val Loss=1.3249, lr=0.0010
[2025-05-03 13:45:57,396][train][INFO] - Epoch 62/100, Val Acc=0.7240, Val Loss=1.3223, lr=0.0010
[2025-05-03 13:46:05,590][train][INFO] - Epoch 63/100, Val Acc=0.7283, Val Loss=1.3249, lr=0.0010
[2025-05-03 13:46:11,735][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.7197, lr=0.0001
[2025-05-03 13:46:14,007][train][INFO] - Epoch 64/100, Val Acc=0.7282, Val Loss=1.3228, lr=0.0010
[2025-05-03 13:46:22,385][train][INFO] - Epoch 65/100, Val Acc=0.7266, Val Loss=1.3298, lr=0.0010
[2025-05-03 13:46:30,119][train][INFO] - Epoch 66/100, Val Acc=0.7288, Val Loss=1.3370, lr=0.0010
[2025-05-03 13:46:38,156][train][INFO] - Epoch 67/100, Val Acc=0.7285, Val Loss=1.3344, lr=0.0010
[2025-05-03 13:46:39,612][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.7336, lr=0.0001
[2025-05-03 13:46:46,348][train][INFO] - Epoch 68/100, Val Acc=0.7318, Val Loss=1.3347, lr=0.0010
[2025-05-03 13:46:54,547][train][INFO] - Epoch 69/100, Val Acc=0.7303, Val Loss=1.3351, lr=0.0010
[2025-05-03 13:47:02,549][train][INFO] - Epoch 70/100, Val Acc=0.7289, Val Loss=1.3398, lr=0.0010
[2025-05-03 13:47:07,461][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.8169, lr=0.0001
[2025-05-03 13:47:07,476][meta_train][INFO] - epoch_24 saved !
[2025-05-03 13:47:11,087][train][INFO] - Epoch 71/100, Val Acc=0.7282, Val Loss=1.3418, lr=0.0010
[2025-05-03 13:47:18,714][train][INFO] - Epoch 72/100, Val Acc=0.7288, Val Loss=1.3483, lr=0.0010
[2025-05-03 13:47:26,491][train][INFO] - Epoch 73/100, Val Acc=0.7318, Val Loss=1.3407, lr=0.0010
[2025-05-03 13:47:34,866][train][INFO] - Epoch 74/100, Val Acc=0.7303, Val Loss=1.3376, lr=0.0010
[2025-05-03 13:47:34,986][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.7292, lr=0.0001
[2025-05-03 13:47:43,200][train][INFO] - Epoch 75/100, Val Acc=0.7327, Val Loss=1.3376, lr=0.0010
[2025-05-03 13:47:51,050][train][INFO] - Epoch 76/100, Val Acc=0.7330, Val Loss=1.3352, lr=0.0010
[2025-05-03 13:47:58,582][train][INFO] - Epoch 77/100, Val Acc=0.7336, Val Loss=1.3400, lr=0.0010
[2025-05-03 13:48:03,563][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.8155, lr=0.0001
[2025-05-03 13:48:06,331][train][INFO] - Epoch 78/100, Val Acc=0.7319, Val Loss=1.3380, lr=0.0010
[2025-05-03 13:48:14,322][train][INFO] - Epoch 79/100, Val Acc=0.7325, Val Loss=1.3425, lr=0.0010
[2025-05-03 13:48:21,450][train][INFO] - Epoch 80/100, Val Acc=0.7325, Val Loss=1.3483, lr=0.0010
[2025-05-03 13:48:29,472][train][INFO] - Epoch 81/100, Val Acc=0.7315, Val Loss=1.3466, lr=0.0010
[2025-05-03 13:48:30,433][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.7322, lr=0.0001
[2025-05-03 13:48:37,095][train][INFO] - Epoch 82/100, Val Acc=0.7330, Val Loss=1.3455, lr=0.0010
[2025-05-03 13:48:44,765][train][INFO] - Epoch 83/100, Val Acc=0.7324, Val Loss=1.3454, lr=0.0010
[2025-05-03 13:48:52,050][train][INFO] - Epoch 84/100, Val Acc=0.7344, Val Loss=1.3516, lr=0.0010
[2025-05-03 13:48:58,112][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6991, lr=0.0001
[2025-05-03 13:49:00,259][train][INFO] - Epoch 85/100, Val Acc=0.7340, Val Loss=1.3458, lr=0.0010
[2025-05-03 13:49:07,767][train][INFO] - Epoch 86/100, Val Acc=0.7355, Val Loss=1.3479, lr=0.0010
[2025-05-03 13:49:15,999][train][INFO] - Epoch 87/100, Val Acc=0.7348, Val Loss=1.3509, lr=0.0010
[2025-05-03 13:49:23,077][train][INFO] - Epoch 88/100, Val Acc=0.7335, Val Loss=1.3552, lr=0.0010
[2025-05-03 13:49:24,717][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7951, lr=0.0001
[2025-05-03 13:49:30,466][train][INFO] - Epoch 89/100, Val Acc=0.7346, Val Loss=1.3438, lr=0.0010
[2025-05-03 13:49:38,430][train][INFO] - Epoch 90/100, Val Acc=0.7351, Val Loss=1.3541, lr=0.0010
[2025-05-03 13:49:45,901][train][INFO] - Epoch 91/100, Val Acc=0.7354, Val Loss=1.3464, lr=0.0001
[2025-05-03 13:49:53,180][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.7664, lr=0.0001
[2025-05-03 13:49:53,505][train][INFO] - Epoch 92/100, Val Acc=0.7345, Val Loss=1.3524, lr=0.0001
[2025-05-03 13:50:02,380][train][INFO] - Epoch 93/100, Val Acc=0.7345, Val Loss=1.3468, lr=0.0001
[2025-05-03 13:50:10,436][train][INFO] - Epoch 94/100, Val Acc=0.7351, Val Loss=1.3443, lr=0.0001
[2025-05-03 13:50:18,514][train][INFO] - Epoch 95/100, Val Acc=0.7359, Val Loss=1.3487, lr=0.0001
[2025-05-03 13:50:20,277][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.7133, lr=0.0001
[2025-05-03 13:50:26,803][train][INFO] - Epoch 96/100, Val Acc=0.7361, Val Loss=1.3442, lr=0.0001
[2025-05-03 13:50:34,609][train][INFO] - Epoch 97/100, Val Acc=0.7348, Val Loss=1.3464, lr=0.0001
[2025-05-03 13:50:42,399][train][INFO] - Epoch 98/100, Val Acc=0.7370, Val Loss=1.3460, lr=0.0001
[2025-05-03 13:50:47,866][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6605, lr=0.0001
[2025-05-03 13:50:47,885][meta_train][INFO] - epoch_25 saved !
[2025-05-03 13:50:50,442][train][INFO] - Epoch 99/100, Val Acc=0.7365, Val Loss=1.3462, lr=0.0001
[2025-05-03 13:50:58,731][train][INFO] - Epoch 100/100, Val Acc=0.7363, Val Loss=1.3434, lr=0.0001
[2025-05-03 13:51:03,728][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7370
[2025-05-03 13:51:03,739][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 13:51:15,208][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.7908, lr=0.0001
[2025-05-03 13:51:42,834][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.7591, lr=0.0001
[2025-05-03 13:52:10,964][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.7288, lr=0.0001
[2025-05-03 13:52:39,825][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.7195, lr=0.0001
[2025-05-03 13:52:44,409][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 13:53:07,338][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6792, lr=0.0001
[2025-05-03 13:53:36,079][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.8054, lr=0.0001
[2025-05-03 13:54:04,334][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6512, lr=0.0001
[2025-05-03 13:54:22,658][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 13:54:23,092][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 13:54:31,648][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.7052, lr=0.0001
[2025-05-03 13:54:31,678][meta_train][INFO] - epoch_26 saved !
[2025-05-03 13:54:58,590][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.7043, lr=0.0001
[2025-05-03 13:55:26,671][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.7414, lr=0.0001
[2025-05-03 13:55:53,787][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6648, lr=0.0001
[2025-05-03 13:56:21,192][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.7233, lr=0.0001
[2025-05-03 13:56:47,498][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.7788, lr=0.0001
[2025-05-03 13:57:14,047][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.7970, lr=0.0001
[2025-05-03 13:57:41,938][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6432, lr=0.0001
[2025-05-03 13:58:08,451][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.7083, lr=0.0001
[2025-05-03 13:58:08,482][meta_train][INFO] - epoch_27 saved !
[2025-05-03 13:58:36,269][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.7310, lr=0.0001
[2025-05-03 13:59:03,175][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.7923, lr=0.0001
[2025-05-03 13:59:30,943][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.7200, lr=0.0001
[2025-05-03 13:59:58,501][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6482, lr=0.0001
[2025-05-03 14:00:25,768][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6926, lr=0.0001
[2025-05-03 14:00:53,290][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.7008, lr=0.0001
[2025-05-03 14:01:20,595][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6349, lr=0.0001
[2025-05-03 14:01:46,594][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7687, lr=0.0001
[2025-05-03 14:01:46,621][meta_train][INFO] - epoch_28 saved !
[2025-05-03 14:02:13,982][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6404, lr=0.0001
[2025-05-03 14:02:41,418][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6879, lr=0.0001
[2025-05-03 14:03:08,980][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.7150, lr=0.0001
[2025-05-03 14:03:36,235][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.7082, lr=0.0001
[2025-05-03 14:04:03,662][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.7780, lr=0.0001
[2025-05-03 14:04:29,971][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.7637, lr=0.0001
[2025-05-03 14:04:57,866][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6282, lr=0.0001
[2025-05-03 14:05:24,859][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6906, lr=0.0001
[2025-05-03 14:05:24,892][meta_train][INFO] - epoch_29 saved !
[2025-05-03 14:05:53,267][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6928, lr=0.0001
[2025-05-03 14:06:19,240][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7588, lr=0.0001
[2025-05-03 14:06:46,519][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.7670, lr=0.0001
[2025-05-03 14:07:12,919][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6852, lr=0.0001
[2025-05-03 14:07:40,771][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6231, lr=0.0001
[2025-05-03 14:08:07,310][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.7022, lr=0.0001
[2025-05-03 14:08:34,261][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6707, lr=0.0001
[2025-05-03 14:09:02,077][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6201, lr=0.0001
[2025-05-03 14:09:02,094][meta_train][INFO] - epoch_30 saved !
[2025-05-03 14:09:28,978][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6692, lr=0.0001
[2025-05-03 14:09:56,995][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6750, lr=0.0001
[2025-05-03 14:10:24,070][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.7562, lr=0.0001
[2025-05-03 14:10:51,353][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6198, lr=0.0001
[2025-05-03 14:11:18,626][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-05-03 14:11:48,050][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '1000'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 14:11:48,142][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 14:11:48,143][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 14:11:48,143][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 14:12:43,145][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '1000'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 14:12:43,231][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 14:12:43,231][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 14:12:43,231][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 14:13:15,307][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.1667, lr=0.001
[2025-05-03 14:13:42,605][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0139, lr=0.001
[2025-05-03 14:14:10,061][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=0.0210, lr=0.001
[2025-05-03 14:14:36,024][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=0.1583, lr=0.001
[2025-05-03 14:15:02,921][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.6060, lr=0.001
[2025-05-03 14:15:29,981][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=1.2982, lr=0.001
[2025-05-03 14:15:56,805][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=1.8115, lr=0.001
[2025-05-03 14:16:24,397][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=1.3921, lr=0.001
[2025-05-03 14:16:24,413][meta_train][INFO] - epoch_1 saved !
[2025-05-03 14:16:51,822][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.6722, lr=0.001
[2025-05-03 14:17:18,608][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.4667, lr=0.001
[2025-05-03 14:17:45,775][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.2690, lr=0.001
[2025-05-03 14:18:12,519][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.1658, lr=0.001
[2025-05-03 14:18:39,919][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.1281, lr=0.001
[2025-05-03 14:19:06,023][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.1605, lr=0.001
[2025-05-03 14:19:33,134][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.2213, lr=0.001
[2025-05-03 14:20:00,992][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.5584, lr=0.001
[2025-05-03 14:20:01,011][meta_train][INFO] - epoch_2 saved !
[2025-05-03 14:20:26,787][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.9922, lr=0.001
[2025-05-03 14:20:53,566][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=1.3833, lr=0.001
[2025-05-03 14:21:21,262][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=1.9676, lr=0.001
[2025-05-03 14:21:47,903][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=2.6424, lr=0.001
[2025-05-03 14:22:15,208][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=1.7414, lr=0.001
[2025-05-03 14:22:41,859][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=2.6573, lr=0.001
[2025-05-03 14:23:08,662][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=3.1153, lr=0.001
[2025-05-03 14:23:36,909][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.3984, lr=0.001
[2025-05-03 14:23:36,937][meta_train][INFO] - epoch_3 saved !
[2025-05-03 14:24:03,448][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.2166, lr=0.001
[2025-05-03 14:24:31,405][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.7794, lr=0.001
[2025-05-03 14:24:57,558][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.3844, lr=0.001
[2025-05-03 14:25:25,124][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.6650, lr=0.001
[2025-05-03 14:25:52,581][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.8475, lr=0.001
[2025-05-03 14:26:18,803][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=1.3175, lr=0.001
[2025-05-03 14:26:45,784][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=1.9756, lr=0.001
[2025-05-03 14:27:13,268][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=2.3198, lr=0.001
[2025-05-03 14:27:13,301][meta_train][INFO] - epoch_4 saved !
[2025-05-03 14:27:40,653][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=2.5160, lr=0.001
[2025-05-03 14:28:07,782][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.6670, lr=0.001
[2025-05-03 14:28:35,546][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=3.5625, lr=0.001
[2025-05-03 14:29:02,534][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=4.3347, lr=0.001
[2025-05-03 14:29:29,878][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=4.6479, lr=0.001
[2025-05-03 14:29:57,092][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=4.7402, lr=0.001
[2025-05-03 14:30:23,690][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9025, lr=0.001
[2025-05-03 14:30:51,143][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.8421, lr=0.001
[2025-05-03 14:30:51,163][meta_train][INFO] - epoch_5 saved !
[2025-05-03 14:31:19,053][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=4.7108, lr=0.001
[2025-05-03 14:31:45,900][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=4.7965, lr=0.001
[2025-05-03 14:32:11,754][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.6988, lr=0.001
[2025-05-03 14:32:38,536][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=4.6811, lr=0.001
[2025-05-03 14:33:05,905][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=4.7079, lr=0.001
[2025-05-03 14:33:33,833][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=4.7138, lr=0.001
[2025-05-03 14:34:01,757][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=4.8310, lr=0.001
[2025-05-03 14:34:28,500][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=4.8095, lr=0.001
[2025-05-03 14:34:28,518][meta_train][INFO] - epoch_6 saved !
[2025-05-03 14:34:56,102][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.7099, lr=0.001
[2025-05-03 14:35:23,820][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=4.7228, lr=0.001
[2025-05-03 14:35:51,132][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=4.8149, lr=0.001
[2025-05-03 14:36:17,355][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.8237, lr=0.001
[2025-05-03 14:36:45,400][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=4.9037, lr=0.001
[2025-05-03 14:37:12,576][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=4.6840, lr=0.001
[2025-05-03 14:37:40,166][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=4.7416, lr=0.001
[2025-05-03 14:38:06,931][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=4.8092, lr=0.001
[2025-05-03 14:38:06,958][meta_train][INFO] - epoch_7 saved !
[2025-05-03 14:38:34,047][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=4.7404, lr=0.001
[2025-05-03 14:39:01,540][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=4.8192, lr=0.001
[2025-05-03 14:39:29,984][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.7949, lr=0.001
[2025-05-03 14:39:56,537][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.7062, lr=0.001
[2025-05-03 14:40:24,333][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=4.6612, lr=0.001
[2025-05-03 14:40:51,917][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=4.6276, lr=0.001
[2025-05-03 14:41:17,725][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7618, lr=0.001
[2025-05-03 14:41:45,041][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=4.6862, lr=0.001
[2025-05-03 14:41:45,076][meta_train][INFO] - epoch_8 saved !
[2025-05-03 14:42:12,422][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=4.6149, lr=0.001
[2025-05-03 14:42:39,289][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=4.6998, lr=0.001
[2025-05-03 14:43:07,248][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=4.6121, lr=0.001
[2025-05-03 14:43:32,694][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7445, lr=0.001
[2025-05-03 14:43:59,775][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.6376, lr=0.001
[2025-05-03 14:44:27,475][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=4.6565, lr=0.001
[2025-05-03 14:44:55,202][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=4.7008, lr=0.001
[2025-05-03 14:45:22,129][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.6102, lr=0.001
[2025-05-03 14:45:22,145][meta_train][INFO] - epoch_9 saved !
[2025-05-03 14:45:49,660][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=4.6063, lr=0.001
[2025-05-03 14:46:17,349][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-03 14:46:44,180][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.6108, lr=0.001
[2025-05-03 14:47:11,989][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=4.6344, lr=0.001
[2025-05-03 14:47:39,368][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=4.6305, lr=0.001
[2025-05-03 14:48:05,290][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.6813, lr=0.001
[2025-05-03 14:48:32,984][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=4.6431, lr=0.001
[2025-05-03 14:48:59,562][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.6074, lr=0.001
[2025-05-03 14:48:59,585][meta_train][INFO] - epoch_10 saved !
[2025-05-03 14:49:27,014][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=4.6143, lr=0.001
[2025-05-03 14:49:53,918][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.6068, lr=0.001
[2025-05-03 14:50:21,771][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 14:50:48,826][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=4.6203, lr=0.001
[2025-05-03 14:51:16,124][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=4.6120, lr=0.001
[2025-05-03 14:51:42,255][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6303, lr=0.001
[2025-05-03 14:52:10,279][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 14:52:37,575][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 14:52:37,600][meta_train][INFO] - epoch_11 saved !
[2025-05-03 14:53:04,697][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=4.6056, lr=0.001
[2025-05-03 14:53:32,068][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 14:53:58,525][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=4.6086, lr=0.001
[2025-05-03 14:54:25,479][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 14:54:52,008][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.6116, lr=0.001
[2025-05-03 14:55:19,531][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 14:55:47,144][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=4.6061, lr=0.001
[2025-05-03 14:56:14,455][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 14:56:14,475][meta_train][INFO] - epoch_12 saved !
[2025-05-03 14:56:41,273][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 14:57:08,334][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=4.6057, lr=0.001
[2025-05-03 14:57:36,285][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 14:58:03,590][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 14:58:30,312][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 14:58:57,929][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=4.6058, lr=0.001
[2025-05-03 14:59:24,314][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.6055, lr=0.001
[2025-05-03 14:59:51,769][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 14:59:51,797][meta_train][INFO] - epoch_13 saved !
[2025-05-03 15:00:18,858][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:00:46,590][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:01:12,962][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:01:39,570][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-03 15:02:07,087][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-03 15:02:34,437][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-03 15:03:01,073][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:03:28,614][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:03:28,630][meta_train][INFO] - epoch_14 saved !
[2025-05-03 15:03:56,147][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:04:22,024][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:04:48,539][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:05:15,772][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:05:43,208][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-03 15:06:10,617][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:06:37,452][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:07:04,850][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:07:04,877][meta_train][INFO] - epoch_15 saved !
[2025-05-03 15:07:32,451][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:07:59,808][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:08:27,144][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:08:54,599][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:09:22,062][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:09:49,233][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:10:16,591][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:10:42,363][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:10:42,379][meta_train][INFO] - epoch_16 saved !
[2025-05-03 15:11:09,819][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:11:37,113][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:12:03,138][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:12:29,983][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:12:56,934][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:13:25,239][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:13:51,734][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:14:19,804][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:14:19,827][meta_train][INFO] - epoch_17 saved !
[2025-05-03 15:14:46,955][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:15:14,381][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:15:42,362][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:16:09,546][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:16:36,023][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:17:01,996][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:17:29,719][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:17:57,144][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:17:57,163][meta_train][INFO] - epoch_18 saved !
[2025-05-03 15:18:24,646][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:18:51,937][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:19:18,935][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:19:45,658][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:20:12,816][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:20:39,462][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:21:07,744][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:21:35,260][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:21:35,281][meta_train][INFO] - epoch_19 saved !
[2025-05-03 15:22:01,736][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:22:29,337][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:22:57,397][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:23:24,713][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:23:50,796][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:24:18,386][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:24:44,972][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:25:12,597][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:25:12,613][meta_train][INFO] - epoch_20 saved !
[2025-05-03 15:25:40,130][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:26:07,708][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:26:34,848][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:27:02,133][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:27:29,717][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:27:55,600][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:28:22,782][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:28:50,061][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:28:50,078][meta_train][INFO] - epoch_21 saved !
[2025-05-03 15:29:17,902][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:29:45,300][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:30:13,297][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:30:40,010][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:31:06,075][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:31:32,939][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:32:00,393][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:32:28,087][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:32:28,115][meta_train][INFO] - epoch_22 saved !
[2025-05-03 15:32:55,084][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:33:19,363][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '1000'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-03 15:33:19,430][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 15:33:19,430][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 15:33:19,430][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 15:33:22,889][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6052, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 15:33:38,984][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 15:33:47,458][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6114, lr=0.0100
[2025-05-03 15:33:49,994][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:33:54,991][train][INFO] - Epoch 2/100, Val Acc=0.0083, Val Loss=4.6816, lr=0.0100
[2025-05-03 15:34:02,324][train][INFO] - Epoch 3/100, Val Acc=0.0347, Val Loss=4.5056, lr=0.0100
[2025-05-03 15:34:10,037][train][INFO] - Epoch 4/100, Val Acc=0.0909, Val Loss=3.6941, lr=0.0100
[2025-05-03 15:34:18,163][train][INFO] - Epoch 5/100, Val Acc=0.1538, Val Loss=3.3655, lr=0.0100
[2025-05-03 15:34:18,300][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:34:25,468][train][INFO] - Epoch 6/100, Val Acc=0.1839, Val Loss=3.2121, lr=0.0100
[2025-05-03 15:34:33,801][train][INFO] - Epoch 7/100, Val Acc=0.1721, Val Loss=3.3469, lr=0.0100
[2025-05-03 15:34:41,484][train][INFO] - Epoch 8/100, Val Acc=0.2367, Val Loss=2.9546, lr=0.0100
[2025-05-03 15:34:44,804][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:34:48,924][train][INFO] - Epoch 9/100, Val Acc=0.2380, Val Loss=2.9688, lr=0.0100
[2025-05-03 15:34:56,789][train][INFO] - Epoch 10/100, Val Acc=0.2335, Val Loss=2.9973, lr=0.0100
[2025-05-03 15:35:04,917][train][INFO] - Epoch 11/100, Val Acc=0.3091, Val Loss=2.5310, lr=0.0100
[2025-05-03 15:35:12,668][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:35:12,925][train][INFO] - Epoch 12/100, Val Acc=0.2669, Val Loss=2.8693, lr=0.0100
[2025-05-03 15:35:19,773][train][INFO] - Epoch 13/100, Val Acc=0.3443, Val Loss=2.4074, lr=0.0100
[2025-05-03 15:35:27,320][train][INFO] - Epoch 14/100, Val Acc=0.3454, Val Loss=2.4001, lr=0.0100
[2025-05-03 15:35:35,538][train][INFO] - Epoch 15/100, Val Acc=0.2666, Val Loss=3.0072, lr=0.0100
[2025-05-03 15:35:40,050][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:35:43,228][train][INFO] - Epoch 16/100, Val Acc=0.3399, Val Loss=2.5008, lr=0.0100
[2025-05-03 15:35:51,655][train][INFO] - Epoch 17/100, Val Acc=0.3537, Val Loss=2.4310, lr=0.0100
[2025-05-03 15:35:59,614][train][INFO] - Epoch 18/100, Val Acc=0.3419, Val Loss=2.5220, lr=0.0100
[2025-05-03 15:36:07,580][train][INFO] - Epoch 19/100, Val Acc=0.3757, Val Loss=2.3394, lr=0.0100
[2025-05-03 15:36:07,763][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:36:07,781][meta_train][INFO] - epoch_23 saved !
[2025-05-03 15:36:15,073][train][INFO] - Epoch 20/100, Val Acc=0.4116, Val Loss=2.1341, lr=0.0100
[2025-05-03 15:36:22,812][train][INFO] - Epoch 21/100, Val Acc=0.4161, Val Loss=2.1494, lr=0.0100
[2025-05-03 15:36:30,983][train][INFO] - Epoch 22/100, Val Acc=0.3860, Val Loss=2.2593, lr=0.0100
[2025-05-03 15:36:35,638][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:36:38,751][train][INFO] - Epoch 23/100, Val Acc=0.4250, Val Loss=2.1168, lr=0.0100
[2025-05-03 15:36:47,048][train][INFO] - Epoch 24/100, Val Acc=0.4479, Val Loss=2.0023, lr=0.0100
[2025-05-03 15:36:55,543][train][INFO] - Epoch 25/100, Val Acc=0.4573, Val Loss=1.9823, lr=0.0100
[2025-05-03 15:37:02,109][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:37:03,602][train][INFO] - Epoch 26/100, Val Acc=0.4316, Val Loss=2.1276, lr=0.0100
[2025-05-03 15:37:12,206][train][INFO] - Epoch 27/100, Val Acc=0.4108, Val Loss=2.2066, lr=0.0100
[2025-05-03 15:37:19,905][train][INFO] - Epoch 28/100, Val Acc=0.4160, Val Loss=2.2133, lr=0.0100
[2025-05-03 15:37:27,921][train][INFO] - Epoch 29/100, Val Acc=0.4561, Val Loss=2.0136, lr=0.0100
[2025-05-03 15:37:29,832][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:37:36,303][train][INFO] - Epoch 30/100, Val Acc=0.4730, Val Loss=1.9318, lr=0.0100
[2025-05-03 15:37:44,652][train][INFO] - Epoch 31/100, Val Acc=0.4696, Val Loss=1.9640, lr=0.0100
[2025-05-03 15:37:53,536][train][INFO] - Epoch 32/100, Val Acc=0.4584, Val Loss=1.9701, lr=0.0100
[2025-05-03 15:37:57,638][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:38:01,670][train][INFO] - Epoch 33/100, Val Acc=0.4362, Val Loss=2.1575, lr=0.0100
[2025-05-03 15:38:09,718][train][INFO] - Epoch 34/100, Val Acc=0.4595, Val Loss=1.9880, lr=0.0100
[2025-05-03 15:38:18,216][train][INFO] - Epoch 35/100, Val Acc=0.4626, Val Loss=2.0220, lr=0.0100
[2025-05-03 15:38:25,876][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:38:26,759][train][INFO] - Epoch 36/100, Val Acc=0.4735, Val Loss=2.0218, lr=0.0100
[2025-05-03 15:38:35,207][train][INFO] - Epoch 37/100, Val Acc=0.5081, Val Loss=1.8295, lr=0.0100
[2025-05-03 15:38:43,675][train][INFO] - Epoch 38/100, Val Acc=0.4977, Val Loss=1.8533, lr=0.0100
[2025-05-03 15:38:52,100][train][INFO] - Epoch 39/100, Val Acc=0.4727, Val Loss=1.9816, lr=0.0100
[2025-05-03 15:38:52,740][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:39:00,476][train][INFO] - Epoch 40/100, Val Acc=0.4728, Val Loss=1.9976, lr=0.0100
[2025-05-03 15:39:08,597][train][INFO] - Epoch 41/100, Val Acc=0.4957, Val Loss=1.8969, lr=0.0100
[2025-05-03 15:39:16,492][train][INFO] - Epoch 42/100, Val Acc=0.5027, Val Loss=1.8587, lr=0.0100
[2025-05-03 15:39:20,676][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:39:24,749][train][INFO] - Epoch 43/100, Val Acc=0.5207, Val Loss=1.8040, lr=0.0100
[2025-05-03 15:39:33,027][train][INFO] - Epoch 44/100, Val Acc=0.5109, Val Loss=1.8133, lr=0.0100
[2025-05-03 15:39:41,004][train][INFO] - Epoch 45/100, Val Acc=0.5089, Val Loss=1.8242, lr=0.0100
[2025-05-03 15:39:48,336][train][INFO] - Epoch 46/100, Val Acc=0.5104, Val Loss=1.8402, lr=0.0100
[2025-05-03 15:39:48,485][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:39:48,503][meta_train][INFO] - epoch_24 saved !
[2025-05-03 15:39:56,022][train][INFO] - Epoch 47/100, Val Acc=0.5216, Val Loss=1.7895, lr=0.0100
[2025-05-03 15:40:03,971][train][INFO] - Epoch 48/100, Val Acc=0.5184, Val Loss=1.8127, lr=0.0100
[2025-05-03 15:40:12,608][train][INFO] - Epoch 49/100, Val Acc=0.5162, Val Loss=1.8359, lr=0.0100
[2025-05-03 15:40:16,286][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:40:20,879][train][INFO] - Epoch 50/100, Val Acc=0.5123, Val Loss=1.8540, lr=0.0100
[2025-05-03 15:40:28,944][train][INFO] - Epoch 51/100, Val Acc=0.5112, Val Loss=1.8444, lr=0.0100
[2025-05-03 15:40:36,703][train][INFO] - Epoch 52/100, Val Acc=0.4748, Val Loss=2.0892, lr=0.0100
[2025-05-03 15:40:44,820][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:40:44,860][train][INFO] - Epoch 53/100, Val Acc=0.5040, Val Loss=1.9552, lr=0.0100
[2025-05-03 15:40:53,140][train][INFO] - Epoch 54/100, Val Acc=0.5304, Val Loss=1.7693, lr=0.0100
[2025-05-03 15:41:01,506][train][INFO] - Epoch 55/100, Val Acc=0.4946, Val Loss=1.9258, lr=0.0100
[2025-05-03 15:41:09,732][train][INFO] - Epoch 56/100, Val Acc=0.5227, Val Loss=1.8318, lr=0.0100
[2025-05-03 15:41:11,799][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:41:18,804][train][INFO] - Epoch 57/100, Val Acc=0.5483, Val Loss=1.6845, lr=0.0100
[2025-05-03 15:41:26,452][train][INFO] - Epoch 58/100, Val Acc=0.5310, Val Loss=1.7666, lr=0.0100
[2025-05-03 15:41:34,364][train][INFO] - Epoch 59/100, Val Acc=0.5432, Val Loss=1.6975, lr=0.0100
[2025-05-03 15:41:39,603][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:41:42,151][train][INFO] - Epoch 60/100, Val Acc=0.5255, Val Loss=1.8257, lr=0.0100
[2025-05-03 15:41:50,915][train][INFO] - Epoch 61/100, Val Acc=0.6110, Val Loss=1.4214, lr=0.0010
[2025-05-03 15:41:59,026][train][INFO] - Epoch 62/100, Val Acc=0.6159, Val Loss=1.4208, lr=0.0010
[2025-05-03 15:42:05,999][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:42:06,497][train][INFO] - Epoch 63/100, Val Acc=0.6175, Val Loss=1.4098, lr=0.0010
[2025-05-03 15:42:14,885][train][INFO] - Epoch 64/100, Val Acc=0.6167, Val Loss=1.4114, lr=0.0010
[2025-05-03 15:42:22,302][train][INFO] - Epoch 65/100, Val Acc=0.6195, Val Loss=1.4153, lr=0.0010
[2025-05-03 15:42:30,271][train][INFO] - Epoch 66/100, Val Acc=0.6207, Val Loss=1.4140, lr=0.0010
[2025-05-03 15:42:34,633][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:42:38,439][train][INFO] - Epoch 67/100, Val Acc=0.6203, Val Loss=1.4220, lr=0.0010
[2025-05-03 15:42:46,892][train][INFO] - Epoch 68/100, Val Acc=0.6192, Val Loss=1.4265, lr=0.0010
[2025-05-03 15:42:55,412][train][INFO] - Epoch 69/100, Val Acc=0.6199, Val Loss=1.4278, lr=0.0010
[2025-05-03 15:43:01,830][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:43:03,492][train][INFO] - Epoch 70/100, Val Acc=0.6185, Val Loss=1.4279, lr=0.0010
[2025-05-03 15:43:11,724][train][INFO] - Epoch 71/100, Val Acc=0.6197, Val Loss=1.4421, lr=0.0010
[2025-05-03 15:43:19,628][train][INFO] - Epoch 72/100, Val Acc=0.6196, Val Loss=1.4494, lr=0.0010
[2025-05-03 15:43:27,571][train][INFO] - Epoch 73/100, Val Acc=0.6198, Val Loss=1.4512, lr=0.0010
[2025-05-03 15:43:29,475][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:43:29,505][meta_train][INFO] - epoch_25 saved !
[2025-05-03 15:43:36,212][train][INFO] - Epoch 74/100, Val Acc=0.6192, Val Loss=1.4476, lr=0.0010
[2025-05-03 15:43:44,163][train][INFO] - Epoch 75/100, Val Acc=0.6176, Val Loss=1.4577, lr=0.0010
[2025-05-03 15:43:52,482][train][INFO] - Epoch 76/100, Val Acc=0.6198, Val Loss=1.4503, lr=0.0010
[2025-05-03 15:43:56,680][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:44:00,335][train][INFO] - Epoch 77/100, Val Acc=0.6171, Val Loss=1.4615, lr=0.0010
[2025-05-03 15:44:08,637][train][INFO] - Epoch 78/100, Val Acc=0.6199, Val Loss=1.4683, lr=0.0010
[2025-05-03 15:44:16,396][train][INFO] - Epoch 79/100, Val Acc=0.6170, Val Loss=1.4773, lr=0.0010
[2025-05-03 15:44:23,937][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:44:24,298][train][INFO] - Epoch 80/100, Val Acc=0.6150, Val Loss=1.4789, lr=0.0010
[2025-05-03 15:44:32,819][train][INFO] - Epoch 81/100, Val Acc=0.6213, Val Loss=1.4733, lr=0.0010
[2025-05-03 15:44:40,903][train][INFO] - Epoch 82/100, Val Acc=0.6184, Val Loss=1.4856, lr=0.0010
[2025-05-03 15:44:48,996][train][INFO] - Epoch 83/100, Val Acc=0.6200, Val Loss=1.4781, lr=0.0010
[2025-05-03 15:44:51,527][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:44:57,160][train][INFO] - Epoch 84/100, Val Acc=0.6193, Val Loss=1.4785, lr=0.0010
[2025-05-03 15:45:05,178][train][INFO] - Epoch 85/100, Val Acc=0.6161, Val Loss=1.4860, lr=0.0010
[2025-05-03 15:45:13,805][train][INFO] - Epoch 86/100, Val Acc=0.6180, Val Loss=1.5024, lr=0.0010
[2025-05-03 15:45:19,851][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:45:22,084][train][INFO] - Epoch 87/100, Val Acc=0.6176, Val Loss=1.5095, lr=0.0010
[2025-05-03 15:45:29,760][train][INFO] - Epoch 88/100, Val Acc=0.6200, Val Loss=1.5113, lr=0.0010
[2025-05-03 15:45:37,969][train][INFO] - Epoch 89/100, Val Acc=0.6144, Val Loss=1.5193, lr=0.0010
[2025-05-03 15:45:46,731][train][INFO] - Epoch 90/100, Val Acc=0.6206, Val Loss=1.4963, lr=0.0010
[2025-05-03 15:45:47,099][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:45:53,797][train][INFO] - Epoch 91/100, Val Acc=0.6216, Val Loss=1.4827, lr=0.0001
[2025-05-03 15:46:01,681][train][INFO] - Epoch 92/100, Val Acc=0.6216, Val Loss=1.4896, lr=0.0001
[2025-05-03 15:46:09,679][train][INFO] - Epoch 93/100, Val Acc=0.6208, Val Loss=1.4882, lr=0.0001
[2025-05-03 15:46:15,329][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:46:18,256][train][INFO] - Epoch 94/100, Val Acc=0.6229, Val Loss=1.4810, lr=0.0001
[2025-05-03 15:46:26,874][train][INFO] - Epoch 95/100, Val Acc=0.6236, Val Loss=1.4892, lr=0.0001
[2025-05-03 15:46:34,749][train][INFO] - Epoch 96/100, Val Acc=0.6239, Val Loss=1.4869, lr=0.0001
[2025-05-03 15:46:43,175][train][INFO] - Epoch 97/100, Val Acc=0.6227, Val Loss=1.4900, lr=0.0001
[2025-05-03 15:46:43,421][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:46:51,789][train][INFO] - Epoch 98/100, Val Acc=0.6230, Val Loss=1.4868, lr=0.0001
[2025-05-03 15:46:59,123][train][INFO] - Epoch 99/100, Val Acc=0.6208, Val Loss=1.4925, lr=0.0001
[2025-05-03 15:47:07,444][train][INFO] - Epoch 100/100, Val Acc=0.6219, Val Loss=1.4903, lr=0.0001
[2025-05-03 15:47:10,498][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:47:10,526][meta_train][INFO] - epoch_26 saved !
[2025-05-03 15:47:12,371][train][INFO] - After training : Train Acc=0.8349  Val Acc=0.6239
[2025-05-03 15:47:12,376][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 15:47:38,384][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:48:07,453][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:48:35,843][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:48:57,336][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 15:49:04,381][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:49:31,569][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:49:59,182][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:50:28,006][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:50:55,816][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:50:55,837][meta_train][INFO] - epoch_27 saved !
[2025-05-03 15:51:15,372][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 15:51:15,819][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 15:51:24,440][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:51:51,897][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:52:18,969][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:52:46,440][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:53:13,487][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:53:40,875][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:54:08,327][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:54:34,529][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:54:34,549][meta_train][INFO] - epoch_28 saved !
[2025-05-03 15:55:01,634][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:55:28,741][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:55:56,158][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 15:56:23,368][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 15:56:50,974][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 15:57:17,072][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 15:57:44,835][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 15:58:11,845][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 15:58:11,874][meta_train][INFO] - epoch_29 saved !
[2025-05-03 15:58:40,187][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 15:59:06,027][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 15:59:33,574][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 16:00:00,386][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 16:00:28,191][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6052, lr=0.001
[2025-05-03 16:00:54,785][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 16:01:21,692][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 16:01:49,717][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 16:01:49,737][meta_train][INFO] - epoch_30 saved !
[2025-05-03 16:02:17,313][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 16:02:45,573][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 16:03:13,150][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 16:03:40,823][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6052, lr=0.001
[2025-05-03 16:04:08,396][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-03 16:04:34,940][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6052, lr=0.001
[2025-05-03 16:05:02,664][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6053, lr=0.001
[2025-05-03 16:05:29,300][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 16:05:29,325][meta_train][INFO] - epoch_31 saved !
[2025-05-03 16:05:55,691][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6052, lr=0.001
[2025-05-03 16:06:22,310][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6052, lr=0.001
[2025-05-03 16:06:50,426][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6052, lr=0.001
[2025-05-03 16:07:17,172][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6053, lr=0.001
[2025-05-03 16:07:44,355][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6053, lr=0.001
[2025-05-03 16:08:12,159][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6054, lr=0.001
[2025-05-03 16:08:39,689][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6052, lr=0.001
[2025-05-03 16:09:06,446][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6052, lr=0.001
[2025-05-03 16:09:06,462][meta_train][INFO] - epoch_32 saved !
[2025-05-03 16:10:24,861][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 15

[2025-05-03 16:10:24,947][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 16:10:24,947][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 16:10:24,947][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 16:10:44,262][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 16:10:52,383][train][INFO] - Epoch 1/100, Val Acc=0.0349, Val Loss=4.3077, lr=0.0100
[2025-05-03 16:10:59,899][train][INFO] - Epoch 2/100, Val Acc=0.1015, Val Loss=3.8209, lr=0.0100
[2025-05-03 16:11:06,925][train][INFO] - Epoch 3/100, Val Acc=0.1802, Val Loss=3.1915, lr=0.0100
[2025-05-03 16:11:15,075][train][INFO] - Epoch 4/100, Val Acc=0.2201, Val Loss=3.0500, lr=0.0100
[2025-05-03 16:11:22,964][train][INFO] - Epoch 5/100, Val Acc=0.2616, Val Loss=2.8036, lr=0.0100
[2025-05-03 16:11:30,767][train][INFO] - Epoch 6/100, Val Acc=0.3272, Val Loss=2.5696, lr=0.0100
[2025-05-03 16:11:38,894][train][INFO] - Epoch 7/100, Val Acc=0.4125, Val Loss=2.1535, lr=0.0100
[2025-05-03 16:11:47,040][train][INFO] - Epoch 8/100, Val Acc=0.4032, Val Loss=2.2165, lr=0.0100
[2025-05-03 16:11:54,878][train][INFO] - Epoch 9/100, Val Acc=0.4190, Val Loss=2.1593, lr=0.0100
[2025-05-03 16:12:02,698][train][INFO] - Epoch 10/100, Val Acc=0.4434, Val Loss=2.0629, lr=0.0100
[2025-05-03 16:12:10,612][train][INFO] - Epoch 11/100, Val Acc=0.4574, Val Loss=2.0133, lr=0.0100
[2025-05-03 16:12:18,720][train][INFO] - Epoch 12/100, Val Acc=0.4776, Val Loss=1.9879, lr=0.0100
[2025-05-03 16:12:26,938][train][INFO] - Epoch 13/100, Val Acc=0.4801, Val Loss=1.9217, lr=0.0100
[2025-05-03 16:12:34,584][train][INFO] - Epoch 14/100, Val Acc=0.4987, Val Loss=1.8716, lr=0.0100
[2025-05-03 16:12:42,269][train][INFO] - Epoch 15/100, Val Acc=0.5159, Val Loss=1.7931, lr=0.0100
[2025-05-03 16:12:49,832][train][INFO] - Epoch 16/100, Val Acc=0.4784, Val Loss=2.0278, lr=0.0100
[2025-05-03 16:12:57,409][train][INFO] - Epoch 17/100, Val Acc=0.5266, Val Loss=1.7460, lr=0.0100
[2025-05-03 16:13:05,352][train][INFO] - Epoch 18/100, Val Acc=0.5237, Val Loss=1.7909, lr=0.0100
[2025-05-03 16:13:13,679][train][INFO] - Epoch 19/100, Val Acc=0.5231, Val Loss=1.8106, lr=0.0100
[2025-05-03 16:13:21,384][train][INFO] - Epoch 20/100, Val Acc=0.5345, Val Loss=1.8141, lr=0.0100
[2025-05-03 16:13:29,417][train][INFO] - Epoch 21/100, Val Acc=0.5476, Val Loss=1.6855, lr=0.0100
[2025-05-03 16:13:37,539][train][INFO] - Epoch 22/100, Val Acc=0.5233, Val Loss=1.8282, lr=0.0100
[2025-05-03 16:13:45,572][train][INFO] - Epoch 23/100, Val Acc=0.5546, Val Loss=1.6765, lr=0.0100
[2025-05-03 16:13:53,681][train][INFO] - Epoch 24/100, Val Acc=0.5700, Val Loss=1.6179, lr=0.0100
[2025-05-03 16:14:01,700][train][INFO] - Epoch 25/100, Val Acc=0.5725, Val Loss=1.6230, lr=0.0100
[2025-05-03 16:14:09,669][train][INFO] - Epoch 26/100, Val Acc=0.5601, Val Loss=1.6903, lr=0.0100
[2025-05-03 16:14:17,528][train][INFO] - Epoch 27/100, Val Acc=0.5570, Val Loss=1.7488, lr=0.0100
[2025-05-03 16:14:25,464][train][INFO] - Epoch 28/100, Val Acc=0.5668, Val Loss=1.6907, lr=0.0100
[2025-05-03 16:14:32,246][train][INFO] - Epoch 29/100, Val Acc=0.5724, Val Loss=1.6357, lr=0.0100
[2025-05-03 16:14:40,497][train][INFO] - Epoch 30/100, Val Acc=0.5813, Val Loss=1.6270, lr=0.0100
[2025-05-03 16:14:48,895][train][INFO] - Epoch 31/100, Val Acc=0.5858, Val Loss=1.5939, lr=0.0100
[2025-05-03 16:14:57,066][train][INFO] - Epoch 32/100, Val Acc=0.5704, Val Loss=1.6999, lr=0.0100
[2025-05-03 16:15:05,178][train][INFO] - Epoch 33/100, Val Acc=0.5796, Val Loss=1.6652, lr=0.0100
[2025-05-03 16:15:12,514][train][INFO] - Epoch 34/100, Val Acc=0.5564, Val Loss=1.7922, lr=0.0100
[2025-05-03 16:15:19,453][train][INFO] - Epoch 35/100, Val Acc=0.5927, Val Loss=1.6195, lr=0.0100
[2025-05-03 16:15:27,666][train][INFO] - Epoch 36/100, Val Acc=0.5819, Val Loss=1.7134, lr=0.0100
[2025-05-03 16:15:35,533][train][INFO] - Epoch 37/100, Val Acc=0.5902, Val Loss=1.6378, lr=0.0100
[2025-05-03 16:15:43,279][train][INFO] - Epoch 38/100, Val Acc=0.5960, Val Loss=1.6032, lr=0.0100
[2025-05-03 16:15:51,388][train][INFO] - Epoch 39/100, Val Acc=0.5845, Val Loss=1.6720, lr=0.0100
[2025-05-03 16:15:59,552][train][INFO] - Epoch 40/100, Val Acc=0.5907, Val Loss=1.6315, lr=0.0100
[2025-05-03 16:16:07,483][train][INFO] - Epoch 41/100, Val Acc=0.6090, Val Loss=1.5582, lr=0.0100
[2025-05-03 16:16:15,341][train][INFO] - Epoch 42/100, Val Acc=0.5906, Val Loss=1.6638, lr=0.0100
[2025-05-03 16:16:23,468][train][INFO] - Epoch 43/100, Val Acc=0.5921, Val Loss=1.6588, lr=0.0100
[2025-05-03 16:16:31,639][train][INFO] - Epoch 44/100, Val Acc=0.6052, Val Loss=1.6226, lr=0.0100
[2025-05-03 16:16:40,139][train][INFO] - Epoch 45/100, Val Acc=0.5858, Val Loss=1.7206, lr=0.0100
[2025-05-03 16:16:48,206][train][INFO] - Epoch 46/100, Val Acc=0.6049, Val Loss=1.6373, lr=0.0100
[2025-05-03 16:16:55,694][train][INFO] - Epoch 47/100, Val Acc=0.6049, Val Loss=1.6022, lr=0.0100
[2025-05-03 16:17:03,393][train][INFO] - Epoch 48/100, Val Acc=0.5972, Val Loss=1.6697, lr=0.0100
[2025-05-03 16:17:11,726][train][INFO] - Epoch 49/100, Val Acc=0.6067, Val Loss=1.6502, lr=0.0100
[2025-05-03 16:17:20,063][train][INFO] - Epoch 50/100, Val Acc=0.6018, Val Loss=1.6520, lr=0.0100
[2025-05-03 16:17:28,289][train][INFO] - Epoch 51/100, Val Acc=0.6085, Val Loss=1.6064, lr=0.0100
[2025-05-03 16:17:35,998][train][INFO] - Epoch 52/100, Val Acc=0.5693, Val Loss=1.8811, lr=0.0100
[2025-05-03 16:17:43,201][train][INFO] - Epoch 53/100, Val Acc=0.6102, Val Loss=1.5905, lr=0.0100
[2025-05-03 16:17:51,096][train][INFO] - Epoch 54/100, Val Acc=0.5923, Val Loss=1.7395, lr=0.0100
[2025-05-03 16:17:59,018][train][INFO] - Epoch 55/100, Val Acc=0.5881, Val Loss=1.7764, lr=0.0100
[2025-05-03 16:18:07,293][train][INFO] - Epoch 56/100, Val Acc=0.6153, Val Loss=1.6078, lr=0.0100
[2025-05-03 16:18:15,306][train][INFO] - Epoch 57/100, Val Acc=0.6154, Val Loss=1.6031, lr=0.0100
[2025-05-03 16:18:22,765][train][INFO] - Epoch 58/100, Val Acc=0.6104, Val Loss=1.6201, lr=0.0100
[2025-05-03 16:18:30,505][train][INFO] - Epoch 59/100, Val Acc=0.6195, Val Loss=1.6012, lr=0.0100
[2025-05-03 16:18:38,803][train][INFO] - Epoch 60/100, Val Acc=0.5967, Val Loss=1.7434, lr=0.0100
[2025-05-03 16:18:46,905][train][INFO] - Epoch 61/100, Val Acc=0.6728, Val Loss=1.3712, lr=0.0010
[2025-05-03 16:18:54,309][train][INFO] - Epoch 62/100, Val Acc=0.6770, Val Loss=1.3631, lr=0.0010
[2025-05-03 16:19:02,424][train][INFO] - Epoch 63/100, Val Acc=0.6768, Val Loss=1.3761, lr=0.0010
[2025-05-03 16:19:10,485][train][INFO] - Epoch 64/100, Val Acc=0.6766, Val Loss=1.3827, lr=0.0010
[2025-05-03 16:19:18,324][train][INFO] - Epoch 65/100, Val Acc=0.6778, Val Loss=1.3894, lr=0.0010
[2025-05-03 16:19:26,111][train][INFO] - Epoch 66/100, Val Acc=0.6798, Val Loss=1.3924, lr=0.0010
[2025-05-03 16:19:34,000][train][INFO] - Epoch 67/100, Val Acc=0.6804, Val Loss=1.3946, lr=0.0010
[2025-05-03 16:19:42,094][train][INFO] - Epoch 68/100, Val Acc=0.6778, Val Loss=1.4248, lr=0.0010
[2025-05-03 16:19:50,230][train][INFO] - Epoch 69/100, Val Acc=0.6786, Val Loss=1.4279, lr=0.0010
[2025-05-03 16:19:58,985][train][INFO] - Epoch 70/100, Val Acc=0.6803, Val Loss=1.4261, lr=0.0010
[2025-05-03 16:20:07,736][train][INFO] - Epoch 71/100, Val Acc=0.6796, Val Loss=1.4393, lr=0.0010
[2025-05-03 16:20:15,912][train][INFO] - Epoch 72/100, Val Acc=0.6807, Val Loss=1.4406, lr=0.0010
[2025-05-03 16:20:23,868][train][INFO] - Epoch 73/100, Val Acc=0.6801, Val Loss=1.4450, lr=0.0010
[2025-05-03 16:20:31,844][train][INFO] - Epoch 74/100, Val Acc=0.6797, Val Loss=1.4592, lr=0.0010
[2025-05-03 16:20:39,959][train][INFO] - Epoch 75/100, Val Acc=0.6801, Val Loss=1.4561, lr=0.0010
[2025-05-03 16:20:47,135][train][INFO] - Epoch 76/100, Val Acc=0.6790, Val Loss=1.4712, lr=0.0010
[2025-05-03 16:20:55,208][train][INFO] - Epoch 77/100, Val Acc=0.6791, Val Loss=1.4806, lr=0.0010
[2025-05-03 16:21:03,208][train][INFO] - Epoch 78/100, Val Acc=0.6814, Val Loss=1.4852, lr=0.0010
[2025-05-03 16:21:11,640][train][INFO] - Epoch 79/100, Val Acc=0.6812, Val Loss=1.4991, lr=0.0010
[2025-05-03 16:21:19,391][train][INFO] - Epoch 80/100, Val Acc=0.6774, Val Loss=1.5045, lr=0.0010
[2025-05-03 16:21:27,161][train][INFO] - Epoch 81/100, Val Acc=0.6796, Val Loss=1.5087, lr=0.0010
[2025-05-03 16:21:35,809][train][INFO] - Epoch 82/100, Val Acc=0.6787, Val Loss=1.5136, lr=0.0010
[2025-05-03 16:21:43,742][train][INFO] - Epoch 83/100, Val Acc=0.6799, Val Loss=1.5284, lr=0.0010
[2025-05-03 16:21:51,548][train][INFO] - Epoch 84/100, Val Acc=0.6807, Val Loss=1.5319, lr=0.0010
[2025-05-03 16:21:58,799][train][INFO] - Epoch 85/100, Val Acc=0.6772, Val Loss=1.5373, lr=0.0010
[2025-05-03 16:22:07,051][train][INFO] - Epoch 86/100, Val Acc=0.6791, Val Loss=1.5518, lr=0.0010
[2025-05-03 16:22:15,218][train][INFO] - Epoch 87/100, Val Acc=0.6788, Val Loss=1.5541, lr=0.0010
[2025-05-03 16:22:23,157][train][INFO] - Epoch 88/100, Val Acc=0.6774, Val Loss=1.5593, lr=0.0010
[2025-05-03 16:22:30,940][train][INFO] - Epoch 89/100, Val Acc=0.6757, Val Loss=1.5656, lr=0.0010
[2025-05-03 16:22:38,542][train][INFO] - Epoch 90/100, Val Acc=0.6806, Val Loss=1.5638, lr=0.0010
[2025-05-03 16:22:46,263][train][INFO] - Epoch 91/100, Val Acc=0.6806, Val Loss=1.5514, lr=0.0001
[2025-05-03 16:22:53,633][train][INFO] - Epoch 92/100, Val Acc=0.6787, Val Loss=1.5580, lr=0.0001
[2025-05-03 16:23:01,257][train][INFO] - Epoch 93/100, Val Acc=0.6823, Val Loss=1.5506, lr=0.0001
[2025-05-03 16:23:09,622][train][INFO] - Epoch 94/100, Val Acc=0.6808, Val Loss=1.5526, lr=0.0001
[2025-05-03 16:23:17,301][train][INFO] - Epoch 95/100, Val Acc=0.6817, Val Loss=1.5564, lr=0.0001
[2025-05-03 16:23:24,951][train][INFO] - Epoch 96/100, Val Acc=0.6802, Val Loss=1.5545, lr=0.0001
[2025-05-03 16:23:33,155][train][INFO] - Epoch 97/100, Val Acc=0.6824, Val Loss=1.5549, lr=0.0001
[2025-05-03 16:23:41,559][train][INFO] - Epoch 98/100, Val Acc=0.6802, Val Loss=1.5537, lr=0.0001
[2025-05-03 16:23:50,424][train][INFO] - Epoch 99/100, Val Acc=0.6801, Val Loss=1.5611, lr=0.0001
[2025-05-03 16:23:59,079][train][INFO] - Epoch 100/100, Val Acc=0.6814, Val Loss=1.5582, lr=0.0001
[2025-05-03 16:24:04,278][train][INFO] - After training : Train Acc=0.9817  Val Acc=0.6824
[2025-05-03 16:24:04,283][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 16:25:51,623][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 16:28:24,398][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 16:28:24,841][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 16:46:01,372][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 16:46:01,457][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 16:46:01,457][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 16:46:01,457][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 16:46:33,664][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.1667, lr=0.001
[2025-05-03 16:46:53,398][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.0001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.1
      edge_res_ratio: 0.1
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Joy
level: 0
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-03 16:46:53,449][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 16:46:53,449][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 16:46:53,449][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 16:47:01,088][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0139, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 16:47:25,383][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=756523755.5200, lr=0.0001
[2025-05-03 16:47:28,757][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=0.0210, lr=0.001
[2025-05-03 16:47:52,682][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=12991820.6800, lr=0.0001
[2025-05-03 16:47:55,121][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=0.1583, lr=0.001
[2025-05-03 16:48:20,254][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=21312495.1600, lr=0.0001
[2025-05-03 16:48:22,513][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.6060, lr=0.001
[2025-05-03 16:48:46,383][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=46765873.1200, lr=0.0001
[2025-05-03 16:48:49,986][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=1.2982, lr=0.001
[2025-05-03 16:49:13,504][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=15052422.2600, lr=0.0001
[2025-05-03 16:49:17,024][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=1.8115, lr=0.001
[2025-05-03 16:49:40,809][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=141085.6473, lr=0.0001
[2025-05-03 16:49:44,965][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=1.3920, lr=0.001
[2025-05-03 16:49:44,982][meta_train][INFO] - epoch_1 saved !
[2025-05-03 16:50:07,796][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=3817666.7850, lr=0.0001
[2025-05-03 16:50:12,590][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.6722, lr=0.001
[2025-05-03 16:50:35,404][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=237898449.6000, lr=0.0001
[2025-05-03 16:50:35,424][meta_train][INFO] - epoch_1 saved !
[2025-05-03 16:50:39,668][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.4667, lr=0.001
[2025-05-03 16:51:02,823][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=2263285.7938, lr=0.0001
[2025-05-03 16:51:07,130][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=0.2690, lr=0.001
[2025-05-03 16:51:29,712][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=243515.8398, lr=0.0001
[2025-05-03 16:51:34,321][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.1658, lr=0.001
[2025-05-03 16:51:57,015][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=2925892.9350, lr=0.0001
[2025-05-03 16:52:02,283][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.1281, lr=0.001
[2025-05-03 16:52:24,220][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=272309.2906, lr=0.0001
[2025-05-03 16:52:28,716][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.1605, lr=0.001
[2025-05-03 16:52:52,068][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=23449666.9200, lr=0.0001
[2025-05-03 16:52:56,544][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.2213, lr=0.001
[2025-05-03 16:53:18,238][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=442751.1453, lr=0.0001
[2025-05-03 16:53:24,549][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.5584, lr=0.001
[2025-05-03 16:53:24,565][meta_train][INFO] - epoch_2 saved !
[2025-05-03 16:53:45,617][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=105764.1962, lr=0.0001
[2025-05-03 16:53:50,800][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.9922, lr=0.001
[2025-05-03 16:54:13,488][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=8064.5554, lr=0.0001
[2025-05-03 16:54:13,520][meta_train][INFO] - epoch_2 saved !
[2025-05-03 16:54:17,879][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=1.3833, lr=0.001
[2025-05-03 16:54:39,732][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=172023.0594, lr=0.0001
[2025-05-03 16:54:46,013][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=1.9676, lr=0.001
[2025-05-03 16:55:06,761][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=4562544.0425, lr=0.0001
[2025-05-03 16:55:13,033][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=2.6424, lr=0.001
[2025-05-03 16:55:34,596][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=19020.8781, lr=0.0001
[2025-05-03 16:55:41,023][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=1.7414, lr=0.001
[2025-05-03 16:56:01,688][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=182248.1372, lr=0.0001
[2025-05-03 16:56:08,269][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=2.6572, lr=0.001
[2025-05-03 16:56:29,596][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=26230.9246, lr=0.0001
[2025-05-03 16:56:35,411][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=3.1153, lr=0.001
[2025-05-03 16:56:56,737][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=42668.5852, lr=0.0001
[2025-05-03 16:57:03,818][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=1.3983, lr=0.001
[2025-05-03 16:57:03,833][meta_train][INFO] - epoch_3 saved !
[2025-05-03 16:57:23,747][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=3134.5796, lr=0.0001
[2025-05-03 16:57:30,430][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=0.2166, lr=0.001
[2025-05-03 16:57:52,038][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=17645.9832, lr=0.0001
[2025-05-03 16:57:52,065][meta_train][INFO] - epoch_3 saved !
[2025-05-03 16:57:58,503][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=0.7794, lr=0.001
[2025-05-03 16:58:18,461][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=78306.1652, lr=0.0001
[2025-05-03 16:58:25,119][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=0.3844, lr=0.001
[2025-05-03 16:58:46,407][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=2363.9762, lr=0.0001
[2025-05-03 16:58:52,980][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=0.6650, lr=0.001
[2025-05-03 16:59:12,739][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=23134.3579, lr=0.0001
[2025-05-03 16:59:20,859][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=0.8475, lr=0.001
[2025-05-03 16:59:40,611][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=12023.6600, lr=0.0001
[2025-05-03 16:59:47,491][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=1.3174, lr=0.001
[2025-05-03 17:00:08,362][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=758056.6053, lr=0.0001
[2025-05-03 17:00:14,881][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=1.9756, lr=0.001
[2025-05-03 17:00:34,935][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=23217.1388, lr=0.0001
[2025-05-03 17:00:42,691][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=2.3198, lr=0.001
[2025-05-03 17:00:42,713][meta_train][INFO] - epoch_4 saved !
[2025-05-03 17:01:02,155][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=9566.9353, lr=0.0001
[2025-05-03 17:01:10,466][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=2.5160, lr=0.001
[2025-05-03 17:01:29,868][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=4638.0240, lr=0.0001
[2025-05-03 17:01:29,896][meta_train][INFO] - epoch_4 saved !
[2025-05-03 17:01:37,741][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.6670, lr=0.001
[2025-05-03 17:01:57,441][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=15519.4568, lr=0.0001
[2025-05-03 17:02:05,403][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=3.5625, lr=0.001
[2025-05-03 17:02:24,659][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=530074.5566, lr=0.0001
[2025-05-03 17:02:32,850][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=4.3347, lr=0.001
[2025-05-03 17:02:52,407][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=1428.5603, lr=0.0001
[2025-05-03 17:03:00,325][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=4.6479, lr=0.001
[2025-05-03 17:03:19,729][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=31110.0492, lr=0.0001
[2025-05-03 17:03:28,058][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=4.7402, lr=0.001
[2025-05-03 17:03:46,811][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=7488.8796, lr=0.0001
[2025-05-03 17:03:54,892][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9025, lr=0.001
[2025-05-03 17:04:14,076][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=3627.4968, lr=0.0001
[2025-05-03 17:04:22,625][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.8421, lr=0.001
[2025-05-03 17:04:22,642][meta_train][INFO] - epoch_5 saved !
[2025-05-03 17:04:40,660][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=14383.0657, lr=0.0001
[2025-05-03 17:04:50,885][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=4.7108, lr=0.001
[2025-05-03 17:05:08,131][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=6344.3774, lr=0.0001
[2025-05-03 17:05:08,147][meta_train][INFO] - epoch_5 saved !
[2025-05-03 17:05:18,128][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=4.7965, lr=0.001
[2025-05-03 17:05:36,174][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6599.4916, lr=0.0001
[2025-05-03 17:05:44,407][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.6988, lr=0.001
[2025-05-03 17:06:03,236][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=393078.3798, lr=0.0001
[2025-05-03 17:06:11,392][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=4.6811, lr=0.001
[2025-05-03 17:06:38,753][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=4.7079, lr=0.001
[2025-05-03 17:06:49,085][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 5

[2025-05-03 17:06:49,140][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 17:06:49,140][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 17:06:49,140][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 17:07:06,998][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=4.7138, lr=0.001
[2025-05-03 17:07:08,720][train][INFO] - Before training : Train Acc=0.0103  Val Acc=0.0104
[2025-05-03 17:07:16,708][train][INFO] - Epoch 1/100, Val Acc=0.6050, Val Loss=1.7568, lr=0.0100
[2025-05-03 17:07:24,497][train][INFO] - Epoch 2/100, Val Acc=0.6348, Val Loss=1.5546, lr=0.0100
[2025-05-03 17:07:32,201][train][INFO] - Epoch 3/100, Val Acc=0.6369, Val Loss=1.6226, lr=0.0100
[2025-05-03 17:07:35,491][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=4.8310, lr=0.001
[2025-05-03 17:07:40,421][train][INFO] - Epoch 4/100, Val Acc=0.6386, Val Loss=1.5741, lr=0.0100
[2025-05-03 17:07:47,824][train][INFO] - Epoch 5/100, Val Acc=0.6516, Val Loss=1.5531, lr=0.0100
[2025-05-03 17:07:56,010][train][INFO] - Epoch 6/100, Val Acc=0.6542, Val Loss=1.5649, lr=0.0100
[2025-05-03 17:08:02,604][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=4.8095, lr=0.001
[2025-05-03 17:08:02,624][meta_train][INFO] - epoch_6 saved !
[2025-05-03 17:08:03,741][train][INFO] - Epoch 7/100, Val Acc=0.6628, Val Loss=1.4816, lr=0.0100
[2025-05-03 17:08:12,004][train][INFO] - Epoch 8/100, Val Acc=0.6631, Val Loss=1.4782, lr=0.0100
[2025-05-03 17:08:18,975][train][INFO] - Epoch 9/100, Val Acc=0.6472, Val Loss=1.6406, lr=0.0100
[2025-05-03 17:08:25,253][train][INFO] - Epoch 10/100, Val Acc=0.6649, Val Loss=1.5375, lr=0.0100
[2025-05-03 17:08:30,540][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.7099, lr=0.001
[2025-05-03 17:08:33,893][train][INFO] - Epoch 11/100, Val Acc=0.6431, Val Loss=1.6484, lr=0.0100
[2025-05-03 17:08:42,136][train][INFO] - Epoch 12/100, Val Acc=0.6735, Val Loss=1.4763, lr=0.0100
[2025-05-03 17:08:49,665][train][INFO] - Epoch 13/100, Val Acc=0.6615, Val Loss=1.5929, lr=0.0100
[2025-05-03 17:08:57,503][train][INFO] - Epoch 14/100, Val Acc=0.6650, Val Loss=1.5490, lr=0.0100
[2025-05-03 17:08:58,875][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=4.7228, lr=0.001
[2025-05-03 17:09:05,941][train][INFO] - Epoch 15/100, Val Acc=0.6620, Val Loss=1.6012, lr=0.0100
[2025-05-03 17:09:14,270][train][INFO] - Epoch 16/100, Val Acc=0.6782, Val Loss=1.5028, lr=0.0100
[2025-05-03 17:09:21,730][train][INFO] - Epoch 17/100, Val Acc=0.6578, Val Loss=1.5883, lr=0.0100
[2025-05-03 17:09:26,728][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=4.8149, lr=0.001
[2025-05-03 17:09:29,982][train][INFO] - Epoch 18/100, Val Acc=0.6752, Val Loss=1.5057, lr=0.0100
[2025-05-03 17:09:38,071][train][INFO] - Epoch 19/100, Val Acc=0.6645, Val Loss=1.5769, lr=0.0100
[2025-05-03 17:09:45,485][train][INFO] - Epoch 20/100, Val Acc=0.6588, Val Loss=1.6407, lr=0.0100
[2025-05-03 17:09:53,339][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.8237, lr=0.001
[2025-05-03 17:09:53,546][train][INFO] - Epoch 21/100, Val Acc=0.6606, Val Loss=1.6245, lr=0.0100
[2025-05-03 17:10:01,802][train][INFO] - Epoch 22/100, Val Acc=0.6686, Val Loss=1.5685, lr=0.0100
[2025-05-03 17:10:10,012][train][INFO] - Epoch 23/100, Val Acc=0.6506, Val Loss=1.6746, lr=0.0100
[2025-05-03 17:10:18,387][train][INFO] - Epoch 24/100, Val Acc=0.6688, Val Loss=1.5674, lr=0.0100
[2025-05-03 17:10:22,015][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=4.9037, lr=0.001
[2025-05-03 17:10:26,624][train][INFO] - Epoch 25/100, Val Acc=0.6807, Val Loss=1.5265, lr=0.0100
[2025-05-03 17:10:34,441][train][INFO] - Epoch 26/100, Val Acc=0.6710, Val Loss=1.5537, lr=0.0100
[2025-05-03 17:10:43,161][train][INFO] - Epoch 27/100, Val Acc=0.6695, Val Loss=1.5712, lr=0.0100
[2025-05-03 17:10:49,480][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=4.6840, lr=0.001
[2025-05-03 17:10:52,001][train][INFO] - Epoch 28/100, Val Acc=0.6595, Val Loss=1.6373, lr=0.0100
[2025-05-03 17:11:00,468][train][INFO] - Epoch 29/100, Val Acc=0.6626, Val Loss=1.6149, lr=0.0100
[2025-05-03 17:11:08,554][train][INFO] - Epoch 30/100, Val Acc=0.6607, Val Loss=1.6249, lr=0.0100
[2025-05-03 17:11:16,588][train][INFO] - Epoch 31/100, Val Acc=0.6605, Val Loss=1.6369, lr=0.0100
[2025-05-03 17:11:17,536][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=4.7416, lr=0.001
[2025-05-03 17:11:24,632][train][INFO] - Epoch 32/100, Val Acc=0.6534, Val Loss=1.6695, lr=0.0100
[2025-05-03 17:11:32,072][train][INFO] - Epoch 33/100, Val Acc=0.6609, Val Loss=1.6266, lr=0.0100
[2025-05-03 17:11:39,996][train][INFO] - Epoch 34/100, Val Acc=0.6641, Val Loss=1.6092, lr=0.0100
[2025-05-03 17:11:44,877][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=4.8092, lr=0.001
[2025-05-03 17:11:44,904][meta_train][INFO] - epoch_7 saved !
[2025-05-03 17:11:48,522][train][INFO] - Epoch 35/100, Val Acc=0.6622, Val Loss=1.6170, lr=0.0100
[2025-05-03 17:11:56,621][train][INFO] - Epoch 36/100, Val Acc=0.6547, Val Loss=1.6875, lr=0.0100
[2025-05-03 17:12:05,238][train][INFO] - Epoch 37/100, Val Acc=0.6669, Val Loss=1.5995, lr=0.0100
[2025-05-03 17:12:12,221][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=4.7404, lr=0.001
[2025-05-03 17:12:13,743][train][INFO] - Epoch 38/100, Val Acc=0.6693, Val Loss=1.6040, lr=0.0100
[2025-05-03 17:12:21,195][train][INFO] - Epoch 39/100, Val Acc=0.6592, Val Loss=1.6101, lr=0.0100
[2025-05-03 17:12:29,237][train][INFO] - Epoch 40/100, Val Acc=0.6723, Val Loss=1.5719, lr=0.0100
[2025-05-03 17:12:37,985][train][INFO] - Epoch 41/100, Val Acc=0.6754, Val Loss=1.5513, lr=0.0100
[2025-05-03 17:12:40,640][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=4.8192, lr=0.001
[2025-05-03 17:12:45,969][train][INFO] - Epoch 42/100, Val Acc=0.6784, Val Loss=1.5452, lr=0.0100
[2025-05-03 17:12:53,923][train][INFO] - Epoch 43/100, Val Acc=0.6501, Val Loss=1.6867, lr=0.0100
[2025-05-03 17:13:02,393][train][INFO] - Epoch 44/100, Val Acc=0.6666, Val Loss=1.6070, lr=0.0100
[2025-05-03 17:13:09,333][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.7949, lr=0.001
[2025-05-03 17:13:10,890][train][INFO] - Epoch 45/100, Val Acc=0.6551, Val Loss=1.6418, lr=0.0100
[2025-05-03 17:13:19,104][train][INFO] - Epoch 46/100, Val Acc=0.6680, Val Loss=1.5832, lr=0.0100
[2025-05-03 17:13:26,643][train][INFO] - Epoch 47/100, Val Acc=0.6629, Val Loss=1.5997, lr=0.0100
[2025-05-03 17:13:34,818][train][INFO] - Epoch 48/100, Val Acc=0.6738, Val Loss=1.5701, lr=0.0100
[2025-05-03 17:13:36,316][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.7062, lr=0.001
[2025-05-03 17:13:43,288][train][INFO] - Epoch 49/100, Val Acc=0.6635, Val Loss=1.6002, lr=0.0100
[2025-05-03 17:13:50,742][train][INFO] - Epoch 50/100, Val Acc=0.6732, Val Loss=1.5604, lr=0.0100
[2025-05-03 17:13:59,077][train][INFO] - Epoch 51/100, Val Acc=0.6609, Val Loss=1.6477, lr=0.0100
[2025-05-03 17:14:04,701][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=4.6612, lr=0.001
[2025-05-03 17:14:06,976][train][INFO] - Epoch 52/100, Val Acc=0.6388, Val Loss=1.7610, lr=0.0100
[2025-05-03 17:14:15,653][train][INFO] - Epoch 53/100, Val Acc=0.6662, Val Loss=1.5645, lr=0.0100
[2025-05-03 17:14:24,114][train][INFO] - Epoch 54/100, Val Acc=0.6725, Val Loss=1.5711, lr=0.0100
[2025-05-03 17:14:31,144][train][INFO] - Epoch 55/100, Val Acc=0.6675, Val Loss=1.6549, lr=0.0100
[2025-05-03 17:14:32,754][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=4.6276, lr=0.001
[2025-05-03 17:14:39,613][train][INFO] - Epoch 56/100, Val Acc=0.6673, Val Loss=1.6185, lr=0.0100
[2025-05-03 17:14:48,058][train][INFO] - Epoch 57/100, Val Acc=0.6670, Val Loss=1.6117, lr=0.0100
[2025-05-03 17:14:55,949][train][INFO] - Epoch 58/100, Val Acc=0.6664, Val Loss=1.6062, lr=0.0100
[2025-05-03 17:14:58,875][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7618, lr=0.001
[2025-05-03 17:15:03,224][train][INFO] - Epoch 59/100, Val Acc=0.6630, Val Loss=1.6033, lr=0.0100
[2025-05-03 17:15:10,007][train][INFO] - Epoch 60/100, Val Acc=0.6718, Val Loss=1.5724, lr=0.0100
[2025-05-03 17:15:17,538][train][INFO] - Epoch 61/100, Val Acc=0.7193, Val Loss=1.3298, lr=0.0010
[2025-05-03 17:15:25,689][train][INFO] - Epoch 62/100, Val Acc=0.7225, Val Loss=1.3209, lr=0.0010
[2025-05-03 17:15:26,872][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=4.6862, lr=0.001
[2025-05-03 17:15:26,891][meta_train][INFO] - epoch_8 saved !
[2025-05-03 17:15:34,195][train][INFO] - Epoch 63/100, Val Acc=0.7243, Val Loss=1.3333, lr=0.0010
[2025-05-03 17:15:41,597][train][INFO] - Epoch 64/100, Val Acc=0.7283, Val Loss=1.3401, lr=0.0010
[2025-05-03 17:15:48,998][train][INFO] - Epoch 65/100, Val Acc=0.7276, Val Loss=1.3462, lr=0.0010
[2025-05-03 17:15:54,324][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=4.6149, lr=0.001
[2025-05-03 17:15:56,791][train][INFO] - Epoch 66/100, Val Acc=0.7271, Val Loss=1.3475, lr=0.0010
[2025-05-03 17:16:05,093][train][INFO] - Epoch 67/100, Val Acc=0.7299, Val Loss=1.3534, lr=0.0010
[2025-05-03 17:16:12,584][train][INFO] - Epoch 68/100, Val Acc=0.7291, Val Loss=1.3499, lr=0.0010
[2025-05-03 17:16:20,698][train][INFO] - Epoch 69/100, Val Acc=0.7297, Val Loss=1.3615, lr=0.0010
[2025-05-03 17:16:21,864][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=4.6998, lr=0.001
[2025-05-03 17:16:28,531][train][INFO] - Epoch 70/100, Val Acc=0.7289, Val Loss=1.3618, lr=0.0010
[2025-05-03 17:16:36,562][train][INFO] - Epoch 71/100, Val Acc=0.7295, Val Loss=1.3624, lr=0.0010
[2025-05-03 17:16:44,429][train][INFO] - Epoch 72/100, Val Acc=0.7314, Val Loss=1.3627, lr=0.0010
[2025-05-03 17:16:50,194][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=4.6121, lr=0.001
[2025-05-03 17:16:52,936][train][INFO] - Epoch 73/100, Val Acc=0.7305, Val Loss=1.3622, lr=0.0010
[2025-05-03 17:17:00,483][train][INFO] - Epoch 74/100, Val Acc=0.7311, Val Loss=1.3660, lr=0.0010
[2025-05-03 17:17:08,502][train][INFO] - Epoch 75/100, Val Acc=0.7318, Val Loss=1.3690, lr=0.0010
[2025-05-03 17:17:16,510][train][INFO] - Epoch 76/100, Val Acc=0.7322, Val Loss=1.3641, lr=0.0010
[2025-05-03 17:17:16,541][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7445, lr=0.001
[2025-05-03 17:17:23,585][train][INFO] - Epoch 77/100, Val Acc=0.7314, Val Loss=1.3639, lr=0.0010
[2025-05-03 17:17:31,526][train][INFO] - Epoch 78/100, Val Acc=0.7322, Val Loss=1.3733, lr=0.0010
[2025-05-03 17:17:40,199][train][INFO] - Epoch 79/100, Val Acc=0.7315, Val Loss=1.3742, lr=0.0010
[2025-05-03 17:17:44,406][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.6376, lr=0.001
[2025-05-03 17:17:48,845][train][INFO] - Epoch 80/100, Val Acc=0.7338, Val Loss=1.3691, lr=0.0010
[2025-05-03 17:17:56,838][train][INFO] - Epoch 81/100, Val Acc=0.7319, Val Loss=1.3786, lr=0.0010
[2025-05-03 17:18:04,707][train][INFO] - Epoch 82/100, Val Acc=0.7327, Val Loss=1.3801, lr=0.0010
[2025-05-03 17:18:12,432][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=4.6565, lr=0.001
[2025-05-03 17:18:13,373][train][INFO] - Epoch 83/100, Val Acc=0.7326, Val Loss=1.3833, lr=0.0010
[2025-05-03 17:18:20,487][train][INFO] - Epoch 84/100, Val Acc=0.7321, Val Loss=1.3815, lr=0.0010
[2025-05-03 17:18:28,562][train][INFO] - Epoch 85/100, Val Acc=0.7323, Val Loss=1.3759, lr=0.0010
[2025-05-03 17:18:36,254][train][INFO] - Epoch 86/100, Val Acc=0.7319, Val Loss=1.3809, lr=0.0010
[2025-05-03 17:18:40,793][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=4.7008, lr=0.001
[2025-05-03 17:18:44,170][train][INFO] - Epoch 87/100, Val Acc=0.7322, Val Loss=1.3743, lr=0.0010
[2025-05-03 17:18:52,722][train][INFO] - Epoch 88/100, Val Acc=0.7324, Val Loss=1.3733, lr=0.0010
[2025-05-03 17:19:01,009][train][INFO] - Epoch 89/100, Val Acc=0.7344, Val Loss=1.3705, lr=0.0010
[2025-05-03 17:19:08,195][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.6102, lr=0.001
[2025-05-03 17:19:08,216][meta_train][INFO] - epoch_9 saved !
[2025-05-03 17:19:09,149][train][INFO] - Epoch 90/100, Val Acc=0.7327, Val Loss=1.3757, lr=0.0010
[2025-05-03 17:19:16,780][train][INFO] - Epoch 91/100, Val Acc=0.7327, Val Loss=1.3713, lr=0.0001
[2025-05-03 17:19:25,167][train][INFO] - Epoch 92/100, Val Acc=0.7341, Val Loss=1.3730, lr=0.0001
[2025-05-03 17:19:32,829][train][INFO] - Epoch 93/100, Val Acc=0.7329, Val Loss=1.3697, lr=0.0001
[2025-05-03 17:19:36,609][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=4.6063, lr=0.001
[2025-05-03 17:19:40,547][train][INFO] - Epoch 94/100, Val Acc=0.7342, Val Loss=1.3673, lr=0.0001
[2025-05-03 17:19:48,978][train][INFO] - Epoch 95/100, Val Acc=0.7332, Val Loss=1.3742, lr=0.0001
[2025-05-03 17:19:57,465][train][INFO] - Epoch 96/100, Val Acc=0.7330, Val Loss=1.3696, lr=0.0001
[2025-05-03 17:20:04,756][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=4.6055, lr=0.001
[2025-05-03 17:20:05,208][train][INFO] - Epoch 97/100, Val Acc=0.7346, Val Loss=1.3660, lr=0.0001
[2025-05-03 17:20:13,507][train][INFO] - Epoch 98/100, Val Acc=0.7325, Val Loss=1.3727, lr=0.0001
[2025-05-03 17:20:21,317][train][INFO] - Epoch 99/100, Val Acc=0.7338, Val Loss=1.3715, lr=0.0001
[2025-05-03 17:20:29,652][train][INFO] - Epoch 100/100, Val Acc=0.7352, Val Loss=1.3667, lr=0.0001
[2025-05-03 17:20:32,112][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.6108, lr=0.001
[2025-05-03 17:20:34,558][train][INFO] - After training : Train Acc=0.9994  Val Acc=0.7352
[2025-05-03 17:20:34,563][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 17:21:00,897][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=4.6344, lr=0.001
[2025-05-03 17:21:29,410][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=4.6305, lr=0.001
[2025-05-03 17:21:56,426][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.6813, lr=0.001
[2025-05-03 17:22:12,713][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 17:22:25,368][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=4.6431, lr=0.001
[2025-05-03 17:22:53,023][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.6074, lr=0.001
[2025-05-03 17:22:53,045][meta_train][INFO] - epoch_10 saved !
[2025-05-03 17:23:21,385][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=4.6143, lr=0.0001
[2025-05-03 17:23:49,397][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.6072, lr=0.0001
[2025-05-03 17:23:53,653][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 17:23:54,119][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 17:24:17,397][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:24:44,535][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=4.6317, lr=0.0001
[2025-05-03 17:25:00,170][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-03 17:25:00,221][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 17:25:00,221][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 17:25:00,221][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 17:25:11,867][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=4.6183, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 17:25:19,435][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 17:25:27,579][train][INFO] - Epoch 1/100, Val Acc=0.3756, Val Loss=2.3983, lr=0.0100
[2025-05-03 17:25:35,277][train][INFO] - Epoch 2/100, Val Acc=0.5548, Val Loss=1.7266, lr=0.0100
[2025-05-03 17:25:38,485][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6553, lr=0.0001
[2025-05-03 17:25:42,920][train][INFO] - Epoch 3/100, Val Acc=0.6071, Val Loss=1.5652, lr=0.0100
[2025-05-03 17:25:49,895][train][INFO] - Epoch 4/100, Val Acc=0.6044, Val Loss=1.5477, lr=0.0100
[2025-05-03 17:25:57,866][train][INFO] - Epoch 5/100, Val Acc=0.6225, Val Loss=1.5335, lr=0.0100
[2025-05-03 17:26:05,547][train][INFO] - Epoch 6/100, Val Acc=0.6463, Val Loss=1.4329, lr=0.0100
[2025-05-03 17:26:07,076][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:26:14,361][train][INFO] - Epoch 7/100, Val Acc=0.6422, Val Loss=1.4390, lr=0.0100
[2025-05-03 17:26:23,073][train][INFO] - Epoch 8/100, Val Acc=0.6362, Val Loss=1.5318, lr=0.0100
[2025-05-03 17:26:30,093][train][INFO] - Epoch 9/100, Val Acc=0.6410, Val Loss=1.4812, lr=0.0100
[2025-05-03 17:26:34,924][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:26:34,963][meta_train][INFO] - epoch_11 saved !
[2025-05-03 17:26:38,247][train][INFO] - Epoch 10/100, Val Acc=0.6484, Val Loss=1.4473, lr=0.0100
[2025-05-03 17:26:46,941][train][INFO] - Epoch 11/100, Val Acc=0.6606, Val Loss=1.4222, lr=0.0100
[2025-05-03 17:26:54,966][train][INFO] - Epoch 12/100, Val Acc=0.6562, Val Loss=1.4500, lr=0.0100
[2025-05-03 17:27:02,438][train][INFO] - Epoch 13/100, Val Acc=0.6402, Val Loss=1.5633, lr=0.0100
[2025-05-03 17:27:02,517][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=4.6116, lr=0.0001
[2025-05-03 17:27:10,506][train][INFO] - Epoch 14/100, Val Acc=0.6688, Val Loss=1.4084, lr=0.0100
[2025-05-03 17:27:18,647][train][INFO] - Epoch 15/100, Val Acc=0.6634, Val Loss=1.4742, lr=0.0100
[2025-05-03 17:27:26,739][train][INFO] - Epoch 16/100, Val Acc=0.6508, Val Loss=1.5098, lr=0.0100
[2025-05-03 17:27:30,524][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:27:35,250][train][INFO] - Epoch 17/100, Val Acc=0.6597, Val Loss=1.5001, lr=0.0100
[2025-05-03 17:27:43,728][train][INFO] - Epoch 18/100, Val Acc=0.6610, Val Loss=1.5021, lr=0.0100
[2025-05-03 17:27:51,879][train][INFO] - Epoch 19/100, Val Acc=0.6630, Val Loss=1.4726, lr=0.0100
[2025-05-03 17:27:57,810][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=4.6278, lr=0.0001
[2025-05-03 17:28:00,256][train][INFO] - Epoch 20/100, Val Acc=0.6662, Val Loss=1.4845, lr=0.0100
[2025-05-03 17:28:08,663][train][INFO] - Epoch 21/100, Val Acc=0.6468, Val Loss=1.6116, lr=0.0100
[2025-05-03 17:28:16,413][train][INFO] - Epoch 22/100, Val Acc=0.6482, Val Loss=1.5965, lr=0.0100
[2025-05-03 17:28:24,878][train][INFO] - Epoch 23/100, Val Acc=0.6558, Val Loss=1.5795, lr=0.0100
[2025-05-03 17:28:25,457][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.6065, lr=0.0001
[2025-05-03 17:28:32,692][train][INFO] - Epoch 24/100, Val Acc=0.6712, Val Loss=1.4950, lr=0.0100
[2025-05-03 17:28:40,656][train][INFO] - Epoch 25/100, Val Acc=0.6642, Val Loss=1.5024, lr=0.0100
[2025-05-03 17:28:48,769][train][INFO] - Epoch 26/100, Val Acc=0.6583, Val Loss=1.5540, lr=0.0100
[2025-05-03 17:28:52,547][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.6484, lr=0.0001
[2025-05-03 17:28:56,947][train][INFO] - Epoch 27/100, Val Acc=0.6527, Val Loss=1.6217, lr=0.0100
[2025-05-03 17:29:05,195][train][INFO] - Epoch 28/100, Val Acc=0.6695, Val Loss=1.4995, lr=0.0100
[2025-05-03 17:29:12,986][train][INFO] - Epoch 29/100, Val Acc=0.6565, Val Loss=1.5698, lr=0.0100
[2025-05-03 17:29:20,746][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:29:20,764][train][INFO] - Epoch 30/100, Val Acc=0.6740, Val Loss=1.4878, lr=0.0100
[2025-05-03 17:29:28,433][train][INFO] - Epoch 31/100, Val Acc=0.6526, Val Loss=1.5919, lr=0.0100
[2025-05-03 17:29:36,885][train][INFO] - Epoch 32/100, Val Acc=0.6655, Val Loss=1.5665, lr=0.0100
[2025-05-03 17:29:44,801][train][INFO] - Epoch 33/100, Val Acc=0.6694, Val Loss=1.5428, lr=0.0100
[2025-05-03 17:29:48,854][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=4.6163, lr=0.0001
[2025-05-03 17:29:52,467][train][INFO] - Epoch 34/100, Val Acc=0.6777, Val Loss=1.4965, lr=0.0100
[2025-05-03 17:30:00,357][train][INFO] - Epoch 35/100, Val Acc=0.6641, Val Loss=1.5606, lr=0.0100
[2025-05-03 17:30:08,045][train][INFO] - Epoch 36/100, Val Acc=0.6822, Val Loss=1.4814, lr=0.0100
[2025-05-03 17:30:16,222][train][INFO] - Epoch 37/100, Val Acc=0.6676, Val Loss=1.5488, lr=0.0100
[2025-05-03 17:30:16,814][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:30:16,830][meta_train][INFO] - epoch_12 saved !
[2025-05-03 17:30:24,037][train][INFO] - Epoch 38/100, Val Acc=0.6719, Val Loss=1.5374, lr=0.0100
[2025-05-03 17:30:32,137][train][INFO] - Epoch 39/100, Val Acc=0.6483, Val Loss=1.6965, lr=0.0100
[2025-05-03 17:30:40,520][train][INFO] - Epoch 40/100, Val Acc=0.6543, Val Loss=1.5734, lr=0.0100
[2025-05-03 17:30:44,524][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=4.6107, lr=0.0001
[2025-05-03 17:30:48,848][train][INFO] - Epoch 41/100, Val Acc=0.6666, Val Loss=1.5373, lr=0.0100
[2025-05-03 17:30:56,798][train][INFO] - Epoch 42/100, Val Acc=0.6664, Val Loss=1.5564, lr=0.0100
[2025-05-03 17:31:04,976][train][INFO] - Epoch 43/100, Val Acc=0.6753, Val Loss=1.5304, lr=0.0100
[2025-05-03 17:31:12,162][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=4.6158, lr=0.0001
[2025-05-03 17:31:12,812][train][INFO] - Epoch 44/100, Val Acc=0.6626, Val Loss=1.6165, lr=0.0100
[2025-05-03 17:31:21,305][train][INFO] - Epoch 45/100, Val Acc=0.6671, Val Loss=1.5803, lr=0.0100
[2025-05-03 17:31:29,155][train][INFO] - Epoch 46/100, Val Acc=0.6629, Val Loss=1.5775, lr=0.0100
[2025-05-03 17:31:37,253][train][INFO] - Epoch 47/100, Val Acc=0.6659, Val Loss=1.5879, lr=0.0100
[2025-05-03 17:31:40,714][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:31:45,485][train][INFO] - Epoch 48/100, Val Acc=0.6606, Val Loss=1.6117, lr=0.0100
[2025-05-03 17:31:53,613][train][INFO] - Epoch 49/100, Val Acc=0.6635, Val Loss=1.5855, lr=0.0100
[2025-05-03 17:32:01,970][train][INFO] - Epoch 50/100, Val Acc=0.6706, Val Loss=1.5712, lr=0.0100
[2025-05-03 17:32:08,570][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:32:10,211][train][INFO] - Epoch 51/100, Val Acc=0.6637, Val Loss=1.5677, lr=0.0100
[2025-05-03 17:32:18,383][train][INFO] - Epoch 52/100, Val Acc=0.6699, Val Loss=1.5885, lr=0.0100
[2025-05-03 17:32:26,241][train][INFO] - Epoch 53/100, Val Acc=0.6532, Val Loss=1.6345, lr=0.0100
[2025-05-03 17:32:34,147][train][INFO] - Epoch 54/100, Val Acc=0.6490, Val Loss=1.6700, lr=0.0100
[2025-05-03 17:32:35,826][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-05-03 17:32:42,948][train][INFO] - Epoch 55/100, Val Acc=0.6707, Val Loss=1.5741, lr=0.0100
[2025-05-03 17:32:51,247][train][INFO] - Epoch 56/100, Val Acc=0.6670, Val Loss=1.5758, lr=0.0100
[2025-05-03 17:32:59,295][train][INFO] - Epoch 57/100, Val Acc=0.6568, Val Loss=1.6250, lr=0.0100
[2025-05-03 17:33:04,085][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=4.6244, lr=0.0001
[2025-05-03 17:33:07,934][train][INFO] - Epoch 58/100, Val Acc=0.6674, Val Loss=1.6248, lr=0.0100
[2025-05-03 17:33:16,519][train][INFO] - Epoch 59/100, Val Acc=0.6606, Val Loss=1.5901, lr=0.0100
[2025-05-03 17:33:24,290][train][INFO] - Epoch 60/100, Val Acc=0.6688, Val Loss=1.5756, lr=0.0100
[2025-05-03 17:33:30,820][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.6442, lr=0.0001
[2025-05-03 17:33:32,106][train][INFO] - Epoch 61/100, Val Acc=0.7243, Val Loss=1.2935, lr=0.0010
[2025-05-03 17:33:40,245][train][INFO] - Epoch 62/100, Val Acc=0.7283, Val Loss=1.2866, lr=0.0010
[2025-05-03 17:33:47,558][train][INFO] - Epoch 63/100, Val Acc=0.7298, Val Loss=1.2890, lr=0.0010
[2025-05-03 17:33:55,521][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.3054, lr=0.0010
[2025-05-03 17:33:58,767][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:33:58,800][meta_train][INFO] - epoch_13 saved !
[2025-05-03 17:34:03,483][train][INFO] - Epoch 65/100, Val Acc=0.7315, Val Loss=1.3032, lr=0.0010
[2025-05-03 17:34:11,310][train][INFO] - Epoch 66/100, Val Acc=0.7302, Val Loss=1.3071, lr=0.0010
[2025-05-03 17:34:19,499][train][INFO] - Epoch 67/100, Val Acc=0.7327, Val Loss=1.3046, lr=0.0010
[2025-05-03 17:34:26,495][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:34:27,765][train][INFO] - Epoch 68/100, Val Acc=0.7340, Val Loss=1.3021, lr=0.0010
[2025-05-03 17:34:35,725][train][INFO] - Epoch 69/100, Val Acc=0.7310, Val Loss=1.3137, lr=0.0010
[2025-05-03 17:34:44,475][train][INFO] - Epoch 70/100, Val Acc=0.7336, Val Loss=1.3185, lr=0.0010
[2025-05-03 17:34:52,193][train][INFO] - Epoch 71/100, Val Acc=0.7352, Val Loss=1.3199, lr=0.0010
[2025-05-03 17:34:55,195][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:34:59,560][train][INFO] - Epoch 72/100, Val Acc=0.7353, Val Loss=1.3226, lr=0.0010
[2025-05-03 17:35:07,702][train][INFO] - Epoch 73/100, Val Acc=0.7365, Val Loss=1.3232, lr=0.0010
[2025-05-03 17:35:15,628][train][INFO] - Epoch 74/100, Val Acc=0.7350, Val Loss=1.3184, lr=0.0010
[2025-05-03 17:35:22,188][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.6061, lr=0.0001
[2025-05-03 17:35:24,223][train][INFO] - Epoch 75/100, Val Acc=0.7328, Val Loss=1.3215, lr=0.0010
[2025-05-03 17:35:31,700][train][INFO] - Epoch 76/100, Val Acc=0.7341, Val Loss=1.3228, lr=0.0010
[2025-05-03 17:35:39,599][train][INFO] - Epoch 77/100, Val Acc=0.7328, Val Loss=1.3254, lr=0.0010
[2025-05-03 17:35:46,541][train][INFO] - Epoch 78/100, Val Acc=0.7335, Val Loss=1.3222, lr=0.0010
[2025-05-03 17:35:49,368][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6401, lr=0.0001
[2025-05-03 17:35:55,202][train][INFO] - Epoch 79/100, Val Acc=0.7318, Val Loss=1.3278, lr=0.0010
[2025-05-03 17:36:03,648][train][INFO] - Epoch 80/100, Val Acc=0.7367, Val Loss=1.3227, lr=0.0010
[2025-05-03 17:36:11,812][train][INFO] - Epoch 81/100, Val Acc=0.7345, Val Loss=1.3282, lr=0.0010
[2025-05-03 17:36:17,344][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.6141, lr=0.0001
[2025-05-03 17:36:19,876][train][INFO] - Epoch 82/100, Val Acc=0.7357, Val Loss=1.3265, lr=0.0010
[2025-05-03 17:36:27,574][train][INFO] - Epoch 83/100, Val Acc=0.7356, Val Loss=1.3277, lr=0.0010
[2025-05-03 17:36:36,065][train][INFO] - Epoch 84/100, Val Acc=0.7363, Val Loss=1.3272, lr=0.0010
[2025-05-03 17:36:43,654][train][INFO] - Epoch 85/100, Val Acc=0.7361, Val Loss=1.3293, lr=0.0010
[2025-05-03 17:36:45,275][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.6217, lr=0.0001
[2025-05-03 17:36:51,378][train][INFO] - Epoch 86/100, Val Acc=0.7368, Val Loss=1.3301, lr=0.0010
[2025-05-03 17:36:59,529][train][INFO] - Epoch 87/100, Val Acc=0.7363, Val Loss=1.3226, lr=0.0010
[2025-05-03 17:37:07,464][train][INFO] - Epoch 88/100, Val Acc=0.7369, Val Loss=1.3309, lr=0.0010
[2025-05-03 17:37:12,597][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=4.6083, lr=0.0001
[2025-05-03 17:37:15,276][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3260, lr=0.0010
[2025-05-03 17:37:22,780][train][INFO] - Epoch 90/100, Val Acc=0.7373, Val Loss=1.3367, lr=0.0010
[2025-05-03 17:37:30,943][train][INFO] - Epoch 91/100, Val Acc=0.7369, Val Loss=1.3344, lr=0.0001
[2025-05-03 17:37:39,140][train][INFO] - Epoch 92/100, Val Acc=0.7379, Val Loss=1.3341, lr=0.0001
[2025-05-03 17:37:41,112][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:37:41,142][meta_train][INFO] - epoch_14 saved !
[2025-05-03 17:37:46,769][train][INFO] - Epoch 93/100, Val Acc=0.7362, Val Loss=1.3279, lr=0.0001
[2025-05-03 17:37:55,240][train][INFO] - Epoch 94/100, Val Acc=0.7379, Val Loss=1.3258, lr=0.0001
[2025-05-03 17:38:03,183][train][INFO] - Epoch 95/100, Val Acc=0.7385, Val Loss=1.3306, lr=0.0001
[2025-05-03 17:38:09,098][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.6136, lr=0.0001
[2025-05-03 17:38:11,418][train][INFO] - Epoch 96/100, Val Acc=0.7390, Val Loss=1.3265, lr=0.0001
[2025-05-03 17:38:18,718][train][INFO] - Epoch 97/100, Val Acc=0.7380, Val Loss=1.3252, lr=0.0001
[2025-05-03 17:38:27,170][train][INFO] - Epoch 98/100, Val Acc=0.7373, Val Loss=1.3288, lr=0.0001
[2025-05-03 17:38:35,661][train][INFO] - Epoch 99/100, Val Acc=0.7372, Val Loss=1.3271, lr=0.0001
[2025-05-03 17:38:35,744][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6367, lr=0.0001
[2025-05-03 17:38:43,604][train][INFO] - Epoch 100/100, Val Acc=0.7375, Val Loss=1.3278, lr=0.0001
[2025-05-03 17:38:48,559][train][INFO] - After training : Train Acc=0.9990  Val Acc=0.7390
[2025-05-03 17:38:48,565][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 17:39:03,351][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=4.6080, lr=0.0001
[2025-05-03 17:39:31,858][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.6059, lr=0.0001
[2025-05-03 17:40:00,193][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.6200, lr=0.0001
[2025-05-03 17:40:27,808][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 17:40:28,818][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:40:56,704][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:41:25,257][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:41:25,274][meta_train][INFO] - epoch_15 saved !
[2025-05-03 17:41:54,061][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.6127, lr=0.0001
[2025-05-03 17:42:07,769][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 17:42:08,202][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 17:42:21,986][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:42:49,486][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:43:16,967][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:43:44,461][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=4.6073, lr=0.0001
[2025-05-03 17:44:11,796][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-03 17:44:39,328][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.6181, lr=0.0001
[2025-05-03 17:45:05,312][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6305, lr=0.0001
[2025-05-03 17:45:05,331][meta_train][INFO] - epoch_16 saved !
[2025-05-03 17:45:32,819][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.6118, lr=0.0001
[2025-05-03 17:46:00,216][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.6056, lr=0.0001
[2025-05-03 17:46:26,276][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6276, lr=0.0001
[2025-05-03 17:46:52,982][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=4.6065, lr=0.0001
[2025-05-03 17:47:19,987][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.6164, lr=0.0001
[2025-05-03 17:47:48,197][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:48:14,641][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:48:42,532][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:48:42,547][meta_train][INFO] - epoch_17 saved !
[2025-05-03 17:49:09,777][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:49:36,991][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-03 17:50:05,061][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:50:32,560][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6109, lr=0.0001
[2025-05-03 17:50:59,174][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:51:25,272][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6260, lr=0.0001
[2025-05-03 17:51:52,866][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.6155, lr=0.0001
[2025-05-03 17:52:20,234][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=4.6062, lr=0.0001
[2025-05-03 17:52:20,250][meta_train][INFO] - epoch_18 saved !
[2025-05-03 17:52:47,706][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:53:15,042][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6104, lr=0.0001
[2025-05-03 17:53:42,188][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=4.6061, lr=0.0001
[2025-05-03 17:54:08,724][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6227, lr=0.0001
[2025-05-03 17:54:36,125][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 17:55:02,852][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:55:31,163][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:55:58,780][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.6141, lr=0.0001
[2025-05-03 17:55:58,806][meta_train][INFO] - epoch_19 saved !
[2025-05-03 17:56:25,464][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:56:52,797][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.6139, lr=0.0001
[2025-05-03 17:57:21,040][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6098, lr=0.0001
[2025-05-03 17:57:48,133][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:58:14,149][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6214, lr=0.0001
[2025-05-03 17:58:41,712][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 17:59:07,958][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=4.6059, lr=0.0001
[2025-05-03 17:59:35,713][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 17:59:35,751][meta_train][INFO] - epoch_20 saved !
[2025-05-03 18:00:03,429][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=4.6059, lr=0.0001
[2025-05-03 18:00:30,862][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:00:58,227][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.6131, lr=0.0001
[2025-05-03 18:01:25,524][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6054, lr=0.0001
[2025-05-03 18:01:53,098][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:02:19,224][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6190, lr=0.0001
[2025-05-03 18:02:46,525][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6091, lr=0.0001
[2025-05-03 18:03:13,668][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:03:13,698][meta_train][INFO] - epoch_21 saved !
[2025-05-03 18:03:41,722][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:04:09,394][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6124, lr=0.0001
[2025-05-03 18:04:37,520][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6089, lr=0.0001
[2025-05-03 18:05:04,062][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:05:30,337][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6185, lr=0.0001
[2025-05-03 18:05:57,198][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-03 18:06:24,762][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:06:52,358][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:06:52,373][meta_train][INFO] - epoch_22 saved !
[2025-05-03 18:07:19,134][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:07:46,862][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6118, lr=0.0001
[2025-05-03 18:08:13,496][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:08:41,533][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:09:07,401][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6160, lr=0.0001
[2025-05-03 18:09:34,578][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:10:01,192][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6084, lr=0.0001
[2025-05-03 18:10:28,327][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.6055, lr=0.0001
[2025-05-03 18:10:28,343][meta_train][INFO] - epoch_23 saved !
[2025-05-03 18:10:55,589][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6084, lr=0.0001
[2025-05-03 18:11:21,383][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6157, lr=0.0001
[2025-05-03 18:11:48,437][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:12:15,852][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:12:43,483][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:13:10,227][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:13:37,615][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.6055, lr=0.0001
[2025-05-03 18:14:05,111][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6109, lr=0.0001
[2025-05-03 18:14:05,138][meta_train][INFO] - epoch_24 saved !
[2025-05-03 18:14:32,339][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6081, lr=0.0001
[2025-05-03 18:15:00,392][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6107, lr=0.0001
[2025-05-03 18:15:26,736][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 18:15:54,159][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:16:20,429][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6137, lr=0.0001
[2025-05-03 18:16:48,452][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:17:14,789][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:17:41,518][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:17:41,535][meta_train][INFO] - epoch_25 saved !
[2025-05-03 18:18:07,867][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6140, lr=0.0001
[2025-05-03 18:18:34,631][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:19:01,808][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 18:19:29,229][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6077, lr=0.0001
[2025-05-03 18:19:55,874][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:20:23,719][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6101, lr=0.0001
[2025-05-03 18:20:51,038][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:21:17,487][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:21:17,509][meta_train][INFO] - epoch_26 saved !
[2025-05-03 18:21:43,883][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:22:11,350][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:22:38,349][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:23:05,371][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.6054, lr=0.0001
[2025-05-03 18:23:31,486][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6127, lr=0.0001
[2025-05-03 18:23:57,933][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6099, lr=0.0001
[2025-05-03 18:24:25,595][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:24:52,385][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6074, lr=0.0001
[2025-05-03 18:24:52,413][meta_train][INFO] - epoch_27 saved !
[2025-05-03 18:25:20,404][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:25:47,625][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6095, lr=0.0001
[2025-05-03 18:26:14,532][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:26:41,489][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:27:08,254][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:27:35,491][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6073, lr=0.0001
[2025-05-03 18:28:02,706][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:28:28,629][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6115, lr=0.0001
[2025-05-03 18:28:28,654][meta_train][INFO] - epoch_28 saved !
[2025-05-03 18:28:55,269][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:29:22,228][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:29:49,457][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:30:16,535][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:30:43,826][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6090, lr=0.0001
[2025-05-03 18:31:09,869][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6104, lr=0.0001
[2025-05-03 18:31:37,499][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:32:04,476][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6070, lr=0.0001
[2025-05-03 18:32:04,514][meta_train][INFO] - epoch_29 saved !
[2025-05-03 18:32:32,668][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:32:58,454][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6104, lr=0.0001
[2025-05-03 18:33:25,786][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6089, lr=0.0001
[2025-05-03 18:33:52,590][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6069, lr=0.0001
[2025-05-03 18:34:20,162][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:34:46,675][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:35:13,402][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:35:41,316][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:35:41,331][meta_train][INFO] - epoch_30 saved !
[2025-05-03 18:36:07,813][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:36:35,811][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:37:03,112][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6086, lr=0.0001
[2025-05-03 18:37:15,475][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-03 18:37:15,542][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 18:37:15,542][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 18:37:15,542][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 18:37:27,089][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-03 18:37:27,160][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 18:37:27,161][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 18:37:27,161][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 18:37:30,691][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:37:35,078][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 18:37:43,731][train][INFO] - Epoch 1/100, Val Acc=0.0924, Val Loss=3.9499, lr=0.0100
[2025-05-03 18:37:47,459][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 18:37:52,144][train][INFO] - Epoch 2/100, Val Acc=0.2813, Val Loss=2.6274, lr=0.0100
[2025-05-03 18:37:55,702][train][INFO] - Epoch 1/100, Val Acc=0.2730, Val Loss=2.6716, lr=0.0100
[2025-05-03 18:37:59,019][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:38:00,225][train][INFO] - Epoch 3/100, Val Acc=0.3970, Val Loss=2.3476, lr=0.0100
[2025-05-03 18:38:03,797][train][INFO] - Epoch 2/100, Val Acc=0.4673, Val Loss=2.0022, lr=0.0100
[2025-05-03 18:38:08,271][train][INFO] - Epoch 4/100, Val Acc=0.4939, Val Loss=1.9003, lr=0.0100
[2025-05-03 18:38:11,021][train][INFO] - Epoch 3/100, Val Acc=0.5391, Val Loss=1.7415, lr=0.0100
[2025-05-03 18:38:16,281][train][INFO] - Epoch 5/100, Val Acc=0.4903, Val Loss=1.9535, lr=0.0100
[2025-05-03 18:38:18,949][train][INFO] - Epoch 4/100, Val Acc=0.5935, Val Loss=1.5126, lr=0.0100
[2025-05-03 18:38:23,918][train][INFO] - Epoch 6/100, Val Acc=0.5402, Val Loss=1.7554, lr=0.0100
[2025-05-03 18:38:26,716][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6092, lr=0.0001
[2025-05-03 18:38:27,003][train][INFO] - Epoch 5/100, Val Acc=0.5768, Val Loss=1.6727, lr=0.0100
[2025-05-03 18:38:31,543][train][INFO] - Epoch 7/100, Val Acc=0.5764, Val Loss=1.6016, lr=0.0100
[2025-05-03 18:38:34,887][train][INFO] - Epoch 6/100, Val Acc=0.6060, Val Loss=1.5505, lr=0.0100
[2025-05-03 18:38:39,570][train][INFO] - Epoch 8/100, Val Acc=0.5944, Val Loss=1.5837, lr=0.0100
[2025-05-03 18:38:43,189][train][INFO] - Epoch 7/100, Val Acc=0.6148, Val Loss=1.5178, lr=0.0100
[2025-05-03 18:38:46,891][train][INFO] - Epoch 9/100, Val Acc=0.5787, Val Loss=1.7211, lr=0.0100
[2025-05-03 18:38:50,496][train][INFO] - Epoch 8/100, Val Acc=0.6442, Val Loss=1.4149, lr=0.0100
[2025-05-03 18:38:54,696][train][INFO] - Epoch 10/100, Val Acc=0.6129, Val Loss=1.5233, lr=0.0100
[2025-05-03 18:38:55,580][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6067, lr=0.0001
[2025-05-03 18:38:58,646][train][INFO] - Epoch 9/100, Val Acc=0.6366, Val Loss=1.4372, lr=0.0100
[2025-05-03 18:39:02,915][train][INFO] - Epoch 11/100, Val Acc=0.6220, Val Loss=1.5096, lr=0.0100
[2025-05-03 18:39:06,234][train][INFO] - Epoch 10/100, Val Acc=0.6513, Val Loss=1.3716, lr=0.0100
[2025-05-03 18:39:10,574][train][INFO] - Epoch 12/100, Val Acc=0.6292, Val Loss=1.4511, lr=0.0100
[2025-05-03 18:39:14,167][train][INFO] - Epoch 11/100, Val Acc=0.6479, Val Loss=1.4248, lr=0.0100
[2025-05-03 18:39:18,695][train][INFO] - Epoch 13/100, Val Acc=0.6174, Val Loss=1.5439, lr=0.0100
[2025-05-03 18:39:22,017][train][INFO] - Epoch 12/100, Val Acc=0.6545, Val Loss=1.3844, lr=0.0100
[2025-05-03 18:39:23,189][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:39:23,215][meta_train][INFO] - epoch_31 saved !
[2025-05-03 18:39:26,740][train][INFO] - Epoch 14/100, Val Acc=0.6386, Val Loss=1.4371, lr=0.0100
[2025-05-03 18:39:29,586][train][INFO] - Epoch 13/100, Val Acc=0.6551, Val Loss=1.4031, lr=0.0100
[2025-05-03 18:39:35,161][train][INFO] - Epoch 15/100, Val Acc=0.6382, Val Loss=1.4554, lr=0.0100
[2025-05-03 18:39:37,925][train][INFO] - Epoch 14/100, Val Acc=0.6619, Val Loss=1.4064, lr=0.0100
[2025-05-03 18:39:43,354][train][INFO] - Epoch 16/100, Val Acc=0.6260, Val Loss=1.5314, lr=0.0100
[2025-05-03 18:39:45,997][train][INFO] - Epoch 15/100, Val Acc=0.6526, Val Loss=1.4617, lr=0.0100
[2025-05-03 18:39:50,653][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6091, lr=0.0001
[2025-05-03 18:39:51,242][train][INFO] - Epoch 17/100, Val Acc=0.6274, Val Loss=1.5060, lr=0.0100
[2025-05-03 18:39:53,898][train][INFO] - Epoch 16/100, Val Acc=0.6300, Val Loss=1.5648, lr=0.0100
[2025-05-03 18:39:58,678][train][INFO] - Epoch 18/100, Val Acc=0.6345, Val Loss=1.4905, lr=0.0100
[2025-05-03 18:40:01,359][train][INFO] - Epoch 17/100, Val Acc=0.6582, Val Loss=1.4165, lr=0.0100
[2025-05-03 18:40:06,257][train][INFO] - Epoch 19/100, Val Acc=0.6386, Val Loss=1.4887, lr=0.0100
[2025-05-03 18:40:09,816][train][INFO] - Epoch 18/100, Val Acc=0.6614, Val Loss=1.3902, lr=0.0100
[2025-05-03 18:40:14,473][train][INFO] - Epoch 20/100, Val Acc=0.6435, Val Loss=1.4716, lr=0.0100
[2025-05-03 18:40:16,703][train][INFO] - Epoch 19/100, Val Acc=0.6591, Val Loss=1.4540, lr=0.0100
[2025-05-03 18:40:18,478][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 18:40:22,013][train][INFO] - Epoch 21/100, Val Acc=0.6496, Val Loss=1.4615, lr=0.0100
[2025-05-03 18:40:23,823][train][INFO] - Epoch 20/100, Val Acc=0.6548, Val Loss=1.4873, lr=0.0100
[2025-05-03 18:40:29,595][train][INFO] - Epoch 22/100, Val Acc=0.6497, Val Loss=1.4719, lr=0.0100
[2025-05-03 18:40:31,729][train][INFO] - Epoch 21/100, Val Acc=0.6596, Val Loss=1.4564, lr=0.0100
[2025-05-03 18:40:37,541][train][INFO] - Epoch 23/100, Val Acc=0.6434, Val Loss=1.5289, lr=0.0100
[2025-05-03 18:40:39,680][train][INFO] - Epoch 22/100, Val Acc=0.6497, Val Loss=1.5254, lr=0.0100
[2025-05-03 18:40:45,628][train][INFO] - Epoch 24/100, Val Acc=0.6576, Val Loss=1.4195, lr=0.0100
[2025-05-03 18:40:47,928][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6082, lr=0.0001
[2025-05-03 18:40:47,968][train][INFO] - Epoch 23/100, Val Acc=0.6417, Val Loss=1.6343, lr=0.0100
[2025-05-03 18:40:54,239][train][INFO] - Epoch 25/100, Val Acc=0.6600, Val Loss=1.4256, lr=0.0100
[2025-05-03 18:40:56,051][train][INFO] - Epoch 24/100, Val Acc=0.6545, Val Loss=1.5012, lr=0.0100
[2025-05-03 18:41:02,183][train][INFO] - Epoch 26/100, Val Acc=0.6557, Val Loss=1.4682, lr=0.0100
[2025-05-03 18:41:04,063][train][INFO] - Epoch 25/100, Val Acc=0.6575, Val Loss=1.4709, lr=0.0100
[2025-05-03 18:41:09,992][train][INFO] - Epoch 27/100, Val Acc=0.6327, Val Loss=1.6046, lr=0.0100
[2025-05-03 18:41:12,020][train][INFO] - Epoch 26/100, Val Acc=0.6694, Val Loss=1.4551, lr=0.0100
[2025-05-03 18:41:15,894][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:41:17,539][train][INFO] - Epoch 28/100, Val Acc=0.6601, Val Loss=1.4745, lr=0.0100
[2025-05-03 18:41:20,151][train][INFO] - Epoch 27/100, Val Acc=0.6622, Val Loss=1.4740, lr=0.0100
[2025-05-03 18:41:24,967][train][INFO] - Epoch 29/100, Val Acc=0.6523, Val Loss=1.4858, lr=0.0100
[2025-05-03 18:41:27,219][train][INFO] - Epoch 28/100, Val Acc=0.6574, Val Loss=1.4785, lr=0.0100
[2025-05-03 18:41:32,273][train][INFO] - Epoch 30/100, Val Acc=0.6552, Val Loss=1.4672, lr=0.0100
[2025-05-03 18:41:35,238][train][INFO] - Epoch 29/100, Val Acc=0.6758, Val Loss=1.4209, lr=0.0100
[2025-05-03 18:41:40,249][train][INFO] - Epoch 31/100, Val Acc=0.6588, Val Loss=1.4786, lr=0.0100
[2025-05-03 18:41:43,157][train][INFO] - Epoch 30/100, Val Acc=0.6689, Val Loss=1.4660, lr=0.0100
[2025-05-03 18:41:44,085][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:41:46,792][train][INFO] - Epoch 32/100, Val Acc=0.6455, Val Loss=1.5646, lr=0.0100
[2025-05-03 18:41:51,598][train][INFO] - Epoch 31/100, Val Acc=0.6690, Val Loss=1.4755, lr=0.0100
[2025-05-03 18:41:55,519][train][INFO] - Epoch 33/100, Val Acc=0.6564, Val Loss=1.4975, lr=0.0100
[2025-05-03 18:42:00,127][train][INFO] - Epoch 32/100, Val Acc=0.6579, Val Loss=1.5659, lr=0.0100
[2025-05-03 18:42:03,389][train][INFO] - Epoch 34/100, Val Acc=0.6595, Val Loss=1.4764, lr=0.0100
[2025-05-03 18:42:08,212][train][INFO] - Epoch 33/100, Val Acc=0.6738, Val Loss=1.4745, lr=0.0100
[2025-05-03 18:42:11,187][train][INFO] - Epoch 35/100, Val Acc=0.6462, Val Loss=1.5576, lr=0.0100
[2025-05-03 18:42:12,963][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6066, lr=0.0001
[2025-05-03 18:42:16,402][train][INFO] - Epoch 34/100, Val Acc=0.6651, Val Loss=1.4840, lr=0.0100
[2025-05-03 18:42:18,855][train][INFO] - Epoch 36/100, Val Acc=0.6468, Val Loss=1.5397, lr=0.0100
[2025-05-03 18:42:24,513][train][INFO] - Epoch 35/100, Val Acc=0.6648, Val Loss=1.5191, lr=0.0100
[2025-05-03 18:42:27,118][train][INFO] - Epoch 37/100, Val Acc=0.6614, Val Loss=1.5007, lr=0.0100
[2025-05-03 18:42:32,143][train][INFO] - Epoch 36/100, Val Acc=0.6614, Val Loss=1.5336, lr=0.0100
[2025-05-03 18:42:34,638][train][INFO] - Epoch 38/100, Val Acc=0.6526, Val Loss=1.5176, lr=0.0100
[2025-05-03 18:42:39,717][train][INFO] - Epoch 37/100, Val Acc=0.6718, Val Loss=1.4430, lr=0.0100
[2025-05-03 18:42:41,909][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:42:42,747][train][INFO] - Epoch 39/100, Val Acc=0.6687, Val Loss=1.4466, lr=0.0100
[2025-05-03 18:42:47,553][train][INFO] - Epoch 38/100, Val Acc=0.6656, Val Loss=1.5043, lr=0.0100
[2025-05-03 18:42:50,161][train][INFO] - Epoch 40/100, Val Acc=0.6500, Val Loss=1.5475, lr=0.0100
[2025-05-03 18:42:55,668][train][INFO] - Epoch 39/100, Val Acc=0.6639, Val Loss=1.5422, lr=0.0100
[2025-05-03 18:42:58,258][train][INFO] - Epoch 41/100, Val Acc=0.6431, Val Loss=1.6052, lr=0.0100
[2025-05-03 18:43:03,153][train][INFO] - Epoch 40/100, Val Acc=0.6615, Val Loss=1.5421, lr=0.0100
[2025-05-03 18:43:06,078][train][INFO] - Epoch 42/100, Val Acc=0.6474, Val Loss=1.5762, lr=0.0100
[2025-05-03 18:43:10,007][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:43:10,033][meta_train][INFO] - epoch_32 saved !
[2025-05-03 18:43:11,594][train][INFO] - Epoch 41/100, Val Acc=0.6660, Val Loss=1.4809, lr=0.0100
[2025-05-03 18:43:14,080][train][INFO] - Epoch 43/100, Val Acc=0.6552, Val Loss=1.5581, lr=0.0100
[2025-05-03 18:43:20,032][train][INFO] - Epoch 42/100, Val Acc=0.6580, Val Loss=1.5515, lr=0.0100
[2025-05-03 18:43:22,165][train][INFO] - Epoch 44/100, Val Acc=0.6483, Val Loss=1.5976, lr=0.0100
[2025-05-03 18:43:28,266][train][INFO] - Epoch 43/100, Val Acc=0.6666, Val Loss=1.4967, lr=0.0100
[2025-05-03 18:43:29,479][train][INFO] - Epoch 45/100, Val Acc=0.6586, Val Loss=1.5523, lr=0.0100
[2025-05-03 18:43:35,764][train][INFO] - Epoch 44/100, Val Acc=0.6678, Val Loss=1.5424, lr=0.0100
[2025-05-03 18:43:37,250][train][INFO] - Epoch 46/100, Val Acc=0.6587, Val Loss=1.5354, lr=0.0100
[2025-05-03 18:43:38,636][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:43:43,386][train][INFO] - Epoch 45/100, Val Acc=0.6663, Val Loss=1.5004, lr=0.0100
[2025-05-03 18:43:45,763][train][INFO] - Epoch 47/100, Val Acc=0.6660, Val Loss=1.5151, lr=0.0100
[2025-05-03 18:43:52,008][train][INFO] - Epoch 46/100, Val Acc=0.6450, Val Loss=1.6264, lr=0.0100
[2025-05-03 18:43:53,990][train][INFO] - Epoch 48/100, Val Acc=0.6485, Val Loss=1.6061, lr=0.0100
[2025-05-03 18:44:00,291][train][INFO] - Epoch 47/100, Val Acc=0.6530, Val Loss=1.6263, lr=0.0100
[2025-05-03 18:44:02,138][train][INFO] - Epoch 49/100, Val Acc=0.6605, Val Loss=1.5589, lr=0.0100
[2025-05-03 18:44:07,356][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:44:08,546][train][INFO] - Epoch 48/100, Val Acc=0.6309, Val Loss=1.7313, lr=0.0100
[2025-05-03 18:44:10,423][train][INFO] - Epoch 50/100, Val Acc=0.6501, Val Loss=1.6010, lr=0.0100
[2025-05-03 18:44:15,975][train][INFO] - Epoch 49/100, Val Acc=0.6829, Val Loss=1.4742, lr=0.0100
[2025-05-03 18:44:19,280][train][INFO] - Epoch 51/100, Val Acc=0.6630, Val Loss=1.5037, lr=0.0100
[2025-05-03 18:44:23,938][train][INFO] - Epoch 50/100, Val Acc=0.6577, Val Loss=1.5931, lr=0.0100
[2025-05-03 18:44:27,312][train][INFO] - Epoch 52/100, Val Acc=0.6592, Val Loss=1.5398, lr=0.0100
[2025-05-03 18:44:32,093][train][INFO] - Epoch 51/100, Val Acc=0.6632, Val Loss=1.5497, lr=0.0100
[2025-05-03 18:44:35,374][train][INFO] - Epoch 53/100, Val Acc=0.6614, Val Loss=1.5592, lr=0.0100
[2025-05-03 18:44:35,707][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:44:40,055][train][INFO] - Epoch 52/100, Val Acc=0.6551, Val Loss=1.6175, lr=0.0100
[2025-05-03 18:44:43,329][train][INFO] - Epoch 54/100, Val Acc=0.6545, Val Loss=1.5663, lr=0.0100
[2025-05-03 18:44:48,131][train][INFO] - Epoch 53/100, Val Acc=0.6745, Val Loss=1.4806, lr=0.0100
[2025-05-03 18:44:51,042][train][INFO] - Epoch 55/100, Val Acc=0.6526, Val Loss=1.6012, lr=0.0100
[2025-05-03 18:44:56,039][train][INFO] - Epoch 54/100, Val Acc=0.6617, Val Loss=1.6027, lr=0.0100
[2025-05-03 18:44:59,160][train][INFO] - Epoch 56/100, Val Acc=0.6663, Val Loss=1.4856, lr=0.0100
[2025-05-03 18:45:03,967][train][INFO] - Epoch 55/100, Val Acc=0.6703, Val Loss=1.5238, lr=0.0100
[2025-05-03 18:45:04,612][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:45:07,328][train][INFO] - Epoch 57/100, Val Acc=0.6431, Val Loss=1.6120, lr=0.0100
[2025-05-03 18:45:11,905][train][INFO] - Epoch 56/100, Val Acc=0.6715, Val Loss=1.5189, lr=0.0100
[2025-05-03 18:45:15,228][train][INFO] - Epoch 58/100, Val Acc=0.6557, Val Loss=1.5472, lr=0.0100
[2025-05-03 18:45:19,555][train][INFO] - Epoch 57/100, Val Acc=0.6648, Val Loss=1.5348, lr=0.0100
[2025-05-03 18:45:22,893][train][INFO] - Epoch 59/100, Val Acc=0.6491, Val Loss=1.5939, lr=0.0100
[2025-05-03 18:45:27,613][train][INFO] - Epoch 58/100, Val Acc=0.6497, Val Loss=1.6146, lr=0.0100
[2025-05-03 18:45:30,697][train][INFO] - Epoch 60/100, Val Acc=0.6707, Val Loss=1.4965, lr=0.0100
[2025-05-03 18:45:33,357][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:45:35,559][train][INFO] - Epoch 59/100, Val Acc=0.6736, Val Loss=1.4838, lr=0.0100
[2025-05-03 18:45:38,930][train][INFO] - Epoch 61/100, Val Acc=0.7191, Val Loss=1.2591, lr=0.0010
[2025-05-03 18:45:44,128][train][INFO] - Epoch 60/100, Val Acc=0.6738, Val Loss=1.5538, lr=0.0100
[2025-05-03 18:45:46,985][train][INFO] - Epoch 62/100, Val Acc=0.7238, Val Loss=1.2491, lr=0.0010
[2025-05-03 18:45:52,302][train][INFO] - Epoch 61/100, Val Acc=0.7262, Val Loss=1.2668, lr=0.0010
[2025-05-03 18:45:54,800][train][INFO] - Epoch 63/100, Val Acc=0.7204, Val Loss=1.2664, lr=0.0010
[2025-05-03 18:46:00,510][train][INFO] - Epoch 62/100, Val Acc=0.7310, Val Loss=1.2570, lr=0.0010
[2025-05-03 18:46:01,736][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6079, lr=0.0001
[2025-05-03 18:46:02,739][train][INFO] - Epoch 64/100, Val Acc=0.7235, Val Loss=1.2634, lr=0.0010
[2025-05-03 18:46:08,864][train][INFO] - Epoch 63/100, Val Acc=0.7306, Val Loss=1.2722, lr=0.0010
[2025-05-03 18:46:11,212][train][INFO] - Epoch 65/100, Val Acc=0.7267, Val Loss=1.2793, lr=0.0010
[2025-05-03 18:46:16,696][train][INFO] - Epoch 64/100, Val Acc=0.7312, Val Loss=1.2892, lr=0.0010
[2025-05-03 18:46:19,298][train][INFO] - Epoch 66/100, Val Acc=0.7243, Val Loss=1.2865, lr=0.0010
[2025-05-03 18:46:24,471][train][INFO] - Epoch 65/100, Val Acc=0.7356, Val Loss=1.2847, lr=0.0010
[2025-05-03 18:46:26,687][train][INFO] - Epoch 67/100, Val Acc=0.7279, Val Loss=1.2851, lr=0.0010
[2025-05-03 18:46:30,057][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6064, lr=0.0001
[2025-05-03 18:46:32,409][train][INFO] - Epoch 66/100, Val Acc=0.7343, Val Loss=1.2924, lr=0.0010
[2025-05-03 18:46:34,369][train][INFO] - Epoch 68/100, Val Acc=0.7278, Val Loss=1.2859, lr=0.0010
[2025-05-03 18:46:40,695][train][INFO] - Epoch 67/100, Val Acc=0.7360, Val Loss=1.2941, lr=0.0010
[2025-05-03 18:46:41,605][train][INFO] - Epoch 69/100, Val Acc=0.7293, Val Loss=1.2961, lr=0.0010
[2025-05-03 18:46:47,978][train][INFO] - Epoch 68/100, Val Acc=0.7361, Val Loss=1.2994, lr=0.0010
[2025-05-03 18:46:49,661][train][INFO] - Epoch 70/100, Val Acc=0.7287, Val Loss=1.2955, lr=0.0010
[2025-05-03 18:46:56,095][train][INFO] - Epoch 69/100, Val Acc=0.7348, Val Loss=1.3119, lr=0.0010
[2025-05-03 18:46:57,240][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6081, lr=0.0001
[2025-05-03 18:46:57,261][meta_train][INFO] - epoch_33 saved !
[2025-05-03 18:46:57,597][train][INFO] - Epoch 71/100, Val Acc=0.7273, Val Loss=1.3079, lr=0.0010
[2025-05-03 18:47:04,005][train][INFO] - Epoch 70/100, Val Acc=0.7361, Val Loss=1.3137, lr=0.0010
[2025-05-03 18:47:05,035][train][INFO] - Epoch 72/100, Val Acc=0.7243, Val Loss=1.3140, lr=0.0010
[2025-05-03 18:47:12,067][train][INFO] - Epoch 71/100, Val Acc=0.7354, Val Loss=1.3216, lr=0.0010
[2025-05-03 18:47:13,142][train][INFO] - Epoch 73/100, Val Acc=0.7262, Val Loss=1.3077, lr=0.0010
[2025-05-03 18:47:19,940][train][INFO] - Epoch 72/100, Val Acc=0.7360, Val Loss=1.3172, lr=0.0010
[2025-05-03 18:47:21,077][train][INFO] - Epoch 74/100, Val Acc=0.7281, Val Loss=1.3126, lr=0.0010
[2025-05-03 18:47:24,972][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6080, lr=0.0001
[2025-05-03 18:47:27,553][train][INFO] - Epoch 73/100, Val Acc=0.7368, Val Loss=1.3194, lr=0.0010
[2025-05-03 18:47:28,683][train][INFO] - Epoch 75/100, Val Acc=0.7267, Val Loss=1.3161, lr=0.0010
[2025-05-03 18:47:36,142][train][INFO] - Epoch 74/100, Val Acc=0.7362, Val Loss=1.3156, lr=0.0010
[2025-05-03 18:47:36,964][train][INFO] - Epoch 76/100, Val Acc=0.7277, Val Loss=1.3071, lr=0.0010
[2025-05-03 18:47:42,700][train][INFO] - Epoch 75/100, Val Acc=0.7339, Val Loss=1.3243, lr=0.0010
[2025-05-03 18:47:45,192][train][INFO] - Epoch 77/100, Val Acc=0.7284, Val Loss=1.3125, lr=0.0010
[2025-05-03 18:47:50,248][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3283, lr=0.0010
[2025-05-03 18:47:52,793][train][INFO] - Epoch 78/100, Val Acc=0.7300, Val Loss=1.3183, lr=0.0010
[2025-05-03 18:47:53,292][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6077, lr=0.0001
[2025-05-03 18:47:58,634][train][INFO] - Epoch 77/100, Val Acc=0.7370, Val Loss=1.3223, lr=0.0010
[2025-05-03 18:48:00,999][train][INFO] - Epoch 79/100, Val Acc=0.7283, Val Loss=1.3298, lr=0.0010
[2025-05-03 18:48:06,761][train][INFO] - Epoch 78/100, Val Acc=0.7367, Val Loss=1.3238, lr=0.0010
[2025-05-03 18:48:08,891][train][INFO] - Epoch 80/100, Val Acc=0.7282, Val Loss=1.3259, lr=0.0010
[2025-05-03 18:48:14,915][train][INFO] - Epoch 79/100, Val Acc=0.7323, Val Loss=1.3326, lr=0.0010
[2025-05-03 18:48:16,864][train][INFO] - Epoch 81/100, Val Acc=0.7295, Val Loss=1.3263, lr=0.0010
[2025-05-03 18:48:22,016][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6064, lr=0.0001
[2025-05-03 18:48:23,232][train][INFO] - Epoch 80/100, Val Acc=0.7340, Val Loss=1.3358, lr=0.0010
[2025-05-03 18:48:25,290][train][INFO] - Epoch 82/100, Val Acc=0.7287, Val Loss=1.3295, lr=0.0010
[2025-05-03 18:48:31,994][train][INFO] - Epoch 81/100, Val Acc=0.7344, Val Loss=1.3420, lr=0.0010
[2025-05-03 18:48:33,657][train][INFO] - Epoch 83/100, Val Acc=0.7307, Val Loss=1.3332, lr=0.0010
[2025-05-03 18:48:39,616][train][INFO] - Epoch 82/100, Val Acc=0.7356, Val Loss=1.3428, lr=0.0010
[2025-05-03 18:48:42,034][train][INFO] - Epoch 84/100, Val Acc=0.7282, Val Loss=1.3341, lr=0.0010
[2025-05-03 18:48:47,478][train][INFO] - Epoch 83/100, Val Acc=0.7359, Val Loss=1.3462, lr=0.0010
[2025-05-03 18:48:49,762][train][INFO] - Epoch 85/100, Val Acc=0.7288, Val Loss=1.3389, lr=0.0010
[2025-05-03 18:48:50,532][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:48:55,522][train][INFO] - Epoch 84/100, Val Acc=0.7354, Val Loss=1.3470, lr=0.0010
[2025-05-03 18:48:56,913][train][INFO] - Epoch 86/100, Val Acc=0.7293, Val Loss=1.3402, lr=0.0010
[2025-05-03 18:49:03,977][train][INFO] - Epoch 85/100, Val Acc=0.7367, Val Loss=1.3357, lr=0.0010
[2025-05-03 18:49:05,179][train][INFO] - Epoch 87/100, Val Acc=0.7282, Val Loss=1.3417, lr=0.0010
[2025-05-03 18:49:11,833][train][INFO] - Epoch 86/100, Val Acc=0.7352, Val Loss=1.3452, lr=0.0010
[2025-05-03 18:49:13,042][train][INFO] - Epoch 88/100, Val Acc=0.7283, Val Loss=1.3393, lr=0.0010
[2025-05-03 18:49:19,481][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:49:20,352][train][INFO] - Epoch 87/100, Val Acc=0.7348, Val Loss=1.3407, lr=0.0010
[2025-05-03 18:49:21,430][train][INFO] - Epoch 89/100, Val Acc=0.7293, Val Loss=1.3451, lr=0.0010
[2025-05-03 18:49:28,565][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3351, lr=0.0010
[2025-05-03 18:49:28,701][train][INFO] - Epoch 90/100, Val Acc=0.7286, Val Loss=1.3471, lr=0.0010
[2025-05-03 18:49:36,418][train][INFO] - Epoch 89/100, Val Acc=0.7356, Val Loss=1.3423, lr=0.0010
[2025-05-03 18:49:36,918][train][INFO] - Epoch 91/100, Val Acc=0.7302, Val Loss=1.3399, lr=0.0001
[2025-05-03 18:49:44,666][train][INFO] - Epoch 90/100, Val Acc=0.7360, Val Loss=1.3501, lr=0.0010
[2025-05-03 18:49:44,814][train][INFO] - Epoch 92/100, Val Acc=0.7301, Val Loss=1.3447, lr=0.0001
[2025-05-03 18:49:47,733][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:49:52,469][train][INFO] - Epoch 91/100, Val Acc=0.7358, Val Loss=1.3428, lr=0.0001
[2025-05-03 18:49:53,176][train][INFO] - Epoch 93/100, Val Acc=0.7290, Val Loss=1.3424, lr=0.0001
[2025-05-03 18:50:00,663][train][INFO] - Epoch 92/100, Val Acc=0.7359, Val Loss=1.3461, lr=0.0001
[2025-05-03 18:50:01,344][train][INFO] - Epoch 94/100, Val Acc=0.7307, Val Loss=1.3332, lr=0.0001
[2025-05-03 18:50:08,803][train][INFO] - Epoch 93/100, Val Acc=0.7380, Val Loss=1.3411, lr=0.0001
[2025-05-03 18:50:09,015][train][INFO] - Epoch 95/100, Val Acc=0.7297, Val Loss=1.3410, lr=0.0001
[2025-05-03 18:50:16,213][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:50:16,561][train][INFO] - Epoch 94/100, Val Acc=0.7368, Val Loss=1.3383, lr=0.0001
[2025-05-03 18:50:16,643][train][INFO] - Epoch 96/100, Val Acc=0.7288, Val Loss=1.3385, lr=0.0001
[2025-05-03 18:50:24,266][train][INFO] - Epoch 95/100, Val Acc=0.7366, Val Loss=1.3435, lr=0.0001
[2025-05-03 18:50:24,538][train][INFO] - Epoch 97/100, Val Acc=0.7279, Val Loss=1.3356, lr=0.0001
[2025-05-03 18:50:32,541][train][INFO] - Epoch 96/100, Val Acc=0.7375, Val Loss=1.3382, lr=0.0001
[2025-05-03 18:50:32,789][train][INFO] - Epoch 98/100, Val Acc=0.7300, Val Loss=1.3357, lr=0.0001
[2025-05-03 18:50:40,635][train][INFO] - Epoch 99/100, Val Acc=0.7287, Val Loss=1.3395, lr=0.0001
[2025-05-03 18:50:40,685][train][INFO] - Epoch 97/100, Val Acc=0.7366, Val Loss=1.3406, lr=0.0001
[2025-05-03 18:50:44,324][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:50:44,354][meta_train][INFO] - epoch_34 saved !
[2025-05-03 18:50:48,524][train][INFO] - Epoch 100/100, Val Acc=0.7312, Val Loss=1.3398, lr=0.0001
[2025-05-03 18:50:48,647][train][INFO] - Epoch 98/100, Val Acc=0.7381, Val Loss=1.3422, lr=0.0001
[2025-05-03 18:50:53,536][train][INFO] - After training : Train Acc=0.9982  Val Acc=0.7312
[2025-05-03 18:50:53,547][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 18:50:56,257][train][INFO] - Epoch 99/100, Val Acc=0.7392, Val Loss=1.3421, lr=0.0001
[2025-05-03 18:51:04,318][train][INFO] - Epoch 100/100, Val Acc=0.7355, Val Loss=1.3397, lr=0.0001
[2025-05-03 18:51:09,342][train][INFO] - After training : Train Acc=0.9990  Val Acc=0.7392
[2025-05-03 18:51:09,353][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 18:51:14,019][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:51:42,574][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:52:12,135][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6076, lr=0.0001
[2025-05-03 18:52:38,709][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 18:52:40,814][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:52:52,868][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 18:53:10,287][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:53:39,036][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6062, lr=0.0001
[2025-05-03 18:54:07,010][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6075, lr=0.0001
[2025-05-03 18:54:36,351][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:54:36,368][meta_train][INFO] - epoch_35 saved !
[2025-05-03 18:54:53,141][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 18:54:53,601][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 18:55:03,916][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6075, lr=0.0001
[2025-05-03 18:55:08,262][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 18:55:08,777][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 18:55:31,926][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6074, lr=0.0001
[2025-05-03 18:55:59,743][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:56:26,178][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:56:54,201][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6062, lr=0.0001
[2025-05-03 18:57:20,486][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:57:47,750][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:58:15,036][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:58:15,052][meta_train][INFO] - epoch_36 saved !
[2025-05-03 18:58:42,445][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 18:59:09,396][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6072, lr=0.0001
[2025-05-03 18:59:36,842][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6061, lr=0.0001
[2025-05-03 19:00:03,966][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:00:31,145][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:00:58,305][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:01:25,682][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:01:53,407][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6071, lr=0.0001
[2025-05-03 19:01:53,430][meta_train][INFO] - epoch_37 saved !
[2025-05-03 19:02:20,581][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:02:48,021][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:03:13,911][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6069, lr=0.0001
[2025-05-03 19:03:41,151][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:04:07,582][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:04:34,852][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:05:02,769][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6070, lr=0.0001
[2025-05-03 19:05:29,919][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:05:29,936][meta_train][INFO] - epoch_38 saved !
[2025-05-03 19:05:57,291][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:06:24,217][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:06:51,604][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:07:18,931][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6070, lr=0.0001
[2025-05-03 19:07:46,747][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:08:12,695][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6065, lr=0.0001
[2025-05-03 19:08:39,910][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:09:07,021][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:09:07,037][meta_train][INFO] - epoch_39 saved !
[2025-05-03 19:09:34,946][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6059, lr=0.0001
[2025-05-03 19:10:02,073][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:10:29,757][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6068, lr=0.0001
[2025-05-03 19:10:56,773][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:11:22,562][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6063, lr=0.0001
[2025-05-03 19:11:49,683][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:12:18,022][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:12:44,449][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:12:44,465][meta_train][INFO] - epoch_40 saved !
[2025-05-03 19:13:12,205][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:13:39,916][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:14:06,866][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:14:34,514][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6058, lr=0.0001
[2025-05-03 19:15:01,690][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:15:28,756][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6067, lr=0.0001
[2025-05-03 19:15:56,148][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:16:22,124][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6061, lr=0.0001
[2025-05-03 19:16:22,140][meta_train][INFO] - epoch_41 saved !
[2025-05-03 19:16:49,972][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6066, lr=0.0001
[2025-05-03 19:17:16,885][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:17:44,547][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:18:12,452][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:18:38,935][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:19:05,660][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:19:33,067][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:20:00,341][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6058, lr=0.0001
[2025-05-03 19:20:00,357][meta_train][INFO] - epoch_42 saved !
[2025-05-03 19:20:27,064][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:20:54,775][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:21:20,817][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:21:47,623][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:22:15,624][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-03 19:22:42,243][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:23:10,282][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:23:37,664][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6064, lr=0.0001
[2025-05-03 19:23:37,692][meta_train][INFO] - epoch_43 saved !
[2025-05-03 19:24:04,442][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6058, lr=0.0001
[2025-05-03 19:24:31,271][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:24:58,937][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:25:26,125][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6064, lr=0.0001
[2025-05-03 19:25:53,297][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:26:20,094][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:26:47,942][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6057, lr=0.0001
[2025-05-03 19:27:14,820][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:27:14,839][meta_train][INFO] - epoch_44 saved !
[2025-05-03 19:27:42,396][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:28:09,497][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:28:37,177][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6057, lr=0.0001
[2025-05-03 19:29:03,971][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:29:30,260][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-03 19:29:57,816][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6063, lr=0.0001
[2025-05-03 19:30:25,393][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:30:52,405][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:30:52,420][meta_train][INFO] - epoch_45 saved !
[2025-05-03 19:31:19,891][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:31:25,468][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-03 19:31:25,518][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 19:31:25,518][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 19:31:25,518][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 19:31:44,991][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 19:31:47,973][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6063, lr=0.0001
[2025-05-03 19:31:53,154][train][INFO] - Epoch 1/100, Val Acc=0.0628, Val Loss=3.9465, lr=0.0100
[2025-05-03 19:32:00,877][train][INFO] - Epoch 2/100, Val Acc=0.2409, Val Loss=2.8412, lr=0.0100
[2025-05-03 19:32:08,678][train][INFO] - Epoch 3/100, Val Acc=0.3140, Val Loss=2.6228, lr=0.0100
[2025-05-03 19:32:15,122][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6056, lr=0.0001
[2025-05-03 19:32:16,140][train][INFO] - Epoch 4/100, Val Acc=0.3967, Val Loss=2.2098, lr=0.0100
[2025-05-03 19:32:23,478][train][INFO] - Epoch 5/100, Val Acc=0.4572, Val Loss=2.0084, lr=0.0100
[2025-05-03 19:32:31,839][train][INFO] - Epoch 6/100, Val Acc=0.4667, Val Loss=2.0535, lr=0.0100
[2025-05-03 19:32:39,949][train][INFO] - Epoch 7/100, Val Acc=0.5403, Val Loss=1.7169, lr=0.0100
[2025-05-03 19:32:43,195][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:32:47,575][train][INFO] - Epoch 8/100, Val Acc=0.5366, Val Loss=1.7757, lr=0.0100
[2025-05-03 19:32:55,700][train][INFO] - Epoch 9/100, Val Acc=0.5476, Val Loss=1.7621, lr=0.0100
[2025-05-03 19:33:03,925][train][INFO] - Epoch 10/100, Val Acc=0.5788, Val Loss=1.6087, lr=0.0100
[2025-05-03 19:33:09,876][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:33:10,862][train][INFO] - Epoch 11/100, Val Acc=0.6044, Val Loss=1.4911, lr=0.0100
[2025-05-03 19:33:17,260][train][INFO] - Epoch 12/100, Val Acc=0.5985, Val Loss=1.5820, lr=0.0100
[2025-05-03 19:33:24,825][train][INFO] - Epoch 13/100, Val Acc=0.5849, Val Loss=1.6367, lr=0.0100
[2025-05-03 19:33:33,068][train][INFO] - Epoch 14/100, Val Acc=0.6296, Val Loss=1.4463, lr=0.0100
[2025-05-03 19:33:38,000][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:33:40,712][train][INFO] - Epoch 15/100, Val Acc=0.6188, Val Loss=1.5124, lr=0.0100
[2025-05-03 19:33:48,580][train][INFO] - Epoch 16/100, Val Acc=0.5907, Val Loss=1.6319, lr=0.0100
[2025-05-03 19:33:56,577][train][INFO] - Epoch 17/100, Val Acc=0.6213, Val Loss=1.4974, lr=0.0100
[2025-05-03 19:34:04,364][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6056, lr=0.0001
[2025-05-03 19:34:04,711][train][INFO] - Epoch 18/100, Val Acc=0.6267, Val Loss=1.4999, lr=0.0100
[2025-05-03 19:34:12,343][train][INFO] - Epoch 19/100, Val Acc=0.6205, Val Loss=1.5298, lr=0.0100
[2025-05-03 19:34:20,355][train][INFO] - Epoch 20/100, Val Acc=0.6269, Val Loss=1.5115, lr=0.0100
[2025-05-03 19:34:28,061][train][INFO] - Epoch 21/100, Val Acc=0.6204, Val Loss=1.5880, lr=0.0100
[2025-05-03 19:34:32,250][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:34:32,279][meta_train][INFO] - epoch_46 saved !
[2025-05-03 19:34:36,409][train][INFO] - Epoch 22/100, Val Acc=0.6353, Val Loss=1.5153, lr=0.0100
[2025-05-03 19:34:44,567][train][INFO] - Epoch 23/100, Val Acc=0.6271, Val Loss=1.5117, lr=0.0100
[2025-05-03 19:34:52,700][train][INFO] - Epoch 24/100, Val Acc=0.6289, Val Loss=1.6078, lr=0.0100
[2025-05-03 19:34:59,554][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6062, lr=0.0001
[2025-05-03 19:35:00,971][train][INFO] - Epoch 25/100, Val Acc=0.6409, Val Loss=1.5260, lr=0.0100
[2025-05-03 19:35:08,789][train][INFO] - Epoch 26/100, Val Acc=0.6063, Val Loss=1.7043, lr=0.0100
[2025-05-03 19:35:16,537][train][INFO] - Epoch 27/100, Val Acc=0.6130, Val Loss=1.6800, lr=0.0100
[2025-05-03 19:35:24,770][train][INFO] - Epoch 28/100, Val Acc=0.6445, Val Loss=1.5446, lr=0.0100
[2025-05-03 19:35:28,031][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:35:32,083][train][INFO] - Epoch 29/100, Val Acc=0.6401, Val Loss=1.5094, lr=0.0100
[2025-05-03 19:35:39,948][train][INFO] - Epoch 30/100, Val Acc=0.6545, Val Loss=1.4600, lr=0.0100
[2025-05-03 19:35:47,722][train][INFO] - Epoch 31/100, Val Acc=0.6496, Val Loss=1.5288, lr=0.0100
[2025-05-03 19:35:55,289][train][INFO] - Epoch 32/100, Val Acc=0.6515, Val Loss=1.5034, lr=0.0100
[2025-05-03 19:35:55,889][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6056, lr=0.0001
[2025-05-03 19:36:03,118][train][INFO] - Epoch 33/100, Val Acc=0.6498, Val Loss=1.5003, lr=0.0100
[2025-05-03 19:36:11,484][train][INFO] - Epoch 34/100, Val Acc=0.6590, Val Loss=1.4502, lr=0.0100
[2025-05-03 19:36:19,522][train][INFO] - Epoch 35/100, Val Acc=0.6498, Val Loss=1.5339, lr=0.0100
[2025-05-03 19:36:22,140][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6056, lr=0.0001
[2025-05-03 19:36:27,684][train][INFO] - Epoch 36/100, Val Acc=0.6414, Val Loss=1.5838, lr=0.0100
[2025-05-03 19:36:35,036][train][INFO] - Epoch 37/100, Val Acc=0.6295, Val Loss=1.6534, lr=0.0100
[2025-05-03 19:36:42,818][train][INFO] - Epoch 38/100, Val Acc=0.6218, Val Loss=1.6983, lr=0.0100
[2025-05-03 19:36:50,214][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:36:50,610][train][INFO] - Epoch 39/100, Val Acc=0.6405, Val Loss=1.6089, lr=0.0100
[2025-05-03 19:36:58,687][train][INFO] - Epoch 40/100, Val Acc=0.6407, Val Loss=1.5597, lr=0.0100
[2025-05-03 19:37:06,683][train][INFO] - Epoch 41/100, Val Acc=0.6287, Val Loss=1.6774, lr=0.0100
[2025-05-03 19:37:14,154][train][INFO] - Epoch 42/100, Val Acc=0.6356, Val Loss=1.6461, lr=0.0100
[2025-05-03 19:37:17,316][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:37:21,966][train][INFO] - Epoch 43/100, Val Acc=0.6277, Val Loss=1.6772, lr=0.0100
[2025-05-03 19:37:29,695][train][INFO] - Epoch 44/100, Val Acc=0.6404, Val Loss=1.5988, lr=0.0100
[2025-05-03 19:37:37,771][train][INFO] - Epoch 45/100, Val Acc=0.6418, Val Loss=1.6109, lr=0.0100
[2025-05-03 19:37:45,661][train][INFO] - Epoch 46/100, Val Acc=0.6468, Val Loss=1.5447, lr=0.0100
[2025-05-03 19:37:46,050][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:37:53,816][train][INFO] - Epoch 47/100, Val Acc=0.6547, Val Loss=1.5368, lr=0.0100
[2025-05-03 19:38:01,619][train][INFO] - Epoch 48/100, Val Acc=0.6297, Val Loss=1.6948, lr=0.0100
[2025-05-03 19:38:09,975][train][INFO] - Epoch 49/100, Val Acc=0.6432, Val Loss=1.6274, lr=0.0100
[2025-05-03 19:38:13,153][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:38:13,180][meta_train][INFO] - epoch_47 saved !
[2025-05-03 19:38:17,965][train][INFO] - Epoch 50/100, Val Acc=0.6504, Val Loss=1.5781, lr=0.0100
[2025-05-03 19:38:25,412][train][INFO] - Epoch 51/100, Val Acc=0.6337, Val Loss=1.6617, lr=0.0100
[2025-05-03 19:38:34,104][train][INFO] - Epoch 52/100, Val Acc=0.6602, Val Loss=1.5069, lr=0.0100
[2025-05-03 19:38:41,243][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6061, lr=0.0001
[2025-05-03 19:38:41,840][train][INFO] - Epoch 53/100, Val Acc=0.6549, Val Loss=1.5744, lr=0.0100
[2025-05-03 19:38:50,059][train][INFO] - Epoch 54/100, Val Acc=0.6522, Val Loss=1.5670, lr=0.0100
[2025-05-03 19:38:58,115][train][INFO] - Epoch 55/100, Val Acc=0.6612, Val Loss=1.5137, lr=0.0100
[2025-05-03 19:39:06,266][train][INFO] - Epoch 56/100, Val Acc=0.6555, Val Loss=1.5373, lr=0.0100
[2025-05-03 19:39:08,325][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:39:13,949][train][INFO] - Epoch 57/100, Val Acc=0.6415, Val Loss=1.6430, lr=0.0100
[2025-05-03 19:39:22,109][train][INFO] - Epoch 58/100, Val Acc=0.6531, Val Loss=1.5788, lr=0.0100
[2025-05-03 19:39:30,262][train][INFO] - Epoch 59/100, Val Acc=0.6416, Val Loss=1.6816, lr=0.0100
[2025-05-03 19:39:36,279][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:39:37,480][train][INFO] - Epoch 60/100, Val Acc=0.6599, Val Loss=1.5457, lr=0.0100
[2025-05-03 19:39:46,021][train][INFO] - Epoch 61/100, Val Acc=0.7130, Val Loss=1.2706, lr=0.0010
[2025-05-03 19:39:54,302][train][INFO] - Epoch 62/100, Val Acc=0.7146, Val Loss=1.2700, lr=0.0010
[2025-05-03 19:40:01,877][train][INFO] - Epoch 63/100, Val Acc=0.7181, Val Loss=1.2711, lr=0.0010
[2025-05-03 19:40:04,908][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:40:09,871][train][INFO] - Epoch 64/100, Val Acc=0.7186, Val Loss=1.2831, lr=0.0010
[2025-05-03 19:40:18,106][train][INFO] - Epoch 65/100, Val Acc=0.7182, Val Loss=1.2865, lr=0.0010
[2025-05-03 19:40:26,231][train][INFO] - Epoch 66/100, Val Acc=0.7184, Val Loss=1.2939, lr=0.0010
[2025-05-03 19:40:32,629][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:40:34,257][train][INFO] - Epoch 67/100, Val Acc=0.7165, Val Loss=1.2988, lr=0.0010
[2025-05-03 19:40:42,644][train][INFO] - Epoch 68/100, Val Acc=0.7174, Val Loss=1.3026, lr=0.0010
[2025-05-03 19:40:51,003][train][INFO] - Epoch 69/100, Val Acc=0.7166, Val Loss=1.3137, lr=0.0010
[2025-05-03 19:40:58,921][train][INFO] - Epoch 70/100, Val Acc=0.7199, Val Loss=1.3138, lr=0.0010
[2025-05-03 19:41:00,941][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6056, lr=0.0001
[2025-05-03 19:41:06,706][train][INFO] - Epoch 71/100, Val Acc=0.7201, Val Loss=1.3202, lr=0.0010
[2025-05-03 19:41:13,248][train][INFO] - Epoch 72/100, Val Acc=0.7166, Val Loss=1.3288, lr=0.0010
[2025-05-03 19:41:21,155][train][INFO] - Epoch 73/100, Val Acc=0.7189, Val Loss=1.3265, lr=0.0010
[2025-05-03 19:41:26,777][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:41:29,011][train][INFO] - Epoch 74/100, Val Acc=0.7185, Val Loss=1.3365, lr=0.0010
[2025-05-03 19:41:36,365][train][INFO] - Epoch 75/100, Val Acc=0.7178, Val Loss=1.3407, lr=0.0010
[2025-05-03 19:41:44,099][train][INFO] - Epoch 76/100, Val Acc=0.7191, Val Loss=1.3501, lr=0.0010
[2025-05-03 19:41:51,401][train][INFO] - Epoch 77/100, Val Acc=0.7191, Val Loss=1.3562, lr=0.0010
[2025-05-03 19:41:54,937][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:41:54,953][meta_train][INFO] - epoch_48 saved !
[2025-05-03 19:41:58,858][train][INFO] - Epoch 78/100, Val Acc=0.7191, Val Loss=1.3516, lr=0.0010
[2025-05-03 19:42:05,951][train][INFO] - Epoch 79/100, Val Acc=0.7204, Val Loss=1.3559, lr=0.0010
[2025-05-03 19:42:14,048][train][INFO] - Epoch 80/100, Val Acc=0.7212, Val Loss=1.3554, lr=0.0010
[2025-05-03 19:42:21,822][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:42:22,449][train][INFO] - Epoch 81/100, Val Acc=0.7193, Val Loss=1.3693, lr=0.0010
[2025-05-03 19:42:29,664][train][INFO] - Epoch 82/100, Val Acc=0.7197, Val Loss=1.3661, lr=0.0010
[2025-05-03 19:42:37,347][train][INFO] - Epoch 83/100, Val Acc=0.7218, Val Loss=1.3672, lr=0.0010
[2025-05-03 19:42:45,384][train][INFO] - Epoch 84/100, Val Acc=0.7211, Val Loss=1.3733, lr=0.0010
[2025-05-03 19:42:48,771][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:42:52,344][train][INFO] - Epoch 85/100, Val Acc=0.7212, Val Loss=1.3741, lr=0.0010
[2025-05-03 19:42:59,708][train][INFO] - Epoch 86/100, Val Acc=0.7192, Val Loss=1.3773, lr=0.0010
[2025-05-03 19:43:07,685][train][INFO] - Epoch 87/100, Val Acc=0.7219, Val Loss=1.3779, lr=0.0010
[2025-05-03 19:43:15,150][train][INFO] - Epoch 88/100, Val Acc=0.7211, Val Loss=1.3809, lr=0.0010
[2025-05-03 19:43:16,551][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:43:23,268][train][INFO] - Epoch 89/100, Val Acc=0.7195, Val Loss=1.3908, lr=0.0010
[2025-05-03 19:43:31,590][train][INFO] - Epoch 90/100, Val Acc=0.7211, Val Loss=1.3941, lr=0.0010
[2025-05-03 19:43:38,588][train][INFO] - Epoch 91/100, Val Acc=0.7211, Val Loss=1.3887, lr=0.0001
[2025-05-03 19:43:44,278][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:43:46,204][train][INFO] - Epoch 92/100, Val Acc=0.7216, Val Loss=1.3901, lr=0.0001
[2025-05-03 19:43:53,986][train][INFO] - Epoch 93/100, Val Acc=0.7223, Val Loss=1.3865, lr=0.0001
[2025-05-03 19:44:01,684][train][INFO] - Epoch 94/100, Val Acc=0.7206, Val Loss=1.3823, lr=0.0001
[2025-05-03 19:44:08,706][train][INFO] - Epoch 95/100, Val Acc=0.7203, Val Loss=1.3892, lr=0.0001
[2025-05-03 19:44:12,112][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:44:16,705][train][INFO] - Epoch 96/100, Val Acc=0.7208, Val Loss=1.3860, lr=0.0001
[2025-05-03 19:44:24,732][train][INFO] - Epoch 97/100, Val Acc=0.7213, Val Loss=1.3838, lr=0.0001
[2025-05-03 19:44:32,604][train][INFO] - Epoch 98/100, Val Acc=0.7207, Val Loss=1.3822, lr=0.0001
[2025-05-03 19:44:38,983][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:44:40,140][train][INFO] - Epoch 99/100, Val Acc=0.7212, Val Loss=1.3904, lr=0.0001
[2025-05-03 19:44:48,484][train][INFO] - Epoch 100/100, Val Acc=0.7208, Val Loss=1.3841, lr=0.0001
[2025-05-03 19:44:53,343][train][INFO] - After training : Train Acc=0.9973  Val Acc=0.7223
[2025-05-03 19:44:53,348][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 19:45:07,454][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:45:35,110][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:45:35,128][meta_train][INFO] - epoch_49 saved !
[2025-05-03 19:46:03,699][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:46:30,633][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6054, lr=0.0001
[2025-05-03 19:46:31,560][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 19:46:58,568][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6060, lr=0.0001
[2025-05-03 19:47:26,379][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:47:55,483][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:48:24,131][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:48:47,930][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 19:48:48,379][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 19:48:51,810][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:49:18,660][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:49:18,676][meta_train][INFO] - epoch_50 saved !
[2025-05-03 19:49:45,778][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:50:13,557][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:50:40,708][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:51:07,351][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:51:35,015][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6059, lr=0.0001
[2025-05-03 19:52:01,786][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:52:28,239][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6054, lr=0.0001
[2025-05-03 19:52:55,530][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:52:55,545][meta_train][INFO] - epoch_51 saved !
[2025-05-03 19:53:22,269][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:53:50,383][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:54:18,003][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6059, lr=0.0001
[2025-05-03 19:54:44,814][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:55:11,576][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:55:39,424][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:56:05,480][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6054, lr=0.0001
[2025-05-03 19:56:32,402][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:56:32,433][meta_train][INFO] - epoch_52 saved !
[2025-05-03 19:57:00,179][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 19:57:26,692][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:57:53,151][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 19:58:20,154][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:58:47,720][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:59:15,389][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 19:59:42,086][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6059, lr=0.0001
[2025-05-03 20:00:10,077][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:00:10,092][meta_train][INFO] - epoch_53 saved !
[2025-05-03 20:00:35,851][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:01:03,608][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6055, lr=0.0001
[2025-05-03 20:01:30,344][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:01:57,520][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:02:24,723][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:02:52,346][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-03 20:03:20,196][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:03:47,057][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:03:47,074][meta_train][INFO] - epoch_54 saved !
[2025-05-03 20:04:14,203][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:04:41,270][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:05:09,112][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:05:36,445][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:06:03,619][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6058, lr=0.0001
[2025-05-03 20:06:30,957][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:06:56,646][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:07:24,143][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:07:24,163][meta_train][INFO] - epoch_55 saved !
[2025-05-03 20:07:51,674][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:08:17,815][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:08:44,796][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:09:11,932][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:09:39,131][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:10:05,797][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6058, lr=0.0001
[2025-05-03 20:10:33,402][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:11:00,769][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:11:00,789][meta_train][INFO] - epoch_56 saved !
[2025-05-03 20:11:27,351][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:11:55,678][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6058, lr=0.0001
[2025-05-03 20:12:22,682][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:12:48,679][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:13:15,817][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:13:42,756][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:14:10,482][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:14:37,784][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:14:37,799][meta_train][INFO] - epoch_57 saved !
[2025-05-03 20:15:04,015][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:15:31,884][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=4.6057, lr=0.0001
[2025-05-03 20:15:59,405][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:16:26,851][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:16:54,273][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:17:21,517][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:17:48,867][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:18:15,610][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:18:15,627][meta_train][INFO] - epoch_58 saved !
[2025-05-03 20:18:42,749][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:19:06,441][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-03 20:19:06,517][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 20:19:06,517][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 20:19:06,517][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 20:19:09,288][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:19:20,545][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-03 20:19:20,626][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 20:19:20,626][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 20:19:20,626][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 20:19:25,970][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 20:19:34,440][train][INFO] - Epoch 1/100, Val Acc=0.2730, Val Loss=2.6716, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 20:19:36,559][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:19:40,657][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 20:19:43,051][train][INFO] - Epoch 2/100, Val Acc=0.4673, Val Loss=2.0022, lr=0.0100
[2025-05-03 20:19:48,995][train][INFO] - Epoch 1/100, Val Acc=0.0924, Val Loss=3.9499, lr=0.0100
[2025-05-03 20:19:51,195][train][INFO] - Epoch 3/100, Val Acc=0.5391, Val Loss=1.7415, lr=0.0100
[2025-05-03 20:19:56,616][train][INFO] - Epoch 2/100, Val Acc=0.2813, Val Loss=2.6274, lr=0.0100
[2025-05-03 20:19:59,109][train][INFO] - Epoch 4/100, Val Acc=0.5935, Val Loss=1.5126, lr=0.0100
[2025-05-03 20:20:04,775][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:20:04,781][train][INFO] - Epoch 3/100, Val Acc=0.3970, Val Loss=2.3476, lr=0.0100
[2025-05-03 20:20:06,789][train][INFO] - Epoch 5/100, Val Acc=0.5768, Val Loss=1.6727, lr=0.0100
[2025-05-03 20:20:13,009][train][INFO] - Epoch 4/100, Val Acc=0.4939, Val Loss=1.9003, lr=0.0100
[2025-05-03 20:20:15,275][train][INFO] - Epoch 6/100, Val Acc=0.6060, Val Loss=1.5505, lr=0.0100
[2025-05-03 20:20:20,363][train][INFO] - Epoch 5/100, Val Acc=0.4903, Val Loss=1.9535, lr=0.0100
[2025-05-03 20:20:23,303][train][INFO] - Epoch 7/100, Val Acc=0.6148, Val Loss=1.5178, lr=0.0100
[2025-05-03 20:20:28,109][train][INFO] - Epoch 6/100, Val Acc=0.5402, Val Loss=1.7554, lr=0.0100
[2025-05-03 20:20:31,596][train][INFO] - Epoch 8/100, Val Acc=0.6442, Val Loss=1.4149, lr=0.0100
[2025-05-03 20:20:34,115][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:20:35,834][train][INFO] - Epoch 7/100, Val Acc=0.5764, Val Loss=1.6016, lr=0.0100
[2025-05-03 20:20:39,889][train][INFO] - Epoch 9/100, Val Acc=0.6366, Val Loss=1.4372, lr=0.0100
[2025-05-03 20:20:44,215][train][INFO] - Epoch 8/100, Val Acc=0.5944, Val Loss=1.5837, lr=0.0100
[2025-05-03 20:20:47,786][train][INFO] - Epoch 10/100, Val Acc=0.6513, Val Loss=1.3716, lr=0.0100
[2025-05-03 20:20:51,738][train][INFO] - Epoch 9/100, Val Acc=0.5787, Val Loss=1.7211, lr=0.0100
[2025-05-03 20:20:55,843][train][INFO] - Epoch 11/100, Val Acc=0.6479, Val Loss=1.4248, lr=0.0100
[2025-05-03 20:20:59,615][train][INFO] - Epoch 10/100, Val Acc=0.6129, Val Loss=1.5233, lr=0.0100
[2025-05-03 20:21:01,981][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.6057, lr=0.0001
[2025-05-03 20:21:03,756][train][INFO] - Epoch 12/100, Val Acc=0.6545, Val Loss=1.3844, lr=0.0100
[2025-05-03 20:21:07,909][train][INFO] - Epoch 11/100, Val Acc=0.6220, Val Loss=1.5096, lr=0.0100
[2025-05-03 20:21:11,414][train][INFO] - Epoch 13/100, Val Acc=0.6551, Val Loss=1.4031, lr=0.0100
[2025-05-03 20:21:15,822][train][INFO] - Epoch 12/100, Val Acc=0.6292, Val Loss=1.4511, lr=0.0100
[2025-05-03 20:21:19,614][train][INFO] - Epoch 14/100, Val Acc=0.6619, Val Loss=1.4064, lr=0.0100
[2025-05-03 20:21:23,717][train][INFO] - Epoch 13/100, Val Acc=0.6174, Val Loss=1.5439, lr=0.0100
[2025-05-03 20:21:26,878][train][INFO] - Epoch 15/100, Val Acc=0.6526, Val Loss=1.4617, lr=0.0100
[2025-05-03 20:21:31,114][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:21:31,237][train][INFO] - Epoch 14/100, Val Acc=0.6386, Val Loss=1.4371, lr=0.0100
[2025-05-03 20:21:35,231][train][INFO] - Epoch 16/100, Val Acc=0.6300, Val Loss=1.5648, lr=0.0100
[2025-05-03 20:21:39,384][train][INFO] - Epoch 15/100, Val Acc=0.6382, Val Loss=1.4554, lr=0.0100
[2025-05-03 20:21:43,568][train][INFO] - Epoch 17/100, Val Acc=0.6582, Val Loss=1.4165, lr=0.0100
[2025-05-03 20:21:47,496][train][INFO] - Epoch 16/100, Val Acc=0.6260, Val Loss=1.5314, lr=0.0100
[2025-05-03 20:21:51,671][train][INFO] - Epoch 18/100, Val Acc=0.6614, Val Loss=1.3902, lr=0.0100
[2025-05-03 20:21:55,391][train][INFO] - Epoch 17/100, Val Acc=0.6274, Val Loss=1.5060, lr=0.0100
[2025-05-03 20:21:59,416][train][INFO] - Epoch 19/100, Val Acc=0.6591, Val Loss=1.4540, lr=0.0100
[2025-05-03 20:21:59,866][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:21:59,895][meta_train][INFO] - epoch_59 saved !
[2025-05-03 20:22:03,462][train][INFO] - Epoch 18/100, Val Acc=0.6345, Val Loss=1.4905, lr=0.0100
[2025-05-03 20:22:07,606][train][INFO] - Epoch 20/100, Val Acc=0.6548, Val Loss=1.4873, lr=0.0100
[2025-05-03 20:22:11,251][train][INFO] - Epoch 19/100, Val Acc=0.6386, Val Loss=1.4887, lr=0.0100
[2025-05-03 20:22:15,815][train][INFO] - Epoch 21/100, Val Acc=0.6596, Val Loss=1.4564, lr=0.0100
[2025-05-03 20:22:18,810][train][INFO] - Epoch 20/100, Val Acc=0.6435, Val Loss=1.4716, lr=0.0100
[2025-05-03 20:22:23,919][train][INFO] - Epoch 22/100, Val Acc=0.6497, Val Loss=1.5254, lr=0.0100
[2025-05-03 20:22:26,645][train][INFO] - Epoch 21/100, Val Acc=0.6496, Val Loss=1.4615, lr=0.0100
[2025-05-03 20:22:28,413][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:22:31,959][train][INFO] - Epoch 23/100, Val Acc=0.6417, Val Loss=1.6343, lr=0.0100
[2025-05-03 20:22:35,172][train][INFO] - Epoch 22/100, Val Acc=0.6497, Val Loss=1.4719, lr=0.0100
[2025-05-03 20:22:39,950][train][INFO] - Epoch 24/100, Val Acc=0.6545, Val Loss=1.5012, lr=0.0100
[2025-05-03 20:22:42,663][train][INFO] - Epoch 23/100, Val Acc=0.6434, Val Loss=1.5289, lr=0.0100
[2025-05-03 20:22:48,051][train][INFO] - Epoch 25/100, Val Acc=0.6575, Val Loss=1.4709, lr=0.0100
[2025-05-03 20:22:51,093][train][INFO] - Epoch 24/100, Val Acc=0.6576, Val Loss=1.4195, lr=0.0100
[2025-05-03 20:22:55,928][train][INFO] - Epoch 26/100, Val Acc=0.6694, Val Loss=1.4551, lr=0.0100
[2025-05-03 20:22:57,013][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:22:59,400][train][INFO] - Epoch 25/100, Val Acc=0.6600, Val Loss=1.4256, lr=0.0100
[2025-05-03 20:23:04,178][train][INFO] - Epoch 27/100, Val Acc=0.6622, Val Loss=1.4740, lr=0.0100
[2025-05-03 20:23:07,250][train][INFO] - Epoch 26/100, Val Acc=0.6557, Val Loss=1.4682, lr=0.0100
[2025-05-03 20:23:12,384][train][INFO] - Epoch 28/100, Val Acc=0.6574, Val Loss=1.4785, lr=0.0100
[2025-05-03 20:23:14,765][train][INFO] - Epoch 27/100, Val Acc=0.6327, Val Loss=1.6046, lr=0.0100
[2025-05-03 20:23:20,339][train][INFO] - Epoch 29/100, Val Acc=0.6758, Val Loss=1.4209, lr=0.0100
[2025-05-03 20:23:22,482][train][INFO] - Epoch 28/100, Val Acc=0.6601, Val Loss=1.4745, lr=0.0100
[2025-05-03 20:23:25,255][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:23:28,380][train][INFO] - Epoch 30/100, Val Acc=0.6689, Val Loss=1.4660, lr=0.0100
[2025-05-03 20:23:30,694][train][INFO] - Epoch 29/100, Val Acc=0.6523, Val Loss=1.4858, lr=0.0100
[2025-05-03 20:23:35,717][train][INFO] - Epoch 31/100, Val Acc=0.6690, Val Loss=1.4755, lr=0.0100
[2025-05-03 20:23:39,086][train][INFO] - Epoch 30/100, Val Acc=0.6552, Val Loss=1.4672, lr=0.0100
[2025-05-03 20:23:43,360][train][INFO] - Epoch 32/100, Val Acc=0.6579, Val Loss=1.5659, lr=0.0100
[2025-05-03 20:23:47,190][train][INFO] - Epoch 31/100, Val Acc=0.6588, Val Loss=1.4786, lr=0.0100
[2025-05-03 20:23:51,316][train][INFO] - Epoch 33/100, Val Acc=0.6738, Val Loss=1.4745, lr=0.0100
[2025-05-03 20:23:53,379][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:23:55,062][train][INFO] - Epoch 32/100, Val Acc=0.6455, Val Loss=1.5646, lr=0.0100
[2025-05-03 20:23:59,380][train][INFO] - Epoch 34/100, Val Acc=0.6651, Val Loss=1.4840, lr=0.0100
[2025-05-03 20:24:02,618][train][INFO] - Epoch 33/100, Val Acc=0.6564, Val Loss=1.4975, lr=0.0100
[2025-05-03 20:24:07,207][train][INFO] - Epoch 35/100, Val Acc=0.6648, Val Loss=1.5191, lr=0.0100
[2025-05-03 20:24:10,790][train][INFO] - Epoch 34/100, Val Acc=0.6595, Val Loss=1.4764, lr=0.0100
[2025-05-03 20:24:15,055][train][INFO] - Epoch 36/100, Val Acc=0.6614, Val Loss=1.5336, lr=0.0100
[2025-05-03 20:24:18,366][train][INFO] - Epoch 35/100, Val Acc=0.6462, Val Loss=1.5576, lr=0.0100
[2025-05-03 20:24:22,096][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-03 20:24:22,155][train][INFO] - Epoch 37/100, Val Acc=0.6718, Val Loss=1.4430, lr=0.0100
[2025-05-03 20:24:26,076][train][INFO] - Epoch 36/100, Val Acc=0.6468, Val Loss=1.5397, lr=0.0100
[2025-05-03 20:24:30,541][train][INFO] - Epoch 38/100, Val Acc=0.6656, Val Loss=1.5043, lr=0.0100
[2025-05-03 20:24:34,017][train][INFO] - Epoch 37/100, Val Acc=0.6614, Val Loss=1.5007, lr=0.0100
[2025-05-03 20:24:38,431][train][INFO] - Epoch 39/100, Val Acc=0.6639, Val Loss=1.5422, lr=0.0100
[2025-05-03 20:24:42,250][train][INFO] - Epoch 38/100, Val Acc=0.6526, Val Loss=1.5176, lr=0.0100
[2025-05-03 20:24:46,565][train][INFO] - Epoch 40/100, Val Acc=0.6615, Val Loss=1.5421, lr=0.0100
[2025-05-03 20:24:50,498][train][INFO] - Epoch 39/100, Val Acc=0.6687, Val Loss=1.4466, lr=0.0100
[2025-05-03 20:24:51,234][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:24:55,061][train][INFO] - Epoch 41/100, Val Acc=0.6660, Val Loss=1.4809, lr=0.0100
[2025-05-03 20:24:58,713][train][INFO] - Epoch 40/100, Val Acc=0.6500, Val Loss=1.5475, lr=0.0100
[2025-05-03 20:25:03,412][train][INFO] - Epoch 42/100, Val Acc=0.6580, Val Loss=1.5515, lr=0.0100
[2025-05-03 20:25:06,931][train][INFO] - Epoch 41/100, Val Acc=0.6431, Val Loss=1.6052, lr=0.0100
[2025-05-03 20:25:11,531][train][INFO] - Epoch 43/100, Val Acc=0.6666, Val Loss=1.4967, lr=0.0100
[2025-05-03 20:25:15,190][train][INFO] - Epoch 42/100, Val Acc=0.6474, Val Loss=1.5762, lr=0.0100
[2025-05-03 20:25:18,683][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:25:19,470][train][INFO] - Epoch 44/100, Val Acc=0.6678, Val Loss=1.5424, lr=0.0100
[2025-05-03 20:25:23,672][train][INFO] - Epoch 43/100, Val Acc=0.6552, Val Loss=1.5581, lr=0.0100
[2025-05-03 20:25:27,633][train][INFO] - Epoch 45/100, Val Acc=0.6663, Val Loss=1.5004, lr=0.0100
[2025-05-03 20:25:31,127][train][INFO] - Epoch 44/100, Val Acc=0.6483, Val Loss=1.5976, lr=0.0100
[2025-05-03 20:25:35,108][train][INFO] - Epoch 46/100, Val Acc=0.6450, Val Loss=1.6264, lr=0.0100
[2025-05-03 20:25:38,881][train][INFO] - Epoch 45/100, Val Acc=0.6586, Val Loss=1.5523, lr=0.0100
[2025-05-03 20:25:42,901][train][INFO] - Epoch 47/100, Val Acc=0.6530, Val Loss=1.6263, lr=0.0100
[2025-05-03 20:25:46,821][train][INFO] - Epoch 46/100, Val Acc=0.6587, Val Loss=1.5354, lr=0.0100
[2025-05-03 20:25:47,231][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:25:47,251][meta_train][INFO] - epoch_60 saved !
[2025-05-03 20:25:51,641][train][INFO] - Epoch 48/100, Val Acc=0.6309, Val Loss=1.7313, lr=0.0100
[2025-05-03 20:25:54,631][train][INFO] - Epoch 47/100, Val Acc=0.6660, Val Loss=1.5151, lr=0.0100
[2025-05-03 20:25:59,442][train][INFO] - Epoch 49/100, Val Acc=0.6829, Val Loss=1.4742, lr=0.0100
[2025-05-03 20:26:02,702][train][INFO] - Epoch 48/100, Val Acc=0.6485, Val Loss=1.6061, lr=0.0100
[2025-05-03 20:26:07,204][train][INFO] - Epoch 50/100, Val Acc=0.6577, Val Loss=1.5931, lr=0.0100
[2025-05-03 20:26:10,885][train][INFO] - Epoch 49/100, Val Acc=0.6605, Val Loss=1.5589, lr=0.0100
[2025-05-03 20:26:15,211][train][INFO] - Epoch 51/100, Val Acc=0.6632, Val Loss=1.5497, lr=0.0100
[2025-05-03 20:26:15,721][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:26:18,824][train][INFO] - Epoch 50/100, Val Acc=0.6501, Val Loss=1.6010, lr=0.0100
[2025-05-03 20:26:22,905][train][INFO] - Epoch 52/100, Val Acc=0.6551, Val Loss=1.6175, lr=0.0100
[2025-05-03 20:26:27,162][train][INFO] - Epoch 51/100, Val Acc=0.6630, Val Loss=1.5037, lr=0.0100
[2025-05-03 20:26:31,034][train][INFO] - Epoch 53/100, Val Acc=0.6745, Val Loss=1.4806, lr=0.0100
[2025-05-03 20:26:35,103][train][INFO] - Epoch 52/100, Val Acc=0.6592, Val Loss=1.5398, lr=0.0100
[2025-05-03 20:26:39,202][train][INFO] - Epoch 54/100, Val Acc=0.6617, Val Loss=1.6027, lr=0.0100
[2025-05-03 20:26:42,396][train][INFO] - Epoch 53/100, Val Acc=0.6614, Val Loss=1.5592, lr=0.0100
[2025-05-03 20:26:44,791][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:26:46,745][train][INFO] - Epoch 55/100, Val Acc=0.6703, Val Loss=1.5238, lr=0.0100
[2025-05-03 20:26:49,829][train][INFO] - Epoch 54/100, Val Acc=0.6545, Val Loss=1.5663, lr=0.0100
[2025-05-03 20:26:54,510][train][INFO] - Epoch 56/100, Val Acc=0.6715, Val Loss=1.5189, lr=0.0100
[2025-05-03 20:26:57,842][train][INFO] - Epoch 55/100, Val Acc=0.6526, Val Loss=1.6012, lr=0.0100
[2025-05-03 20:27:02,543][train][INFO] - Epoch 57/100, Val Acc=0.6648, Val Loss=1.5348, lr=0.0100
[2025-05-03 20:27:05,887][train][INFO] - Epoch 56/100, Val Acc=0.6663, Val Loss=1.4856, lr=0.0100
[2025-05-03 20:27:09,875][train][INFO] - Epoch 58/100, Val Acc=0.6497, Val Loss=1.6146, lr=0.0100
[2025-05-03 20:27:13,436][train][INFO] - Epoch 57/100, Val Acc=0.6431, Val Loss=1.6120, lr=0.0100
[2025-05-03 20:27:13,838][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 20:27:17,964][train][INFO] - Epoch 59/100, Val Acc=0.6736, Val Loss=1.4838, lr=0.0100
[2025-05-03 20:27:21,898][train][INFO] - Epoch 58/100, Val Acc=0.6557, Val Loss=1.5472, lr=0.0100
[2025-05-03 20:27:25,647][train][INFO] - Epoch 60/100, Val Acc=0.6738, Val Loss=1.5538, lr=0.0100
[2025-05-03 20:27:29,887][train][INFO] - Epoch 59/100, Val Acc=0.6491, Val Loss=1.5939, lr=0.0100
[2025-05-03 20:27:33,853][train][INFO] - Epoch 61/100, Val Acc=0.7262, Val Loss=1.2668, lr=0.0010
[2025-05-03 20:27:37,879][train][INFO] - Epoch 60/100, Val Acc=0.6707, Val Loss=1.4965, lr=0.0100
[2025-05-03 20:27:41,702][train][INFO] - Epoch 62/100, Val Acc=0.7310, Val Loss=1.2570, lr=0.0010
[2025-05-03 20:27:42,398][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:27:45,987][train][INFO] - Epoch 61/100, Val Acc=0.7191, Val Loss=1.2591, lr=0.0010
[2025-05-03 20:27:49,597][train][INFO] - Epoch 63/100, Val Acc=0.7306, Val Loss=1.2722, lr=0.0010
[2025-05-03 20:27:54,232][train][INFO] - Epoch 62/100, Val Acc=0.7238, Val Loss=1.2491, lr=0.0010
[2025-05-03 20:27:57,180][train][INFO] - Epoch 64/100, Val Acc=0.7312, Val Loss=1.2892, lr=0.0010
[2025-05-03 20:28:02,320][train][INFO] - Epoch 63/100, Val Acc=0.7204, Val Loss=1.2664, lr=0.0010
[2025-05-03 20:28:04,959][train][INFO] - Epoch 65/100, Val Acc=0.7356, Val Loss=1.2847, lr=0.0010
[2025-05-03 20:28:10,347][train][INFO] - Epoch 64/100, Val Acc=0.7235, Val Loss=1.2634, lr=0.0010
[2025-05-03 20:28:10,991][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.6057, lr=0.0001
[2025-05-03 20:28:12,781][train][INFO] - Epoch 66/100, Val Acc=0.7343, Val Loss=1.2924, lr=0.0010
[2025-05-03 20:28:18,498][train][INFO] - Epoch 65/100, Val Acc=0.7267, Val Loss=1.2793, lr=0.0010
[2025-05-03 20:28:21,257][train][INFO] - Epoch 67/100, Val Acc=0.7360, Val Loss=1.2941, lr=0.0010
[2025-05-03 20:28:25,301][train][INFO] - Epoch 66/100, Val Acc=0.7243, Val Loss=1.2865, lr=0.0010
[2025-05-03 20:28:27,946][train][INFO] - Epoch 68/100, Val Acc=0.7361, Val Loss=1.2994, lr=0.0010
[2025-05-03 20:28:33,053][train][INFO] - Epoch 67/100, Val Acc=0.7279, Val Loss=1.2851, lr=0.0010
[2025-05-03 20:28:36,147][train][INFO] - Epoch 69/100, Val Acc=0.7348, Val Loss=1.3119, lr=0.0010
[2025-05-03 20:28:38,163][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:28:41,212][train][INFO] - Epoch 68/100, Val Acc=0.7278, Val Loss=1.2859, lr=0.0010
[2025-05-03 20:28:44,101][train][INFO] - Epoch 70/100, Val Acc=0.7361, Val Loss=1.3137, lr=0.0010
[2025-05-03 20:28:48,671][train][INFO] - Epoch 69/100, Val Acc=0.7293, Val Loss=1.2961, lr=0.0010
[2025-05-03 20:28:52,086][train][INFO] - Epoch 71/100, Val Acc=0.7354, Val Loss=1.3216, lr=0.0010
[2025-05-03 20:28:56,860][train][INFO] - Epoch 70/100, Val Acc=0.7287, Val Loss=1.2955, lr=0.0010
[2025-05-03 20:28:59,931][train][INFO] - Epoch 72/100, Val Acc=0.7360, Val Loss=1.3172, lr=0.0010
[2025-05-03 20:29:04,823][train][INFO] - Epoch 71/100, Val Acc=0.7273, Val Loss=1.3079, lr=0.0010
[2025-05-03 20:29:06,531][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:29:07,813][train][INFO] - Epoch 73/100, Val Acc=0.7368, Val Loss=1.3194, lr=0.0010
[2025-05-03 20:29:12,797][train][INFO] - Epoch 72/100, Val Acc=0.7243, Val Loss=1.3140, lr=0.0010
[2025-05-03 20:29:16,014][train][INFO] - Epoch 74/100, Val Acc=0.7362, Val Loss=1.3156, lr=0.0010
[2025-05-03 20:29:20,970][train][INFO] - Epoch 73/100, Val Acc=0.7262, Val Loss=1.3077, lr=0.0010
[2025-05-03 20:29:23,604][train][INFO] - Epoch 75/100, Val Acc=0.7339, Val Loss=1.3243, lr=0.0010
[2025-05-03 20:29:29,044][train][INFO] - Epoch 74/100, Val Acc=0.7281, Val Loss=1.3126, lr=0.0010
[2025-05-03 20:29:31,747][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.3283, lr=0.0010
[2025-05-03 20:29:34,111][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:29:34,132][meta_train][INFO] - epoch_61 saved !
[2025-05-03 20:29:36,791][train][INFO] - Epoch 75/100, Val Acc=0.7267, Val Loss=1.3161, lr=0.0010
[2025-05-03 20:29:39,550][train][INFO] - Epoch 77/100, Val Acc=0.7370, Val Loss=1.3223, lr=0.0010
[2025-05-03 20:29:44,660][train][INFO] - Epoch 76/100, Val Acc=0.7277, Val Loss=1.3071, lr=0.0010
[2025-05-03 20:29:47,258][train][INFO] - Epoch 78/100, Val Acc=0.7367, Val Loss=1.3238, lr=0.0010
[2025-05-03 20:29:52,573][train][INFO] - Epoch 77/100, Val Acc=0.7284, Val Loss=1.3125, lr=0.0010
[2025-05-03 20:29:55,167][train][INFO] - Epoch 79/100, Val Acc=0.7323, Val Loss=1.3326, lr=0.0010
[2025-05-03 20:30:00,053][train][INFO] - Epoch 78/100, Val Acc=0.7300, Val Loss=1.3183, lr=0.0010
[2025-05-03 20:30:02,905][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:30:03,260][train][INFO] - Epoch 80/100, Val Acc=0.7340, Val Loss=1.3358, lr=0.0010
[2025-05-03 20:30:08,273][train][INFO] - Epoch 79/100, Val Acc=0.7283, Val Loss=1.3298, lr=0.0010
[2025-05-03 20:30:11,892][train][INFO] - Epoch 81/100, Val Acc=0.7344, Val Loss=1.3420, lr=0.0010
[2025-05-03 20:30:16,544][train][INFO] - Epoch 80/100, Val Acc=0.7282, Val Loss=1.3259, lr=0.0010
[2025-05-03 20:30:19,830][train][INFO] - Epoch 82/100, Val Acc=0.7356, Val Loss=1.3428, lr=0.0010
[2025-05-03 20:30:24,635][train][INFO] - Epoch 81/100, Val Acc=0.7295, Val Loss=1.3263, lr=0.0010
[2025-05-03 20:30:28,164][train][INFO] - Epoch 83/100, Val Acc=0.7359, Val Loss=1.3462, lr=0.0010
[2025-05-03 20:30:30,104][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:30:32,475][train][INFO] - Epoch 82/100, Val Acc=0.7287, Val Loss=1.3295, lr=0.0010
[2025-05-03 20:30:36,338][train][INFO] - Epoch 84/100, Val Acc=0.7354, Val Loss=1.3470, lr=0.0010
[2025-05-03 20:30:40,657][train][INFO] - Epoch 83/100, Val Acc=0.7307, Val Loss=1.3332, lr=0.0010
[2025-05-03 20:30:44,247][train][INFO] - Epoch 85/100, Val Acc=0.7367, Val Loss=1.3357, lr=0.0010
[2025-05-03 20:30:48,735][train][INFO] - Epoch 84/100, Val Acc=0.7282, Val Loss=1.3341, lr=0.0010
[2025-05-03 20:30:52,017][train][INFO] - Epoch 86/100, Val Acc=0.7352, Val Loss=1.3452, lr=0.0010
[2025-05-03 20:30:56,691][train][INFO] - Epoch 85/100, Val Acc=0.7288, Val Loss=1.3389, lr=0.0010
[2025-05-03 20:30:58,517][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.6056, lr=0.0001
[2025-05-03 20:31:00,029][train][INFO] - Epoch 87/100, Val Acc=0.7348, Val Loss=1.3407, lr=0.0010
[2025-05-03 20:31:04,953][train][INFO] - Epoch 86/100, Val Acc=0.7293, Val Loss=1.3402, lr=0.0010
[2025-05-03 20:31:08,096][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3351, lr=0.0010
[2025-05-03 20:31:12,743][train][INFO] - Epoch 87/100, Val Acc=0.7282, Val Loss=1.3417, lr=0.0010
[2025-05-03 20:31:15,928][train][INFO] - Epoch 89/100, Val Acc=0.7356, Val Loss=1.3423, lr=0.0010
[2025-05-03 20:31:20,694][train][INFO] - Epoch 88/100, Val Acc=0.7283, Val Loss=1.3393, lr=0.0010
[2025-05-03 20:31:24,213][train][INFO] - Epoch 90/100, Val Acc=0.7360, Val Loss=1.3501, lr=0.0010
[2025-05-03 20:31:26,324][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:31:28,810][train][INFO] - Epoch 89/100, Val Acc=0.7293, Val Loss=1.3451, lr=0.0010
[2025-05-03 20:31:31,755][train][INFO] - Epoch 91/100, Val Acc=0.7358, Val Loss=1.3428, lr=0.0001
[2025-05-03 20:31:36,441][train][INFO] - Epoch 90/100, Val Acc=0.7286, Val Loss=1.3471, lr=0.0010
[2025-05-03 20:31:39,807][train][INFO] - Epoch 92/100, Val Acc=0.7359, Val Loss=1.3461, lr=0.0001
[2025-05-03 20:31:44,008][train][INFO] - Epoch 91/100, Val Acc=0.7302, Val Loss=1.3399, lr=0.0001
[2025-05-03 20:31:47,924][train][INFO] - Epoch 93/100, Val Acc=0.7380, Val Loss=1.3411, lr=0.0001
[2025-05-03 20:31:52,086][train][INFO] - Epoch 92/100, Val Acc=0.7301, Val Loss=1.3447, lr=0.0001
[2025-05-03 20:31:55,707][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:31:55,981][train][INFO] - Epoch 94/100, Val Acc=0.7368, Val Loss=1.3383, lr=0.0001
[2025-05-03 20:31:59,881][train][INFO] - Epoch 93/100, Val Acc=0.7290, Val Loss=1.3424, lr=0.0001
[2025-05-03 20:32:04,560][train][INFO] - Epoch 95/100, Val Acc=0.7366, Val Loss=1.3435, lr=0.0001
[2025-05-03 20:32:08,315][train][INFO] - Epoch 94/100, Val Acc=0.7307, Val Loss=1.3332, lr=0.0001
[2025-05-03 20:32:12,620][train][INFO] - Epoch 96/100, Val Acc=0.7375, Val Loss=1.3382, lr=0.0001
[2025-05-03 20:32:16,223][train][INFO] - Epoch 95/100, Val Acc=0.7297, Val Loss=1.3410, lr=0.0001
[2025-05-03 20:32:20,279][train][INFO] - Epoch 97/100, Val Acc=0.7366, Val Loss=1.3406, lr=0.0001
[2025-05-03 20:32:23,874][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:32:23,918][train][INFO] - Epoch 96/100, Val Acc=0.7288, Val Loss=1.3385, lr=0.0001
[2025-05-03 20:32:28,187][train][INFO] - Epoch 98/100, Val Acc=0.7381, Val Loss=1.3422, lr=0.0001
[2025-05-03 20:32:31,878][train][INFO] - Epoch 97/100, Val Acc=0.7279, Val Loss=1.3356, lr=0.0001
[2025-05-03 20:32:35,963][train][INFO] - Epoch 99/100, Val Acc=0.7392, Val Loss=1.3421, lr=0.0001
[2025-05-03 20:32:39,422][train][INFO] - Epoch 98/100, Val Acc=0.7300, Val Loss=1.3357, lr=0.0001
[2025-05-03 20:32:43,819][train][INFO] - Epoch 100/100, Val Acc=0.7355, Val Loss=1.3397, lr=0.0001
[2025-05-03 20:32:47,174][train][INFO] - Epoch 99/100, Val Acc=0.7287, Val Loss=1.3395, lr=0.0001
[2025-05-03 20:32:48,918][train][INFO] - After training : Train Acc=0.9990  Val Acc=0.7392
[2025-05-03 20:32:52,298][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:32:55,323][train][INFO] - Epoch 100/100, Val Acc=0.7312, Val Loss=1.3398, lr=0.0001
[2025-05-03 20:32:56,154][Progressive pruning][INFO] - Train acc : 0.37836000323295593   Val acc : 0.2930999994277954
[2025-05-03 20:32:56,155][Progressive pruning][INFO] - Current speed up: 1.52
[2025-05-03 20:33:00,489][train][INFO] - After training : Train Acc=0.9982  Val Acc=0.7312
[2025-05-03 20:33:01,243][train][INFO] - Before training : Train Acc=0.3788  Val Acc=0.2931
[2025-05-03 20:33:09,629][train][INFO] - Epoch 1/140, Val Acc=0.5924, Val Loss=1.7895, lr=0.0100
[2025-05-03 20:33:10,049][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-03 20:33:10,049][Progressive pruning][INFO] - Current speed up: 1.51
[2025-05-03 20:33:15,109][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 20:33:17,956][train][INFO] - Epoch 2/140, Val Acc=0.6497, Val Loss=1.4461, lr=0.0100
[2025-05-03 20:33:21,472][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:33:21,490][meta_train][INFO] - epoch_62 saved !
[2025-05-03 20:33:23,592][train][INFO] - Epoch 1/140, Val Acc=0.5633, Val Loss=1.9317, lr=0.0100
[2025-05-03 20:33:25,810][train][INFO] - Epoch 3/140, Val Acc=0.6085, Val Loss=1.6960, lr=0.0100
[2025-05-03 20:33:30,921][train][INFO] - Epoch 2/140, Val Acc=0.6002, Val Loss=1.7197, lr=0.0100
[2025-05-03 20:33:34,015][train][INFO] - Epoch 4/140, Val Acc=0.6309, Val Loss=1.5775, lr=0.0100
[2025-05-03 20:33:38,913][train][INFO] - Epoch 3/140, Val Acc=0.6019, Val Loss=1.7317, lr=0.0100
[2025-05-03 20:33:42,381][train][INFO] - Epoch 5/140, Val Acc=0.6477, Val Loss=1.4973, lr=0.0100
[2025-05-03 20:33:47,104][train][INFO] - Epoch 4/140, Val Acc=0.5901, Val Loss=1.7817, lr=0.0100
[2025-05-03 20:33:50,604][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:33:50,929][train][INFO] - Epoch 6/140, Val Acc=0.6484, Val Loss=1.5382, lr=0.0100
[2025-05-03 20:33:55,360][train][INFO] - Epoch 5/140, Val Acc=0.6010, Val Loss=1.8014, lr=0.0100
[2025-05-03 20:33:58,717][train][INFO] - Epoch 7/140, Val Acc=0.6578, Val Loss=1.4642, lr=0.0100
[2025-05-03 20:34:03,009][train][INFO] - Epoch 6/140, Val Acc=0.6279, Val Loss=1.6652, lr=0.0100
[2025-05-03 20:34:05,766][train][INFO] - Epoch 8/140, Val Acc=0.6373, Val Loss=1.6138, lr=0.0100
[2025-05-03 20:34:11,144][train][INFO] - Epoch 7/140, Val Acc=0.6371, Val Loss=1.6170, lr=0.0100
[2025-05-03 20:34:13,520][train][INFO] - Epoch 9/140, Val Acc=0.6577, Val Loss=1.4811, lr=0.0100
[2025-05-03 20:34:18,451][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:34:19,195][train][INFO] - Epoch 8/140, Val Acc=0.6200, Val Loss=1.7243, lr=0.0100
[2025-05-03 20:34:21,578][train][INFO] - Epoch 10/140, Val Acc=0.6623, Val Loss=1.4795, lr=0.0100
[2025-05-03 20:34:27,842][train][INFO] - Epoch 9/140, Val Acc=0.6248, Val Loss=1.7208, lr=0.0100
[2025-05-03 20:34:29,675][train][INFO] - Epoch 11/140, Val Acc=0.6613, Val Loss=1.4748, lr=0.0100
[2025-05-03 20:34:35,911][train][INFO] - Epoch 10/140, Val Acc=0.6306, Val Loss=1.6896, lr=0.0100
[2025-05-03 20:34:37,627][train][INFO] - Epoch 12/140, Val Acc=0.6571, Val Loss=1.5163, lr=0.0100
[2025-05-03 20:34:43,827][train][INFO] - Epoch 11/140, Val Acc=0.6298, Val Loss=1.6536, lr=0.0100
[2025-05-03 20:34:45,497][train][INFO] - Epoch 13/140, Val Acc=0.6515, Val Loss=1.5333, lr=0.0100
[2025-05-03 20:34:45,842][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:34:51,781][train][INFO] - Epoch 12/140, Val Acc=0.6320, Val Loss=1.6641, lr=0.0100
[2025-05-03 20:34:54,081][train][INFO] - Epoch 14/140, Val Acc=0.6622, Val Loss=1.4813, lr=0.0100
[2025-05-03 20:35:00,043][train][INFO] - Epoch 13/140, Val Acc=0.6353, Val Loss=1.6732, lr=0.0100
[2025-05-03 20:35:02,024][train][INFO] - Epoch 15/140, Val Acc=0.6559, Val Loss=1.5376, lr=0.0100
[2025-05-03 20:35:08,309][train][INFO] - Epoch 14/140, Val Acc=0.6279, Val Loss=1.7036, lr=0.0100
[2025-05-03 20:35:10,203][train][INFO] - Epoch 16/140, Val Acc=0.6531, Val Loss=1.5718, lr=0.0100
[2025-05-03 20:35:13,729][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:35:16,568][train][INFO] - Epoch 15/140, Val Acc=0.6279, Val Loss=1.7217, lr=0.0100
[2025-05-03 20:35:18,542][train][INFO] - Epoch 17/140, Val Acc=0.6529, Val Loss=1.5576, lr=0.0100
[2025-05-03 20:35:24,883][train][INFO] - Epoch 16/140, Val Acc=0.6531, Val Loss=1.5513, lr=0.0100
[2025-05-03 20:35:26,522][train][INFO] - Epoch 18/140, Val Acc=0.6708, Val Loss=1.4533, lr=0.0100
[2025-05-03 20:35:32,890][train][INFO] - Epoch 17/140, Val Acc=0.6273, Val Loss=1.7273, lr=0.0100
[2025-05-03 20:35:34,466][train][INFO] - Epoch 19/140, Val Acc=0.6514, Val Loss=1.5584, lr=0.0100
[2025-05-03 20:35:41,012][train][INFO] - Epoch 18/140, Val Acc=0.6521, Val Loss=1.6145, lr=0.0100
[2025-05-03 20:35:42,562][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-03 20:35:42,610][train][INFO] - Epoch 20/140, Val Acc=0.6522, Val Loss=1.6127, lr=0.0100
[2025-05-03 20:35:49,109][train][INFO] - Epoch 19/140, Val Acc=0.6299, Val Loss=1.6889, lr=0.0100
[2025-05-03 20:35:50,385][train][INFO] - Epoch 21/140, Val Acc=0.6630, Val Loss=1.4987, lr=0.0100
[2025-05-03 20:35:57,566][train][INFO] - Epoch 20/140, Val Acc=0.6261, Val Loss=1.7611, lr=0.0100
[2025-05-03 20:35:58,903][train][INFO] - Epoch 22/140, Val Acc=0.6644, Val Loss=1.5129, lr=0.0100
[2025-05-03 20:36:05,214][train][INFO] - Epoch 21/140, Val Acc=0.6231, Val Loss=1.7701, lr=0.0100
[2025-05-03 20:36:05,937][train][INFO] - Epoch 23/140, Val Acc=0.6558, Val Loss=1.5379, lr=0.0100
[2025-05-03 20:36:11,357][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:36:13,387][train][INFO] - Epoch 22/140, Val Acc=0.6430, Val Loss=1.6317, lr=0.0100
[2025-05-03 20:36:13,997][train][INFO] - Epoch 24/140, Val Acc=0.6467, Val Loss=1.6023, lr=0.0100
[2025-05-03 20:36:21,208][train][INFO] - Epoch 23/140, Val Acc=0.6500, Val Loss=1.5755, lr=0.0100
[2025-05-03 20:36:21,908][train][INFO] - Epoch 25/140, Val Acc=0.6539, Val Loss=1.5745, lr=0.0100
[2025-05-03 20:36:29,380][train][INFO] - Epoch 24/140, Val Acc=0.6363, Val Loss=1.6921, lr=0.0100
[2025-05-03 20:36:30,297][train][INFO] - Epoch 26/140, Val Acc=0.6580, Val Loss=1.5620, lr=0.0100
[2025-05-03 20:36:37,867][train][INFO] - Epoch 25/140, Val Acc=0.6539, Val Loss=1.6133, lr=0.0100
[2025-05-03 20:36:38,479][train][INFO] - Epoch 27/140, Val Acc=0.6554, Val Loss=1.5644, lr=0.0100
[2025-05-03 20:36:39,846][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:36:45,706][train][INFO] - Epoch 26/140, Val Acc=0.6468, Val Loss=1.6841, lr=0.0100
[2025-05-03 20:36:46,776][train][INFO] - Epoch 28/140, Val Acc=0.6618, Val Loss=1.5254, lr=0.0100
[2025-05-03 20:36:53,807][train][INFO] - Epoch 27/140, Val Acc=0.6453, Val Loss=1.6455, lr=0.0100
[2025-05-03 20:36:55,106][train][INFO] - Epoch 29/140, Val Acc=0.6781, Val Loss=1.4558, lr=0.0100
[2025-05-03 20:37:02,485][train][INFO] - Epoch 28/140, Val Acc=0.6544, Val Loss=1.5739, lr=0.0100
[2025-05-03 20:37:03,586][train][INFO] - Epoch 30/140, Val Acc=0.6595, Val Loss=1.5466, lr=0.0100
[2025-05-03 20:37:09,065][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:37:09,101][meta_train][INFO] - epoch_63 saved !
[2025-05-03 20:37:10,771][train][INFO] - Epoch 29/140, Val Acc=0.6459, Val Loss=1.6636, lr=0.0100
[2025-05-03 20:37:11,517][train][INFO] - Epoch 31/140, Val Acc=0.6671, Val Loss=1.5283, lr=0.0100
[2025-05-03 20:37:18,398][train][INFO] - Epoch 30/140, Val Acc=0.6573, Val Loss=1.6169, lr=0.0100
[2025-05-03 20:37:20,166][train][INFO] - Epoch 32/140, Val Acc=0.6672, Val Loss=1.5134, lr=0.0100
[2025-05-03 20:37:25,974][train][INFO] - Epoch 31/140, Val Acc=0.6380, Val Loss=1.6966, lr=0.0100
[2025-05-03 20:37:28,335][train][INFO] - Epoch 33/140, Val Acc=0.6644, Val Loss=1.5335, lr=0.0100
[2025-05-03 20:37:34,081][train][INFO] - Epoch 32/140, Val Acc=0.6430, Val Loss=1.6930, lr=0.0100
[2025-05-03 20:37:36,297][train][INFO] - Epoch 34/140, Val Acc=0.6695, Val Loss=1.5155, lr=0.0100
[2025-05-03 20:37:37,981][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:37:42,644][train][INFO] - Epoch 33/140, Val Acc=0.6365, Val Loss=1.7084, lr=0.0100
[2025-05-03 20:37:44,780][train][INFO] - Epoch 35/140, Val Acc=0.6633, Val Loss=1.5170, lr=0.0100
[2025-05-03 20:37:50,628][train][INFO] - Epoch 34/140, Val Acc=0.6482, Val Loss=1.6327, lr=0.0100
[2025-05-03 20:37:53,270][train][INFO] - Epoch 36/140, Val Acc=0.6633, Val Loss=1.5620, lr=0.0100
[2025-05-03 20:37:58,780][train][INFO] - Epoch 35/140, Val Acc=0.6335, Val Loss=1.7168, lr=0.0100
[2025-05-03 20:38:01,475][train][INFO] - Epoch 37/140, Val Acc=0.6511, Val Loss=1.5827, lr=0.0100
[2025-05-03 20:38:05,678][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:38:07,118][train][INFO] - Epoch 36/140, Val Acc=0.6509, Val Loss=1.6501, lr=0.0100
[2025-05-03 20:38:09,433][train][INFO] - Epoch 38/140, Val Acc=0.6557, Val Loss=1.5649, lr=0.0100
[2025-05-03 20:38:14,826][train][INFO] - Epoch 37/140, Val Acc=0.6371, Val Loss=1.7324, lr=0.0100
[2025-05-03 20:38:17,526][train][INFO] - Epoch 39/140, Val Acc=0.6627, Val Loss=1.5340, lr=0.0100
[2025-05-03 20:38:22,706][train][INFO] - Epoch 38/140, Val Acc=0.6595, Val Loss=1.6089, lr=0.0100
[2025-05-03 20:38:25,373][train][INFO] - Epoch 40/140, Val Acc=0.6391, Val Loss=1.6914, lr=0.0100
[2025-05-03 20:38:30,947][train][INFO] - Epoch 39/140, Val Acc=0.6505, Val Loss=1.6484, lr=0.0100
[2025-05-03 20:38:33,062][train][INFO] - Epoch 41/140, Val Acc=0.6524, Val Loss=1.5971, lr=0.0100
[2025-05-03 20:38:34,480][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:38:39,001][train][INFO] - Epoch 40/140, Val Acc=0.6421, Val Loss=1.6794, lr=0.0100
[2025-05-03 20:38:40,663][train][INFO] - Epoch 42/140, Val Acc=0.6584, Val Loss=1.5694, lr=0.0100
[2025-05-03 20:38:46,787][train][INFO] - Epoch 41/140, Val Acc=0.6330, Val Loss=1.7434, lr=0.0100
[2025-05-03 20:38:48,895][train][INFO] - Epoch 43/140, Val Acc=0.6566, Val Loss=1.5909, lr=0.0100
[2025-05-03 20:38:54,696][train][INFO] - Epoch 42/140, Val Acc=0.6413, Val Loss=1.6284, lr=0.0100
[2025-05-03 20:38:56,939][train][INFO] - Epoch 44/140, Val Acc=0.6760, Val Loss=1.5050, lr=0.0100
[2025-05-03 20:39:02,620][train][INFO] - Epoch 43/140, Val Acc=0.6420, Val Loss=1.7262, lr=0.0100
[2025-05-03 20:39:02,766][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:39:05,008][train][INFO] - Epoch 45/140, Val Acc=0.6486, Val Loss=1.5874, lr=0.0100
[2025-05-03 20:39:10,746][train][INFO] - Epoch 44/140, Val Acc=0.6437, Val Loss=1.6845, lr=0.0100
[2025-05-03 20:39:12,835][train][INFO] - Epoch 46/140, Val Acc=0.6602, Val Loss=1.5521, lr=0.0100
[2025-05-03 20:39:18,257][train][INFO] - Epoch 45/140, Val Acc=0.6412, Val Loss=1.7133, lr=0.0100
[2025-05-03 20:39:20,826][train][INFO] - Epoch 47/140, Val Acc=0.6609, Val Loss=1.5401, lr=0.0100
[2025-05-03 20:39:26,405][train][INFO] - Epoch 46/140, Val Acc=0.6336, Val Loss=1.7041, lr=0.0100
[2025-05-03 20:39:29,019][train][INFO] - Epoch 48/140, Val Acc=0.6634, Val Loss=1.5371, lr=0.0100
[2025-05-03 20:39:31,627][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:39:33,910][train][INFO] - Epoch 47/140, Val Acc=0.6401, Val Loss=1.7536, lr=0.0100
[2025-05-03 20:39:37,255][train][INFO] - Epoch 49/140, Val Acc=0.6602, Val Loss=1.6338, lr=0.0100
[2025-05-03 20:39:41,512][train][INFO] - Epoch 48/140, Val Acc=0.6366, Val Loss=1.7384, lr=0.0100
[2025-05-03 20:39:45,453][train][INFO] - Epoch 50/140, Val Acc=0.6614, Val Loss=1.5854, lr=0.0100
[2025-05-03 20:39:49,578][train][INFO] - Epoch 49/140, Val Acc=0.6335, Val Loss=1.7412, lr=0.0100
[2025-05-03 20:39:52,987][train][INFO] - Epoch 51/140, Val Acc=0.6736, Val Loss=1.5051, lr=0.0100
[2025-05-03 20:39:57,677][train][INFO] - Epoch 50/140, Val Acc=0.6348, Val Loss=1.7536, lr=0.0100
[2025-05-03 20:40:00,061][train][INFO] - Epoch 52/140, Val Acc=0.6616, Val Loss=1.5544, lr=0.0100
[2025-05-03 20:40:00,831][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:40:05,779][train][INFO] - Epoch 51/140, Val Acc=0.6332, Val Loss=1.7493, lr=0.0100
[2025-05-03 20:40:07,622][train][INFO] - Epoch 53/140, Val Acc=0.6515, Val Loss=1.6121, lr=0.0100
[2025-05-03 20:40:13,438][train][INFO] - Epoch 52/140, Val Acc=0.6211, Val Loss=1.8196, lr=0.0100
[2025-05-03 20:40:15,081][train][INFO] - Epoch 54/140, Val Acc=0.6582, Val Loss=1.5486, lr=0.0100
[2025-05-03 20:40:21,754][train][INFO] - Epoch 53/140, Val Acc=0.6408, Val Loss=1.7315, lr=0.0100
[2025-05-03 20:40:21,991][train][INFO] - Epoch 55/140, Val Acc=0.6605, Val Loss=1.5553, lr=0.0100
[2025-05-03 20:40:27,654][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:40:30,017][train][INFO] - Epoch 54/140, Val Acc=0.6510, Val Loss=1.6461, lr=0.0100
[2025-05-03 20:40:30,384][train][INFO] - Epoch 56/140, Val Acc=0.6559, Val Loss=1.5942, lr=0.0100
[2025-05-03 20:40:38,295][train][INFO] - Epoch 57/140, Val Acc=0.6563, Val Loss=1.5900, lr=0.0100
[2025-05-03 20:40:38,426][train][INFO] - Epoch 55/140, Val Acc=0.6546, Val Loss=1.6626, lr=0.0100
[2025-05-03 20:40:46,100][train][INFO] - Epoch 56/140, Val Acc=0.6271, Val Loss=1.7774, lr=0.0100
[2025-05-03 20:40:46,267][train][INFO] - Epoch 58/140, Val Acc=0.6572, Val Loss=1.6144, lr=0.0100
[2025-05-03 20:40:53,782][train][INFO] - Epoch 59/140, Val Acc=0.6664, Val Loss=1.5275, lr=0.0100
[2025-05-03 20:40:54,540][train][INFO] - Epoch 57/140, Val Acc=0.6413, Val Loss=1.7126, lr=0.0100
[2025-05-03 20:40:56,402][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.6056, lr=0.0001
[2025-05-03 20:40:56,420][meta_train][INFO] - epoch_64 saved !
[2025-05-03 20:41:01,887][train][INFO] - Epoch 60/140, Val Acc=0.6624, Val Loss=1.5740, lr=0.0100
[2025-05-03 20:41:02,997][train][INFO] - Epoch 58/140, Val Acc=0.6433, Val Loss=1.6726, lr=0.0100
[2025-05-03 20:41:09,809][train][INFO] - Epoch 61/140, Val Acc=0.6538, Val Loss=1.6142, lr=0.0100
[2025-05-03 20:41:10,729][train][INFO] - Epoch 59/140, Val Acc=0.6380, Val Loss=1.7118, lr=0.0100
[2025-05-03 20:41:18,192][train][INFO] - Epoch 62/140, Val Acc=0.6541, Val Loss=1.5909, lr=0.0100
[2025-05-03 20:41:18,905][train][INFO] - Epoch 60/140, Val Acc=0.6358, Val Loss=1.7348, lr=0.0100
[2025-05-03 20:41:23,591][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:41:25,775][train][INFO] - Epoch 63/140, Val Acc=0.6654, Val Loss=1.5421, lr=0.0100
[2025-05-03 20:41:26,731][train][INFO] - Epoch 61/140, Val Acc=0.6566, Val Loss=1.6160, lr=0.0100
[2025-05-03 20:41:33,170][train][INFO] - Epoch 64/140, Val Acc=0.6544, Val Loss=1.5593, lr=0.0100
[2025-05-03 20:41:34,984][train][INFO] - Epoch 62/140, Val Acc=0.6422, Val Loss=1.7244, lr=0.0100
[2025-05-03 20:41:40,697][train][INFO] - Epoch 65/140, Val Acc=0.6673, Val Loss=1.5607, lr=0.0100
[2025-05-03 20:41:42,946][train][INFO] - Epoch 63/140, Val Acc=0.6382, Val Loss=1.7222, lr=0.0100
[2025-05-03 20:41:48,870][train][INFO] - Epoch 66/140, Val Acc=0.6439, Val Loss=1.7001, lr=0.0100
[2025-05-03 20:41:51,065][train][INFO] - Epoch 64/140, Val Acc=0.6411, Val Loss=1.7070, lr=0.0100
[2025-05-03 20:41:52,779][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:41:56,944][train][INFO] - Epoch 67/140, Val Acc=0.6728, Val Loss=1.5165, lr=0.0100
[2025-05-03 20:41:59,815][train][INFO] - Epoch 65/140, Val Acc=0.6454, Val Loss=1.6868, lr=0.0100
[2025-05-03 20:42:05,026][train][INFO] - Epoch 68/140, Val Acc=0.6478, Val Loss=1.6426, lr=0.0100
[2025-05-03 20:42:07,782][train][INFO] - Epoch 66/140, Val Acc=0.6415, Val Loss=1.6826, lr=0.0100
[2025-05-03 20:42:12,462][train][INFO] - Epoch 69/140, Val Acc=0.6630, Val Loss=1.5431, lr=0.0100
[2025-05-03 20:42:15,981][train][INFO] - Epoch 67/140, Val Acc=0.6409, Val Loss=1.6965, lr=0.0100
[2025-05-03 20:42:20,812][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:42:20,879][train][INFO] - Epoch 70/140, Val Acc=0.6629, Val Loss=1.5603, lr=0.0100
[2025-05-03 20:42:24,582][train][INFO] - Epoch 68/140, Val Acc=0.6493, Val Loss=1.6486, lr=0.0100
[2025-05-03 20:42:29,169][train][INFO] - Epoch 71/140, Val Acc=0.6529, Val Loss=1.6248, lr=0.0100
[2025-05-03 20:42:32,942][train][INFO] - Epoch 69/140, Val Acc=0.6559, Val Loss=1.5997, lr=0.0100
[2025-05-03 20:42:37,292][train][INFO] - Epoch 72/140, Val Acc=0.6599, Val Loss=1.5848, lr=0.0100
[2025-05-03 20:42:40,747][train][INFO] - Epoch 70/140, Val Acc=0.6543, Val Loss=1.5965, lr=0.0100
[2025-05-03 20:42:45,706][train][INFO] - Epoch 73/140, Val Acc=0.6588, Val Loss=1.5586, lr=0.0100
[2025-05-03 20:42:48,889][train][INFO] - Epoch 71/140, Val Acc=0.6568, Val Loss=1.6397, lr=0.0100
[2025-05-03 20:42:49,425][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:42:53,436][train][INFO] - Epoch 74/140, Val Acc=0.6613, Val Loss=1.5667, lr=0.0100
[2025-05-03 20:42:57,306][train][INFO] - Epoch 72/140, Val Acc=0.6512, Val Loss=1.6521, lr=0.0100
[2025-05-03 20:43:01,977][train][INFO] - Epoch 75/140, Val Acc=0.6660, Val Loss=1.4940, lr=0.0100
[2025-05-03 20:43:05,580][train][INFO] - Epoch 73/140, Val Acc=0.6340, Val Loss=1.7256, lr=0.0100
[2025-05-03 20:43:09,932][train][INFO] - Epoch 76/140, Val Acc=0.6492, Val Loss=1.6785, lr=0.0100
[2025-05-03 20:43:13,627][train][INFO] - Epoch 74/140, Val Acc=0.6554, Val Loss=1.6042, lr=0.0100
[2025-05-03 20:43:17,879][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.6056, lr=0.0001
[2025-05-03 20:43:18,135][train][INFO] - Epoch 77/140, Val Acc=0.6619, Val Loss=1.5720, lr=0.0100
[2025-05-03 20:43:20,897][train][INFO] - Epoch 75/140, Val Acc=0.6539, Val Loss=1.6013, lr=0.0100
[2025-05-03 20:43:26,183][train][INFO] - Epoch 78/140, Val Acc=0.6618, Val Loss=1.5410, lr=0.0100
[2025-05-03 20:43:29,085][train][INFO] - Epoch 76/140, Val Acc=0.6407, Val Loss=1.6997, lr=0.0100
[2025-05-03 20:43:33,903][train][INFO] - Epoch 79/140, Val Acc=0.6479, Val Loss=1.6446, lr=0.0100
[2025-05-03 20:43:37,192][train][INFO] - Epoch 77/140, Val Acc=0.6399, Val Loss=1.7226, lr=0.0100
[2025-05-03 20:43:41,985][train][INFO] - Epoch 80/140, Val Acc=0.6703, Val Loss=1.5253, lr=0.0100
[2025-05-03 20:43:44,939][train][INFO] - Epoch 78/140, Val Acc=0.6430, Val Loss=1.6637, lr=0.0100
[2025-05-03 20:43:46,676][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:43:49,773][train][INFO] - Epoch 81/140, Val Acc=0.7160, Val Loss=1.2918, lr=0.0010
[2025-05-03 20:43:52,793][train][INFO] - Epoch 79/140, Val Acc=0.6304, Val Loss=1.8144, lr=0.0100
[2025-05-03 20:43:57,471][train][INFO] - Epoch 82/140, Val Acc=0.7209, Val Loss=1.2972, lr=0.0010
[2025-05-03 20:44:00,873][train][INFO] - Epoch 80/140, Val Acc=0.6495, Val Loss=1.6965, lr=0.0100
[2025-05-03 20:44:05,157][train][INFO] - Epoch 83/140, Val Acc=0.7201, Val Loss=1.2985, lr=0.0010
[2025-05-03 20:44:08,825][train][INFO] - Epoch 81/140, Val Acc=0.7080, Val Loss=1.3638, lr=0.0010
[2025-05-03 20:44:12,852][train][INFO] - Epoch 84/140, Val Acc=0.7192, Val Loss=1.3000, lr=0.0010
[2025-05-03 20:44:15,044][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:44:16,874][train][INFO] - Epoch 82/140, Val Acc=0.7131, Val Loss=1.3634, lr=0.0010
[2025-05-03 20:44:21,307][train][INFO] - Epoch 85/140, Val Acc=0.7235, Val Loss=1.3041, lr=0.0010
[2025-05-03 20:44:24,690][train][INFO] - Epoch 83/140, Val Acc=0.7135, Val Loss=1.3645, lr=0.0010
[2025-05-03 20:44:29,062][train][INFO] - Epoch 86/140, Val Acc=0.7247, Val Loss=1.3118, lr=0.0010
[2025-05-03 20:44:32,491][train][INFO] - Epoch 84/140, Val Acc=0.7133, Val Loss=1.3701, lr=0.0010
[2025-05-03 20:44:36,927][train][INFO] - Epoch 87/140, Val Acc=0.7239, Val Loss=1.3153, lr=0.0010
[2025-05-03 20:44:40,856][train][INFO] - Epoch 85/140, Val Acc=0.7155, Val Loss=1.3655, lr=0.0010
[2025-05-03 20:44:43,896][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:44:43,927][meta_train][INFO] - epoch_65 saved !
[2025-05-03 20:44:45,160][train][INFO] - Epoch 88/140, Val Acc=0.7226, Val Loss=1.3235, lr=0.0010
[2025-05-03 20:44:49,060][train][INFO] - Epoch 86/140, Val Acc=0.7170, Val Loss=1.3743, lr=0.0010
[2025-05-03 20:44:53,289][train][INFO] - Epoch 89/140, Val Acc=0.7277, Val Loss=1.3193, lr=0.0010
[2025-05-03 20:44:57,060][train][INFO] - Epoch 87/140, Val Acc=0.7146, Val Loss=1.3860, lr=0.0010
[2025-05-03 20:45:01,781][train][INFO] - Epoch 90/140, Val Acc=0.7258, Val Loss=1.3233, lr=0.0010
[2025-05-03 20:45:04,808][train][INFO] - Epoch 88/140, Val Acc=0.7155, Val Loss=1.3875, lr=0.0010
[2025-05-03 20:45:09,468][train][INFO] - Epoch 91/140, Val Acc=0.7250, Val Loss=1.3290, lr=0.0010
[2025-05-03 20:45:12,332][train][INFO] - Epoch 89/140, Val Acc=0.7166, Val Loss=1.3906, lr=0.0010
[2025-05-03 20:45:13,071][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:45:17,654][train][INFO] - Epoch 92/140, Val Acc=0.7245, Val Loss=1.3332, lr=0.0010
[2025-05-03 20:45:19,960][train][INFO] - Epoch 90/140, Val Acc=0.7165, Val Loss=1.3934, lr=0.0010
[2025-05-03 20:45:25,455][train][INFO] - Epoch 93/140, Val Acc=0.7234, Val Loss=1.3335, lr=0.0010
[2025-05-03 20:45:28,149][train][INFO] - Epoch 91/140, Val Acc=0.7219, Val Loss=1.3939, lr=0.0010
[2025-05-03 20:45:33,510][train][INFO] - Epoch 94/140, Val Acc=0.7234, Val Loss=1.3394, lr=0.0010
[2025-05-03 20:45:35,501][train][INFO] - Epoch 92/140, Val Acc=0.7201, Val Loss=1.3979, lr=0.0010
[2025-05-03 20:45:41,130][train][INFO] - Epoch 95/140, Val Acc=0.7245, Val Loss=1.3465, lr=0.0010
[2025-05-03 20:45:41,663][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:45:43,095][train][INFO] - Epoch 93/140, Val Acc=0.7188, Val Loss=1.3920, lr=0.0010
[2025-05-03 20:45:49,049][train][INFO] - Epoch 96/140, Val Acc=0.7273, Val Loss=1.3473, lr=0.0010
[2025-05-03 20:45:51,283][train][INFO] - Epoch 94/140, Val Acc=0.7192, Val Loss=1.4037, lr=0.0010
[2025-05-03 20:45:56,771][train][INFO] - Epoch 97/140, Val Acc=0.7269, Val Loss=1.3510, lr=0.0010
[2025-05-03 20:45:58,796][train][INFO] - Epoch 95/140, Val Acc=0.7182, Val Loss=1.4028, lr=0.0010
[2025-05-03 20:46:05,036][train][INFO] - Epoch 98/140, Val Acc=0.7258, Val Loss=1.3470, lr=0.0010
[2025-05-03 20:46:06,378][train][INFO] - Epoch 96/140, Val Acc=0.7207, Val Loss=1.4109, lr=0.0010
[2025-05-03 20:46:09,538][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:46:13,259][train][INFO] - Epoch 99/140, Val Acc=0.7273, Val Loss=1.3511, lr=0.0010
[2025-05-03 20:46:14,359][train][INFO] - Epoch 97/140, Val Acc=0.7195, Val Loss=1.4101, lr=0.0010
[2025-05-03 20:46:21,018][train][INFO] - Epoch 98/140, Val Acc=0.7220, Val Loss=1.4075, lr=0.0010
[2025-05-03 20:46:21,641][train][INFO] - Epoch 100/140, Val Acc=0.7277, Val Loss=1.3463, lr=0.0010
[2025-05-03 20:46:28,913][train][INFO] - Epoch 99/140, Val Acc=0.7211, Val Loss=1.4139, lr=0.0010
[2025-05-03 20:46:29,559][train][INFO] - Epoch 101/140, Val Acc=0.7306, Val Loss=1.3427, lr=0.0010
[2025-05-03 20:46:36,735][train][INFO] - Epoch 100/140, Val Acc=0.7218, Val Loss=1.4145, lr=0.0010
[2025-05-03 20:46:37,829][train][INFO] - Epoch 102/140, Val Acc=0.7280, Val Loss=1.3572, lr=0.0010
[2025-05-03 20:46:38,298][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:46:44,975][train][INFO] - Epoch 101/140, Val Acc=0.7211, Val Loss=1.4131, lr=0.0010
[2025-05-03 20:46:45,846][train][INFO] - Epoch 103/140, Val Acc=0.7284, Val Loss=1.3516, lr=0.0010
[2025-05-03 20:46:52,770][train][INFO] - Epoch 102/140, Val Acc=0.7196, Val Loss=1.4119, lr=0.0010
[2025-05-03 20:46:53,971][train][INFO] - Epoch 104/140, Val Acc=0.7285, Val Loss=1.3640, lr=0.0010
[2025-05-03 20:47:00,931][train][INFO] - Epoch 103/140, Val Acc=0.7181, Val Loss=1.4185, lr=0.0010
[2025-05-03 20:47:02,055][train][INFO] - Epoch 105/140, Val Acc=0.7275, Val Loss=1.3602, lr=0.0010
[2025-05-03 20:47:07,328][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-03 20:47:08,755][train][INFO] - Epoch 104/140, Val Acc=0.7193, Val Loss=1.4162, lr=0.0010
[2025-05-03 20:47:10,240][train][INFO] - Epoch 106/140, Val Acc=0.7282, Val Loss=1.3618, lr=0.0010
[2025-05-03 20:47:17,029][train][INFO] - Epoch 105/140, Val Acc=0.7212, Val Loss=1.4165, lr=0.0010
[2025-05-03 20:47:18,659][train][INFO] - Epoch 107/140, Val Acc=0.7257, Val Loss=1.3669, lr=0.0010
[2025-05-03 20:47:24,741][train][INFO] - Epoch 106/140, Val Acc=0.7198, Val Loss=1.4203, lr=0.0010
[2025-05-03 20:47:26,849][train][INFO] - Epoch 108/140, Val Acc=0.7292, Val Loss=1.3532, lr=0.0010
[2025-05-03 20:47:32,839][train][INFO] - Epoch 107/140, Val Acc=0.7195, Val Loss=1.4257, lr=0.0010
[2025-05-03 20:47:35,022][train][INFO] - Epoch 109/140, Val Acc=0.7289, Val Loss=1.3662, lr=0.0010
[2025-05-03 20:47:35,620][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:47:41,312][train][INFO] - Epoch 108/140, Val Acc=0.7195, Val Loss=1.4261, lr=0.0010
[2025-05-03 20:47:43,381][train][INFO] - Epoch 110/140, Val Acc=0.7285, Val Loss=1.3674, lr=0.0010
[2025-05-03 20:47:49,036][train][INFO] - Epoch 109/140, Val Acc=0.7202, Val Loss=1.4203, lr=0.0010
[2025-05-03 20:47:51,167][train][INFO] - Epoch 111/140, Val Acc=0.7286, Val Loss=1.3648, lr=0.0010
[2025-05-03 20:47:57,265][train][INFO] - Epoch 110/140, Val Acc=0.7235, Val Loss=1.4200, lr=0.0010
[2025-05-03 20:47:58,931][train][INFO] - Epoch 112/140, Val Acc=0.7316, Val Loss=1.3641, lr=0.0010
[2025-05-03 20:48:02,725][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:48:05,409][train][INFO] - Epoch 111/140, Val Acc=0.7217, Val Loss=1.4256, lr=0.0010
[2025-05-03 20:48:07,234][train][INFO] - Epoch 113/140, Val Acc=0.7299, Val Loss=1.3607, lr=0.0010
[2025-05-03 20:48:13,847][train][INFO] - Epoch 112/140, Val Acc=0.7224, Val Loss=1.4256, lr=0.0010
[2025-05-03 20:48:15,395][train][INFO] - Epoch 114/140, Val Acc=0.7292, Val Loss=1.3607, lr=0.0010
[2025-05-03 20:48:22,009][train][INFO] - Epoch 113/140, Val Acc=0.7212, Val Loss=1.4277, lr=0.0010
[2025-05-03 20:48:23,124][train][INFO] - Epoch 115/140, Val Acc=0.7311, Val Loss=1.3603, lr=0.0010
[2025-05-03 20:48:29,859][train][INFO] - Epoch 114/140, Val Acc=0.7207, Val Loss=1.4275, lr=0.0010
[2025-05-03 20:48:31,055][train][INFO] - Epoch 116/140, Val Acc=0.7305, Val Loss=1.3570, lr=0.0010
[2025-05-03 20:48:31,833][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:48:31,859][meta_train][INFO] - epoch_66 saved !
[2025-05-03 20:48:37,918][train][INFO] - Epoch 115/140, Val Acc=0.7214, Val Loss=1.4287, lr=0.0010
[2025-05-03 20:48:39,346][train][INFO] - Epoch 117/140, Val Acc=0.7311, Val Loss=1.3722, lr=0.0010
[2025-05-03 20:48:45,928][train][INFO] - Epoch 116/140, Val Acc=0.7227, Val Loss=1.4251, lr=0.0010
[2025-05-03 20:48:47,251][train][INFO] - Epoch 118/140, Val Acc=0.7300, Val Loss=1.3687, lr=0.0010
[2025-05-03 20:48:53,391][train][INFO] - Epoch 117/140, Val Acc=0.7227, Val Loss=1.4304, lr=0.0010
[2025-05-03 20:48:55,278][train][INFO] - Epoch 119/140, Val Acc=0.7308, Val Loss=1.3700, lr=0.0010
[2025-05-03 20:49:00,412][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 20:49:01,657][train][INFO] - Epoch 118/140, Val Acc=0.7242, Val Loss=1.4270, lr=0.0010
[2025-05-03 20:49:02,984][train][INFO] - Epoch 120/140, Val Acc=0.7312, Val Loss=1.3652, lr=0.0010
[2025-05-03 20:49:10,196][train][INFO] - Epoch 119/140, Val Acc=0.7232, Val Loss=1.4287, lr=0.0010
[2025-05-03 20:49:11,638][train][INFO] - Epoch 121/140, Val Acc=0.7294, Val Loss=1.3606, lr=0.0001
[2025-05-03 20:49:18,612][train][INFO] - Epoch 120/140, Val Acc=0.7239, Val Loss=1.4309, lr=0.0010
[2025-05-03 20:49:19,641][train][INFO] - Epoch 122/140, Val Acc=0.7297, Val Loss=1.3666, lr=0.0001
[2025-05-03 20:49:26,490][train][INFO] - Epoch 121/140, Val Acc=0.7251, Val Loss=1.4309, lr=0.0001
[2025-05-03 20:49:27,627][train][INFO] - Epoch 123/140, Val Acc=0.7306, Val Loss=1.3706, lr=0.0001
[2025-05-03 20:49:28,107][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:49:35,031][train][INFO] - Epoch 122/140, Val Acc=0.7247, Val Loss=1.4287, lr=0.0001
[2025-05-03 20:49:35,486][train][INFO] - Epoch 124/140, Val Acc=0.7296, Val Loss=1.3680, lr=0.0001
[2025-05-03 20:49:42,644][train][INFO] - Epoch 123/140, Val Acc=0.7250, Val Loss=1.4250, lr=0.0001
[2025-05-03 20:49:43,522][train][INFO] - Epoch 125/140, Val Acc=0.7289, Val Loss=1.3725, lr=0.0001
[2025-05-03 20:49:51,035][train][INFO] - Epoch 124/140, Val Acc=0.7249, Val Loss=1.4246, lr=0.0001
[2025-05-03 20:49:51,964][train][INFO] - Epoch 126/140, Val Acc=0.7299, Val Loss=1.3623, lr=0.0001
[2025-05-03 20:49:55,985][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:49:59,158][train][INFO] - Epoch 125/140, Val Acc=0.7233, Val Loss=1.4265, lr=0.0001
[2025-05-03 20:50:00,375][train][INFO] - Epoch 127/140, Val Acc=0.7298, Val Loss=1.3680, lr=0.0001
[2025-05-03 20:50:07,474][train][INFO] - Epoch 126/140, Val Acc=0.7237, Val Loss=1.4254, lr=0.0001
[2025-05-03 20:50:08,236][train][INFO] - Epoch 128/140, Val Acc=0.7320, Val Loss=1.3625, lr=0.0001
[2025-05-03 20:50:15,908][train][INFO] - Epoch 127/140, Val Acc=0.7219, Val Loss=1.4300, lr=0.0001
[2025-05-03 20:50:16,084][train][INFO] - Epoch 129/140, Val Acc=0.7301, Val Loss=1.3641, lr=0.0001
[2025-05-03 20:50:24,036][train][INFO] - Epoch 130/140, Val Acc=0.7309, Val Loss=1.3620, lr=0.0001
[2025-05-03 20:50:24,354][train][INFO] - Epoch 128/140, Val Acc=0.7235, Val Loss=1.4251, lr=0.0001
[2025-05-03 20:50:24,978][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:50:32,203][train][INFO] - Epoch 129/140, Val Acc=0.7236, Val Loss=1.4259, lr=0.0001
[2025-05-03 20:50:32,755][train][INFO] - Epoch 131/140, Val Acc=0.7303, Val Loss=1.3630, lr=0.0001
[2025-05-03 20:50:39,226][train][INFO] - Epoch 130/140, Val Acc=0.7237, Val Loss=1.4245, lr=0.0001
[2025-05-03 20:50:40,919][train][INFO] - Epoch 132/140, Val Acc=0.7302, Val Loss=1.3608, lr=0.0001
[2025-05-03 20:50:47,574][train][INFO] - Epoch 131/140, Val Acc=0.7226, Val Loss=1.4291, lr=0.0001
[2025-05-03 20:50:49,491][train][INFO] - Epoch 133/140, Val Acc=0.7312, Val Loss=1.3616, lr=0.0001
[2025-05-03 20:50:53,557][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:50:55,434][train][INFO] - Epoch 132/140, Val Acc=0.7226, Val Loss=1.4294, lr=0.0001
[2025-05-03 20:50:58,060][train][INFO] - Epoch 134/140, Val Acc=0.7309, Val Loss=1.3593, lr=0.0001
[2025-05-03 20:51:03,855][train][INFO] - Epoch 133/140, Val Acc=0.7234, Val Loss=1.4276, lr=0.0001
[2025-05-03 20:51:05,976][train][INFO] - Epoch 135/140, Val Acc=0.7304, Val Loss=1.3682, lr=0.0001
[2025-05-03 20:51:11,392][train][INFO] - Epoch 134/140, Val Acc=0.7245, Val Loss=1.4249, lr=0.0001
[2025-05-03 20:51:13,517][train][INFO] - Epoch 136/140, Val Acc=0.7308, Val Loss=1.3649, lr=0.0001
[2025-05-03 20:51:19,290][train][INFO] - Epoch 135/140, Val Acc=0.7205, Val Loss=1.4297, lr=0.0001
[2025-05-03 20:51:20,963][train][INFO] - Epoch 137/140, Val Acc=0.7306, Val Loss=1.3639, lr=0.0001
[2025-05-03 20:51:22,229][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:51:26,751][train][INFO] - Epoch 136/140, Val Acc=0.7242, Val Loss=1.4281, lr=0.0001
[2025-05-03 20:51:29,393][train][INFO] - Epoch 138/140, Val Acc=0.7300, Val Loss=1.3645, lr=0.0001
[2025-05-03 20:51:34,700][train][INFO] - Epoch 137/140, Val Acc=0.7248, Val Loss=1.4243, lr=0.0001
[2025-05-03 20:51:36,961][train][INFO] - Epoch 139/140, Val Acc=0.7310, Val Loss=1.3658, lr=0.0001
[2025-05-03 20:51:42,466][train][INFO] - Epoch 138/140, Val Acc=0.7228, Val Loss=1.4226, lr=0.0001
[2025-05-03 20:51:44,781][train][INFO] - Epoch 140/140, Val Acc=0.7301, Val Loss=1.3635, lr=0.0001
[2025-05-03 20:51:49,736][train][INFO] - After training : Train Acc=0.9991  Val Acc=0.7320
[2025-05-03 20:51:49,785][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(9, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(59, 117, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(117, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(256, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(250, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(104, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(256, 393, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(393, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(393, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(128, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(58, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(62, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(38, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(31, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(82, 178, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=178, out_features=100, bias=True)
)
[2025-05-03 20:51:49,785][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.7319999933242798
                      Speed up: 1.52   Final speed up: 3.04
[2025-05-03 20:51:50,050][train][INFO] - Epoch 139/140, Val Acc=0.7257, Val Loss=1.4255, lr=0.0001
[2025-05-03 20:51:50,138][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:51:58,551][train][INFO] - Epoch 140/140, Val Acc=0.7220, Val Loss=1.4306, lr=0.0001
[2025-05-03 20:52:03,616][train][INFO] - After training : Train Acc=0.9988  Val Acc=0.7257
[2025-05-03 20:52:03,683][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(47, 105, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(105, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(254, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(255, 222, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(222, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(244, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(68, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(3, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(14, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(26, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(18, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(41, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=140, out_features=100, bias=True)
)
[2025-05-03 20:52:03,684][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.7256999611854553
                      Speed up: 1.51   Final speed up: 3.02
[2025-05-03 20:52:18,123][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:52:18,138][meta_train][INFO] - epoch_67 saved !
[2025-05-03 20:52:45,921][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 20:53:12,505][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:53:40,088][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:54:07,805][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:54:34,568][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:55:02,310][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:55:20,316][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 20:55:20,382][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 20:55:20,382][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 20:55:20,382][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 20:55:29,318][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:55:30,703][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 20:55:30,753][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 20:55:30,753][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 20:55:30,753][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 20:55:40,127][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 20:55:48,866][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-03 20:55:50,789][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 20:55:56,791][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 20:55:56,933][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:55:56,960][meta_train][INFO] - epoch_68 saved !
[2025-05-03 20:55:59,510][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-03 20:56:05,440][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 20:56:07,466][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 20:56:13,729][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 20:56:15,255][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 20:56:22,031][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 20:56:23,508][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 20:56:26,026][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:56:30,067][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 20:56:31,538][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 20:56:38,104][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 20:56:39,666][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 20:56:45,752][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 20:56:47,348][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 20:56:53,681][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 20:56:54,352][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:56:54,689][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 20:57:01,944][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 20:57:03,019][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 20:57:09,877][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 20:57:10,605][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 20:57:17,429][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 20:57:18,638][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 20:57:23,218][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:57:25,370][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 20:57:26,063][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 20:57:33,481][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 20:57:34,325][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 20:57:41,379][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 20:57:41,457][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 20:57:49,547][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 20:57:49,578][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 20:57:51,962][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:57:57,184][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 20:57:57,836][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 20:58:05,315][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 20:58:05,841][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 20:58:13,193][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 20:58:14,202][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 20:58:21,290][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.6055, lr=0.0001
[2025-05-03 20:58:21,455][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 20:58:22,278][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 20:58:29,647][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 20:58:30,846][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 20:58:37,533][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 20:58:38,935][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 20:58:45,303][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 20:58:47,074][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 20:58:48,086][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:58:53,549][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 20:58:55,400][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 20:59:01,383][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 20:59:03,214][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 20:59:09,324][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 20:59:10,420][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 20:59:16,616][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 20:59:17,688][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 20:59:18,702][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 20:59:25,748][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 20:59:26,904][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 20:59:33,918][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 20:59:34,869][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 20:59:41,773][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 20:59:43,023][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 20:59:45,733][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 20:59:45,762][meta_train][INFO] - epoch_69 saved !
[2025-05-03 20:59:49,816][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 20:59:50,888][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 20:59:57,822][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 20:59:59,111][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 21:00:06,169][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 21:00:06,957][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 21:00:13,913][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 21:00:14,435][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:00:14,756][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 21:00:21,544][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 21:00:23,080][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 21:00:28,947][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 21:00:30,950][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 21:00:36,949][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 21:00:39,081][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 21:00:43,103][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:00:45,066][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 21:00:47,397][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 21:00:53,541][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 21:00:55,069][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 21:01:01,175][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 21:01:03,360][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 21:01:08,972][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 21:01:10,913][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 21:01:12,049][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:01:16,960][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 21:01:18,789][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 21:01:24,508][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 21:01:26,609][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 21:01:32,817][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 21:01:34,828][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 21:01:40,593][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:01:40,646][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 21:01:42,644][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 21:01:48,672][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 21:01:50,481][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 21:01:56,707][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 21:01:58,259][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 21:02:04,572][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 21:02:06,565][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 21:02:08,052][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:02:12,666][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 21:02:14,527][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 21:02:20,848][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 21:02:22,536][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 21:02:28,318][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 21:02:30,943][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 21:02:36,150][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 21:02:36,989][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:02:38,473][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 21:02:43,816][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 21:02:45,872][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 21:02:51,883][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 21:02:53,765][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 21:02:59,783][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 21:03:01,697][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 21:03:05,110][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:03:08,064][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 21:03:09,703][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 21:03:16,542][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 21:03:17,555][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 21:03:24,541][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 21:03:25,571][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 21:03:32,557][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 21:03:33,827][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:03:33,842][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 21:03:33,846][meta_train][INFO] - epoch_70 saved !
[2025-05-03 21:03:40,884][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 21:03:42,058][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 21:03:48,613][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 21:03:49,837][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 21:03:56,681][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 21:03:57,627][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 21:04:02,559][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:04:04,444][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 21:04:05,636][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 21:04:12,809][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 21:04:13,846][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 21:04:20,614][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 21:04:21,795][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 21:04:28,832][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 21:04:29,932][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 21:04:30,573][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:04:36,521][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 21:04:37,597][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 21:04:43,499][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 21:04:45,750][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 21:04:51,382][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 21:04:53,109][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 21:04:59,113][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:04:59,194][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 21:05:00,724][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 21:05:07,142][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 21:05:08,787][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 21:05:15,156][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 21:05:16,755][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 21:05:23,082][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 21:05:24,601][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 21:05:27,742][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:05:31,084][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 21:05:32,874][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 21:05:38,996][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 21:05:40,872][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 21:05:46,859][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 21:05:48,404][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 21:05:54,875][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 21:05:56,289][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 21:05:56,807][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:06:02,867][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 21:06:04,694][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 21:06:11,194][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 21:06:12,675][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 21:06:18,709][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 21:06:20,969][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 21:06:24,219][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:06:26,265][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 21:06:29,114][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 21:06:34,395][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 21:06:37,357][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 21:06:42,616][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 21:06:45,406][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:06:49,998][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:06:53,183][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:06:53,493][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 21:06:58,061][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 21:07:01,687][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 21:07:05,915][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 21:07:09,757][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 21:07:13,714][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 21:07:18,070][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:07:21,123][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:07:21,153][meta_train][INFO] - epoch_71 saved !
[2025-05-03 21:07:21,502][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:07:26,262][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 21:07:29,983][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 21:07:34,226][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 21:07:37,654][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 21:07:42,314][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 21:07:45,507][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 21:07:50,138][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:07:50,470][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 21:07:53,835][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 21:07:58,768][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:08:01,681][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:08:06,369][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 21:08:09,384][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 21:08:14,681][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 21:08:17,121][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 21:08:17,259][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:08:22,359][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 21:08:24,801][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 21:08:29,792][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:08:32,406][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:08:37,923][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 21:08:39,902][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 21:08:45,807][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 21:08:45,815][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:08:47,585][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 21:08:54,000][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 21:08:55,029][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 21:09:01,961][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 21:09:02,680][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 21:09:07,123][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 21:09:07,758][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 21:09:07,763][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 21:09:14,936][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:09:15,742][Progressive pruning][INFO] - Train acc : 0.2210799902677536   Val acc : 0.1890999972820282
[2025-05-03 21:09:15,742][Progressive pruning][INFO] - Current speed up: 1.52
[2025-05-03 21:09:21,017][train][INFO] - Before training : Train Acc=0.2238  Val Acc=0.1891
[2025-05-03 21:09:29,193][train][INFO] - Epoch 1/140, Val Acc=0.6137, Val Loss=1.6105, lr=0.0100
[2025-05-03 21:09:37,645][train][INFO] - Epoch 2/140, Val Acc=0.6069, Val Loss=1.6713, lr=0.0100
[2025-05-03 21:09:43,435][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:09:45,825][train][INFO] - Epoch 3/140, Val Acc=0.6310, Val Loss=1.5821, lr=0.0100
[2025-05-03 21:09:54,092][train][INFO] - Epoch 4/140, Val Acc=0.6404, Val Loss=1.5590, lr=0.0100
[2025-05-03 21:10:01,731][train][INFO] - Epoch 5/140, Val Acc=0.6321, Val Loss=1.6486, lr=0.0100
[2025-05-03 21:10:09,911][train][INFO] - Epoch 6/140, Val Acc=0.6390, Val Loss=1.5564, lr=0.0100
[2025-05-03 21:10:12,539][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:10:17,659][train][INFO] - Epoch 7/140, Val Acc=0.6502, Val Loss=1.5376, lr=0.0100
[2025-05-03 21:10:25,637][train][INFO] - Epoch 8/140, Val Acc=0.6307, Val Loss=1.6178, lr=0.0100
[2025-05-03 21:10:33,746][train][INFO] - Epoch 9/140, Val Acc=0.6486, Val Loss=1.5444, lr=0.0100
[2025-05-03 21:10:41,310][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:10:41,799][train][INFO] - Epoch 10/140, Val Acc=0.6586, Val Loss=1.5132, lr=0.0100
[2025-05-03 21:10:47,437][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 21:10:49,966][train][INFO] - Epoch 11/140, Val Acc=0.6561, Val Loss=1.5212, lr=0.0100
[2025-05-03 21:10:58,097][train][INFO] - Epoch 12/140, Val Acc=0.6564, Val Loss=1.5349, lr=0.0100
[2025-05-03 21:11:06,456][train][INFO] - Epoch 13/140, Val Acc=0.6507, Val Loss=1.5645, lr=0.0100
[2025-05-03 21:11:10,124][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:11:10,148][meta_train][INFO] - epoch_72 saved !
[2025-05-03 21:11:14,699][train][INFO] - Epoch 14/140, Val Acc=0.6544, Val Loss=1.5453, lr=0.0100
[2025-05-03 21:11:22,078][train][INFO] - Epoch 15/140, Val Acc=0.6603, Val Loss=1.5297, lr=0.0100
[2025-05-03 21:11:30,023][train][INFO] - Epoch 16/140, Val Acc=0.6526, Val Loss=1.5632, lr=0.0100
[2025-05-03 21:11:38,329][train][INFO] - Epoch 17/140, Val Acc=0.6612, Val Loss=1.5121, lr=0.0100
[2025-05-03 21:11:38,464][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:11:46,447][train][INFO] - Epoch 18/140, Val Acc=0.6583, Val Loss=1.5180, lr=0.0100
[2025-05-03 21:11:54,344][train][INFO] - Epoch 19/140, Val Acc=0.6510, Val Loss=1.5543, lr=0.0100
[2025-05-03 21:12:02,334][train][INFO] - Epoch 20/140, Val Acc=0.6531, Val Loss=1.5857, lr=0.0100
[2025-05-03 21:12:07,645][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:12:10,332][train][INFO] - Epoch 21/140, Val Acc=0.6522, Val Loss=1.5417, lr=0.0100
[2025-05-03 21:12:18,392][train][INFO] - Epoch 22/140, Val Acc=0.6644, Val Loss=1.5103, lr=0.0100
[2025-05-03 21:12:26,209][train][INFO] - Epoch 23/140, Val Acc=0.6632, Val Loss=1.5353, lr=0.0100
[2025-05-03 21:12:34,270][train][INFO] - Epoch 24/140, Val Acc=0.6652, Val Loss=1.5328, lr=0.0100
[2025-05-03 21:12:36,483][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:12:42,086][train][INFO] - Epoch 25/140, Val Acc=0.6640, Val Loss=1.5263, lr=0.0100
[2025-05-03 21:12:50,094][train][INFO] - Epoch 26/140, Val Acc=0.6645, Val Loss=1.5097, lr=0.0100
[2025-05-03 21:12:57,859][train][INFO] - Epoch 27/140, Val Acc=0.6660, Val Loss=1.5192, lr=0.0100
[2025-05-03 21:13:04,332][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:13:05,544][train][INFO] - Epoch 28/140, Val Acc=0.6471, Val Loss=1.6020, lr=0.0100
[2025-05-03 21:13:08,387][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 21:13:08,830][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 21:13:13,047][train][INFO] - Epoch 29/140, Val Acc=0.6581, Val Loss=1.5781, lr=0.0100
[2025-05-03 21:13:20,948][train][INFO] - Epoch 30/140, Val Acc=0.6619, Val Loss=1.5545, lr=0.0100
[2025-05-03 21:13:28,350][train][INFO] - Epoch 31/140, Val Acc=0.6632, Val Loss=1.5436, lr=0.0100
[2025-05-03 21:13:31,721][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:13:36,192][train][INFO] - Epoch 32/140, Val Acc=0.6652, Val Loss=1.5304, lr=0.0100
[2025-05-03 21:13:43,688][train][INFO] - Epoch 33/140, Val Acc=0.6704, Val Loss=1.5280, lr=0.0100
[2025-05-03 21:13:51,294][train][INFO] - Epoch 34/140, Val Acc=0.6725, Val Loss=1.5224, lr=0.0100
[2025-05-03 21:13:59,174][train][INFO] - Epoch 35/140, Val Acc=0.6665, Val Loss=1.5354, lr=0.0100
[2025-05-03 21:13:59,717][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:14:06,898][train][INFO] - Epoch 36/140, Val Acc=0.6637, Val Loss=1.5876, lr=0.0100
[2025-05-03 21:14:14,861][train][INFO] - Epoch 37/140, Val Acc=0.6661, Val Loss=1.5235, lr=0.0100
[2025-05-03 21:14:22,403][train][INFO] - Epoch 38/140, Val Acc=0.6555, Val Loss=1.5770, lr=0.0100
[2025-05-03 21:14:27,959][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:14:30,586][train][INFO] - Epoch 39/140, Val Acc=0.6328, Val Loss=1.7252, lr=0.0100
[2025-05-03 21:14:39,018][train][INFO] - Epoch 40/140, Val Acc=0.6601, Val Loss=1.5366, lr=0.0100
[2025-05-03 21:14:47,091][train][INFO] - Epoch 41/140, Val Acc=0.6529, Val Loss=1.6378, lr=0.0100
[2025-05-03 21:14:54,727][train][INFO] - Epoch 42/140, Val Acc=0.6685, Val Loss=1.5015, lr=0.0100
[2025-05-03 21:14:56,188][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:14:56,227][meta_train][INFO] - epoch_73 saved !
[2025-05-03 21:15:03,296][train][INFO] - Epoch 43/140, Val Acc=0.6536, Val Loss=1.5965, lr=0.0100
[2025-05-03 21:15:11,472][train][INFO] - Epoch 44/140, Val Acc=0.6730, Val Loss=1.5638, lr=0.0100
[2025-05-03 21:15:19,817][train][INFO] - Epoch 45/140, Val Acc=0.6554, Val Loss=1.5582, lr=0.0100
[2025-05-03 21:15:23,620][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:15:27,432][train][INFO] - Epoch 46/140, Val Acc=0.6348, Val Loss=1.7279, lr=0.0100
[2025-05-03 21:15:35,340][train][INFO] - Epoch 47/140, Val Acc=0.6662, Val Loss=1.5707, lr=0.0100
[2025-05-03 21:15:43,391][train][INFO] - Epoch 48/140, Val Acc=0.6644, Val Loss=1.5242, lr=0.0100
[2025-05-03 21:15:51,804][train][INFO] - Epoch 49/140, Val Acc=0.6558, Val Loss=1.5830, lr=0.0100
[2025-05-03 21:15:51,917][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:15:59,942][train][INFO] - Epoch 50/140, Val Acc=0.6671, Val Loss=1.5065, lr=0.0100
[2025-05-03 21:16:07,901][train][INFO] - Epoch 51/140, Val Acc=0.6655, Val Loss=1.5206, lr=0.0100
[2025-05-03 21:16:15,389][train][INFO] - Epoch 52/140, Val Acc=0.6175, Val Loss=1.8831, lr=0.0100
[2025-05-03 21:16:19,894][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:16:23,445][train][INFO] - Epoch 53/140, Val Acc=0.6530, Val Loss=1.6175, lr=0.0100
[2025-05-03 21:16:31,651][train][INFO] - Epoch 54/140, Val Acc=0.6657, Val Loss=1.5705, lr=0.0100
[2025-05-03 21:16:39,036][train][INFO] - Epoch 55/140, Val Acc=0.6590, Val Loss=1.5548, lr=0.0100
[2025-05-03 21:16:46,761][train][INFO] - Epoch 56/140, Val Acc=0.6581, Val Loss=1.5650, lr=0.0100
[2025-05-03 21:16:47,765][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:16:54,522][train][INFO] - Epoch 57/140, Val Acc=0.6575, Val Loss=1.5720, lr=0.0100
[2025-05-03 21:17:02,872][train][INFO] - Epoch 58/140, Val Acc=0.6612, Val Loss=1.5808, lr=0.0100
[2025-05-03 21:17:10,583][train][INFO] - Epoch 59/140, Val Acc=0.6662, Val Loss=1.5377, lr=0.0100
[2025-05-03 21:17:15,821][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:17:17,989][train][INFO] - Epoch 60/140, Val Acc=0.6655, Val Loss=1.5657, lr=0.0100
[2025-05-03 21:17:25,914][train][INFO] - Epoch 61/140, Val Acc=0.6529, Val Loss=1.6207, lr=0.0100
[2025-05-03 21:17:33,863][train][INFO] - Epoch 62/140, Val Acc=0.6547, Val Loss=1.5893, lr=0.0100
[2025-05-03 21:17:41,666][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:17:42,430][train][INFO] - Epoch 63/140, Val Acc=0.6732, Val Loss=1.5235, lr=0.0100
[2025-05-03 21:17:50,903][train][INFO] - Epoch 64/140, Val Acc=0.6674, Val Loss=1.5445, lr=0.0100
[2025-05-03 21:17:58,919][train][INFO] - Epoch 65/140, Val Acc=0.6660, Val Loss=1.5685, lr=0.0100
[2025-05-03 21:18:07,328][train][INFO] - Epoch 66/140, Val Acc=0.6465, Val Loss=1.6668, lr=0.0100
[2025-05-03 21:18:08,995][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:18:15,601][train][INFO] - Epoch 67/140, Val Acc=0.6610, Val Loss=1.5759, lr=0.0100
[2025-05-03 21:18:23,210][train][INFO] - Epoch 68/140, Val Acc=0.6570, Val Loss=1.5826, lr=0.0100
[2025-05-03 21:18:31,347][train][INFO] - Epoch 69/140, Val Acc=0.6631, Val Loss=1.5754, lr=0.0100
[2025-05-03 21:18:36,993][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:18:37,009][meta_train][INFO] - epoch_74 saved !
[2025-05-03 21:18:39,508][train][INFO] - Epoch 70/140, Val Acc=0.6540, Val Loss=1.5959, lr=0.0100
[2025-05-03 21:18:46,802][train][INFO] - Epoch 71/140, Val Acc=0.6672, Val Loss=1.5421, lr=0.0100
[2025-05-03 21:18:54,690][train][INFO] - Epoch 72/140, Val Acc=0.6597, Val Loss=1.5790, lr=0.0100
[2025-05-03 21:19:02,860][train][INFO] - Epoch 73/140, Val Acc=0.6618, Val Loss=1.5749, lr=0.0100
[2025-05-03 21:19:04,343][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:19:10,768][train][INFO] - Epoch 74/140, Val Acc=0.6564, Val Loss=1.5659, lr=0.0100
[2025-05-03 21:19:18,647][train][INFO] - Epoch 75/140, Val Acc=0.6685, Val Loss=1.5420, lr=0.0100
[2025-05-03 21:19:26,665][train][INFO] - Epoch 76/140, Val Acc=0.6579, Val Loss=1.5456, lr=0.0100
[2025-05-03 21:19:32,180][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:19:34,675][train][INFO] - Epoch 77/140, Val Acc=0.6562, Val Loss=1.5781, lr=0.0100
[2025-05-03 21:19:42,597][train][INFO] - Epoch 78/140, Val Acc=0.6491, Val Loss=1.6347, lr=0.0100
[2025-05-03 21:19:50,691][train][INFO] - Epoch 79/140, Val Acc=0.6567, Val Loss=1.5562, lr=0.0100
[2025-05-03 21:19:58,999][train][INFO] - Epoch 80/140, Val Acc=0.6491, Val Loss=1.6281, lr=0.0100
[2025-05-03 21:19:59,922][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:20:07,140][train][INFO] - Epoch 81/140, Val Acc=0.7189, Val Loss=1.2589, lr=0.0010
[2025-05-03 21:20:15,549][train][INFO] - Epoch 82/140, Val Acc=0.7256, Val Loss=1.2601, lr=0.0010
[2025-05-03 21:20:24,103][train][INFO] - Epoch 83/140, Val Acc=0.7269, Val Loss=1.2629, lr=0.0010
[2025-05-03 21:20:28,302][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:20:32,423][train][INFO] - Epoch 84/140, Val Acc=0.7256, Val Loss=1.2745, lr=0.0010
[2025-05-03 21:20:39,997][train][INFO] - Epoch 85/140, Val Acc=0.7264, Val Loss=1.2727, lr=0.0010
[2025-05-03 21:20:48,373][train][INFO] - Epoch 86/140, Val Acc=0.7289, Val Loss=1.2829, lr=0.0010
[2025-05-03 21:20:55,717][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:20:56,006][train][INFO] - Epoch 87/140, Val Acc=0.7300, Val Loss=1.2899, lr=0.0010
[2025-05-03 21:21:03,611][train][INFO] - Epoch 88/140, Val Acc=0.7297, Val Loss=1.2968, lr=0.0010
[2025-05-03 21:21:11,182][train][INFO] - Epoch 89/140, Val Acc=0.7303, Val Loss=1.3012, lr=0.0010
[2025-05-03 21:21:19,326][train][INFO] - Epoch 90/140, Val Acc=0.7323, Val Loss=1.2993, lr=0.0010
[2025-05-03 21:21:23,677][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:21:26,254][train][INFO] - Epoch 91/140, Val Acc=0.7306, Val Loss=1.3009, lr=0.0010
[2025-05-03 21:21:34,612][train][INFO] - Epoch 92/140, Val Acc=0.7341, Val Loss=1.3000, lr=0.0010
[2025-05-03 21:21:42,743][train][INFO] - Epoch 93/140, Val Acc=0.7327, Val Loss=1.3068, lr=0.0010
[2025-05-03 21:21:51,420][train][INFO] - Epoch 94/140, Val Acc=0.7352, Val Loss=1.3034, lr=0.0010
[2025-05-03 21:21:51,774][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:21:58,529][train][INFO] - Epoch 95/140, Val Acc=0.7335, Val Loss=1.3090, lr=0.0010
[2025-05-03 21:22:06,469][train][INFO] - Epoch 96/140, Val Acc=0.7351, Val Loss=1.3186, lr=0.0010
[2025-05-03 21:22:13,982][train][INFO] - Epoch 97/140, Val Acc=0.7330, Val Loss=1.3187, lr=0.0010
[2025-05-03 21:22:18,446][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:22:18,486][meta_train][INFO] - epoch_75 saved !
[2025-05-03 21:22:22,060][train][INFO] - Epoch 98/140, Val Acc=0.7317, Val Loss=1.3168, lr=0.0010
[2025-05-03 21:22:30,142][train][INFO] - Epoch 99/140, Val Acc=0.7348, Val Loss=1.3234, lr=0.0010
[2025-05-03 21:22:38,180][train][INFO] - Epoch 100/140, Val Acc=0.7348, Val Loss=1.3262, lr=0.0010
[2025-05-03 21:22:46,019][train][INFO] - Epoch 101/140, Val Acc=0.7358, Val Loss=1.3213, lr=0.0010
[2025-05-03 21:22:46,478][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:22:54,424][train][INFO] - Epoch 102/140, Val Acc=0.7342, Val Loss=1.3280, lr=0.0010
[2025-05-03 21:23:01,899][train][INFO] - Epoch 103/140, Val Acc=0.7348, Val Loss=1.3354, lr=0.0010
[2025-05-03 21:23:10,121][train][INFO] - Epoch 104/140, Val Acc=0.7350, Val Loss=1.3414, lr=0.0010
[2025-05-03 21:23:14,126][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:23:18,258][train][INFO] - Epoch 105/140, Val Acc=0.7351, Val Loss=1.3348, lr=0.0010
[2025-05-03 21:23:26,484][train][INFO] - Epoch 106/140, Val Acc=0.7360, Val Loss=1.3343, lr=0.0010
[2025-05-03 21:23:34,519][train][INFO] - Epoch 107/140, Val Acc=0.7343, Val Loss=1.3435, lr=0.0010
[2025-05-03 21:23:42,883][train][INFO] - Epoch 108/140, Val Acc=0.7328, Val Loss=1.3380, lr=0.0010
[2025-05-03 21:23:43,228][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:23:50,069][train][INFO] - Epoch 109/140, Val Acc=0.7346, Val Loss=1.3361, lr=0.0010
[2025-05-03 21:23:58,407][train][INFO] - Epoch 110/140, Val Acc=0.7351, Val Loss=1.3416, lr=0.0010
[2025-05-03 21:24:06,565][train][INFO] - Epoch 111/140, Val Acc=0.7353, Val Loss=1.3479, lr=0.0010
[2025-05-03 21:24:10,716][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:24:14,198][train][INFO] - Epoch 112/140, Val Acc=0.7359, Val Loss=1.3442, lr=0.0010
[2025-05-03 21:24:21,907][train][INFO] - Epoch 113/140, Val Acc=0.7361, Val Loss=1.3417, lr=0.0010
[2025-05-03 21:24:30,262][train][INFO] - Epoch 114/140, Val Acc=0.7348, Val Loss=1.3416, lr=0.0010
[2025-05-03 21:24:38,147][train][INFO] - Epoch 115/140, Val Acc=0.7345, Val Loss=1.3442, lr=0.0010
[2025-05-03 21:24:38,810][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:24:45,923][train][INFO] - Epoch 116/140, Val Acc=0.7370, Val Loss=1.3430, lr=0.0010
[2025-05-03 21:24:52,976][train][INFO] - Epoch 117/140, Val Acc=0.7381, Val Loss=1.3432, lr=0.0010
[2025-05-03 21:25:01,448][train][INFO] - Epoch 118/140, Val Acc=0.7350, Val Loss=1.3447, lr=0.0010
[2025-05-03 21:25:06,558][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:25:09,590][train][INFO] - Epoch 119/140, Val Acc=0.7334, Val Loss=1.3541, lr=0.0010
[2025-05-03 21:25:16,974][train][INFO] - Epoch 120/140, Val Acc=0.7341, Val Loss=1.3489, lr=0.0010
[2025-05-03 21:25:25,163][train][INFO] - Epoch 121/140, Val Acc=0.7335, Val Loss=1.3457, lr=0.0001
[2025-05-03 21:25:33,130][train][INFO] - Epoch 122/140, Val Acc=0.7356, Val Loss=1.3432, lr=0.0001
[2025-05-03 21:25:34,510][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:25:41,360][train][INFO] - Epoch 123/140, Val Acc=0.7358, Val Loss=1.3441, lr=0.0001
[2025-05-03 21:25:49,817][train][INFO] - Epoch 124/140, Val Acc=0.7370, Val Loss=1.3430, lr=0.0001
[2025-05-03 21:25:58,252][train][INFO] - Epoch 125/140, Val Acc=0.7352, Val Loss=1.3404, lr=0.0001
[2025-05-03 21:26:00,426][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:26:00,455][meta_train][INFO] - epoch_76 saved !
[2025-05-03 21:26:05,720][train][INFO] - Epoch 126/140, Val Acc=0.7373, Val Loss=1.3357, lr=0.0001
[2025-05-03 21:26:13,551][train][INFO] - Epoch 127/140, Val Acc=0.7356, Val Loss=1.3419, lr=0.0001
[2025-05-03 21:26:22,214][train][INFO] - Epoch 128/140, Val Acc=0.7363, Val Loss=1.3392, lr=0.0001
[2025-05-03 21:26:26,919][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:26:30,214][train][INFO] - Epoch 129/140, Val Acc=0.7372, Val Loss=1.3375, lr=0.0001
[2025-05-03 21:26:38,376][train][INFO] - Epoch 130/140, Val Acc=0.7378, Val Loss=1.3367, lr=0.0001
[2025-05-03 21:26:45,849][train][INFO] - Epoch 131/140, Val Acc=0.7360, Val Loss=1.3470, lr=0.0001
[2025-05-03 21:26:54,041][train][INFO] - Epoch 132/140, Val Acc=0.7372, Val Loss=1.3397, lr=0.0001
[2025-05-03 21:26:54,659][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:27:02,559][train][INFO] - Epoch 133/140, Val Acc=0.7372, Val Loss=1.3376, lr=0.0001
[2025-05-03 21:27:09,791][train][INFO] - Epoch 134/140, Val Acc=0.7363, Val Loss=1.3383, lr=0.0001
[2025-05-03 21:27:17,739][train][INFO] - Epoch 135/140, Val Acc=0.7381, Val Loss=1.3417, lr=0.0001
[2025-05-03 21:27:22,568][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:27:26,029][train][INFO] - Epoch 136/140, Val Acc=0.7383, Val Loss=1.3374, lr=0.0001
[2025-05-03 21:27:32,995][train][INFO] - Epoch 137/140, Val Acc=0.7365, Val Loss=1.3375, lr=0.0001
[2025-05-03 21:27:39,416][train][INFO] - Epoch 138/140, Val Acc=0.7374, Val Loss=1.3382, lr=0.0001
[2025-05-03 21:27:47,365][train][INFO] - Epoch 139/140, Val Acc=0.7363, Val Loss=1.3383, lr=0.0001
[2025-05-03 21:27:50,599][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:27:55,299][train][INFO] - Epoch 140/140, Val Acc=0.7375, Val Loss=1.3396, lr=0.0001
[2025-05-03 21:28:00,478][train][INFO] - After training : Train Acc=0.9991  Val Acc=0.7383
[2025-05-03 21:28:00,519][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(8, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(52, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(114, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(255, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(253, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(160, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(256, 257, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(257, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(257, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(36, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(33, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(50, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(36, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(29, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(68, 156, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=156, out_features=100, bias=True)
)
[2025-05-03 21:28:00,519][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.7382999658584595
                      Speed up: 1.52   Final speed up: 3.04
[2025-05-03 21:28:18,259][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:28:46,124][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.6055, lr=0.0001
[2025-05-03 21:29:12,937][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:29:40,734][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:29:40,749][meta_train][INFO] - epoch_77 saved !
[2025-05-03 21:30:07,553][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:30:24,336][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 21:30:24,386][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 21:30:24,386][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 21:30:24,386][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 21:30:34,246][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6052, lr=0.0001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 21:30:40,191][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 21:30:40,244][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 21:30:40,244][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 21:30:40,244][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 21:30:43,631][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 21:30:52,287][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 21:31:00,538][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 21:31:00,670][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 21:31:02,763][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:31:08,434][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-03 21:31:09,350][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 21:31:16,296][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 21:31:17,405][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 21:31:24,450][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 21:31:25,513][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 21:31:31,368][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:31:32,520][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 21:31:33,627][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 21:31:40,240][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 21:31:41,872][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 21:31:48,588][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 21:31:50,365][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 21:31:56,777][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 21:31:57,929][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 21:31:58,043][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:32:05,078][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 21:32:05,875][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 21:32:12,431][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 21:32:14,018][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 21:32:20,151][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 21:32:21,736][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 21:32:27,313][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:32:28,171][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 21:32:29,968][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 21:32:35,964][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 21:32:38,418][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 21:32:44,232][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 21:32:46,731][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 21:32:52,633][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 21:32:55,067][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 21:32:56,162][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:33:00,415][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 21:33:03,112][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 21:33:08,338][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 21:33:10,859][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 21:33:16,476][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 21:33:18,932][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 21:33:24,571][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 21:33:24,726][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:33:24,757][meta_train][INFO] - epoch_78 saved !
[2025-05-03 21:33:26,944][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 21:33:32,836][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 21:33:34,648][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 21:33:41,318][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 21:33:42,697][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 21:33:48,815][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 21:33:50,729][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 21:33:52,921][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:33:57,437][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 21:33:58,336][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 21:34:05,242][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 21:34:06,505][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 21:34:13,228][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 21:34:14,293][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 21:34:20,230][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:34:21,179][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 21:34:22,067][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 21:34:29,531][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 21:34:29,646][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 21:34:37,397][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 21:34:38,010][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 21:34:45,474][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 21:34:46,205][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 21:34:49,358][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:34:53,874][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 21:34:54,599][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 21:35:01,787][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 21:35:02,267][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 21:35:09,872][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 21:35:10,120][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 21:35:17,856][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:35:18,033][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 21:35:18,364][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 21:35:26,051][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 21:35:26,627][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 21:35:34,116][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 21:35:35,000][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 21:35:42,230][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 21:35:42,828][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 21:35:46,880][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:35:50,011][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 21:35:50,400][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 21:35:58,174][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 21:35:58,528][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 21:36:06,228][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 21:36:06,491][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 21:36:13,671][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 21:36:14,821][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 21:36:15,461][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:36:22,178][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 21:36:22,752][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 21:36:30,351][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 21:36:30,412][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 21:36:38,118][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 21:36:38,667][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 21:36:44,591][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:36:45,432][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 21:36:46,477][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 21:36:53,626][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 21:36:54,519][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 21:37:01,795][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 21:37:02,930][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 21:37:09,816][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 21:37:10,448][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 21:37:12,219][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:37:12,237][meta_train][INFO] - epoch_79 saved !
[2025-05-03 21:37:17,473][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 21:37:18,311][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 21:37:24,999][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 21:37:26,262][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 21:37:33,246][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 21:37:34,256][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 21:37:39,770][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:37:41,108][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 21:37:42,792][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 21:37:49,338][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 21:37:50,999][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 21:37:57,034][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 21:37:58,895][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 21:38:04,781][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 21:38:07,246][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 21:38:08,332][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:38:12,812][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 21:38:15,731][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 21:38:20,810][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 21:38:23,694][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 21:38:28,913][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 21:38:31,550][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 21:38:36,986][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:38:37,252][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 21:38:39,818][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 21:38:45,643][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 21:38:47,993][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 21:38:53,318][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 21:38:55,771][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 21:39:00,948][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 21:39:04,108][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 21:39:05,746][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:39:08,215][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 21:39:12,267][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 21:39:16,182][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 21:39:20,422][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 21:39:23,647][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 21:39:28,201][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 21:39:31,667][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 21:39:33,885][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:39:35,467][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 21:39:39,916][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 21:39:43,202][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 21:39:47,634][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 21:39:51,179][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 21:39:55,754][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 21:39:58,557][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 21:40:02,352][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:40:03,885][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 21:40:06,327][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 21:40:12,185][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 21:40:14,719][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 21:40:20,508][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 21:40:22,642][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 21:40:28,849][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 21:40:30,260][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 21:40:31,201][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:40:36,946][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 21:40:38,357][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 21:40:44,958][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 21:40:46,239][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 21:40:52,990][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 21:40:54,316][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 21:40:59,348][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:40:59,366][meta_train][INFO] - epoch_80 saved !
[2025-05-03 21:41:00,856][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 21:41:02,500][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 21:41:08,373][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 21:41:10,390][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 21:41:16,501][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 21:41:18,181][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 21:41:24,256][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 21:41:26,101][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 21:41:27,876][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:41:32,204][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 21:41:33,989][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 21:41:40,124][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 21:41:41,810][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 21:41:48,118][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 21:41:50,029][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:41:55,549][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 21:41:56,897][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:41:58,201][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 21:42:02,969][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:42:06,244][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 21:42:10,792][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 21:42:14,229][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 21:42:18,541][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 21:42:22,286][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:42:25,401][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:42:26,699][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 21:42:29,901][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 21:42:34,460][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 21:42:37,856][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 21:42:42,153][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 21:42:45,186][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 21:42:50,428][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 21:42:53,209][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 21:42:53,280][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:42:58,974][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 21:43:01,130][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:43:06,676][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 21:43:09,254][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 21:43:14,432][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:43:17,511][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 21:43:20,927][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:43:22,980][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 21:43:26,014][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 21:43:31,132][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 21:43:33,950][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:43:39,396][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 21:43:41,817][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 21:43:47,271][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 21:43:49,840][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:43:50,110][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 21:43:55,617][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 21:43:57,455][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 21:44:03,419][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 21:44:05,402][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 21:44:10,528][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 21:44:10,539][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 21:44:11,982][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 21:44:18,000][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:44:19,980][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 21:44:25,234][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 21:44:25,244][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-03 21:44:47,431][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:44:47,450][meta_train][INFO] - epoch_81 saved !
[2025-05-03 21:45:15,123][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:45:43,866][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:45:56,033][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 21:46:08,313][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-03 21:46:12,956][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:46:42,413][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:47:10,814][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:47:39,434][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:48:08,979][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:48:22,599][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 21:48:23,045][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 21:48:33,545][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-03 21:48:34,052][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-03 21:48:38,511][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:48:38,526][meta_train][INFO] - epoch_82 saved !
[2025-05-03 21:49:05,148][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:49:32,583][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:50:00,104][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:50:25,680][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:50:52,339][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:51:20,415][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:51:47,613][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:52:15,286][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.6054, lr=0.0001
[2025-05-03 21:52:15,317][meta_train][INFO] - epoch_83 saved !
[2025-05-03 21:52:42,672][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:53:10,472][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:53:37,927][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:54:03,959][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:54:31,603][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:54:58,361][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:55:25,277][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:55:52,460][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:55:52,497][meta_train][INFO] - epoch_84 saved !
[2025-05-03 21:56:19,376][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:56:46,459][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:57:14,557][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:57:41,416][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:58:09,023][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:58:34,929][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:59:01,740][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 21:59:29,328][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 21:59:29,344][meta_train][INFO] - epoch_85 saved !
[2025-05-03 21:59:57,189][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:00:23,774][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:00:50,920][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:01:19,016][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:01:46,265][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:02:13,919][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:02:40,826][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:03:06,891][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:03:06,908][meta_train][INFO] - epoch_86 saved !
[2025-05-03 22:03:34,674][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:04:01,814][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:04:28,863][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:04:56,207][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:05:22,244][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:05:49,741][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:06:17,044][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:06:43,865][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:06:43,883][meta_train][INFO] - epoch_87 saved !
[2025-05-03 22:07:11,479][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:07:38,461][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:08:06,219][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:08:33,496][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:09:00,072][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:09:27,875][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:09:53,521][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:10:21,466][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:10:21,481][meta_train][INFO] - epoch_88 saved !
[2025-05-03 22:10:47,716][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:11:15,205][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:11:42,977][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:12:09,698][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:12:37,000][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:13:04,534][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:13:31,581][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:13:58,218][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:13:58,233][meta_train][INFO] - epoch_89 saved !
[2025-05-03 22:14:25,906][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:14:53,660][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:15:20,577][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:15:46,880][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:16:14,082][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:16:40,863][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:17:08,842][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:17:22,179][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 22:17:22,228][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 22:17:22,229][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 22:17:22,229][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 22:17:34,550][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-03 22:17:34,631][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-03 22:17:34,631][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-03 22:17:34,631][get_dataset_model_loader][INFO] - ==================================================
[2025-05-03 22:17:35,447][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:17:35,468][meta_train][INFO] - epoch_90 saved !
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 22:17:42,068][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-03 22:17:50,417][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-03 22:17:55,118][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-03 22:17:58,713][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 22:18:03,156][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-03 22:18:04,404][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:18:07,315][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 22:18:11,238][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-03 22:18:15,241][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 22:18:19,580][train][INFO] - Epoch 3/100, Val Acc=0.4599, Val Loss=2.0722, lr=0.0100
[2025-05-03 22:18:23,189][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 22:18:27,502][train][INFO] - Epoch 4/100, Val Acc=0.5493, Val Loss=1.6971, lr=0.0100
[2025-05-03 22:18:30,571][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 22:18:33,096][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:18:35,836][train][INFO] - Epoch 5/100, Val Acc=0.5582, Val Loss=1.7123, lr=0.0100
[2025-05-03 22:18:38,294][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 22:18:44,328][train][INFO] - Epoch 6/100, Val Acc=0.5604, Val Loss=1.7875, lr=0.0100
[2025-05-03 22:18:46,574][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 22:18:52,524][train][INFO] - Epoch 7/100, Val Acc=0.5908, Val Loss=1.5787, lr=0.0100
[2025-05-03 22:18:54,513][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 22:19:00,816][train][INFO] - Epoch 8/100, Val Acc=0.6318, Val Loss=1.4421, lr=0.0100
[2025-05-03 22:19:01,046][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:19:03,298][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 22:19:09,407][train][INFO] - Epoch 9/100, Val Acc=0.5933, Val Loss=1.6393, lr=0.0100
[2025-05-03 22:19:11,741][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 22:19:17,949][train][INFO] - Epoch 10/100, Val Acc=0.6250, Val Loss=1.4813, lr=0.0100
[2025-05-03 22:19:20,246][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 22:19:26,105][train][INFO] - Epoch 11/100, Val Acc=0.6390, Val Loss=1.4268, lr=0.0100
[2025-05-03 22:19:28,146][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 22:19:29,219][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:19:34,113][train][INFO] - Epoch 12/100, Val Acc=0.6311, Val Loss=1.4926, lr=0.0100
[2025-05-03 22:19:37,040][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 22:19:41,960][train][INFO] - Epoch 13/100, Val Acc=0.6389, Val Loss=1.4512, lr=0.0100
[2025-05-03 22:19:45,204][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 22:19:50,268][train][INFO] - Epoch 14/100, Val Acc=0.6448, Val Loss=1.4405, lr=0.0100
[2025-05-03 22:19:52,673][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 22:19:57,792][train][INFO] - Epoch 15/100, Val Acc=0.6346, Val Loss=1.4719, lr=0.0100
[2025-05-03 22:19:57,824][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:20:00,324][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 22:20:05,536][train][INFO] - Epoch 16/100, Val Acc=0.6406, Val Loss=1.4571, lr=0.0100
[2025-05-03 22:20:08,162][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 22:20:13,677][train][INFO] - Epoch 17/100, Val Acc=0.6483, Val Loss=1.4268, lr=0.0100
[2025-05-03 22:20:15,945][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 22:20:21,474][train][INFO] - Epoch 18/100, Val Acc=0.6437, Val Loss=1.4489, lr=0.0100
[2025-05-03 22:20:23,610][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 22:20:26,301][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:20:29,310][train][INFO] - Epoch 19/100, Val Acc=0.6475, Val Loss=1.4478, lr=0.0100
[2025-05-03 22:20:31,518][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 22:20:37,746][train][INFO] - Epoch 20/100, Val Acc=0.6486, Val Loss=1.4731, lr=0.0100
[2025-05-03 22:20:39,712][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 22:20:45,767][train][INFO] - Epoch 21/100, Val Acc=0.6565, Val Loss=1.4309, lr=0.0100
[2025-05-03 22:20:47,110][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 22:20:53,517][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:20:53,560][train][INFO] - Epoch 22/100, Val Acc=0.6498, Val Loss=1.4978, lr=0.0100
[2025-05-03 22:20:55,394][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 22:21:01,444][train][INFO] - Epoch 23/100, Val Acc=0.6495, Val Loss=1.4717, lr=0.0100
[2025-05-03 22:21:03,769][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 22:21:09,183][train][INFO] - Epoch 24/100, Val Acc=0.6563, Val Loss=1.4546, lr=0.0100
[2025-05-03 22:21:10,994][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 22:21:17,303][train][INFO] - Epoch 25/100, Val Acc=0.6651, Val Loss=1.4194, lr=0.0100
[2025-05-03 22:21:19,487][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 22:21:21,475][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:21:21,496][meta_train][INFO] - epoch_91 saved !
[2025-05-03 22:21:25,543][train][INFO] - Epoch 26/100, Val Acc=0.6458, Val Loss=1.5080, lr=0.0100
[2025-05-03 22:21:28,187][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 22:21:33,772][train][INFO] - Epoch 27/100, Val Acc=0.6555, Val Loss=1.4908, lr=0.0100
[2025-05-03 22:21:35,336][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 22:21:41,665][train][INFO] - Epoch 28/100, Val Acc=0.6363, Val Loss=1.6242, lr=0.0100
[2025-05-03 22:21:43,461][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 22:21:49,945][train][INFO] - Epoch 29/100, Val Acc=0.6657, Val Loss=1.4430, lr=0.0100
[2025-05-03 22:21:50,318][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:21:51,803][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 22:21:58,295][train][INFO] - Epoch 30/100, Val Acc=0.6565, Val Loss=1.5046, lr=0.0100
[2025-05-03 22:22:00,279][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 22:22:06,401][train][INFO] - Epoch 31/100, Val Acc=0.6559, Val Loss=1.5161, lr=0.0100
[2025-05-03 22:22:08,128][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 22:22:14,393][train][INFO] - Epoch 32/100, Val Acc=0.6723, Val Loss=1.4010, lr=0.0100
[2025-05-03 22:22:16,577][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 22:22:18,840][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:22:22,350][train][INFO] - Epoch 33/100, Val Acc=0.6774, Val Loss=1.4044, lr=0.0100
[2025-05-03 22:22:25,097][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 22:22:31,132][train][INFO] - Epoch 34/100, Val Acc=0.6600, Val Loss=1.4993, lr=0.0100
[2025-05-03 22:22:33,560][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 22:22:38,858][train][INFO] - Epoch 35/100, Val Acc=0.6625, Val Loss=1.4941, lr=0.0100
[2025-05-03 22:22:42,136][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 22:22:47,032][train][INFO] - Epoch 36/100, Val Acc=0.6664, Val Loss=1.4756, lr=0.0100
[2025-05-03 22:22:47,132][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:22:50,001][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 22:22:55,291][train][INFO] - Epoch 37/100, Val Acc=0.6536, Val Loss=1.5602, lr=0.0100
[2025-05-03 22:22:58,834][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 22:23:03,700][train][INFO] - Epoch 38/100, Val Acc=0.6668, Val Loss=1.4439, lr=0.0100
[2025-05-03 22:23:06,257][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 22:23:11,272][train][INFO] - Epoch 39/100, Val Acc=0.6720, Val Loss=1.4475, lr=0.0100
[2025-05-03 22:23:13,914][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 22:23:15,792][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:23:19,272][train][INFO] - Epoch 40/100, Val Acc=0.6591, Val Loss=1.5278, lr=0.0100
[2025-05-03 22:23:22,483][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 22:23:27,273][train][INFO] - Epoch 41/100, Val Acc=0.6615, Val Loss=1.5111, lr=0.0100
[2025-05-03 22:23:30,426][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 22:23:35,615][train][INFO] - Epoch 42/100, Val Acc=0.6473, Val Loss=1.5827, lr=0.0100
[2025-05-03 22:23:38,913][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 22:23:43,102][train][INFO] - Epoch 43/100, Val Acc=0.6470, Val Loss=1.6040, lr=0.0100
[2025-05-03 22:23:44,385][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:23:46,998][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 22:23:50,713][train][INFO] - Epoch 44/100, Val Acc=0.6599, Val Loss=1.5247, lr=0.0100
[2025-05-03 22:23:55,334][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 22:23:58,855][train][INFO] - Epoch 45/100, Val Acc=0.6541, Val Loss=1.5705, lr=0.0100
[2025-05-03 22:24:03,523][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 22:24:06,688][train][INFO] - Epoch 46/100, Val Acc=0.6622, Val Loss=1.5341, lr=0.0100
[2025-05-03 22:24:11,135][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:24:11,404][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 22:24:14,873][train][INFO] - Epoch 47/100, Val Acc=0.6617, Val Loss=1.5739, lr=0.0100
[2025-05-03 22:24:19,991][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 22:24:22,078][train][INFO] - Epoch 48/100, Val Acc=0.6537, Val Loss=1.5930, lr=0.0100
[2025-05-03 22:24:28,373][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 22:24:29,931][train][INFO] - Epoch 49/100, Val Acc=0.6802, Val Loss=1.4455, lr=0.0100
[2025-05-03 22:24:36,567][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 22:24:37,249][train][INFO] - Epoch 50/100, Val Acc=0.6767, Val Loss=1.4637, lr=0.0100
[2025-05-03 22:24:39,710][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:24:44,430][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 22:24:45,426][train][INFO] - Epoch 51/100, Val Acc=0.6647, Val Loss=1.5262, lr=0.0100
[2025-05-03 22:24:52,708][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 22:24:53,127][train][INFO] - Epoch 52/100, Val Acc=0.6611, Val Loss=1.5687, lr=0.0100
[2025-05-03 22:25:00,483][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 22:25:01,189][train][INFO] - Epoch 53/100, Val Acc=0.6684, Val Loss=1.5003, lr=0.0100
[2025-05-03 22:25:08,712][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:25:08,739][meta_train][INFO] - epoch_92 saved !
[2025-05-03 22:25:08,773][train][INFO] - Epoch 54/100, Val Acc=0.6621, Val Loss=1.5486, lr=0.0100
[2025-05-03 22:25:08,856][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 22:25:16,754][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 22:25:17,432][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.5628, lr=0.0100
[2025-05-03 22:25:24,307][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 22:25:25,099][train][INFO] - Epoch 56/100, Val Acc=0.6680, Val Loss=1.5180, lr=0.0100
[2025-05-03 22:25:32,583][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 22:25:33,363][train][INFO] - Epoch 57/100, Val Acc=0.6592, Val Loss=1.5498, lr=0.0100
[2025-05-03 22:25:37,437][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:25:40,604][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 22:25:41,551][train][INFO] - Epoch 58/100, Val Acc=0.6550, Val Loss=1.5836, lr=0.0100
[2025-05-03 22:25:48,459][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 22:25:49,711][train][INFO] - Epoch 59/100, Val Acc=0.6597, Val Loss=1.5834, lr=0.0100
[2025-05-03 22:25:56,487][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 22:25:58,024][train][INFO] - Epoch 60/100, Val Acc=0.6627, Val Loss=1.5651, lr=0.0100
[2025-05-03 22:26:04,626][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 22:26:05,747][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:26:06,418][train][INFO] - Epoch 61/100, Val Acc=0.7244, Val Loss=1.2475, lr=0.0010
[2025-05-03 22:26:13,053][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 22:26:15,095][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2397, lr=0.0010
[2025-05-03 22:26:21,405][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 22:26:23,407][train][INFO] - Epoch 63/100, Val Acc=0.7302, Val Loss=1.2548, lr=0.0010
[2025-05-03 22:26:29,227][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 22:26:30,939][train][INFO] - Epoch 64/100, Val Acc=0.7295, Val Loss=1.2587, lr=0.0010
[2025-05-03 22:26:34,145][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:26:37,485][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 22:26:38,992][train][INFO] - Epoch 65/100, Val Acc=0.7317, Val Loss=1.2619, lr=0.0010
[2025-05-03 22:26:45,741][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 22:26:47,248][train][INFO] - Epoch 66/100, Val Acc=0.7344, Val Loss=1.2640, lr=0.0010
[2025-05-03 22:26:53,993][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 22:26:54,021][train][INFO] - Epoch 67/100, Val Acc=0.7319, Val Loss=1.2704, lr=0.0010
[2025-05-03 22:27:02,211][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:27:02,409][train][INFO] - Epoch 68/100, Val Acc=0.7325, Val Loss=1.2652, lr=0.0010
[2025-05-03 22:27:02,675][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 22:27:10,963][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 22:27:11,180][train][INFO] - Epoch 69/100, Val Acc=0.7358, Val Loss=1.2836, lr=0.0010
[2025-05-03 22:27:19,238][train][INFO] - Epoch 70/100, Val Acc=0.7342, Val Loss=1.2874, lr=0.0010
[2025-05-03 22:27:19,267][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 22:27:27,266][train][INFO] - Epoch 71/100, Val Acc=0.7332, Val Loss=1.2857, lr=0.0010
[2025-05-03 22:27:27,475][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 22:27:29,639][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:27:35,592][train][INFO] - Epoch 72/100, Val Acc=0.7354, Val Loss=1.2872, lr=0.0010
[2025-05-03 22:27:36,059][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 22:27:43,651][train][INFO] - Epoch 73/100, Val Acc=0.7350, Val Loss=1.2927, lr=0.0010
[2025-05-03 22:27:43,810][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 22:27:51,039][train][INFO] - Epoch 74/100, Val Acc=0.7368, Val Loss=1.2936, lr=0.0010
[2025-05-03 22:27:52,232][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 22:27:57,646][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:27:58,928][train][INFO] - Epoch 75/100, Val Acc=0.7368, Val Loss=1.2926, lr=0.0010
[2025-05-03 22:28:00,744][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 22:28:07,445][train][INFO] - Epoch 76/100, Val Acc=0.7362, Val Loss=1.2925, lr=0.0010
[2025-05-03 22:28:08,798][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 22:28:15,257][train][INFO] - Epoch 77/100, Val Acc=0.7381, Val Loss=1.3024, lr=0.0010
[2025-05-03 22:28:17,252][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 22:28:22,952][train][INFO] - Epoch 78/100, Val Acc=0.7379, Val Loss=1.2989, lr=0.0010
[2025-05-03 22:28:25,157][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 22:28:27,177][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:28:31,067][train][INFO] - Epoch 79/100, Val Acc=0.7382, Val Loss=1.3112, lr=0.0010
[2025-05-03 22:28:33,266][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 22:28:38,860][train][INFO] - Epoch 80/100, Val Acc=0.7376, Val Loss=1.2968, lr=0.0010
[2025-05-03 22:28:40,530][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 22:28:46,606][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3110, lr=0.0010
[2025-05-03 22:28:48,649][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 22:28:53,567][train][INFO] - Epoch 82/100, Val Acc=0.7355, Val Loss=1.3168, lr=0.0010
[2025-05-03 22:28:55,096][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:28:55,113][meta_train][INFO] - epoch_93 saved !
[2025-05-03 22:28:56,746][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 22:29:01,880][train][INFO] - Epoch 83/100, Val Acc=0.7339, Val Loss=1.3171, lr=0.0010
[2025-05-03 22:29:04,902][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 22:29:09,821][train][INFO] - Epoch 84/100, Val Acc=0.7367, Val Loss=1.3172, lr=0.0010
[2025-05-03 22:29:13,237][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 22:29:18,027][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3170, lr=0.0010
[2025-05-03 22:29:21,253][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 22:29:23,625][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:29:26,178][train][INFO] - Epoch 86/100, Val Acc=0.7347, Val Loss=1.3260, lr=0.0010
[2025-05-03 22:29:29,425][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 22:29:34,416][train][INFO] - Epoch 87/100, Val Acc=0.7372, Val Loss=1.3171, lr=0.0010
[2025-05-03 22:29:36,530][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 22:29:42,683][train][INFO] - Epoch 88/100, Val Acc=0.7363, Val Loss=1.3230, lr=0.0010
[2025-05-03 22:29:44,681][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 22:29:50,929][train][INFO] - Epoch 89/100, Val Acc=0.7373, Val Loss=1.3218, lr=0.0010
[2025-05-03 22:29:51,877][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:29:52,919][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 22:29:58,971][train][INFO] - Epoch 90/100, Val Acc=0.7403, Val Loss=1.3186, lr=0.0010
[2025-05-03 22:30:01,149][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 22:30:06,910][train][INFO] - Epoch 91/100, Val Acc=0.7377, Val Loss=1.3145, lr=0.0001
[2025-05-03 22:30:08,943][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 22:30:15,018][train][INFO] - Epoch 92/100, Val Acc=0.7390, Val Loss=1.3180, lr=0.0001
[2025-05-03 22:30:17,374][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 22:30:19,262][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:30:22,884][train][INFO] - Epoch 93/100, Val Acc=0.7371, Val Loss=1.3135, lr=0.0001
[2025-05-03 22:30:25,007][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 22:30:31,006][train][INFO] - Epoch 94/100, Val Acc=0.7401, Val Loss=1.3117, lr=0.0001
[2025-05-03 22:30:33,318][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 22:30:39,198][train][INFO] - Epoch 95/100, Val Acc=0.7393, Val Loss=1.3193, lr=0.0001
[2025-05-03 22:30:41,587][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 22:30:47,067][train][INFO] - Epoch 96/100, Val Acc=0.7386, Val Loss=1.3180, lr=0.0001
[2025-05-03 22:30:47,151][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:30:48,614][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 22:30:55,399][train][INFO] - Epoch 97/100, Val Acc=0.7397, Val Loss=1.3118, lr=0.0001
[2025-05-03 22:30:57,218][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 22:31:03,818][train][INFO] - Epoch 98/100, Val Acc=0.7398, Val Loss=1.3134, lr=0.0001
[2025-05-03 22:31:03,950][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 22:31:11,566][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 22:31:12,128][train][INFO] - Epoch 99/100, Val Acc=0.7401, Val Loss=1.3192, lr=0.0001
[2025-05-03 22:31:16,680][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:31:16,855][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 22:31:20,034][train][INFO] - Epoch 100/100, Val Acc=0.7388, Val Loss=1.3201, lr=0.0001
[2025-05-03 22:31:25,049][train][INFO] - After training : Train Acc=0.9986  Val Acc=0.7403
[2025-05-03 22:31:25,601][Progressive pruning][INFO] - Train acc : 0.0749799981713295   Val acc : 0.0689999982714653
[2025-05-03 22:31:25,601][Progressive pruning][INFO] - Current speed up: 1.76
[2025-05-03 22:31:30,711][train][INFO] - Before training : Train Acc=0.0751  Val Acc=0.0690
[2025-05-03 22:31:33,926][Progressive pruning][INFO] - Train acc : 0.029039999470114708   Val acc : 0.028299998492002487
[2025-05-03 22:31:33,926][Progressive pruning][INFO] - Current speed up: 2.01
[2025-05-03 22:31:39,209][train][INFO] - Before training : Train Acc=0.0297  Val Acc=0.0283
[2025-05-03 22:31:39,260][train][INFO] - Epoch 1/140, Val Acc=0.5707, Val Loss=1.8190, lr=0.0100
[2025-05-03 22:31:44,143][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:31:47,615][train][INFO] - Epoch 1/140, Val Acc=0.5389, Val Loss=1.8894, lr=0.0100
[2025-05-03 22:31:47,631][train][INFO] - Epoch 2/140, Val Acc=0.6173, Val Loss=1.5813, lr=0.0100
[2025-05-03 22:31:55,774][train][INFO] - Epoch 2/140, Val Acc=0.5947, Val Loss=1.6138, lr=0.0100
[2025-05-03 22:31:56,061][train][INFO] - Epoch 3/140, Val Acc=0.6182, Val Loss=1.5846, lr=0.0100
[2025-05-03 22:32:04,097][train][INFO] - Epoch 3/140, Val Acc=0.6027, Val Loss=1.5924, lr=0.0100
[2025-05-03 22:32:04,296][train][INFO] - Epoch 4/140, Val Acc=0.6227, Val Loss=1.5871, lr=0.0100
[2025-05-03 22:32:12,433][train][INFO] - Epoch 4/140, Val Acc=0.5983, Val Loss=1.6642, lr=0.0100
[2025-05-03 22:32:12,802][train][INFO] - Epoch 5/140, Val Acc=0.6092, Val Loss=1.6567, lr=0.0100
[2025-05-03 22:32:12,942][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:32:20,613][train][INFO] - Epoch 5/140, Val Acc=0.6283, Val Loss=1.5247, lr=0.0100
[2025-05-03 22:32:20,752][train][INFO] - Epoch 6/140, Val Acc=0.6316, Val Loss=1.5552, lr=0.0100
[2025-05-03 22:32:28,682][train][INFO] - Epoch 6/140, Val Acc=0.6094, Val Loss=1.6254, lr=0.0100
[2025-05-03 22:32:28,832][train][INFO] - Epoch 7/140, Val Acc=0.6216, Val Loss=1.6295, lr=0.0100
[2025-05-03 22:32:37,226][train][INFO] - Epoch 7/140, Val Acc=0.6105, Val Loss=1.6445, lr=0.0100
[2025-05-03 22:32:37,457][train][INFO] - Epoch 8/140, Val Acc=0.6475, Val Loss=1.5328, lr=0.0100
[2025-05-03 22:32:41,785][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:32:41,808][meta_train][INFO] - epoch_94 saved !
[2025-05-03 22:32:45,306][train][INFO] - Epoch 9/140, Val Acc=0.6545, Val Loss=1.4703, lr=0.0100
[2025-05-03 22:32:45,349][train][INFO] - Epoch 8/140, Val Acc=0.6050, Val Loss=1.6774, lr=0.0100
[2025-05-03 22:32:53,804][train][INFO] - Epoch 9/140, Val Acc=0.6386, Val Loss=1.4785, lr=0.0100
[2025-05-03 22:32:53,969][train][INFO] - Epoch 10/140, Val Acc=0.6322, Val Loss=1.5953, lr=0.0100
[2025-05-03 22:33:02,341][train][INFO] - Epoch 10/140, Val Acc=0.6485, Val Loss=1.4740, lr=0.0100
[2025-05-03 22:33:02,675][train][INFO] - Epoch 11/140, Val Acc=0.6502, Val Loss=1.4895, lr=0.0100
[2025-05-03 22:33:09,497][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:33:10,589][train][INFO] - Epoch 11/140, Val Acc=0.6539, Val Loss=1.3970, lr=0.0100
[2025-05-03 22:33:11,169][train][INFO] - Epoch 12/140, Val Acc=0.6476, Val Loss=1.5846, lr=0.0100
[2025-05-03 22:33:19,002][train][INFO] - Epoch 12/140, Val Acc=0.6385, Val Loss=1.5199, lr=0.0100
[2025-05-03 22:33:19,501][train][INFO] - Epoch 13/140, Val Acc=0.6524, Val Loss=1.5373, lr=0.0100
[2025-05-03 22:33:27,307][train][INFO] - Epoch 13/140, Val Acc=0.6271, Val Loss=1.5990, lr=0.0100
[2025-05-03 22:33:27,586][train][INFO] - Epoch 14/140, Val Acc=0.6433, Val Loss=1.5616, lr=0.0100
[2025-05-03 22:33:35,305][train][INFO] - Epoch 14/140, Val Acc=0.6251, Val Loss=1.6146, lr=0.0100
[2025-05-03 22:33:35,788][train][INFO] - Epoch 15/140, Val Acc=0.6473, Val Loss=1.5348, lr=0.0100
[2025-05-03 22:33:38,878][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:33:43,540][train][INFO] - Epoch 15/140, Val Acc=0.6401, Val Loss=1.5084, lr=0.0100
[2025-05-03 22:33:44,373][train][INFO] - Epoch 16/140, Val Acc=0.6416, Val Loss=1.5979, lr=0.0100
[2025-05-03 22:33:51,422][train][INFO] - Epoch 16/140, Val Acc=0.6394, Val Loss=1.5319, lr=0.0100
[2025-05-03 22:33:52,341][train][INFO] - Epoch 17/140, Val Acc=0.6428, Val Loss=1.5913, lr=0.0100
[2025-05-03 22:33:59,289][train][INFO] - Epoch 17/140, Val Acc=0.6314, Val Loss=1.6067, lr=0.0100
[2025-05-03 22:34:00,766][train][INFO] - Epoch 18/140, Val Acc=0.6456, Val Loss=1.5707, lr=0.0100
[2025-05-03 22:34:06,431][train][INFO] - Epoch 18/140, Val Acc=0.6260, Val Loss=1.5998, lr=0.0100
[2025-05-03 22:34:06,965][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:34:09,081][train][INFO] - Epoch 19/140, Val Acc=0.6519, Val Loss=1.5386, lr=0.0100
[2025-05-03 22:34:14,162][train][INFO] - Epoch 19/140, Val Acc=0.6490, Val Loss=1.4817, lr=0.0100
[2025-05-03 22:34:17,524][train][INFO] - Epoch 20/140, Val Acc=0.6457, Val Loss=1.5840, lr=0.0100
[2025-05-03 22:34:22,405][train][INFO] - Epoch 20/140, Val Acc=0.6353, Val Loss=1.6193, lr=0.0100
[2025-05-03 22:34:25,640][train][INFO] - Epoch 21/140, Val Acc=0.6607, Val Loss=1.4803, lr=0.0100
[2025-05-03 22:34:29,919][train][INFO] - Epoch 21/140, Val Acc=0.6384, Val Loss=1.5658, lr=0.0100
[2025-05-03 22:34:33,682][train][INFO] - Epoch 22/140, Val Acc=0.6616, Val Loss=1.4601, lr=0.0100
[2025-05-03 22:34:35,203][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:34:37,736][train][INFO] - Epoch 22/140, Val Acc=0.6557, Val Loss=1.4937, lr=0.0100
[2025-05-03 22:34:41,581][train][INFO] - Epoch 23/140, Val Acc=0.6464, Val Loss=1.6094, lr=0.0100
[2025-05-03 22:34:44,638][train][INFO] - Epoch 23/140, Val Acc=0.6442, Val Loss=1.5450, lr=0.0100
[2025-05-03 22:34:49,578][train][INFO] - Epoch 24/140, Val Acc=0.6548, Val Loss=1.4848, lr=0.0100
[2025-05-03 22:34:52,285][train][INFO] - Epoch 24/140, Val Acc=0.6526, Val Loss=1.5006, lr=0.0100
[2025-05-03 22:34:57,210][train][INFO] - Epoch 25/140, Val Acc=0.6614, Val Loss=1.5015, lr=0.0100
[2025-05-03 22:35:00,648][train][INFO] - Epoch 25/140, Val Acc=0.6526, Val Loss=1.4966, lr=0.0100
[2025-05-03 22:35:04,633][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:35:05,441][train][INFO] - Epoch 26/140, Val Acc=0.6559, Val Loss=1.5324, lr=0.0100
[2025-05-03 22:35:08,226][train][INFO] - Epoch 26/140, Val Acc=0.6454, Val Loss=1.5406, lr=0.0100
[2025-05-03 22:35:13,870][train][INFO] - Epoch 27/140, Val Acc=0.6586, Val Loss=1.4911, lr=0.0100
[2025-05-03 22:35:16,141][train][INFO] - Epoch 27/140, Val Acc=0.6557, Val Loss=1.4874, lr=0.0100
[2025-05-03 22:35:22,255][train][INFO] - Epoch 28/140, Val Acc=0.6417, Val Loss=1.6184, lr=0.0100
[2025-05-03 22:35:24,427][train][INFO] - Epoch 28/140, Val Acc=0.6319, Val Loss=1.6203, lr=0.0100
[2025-05-03 22:35:30,473][train][INFO] - Epoch 29/140, Val Acc=0.6512, Val Loss=1.5754, lr=0.0100
[2025-05-03 22:35:32,223][train][INFO] - Epoch 29/140, Val Acc=0.6501, Val Loss=1.5149, lr=0.0100
[2025-05-03 22:35:32,467][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:35:38,855][train][INFO] - Epoch 30/140, Val Acc=0.6462, Val Loss=1.6119, lr=0.0100
[2025-05-03 22:35:40,603][train][INFO] - Epoch 30/140, Val Acc=0.6479, Val Loss=1.5595, lr=0.0100
[2025-05-03 22:35:46,155][train][INFO] - Epoch 31/140, Val Acc=0.6560, Val Loss=1.5181, lr=0.0100
[2025-05-03 22:35:48,133][train][INFO] - Epoch 31/140, Val Acc=0.6504, Val Loss=1.5405, lr=0.0100
[2025-05-03 22:35:55,003][train][INFO] - Epoch 32/140, Val Acc=0.6477, Val Loss=1.5727, lr=0.0100
[2025-05-03 22:35:56,035][train][INFO] - Epoch 32/140, Val Acc=0.6462, Val Loss=1.5561, lr=0.0100
[2025-05-03 22:36:00,573][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:36:03,132][train][INFO] - Epoch 33/140, Val Acc=0.6553, Val Loss=1.5337, lr=0.0100
[2025-05-03 22:36:03,848][train][INFO] - Epoch 33/140, Val Acc=0.6548, Val Loss=1.5341, lr=0.0100
[2025-05-03 22:36:11,277][train][INFO] - Epoch 34/140, Val Acc=0.6480, Val Loss=1.6463, lr=0.0100
[2025-05-03 22:36:12,349][train][INFO] - Epoch 34/140, Val Acc=0.6418, Val Loss=1.5803, lr=0.0100
[2025-05-03 22:36:19,259][train][INFO] - Epoch 35/140, Val Acc=0.6435, Val Loss=1.6004, lr=0.0100
[2025-05-03 22:36:20,371][train][INFO] - Epoch 35/140, Val Acc=0.6401, Val Loss=1.5795, lr=0.0100
[2025-05-03 22:36:27,982][train][INFO] - Epoch 36/140, Val Acc=0.6559, Val Loss=1.5225, lr=0.0100
[2025-05-03 22:36:28,416][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:36:28,439][meta_train][INFO] - epoch_95 saved !
[2025-05-03 22:36:28,774][train][INFO] - Epoch 36/140, Val Acc=0.6487, Val Loss=1.5746, lr=0.0100
[2025-05-03 22:36:36,475][train][INFO] - Epoch 37/140, Val Acc=0.6421, Val Loss=1.6200, lr=0.0100
[2025-05-03 22:36:37,185][train][INFO] - Epoch 37/140, Val Acc=0.6507, Val Loss=1.5128, lr=0.0100
[2025-05-03 22:36:44,855][train][INFO] - Epoch 38/140, Val Acc=0.6668, Val Loss=1.5025, lr=0.0100
[2025-05-03 22:36:45,151][train][INFO] - Epoch 38/140, Val Acc=0.6601, Val Loss=1.4855, lr=0.0100
[2025-05-03 22:36:53,245][train][INFO] - Epoch 39/140, Val Acc=0.6556, Val Loss=1.5474, lr=0.0100
[2025-05-03 22:36:53,453][train][INFO] - Epoch 39/140, Val Acc=0.6402, Val Loss=1.5829, lr=0.0100
[2025-05-03 22:36:56,870][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:37:01,721][train][INFO] - Epoch 40/140, Val Acc=0.6569, Val Loss=1.5591, lr=0.0100
[2025-05-03 22:37:02,015][train][INFO] - Epoch 40/140, Val Acc=0.6313, Val Loss=1.6690, lr=0.0100
[2025-05-03 22:37:09,812][train][INFO] - Epoch 41/140, Val Acc=0.6548, Val Loss=1.5377, lr=0.0100
[2025-05-03 22:37:10,002][train][INFO] - Epoch 41/140, Val Acc=0.6427, Val Loss=1.5607, lr=0.0100
[2025-05-03 22:37:18,090][train][INFO] - Epoch 42/140, Val Acc=0.6526, Val Loss=1.5752, lr=0.0100
[2025-05-03 22:37:18,236][train][INFO] - Epoch 42/140, Val Acc=0.6463, Val Loss=1.5353, lr=0.0100
[2025-05-03 22:37:24,014][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:37:25,709][train][INFO] - Epoch 43/140, Val Acc=0.6499, Val Loss=1.5448, lr=0.0100
[2025-05-03 22:37:25,950][train][INFO] - Epoch 43/140, Val Acc=0.6276, Val Loss=1.7483, lr=0.0100
[2025-05-03 22:37:34,112][train][INFO] - Epoch 44/140, Val Acc=0.6758, Val Loss=1.4373, lr=0.0100
[2025-05-03 22:37:34,208][train][INFO] - Epoch 44/140, Val Acc=0.6444, Val Loss=1.6279, lr=0.0100
[2025-05-03 22:37:42,226][train][INFO] - Epoch 45/140, Val Acc=0.6484, Val Loss=1.5441, lr=0.0100
[2025-05-03 22:37:42,501][train][INFO] - Epoch 45/140, Val Acc=0.6548, Val Loss=1.5155, lr=0.0100
[2025-05-03 22:37:50,695][train][INFO] - Epoch 46/140, Val Acc=0.6342, Val Loss=1.6976, lr=0.0100
[2025-05-03 22:37:51,155][train][INFO] - Epoch 46/140, Val Acc=0.6224, Val Loss=1.6819, lr=0.0100
[2025-05-03 22:37:52,371][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:37:59,720][train][INFO] - Epoch 47/140, Val Acc=0.6459, Val Loss=1.5926, lr=0.0100
[2025-05-03 22:37:59,889][train][INFO] - Epoch 47/140, Val Acc=0.6465, Val Loss=1.5669, lr=0.0100
[2025-05-03 22:38:07,930][train][INFO] - Epoch 48/140, Val Acc=0.6658, Val Loss=1.4781, lr=0.0100
[2025-05-03 22:38:07,956][train][INFO] - Epoch 48/140, Val Acc=0.6379, Val Loss=1.5880, lr=0.0100
[2025-05-03 22:38:15,971][train][INFO] - Epoch 49/140, Val Acc=0.6482, Val Loss=1.5868, lr=0.0100
[2025-05-03 22:38:16,210][train][INFO] - Epoch 49/140, Val Acc=0.6421, Val Loss=1.5813, lr=0.0100
[2025-05-03 22:38:20,505][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:38:24,154][train][INFO] - Epoch 50/140, Val Acc=0.6698, Val Loss=1.4600, lr=0.0100
[2025-05-03 22:38:24,315][train][INFO] - Epoch 50/140, Val Acc=0.6439, Val Loss=1.5654, lr=0.0100
[2025-05-03 22:38:32,607][train][INFO] - Epoch 51/140, Val Acc=0.6401, Val Loss=1.6839, lr=0.0100
[2025-05-03 22:38:32,662][train][INFO] - Epoch 51/140, Val Acc=0.6408, Val Loss=1.6155, lr=0.0100
[2025-05-03 22:38:40,121][train][INFO] - Epoch 52/140, Val Acc=0.6411, Val Loss=1.6803, lr=0.0100
[2025-05-03 22:38:41,131][train][INFO] - Epoch 52/140, Val Acc=0.6414, Val Loss=1.5731, lr=0.0100
[2025-05-03 22:38:49,029][train][INFO] - Epoch 53/140, Val Acc=0.6437, Val Loss=1.6134, lr=0.0100
[2025-05-03 22:38:49,200][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:38:49,463][train][INFO] - Epoch 53/140, Val Acc=0.6562, Val Loss=1.5561, lr=0.0100
[2025-05-03 22:38:57,333][train][INFO] - Epoch 54/140, Val Acc=0.6477, Val Loss=1.5641, lr=0.0100
[2025-05-03 22:38:57,487][train][INFO] - Epoch 54/140, Val Acc=0.6550, Val Loss=1.5751, lr=0.0100
[2025-05-03 22:39:05,596][train][INFO] - Epoch 55/140, Val Acc=0.6556, Val Loss=1.4915, lr=0.0100
[2025-05-03 22:39:05,658][train][INFO] - Epoch 55/140, Val Acc=0.6504, Val Loss=1.5659, lr=0.0100
[2025-05-03 22:39:13,622][train][INFO] - Epoch 56/140, Val Acc=0.6378, Val Loss=1.6222, lr=0.0100
[2025-05-03 22:39:13,730][train][INFO] - Epoch 56/140, Val Acc=0.6365, Val Loss=1.5959, lr=0.0100
[2025-05-03 22:39:18,220][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:39:21,391][train][INFO] - Epoch 57/140, Val Acc=0.6328, Val Loss=1.7170, lr=0.0100
[2025-05-03 22:39:21,850][train][INFO] - Epoch 57/140, Val Acc=0.6436, Val Loss=1.6318, lr=0.0100
[2025-05-03 22:39:29,745][train][INFO] - Epoch 58/140, Val Acc=0.6394, Val Loss=1.6663, lr=0.0100
[2025-05-03 22:39:29,908][train][INFO] - Epoch 58/140, Val Acc=0.6623, Val Loss=1.5353, lr=0.0100
[2025-05-03 22:39:37,901][train][INFO] - Epoch 59/140, Val Acc=0.6578, Val Loss=1.5676, lr=0.0100
[2025-05-03 22:39:38,001][train][INFO] - Epoch 59/140, Val Acc=0.6508, Val Loss=1.5706, lr=0.0100
[2025-05-03 22:39:45,769][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:39:45,939][train][INFO] - Epoch 60/140, Val Acc=0.6588, Val Loss=1.5044, lr=0.0100
[2025-05-03 22:39:46,419][train][INFO] - Epoch 60/140, Val Acc=0.6564, Val Loss=1.5876, lr=0.0100
[2025-05-03 22:39:54,581][train][INFO] - Epoch 61/140, Val Acc=0.6472, Val Loss=1.5785, lr=0.0100
[2025-05-03 22:39:54,697][train][INFO] - Epoch 61/140, Val Acc=0.6523, Val Loss=1.5914, lr=0.0100
[2025-05-03 22:40:02,465][train][INFO] - Epoch 62/140, Val Acc=0.6482, Val Loss=1.5873, lr=0.0100
[2025-05-03 22:40:03,167][train][INFO] - Epoch 62/140, Val Acc=0.6291, Val Loss=1.7235, lr=0.0100
[2025-05-03 22:40:10,117][train][INFO] - Epoch 63/140, Val Acc=0.6537, Val Loss=1.5529, lr=0.0100
[2025-05-03 22:40:11,318][train][INFO] - Epoch 63/140, Val Acc=0.6564, Val Loss=1.5696, lr=0.0100
[2025-05-03 22:40:15,108][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.6053, lr=0.0001
[2025-05-03 22:40:15,134][meta_train][INFO] - epoch_96 saved !
[2025-05-03 22:40:18,654][train][INFO] - Epoch 64/140, Val Acc=0.6537, Val Loss=1.5579, lr=0.0100
[2025-05-03 22:40:20,099][train][INFO] - Epoch 64/140, Val Acc=0.6561, Val Loss=1.5645, lr=0.0100
[2025-05-03 22:40:26,909][train][INFO] - Epoch 65/140, Val Acc=0.6479, Val Loss=1.6113, lr=0.0100
[2025-05-03 22:40:27,935][train][INFO] - Epoch 65/140, Val Acc=0.6559, Val Loss=1.5580, lr=0.0100
[2025-05-03 22:40:34,411][train][INFO] - Epoch 66/140, Val Acc=0.6366, Val Loss=1.6227, lr=0.0100
[2025-05-03 22:40:36,200][train][INFO] - Epoch 66/140, Val Acc=0.6500, Val Loss=1.5679, lr=0.0100
[2025-05-03 22:40:41,662][train][INFO] - Epoch 67/140, Val Acc=0.6487, Val Loss=1.5541, lr=0.0100
[2025-05-03 22:40:43,218][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:40:44,814][train][INFO] - Epoch 67/140, Val Acc=0.6630, Val Loss=1.5672, lr=0.0100
[2025-05-03 22:40:50,328][train][INFO] - Epoch 68/140, Val Acc=0.6306, Val Loss=1.6997, lr=0.0100
[2025-05-03 22:40:53,524][train][INFO] - Epoch 68/140, Val Acc=0.6574, Val Loss=1.5662, lr=0.0100
[2025-05-03 22:40:58,166][train][INFO] - Epoch 69/140, Val Acc=0.6457, Val Loss=1.6243, lr=0.0100
[2025-05-03 22:41:01,685][train][INFO] - Epoch 69/140, Val Acc=0.6461, Val Loss=1.6260, lr=0.0100
[2025-05-03 22:41:06,176][train][INFO] - Epoch 70/140, Val Acc=0.6508, Val Loss=1.5766, lr=0.0100
[2025-05-03 22:41:09,726][train][INFO] - Epoch 70/140, Val Acc=0.6631, Val Loss=1.5286, lr=0.0100
[2025-05-03 22:41:12,170][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:41:14,424][train][INFO] - Epoch 71/140, Val Acc=0.6471, Val Loss=1.5868, lr=0.0100
[2025-05-03 22:41:17,976][train][INFO] - Epoch 71/140, Val Acc=0.6646, Val Loss=1.5074, lr=0.0100
[2025-05-03 22:41:22,793][train][INFO] - Epoch 72/140, Val Acc=0.6590, Val Loss=1.5395, lr=0.0100
[2025-05-03 22:41:26,268][train][INFO] - Epoch 72/140, Val Acc=0.6636, Val Loss=1.5293, lr=0.0100
[2025-05-03 22:41:31,010][train][INFO] - Epoch 73/140, Val Acc=0.6518, Val Loss=1.5252, lr=0.0100
[2025-05-03 22:41:34,529][train][INFO] - Epoch 73/140, Val Acc=0.6520, Val Loss=1.6016, lr=0.0100
[2025-05-03 22:41:39,407][train][INFO] - Epoch 74/140, Val Acc=0.6586, Val Loss=1.5493, lr=0.0100
[2025-05-03 22:41:40,412][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:41:42,571][train][INFO] - Epoch 74/140, Val Acc=0.6501, Val Loss=1.6437, lr=0.0100
[2025-05-03 22:41:46,911][train][INFO] - Epoch 75/140, Val Acc=0.6498, Val Loss=1.6136, lr=0.0100
[2025-05-03 22:41:50,811][train][INFO] - Epoch 75/140, Val Acc=0.6504, Val Loss=1.6156, lr=0.0100
[2025-05-03 22:41:55,532][train][INFO] - Epoch 76/140, Val Acc=0.6256, Val Loss=1.7235, lr=0.0100
[2025-05-03 22:41:58,600][train][INFO] - Epoch 76/140, Val Acc=0.6467, Val Loss=1.6277, lr=0.0100
[2025-05-03 22:42:03,598][train][INFO] - Epoch 77/140, Val Acc=0.6501, Val Loss=1.5465, lr=0.0100
[2025-05-03 22:42:06,265][train][INFO] - Epoch 77/140, Val Acc=0.6578, Val Loss=1.5895, lr=0.0100
[2025-05-03 22:42:08,847][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:42:11,662][train][INFO] - Epoch 78/140, Val Acc=0.6586, Val Loss=1.5286, lr=0.0100
[2025-05-03 22:42:14,001][train][INFO] - Epoch 78/140, Val Acc=0.6476, Val Loss=1.6505, lr=0.0100
[2025-05-03 22:42:19,973][train][INFO] - Epoch 79/140, Val Acc=0.6514, Val Loss=1.5755, lr=0.0100
[2025-05-03 22:42:22,498][train][INFO] - Epoch 79/140, Val Acc=0.6590, Val Loss=1.5561, lr=0.0100
[2025-05-03 22:42:27,996][train][INFO] - Epoch 80/140, Val Acc=0.6541, Val Loss=1.5524, lr=0.0100
[2025-05-03 22:42:30,702][train][INFO] - Epoch 80/140, Val Acc=0.6667, Val Loss=1.5255, lr=0.0100
[2025-05-03 22:42:36,265][train][INFO] - Epoch 81/140, Val Acc=0.7100, Val Loss=1.2766, lr=0.0010
[2025-05-03 22:42:36,997][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:42:39,286][train][INFO] - Epoch 81/140, Val Acc=0.7142, Val Loss=1.2902, lr=0.0010
[2025-05-03 22:42:44,514][train][INFO] - Epoch 82/140, Val Acc=0.7099, Val Loss=1.2817, lr=0.0010
[2025-05-03 22:42:47,384][train][INFO] - Epoch 82/140, Val Acc=0.7150, Val Loss=1.2826, lr=0.0010
[2025-05-03 22:42:52,448][train][INFO] - Epoch 83/140, Val Acc=0.7137, Val Loss=1.2919, lr=0.0010
[2025-05-03 22:42:55,397][train][INFO] - Epoch 83/140, Val Acc=0.7198, Val Loss=1.2868, lr=0.0010
[2025-05-03 22:43:00,282][train][INFO] - Epoch 84/140, Val Acc=0.7142, Val Loss=1.2928, lr=0.0010
[2025-05-03 22:43:03,998][train][INFO] - Epoch 84/140, Val Acc=0.7201, Val Loss=1.2849, lr=0.0010
[2025-05-03 22:43:04,794][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:43:07,632][train][INFO] - Epoch 85/140, Val Acc=0.7170, Val Loss=1.2992, lr=0.0010
[2025-05-03 22:43:12,328][train][INFO] - Epoch 85/140, Val Acc=0.7241, Val Loss=1.2880, lr=0.0010
[2025-05-03 22:43:16,167][train][INFO] - Epoch 86/140, Val Acc=0.7137, Val Loss=1.3079, lr=0.0010
[2025-05-03 22:43:20,246][train][INFO] - Epoch 86/140, Val Acc=0.7198, Val Loss=1.3051, lr=0.0010
[2025-05-03 22:43:24,568][train][INFO] - Epoch 87/140, Val Acc=0.7142, Val Loss=1.3113, lr=0.0010
[2025-05-03 22:43:28,733][train][INFO] - Epoch 87/140, Val Acc=0.7230, Val Loss=1.2974, lr=0.0010
[2025-05-03 22:43:32,708][train][INFO] - Epoch 88/140, Val Acc=0.7155, Val Loss=1.3139, lr=0.0010
[2025-05-03 22:43:33,577][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:43:37,015][train][INFO] - Epoch 88/140, Val Acc=0.7230, Val Loss=1.3008, lr=0.0010
[2025-05-03 22:43:40,946][train][INFO] - Epoch 89/140, Val Acc=0.7160, Val Loss=1.3134, lr=0.0010
[2025-05-03 22:43:45,488][train][INFO] - Epoch 89/140, Val Acc=0.7217, Val Loss=1.3094, lr=0.0010
[2025-05-03 22:43:48,530][train][INFO] - Epoch 90/140, Val Acc=0.7152, Val Loss=1.3243, lr=0.0010
[2025-05-03 22:43:54,154][train][INFO] - Epoch 90/140, Val Acc=0.7223, Val Loss=1.3156, lr=0.0010
[2025-05-03 22:43:56,969][train][INFO] - Epoch 91/140, Val Acc=0.7166, Val Loss=1.3322, lr=0.0010
[2025-05-03 22:44:02,357][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:44:02,387][meta_train][INFO] - epoch_97 saved !
[2025-05-03 22:44:02,742][train][INFO] - Epoch 91/140, Val Acc=0.7249, Val Loss=1.3132, lr=0.0010
[2025-05-03 22:44:04,989][train][INFO] - Epoch 92/140, Val Acc=0.7170, Val Loss=1.3348, lr=0.0010
[2025-05-03 22:44:11,055][train][INFO] - Epoch 92/140, Val Acc=0.7246, Val Loss=1.3206, lr=0.0010
[2025-05-03 22:44:13,472][train][INFO] - Epoch 93/140, Val Acc=0.7151, Val Loss=1.3337, lr=0.0010
[2025-05-03 22:44:19,645][train][INFO] - Epoch 93/140, Val Acc=0.7206, Val Loss=1.3187, lr=0.0010
[2025-05-03 22:44:21,544][train][INFO] - Epoch 94/140, Val Acc=0.7157, Val Loss=1.3472, lr=0.0010
[2025-05-03 22:44:27,907][train][INFO] - Epoch 94/140, Val Acc=0.7221, Val Loss=1.3247, lr=0.0010
[2025-05-03 22:44:29,483][train][INFO] - Epoch 95/140, Val Acc=0.7169, Val Loss=1.3493, lr=0.0010
[2025-05-03 22:44:30,463][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:44:36,799][train][INFO] - Epoch 95/140, Val Acc=0.7247, Val Loss=1.3231, lr=0.0010
[2025-05-03 22:44:37,664][train][INFO] - Epoch 96/140, Val Acc=0.7174, Val Loss=1.3494, lr=0.0010
[2025-05-03 22:44:44,377][train][INFO] - Epoch 96/140, Val Acc=0.7224, Val Loss=1.3355, lr=0.0010
[2025-05-03 22:44:45,793][train][INFO] - Epoch 97/140, Val Acc=0.7165, Val Loss=1.3607, lr=0.0010
[2025-05-03 22:44:52,592][train][INFO] - Epoch 98/140, Val Acc=0.7170, Val Loss=1.3535, lr=0.0010
[2025-05-03 22:44:52,677][train][INFO] - Epoch 97/140, Val Acc=0.7264, Val Loss=1.3335, lr=0.0010
[2025-05-03 22:44:59,327][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:45:00,932][train][INFO] - Epoch 99/140, Val Acc=0.7173, Val Loss=1.3621, lr=0.0010
[2025-05-03 22:45:01,199][train][INFO] - Epoch 98/140, Val Acc=0.7253, Val Loss=1.3357, lr=0.0010
[2025-05-03 22:45:08,979][train][INFO] - Epoch 99/140, Val Acc=0.7212, Val Loss=1.3441, lr=0.0010
[2025-05-03 22:45:09,093][train][INFO] - Epoch 100/140, Val Acc=0.7167, Val Loss=1.3686, lr=0.0010
[2025-05-03 22:45:16,905][train][INFO] - Epoch 101/140, Val Acc=0.7166, Val Loss=1.3654, lr=0.0010
[2025-05-03 22:45:17,003][train][INFO] - Epoch 100/140, Val Acc=0.7246, Val Loss=1.3421, lr=0.0010
[2025-05-03 22:45:25,079][train][INFO] - Epoch 102/140, Val Acc=0.7181, Val Loss=1.3737, lr=0.0010
[2025-05-03 22:45:25,121][train][INFO] - Epoch 101/140, Val Acc=0.7230, Val Loss=1.3411, lr=0.0010
[2025-05-03 22:45:28,379][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:45:33,350][train][INFO] - Epoch 103/140, Val Acc=0.7158, Val Loss=1.3803, lr=0.0010
[2025-05-03 22:45:33,539][train][INFO] - Epoch 102/140, Val Acc=0.7275, Val Loss=1.3324, lr=0.0010
[2025-05-03 22:45:41,886][train][INFO] - Epoch 103/140, Val Acc=0.7267, Val Loss=1.3442, lr=0.0010
[2025-05-03 22:45:42,036][train][INFO] - Epoch 104/140, Val Acc=0.7187, Val Loss=1.3767, lr=0.0010
[2025-05-03 22:45:50,009][train][INFO] - Epoch 104/140, Val Acc=0.7239, Val Loss=1.3457, lr=0.0010
[2025-05-03 22:45:50,047][train][INFO] - Epoch 105/140, Val Acc=0.7173, Val Loss=1.3818, lr=0.0010
[2025-05-03 22:45:55,273][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:45:57,593][train][INFO] - Epoch 105/140, Val Acc=0.7280, Val Loss=1.3466, lr=0.0010
[2025-05-03 22:45:58,462][train][INFO] - Epoch 106/140, Val Acc=0.7189, Val Loss=1.3788, lr=0.0010
[2025-05-03 22:46:05,476][train][INFO] - Epoch 106/140, Val Acc=0.7241, Val Loss=1.3521, lr=0.0010
[2025-05-03 22:46:06,915][train][INFO] - Epoch 107/140, Val Acc=0.7176, Val Loss=1.3821, lr=0.0010
[2025-05-03 22:46:13,415][train][INFO] - Epoch 107/140, Val Acc=0.7250, Val Loss=1.3565, lr=0.0010
[2025-05-03 22:46:14,905][train][INFO] - Epoch 108/140, Val Acc=0.7154, Val Loss=1.3860, lr=0.0010
[2025-05-03 22:46:21,228][train][INFO] - Epoch 108/140, Val Acc=0.7261, Val Loss=1.3550, lr=0.0010
[2025-05-03 22:46:22,848][train][INFO] - Epoch 109/140, Val Acc=0.7169, Val Loss=1.3804, lr=0.0010
[2025-05-03 22:46:24,063][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:46:29,220][train][INFO] - Epoch 109/140, Val Acc=0.7267, Val Loss=1.3528, lr=0.0010
[2025-05-03 22:46:30,840][train][INFO] - Epoch 110/140, Val Acc=0.7143, Val Loss=1.3902, lr=0.0010
[2025-05-03 22:46:37,505][train][INFO] - Epoch 110/140, Val Acc=0.7264, Val Loss=1.3557, lr=0.0010
[2025-05-03 22:46:38,611][train][INFO] - Epoch 111/140, Val Acc=0.7169, Val Loss=1.3921, lr=0.0010
[2025-05-03 22:46:46,181][train][INFO] - Epoch 111/140, Val Acc=0.7264, Val Loss=1.3578, lr=0.0010
[2025-05-03 22:46:47,134][train][INFO] - Epoch 112/140, Val Acc=0.7161, Val Loss=1.3939, lr=0.0010
[2025-05-03 22:46:51,927][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:46:54,438][train][INFO] - Epoch 112/140, Val Acc=0.7270, Val Loss=1.3554, lr=0.0010
[2025-05-03 22:46:55,100][train][INFO] - Epoch 113/140, Val Acc=0.7175, Val Loss=1.3906, lr=0.0010
[2025-05-03 22:47:02,592][train][INFO] - Epoch 114/140, Val Acc=0.7159, Val Loss=1.3985, lr=0.0010
[2025-05-03 22:47:03,227][train][INFO] - Epoch 113/140, Val Acc=0.7254, Val Loss=1.3658, lr=0.0010
[2025-05-03 22:47:10,582][train][INFO] - Epoch 115/140, Val Acc=0.7166, Val Loss=1.3950, lr=0.0010
[2025-05-03 22:47:11,070][train][INFO] - Epoch 114/140, Val Acc=0.7259, Val Loss=1.3637, lr=0.0010
[2025-05-03 22:47:18,310][train][INFO] - Epoch 116/140, Val Acc=0.7179, Val Loss=1.3930, lr=0.0010
[2025-05-03 22:47:19,256][train][INFO] - Epoch 115/140, Val Acc=0.7259, Val Loss=1.3578, lr=0.0010
[2025-05-03 22:47:20,951][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:47:26,782][train][INFO] - Epoch 117/140, Val Acc=0.7184, Val Loss=1.4025, lr=0.0010
[2025-05-03 22:47:27,664][train][INFO] - Epoch 116/140, Val Acc=0.7270, Val Loss=1.3527, lr=0.0010
[2025-05-03 22:47:35,302][train][INFO] - Epoch 118/140, Val Acc=0.7173, Val Loss=1.4026, lr=0.0010
[2025-05-03 22:47:35,968][train][INFO] - Epoch 117/140, Val Acc=0.7277, Val Loss=1.3626, lr=0.0010
[2025-05-03 22:47:43,764][train][INFO] - Epoch 119/140, Val Acc=0.7161, Val Loss=1.4060, lr=0.0010
[2025-05-03 22:47:44,599][train][INFO] - Epoch 118/140, Val Acc=0.7232, Val Loss=1.3652, lr=0.0010
[2025-05-03 22:47:49,369][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:47:49,391][meta_train][INFO] - epoch_98 saved !
[2025-05-03 22:47:51,841][train][INFO] - Epoch 120/140, Val Acc=0.7183, Val Loss=1.3991, lr=0.0010
[2025-05-03 22:47:52,659][train][INFO] - Epoch 119/140, Val Acc=0.7274, Val Loss=1.3684, lr=0.0010
[2025-05-03 22:47:59,738][train][INFO] - Epoch 121/140, Val Acc=0.7186, Val Loss=1.3959, lr=0.0001
[2025-05-03 22:48:00,961][train][INFO] - Epoch 120/140, Val Acc=0.7271, Val Loss=1.3569, lr=0.0010
[2025-05-03 22:48:07,925][train][INFO] - Epoch 122/140, Val Acc=0.7185, Val Loss=1.3950, lr=0.0001
[2025-05-03 22:48:08,975][train][INFO] - Epoch 121/140, Val Acc=0.7275, Val Loss=1.3526, lr=0.0001
[2025-05-03 22:48:16,218][train][INFO] - Epoch 123/140, Val Acc=0.7196, Val Loss=1.3940, lr=0.0001
[2025-05-03 22:48:16,488][train][INFO] - Epoch 122/140, Val Acc=0.7269, Val Loss=1.3535, lr=0.0001
[2025-05-03 22:48:17,991][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:48:24,099][train][INFO] - Epoch 124/140, Val Acc=0.7205, Val Loss=1.3936, lr=0.0001
[2025-05-03 22:48:25,044][train][INFO] - Epoch 123/140, Val Acc=0.7283, Val Loss=1.3539, lr=0.0001
[2025-05-03 22:48:31,448][train][INFO] - Epoch 125/140, Val Acc=0.7197, Val Loss=1.3930, lr=0.0001
[2025-05-03 22:48:32,989][train][INFO] - Epoch 124/140, Val Acc=0.7287, Val Loss=1.3517, lr=0.0001
[2025-05-03 22:48:39,614][train][INFO] - Epoch 126/140, Val Acc=0.7185, Val Loss=1.3925, lr=0.0001
[2025-05-03 22:48:40,748][train][INFO] - Epoch 125/140, Val Acc=0.7293, Val Loss=1.3536, lr=0.0001
[2025-05-03 22:48:45,693][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:48:48,228][train][INFO] - Epoch 127/140, Val Acc=0.7188, Val Loss=1.3996, lr=0.0001
[2025-05-03 22:48:48,837][train][INFO] - Epoch 126/140, Val Acc=0.7296, Val Loss=1.3492, lr=0.0001
[2025-05-03 22:48:56,706][train][INFO] - Epoch 128/140, Val Acc=0.7193, Val Loss=1.3965, lr=0.0001
[2025-05-03 22:48:57,523][train][INFO] - Epoch 127/140, Val Acc=0.7284, Val Loss=1.3533, lr=0.0001
[2025-05-03 22:49:05,118][train][INFO] - Epoch 129/140, Val Acc=0.7182, Val Loss=1.3955, lr=0.0001
[2025-05-03 22:49:05,179][train][INFO] - Epoch 128/140, Val Acc=0.7276, Val Loss=1.3520, lr=0.0001
[2025-05-03 22:49:12,984][train][INFO] - Epoch 130/140, Val Acc=0.7204, Val Loss=1.3919, lr=0.0001
[2025-05-03 22:49:13,236][train][INFO] - Epoch 129/140, Val Acc=0.7285, Val Loss=1.3561, lr=0.0001
[2025-05-03 22:49:14,474][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:49:21,188][train][INFO] - Epoch 130/140, Val Acc=0.7286, Val Loss=1.3521, lr=0.0001
[2025-05-03 22:49:21,189][train][INFO] - Epoch 131/140, Val Acc=0.7205, Val Loss=1.3947, lr=0.0001
[2025-05-03 22:49:28,971][train][INFO] - Epoch 132/140, Val Acc=0.7194, Val Loss=1.3917, lr=0.0001
[2025-05-03 22:49:29,752][train][INFO] - Epoch 131/140, Val Acc=0.7307, Val Loss=1.3584, lr=0.0001
[2025-05-03 22:49:36,811][train][INFO] - Epoch 133/140, Val Acc=0.7177, Val Loss=1.3971, lr=0.0001
[2025-05-03 22:49:38,185][train][INFO] - Epoch 132/140, Val Acc=0.7306, Val Loss=1.3518, lr=0.0001
[2025-05-03 22:49:42,721][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:49:44,757][train][INFO] - Epoch 134/140, Val Acc=0.7210, Val Loss=1.3963, lr=0.0001
[2025-05-03 22:49:46,569][train][INFO] - Epoch 133/140, Val Acc=0.7281, Val Loss=1.3542, lr=0.0001
[2025-05-03 22:49:53,349][train][INFO] - Epoch 135/140, Val Acc=0.7194, Val Loss=1.3931, lr=0.0001
[2025-05-03 22:49:55,004][train][INFO] - Epoch 134/140, Val Acc=0.7287, Val Loss=1.3552, lr=0.0001
[2025-05-03 22:50:01,240][train][INFO] - Epoch 136/140, Val Acc=0.7207, Val Loss=1.3927, lr=0.0001
[2025-05-03 22:50:03,201][train][INFO] - Epoch 135/140, Val Acc=0.7289, Val Loss=1.3536, lr=0.0001
[2025-05-03 22:50:08,900][train][INFO] - Epoch 137/140, Val Acc=0.7202, Val Loss=1.3945, lr=0.0001
[2025-05-03 22:50:11,277][train][INFO] - Epoch 136/140, Val Acc=0.7275, Val Loss=1.3520, lr=0.0001
[2025-05-03 22:50:11,779][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:50:17,193][train][INFO] - Epoch 138/140, Val Acc=0.7188, Val Loss=1.3954, lr=0.0001
[2025-05-03 22:50:19,255][train][INFO] - Epoch 137/140, Val Acc=0.7289, Val Loss=1.3522, lr=0.0001
[2025-05-03 22:50:25,582][train][INFO] - Epoch 139/140, Val Acc=0.7181, Val Loss=1.3999, lr=0.0001
[2025-05-03 22:50:27,673][train][INFO] - Epoch 138/140, Val Acc=0.7286, Val Loss=1.3545, lr=0.0001
[2025-05-03 22:50:33,421][train][INFO] - Epoch 140/140, Val Acc=0.7188, Val Loss=1.3991, lr=0.0001
[2025-05-03 22:50:35,465][train][INFO] - Epoch 139/140, Val Acc=0.7292, Val Loss=1.3565, lr=0.0001
[2025-05-03 22:50:38,457][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:50:38,625][train][INFO] - After training : Train Acc=0.9981  Val Acc=0.7210
[2025-05-03 22:50:38,663][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(46, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(255, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(232, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(66, 243, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(243, 245, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(245, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(26, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(27, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(45, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(31, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(29, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(59, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=122, out_features=100, bias=True)
)
[2025-05-03 22:50:38,663][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.7209999561309814
                      Speed up: 2.01   Final speed up: 4.02
[2025-05-03 22:50:43,913][train][INFO] - Epoch 140/140, Val Acc=0.7294, Val Loss=1.3527, lr=0.0001
[2025-05-03 22:50:48,852][train][INFO] - After training : Train Acc=0.9988  Val Acc=0.7307
[2025-05-03 22:50:48,890][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(48, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(108, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(255, 247, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(247, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(247, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(104, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(253, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(250, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(30, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(47, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(34, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(29, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(63, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=135, out_features=100, bias=True)
)
[2025-05-03 22:50:48,890][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.7306999564170837
                      Speed up: 1.76   Final speed up: 3.53
[2025-05-03 22:51:05,637][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:51:33,008][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:51:33,023][meta_train][INFO] - epoch_99 saved !
[2025-05-03 22:52:01,177][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:52:27,709][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:52:54,420][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:53:20,832][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:53:47,489][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6054, lr=0.0001
[2025-05-03 22:54:15,223][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:54:42,859][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:55:10,032][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6052, lr=0.0001
[2025-05-03 22:55:10,047][meta_train][INFO] - epoch_100 saved !
[2025-05-04 11:56:56,998][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-04 11:56:57,046][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 11:56:57,047][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 11:56:57,047][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 11:57:07,111][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-04 11:57:07,162][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 11:57:07,162][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 11:57:07,162][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 11:57:16,203][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 11:57:24,679][train][INFO] - Epoch 1/100, Val Acc=0.0498, Val Loss=4.0701, lr=0.0100
[2025-05-04 11:57:26,874][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-04 11:57:32,825][train][INFO] - Epoch 2/100, Val Acc=0.1073, Val Loss=3.7285, lr=0.0100
[2025-05-04 11:57:34,994][train][INFO] - Epoch 1/100, Val Acc=0.0477, Val Loss=4.2598, lr=0.0100
[2025-05-04 11:57:41,457][train][INFO] - Epoch 3/100, Val Acc=0.1012, Val Loss=3.7805, lr=0.0100
[2025-05-04 11:57:43,406][train][INFO] - Epoch 2/100, Val Acc=0.1800, Val Loss=3.1408, lr=0.0100
[2025-05-04 11:57:50,034][train][INFO] - Epoch 4/100, Val Acc=0.2114, Val Loss=3.0320, lr=0.0100
[2025-05-04 11:57:51,047][train][INFO] - Epoch 3/100, Val Acc=0.2047, Val Loss=3.0136, lr=0.0100
[2025-05-04 11:57:57,963][train][INFO] - Epoch 5/100, Val Acc=0.2427, Val Loss=2.9453, lr=0.0100
[2025-05-04 11:57:59,092][train][INFO] - Epoch 4/100, Val Acc=0.1948, Val Loss=3.0851, lr=0.0100
[2025-05-04 11:58:06,204][train][INFO] - Epoch 6/100, Val Acc=0.2416, Val Loss=2.9458, lr=0.0100
[2025-05-04 11:58:06,937][train][INFO] - Epoch 5/100, Val Acc=0.2555, Val Loss=3.0180, lr=0.0100
[2025-05-04 11:58:14,470][train][INFO] - Epoch 7/100, Val Acc=0.2974, Val Loss=2.8628, lr=0.0100
[2025-05-04 11:58:15,188][train][INFO] - Epoch 6/100, Val Acc=0.3487, Val Loss=2.4645, lr=0.0100
[2025-05-04 11:58:22,679][train][INFO] - Epoch 8/100, Val Acc=0.3250, Val Loss=2.6406, lr=0.0100
[2025-05-04 11:58:23,240][train][INFO] - Epoch 7/100, Val Acc=0.3783, Val Loss=2.2895, lr=0.0100
[2025-05-04 11:58:30,549][train][INFO] - Epoch 9/100, Val Acc=0.3207, Val Loss=2.6397, lr=0.0100
[2025-05-04 11:58:31,003][train][INFO] - Epoch 8/100, Val Acc=0.4061, Val Loss=2.2777, lr=0.0100
[2025-05-04 11:58:38,637][train][INFO] - Epoch 10/100, Val Acc=0.3509, Val Loss=2.4300, lr=0.0100
[2025-05-04 11:58:38,673][train][INFO] - Epoch 9/100, Val Acc=0.4010, Val Loss=2.3423, lr=0.0100
[2025-05-04 11:58:46,130][train][INFO] - Epoch 10/100, Val Acc=0.4514, Val Loss=2.0412, lr=0.0100
[2025-05-04 11:58:46,789][train][INFO] - Epoch 11/100, Val Acc=0.4011, Val Loss=2.2054, lr=0.0100
[2025-05-04 11:58:53,920][train][INFO] - Epoch 11/100, Val Acc=0.5048, Val Loss=1.8166, lr=0.0100
[2025-05-04 11:58:54,926][train][INFO] - Epoch 12/100, Val Acc=0.4183, Val Loss=2.1640, lr=0.0100
[2025-05-04 11:59:02,072][train][INFO] - Epoch 12/100, Val Acc=0.4850, Val Loss=1.9557, lr=0.0100
[2025-05-04 11:59:03,338][train][INFO] - Epoch 13/100, Val Acc=0.4435, Val Loss=2.0170, lr=0.0100
[2025-05-04 11:59:09,819][train][INFO] - Epoch 13/100, Val Acc=0.4410, Val Loss=2.2209, lr=0.0100
[2025-05-04 11:59:11,786][train][INFO] - Epoch 14/100, Val Acc=0.4405, Val Loss=2.0874, lr=0.0100
[2025-05-04 11:59:17,572][train][INFO] - Epoch 14/100, Val Acc=0.4867, Val Loss=1.9895, lr=0.0100
[2025-05-04 11:59:19,654][train][INFO] - Epoch 15/100, Val Acc=0.4195, Val Loss=2.2101, lr=0.0100
[2025-05-04 11:59:25,265][train][INFO] - Epoch 15/100, Val Acc=0.5212, Val Loss=1.8461, lr=0.0100
[2025-05-04 11:59:27,972][train][INFO] - Epoch 16/100, Val Acc=0.4628, Val Loss=1.9817, lr=0.0100
[2025-05-04 11:59:32,493][train][INFO] - Epoch 16/100, Val Acc=0.5462, Val Loss=1.6684, lr=0.0100
[2025-05-04 11:59:36,700][train][INFO] - Epoch 17/100, Val Acc=0.4801, Val Loss=1.8794, lr=0.0100
[2025-05-04 11:59:40,622][train][INFO] - Epoch 17/100, Val Acc=0.5245, Val Loss=1.8001, lr=0.0100
[2025-05-04 11:59:44,614][train][INFO] - Epoch 18/100, Val Acc=0.4345, Val Loss=2.1876, lr=0.0100
[2025-05-04 11:59:48,978][train][INFO] - Epoch 18/100, Val Acc=0.5309, Val Loss=1.8349, lr=0.0100
[2025-05-04 11:59:52,373][train][INFO] - Epoch 19/100, Val Acc=0.4943, Val Loss=1.8217, lr=0.0100
[2025-05-04 11:59:56,411][train][INFO] - Epoch 19/100, Val Acc=0.5541, Val Loss=1.6883, lr=0.0100
[2025-05-04 12:00:00,658][train][INFO] - Epoch 20/100, Val Acc=0.4860, Val Loss=1.8589, lr=0.0100
[2025-05-04 12:00:03,822][train][INFO] - Epoch 20/100, Val Acc=0.5786, Val Loss=1.6245, lr=0.0100
[2025-05-04 12:00:09,240][train][INFO] - Epoch 21/100, Val Acc=0.4424, Val Loss=2.1362, lr=0.0100
[2025-05-04 12:00:11,854][train][INFO] - Epoch 21/100, Val Acc=0.5292, Val Loss=1.8784, lr=0.0100
[2025-05-04 12:00:17,424][train][INFO] - Epoch 22/100, Val Acc=0.4686, Val Loss=2.0200, lr=0.0100
[2025-05-04 12:00:20,085][train][INFO] - Epoch 22/100, Val Acc=0.5382, Val Loss=1.8203, lr=0.0100
[2025-05-04 12:00:25,385][train][INFO] - Epoch 23/100, Val Acc=0.5070, Val Loss=1.7903, lr=0.0100
[2025-05-04 12:00:28,446][train][INFO] - Epoch 23/100, Val Acc=0.5682, Val Loss=1.7212, lr=0.0100
[2025-05-04 12:00:32,886][train][INFO] - Epoch 24/100, Val Acc=0.5075, Val Loss=1.8016, lr=0.0100
[2025-05-04 12:00:36,189][train][INFO] - Epoch 24/100, Val Acc=0.5739, Val Loss=1.6791, lr=0.0100
[2025-05-04 12:00:41,146][train][INFO] - Epoch 25/100, Val Acc=0.5087, Val Loss=1.8099, lr=0.0100
[2025-05-04 12:00:43,857][train][INFO] - Epoch 25/100, Val Acc=0.5900, Val Loss=1.5826, lr=0.0100
[2025-05-04 12:00:48,587][train][INFO] - Epoch 26/100, Val Acc=0.4809, Val Loss=1.9551, lr=0.0100
[2025-05-04 12:00:51,958][train][INFO] - Epoch 26/100, Val Acc=0.5526, Val Loss=1.8464, lr=0.0100
[2025-05-04 12:00:56,870][train][INFO] - Epoch 27/100, Val Acc=0.4908, Val Loss=1.8938, lr=0.0100
[2025-05-04 12:00:59,881][train][INFO] - Epoch 27/100, Val Acc=0.6022, Val Loss=1.5530, lr=0.0100
[2025-05-04 12:01:04,859][train][INFO] - Epoch 28/100, Val Acc=0.4820, Val Loss=1.9695, lr=0.0100
[2025-05-04 12:01:07,774][train][INFO] - Epoch 28/100, Val Acc=0.5802, Val Loss=1.6209, lr=0.0100
[2025-05-04 12:01:12,731][train][INFO] - Epoch 29/100, Val Acc=0.5256, Val Loss=1.7564, lr=0.0100
[2025-05-04 12:01:15,066][train][INFO] - Epoch 29/100, Val Acc=0.5965, Val Loss=1.6158, lr=0.0100
[2025-05-04 12:01:20,923][train][INFO] - Epoch 30/100, Val Acc=0.5313, Val Loss=1.7132, lr=0.0100
[2025-05-04 12:01:23,226][train][INFO] - Epoch 30/100, Val Acc=0.6045, Val Loss=1.5908, lr=0.0100
[2025-05-04 12:01:29,383][train][INFO] - Epoch 31/100, Val Acc=0.5290, Val Loss=1.7829, lr=0.0100
[2025-05-04 12:01:31,364][train][INFO] - Epoch 31/100, Val Acc=0.6015, Val Loss=1.6014, lr=0.0100
[2025-05-04 12:01:37,702][train][INFO] - Epoch 32/100, Val Acc=0.5317, Val Loss=1.7320, lr=0.0100
[2025-05-04 12:01:39,439][train][INFO] - Epoch 32/100, Val Acc=0.5894, Val Loss=1.6960, lr=0.0100
[2025-05-04 12:01:45,552][train][INFO] - Epoch 33/100, Val Acc=0.5049, Val Loss=1.9286, lr=0.0100
[2025-05-04 12:01:47,977][train][INFO] - Epoch 33/100, Val Acc=0.5832, Val Loss=1.6813, lr=0.0100
[2025-05-04 12:01:53,838][train][INFO] - Epoch 34/100, Val Acc=0.4972, Val Loss=1.9323, lr=0.0100
[2025-05-04 12:01:55,990][train][INFO] - Epoch 34/100, Val Acc=0.6108, Val Loss=1.5890, lr=0.0100
[2025-05-04 12:02:02,236][train][INFO] - Epoch 35/100, Val Acc=0.5299, Val Loss=1.7207, lr=0.0100
[2025-05-04 12:02:04,254][train][INFO] - Epoch 35/100, Val Acc=0.5902, Val Loss=1.6914, lr=0.0100
[2025-05-04 12:02:10,596][train][INFO] - Epoch 36/100, Val Acc=0.5112, Val Loss=1.8713, lr=0.0100
[2025-05-04 12:02:12,175][train][INFO] - Epoch 36/100, Val Acc=0.5950, Val Loss=1.6372, lr=0.0100
[2025-05-04 12:02:18,270][train][INFO] - Epoch 37/100, Val Acc=0.5491, Val Loss=1.6927, lr=0.0100
[2025-05-04 12:02:20,388][train][INFO] - Epoch 37/100, Val Acc=0.5957, Val Loss=1.6907, lr=0.0100
[2025-05-04 12:02:26,632][train][INFO] - Epoch 38/100, Val Acc=0.5422, Val Loss=1.6943, lr=0.0100
[2025-05-04 12:02:28,138][train][INFO] - Epoch 38/100, Val Acc=0.5994, Val Loss=1.6521, lr=0.0100
[2025-05-04 12:02:35,195][train][INFO] - Epoch 39/100, Val Acc=0.5596, Val Loss=1.6220, lr=0.0100
[2025-05-04 12:02:36,123][train][INFO] - Epoch 39/100, Val Acc=0.6045, Val Loss=1.6506, lr=0.0100
[2025-05-04 12:02:43,514][train][INFO] - Epoch 40/100, Val Acc=0.5390, Val Loss=1.7392, lr=0.0100
[2025-05-04 12:02:44,210][train][INFO] - Epoch 40/100, Val Acc=0.5957, Val Loss=1.6921, lr=0.0100
[2025-05-04 12:02:51,484][train][INFO] - Epoch 41/100, Val Acc=0.5231, Val Loss=1.8813, lr=0.0100
[2025-05-04 12:02:52,287][train][INFO] - Epoch 41/100, Val Acc=0.6126, Val Loss=1.6022, lr=0.0100
[2025-05-04 12:02:59,526][train][INFO] - Epoch 42/100, Val Acc=0.5333, Val Loss=1.7644, lr=0.0100
[2025-05-04 12:03:00,506][train][INFO] - Epoch 42/100, Val Acc=0.6008, Val Loss=1.7293, lr=0.0100
[2025-05-04 12:03:07,114][train][INFO] - Epoch 43/100, Val Acc=0.5573, Val Loss=1.6679, lr=0.0100
[2025-05-04 12:03:08,535][train][INFO] - Epoch 43/100, Val Acc=0.6106, Val Loss=1.6888, lr=0.0100
[2025-05-04 12:03:15,453][train][INFO] - Epoch 44/100, Val Acc=0.5433, Val Loss=1.7712, lr=0.0100
[2025-05-04 12:03:15,991][train][INFO] - Epoch 44/100, Val Acc=0.6022, Val Loss=1.6992, lr=0.0100
[2025-05-04 12:03:23,549][train][INFO] - Epoch 45/100, Val Acc=0.5575, Val Loss=1.6770, lr=0.0100
[2025-05-04 12:03:23,669][train][INFO] - Epoch 45/100, Val Acc=0.6069, Val Loss=1.6741, lr=0.0100
[2025-05-04 12:03:31,252][train][INFO] - Epoch 46/100, Val Acc=0.5451, Val Loss=1.7361, lr=0.0100
[2025-05-04 12:03:32,028][train][INFO] - Epoch 46/100, Val Acc=0.6077, Val Loss=1.6555, lr=0.0100
[2025-05-04 12:03:39,160][train][INFO] - Epoch 47/100, Val Acc=0.5551, Val Loss=1.7168, lr=0.0100
[2025-05-04 12:03:40,190][train][INFO] - Epoch 47/100, Val Acc=0.5942, Val Loss=1.7828, lr=0.0100
[2025-05-04 12:03:46,996][train][INFO] - Epoch 48/100, Val Acc=0.5555, Val Loss=1.7282, lr=0.0100
[2025-05-04 12:03:47,972][train][INFO] - Epoch 48/100, Val Acc=0.6006, Val Loss=1.7140, lr=0.0100
[2025-05-04 12:03:54,885][train][INFO] - Epoch 49/100, Val Acc=0.5588, Val Loss=1.6738, lr=0.0100
[2025-05-04 12:03:56,063][train][INFO] - Epoch 49/100, Val Acc=0.6161, Val Loss=1.6509, lr=0.0100
[2025-05-04 12:04:03,268][train][INFO] - Epoch 50/100, Val Acc=0.5569, Val Loss=1.7256, lr=0.0100
[2025-05-04 12:04:04,478][train][INFO] - Epoch 50/100, Val Acc=0.6044, Val Loss=1.7283, lr=0.0100
[2025-05-04 12:04:11,254][train][INFO] - Epoch 51/100, Val Acc=0.5711, Val Loss=1.6467, lr=0.0100
[2025-05-04 12:04:12,980][train][INFO] - Epoch 51/100, Val Acc=0.6041, Val Loss=1.7113, lr=0.0100
[2025-05-04 12:04:19,476][train][INFO] - Epoch 52/100, Val Acc=0.5407, Val Loss=1.8245, lr=0.0100
[2025-05-04 12:04:21,211][train][INFO] - Epoch 52/100, Val Acc=0.6287, Val Loss=1.5932, lr=0.0100
[2025-05-04 12:04:27,651][train][INFO] - Epoch 53/100, Val Acc=0.5788, Val Loss=1.6307, lr=0.0100
[2025-05-04 12:04:29,626][train][INFO] - Epoch 53/100, Val Acc=0.6217, Val Loss=1.6603, lr=0.0100
[2025-05-04 12:04:36,137][train][INFO] - Epoch 54/100, Val Acc=0.5520, Val Loss=1.7428, lr=0.0100
[2025-05-04 12:04:37,493][train][INFO] - Epoch 54/100, Val Acc=0.6270, Val Loss=1.5705, lr=0.0100
[2025-05-04 12:04:44,280][train][INFO] - Epoch 55/100, Val Acc=0.5525, Val Loss=1.7450, lr=0.0100
[2025-05-04 12:04:45,440][train][INFO] - Epoch 55/100, Val Acc=0.6294, Val Loss=1.5980, lr=0.0100
[2025-05-04 12:04:52,878][train][INFO] - Epoch 56/100, Val Acc=0.5839, Val Loss=1.6067, lr=0.0100
[2025-05-04 12:04:53,724][train][INFO] - Epoch 56/100, Val Acc=0.6263, Val Loss=1.6246, lr=0.0100
[2025-05-04 12:05:01,252][train][INFO] - Epoch 57/100, Val Acc=0.5611, Val Loss=1.7065, lr=0.0100
[2025-05-04 12:05:02,038][train][INFO] - Epoch 57/100, Val Acc=0.6276, Val Loss=1.6091, lr=0.0100
[2025-05-04 12:05:09,349][train][INFO] - Epoch 58/100, Val Acc=0.6157, Val Loss=1.6608, lr=0.0100
[2025-05-04 12:05:09,525][train][INFO] - Epoch 58/100, Val Acc=0.5690, Val Loss=1.6520, lr=0.0100
[2025-05-04 12:05:17,553][train][INFO] - Epoch 59/100, Val Acc=0.5442, Val Loss=1.7990, lr=0.0100
[2025-05-04 12:05:17,717][train][INFO] - Epoch 59/100, Val Acc=0.6123, Val Loss=1.6716, lr=0.0100
[2025-05-04 12:05:25,596][train][INFO] - Epoch 60/100, Val Acc=0.5901, Val Loss=1.5750, lr=0.0100
[2025-05-04 12:05:26,009][train][INFO] - Epoch 60/100, Val Acc=0.6115, Val Loss=1.7082, lr=0.0100
[2025-05-04 12:05:34,100][train][INFO] - Epoch 61/100, Val Acc=0.6420, Val Loss=1.3518, lr=0.0010
[2025-05-04 12:05:34,323][train][INFO] - Epoch 61/100, Val Acc=0.6872, Val Loss=1.3398, lr=0.0010
[2025-05-04 12:05:42,024][train][INFO] - Epoch 62/100, Val Acc=0.6881, Val Loss=1.3396, lr=0.0010
[2025-05-04 12:05:42,599][train][INFO] - Epoch 62/100, Val Acc=0.6463, Val Loss=1.3438, lr=0.0010
[2025-05-04 12:05:50,248][train][INFO] - Epoch 63/100, Val Acc=0.6891, Val Loss=1.3518, lr=0.0010
[2025-05-04 12:05:51,081][train][INFO] - Epoch 63/100, Val Acc=0.6478, Val Loss=1.3418, lr=0.0010
[2025-05-04 12:05:57,981][train][INFO] - Epoch 64/100, Val Acc=0.6876, Val Loss=1.3603, lr=0.0010
[2025-05-04 12:05:59,204][train][INFO] - Epoch 64/100, Val Acc=0.6515, Val Loss=1.3432, lr=0.0010
[2025-05-04 12:06:06,211][train][INFO] - Epoch 65/100, Val Acc=0.6883, Val Loss=1.3687, lr=0.0010
[2025-05-04 12:06:07,160][train][INFO] - Epoch 65/100, Val Acc=0.6473, Val Loss=1.3500, lr=0.0010
[2025-05-04 12:06:14,483][train][INFO] - Epoch 66/100, Val Acc=0.6884, Val Loss=1.3851, lr=0.0010
[2025-05-04 12:06:14,858][train][INFO] - Epoch 66/100, Val Acc=0.6499, Val Loss=1.3581, lr=0.0010
[2025-05-04 12:06:21,824][train][INFO] - Epoch 67/100, Val Acc=0.6917, Val Loss=1.3924, lr=0.0010
[2025-05-04 12:06:22,985][train][INFO] - Epoch 67/100, Val Acc=0.6496, Val Loss=1.3648, lr=0.0010
[2025-05-04 12:06:29,721][train][INFO] - Epoch 68/100, Val Acc=0.6890, Val Loss=1.3990, lr=0.0010
[2025-05-04 12:06:31,206][train][INFO] - Epoch 68/100, Val Acc=0.6518, Val Loss=1.3641, lr=0.0010
[2025-05-04 12:06:37,937][train][INFO] - Epoch 69/100, Val Acc=0.6880, Val Loss=1.4087, lr=0.0010
[2025-05-04 12:06:39,057][train][INFO] - Epoch 69/100, Val Acc=0.6494, Val Loss=1.3727, lr=0.0010
[2025-05-04 12:06:46,416][train][INFO] - Epoch 70/100, Val Acc=0.6900, Val Loss=1.4120, lr=0.0010
[2025-05-04 12:06:46,890][train][INFO] - Epoch 70/100, Val Acc=0.6553, Val Loss=1.3724, lr=0.0010
[2025-05-04 12:06:54,914][train][INFO] - Epoch 71/100, Val Acc=0.6868, Val Loss=1.4293, lr=0.0010
[2025-05-04 12:06:55,451][train][INFO] - Epoch 71/100, Val Acc=0.6521, Val Loss=1.3941, lr=0.0010
[2025-05-04 12:07:02,815][train][INFO] - Epoch 72/100, Val Acc=0.6864, Val Loss=1.4446, lr=0.0010
[2025-05-04 12:07:03,806][train][INFO] - Epoch 72/100, Val Acc=0.6508, Val Loss=1.3897, lr=0.0010
[2025-05-04 12:07:11,289][train][INFO] - Epoch 73/100, Val Acc=0.6909, Val Loss=1.4370, lr=0.0010
[2025-05-04 12:07:11,942][train][INFO] - Epoch 73/100, Val Acc=0.6518, Val Loss=1.3900, lr=0.0010
[2025-05-04 12:07:19,675][train][INFO] - Epoch 74/100, Val Acc=0.6888, Val Loss=1.4518, lr=0.0010
[2025-05-04 12:07:19,695][train][INFO] - Epoch 74/100, Val Acc=0.6540, Val Loss=1.3994, lr=0.0010
[2025-05-04 12:07:27,805][train][INFO] - Epoch 75/100, Val Acc=0.6486, Val Loss=1.4020, lr=0.0010
[2025-05-04 12:07:28,002][train][INFO] - Epoch 75/100, Val Acc=0.6896, Val Loss=1.4553, lr=0.0010
[2025-05-04 12:07:36,138][train][INFO] - Epoch 76/100, Val Acc=0.6508, Val Loss=1.4104, lr=0.0010
[2025-05-04 12:07:36,175][train][INFO] - Epoch 76/100, Val Acc=0.6927, Val Loss=1.4601, lr=0.0010
[2025-05-04 12:07:44,365][train][INFO] - Epoch 77/100, Val Acc=0.6516, Val Loss=1.4169, lr=0.0010
[2025-05-04 12:07:44,553][train][INFO] - Epoch 77/100, Val Acc=0.6894, Val Loss=1.4677, lr=0.0010
[2025-05-04 12:07:52,294][train][INFO] - Epoch 78/100, Val Acc=0.6471, Val Loss=1.4310, lr=0.0010
[2025-05-04 12:07:52,839][train][INFO] - Epoch 78/100, Val Acc=0.6920, Val Loss=1.4677, lr=0.0010
[2025-05-04 12:08:00,614][train][INFO] - Epoch 79/100, Val Acc=0.6480, Val Loss=1.4256, lr=0.0010
[2025-05-04 12:08:01,074][train][INFO] - Epoch 79/100, Val Acc=0.6902, Val Loss=1.4722, lr=0.0010
[2025-05-04 12:08:08,430][train][INFO] - Epoch 80/100, Val Acc=0.6509, Val Loss=1.4344, lr=0.0010
[2025-05-04 12:08:09,315][train][INFO] - Epoch 80/100, Val Acc=0.6890, Val Loss=1.4822, lr=0.0010
[2025-05-04 12:08:16,746][train][INFO] - Epoch 81/100, Val Acc=0.6503, Val Loss=1.4421, lr=0.0010
[2025-05-04 12:08:17,297][train][INFO] - Epoch 81/100, Val Acc=0.6885, Val Loss=1.4847, lr=0.0010
[2025-05-04 12:08:25,097][train][INFO] - Epoch 82/100, Val Acc=0.6490, Val Loss=1.4496, lr=0.0010
[2025-05-04 12:08:25,277][train][INFO] - Epoch 82/100, Val Acc=0.6887, Val Loss=1.4912, lr=0.0010
[2025-05-04 12:08:33,075][train][INFO] - Epoch 83/100, Val Acc=0.6905, Val Loss=1.4933, lr=0.0010
[2025-05-04 12:08:33,118][train][INFO] - Epoch 83/100, Val Acc=0.6504, Val Loss=1.4525, lr=0.0010
[2025-05-04 12:08:40,995][train][INFO] - Epoch 84/100, Val Acc=0.6493, Val Loss=1.4680, lr=0.0010
[2025-05-04 12:08:41,026][train][INFO] - Epoch 84/100, Val Acc=0.6905, Val Loss=1.5087, lr=0.0010
[2025-05-04 12:08:49,369][train][INFO] - Epoch 85/100, Val Acc=0.6479, Val Loss=1.4667, lr=0.0010
[2025-05-04 12:08:49,398][train][INFO] - Epoch 85/100, Val Acc=0.6923, Val Loss=1.5010, lr=0.0010
[2025-05-04 12:08:57,312][train][INFO] - Epoch 86/100, Val Acc=0.6894, Val Loss=1.5237, lr=0.0010
[2025-05-04 12:08:57,388][train][INFO] - Epoch 86/100, Val Acc=0.6495, Val Loss=1.4729, lr=0.0010
[2025-05-04 12:09:05,193][train][INFO] - Epoch 87/100, Val Acc=0.6928, Val Loss=1.5186, lr=0.0010
[2025-05-04 12:09:05,561][train][INFO] - Epoch 87/100, Val Acc=0.6500, Val Loss=1.4826, lr=0.0010
[2025-05-04 12:09:13,157][train][INFO] - Epoch 88/100, Val Acc=0.6891, Val Loss=1.5344, lr=0.0010
[2025-05-04 12:09:14,009][train][INFO] - Epoch 88/100, Val Acc=0.6502, Val Loss=1.4667, lr=0.0010
[2025-05-04 12:09:21,425][train][INFO] - Epoch 89/100, Val Acc=0.6885, Val Loss=1.5389, lr=0.0010
[2025-05-04 12:09:21,928][train][INFO] - Epoch 89/100, Val Acc=0.6516, Val Loss=1.4876, lr=0.0010
[2025-05-04 12:09:29,621][train][INFO] - Epoch 90/100, Val Acc=0.6903, Val Loss=1.5462, lr=0.0010
[2025-05-04 12:09:30,286][train][INFO] - Epoch 90/100, Val Acc=0.6464, Val Loss=1.5131, lr=0.0010
[2025-05-04 12:09:38,070][train][INFO] - Epoch 91/100, Val Acc=0.6901, Val Loss=1.5368, lr=0.0001
[2025-05-04 12:09:38,911][train][INFO] - Epoch 91/100, Val Acc=0.6498, Val Loss=1.4877, lr=0.0001
[2025-05-04 12:09:46,001][train][INFO] - Epoch 92/100, Val Acc=0.6908, Val Loss=1.5402, lr=0.0001
[2025-05-04 12:09:46,754][train][INFO] - Epoch 92/100, Val Acc=0.6507, Val Loss=1.4917, lr=0.0001
[2025-05-04 12:09:54,370][train][INFO] - Epoch 93/100, Val Acc=0.6516, Val Loss=1.4885, lr=0.0001
[2025-05-04 12:09:54,446][train][INFO] - Epoch 93/100, Val Acc=0.6928, Val Loss=1.5334, lr=0.0001
[2025-05-04 12:10:01,448][train][INFO] - Epoch 94/100, Val Acc=0.6933, Val Loss=1.5262, lr=0.0001
[2025-05-04 12:10:02,836][train][INFO] - Epoch 94/100, Val Acc=0.6521, Val Loss=1.4822, lr=0.0001
[2025-05-04 12:10:09,613][train][INFO] - Epoch 95/100, Val Acc=0.6917, Val Loss=1.5338, lr=0.0001
[2025-05-04 12:10:11,039][train][INFO] - Epoch 95/100, Val Acc=0.6518, Val Loss=1.4886, lr=0.0001
[2025-05-04 12:10:17,292][train][INFO] - Epoch 96/100, Val Acc=0.6931, Val Loss=1.5296, lr=0.0001
[2025-05-04 12:10:19,360][train][INFO] - Epoch 96/100, Val Acc=0.6514, Val Loss=1.4836, lr=0.0001
[2025-05-04 12:10:25,393][train][INFO] - Epoch 97/100, Val Acc=0.6907, Val Loss=1.5392, lr=0.0001
[2025-05-04 12:10:27,041][train][INFO] - Epoch 97/100, Val Acc=0.6516, Val Loss=1.4903, lr=0.0001
[2025-05-04 12:10:33,413][train][INFO] - Epoch 98/100, Val Acc=0.6914, Val Loss=1.5317, lr=0.0001
[2025-05-04 12:10:34,584][train][INFO] - Epoch 98/100, Val Acc=0.6531, Val Loss=1.4864, lr=0.0001
[2025-05-04 12:10:41,371][train][INFO] - Epoch 99/100, Val Acc=0.6925, Val Loss=1.5382, lr=0.0001
[2025-05-04 12:10:42,642][train][INFO] - Epoch 99/100, Val Acc=0.6513, Val Loss=1.4929, lr=0.0001
[2025-05-04 12:10:49,808][train][INFO] - Epoch 100/100, Val Acc=0.6930, Val Loss=1.5371, lr=0.0001
[2025-05-04 12:10:51,055][train][INFO] - Epoch 100/100, Val Acc=0.6497, Val Loss=1.4923, lr=0.0001
[2025-05-04 12:10:54,854][train][INFO] - After training : Train Acc=0.9884  Val Acc=0.6933
[2025-05-04 12:10:54,860][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-04 12:10:56,077][train][INFO] - After training : Train Acc=0.8673  Val Acc=0.6553
[2025-05-04 12:10:56,082][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-04 12:12:37,582][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-04 12:12:42,289][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-04 12:15:04,554][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-04 12:15:05,014][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-04 12:15:13,825][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-04 12:15:14,254][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-04 13:08:54,185][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-04 13:08:54,269][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 13:08:54,269][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 13:08:54,269][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 13:09:00,098][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-04 13:09:00,147][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 13:09:00,147][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 13:09:00,147][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 13:09:13,591][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-04 13:09:13,824][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-04 13:09:13,883][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 13:09:13,883][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 13:09:13,883][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 13:09:21,670][train][INFO] - Epoch 1/100, Val Acc=0.0498, Val Loss=4.0701, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 13:09:29,799][train][INFO] - Epoch 2/100, Val Acc=0.1073, Val Loss=3.7285, lr=0.0100
[2025-05-04 13:09:33,485][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-04 13:09:36,960][train][INFO] - Epoch 3/100, Val Acc=0.1012, Val Loss=3.7805, lr=0.0100
[2025-05-04 13:09:41,674][train][INFO] - Epoch 1/100, Val Acc=0.0477, Val Loss=4.2598, lr=0.0100
[2025-05-04 13:09:44,231][train][INFO] - Epoch 4/100, Val Acc=0.2114, Val Loss=3.0320, lr=0.0100
[2025-05-04 13:09:49,614][train][INFO] - Epoch 2/100, Val Acc=0.1800, Val Loss=3.1408, lr=0.0100
[2025-05-04 13:09:52,660][train][INFO] - Epoch 5/100, Val Acc=0.2427, Val Loss=2.9453, lr=0.0100
[2025-05-04 13:09:57,590][train][INFO] - Epoch 3/100, Val Acc=0.2047, Val Loss=3.0136, lr=0.0100
[2025-05-04 13:10:00,561][train][INFO] - Epoch 6/100, Val Acc=0.2416, Val Loss=2.9458, lr=0.0100
[2025-05-04 13:10:04,972][train][INFO] - Epoch 4/100, Val Acc=0.1948, Val Loss=3.0851, lr=0.0100
[2025-05-04 13:10:08,530][train][INFO] - Epoch 7/100, Val Acc=0.2974, Val Loss=2.8628, lr=0.0100
[2025-05-04 13:10:13,043][train][INFO] - Epoch 5/100, Val Acc=0.2555, Val Loss=3.0180, lr=0.0100
[2025-05-04 13:10:16,398][train][INFO] - Epoch 8/100, Val Acc=0.3250, Val Loss=2.6406, lr=0.0100
[2025-05-04 13:10:21,086][train][INFO] - Epoch 6/100, Val Acc=0.3487, Val Loss=2.4645, lr=0.0100
[2025-05-04 13:10:23,747][train][INFO] - Epoch 9/100, Val Acc=0.3207, Val Loss=2.6397, lr=0.0100
[2025-05-04 13:10:29,139][train][INFO] - Epoch 7/100, Val Acc=0.3783, Val Loss=2.2895, lr=0.0100
[2025-05-04 13:10:32,177][train][INFO] - Epoch 10/100, Val Acc=0.3509, Val Loss=2.4300, lr=0.0100
[2025-05-04 13:10:36,592][train][INFO] - Epoch 8/100, Val Acc=0.4061, Val Loss=2.2777, lr=0.0100
[2025-05-04 13:10:40,522][train][INFO] - Epoch 11/100, Val Acc=0.4011, Val Loss=2.2054, lr=0.0100
[2025-05-04 13:10:44,304][train][INFO] - Epoch 9/100, Val Acc=0.4010, Val Loss=2.3423, lr=0.0100
[2025-05-04 13:10:47,832][train][INFO] - Epoch 12/100, Val Acc=0.4183, Val Loss=2.1640, lr=0.0100
[2025-05-04 13:10:52,179][train][INFO] - Epoch 10/100, Val Acc=0.4514, Val Loss=2.0412, lr=0.0100
[2025-05-04 13:10:55,220][train][INFO] - Epoch 13/100, Val Acc=0.4435, Val Loss=2.0170, lr=0.0100
[2025-05-04 13:10:59,894][train][INFO] - Epoch 11/100, Val Acc=0.5048, Val Loss=1.8166, lr=0.0100
[2025-05-04 13:11:03,405][train][INFO] - Epoch 14/100, Val Acc=0.4405, Val Loss=2.0874, lr=0.0100
[2025-05-04 13:11:07,408][train][INFO] - Epoch 12/100, Val Acc=0.4850, Val Loss=1.9557, lr=0.0100
[2025-05-04 13:11:12,098][train][INFO] - Epoch 15/100, Val Acc=0.4195, Val Loss=2.2101, lr=0.0100
[2025-05-04 13:11:15,117][train][INFO] - Epoch 13/100, Val Acc=0.4410, Val Loss=2.2209, lr=0.0100
[2025-05-04 13:11:19,295][train][INFO] - Epoch 16/100, Val Acc=0.4628, Val Loss=1.9817, lr=0.0100
[2025-05-04 13:11:23,131][train][INFO] - Epoch 14/100, Val Acc=0.4867, Val Loss=1.9895, lr=0.0100
[2025-05-04 13:11:27,201][train][INFO] - Epoch 17/100, Val Acc=0.4801, Val Loss=1.8794, lr=0.0100
[2025-05-04 13:11:31,078][train][INFO] - Epoch 15/100, Val Acc=0.5212, Val Loss=1.8461, lr=0.0100
[2025-05-04 13:11:34,973][train][INFO] - Epoch 18/100, Val Acc=0.4345, Val Loss=2.1876, lr=0.0100
[2025-05-04 13:11:39,225][train][INFO] - Epoch 16/100, Val Acc=0.5462, Val Loss=1.6684, lr=0.0100
[2025-05-04 13:11:42,215][train][INFO] - Epoch 19/100, Val Acc=0.4943, Val Loss=1.8217, lr=0.0100
[2025-05-04 13:11:47,412][train][INFO] - Epoch 17/100, Val Acc=0.5245, Val Loss=1.8001, lr=0.0100
[2025-05-04 13:11:50,416][train][INFO] - Epoch 20/100, Val Acc=0.4860, Val Loss=1.8589, lr=0.0100
[2025-05-04 13:11:55,061][train][INFO] - Epoch 18/100, Val Acc=0.5309, Val Loss=1.8349, lr=0.0100
[2025-05-04 13:11:57,729][train][INFO] - Epoch 21/100, Val Acc=0.4424, Val Loss=2.1362, lr=0.0100
[2025-05-04 13:12:03,041][train][INFO] - Epoch 19/100, Val Acc=0.5541, Val Loss=1.6883, lr=0.0100
[2025-05-04 13:12:05,422][train][INFO] - Epoch 22/100, Val Acc=0.4686, Val Loss=2.0200, lr=0.0100
[2025-05-04 13:12:10,683][train][INFO] - Epoch 20/100, Val Acc=0.5786, Val Loss=1.6245, lr=0.0100
[2025-05-04 13:12:12,975][train][INFO] - Epoch 23/100, Val Acc=0.5070, Val Loss=1.7903, lr=0.0100
[2025-05-04 13:12:18,633][train][INFO] - Epoch 21/100, Val Acc=0.5292, Val Loss=1.8784, lr=0.0100
[2025-05-04 13:12:21,135][train][INFO] - Epoch 24/100, Val Acc=0.5075, Val Loss=1.8016, lr=0.0100
[2025-05-04 13:12:26,373][train][INFO] - Epoch 22/100, Val Acc=0.5382, Val Loss=1.8203, lr=0.0100
[2025-05-04 13:12:28,961][train][INFO] - Epoch 25/100, Val Acc=0.5087, Val Loss=1.8099, lr=0.0100
[2025-05-04 13:12:34,632][train][INFO] - Epoch 23/100, Val Acc=0.5682, Val Loss=1.7212, lr=0.0100
[2025-05-04 13:12:37,529][train][INFO] - Epoch 26/100, Val Acc=0.4809, Val Loss=1.9551, lr=0.0100
[2025-05-04 13:12:42,648][train][INFO] - Epoch 24/100, Val Acc=0.5739, Val Loss=1.6791, lr=0.0100
[2025-05-04 13:12:45,861][train][INFO] - Epoch 27/100, Val Acc=0.4908, Val Loss=1.8938, lr=0.0100
[2025-05-04 13:12:50,764][train][INFO] - Epoch 25/100, Val Acc=0.5900, Val Loss=1.5826, lr=0.0100
[2025-05-04 13:12:54,420][train][INFO] - Epoch 28/100, Val Acc=0.4820, Val Loss=1.9695, lr=0.0100
[2025-05-04 13:12:59,191][train][INFO] - Epoch 26/100, Val Acc=0.5526, Val Loss=1.8464, lr=0.0100
[2025-05-04 13:13:02,492][train][INFO] - Epoch 29/100, Val Acc=0.5256, Val Loss=1.7564, lr=0.0100
[2025-05-04 13:13:06,765][train][INFO] - Epoch 27/100, Val Acc=0.6022, Val Loss=1.5530, lr=0.0100
[2025-05-04 13:13:11,064][train][INFO] - Epoch 30/100, Val Acc=0.5313, Val Loss=1.7132, lr=0.0100
[2025-05-04 13:13:14,345][train][INFO] - Epoch 28/100, Val Acc=0.5802, Val Loss=1.6209, lr=0.0100
[2025-05-04 13:13:18,963][train][INFO] - Epoch 31/100, Val Acc=0.5290, Val Loss=1.7829, lr=0.0100
[2025-05-04 13:13:22,331][train][INFO] - Epoch 29/100, Val Acc=0.5965, Val Loss=1.6158, lr=0.0100
[2025-05-04 13:13:27,046][train][INFO] - Epoch 32/100, Val Acc=0.5317, Val Loss=1.7320, lr=0.0100
[2025-05-04 13:13:29,635][train][INFO] - Epoch 30/100, Val Acc=0.6045, Val Loss=1.5908, lr=0.0100
[2025-05-04 13:13:34,828][train][INFO] - Epoch 33/100, Val Acc=0.5049, Val Loss=1.9286, lr=0.0100
[2025-05-04 13:13:37,678][train][INFO] - Epoch 31/100, Val Acc=0.6015, Val Loss=1.6014, lr=0.0100
[2025-05-04 13:13:42,262][train][INFO] - Epoch 34/100, Val Acc=0.4972, Val Loss=1.9323, lr=0.0100
[2025-05-04 13:13:45,467][train][INFO] - Epoch 32/100, Val Acc=0.5894, Val Loss=1.6960, lr=0.0100
[2025-05-04 13:13:50,319][train][INFO] - Epoch 35/100, Val Acc=0.5299, Val Loss=1.7207, lr=0.0100
[2025-05-04 13:13:53,375][train][INFO] - Epoch 33/100, Val Acc=0.5832, Val Loss=1.6813, lr=0.0100
[2025-05-04 13:13:58,812][train][INFO] - Epoch 36/100, Val Acc=0.5112, Val Loss=1.8713, lr=0.0100
[2025-05-04 13:14:01,463][train][INFO] - Epoch 34/100, Val Acc=0.6108, Val Loss=1.5890, lr=0.0100
[2025-05-04 13:14:06,680][train][INFO] - Epoch 37/100, Val Acc=0.5491, Val Loss=1.6927, lr=0.0100
[2025-05-04 13:14:09,350][train][INFO] - Epoch 35/100, Val Acc=0.5902, Val Loss=1.6914, lr=0.0100
[2025-05-04 13:14:13,952][train][INFO] - Epoch 38/100, Val Acc=0.5422, Val Loss=1.6943, lr=0.0100
[2025-05-04 13:14:17,961][train][INFO] - Epoch 36/100, Val Acc=0.5950, Val Loss=1.6372, lr=0.0100
[2025-05-04 13:14:22,532][train][INFO] - Epoch 39/100, Val Acc=0.5596, Val Loss=1.6220, lr=0.0100
[2025-05-04 13:14:25,489][train][INFO] - Epoch 37/100, Val Acc=0.5957, Val Loss=1.6907, lr=0.0100
[2025-05-04 13:14:30,224][train][INFO] - Epoch 40/100, Val Acc=0.5390, Val Loss=1.7392, lr=0.0100
[2025-05-04 13:14:33,567][train][INFO] - Epoch 38/100, Val Acc=0.5994, Val Loss=1.6521, lr=0.0100
[2025-05-04 13:14:38,555][train][INFO] - Epoch 41/100, Val Acc=0.5231, Val Loss=1.8813, lr=0.0100
[2025-05-04 13:14:41,407][train][INFO] - Epoch 39/100, Val Acc=0.6045, Val Loss=1.6506, lr=0.0100
[2025-05-04 13:14:46,132][train][INFO] - Epoch 42/100, Val Acc=0.5333, Val Loss=1.7644, lr=0.0100
[2025-05-04 13:14:49,552][train][INFO] - Epoch 40/100, Val Acc=0.5957, Val Loss=1.6921, lr=0.0100
[2025-05-04 13:14:53,497][train][INFO] - Epoch 43/100, Val Acc=0.5573, Val Loss=1.6679, lr=0.0100
[2025-05-04 13:14:57,881][train][INFO] - Epoch 41/100, Val Acc=0.6126, Val Loss=1.6022, lr=0.0100
[2025-05-04 13:15:01,362][train][INFO] - Epoch 44/100, Val Acc=0.5433, Val Loss=1.7712, lr=0.0100
[2025-05-04 13:15:06,052][train][INFO] - Epoch 42/100, Val Acc=0.6008, Val Loss=1.7293, lr=0.0100
[2025-05-04 13:15:08,447][train][INFO] - Epoch 45/100, Val Acc=0.5575, Val Loss=1.6770, lr=0.0100
[2025-05-04 13:15:14,172][train][INFO] - Epoch 43/100, Val Acc=0.6106, Val Loss=1.6888, lr=0.0100
[2025-05-04 13:15:17,090][train][INFO] - Epoch 46/100, Val Acc=0.5451, Val Loss=1.7361, lr=0.0100
[2025-05-04 13:15:21,590][train][INFO] - Epoch 44/100, Val Acc=0.6022, Val Loss=1.6992, lr=0.0100
[2025-05-04 13:15:25,065][train][INFO] - Epoch 47/100, Val Acc=0.5551, Val Loss=1.7168, lr=0.0100
[2025-05-04 13:15:28,760][train][INFO] - Epoch 45/100, Val Acc=0.6069, Val Loss=1.6741, lr=0.0100
[2025-05-04 13:15:32,878][train][INFO] - Epoch 48/100, Val Acc=0.5555, Val Loss=1.7282, lr=0.0100
[2025-05-04 13:15:36,299][train][INFO] - Epoch 46/100, Val Acc=0.6077, Val Loss=1.6555, lr=0.0100
[2025-05-04 13:15:40,480][train][INFO] - Epoch 49/100, Val Acc=0.5588, Val Loss=1.6738, lr=0.0100
[2025-05-04 13:15:44,094][train][INFO] - Epoch 47/100, Val Acc=0.5942, Val Loss=1.7828, lr=0.0100
[2025-05-04 13:15:48,807][train][INFO] - Epoch 50/100, Val Acc=0.5569, Val Loss=1.7256, lr=0.0100
[2025-05-04 13:15:52,353][train][INFO] - Epoch 48/100, Val Acc=0.6006, Val Loss=1.7140, lr=0.0100
[2025-05-04 13:15:56,448][train][INFO] - Epoch 51/100, Val Acc=0.5711, Val Loss=1.6467, lr=0.0100
[2025-05-04 13:16:00,725][train][INFO] - Epoch 49/100, Val Acc=0.6161, Val Loss=1.6509, lr=0.0100
[2025-05-04 13:16:04,371][train][INFO] - Epoch 52/100, Val Acc=0.5407, Val Loss=1.8245, lr=0.0100
[2025-05-04 13:16:08,034][train][INFO] - Epoch 50/100, Val Acc=0.6044, Val Loss=1.7283, lr=0.0100
[2025-05-04 13:16:12,261][train][INFO] - Epoch 53/100, Val Acc=0.5788, Val Loss=1.6307, lr=0.0100
[2025-05-04 13:16:16,078][train][INFO] - Epoch 51/100, Val Acc=0.6041, Val Loss=1.7113, lr=0.0100
[2025-05-04 13:16:20,564][train][INFO] - Epoch 54/100, Val Acc=0.5520, Val Loss=1.7428, lr=0.0100
[2025-05-04 13:16:24,202][train][INFO] - Epoch 52/100, Val Acc=0.6287, Val Loss=1.5932, lr=0.0100
[2025-05-04 13:16:28,432][train][INFO] - Epoch 55/100, Val Acc=0.5525, Val Loss=1.7450, lr=0.0100
[2025-05-04 13:16:31,885][train][INFO] - Epoch 53/100, Val Acc=0.6217, Val Loss=1.6603, lr=0.0100
[2025-05-04 13:16:37,064][train][INFO] - Epoch 56/100, Val Acc=0.5839, Val Loss=1.6067, lr=0.0100
[2025-05-04 13:16:39,704][train][INFO] - Epoch 54/100, Val Acc=0.6270, Val Loss=1.5705, lr=0.0100
[2025-05-04 13:16:44,735][train][INFO] - Epoch 57/100, Val Acc=0.5611, Val Loss=1.7065, lr=0.0100
[2025-05-04 13:16:47,451][train][INFO] - Epoch 55/100, Val Acc=0.6294, Val Loss=1.5980, lr=0.0100
[2025-05-04 13:16:52,753][train][INFO] - Epoch 58/100, Val Acc=0.5690, Val Loss=1.6520, lr=0.0100
[2025-05-04 13:16:55,791][train][INFO] - Epoch 56/100, Val Acc=0.6263, Val Loss=1.6246, lr=0.0100
[2025-05-04 13:17:00,920][train][INFO] - Epoch 59/100, Val Acc=0.5442, Val Loss=1.7990, lr=0.0100
[2025-05-04 13:17:04,000][train][INFO] - Epoch 57/100, Val Acc=0.6276, Val Loss=1.6091, lr=0.0100
[2025-05-04 13:17:09,438][train][INFO] - Epoch 60/100, Val Acc=0.5901, Val Loss=1.5750, lr=0.0100
[2025-05-04 13:17:12,403][train][INFO] - Epoch 58/100, Val Acc=0.6157, Val Loss=1.6608, lr=0.0100
[2025-05-04 13:17:17,653][train][INFO] - Epoch 61/100, Val Acc=0.6420, Val Loss=1.3518, lr=0.0010
[2025-05-04 13:17:20,804][train][INFO] - Epoch 59/100, Val Acc=0.6123, Val Loss=1.6716, lr=0.0100
[2025-05-04 13:17:25,175][train][INFO] - Epoch 62/100, Val Acc=0.6463, Val Loss=1.3438, lr=0.0010
[2025-05-04 13:17:28,757][train][INFO] - Epoch 60/100, Val Acc=0.6115, Val Loss=1.7082, lr=0.0100
[2025-05-04 13:17:33,184][train][INFO] - Epoch 63/100, Val Acc=0.6478, Val Loss=1.3418, lr=0.0010
[2025-05-04 13:17:36,485][train][INFO] - Epoch 61/100, Val Acc=0.6872, Val Loss=1.3398, lr=0.0010
[2025-05-04 13:17:41,504][train][INFO] - Epoch 64/100, Val Acc=0.6515, Val Loss=1.3432, lr=0.0010
[2025-05-04 13:17:44,862][train][INFO] - Epoch 62/100, Val Acc=0.6881, Val Loss=1.3396, lr=0.0010
[2025-05-04 13:17:49,925][train][INFO] - Epoch 65/100, Val Acc=0.6473, Val Loss=1.3500, lr=0.0010
[2025-05-04 13:17:52,597][train][INFO] - Epoch 63/100, Val Acc=0.6891, Val Loss=1.3518, lr=0.0010
[2025-05-04 13:17:58,487][train][INFO] - Epoch 66/100, Val Acc=0.6499, Val Loss=1.3581, lr=0.0010
[2025-05-04 13:18:00,536][train][INFO] - Epoch 64/100, Val Acc=0.6876, Val Loss=1.3603, lr=0.0010
[2025-05-04 13:18:06,864][train][INFO] - Epoch 67/100, Val Acc=0.6496, Val Loss=1.3648, lr=0.0010
[2025-05-04 13:18:08,418][train][INFO] - Epoch 65/100, Val Acc=0.6883, Val Loss=1.3687, lr=0.0010
[2025-05-04 13:18:15,332][train][INFO] - Epoch 68/100, Val Acc=0.6518, Val Loss=1.3641, lr=0.0010
[2025-05-04 13:18:15,715][train][INFO] - Epoch 66/100, Val Acc=0.6884, Val Loss=1.3851, lr=0.0010
[2025-05-04 13:18:23,665][train][INFO] - Epoch 69/100, Val Acc=0.6494, Val Loss=1.3727, lr=0.0010
[2025-05-04 13:18:23,735][train][INFO] - Epoch 67/100, Val Acc=0.6917, Val Loss=1.3924, lr=0.0010
[2025-05-04 13:18:31,655][train][INFO] - Epoch 70/100, Val Acc=0.6553, Val Loss=1.3724, lr=0.0010
[2025-05-04 13:18:32,125][train][INFO] - Epoch 68/100, Val Acc=0.6890, Val Loss=1.3990, lr=0.0010
[2025-05-04 13:18:39,729][train][INFO] - Epoch 71/100, Val Acc=0.6521, Val Loss=1.3941, lr=0.0010
[2025-05-04 13:18:40,154][train][INFO] - Epoch 69/100, Val Acc=0.6880, Val Loss=1.4087, lr=0.0010
[2025-05-04 13:18:47,450][train][INFO] - Epoch 72/100, Val Acc=0.6508, Val Loss=1.3897, lr=0.0010
[2025-05-04 13:18:48,175][train][INFO] - Epoch 70/100, Val Acc=0.6900, Val Loss=1.4120, lr=0.0010
[2025-05-04 13:18:54,926][train][INFO] - Epoch 73/100, Val Acc=0.6518, Val Loss=1.3900, lr=0.0010
[2025-05-04 13:18:56,354][train][INFO] - Epoch 71/100, Val Acc=0.6868, Val Loss=1.4293, lr=0.0010
[2025-05-04 13:19:02,645][train][INFO] - Epoch 74/100, Val Acc=0.6540, Val Loss=1.3994, lr=0.0010
[2025-05-04 13:19:04,153][train][INFO] - Epoch 72/100, Val Acc=0.6864, Val Loss=1.4446, lr=0.0010
[2025-05-04 13:19:10,554][train][INFO] - Epoch 75/100, Val Acc=0.6486, Val Loss=1.4020, lr=0.0010
[2025-05-04 13:19:12,358][train][INFO] - Epoch 73/100, Val Acc=0.6909, Val Loss=1.4370, lr=0.0010
[2025-05-04 13:19:18,275][train][INFO] - Epoch 76/100, Val Acc=0.6508, Val Loss=1.4104, lr=0.0010
[2025-05-04 13:19:20,111][train][INFO] - Epoch 74/100, Val Acc=0.6888, Val Loss=1.4518, lr=0.0010
[2025-05-04 13:19:25,866][train][INFO] - Epoch 77/100, Val Acc=0.6516, Val Loss=1.4169, lr=0.0010
[2025-05-04 13:19:28,434][train][INFO] - Epoch 75/100, Val Acc=0.6896, Val Loss=1.4553, lr=0.0010
[2025-05-04 13:19:33,444][train][INFO] - Epoch 78/100, Val Acc=0.6471, Val Loss=1.4310, lr=0.0010
[2025-05-04 13:19:36,560][train][INFO] - Epoch 76/100, Val Acc=0.6927, Val Loss=1.4601, lr=0.0010
[2025-05-04 13:19:41,314][train][INFO] - Epoch 79/100, Val Acc=0.6480, Val Loss=1.4256, lr=0.0010
[2025-05-04 13:19:44,708][train][INFO] - Epoch 77/100, Val Acc=0.6894, Val Loss=1.4677, lr=0.0010
[2025-05-04 13:19:49,451][train][INFO] - Epoch 80/100, Val Acc=0.6509, Val Loss=1.4344, lr=0.0010
[2025-05-04 13:19:52,769][train][INFO] - Epoch 78/100, Val Acc=0.6920, Val Loss=1.4677, lr=0.0010
[2025-05-04 13:19:57,384][train][INFO] - Epoch 81/100, Val Acc=0.6503, Val Loss=1.4421, lr=0.0010
[2025-05-04 13:20:00,009][train][INFO] - Epoch 79/100, Val Acc=0.6902, Val Loss=1.4722, lr=0.0010
[2025-05-04 13:20:05,685][train][INFO] - Epoch 82/100, Val Acc=0.6490, Val Loss=1.4496, lr=0.0010
[2025-05-04 13:20:07,934][train][INFO] - Epoch 80/100, Val Acc=0.6890, Val Loss=1.4822, lr=0.0010
[2025-05-04 13:20:13,418][train][INFO] - Epoch 83/100, Val Acc=0.6504, Val Loss=1.4525, lr=0.0010
[2025-05-04 13:20:16,379][train][INFO] - Epoch 81/100, Val Acc=0.6885, Val Loss=1.4847, lr=0.0010
[2025-05-04 13:20:21,629][train][INFO] - Epoch 84/100, Val Acc=0.6493, Val Loss=1.4680, lr=0.0010
[2025-05-04 13:20:23,821][train][INFO] - Epoch 82/100, Val Acc=0.6887, Val Loss=1.4912, lr=0.0010
[2025-05-04 13:20:29,460][train][INFO] - Epoch 85/100, Val Acc=0.6479, Val Loss=1.4667, lr=0.0010
[2025-05-04 13:20:32,022][train][INFO] - Epoch 83/100, Val Acc=0.6905, Val Loss=1.4933, lr=0.0010
[2025-05-04 13:20:36,899][train][INFO] - Epoch 86/100, Val Acc=0.6495, Val Loss=1.4729, lr=0.0010
[2025-05-04 13:20:40,015][train][INFO] - Epoch 84/100, Val Acc=0.6905, Val Loss=1.5087, lr=0.0010
[2025-05-04 13:20:45,215][train][INFO] - Epoch 87/100, Val Acc=0.6500, Val Loss=1.4826, lr=0.0010
[2025-05-04 13:20:47,322][train][INFO] - Epoch 85/100, Val Acc=0.6923, Val Loss=1.5010, lr=0.0010
[2025-05-04 13:20:53,416][train][INFO] - Epoch 88/100, Val Acc=0.6502, Val Loss=1.4667, lr=0.0010
[2025-05-04 13:20:55,426][train][INFO] - Epoch 86/100, Val Acc=0.6894, Val Loss=1.5237, lr=0.0010
[2025-05-04 13:21:01,112][train][INFO] - Epoch 89/100, Val Acc=0.6516, Val Loss=1.4876, lr=0.0010
[2025-05-04 13:21:03,423][train][INFO] - Epoch 87/100, Val Acc=0.6928, Val Loss=1.5186, lr=0.0010
[2025-05-04 13:21:09,239][train][INFO] - Epoch 90/100, Val Acc=0.6464, Val Loss=1.5131, lr=0.0010
[2025-05-04 13:21:11,234][train][INFO] - Epoch 88/100, Val Acc=0.6891, Val Loss=1.5344, lr=0.0010
[2025-05-04 13:21:17,371][train][INFO] - Epoch 91/100, Val Acc=0.6498, Val Loss=1.4877, lr=0.0001
[2025-05-04 13:21:19,606][train][INFO] - Epoch 89/100, Val Acc=0.6885, Val Loss=1.5389, lr=0.0010
[2025-05-04 13:21:25,171][train][INFO] - Epoch 92/100, Val Acc=0.6507, Val Loss=1.4917, lr=0.0001
[2025-05-04 13:21:27,953][train][INFO] - Epoch 90/100, Val Acc=0.6903, Val Loss=1.5462, lr=0.0010
[2025-05-04 13:21:33,230][train][INFO] - Epoch 93/100, Val Acc=0.6516, Val Loss=1.4885, lr=0.0001
[2025-05-04 13:21:35,636][train][INFO] - Epoch 91/100, Val Acc=0.6901, Val Loss=1.5368, lr=0.0001
[2025-05-04 13:21:41,563][train][INFO] - Epoch 94/100, Val Acc=0.6521, Val Loss=1.4822, lr=0.0001
[2025-05-04 13:21:43,597][train][INFO] - Epoch 92/100, Val Acc=0.6908, Val Loss=1.5402, lr=0.0001
[2025-05-04 13:21:49,950][train][INFO] - Epoch 95/100, Val Acc=0.6518, Val Loss=1.4886, lr=0.0001
[2025-05-04 13:21:51,686][train][INFO] - Epoch 93/100, Val Acc=0.6928, Val Loss=1.5334, lr=0.0001
[2025-05-04 13:21:57,833][train][INFO] - Epoch 96/100, Val Acc=0.6514, Val Loss=1.4836, lr=0.0001
[2025-05-04 13:21:59,616][train][INFO] - Epoch 94/100, Val Acc=0.6933, Val Loss=1.5262, lr=0.0001
[2025-05-04 13:22:05,949][train][INFO] - Epoch 97/100, Val Acc=0.6516, Val Loss=1.4903, lr=0.0001
[2025-05-04 13:22:06,933][train][INFO] - Epoch 95/100, Val Acc=0.6917, Val Loss=1.5338, lr=0.0001
[2025-05-04 13:22:14,415][train][INFO] - Epoch 98/100, Val Acc=0.6531, Val Loss=1.4864, lr=0.0001
[2025-05-04 13:22:15,213][train][INFO] - Epoch 96/100, Val Acc=0.6931, Val Loss=1.5296, lr=0.0001
[2025-05-04 13:22:22,380][train][INFO] - Epoch 99/100, Val Acc=0.6513, Val Loss=1.4929, lr=0.0001
[2025-05-04 13:22:23,301][train][INFO] - Epoch 97/100, Val Acc=0.6907, Val Loss=1.5392, lr=0.0001
[2025-05-04 13:22:30,874][train][INFO] - Epoch 98/100, Val Acc=0.6914, Val Loss=1.5317, lr=0.0001
[2025-05-04 13:22:30,893][train][INFO] - Epoch 100/100, Val Acc=0.6497, Val Loss=1.4923, lr=0.0001
[2025-05-04 13:22:36,226][train][INFO] - After training : Train Acc=0.8673  Val Acc=0.6553
[2025-05-04 13:22:39,025][train][INFO] - Epoch 99/100, Val Acc=0.6925, Val Loss=1.5382, lr=0.0001
[2025-05-04 13:22:46,867][train][INFO] - Epoch 100/100, Val Acc=0.6930, Val Loss=1.5371, lr=0.0001
[2025-05-04 13:22:46,903][Progressive pruning][INFO] - Train acc : 0.010079999454319477   Val acc : 0.009999999776482582
[2025-05-04 13:22:46,903][Progressive pruning][INFO] - Current speed up: 4.54
[2025-05-04 13:22:51,954][train][INFO] - After training : Train Acc=0.9884  Val Acc=0.6933
[2025-05-04 13:22:52,106][train][INFO] - Before training : Train Acc=0.0101  Val Acc=0.0100
[2025-05-04 13:22:59,508][train][INFO] - Epoch 1/140, Val Acc=0.4853, Val Loss=1.9541, lr=0.0100
[2025-05-04 13:23:03,542][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-04 13:23:03,542][Progressive pruning][INFO] - Current speed up: 4.54
[2025-05-04 13:23:07,369][train][INFO] - Epoch 2/140, Val Acc=0.4711, Val Loss=2.0950, lr=0.0100
[2025-05-04 13:23:08,581][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-04 13:23:15,576][train][INFO] - Epoch 3/140, Val Acc=0.4961, Val Loss=1.9321, lr=0.0100
[2025-05-04 13:23:16,522][train][INFO] - Epoch 1/140, Val Acc=0.2229, Val Loss=2.8144, lr=0.0100
[2025-05-04 13:23:23,475][train][INFO] - Epoch 2/140, Val Acc=0.3152, Val Loss=2.5526, lr=0.0100
[2025-05-04 13:23:23,541][train][INFO] - Epoch 4/140, Val Acc=0.4980, Val Loss=1.9869, lr=0.0100
[2025-05-04 13:23:31,711][train][INFO] - Epoch 3/140, Val Acc=0.3401, Val Loss=2.5472, lr=0.0100
[2025-05-04 13:23:32,241][train][INFO] - Epoch 5/140, Val Acc=0.5368, Val Loss=1.7664, lr=0.0100
[2025-05-04 13:23:40,278][train][INFO] - Epoch 4/140, Val Acc=0.3032, Val Loss=2.8293, lr=0.0100
[2025-05-04 13:23:40,655][train][INFO] - Epoch 6/140, Val Acc=0.5171, Val Loss=1.8810, lr=0.0100
[2025-05-04 13:23:47,857][train][INFO] - Epoch 5/140, Val Acc=0.2986, Val Loss=2.9631, lr=0.0100
[2025-05-04 13:23:48,411][train][INFO] - Epoch 7/140, Val Acc=0.5105, Val Loss=1.9300, lr=0.0100
[2025-05-04 13:23:56,003][train][INFO] - Epoch 8/140, Val Acc=0.5242, Val Loss=1.8373, lr=0.0100
[2025-05-04 13:23:56,424][train][INFO] - Epoch 6/140, Val Acc=0.3848, Val Loss=2.4080, lr=0.0100
[2025-05-04 13:24:04,014][train][INFO] - Epoch 9/140, Val Acc=0.5189, Val Loss=1.8387, lr=0.0100
[2025-05-04 13:24:04,291][train][INFO] - Epoch 7/140, Val Acc=0.4226, Val Loss=2.2239, lr=0.0100
[2025-05-04 13:24:12,585][train][INFO] - Epoch 10/140, Val Acc=0.5505, Val Loss=1.6773, lr=0.0100
[2025-05-04 13:24:12,628][train][INFO] - Epoch 8/140, Val Acc=0.4309, Val Loss=2.2623, lr=0.0100
[2025-05-04 13:24:19,895][train][INFO] - Epoch 9/140, Val Acc=0.4357, Val Loss=2.1996, lr=0.0100
[2025-05-04 13:24:20,740][train][INFO] - Epoch 11/140, Val Acc=0.4978, Val Loss=2.0221, lr=0.0100
[2025-05-04 13:24:27,813][train][INFO] - Epoch 10/140, Val Acc=0.4624, Val Loss=2.1192, lr=0.0100
[2025-05-04 13:24:29,120][train][INFO] - Epoch 12/140, Val Acc=0.5307, Val Loss=1.8014, lr=0.0100
[2025-05-04 13:24:35,710][train][INFO] - Epoch 11/140, Val Acc=0.4433, Val Loss=2.2037, lr=0.0100
[2025-05-04 13:24:37,595][train][INFO] - Epoch 13/140, Val Acc=0.5214, Val Loss=1.8358, lr=0.0100
[2025-05-04 13:24:43,655][train][INFO] - Epoch 12/140, Val Acc=0.4316, Val Loss=2.3581, lr=0.0100
[2025-05-04 13:24:45,639][train][INFO] - Epoch 14/140, Val Acc=0.5521, Val Loss=1.7056, lr=0.0100
[2025-05-04 13:24:50,699][train][INFO] - Epoch 13/140, Val Acc=0.4615, Val Loss=2.1751, lr=0.0100
[2025-05-04 13:24:53,375][train][INFO] - Epoch 15/140, Val Acc=0.5163, Val Loss=1.9121, lr=0.0100
[2025-05-04 13:24:58,664][train][INFO] - Epoch 14/140, Val Acc=0.4590, Val Loss=2.1651, lr=0.0100
[2025-05-04 13:25:00,991][train][INFO] - Epoch 16/140, Val Acc=0.5350, Val Loss=1.8055, lr=0.0100
[2025-05-04 13:25:06,560][train][INFO] - Epoch 15/140, Val Acc=0.4957, Val Loss=2.0255, lr=0.0100
[2025-05-04 13:25:08,194][train][INFO] - Epoch 17/140, Val Acc=0.5297, Val Loss=1.8581, lr=0.0100
[2025-05-04 13:25:14,099][train][INFO] - Epoch 16/140, Val Acc=0.4836, Val Loss=2.0753, lr=0.0100
[2025-05-04 13:25:15,712][train][INFO] - Epoch 18/140, Val Acc=0.5382, Val Loss=1.7446, lr=0.0100
[2025-05-04 13:25:22,174][train][INFO] - Epoch 17/140, Val Acc=0.4485, Val Loss=2.2704, lr=0.0100
[2025-05-04 13:25:23,028][train][INFO] - Epoch 19/140, Val Acc=0.5432, Val Loss=1.7436, lr=0.0100
[2025-05-04 13:25:30,104][train][INFO] - Epoch 18/140, Val Acc=0.4924, Val Loss=2.0657, lr=0.0100
[2025-05-04 13:25:31,067][train][INFO] - Epoch 20/140, Val Acc=0.5404, Val Loss=1.7838, lr=0.0100
[2025-05-04 13:25:38,292][train][INFO] - Epoch 19/140, Val Acc=0.4646, Val Loss=2.2421, lr=0.0100
[2025-05-04 13:25:38,908][train][INFO] - Epoch 21/140, Val Acc=0.5409, Val Loss=1.7435, lr=0.0100
[2025-05-04 13:25:46,026][train][INFO] - Epoch 20/140, Val Acc=0.4868, Val Loss=2.1951, lr=0.0100
[2025-05-04 13:25:46,875][train][INFO] - Epoch 22/140, Val Acc=0.5435, Val Loss=1.7552, lr=0.0100
[2025-05-04 13:25:53,464][train][INFO] - Epoch 21/140, Val Acc=0.4791, Val Loss=2.1986, lr=0.0100
[2025-05-04 13:25:54,826][train][INFO] - Epoch 23/140, Val Acc=0.5314, Val Loss=1.8545, lr=0.0100
[2025-05-04 13:26:01,596][train][INFO] - Epoch 22/140, Val Acc=0.5303, Val Loss=1.8491, lr=0.0100
[2025-05-04 13:26:03,311][train][INFO] - Epoch 24/140, Val Acc=0.5528, Val Loss=1.7171, lr=0.0100
[2025-05-04 13:26:09,229][train][INFO] - Epoch 23/140, Val Acc=0.5180, Val Loss=1.9294, lr=0.0100
[2025-05-04 13:26:11,174][train][INFO] - Epoch 25/140, Val Acc=0.4983, Val Loss=2.0862, lr=0.0100
[2025-05-04 13:26:16,853][train][INFO] - Epoch 24/140, Val Acc=0.4534, Val Loss=2.3867, lr=0.0100
[2025-05-04 13:26:19,079][train][INFO] - Epoch 26/140, Val Acc=0.5477, Val Loss=1.7411, lr=0.0100
[2025-05-04 13:26:25,161][train][INFO] - Epoch 25/140, Val Acc=0.5176, Val Loss=1.9111, lr=0.0100
[2025-05-04 13:26:26,879][train][INFO] - Epoch 27/140, Val Acc=0.5451, Val Loss=1.7683, lr=0.0100
[2025-05-04 13:26:33,278][train][INFO] - Epoch 26/140, Val Acc=0.5269, Val Loss=1.9116, lr=0.0100
[2025-05-04 13:26:34,535][train][INFO] - Epoch 28/140, Val Acc=0.5060, Val Loss=2.0126, lr=0.0100
[2025-05-04 13:26:40,547][train][INFO] - Epoch 27/140, Val Acc=0.5199, Val Loss=2.0006, lr=0.0100
[2025-05-04 13:26:42,849][train][INFO] - Epoch 29/140, Val Acc=0.5502, Val Loss=1.7287, lr=0.0100
[2025-05-04 13:26:48,426][train][INFO] - Epoch 28/140, Val Acc=0.5275, Val Loss=1.9082, lr=0.0100
[2025-05-04 13:26:50,480][train][INFO] - Epoch 30/140, Val Acc=0.5417, Val Loss=1.8038, lr=0.0100
[2025-05-04 13:26:56,023][train][INFO] - Epoch 29/140, Val Acc=0.5172, Val Loss=1.9873, lr=0.0100
[2025-05-04 13:26:58,624][train][INFO] - Epoch 31/140, Val Acc=0.5538, Val Loss=1.7266, lr=0.0100
[2025-05-04 13:27:04,167][train][INFO] - Epoch 30/140, Val Acc=0.5327, Val Loss=1.9665, lr=0.0100
[2025-05-04 13:27:06,792][train][INFO] - Epoch 32/140, Val Acc=0.5495, Val Loss=1.7408, lr=0.0100
[2025-05-04 13:27:12,319][train][INFO] - Epoch 31/140, Val Acc=0.5410, Val Loss=1.8994, lr=0.0100
[2025-05-04 13:27:14,476][train][INFO] - Epoch 33/140, Val Acc=0.5537, Val Loss=1.7550, lr=0.0100
[2025-05-04 13:27:20,423][train][INFO] - Epoch 32/140, Val Acc=0.5264, Val Loss=1.9323, lr=0.0100
[2025-05-04 13:27:22,815][train][INFO] - Epoch 34/140, Val Acc=0.5668, Val Loss=1.6840, lr=0.0100
[2025-05-04 13:27:28,196][train][INFO] - Epoch 33/140, Val Acc=0.5462, Val Loss=1.8876, lr=0.0100
[2025-05-04 13:27:30,492][train][INFO] - Epoch 35/140, Val Acc=0.5304, Val Loss=1.8571, lr=0.0100
[2025-05-04 13:27:36,112][train][INFO] - Epoch 34/140, Val Acc=0.5183, Val Loss=2.0159, lr=0.0100
[2025-05-04 13:27:38,165][train][INFO] - Epoch 36/140, Val Acc=0.5574, Val Loss=1.7531, lr=0.0100
[2025-05-04 13:27:43,945][train][INFO] - Epoch 35/140, Val Acc=0.5092, Val Loss=2.0876, lr=0.0100
[2025-05-04 13:27:46,192][train][INFO] - Epoch 37/140, Val Acc=0.5396, Val Loss=1.8302, lr=0.0100
[2025-05-04 13:27:51,637][train][INFO] - Epoch 36/140, Val Acc=0.5420, Val Loss=1.8501, lr=0.0100
[2025-05-04 13:27:53,833][train][INFO] - Epoch 38/140, Val Acc=0.5447, Val Loss=1.7523, lr=0.0100
[2025-05-04 13:27:59,524][train][INFO] - Epoch 37/140, Val Acc=0.5158, Val Loss=2.1019, lr=0.0100
[2025-05-04 13:28:01,584][train][INFO] - Epoch 39/140, Val Acc=0.5661, Val Loss=1.6595, lr=0.0100
[2025-05-04 13:28:07,349][train][INFO] - Epoch 38/140, Val Acc=0.5387, Val Loss=1.9224, lr=0.0100
[2025-05-04 13:28:09,707][train][INFO] - Epoch 40/140, Val Acc=0.5662, Val Loss=1.7088, lr=0.0100
[2025-05-04 13:28:15,292][train][INFO] - Epoch 39/140, Val Acc=0.5127, Val Loss=1.9537, lr=0.0100
[2025-05-04 13:28:17,219][train][INFO] - Epoch 41/140, Val Acc=0.5525, Val Loss=1.7323, lr=0.0100
[2025-05-04 13:28:23,422][train][INFO] - Epoch 40/140, Val Acc=0.5445, Val Loss=1.9193, lr=0.0100
[2025-05-04 13:28:25,376][train][INFO] - Epoch 42/140, Val Acc=0.5537, Val Loss=1.7990, lr=0.0100
[2025-05-04 13:28:31,423][train][INFO] - Epoch 41/140, Val Acc=0.5365, Val Loss=1.9560, lr=0.0100
[2025-05-04 13:28:33,453][train][INFO] - Epoch 43/140, Val Acc=0.5636, Val Loss=1.7184, lr=0.0100
[2025-05-04 13:28:39,723][train][INFO] - Epoch 42/140, Val Acc=0.5461, Val Loss=1.8725, lr=0.0100
[2025-05-04 13:28:40,957][train][INFO] - Epoch 44/140, Val Acc=0.5553, Val Loss=1.7615, lr=0.0100
[2025-05-04 13:28:47,754][train][INFO] - Epoch 43/140, Val Acc=0.5380, Val Loss=1.9142, lr=0.0100
[2025-05-04 13:28:49,182][train][INFO] - Epoch 45/140, Val Acc=0.5583, Val Loss=1.7114, lr=0.0100
[2025-05-04 13:28:55,974][train][INFO] - Epoch 44/140, Val Acc=0.5434, Val Loss=1.9827, lr=0.0100
[2025-05-04 13:28:57,188][train][INFO] - Epoch 46/140, Val Acc=0.5471, Val Loss=1.7732, lr=0.0100
[2025-05-04 13:29:04,060][train][INFO] - Epoch 45/140, Val Acc=0.5468, Val Loss=1.9574, lr=0.0100
[2025-05-04 13:29:05,349][train][INFO] - Epoch 47/140, Val Acc=0.5446, Val Loss=1.7610, lr=0.0100
[2025-05-04 13:29:12,177][train][INFO] - Epoch 46/140, Val Acc=0.5256, Val Loss=2.1174, lr=0.0100
[2025-05-04 13:29:13,463][train][INFO] - Epoch 48/140, Val Acc=0.5410, Val Loss=1.8027, lr=0.0100
[2025-05-04 13:29:19,740][train][INFO] - Epoch 47/140, Val Acc=0.5361, Val Loss=1.9231, lr=0.0100
[2025-05-04 13:29:21,805][train][INFO] - Epoch 49/140, Val Acc=0.5495, Val Loss=1.7291, lr=0.0100
[2025-05-04 13:29:27,832][train][INFO] - Epoch 48/140, Val Acc=0.5233, Val Loss=2.0726, lr=0.0100
[2025-05-04 13:29:29,577][train][INFO] - Epoch 50/140, Val Acc=0.5587, Val Loss=1.7155, lr=0.0100
[2025-05-04 13:29:35,844][train][INFO] - Epoch 49/140, Val Acc=0.5396, Val Loss=1.8806, lr=0.0100
[2025-05-04 13:29:37,204][train][INFO] - Epoch 51/140, Val Acc=0.5579, Val Loss=1.7247, lr=0.0100
[2025-05-04 13:29:43,612][train][INFO] - Epoch 50/140, Val Acc=0.5429, Val Loss=1.9212, lr=0.0100
[2025-05-04 13:29:45,246][train][INFO] - Epoch 52/140, Val Acc=0.5367, Val Loss=1.8580, lr=0.0100
[2025-05-04 13:29:51,398][train][INFO] - Epoch 51/140, Val Acc=0.5276, Val Loss=2.0102, lr=0.0100
[2025-05-04 13:29:53,474][train][INFO] - Epoch 53/140, Val Acc=0.5526, Val Loss=1.7357, lr=0.0100
[2025-05-04 13:29:59,173][train][INFO] - Epoch 52/140, Val Acc=0.5280, Val Loss=2.0017, lr=0.0100
[2025-05-04 13:30:00,911][train][INFO] - Epoch 54/140, Val Acc=0.5427, Val Loss=1.8178, lr=0.0100
[2025-05-04 13:30:06,577][train][INFO] - Epoch 53/140, Val Acc=0.5450, Val Loss=1.9234, lr=0.0100
[2025-05-04 13:30:09,053][train][INFO] - Epoch 55/140, Val Acc=0.5219, Val Loss=1.9272, lr=0.0100
[2025-05-04 13:30:14,326][train][INFO] - Epoch 54/140, Val Acc=0.5414, Val Loss=1.9503, lr=0.0100
[2025-05-04 13:30:17,157][train][INFO] - Epoch 56/140, Val Acc=0.5467, Val Loss=1.8037, lr=0.0100
[2025-05-04 13:30:21,781][train][INFO] - Epoch 55/140, Val Acc=0.5512, Val Loss=1.9053, lr=0.0100
[2025-05-04 13:30:25,559][train][INFO] - Epoch 57/140, Val Acc=0.5730, Val Loss=1.6553, lr=0.0100
[2025-05-04 13:30:29,936][train][INFO] - Epoch 56/140, Val Acc=0.5440, Val Loss=1.9150, lr=0.0100
[2025-05-04 13:30:34,030][train][INFO] - Epoch 58/140, Val Acc=0.5496, Val Loss=1.7844, lr=0.0100
[2025-05-04 13:30:38,111][train][INFO] - Epoch 57/140, Val Acc=0.5302, Val Loss=2.0818, lr=0.0100
[2025-05-04 13:30:42,258][train][INFO] - Epoch 59/140, Val Acc=0.5720, Val Loss=1.6632, lr=0.0100
[2025-05-04 13:30:46,512][train][INFO] - Epoch 58/140, Val Acc=0.5345, Val Loss=1.9959, lr=0.0100
[2025-05-04 13:30:49,588][train][INFO] - Epoch 60/140, Val Acc=0.5466, Val Loss=1.7724, lr=0.0100
[2025-05-04 13:30:53,916][train][INFO] - Epoch 59/140, Val Acc=0.5446, Val Loss=1.9698, lr=0.0100
[2025-05-04 13:30:57,870][train][INFO] - Epoch 61/140, Val Acc=0.5746, Val Loss=1.6536, lr=0.0100
[2025-05-04 13:31:02,420][train][INFO] - Epoch 60/140, Val Acc=0.5415, Val Loss=2.0160, lr=0.0100
[2025-05-04 13:31:05,751][train][INFO] - Epoch 62/140, Val Acc=0.5611, Val Loss=1.7253, lr=0.0100
[2025-05-04 13:31:10,511][train][INFO] - Epoch 61/140, Val Acc=0.5390, Val Loss=1.9544, lr=0.0100
[2025-05-04 13:31:13,716][train][INFO] - Epoch 63/140, Val Acc=0.5744, Val Loss=1.6404, lr=0.0100
[2025-05-04 13:31:18,538][train][INFO] - Epoch 62/140, Val Acc=0.5292, Val Loss=2.0155, lr=0.0100
[2025-05-04 13:31:22,088][train][INFO] - Epoch 64/140, Val Acc=0.5720, Val Loss=1.6938, lr=0.0100
[2025-05-04 13:31:25,856][train][INFO] - Epoch 63/140, Val Acc=0.5394, Val Loss=2.0403, lr=0.0100
[2025-05-04 13:31:30,046][train][INFO] - Epoch 65/140, Val Acc=0.5478, Val Loss=1.8475, lr=0.0100
[2025-05-04 13:31:34,128][train][INFO] - Epoch 64/140, Val Acc=0.5518, Val Loss=1.8768, lr=0.0100
[2025-05-04 13:31:38,372][train][INFO] - Epoch 66/140, Val Acc=0.5426, Val Loss=1.8955, lr=0.0100
[2025-05-04 13:31:42,114][train][INFO] - Epoch 65/140, Val Acc=0.5630, Val Loss=1.8698, lr=0.0100
[2025-05-04 13:31:45,934][train][INFO] - Epoch 67/140, Val Acc=0.5384, Val Loss=1.8666, lr=0.0100
[2025-05-04 13:31:50,172][train][INFO] - Epoch 66/140, Val Acc=0.5277, Val Loss=2.0466, lr=0.0100
[2025-05-04 13:31:54,073][train][INFO] - Epoch 68/140, Val Acc=0.5446, Val Loss=1.8055, lr=0.0100
[2025-05-04 13:31:58,226][train][INFO] - Epoch 67/140, Val Acc=0.5627, Val Loss=1.8396, lr=0.0100
[2025-05-04 13:32:01,950][train][INFO] - Epoch 69/140, Val Acc=0.5536, Val Loss=1.8077, lr=0.0100
[2025-05-04 13:32:06,424][train][INFO] - Epoch 68/140, Val Acc=0.5578, Val Loss=1.8195, lr=0.0100
[2025-05-04 13:32:10,163][train][INFO] - Epoch 70/140, Val Acc=0.5421, Val Loss=1.8443, lr=0.0100
[2025-05-04 13:32:13,704][train][INFO] - Epoch 69/140, Val Acc=0.5416, Val Loss=1.9448, lr=0.0100
[2025-05-04 13:32:18,335][train][INFO] - Epoch 71/140, Val Acc=0.5635, Val Loss=1.6778, lr=0.0100
[2025-05-04 13:32:21,398][train][INFO] - Epoch 70/140, Val Acc=0.5491, Val Loss=1.9227, lr=0.0100
[2025-05-04 13:32:26,347][train][INFO] - Epoch 72/140, Val Acc=0.5718, Val Loss=1.6680, lr=0.0100
[2025-05-04 13:32:29,141][train][INFO] - Epoch 71/140, Val Acc=0.5521, Val Loss=1.9725, lr=0.0100
[2025-05-04 13:32:34,268][train][INFO] - Epoch 73/140, Val Acc=0.5665, Val Loss=1.7102, lr=0.0100
[2025-05-04 13:32:36,914][train][INFO] - Epoch 72/140, Val Acc=0.5415, Val Loss=2.0277, lr=0.0100
[2025-05-04 13:32:41,669][train][INFO] - Epoch 74/140, Val Acc=0.5521, Val Loss=1.8016, lr=0.0100
[2025-05-04 13:32:45,263][train][INFO] - Epoch 73/140, Val Acc=0.5426, Val Loss=2.0499, lr=0.0100
[2025-05-04 13:32:49,967][train][INFO] - Epoch 75/140, Val Acc=0.5568, Val Loss=1.7644, lr=0.0100
[2025-05-04 13:32:53,408][train][INFO] - Epoch 74/140, Val Acc=0.5228, Val Loss=2.1641, lr=0.0100
[2025-05-04 13:32:57,659][train][INFO] - Epoch 76/140, Val Acc=0.5708, Val Loss=1.6888, lr=0.0100
[2025-05-04 13:33:01,199][train][INFO] - Epoch 75/140, Val Acc=0.5452, Val Loss=2.0303, lr=0.0100
[2025-05-04 13:33:05,617][train][INFO] - Epoch 77/140, Val Acc=0.5767, Val Loss=1.7000, lr=0.0100
[2025-05-04 13:33:09,164][train][INFO] - Epoch 76/140, Val Acc=0.5213, Val Loss=2.1689, lr=0.0100
[2025-05-04 13:33:13,963][train][INFO] - Epoch 78/140, Val Acc=0.5663, Val Loss=1.7639, lr=0.0100
[2025-05-04 13:33:17,280][train][INFO] - Epoch 77/140, Val Acc=0.5450, Val Loss=1.9935, lr=0.0100
[2025-05-04 13:33:21,730][train][INFO] - Epoch 79/140, Val Acc=0.5388, Val Loss=1.8032, lr=0.0100
[2025-05-04 13:33:24,818][train][INFO] - Epoch 78/140, Val Acc=0.5229, Val Loss=2.1334, lr=0.0100
[2025-05-04 13:33:29,403][train][INFO] - Epoch 80/140, Val Acc=0.5703, Val Loss=1.7311, lr=0.0100
[2025-05-04 13:33:32,563][train][INFO] - Epoch 79/140, Val Acc=0.5218, Val Loss=2.1977, lr=0.0100
[2025-05-04 13:33:37,399][train][INFO] - Epoch 81/140, Val Acc=0.6306, Val Loss=1.3974, lr=0.0010
[2025-05-04 13:33:40,337][train][INFO] - Epoch 80/140, Val Acc=0.5538, Val Loss=1.9016, lr=0.0100
[2025-05-04 13:33:46,071][train][INFO] - Epoch 82/140, Val Acc=0.6335, Val Loss=1.4011, lr=0.0010
[2025-05-04 13:33:48,409][train][INFO] - Epoch 81/140, Val Acc=0.6303, Val Loss=1.5222, lr=0.0010
[2025-05-04 13:33:54,350][train][INFO] - Epoch 83/140, Val Acc=0.6361, Val Loss=1.3942, lr=0.0010
[2025-05-04 13:33:56,107][train][INFO] - Epoch 82/140, Val Acc=0.6324, Val Loss=1.5296, lr=0.0010
[2025-05-04 13:34:01,803][train][INFO] - Epoch 84/140, Val Acc=0.6339, Val Loss=1.4060, lr=0.0010
[2025-05-04 13:34:04,203][train][INFO] - Epoch 83/140, Val Acc=0.6322, Val Loss=1.5317, lr=0.0010
[2025-05-04 13:34:10,050][train][INFO] - Epoch 85/140, Val Acc=0.6352, Val Loss=1.4009, lr=0.0010
[2025-05-04 13:34:12,456][train][INFO] - Epoch 84/140, Val Acc=0.6365, Val Loss=1.5420, lr=0.0010
[2025-05-04 13:34:18,620][train][INFO] - Epoch 86/140, Val Acc=0.6393, Val Loss=1.4076, lr=0.0010
[2025-05-04 13:34:20,594][train][INFO] - Epoch 85/140, Val Acc=0.6360, Val Loss=1.5444, lr=0.0010
[2025-05-04 13:34:26,912][train][INFO] - Epoch 87/140, Val Acc=0.6345, Val Loss=1.4131, lr=0.0010
[2025-05-04 13:34:28,783][train][INFO] - Epoch 86/140, Val Acc=0.6329, Val Loss=1.5611, lr=0.0010
[2025-05-04 13:34:34,581][train][INFO] - Epoch 88/140, Val Acc=0.6377, Val Loss=1.4225, lr=0.0010
[2025-05-04 13:34:36,577][train][INFO] - Epoch 87/140, Val Acc=0.6335, Val Loss=1.5534, lr=0.0010
[2025-05-04 13:34:42,730][train][INFO] - Epoch 89/140, Val Acc=0.6375, Val Loss=1.4314, lr=0.0010
[2025-05-04 13:34:44,128][train][INFO] - Epoch 88/140, Val Acc=0.6344, Val Loss=1.5632, lr=0.0010
[2025-05-04 13:34:50,768][train][INFO] - Epoch 90/140, Val Acc=0.6369, Val Loss=1.4351, lr=0.0010
[2025-05-04 13:34:51,813][train][INFO] - Epoch 89/140, Val Acc=0.6344, Val Loss=1.5707, lr=0.0010
[2025-05-04 13:34:58,586][train][INFO] - Epoch 91/140, Val Acc=0.6355, Val Loss=1.4381, lr=0.0010
[2025-05-04 13:34:59,831][train][INFO] - Epoch 90/140, Val Acc=0.6336, Val Loss=1.5750, lr=0.0010
[2025-05-04 13:35:06,759][train][INFO] - Epoch 92/140, Val Acc=0.6364, Val Loss=1.4384, lr=0.0010
[2025-05-04 13:35:07,956][train][INFO] - Epoch 91/140, Val Acc=0.6329, Val Loss=1.5846, lr=0.0010
[2025-05-04 13:35:15,143][train][INFO] - Epoch 93/140, Val Acc=0.6379, Val Loss=1.4352, lr=0.0010
[2025-05-04 13:35:15,857][train][INFO] - Epoch 92/140, Val Acc=0.6358, Val Loss=1.5807, lr=0.0010
[2025-05-04 13:35:23,369][train][INFO] - Epoch 94/140, Val Acc=0.6398, Val Loss=1.4453, lr=0.0010
[2025-05-04 13:35:23,959][train][INFO] - Epoch 93/140, Val Acc=0.6343, Val Loss=1.5811, lr=0.0010
[2025-05-04 13:35:30,863][train][INFO] - Epoch 95/140, Val Acc=0.6395, Val Loss=1.4460, lr=0.0010
[2025-05-04 13:35:31,538][train][INFO] - Epoch 94/140, Val Acc=0.6375, Val Loss=1.6015, lr=0.0010
[2025-05-04 13:35:38,601][train][INFO] - Epoch 96/140, Val Acc=0.6406, Val Loss=1.4533, lr=0.0010
[2025-05-04 13:35:39,204][train][INFO] - Epoch 95/140, Val Acc=0.6349, Val Loss=1.6104, lr=0.0010
[2025-05-04 13:35:46,577][train][INFO] - Epoch 97/140, Val Acc=0.6395, Val Loss=1.4564, lr=0.0010
[2025-05-04 13:35:46,920][train][INFO] - Epoch 96/140, Val Acc=0.6393, Val Loss=1.6111, lr=0.0010
[2025-05-04 13:35:54,796][train][INFO] - Epoch 98/140, Val Acc=0.6369, Val Loss=1.4651, lr=0.0010
[2025-05-04 13:35:55,077][train][INFO] - Epoch 97/140, Val Acc=0.6321, Val Loss=1.6181, lr=0.0010
[2025-05-04 13:36:02,299][train][INFO] - Epoch 99/140, Val Acc=0.6389, Val Loss=1.4680, lr=0.0010
[2025-05-04 13:36:03,317][train][INFO] - Epoch 98/140, Val Acc=0.6345, Val Loss=1.6238, lr=0.0010
[2025-05-04 13:36:11,100][train][INFO] - Epoch 100/140, Val Acc=0.6366, Val Loss=1.4842, lr=0.0010
[2025-05-04 13:36:11,162][train][INFO] - Epoch 99/140, Val Acc=0.6335, Val Loss=1.6368, lr=0.0010
[2025-05-04 13:36:19,158][train][INFO] - Epoch 100/140, Val Acc=0.6328, Val Loss=1.6580, lr=0.0010
[2025-05-04 13:36:19,601][train][INFO] - Epoch 101/140, Val Acc=0.6365, Val Loss=1.4873, lr=0.0010
[2025-05-04 13:36:27,573][train][INFO] - Epoch 102/140, Val Acc=0.6387, Val Loss=1.4835, lr=0.0010
[2025-05-04 13:36:27,620][train][INFO] - Epoch 101/140, Val Acc=0.6327, Val Loss=1.6416, lr=0.0010
[2025-05-04 13:36:35,737][train][INFO] - Epoch 102/140, Val Acc=0.6317, Val Loss=1.6383, lr=0.0010
[2025-05-04 13:36:36,072][train][INFO] - Epoch 103/140, Val Acc=0.6403, Val Loss=1.4886, lr=0.0010
[2025-05-04 13:36:43,676][train][INFO] - Epoch 103/140, Val Acc=0.6321, Val Loss=1.6499, lr=0.0010
[2025-05-04 13:36:44,442][train][INFO] - Epoch 104/140, Val Acc=0.6344, Val Loss=1.4929, lr=0.0010
[2025-05-04 13:36:51,315][train][INFO] - Epoch 104/140, Val Acc=0.6340, Val Loss=1.6622, lr=0.0010
[2025-05-04 13:36:52,402][train][INFO] - Epoch 105/140, Val Acc=0.6387, Val Loss=1.5021, lr=0.0010
[2025-05-04 13:36:59,144][train][INFO] - Epoch 105/140, Val Acc=0.6356, Val Loss=1.6664, lr=0.0010
[2025-05-04 13:37:00,523][train][INFO] - Epoch 106/140, Val Acc=0.6407, Val Loss=1.5038, lr=0.0010
[2025-05-04 13:37:07,378][train][INFO] - Epoch 106/140, Val Acc=0.6317, Val Loss=1.6854, lr=0.0010
[2025-05-04 13:37:08,432][train][INFO] - Epoch 107/140, Val Acc=0.6380, Val Loss=1.5145, lr=0.0010
[2025-05-04 13:37:15,377][train][INFO] - Epoch 107/140, Val Acc=0.6312, Val Loss=1.6916, lr=0.0010
[2025-05-04 13:37:16,285][train][INFO] - Epoch 108/140, Val Acc=0.6364, Val Loss=1.5143, lr=0.0010
[2025-05-04 13:37:23,406][train][INFO] - Epoch 108/140, Val Acc=0.6313, Val Loss=1.6740, lr=0.0010
[2025-05-04 13:37:23,890][train][INFO] - Epoch 109/140, Val Acc=0.6376, Val Loss=1.5190, lr=0.0010
[2025-05-04 13:37:30,969][train][INFO] - Epoch 109/140, Val Acc=0.6271, Val Loss=1.6884, lr=0.0010
[2025-05-04 13:37:31,635][train][INFO] - Epoch 110/140, Val Acc=0.6375, Val Loss=1.5131, lr=0.0010
[2025-05-04 13:37:38,631][train][INFO] - Epoch 110/140, Val Acc=0.6245, Val Loss=1.6947, lr=0.0010
[2025-05-04 13:37:40,227][train][INFO] - Epoch 111/140, Val Acc=0.6361, Val Loss=1.5120, lr=0.0010
[2025-05-04 13:37:45,625][train][INFO] - Epoch 111/140, Val Acc=0.6287, Val Loss=1.6985, lr=0.0010
[2025-05-04 13:37:48,223][train][INFO] - Epoch 112/140, Val Acc=0.6383, Val Loss=1.5359, lr=0.0010
[2025-05-04 13:37:52,928][train][INFO] - Epoch 112/140, Val Acc=0.6282, Val Loss=1.7048, lr=0.0010
[2025-05-04 13:37:56,501][train][INFO] - Epoch 113/140, Val Acc=0.6399, Val Loss=1.5245, lr=0.0010
[2025-05-04 13:38:01,023][train][INFO] - Epoch 113/140, Val Acc=0.6292, Val Loss=1.6971, lr=0.0010
[2025-05-04 13:38:04,573][train][INFO] - Epoch 114/140, Val Acc=0.6381, Val Loss=1.5315, lr=0.0010
[2025-05-04 13:38:08,880][train][INFO] - Epoch 114/140, Val Acc=0.6275, Val Loss=1.7144, lr=0.0010
[2025-05-04 13:38:12,718][train][INFO] - Epoch 115/140, Val Acc=0.6373, Val Loss=1.5341, lr=0.0010
[2025-05-04 13:38:17,145][train][INFO] - Epoch 115/140, Val Acc=0.6247, Val Loss=1.7327, lr=0.0010
[2025-05-04 13:38:20,637][train][INFO] - Epoch 116/140, Val Acc=0.6367, Val Loss=1.5464, lr=0.0010
[2025-05-04 13:38:24,928][train][INFO] - Epoch 116/140, Val Acc=0.6275, Val Loss=1.7210, lr=0.0010
[2025-05-04 13:38:28,775][train][INFO] - Epoch 117/140, Val Acc=0.6387, Val Loss=1.5336, lr=0.0010
[2025-05-04 13:38:33,128][train][INFO] - Epoch 117/140, Val Acc=0.6260, Val Loss=1.7060, lr=0.0010
[2025-05-04 13:38:36,303][train][INFO] - Epoch 118/140, Val Acc=0.6381, Val Loss=1.5372, lr=0.0010
[2025-05-04 13:38:40,920][train][INFO] - Epoch 118/140, Val Acc=0.6260, Val Loss=1.7330, lr=0.0010
[2025-05-04 13:38:44,258][train][INFO] - Epoch 119/140, Val Acc=0.6364, Val Loss=1.5502, lr=0.0010
[2025-05-04 13:38:48,481][train][INFO] - Epoch 119/140, Val Acc=0.6245, Val Loss=1.7586, lr=0.0010
[2025-05-04 13:38:52,800][train][INFO] - Epoch 120/140, Val Acc=0.6350, Val Loss=1.5475, lr=0.0010
[2025-05-04 13:38:56,717][train][INFO] - Epoch 120/140, Val Acc=0.6294, Val Loss=1.7267, lr=0.0010
[2025-05-04 13:39:01,002][train][INFO] - Epoch 121/140, Val Acc=0.6392, Val Loss=1.5289, lr=0.0001
[2025-05-04 13:39:04,038][train][INFO] - Epoch 121/140, Val Acc=0.6318, Val Loss=1.7246, lr=0.0001
[2025-05-04 13:39:08,622][train][INFO] - Epoch 122/140, Val Acc=0.6411, Val Loss=1.5327, lr=0.0001
[2025-05-04 13:39:11,902][train][INFO] - Epoch 122/140, Val Acc=0.6303, Val Loss=1.7324, lr=0.0001
[2025-05-04 13:39:16,250][train][INFO] - Epoch 123/140, Val Acc=0.6419, Val Loss=1.5221, lr=0.0001
[2025-05-04 13:39:19,717][train][INFO] - Epoch 123/140, Val Acc=0.6307, Val Loss=1.7246, lr=0.0001
[2025-05-04 13:39:24,682][train][INFO] - Epoch 124/140, Val Acc=0.6417, Val Loss=1.5329, lr=0.0001
[2025-05-04 13:39:27,569][train][INFO] - Epoch 124/140, Val Acc=0.6315, Val Loss=1.7267, lr=0.0001
[2025-05-04 13:39:32,791][train][INFO] - Epoch 125/140, Val Acc=0.6413, Val Loss=1.5298, lr=0.0001
[2025-05-04 13:39:35,242][train][INFO] - Epoch 125/140, Val Acc=0.6321, Val Loss=1.7344, lr=0.0001
[2025-05-04 13:39:41,138][train][INFO] - Epoch 126/140, Val Acc=0.6415, Val Loss=1.5277, lr=0.0001
[2025-05-04 13:39:43,444][train][INFO] - Epoch 126/140, Val Acc=0.6327, Val Loss=1.7270, lr=0.0001
[2025-05-04 13:39:49,478][train][INFO] - Epoch 127/140, Val Acc=0.6417, Val Loss=1.5365, lr=0.0001
[2025-05-04 13:39:50,918][train][INFO] - Epoch 127/140, Val Acc=0.6342, Val Loss=1.7298, lr=0.0001
[2025-05-04 13:39:57,333][train][INFO] - Epoch 128/140, Val Acc=0.6432, Val Loss=1.5335, lr=0.0001
[2025-05-04 13:39:59,102][train][INFO] - Epoch 128/140, Val Acc=0.6341, Val Loss=1.7260, lr=0.0001
[2025-05-04 13:40:05,150][train][INFO] - Epoch 129/140, Val Acc=0.6421, Val Loss=1.5355, lr=0.0001
[2025-05-04 13:40:07,468][train][INFO] - Epoch 129/140, Val Acc=0.6328, Val Loss=1.7372, lr=0.0001
[2025-05-04 13:40:12,934][train][INFO] - Epoch 130/140, Val Acc=0.6420, Val Loss=1.5320, lr=0.0001
[2025-05-04 13:40:14,849][train][INFO] - Epoch 130/140, Val Acc=0.6319, Val Loss=1.7284, lr=0.0001
[2025-05-04 13:40:20,937][train][INFO] - Epoch 131/140, Val Acc=0.6421, Val Loss=1.5464, lr=0.0001
[2025-05-04 13:40:23,114][train][INFO] - Epoch 131/140, Val Acc=0.6318, Val Loss=1.7355, lr=0.0001
[2025-05-04 13:40:29,481][train][INFO] - Epoch 132/140, Val Acc=0.6410, Val Loss=1.5366, lr=0.0001
[2025-05-04 13:40:29,766][train][INFO] - Epoch 132/140, Val Acc=0.6328, Val Loss=1.7297, lr=0.0001
[2025-05-04 13:40:37,578][train][INFO] - Epoch 133/140, Val Acc=0.6340, Val Loss=1.7332, lr=0.0001
[2025-05-04 13:40:37,919][train][INFO] - Epoch 133/140, Val Acc=0.6414, Val Loss=1.5350, lr=0.0001
[2025-05-04 13:40:45,707][train][INFO] - Epoch 134/140, Val Acc=0.6335, Val Loss=1.7341, lr=0.0001
[2025-05-04 13:40:46,550][train][INFO] - Epoch 134/140, Val Acc=0.6422, Val Loss=1.5371, lr=0.0001
[2025-05-04 13:40:53,522][train][INFO] - Epoch 135/140, Val Acc=0.6344, Val Loss=1.7319, lr=0.0001
[2025-05-04 13:40:54,190][train][INFO] - Epoch 135/140, Val Acc=0.6416, Val Loss=1.5390, lr=0.0001
[2025-05-04 13:41:01,285][train][INFO] - Epoch 136/140, Val Acc=0.6336, Val Loss=1.7347, lr=0.0001
[2025-05-04 13:41:01,961][train][INFO] - Epoch 136/140, Val Acc=0.6429, Val Loss=1.5391, lr=0.0001
[2025-05-04 13:41:09,457][train][INFO] - Epoch 137/140, Val Acc=0.6346, Val Loss=1.7381, lr=0.0001
[2025-05-04 13:41:10,150][train][INFO] - Epoch 137/140, Val Acc=0.6425, Val Loss=1.5379, lr=0.0001
[2025-05-04 13:41:17,366][train][INFO] - Epoch 138/140, Val Acc=0.6345, Val Loss=1.7348, lr=0.0001
[2025-05-04 13:41:18,594][train][INFO] - Epoch 138/140, Val Acc=0.6394, Val Loss=1.5375, lr=0.0001
[2025-05-04 13:41:25,211][train][INFO] - Epoch 139/140, Val Acc=0.6323, Val Loss=1.7396, lr=0.0001
[2025-05-04 13:41:26,722][train][INFO] - Epoch 139/140, Val Acc=0.6426, Val Loss=1.5420, lr=0.0001
[2025-05-04 13:41:33,052][train][INFO] - Epoch 140/140, Val Acc=0.6318, Val Loss=1.7421, lr=0.0001
[2025-05-04 13:41:34,841][train][INFO] - Epoch 140/140, Val Acc=0.6401, Val Loss=1.5452, lr=0.0001
[2025-05-04 13:41:38,176][train][INFO] - After training : Train Acc=0.8896  Val Acc=0.6393
[2025-05-04 13:41:38,193][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(29, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(62, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(118, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(180, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(140, 78, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(78, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(1, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(11, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(2, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(17, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=55, out_features=100, bias=True)
)
[2025-05-04 13:41:38,193][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.6392999887466431
                      Speed up: 4.54   Final speed up: 9.09
[2025-05-04 13:41:39,965][train][INFO] - After training : Train Acc=0.9077  Val Acc=0.6432
[2025-05-04 13:41:39,988][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(9, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(51, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(89, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(98, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(98, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(120, 117, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(117, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(70, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(10, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(12, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(15, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(47, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=99, out_features=100, bias=True)
)
[2025-05-04 13:41:39,989][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.6431999802589417
                      Speed up: 4.54   Final speed up: 9.09
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 219, in <module>
    main()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 105, in run
    cfg = self.compose_config(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 594, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 142, in load_configuration
    return self._load_configuration_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 253, in _load_configuration_impl
    defaults_list = create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 745, in create_defaults_list
    defaults, tree = _create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 715, in _create_defaults_list
    defaults_tree = _create_defaults_tree(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 356, in _create_defaults_tree
    ret = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 457, in _create_defaults_tree_impl
    return _expand_virtual_root(repo, root, overrides, skip_missing)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 280, in _expand_virtual_root
    subtree = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 573, in _create_defaults_tree_impl
    add_child(children, new_root)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 520, in add_child
    subtree_ = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 466, in _create_defaults_tree_impl
    update_package_header(repo=repo, node=parent)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 262, in update_package_header
    loaded = repo.load_config(config_path=node.get_config_path())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 348, in load_config
    ret = self.delegate.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 91, in load_config
    ret = source.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/core_plugins/importlib_resources_config_source.py", line 60, in load_config
    return self._read_config(res)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/core_plugins/importlib_resources_config_source.py", line 44, in _read_config
    cfg = OmegaConf.load(f)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/omegaconf.py", line 192, in load
    obj = yaml.load(file_, Loader=get_yaml_loader())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/_utils.py", line 137, in get_yaml_loader
    class OmegaConfLoader(yaml.SafeLoader):  # type: ignore
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/_utils.py", line 138, in OmegaConfLoader
    def construct_mapping(self, node: yaml.Node, deep: bool = False) -> Any:
KeyboardInterrupt
[2025-05-04 22:00:45,792][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-04 22:00:45,870][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 22:00:45,870][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 22:00:45,870][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 22:01:08,619][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.3092, lr=0.001
[2025-05-04 22:01:27,399][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0919, lr=0.001
[2025-05-04 22:01:45,917][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.5286, lr=0.001
[2025-05-04 22:02:06,232][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.4285, lr=0.001
[2025-05-04 22:02:26,640][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=3.8184, lr=0.001
[2025-05-04 22:02:45,620][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=2.1088, lr=0.001
[2025-05-04 22:03:05,239][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7206, lr=0.001
[2025-05-04 22:03:23,883][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4980, lr=0.001
[2025-05-04 22:03:23,899][meta_train][INFO] - epoch_1 saved !
[2025-05-04 22:03:43,787][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=1.0963, lr=0.001
[2025-05-04 22:04:02,584][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=1.2402, lr=0.001
[2025-05-04 22:04:20,277][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2246, lr=0.001
[2025-05-04 22:04:38,828][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.0867, lr=0.001
[2025-05-04 22:04:57,691][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0615, lr=0.001
[2025-05-04 22:05:18,016][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0551, lr=0.001
[2025-05-04 22:05:37,062][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0856, lr=0.001
[2025-05-04 22:05:56,833][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.1053, lr=0.001
[2025-05-04 22:05:56,849][meta_train][INFO] - epoch_2 saved !
[2025-05-04 22:06:16,812][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1365, lr=0.001
[2025-05-04 22:06:35,422][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.1831, lr=0.001
[2025-05-04 22:06:54,103][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.8700, lr=0.001
[2025-05-04 22:07:11,926][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.3916, lr=0.001
[2025-05-04 22:07:30,602][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2930, lr=0.001
[2025-05-04 22:07:50,593][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.4007, lr=0.001
[2025-05-04 22:08:09,880][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.5278, lr=0.001
[2025-05-04 22:08:29,071][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.6882, lr=0.001
[2025-05-04 22:08:29,088][meta_train][INFO] - epoch_3 saved !
[2025-05-04 22:08:47,503][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.5922, lr=0.001
[2025-05-04 22:09:06,405][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=1.2647, lr=0.001
[2025-05-04 22:09:26,545][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=1.4745, lr=0.001
[2025-05-04 22:09:46,046][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=1.8241, lr=0.001
[2025-05-04 22:10:04,520][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=2.0053, lr=0.001
[2025-05-04 22:10:25,001][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=2.7444, lr=0.001
[2025-05-04 22:10:43,275][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=3.4555, lr=0.001
[2025-05-04 22:11:01,798][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=5.7570, lr=0.001
[2025-05-04 22:11:01,824][meta_train][INFO] - epoch_4 saved !
[2025-05-04 22:11:21,961][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=3.8050, lr=0.001
[2025-05-04 22:11:40,628][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.7332, lr=0.001
[2025-05-04 22:11:59,968][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=4.8864, lr=0.001
[2025-05-04 22:12:18,124][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=6.7454, lr=0.001
[2025-05-04 22:12:36,362][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.9150, lr=0.001
[2025-05-04 22:12:54,641][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=7.6931, lr=0.001
[2025-05-04 22:13:14,309][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9433, lr=0.001
[2025-05-04 22:13:34,069][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.9208, lr=0.001
[2025-05-04 22:13:34,095][meta_train][INFO] - epoch_5 saved !
[2025-05-04 22:13:52,098][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.4155, lr=0.001
[2025-05-04 22:14:10,677][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=5.3798, lr=0.001
[2025-05-04 22:14:30,682][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.8268, lr=0.001
[2025-05-04 22:14:50,722][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.0371, lr=0.001
[2025-05-04 22:15:08,776][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=7.7630, lr=0.001
[2025-05-04 22:15:28,097][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=5.8688, lr=0.001
[2025-05-04 22:15:47,257][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=5.0059, lr=0.001
[2025-05-04 22:16:06,263][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=8.3281, lr=0.001
[2025-05-04 22:16:06,281][meta_train][INFO] - epoch_6 saved !
[2025-05-04 22:16:25,847][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.9874, lr=0.001
[2025-05-04 22:16:44,466][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=7.0864, lr=0.001
[2025-05-04 22:17:02,659][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=8.5477, lr=0.001
[2025-05-04 22:17:22,278][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7421, lr=0.001
[2025-05-04 22:17:41,743][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=5.0420, lr=0.001
[2025-05-04 22:18:00,382][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=5.7017, lr=0.001
[2025-05-04 22:18:18,642][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=8.2784, lr=0.001
[2025-05-04 22:18:37,813][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=6.2093, lr=0.001
[2025-05-04 22:18:37,843][meta_train][INFO] - epoch_7 saved !
[2025-05-04 22:18:56,218][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=8.2074, lr=0.001
[2025-05-04 22:19:15,764][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=6.1951, lr=0.001
[2025-05-04 22:19:35,482][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=5.0037, lr=0.001
[2025-05-04 22:19:55,735][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.8376, lr=0.001
[2025-05-04 22:20:14,340][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=8.7757, lr=0.001
[2025-05-04 22:20:33,072][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=5.6132, lr=0.001
[2025-05-04 22:20:53,255][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7584, lr=0.001
[2025-05-04 22:21:11,966][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=6.8470, lr=0.001
[2025-05-04 22:21:11,983][meta_train][INFO] - epoch_8 saved !
[2025-05-04 22:21:30,399][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=5.5611, lr=0.001
[2025-05-04 22:21:48,563][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=8.2346, lr=0.001
[2025-05-04 22:22:07,181][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=8.4779, lr=0.001
[2025-05-04 22:22:27,423][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7360, lr=0.001
[2025-05-04 22:22:47,670][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.7788, lr=0.001
[2025-05-04 22:23:06,246][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=6.5236, lr=0.001
[2025-05-04 22:23:25,233][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=5.8547, lr=0.001
[2025-05-04 22:23:44,426][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.9007, lr=0.001
[2025-05-04 22:23:44,461][meta_train][INFO] - epoch_9 saved !
[2025-05-04 22:24:03,224][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=5.4172, lr=0.001
[2025-05-04 22:24:21,986][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=8.0329, lr=0.001
[2025-05-04 22:24:41,238][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.8760, lr=0.001
[2025-05-04 22:24:59,830][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=6.2143, lr=0.001
[2025-05-04 22:25:18,101][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=7.7600, lr=0.001
[2025-05-04 22:25:38,175][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.7089, lr=0.001
[2025-05-04 22:25:57,910][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=5.6213, lr=0.001
[2025-05-04 22:26:17,755][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.7290, lr=0.001
[2025-05-04 22:26:17,771][meta_train][INFO] - epoch_10 saved !
[2025-05-04 22:26:36,157][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=7.6630, lr=0.001
[2025-05-04 22:26:55,947][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.7253, lr=0.001
[2025-05-04 22:27:14,494][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=7.3239, lr=0.001
[2025-05-04 22:27:33,956][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=5.4411, lr=0.001
[2025-05-04 22:27:52,394][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=5.7597, lr=0.001
[2025-05-04 22:28:12,585][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.6936, lr=0.001
[2025-05-04 22:28:32,509][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.7863, lr=0.001
[2025-05-04 22:28:51,161][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=5.1004, lr=0.001
[2025-05-04 22:28:51,178][meta_train][INFO] - epoch_11 saved !
[2025-05-04 22:29:09,522][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=7.3119, lr=0.001
[2025-05-04 22:29:28,099][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=6.9502, lr=0.001
[2025-05-04 22:29:47,290][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=5.2458, lr=0.001
[2025-05-04 22:30:07,068][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.6935, lr=0.001
[2025-05-04 22:30:26,987][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.6796, lr=0.001
[2025-05-04 22:30:46,415][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.7498, lr=0.001
[2025-05-04 22:31:04,975][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=5.4786, lr=0.001
[2025-05-04 22:31:23,598][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=4.9877, lr=0.001
[2025-05-04 22:31:23,614][meta_train][INFO] - epoch_12 saved !
[2025-05-04 22:31:41,964][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=7.0135, lr=0.001
[2025-05-04 22:32:00,183][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=5.3974, lr=0.001
[2025-05-04 22:32:18,874][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=4.9490, lr=0.001
[2025-05-04 22:32:38,328][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.7244, lr=0.001
[2025-05-04 22:32:58,735][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.6715, lr=0.001
[2025-05-04 22:33:17,571][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=5.0421, lr=0.001
[2025-05-04 22:33:37,548][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.6665, lr=0.001
[2025-05-04 22:33:56,699][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=6.2195, lr=0.001
[2025-05-04 22:33:56,720][meta_train][INFO] - epoch_13 saved !
[2025-05-04 22:34:15,249][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=4.8712, lr=0.001
[2025-05-04 22:34:34,263][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.7048, lr=0.001
[2025-05-04 22:34:54,131][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.6583, lr=0.001
[2025-05-04 22:35:14,196][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.6598, lr=0.001
[2025-05-04 22:35:32,326][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=5.1360, lr=0.001
[2025-05-04 22:35:51,549][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=4.9256, lr=0.001
[2025-05-04 22:36:10,249][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=6.2715, lr=0.001
[2025-05-04 22:36:28,932][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=5.8837, lr=0.001
[2025-05-04 22:36:28,948][meta_train][INFO] - epoch_14 saved !
[2025-05-04 22:36:47,013][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=5.0145, lr=0.001
[2025-05-04 22:37:07,092][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.6516, lr=0.001
[2025-05-04 22:37:25,282][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=6.1079, lr=0.001
[2025-05-04 22:37:44,462][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.6402, lr=0.001
[2025-05-04 22:38:04,200][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=4.8380, lr=0.001
[2025-05-04 22:38:23,576][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.6609, lr=0.001
[2025-05-04 22:38:42,302][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=4.7561, lr=0.001
[2025-05-04 22:39:01,178][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=5.5683, lr=0.001
[2025-05-04 22:39:01,193][meta_train][INFO] - epoch_15 saved !
[2025-05-04 22:39:19,386][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.9414, lr=0.001
[2025-05-04 22:39:38,652][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.6546, lr=0.001
[2025-05-04 22:39:57,428][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=4.7375, lr=0.001
[2025-05-04 22:40:15,999][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=5.4651, lr=0.001
[2025-05-04 22:40:34,174][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=5.8000, lr=0.001
[2025-05-04 22:40:53,568][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.6324, lr=0.001
[2025-05-04 22:41:13,219][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=4.7446, lr=0.001
[2025-05-04 22:41:33,156][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.6318, lr=0.001
[2025-05-04 22:41:33,172][meta_train][INFO] - epoch_16 saved !
[2025-05-04 22:41:51,821][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.8501, lr=0.001
[2025-05-04 22:42:11,954][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.6257, lr=0.001
[2025-05-04 22:42:31,970][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.6267, lr=0.001
[2025-05-04 22:42:50,625][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=5.6355, lr=0.001
[2025-05-04 22:43:09,648][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=4.7212, lr=0.001
[2025-05-04 22:43:28,583][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.6354, lr=0.001
[2025-05-04 22:43:47,587][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=4.6881, lr=0.001
[2025-05-04 22:44:06,157][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=5.1511, lr=0.001
[2025-05-04 22:44:06,178][meta_train][INFO] - epoch_17 saved !
[2025-05-04 22:44:24,552][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=5.1493, lr=0.001
[2025-05-04 22:44:45,017][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.6183, lr=0.001
[2025-05-04 22:45:03,859][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.6352, lr=0.001
[2025-05-04 22:45:22,324][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.7270, lr=0.001
[2025-05-04 22:45:41,337][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=4.6699, lr=0.001
[2025-05-04 22:46:00,714][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.6195, lr=0.001
[2025-05-04 22:46:19,752][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=4.6733, lr=0.001
[2025-05-04 22:46:38,004][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=5.3995, lr=0.001
[2025-05-04 22:46:38,020][meta_train][INFO] - epoch_18 saved !
[2025-05-04 22:46:56,198][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=4.9691, lr=0.001
[2025-05-04 22:47:14,726][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.7287, lr=0.001
[2025-05-04 22:47:33,244][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=5.2952, lr=0.001
[2025-05-04 22:47:53,086][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.6151, lr=0.001
[2025-05-04 22:48:13,240][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.6136, lr=0.001
[2025-05-04 22:48:31,904][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=4.6445, lr=0.001
[2025-05-04 22:48:51,341][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6171, lr=0.001
[2025-05-04 22:49:11,020][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=4.6571, lr=0.001
[2025-05-04 22:49:11,048][meta_train][INFO] - epoch_19 saved !
[2025-05-04 22:49:29,516][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=4.6411, lr=0.001
[2025-05-04 22:49:49,094][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=4.6510, lr=0.001
[2025-05-04 22:50:07,566][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6958, lr=0.001
[2025-05-04 22:50:25,937][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=4.8462, lr=0.001
[2025-05-04 22:50:45,814][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.6117, lr=0.001
[2025-05-04 22:51:06,296][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.6110, lr=0.001
[2025-05-04 22:51:24,496][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=5.0850, lr=0.001
[2025-05-04 22:51:43,729][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6140, lr=0.001
[2025-05-04 22:51:43,756][meta_train][INFO] - epoch_20 saved !
[2025-05-04 22:52:02,113][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=5.0451, lr=0.001
[2025-05-04 22:52:20,757][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=4.7822, lr=0.001
[2025-05-04 22:52:39,816][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=4.6338, lr=0.001
[2025-05-04 22:52:59,763][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.6095, lr=0.001
[2025-05-04 22:53:18,800][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=4.6227, lr=0.001
[2025-05-04 22:53:38,582][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.6093, lr=0.001
[2025-05-04 22:53:57,167][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6570, lr=0.001
[2025-05-04 22:54:16,296][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6118, lr=0.001
[2025-05-04 22:54:16,313][meta_train][INFO] - epoch_21 saved !
[2025-05-04 22:54:35,362][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6110, lr=0.001
[2025-05-04 22:54:54,930][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=4.6294, lr=0.001
[2025-05-04 22:55:13,087][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6534, lr=0.001
[2025-05-04 22:55:33,182][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.6089, lr=0.001
[2025-05-04 22:55:42,889][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-04 22:55:42,939][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 22:55:42,940][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 22:55:42,940][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 22:55:50,703][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-04 22:55:50,754][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 22:55:50,754][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 22:55:50,754][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=10']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 123, in main
    new_model = get_new_model(metanetwork)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 112, in get_new_model
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 4.78 GiB already allocated; 158.06 MiB free; 5.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-04 22:55:54,384][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.6084, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=20']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 123, in main
    new_model = get_new_model(metanetwork)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 112, in get_new_model
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 4.78 GiB already allocated; 158.06 MiB free; 5.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-04 22:56:12,883][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=4.9425, lr=0.001
[2025-05-04 22:56:31,761][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=4.7131, lr=0.001
[2025-05-04 22:56:50,806][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=4.6183, lr=0.001
[2025-05-04 22:56:50,823][meta_train][INFO] - epoch_22 saved !
[2025-05-04 22:57:10,459][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.6084, lr=0.001
[2025-05-04 22:57:29,366][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=4.6232, lr=0.001
[2025-05-04 22:57:48,011][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=4.6169, lr=0.001
[2025-05-04 22:58:07,599][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6093, lr=0.001
[2025-05-04 22:58:27,542][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.6078, lr=0.001
[2025-05-04 22:58:45,844][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=4.6865, lr=0.001
[2025-05-04 22:59:04,648][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6369, lr=0.001
[2025-05-04 22:59:22,628][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=4.8287, lr=0.001
[2025-05-04 22:59:22,646][meta_train][INFO] - epoch_23 saved !
[2025-05-04 22:59:41,044][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6362, lr=0.001
[2025-05-04 23:00:01,161][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.6076, lr=0.001
[2025-05-04 23:00:20,093][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6087, lr=0.001
[2025-05-04 23:00:39,153][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=4.6138, lr=0.001
[2025-05-04 23:00:57,246][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=4.6671, lr=0.001
[2025-05-04 23:01:17,428][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.6079, lr=0.001
[2025-05-04 23:01:35,794][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=4.7925, lr=0.001
[2025-05-04 23:01:54,932][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.6170, lr=0.001
[2025-05-04 23:01:54,953][meta_train][INFO] - epoch_24 saved !
[2025-05-04 23:02:13,188][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6256, lr=0.001
[2025-05-04 23:02:32,500][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=4.6162, lr=0.001
[2025-05-04 23:02:50,881][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=4.7684, lr=0.001
[2025-05-04 23:03:09,332][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=4.6569, lr=0.001
[2025-05-04 23:03:29,727][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.6074, lr=0.001
[2025-05-04 23:03:48,775][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6083, lr=0.001
[2025-05-04 23:04:08,578][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.6077, lr=0.001
[2025-05-04 23:04:27,605][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=4.6111, lr=0.001
[2025-05-04 23:04:27,622][meta_train][INFO] - epoch_25 saved !
[2025-05-04 23:04:47,303][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6075, lr=0.001
[2025-05-04 23:05:06,507][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6080, lr=0.001
[2025-05-04 23:05:24,666][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=4.7542, lr=0.001
[2025-05-04 23:05:43,137][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6207, lr=0.001
[2025-05-04 23:06:01,882][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=4.6440, lr=0.001
[2025-05-04 23:06:20,908][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=4.6128, lr=0.001
[2025-05-04 23:06:39,842][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=4.6101, lr=0.001
[2025-05-04 23:06:59,989][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.6080, lr=0.001
[2025-05-04 23:07:00,005][meta_train][INFO] - epoch_26 saved !
[2025-05-04 23:07:19,972][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.6079, lr=0.001
[2025-05-04 23:07:39,151][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6081, lr=0.001
[2025-05-04 23:07:57,332][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=4.6381, lr=0.001
[2025-05-04 23:08:15,866][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=4.7228, lr=0.001
[2025-05-04 23:08:35,826][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6078, lr=0.001
[2025-05-04 23:08:55,354][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.6115, lr=0.001
[2025-05-04 23:09:14,361][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=4.6097, lr=0.001
[2025-05-04 23:09:32,909][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6168, lr=0.001
[2025-05-04 23:09:32,925][meta_train][INFO] - epoch_27 saved !
[2025-05-04 23:09:52,181][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6081, lr=0.001
[2025-05-04 23:10:11,718][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.6112, lr=0.001
[2025-05-04 23:10:30,300][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=4.7038, lr=0.001
[2025-05-04 23:10:48,916][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=4.6325, lr=0.001
[2025-05-04 23:11:09,234][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.6084, lr=0.001
[2025-05-04 23:11:27,514][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6165, lr=0.001
[2025-05-04 23:11:46,372][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.6092, lr=0.001
[2025-05-04 23:12:05,902][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.6082, lr=0.001
[2025-05-04 23:12:05,918][meta_train][INFO] - epoch_28 saved !
[2025-05-04 23:12:24,482][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=4.6291, lr=0.001
[2025-05-04 23:12:44,252][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.6085, lr=0.001
[2025-05-04 23:13:02,508][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=4.6832, lr=0.001
[2025-05-04 23:13:21,792][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6084, lr=0.001
[2025-05-04 23:13:41,198][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.6107, lr=0.001
[2025-05-04 23:14:01,168][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6085, lr=0.001
[2025-05-04 23:14:19,902][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.6089, lr=0.001
[2025-05-04 23:14:38,350][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6143, lr=0.001
[2025-05-04 23:14:38,366][meta_train][INFO] - epoch_29 saved !
[2025-05-04 23:14:57,995][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6083, lr=0.001
[2025-05-04 23:15:17,633][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.6084, lr=0.001
[2025-05-04 23:15:37,454][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.6107, lr=0.001
[2025-05-04 23:15:55,662][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6137, lr=0.001
[2025-05-04 23:16:14,842][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=4.6089, lr=0.001
[2025-05-04 23:16:32,827][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=4.6754, lr=0.001
[2025-05-04 23:16:52,856][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.6091, lr=0.001
[2025-05-04 23:17:11,560][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=4.6242, lr=0.001
[2025-05-04 23:17:11,595][meta_train][INFO] - epoch_30 saved !
[2025-05-04 23:17:31,971][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.6093, lr=0.001
[2025-05-04 23:17:51,131][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6088, lr=0.001
[2025-05-04 23:18:10,522][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.6110, lr=0.001
[2025-05-04 23:18:29,220][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=4.6089, lr=0.001
[2025-05-04 23:18:47,827][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=4.6231, lr=0.001
[2025-05-04 23:19:07,979][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.6087, lr=0.001
[2025-05-04 23:19:26,166][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6128, lr=0.001
[2025-05-04 23:19:44,832][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=4.6619, lr=0.001
[2025-05-04 23:19:44,849][meta_train][INFO] - epoch_31 saved !
[2025-05-04 23:20:04,970][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.6087, lr=0.001
[2025-05-04 23:20:23,796][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=4.6559, lr=0.001
[2025-05-04 23:20:43,137][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.6112, lr=0.001
[2025-05-04 23:21:01,349][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=4.6204, lr=0.001
[2025-05-04 23:21:21,222][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.6096, lr=0.001
[2025-05-04 23:21:39,768][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6110, lr=0.001
[2025-05-04 23:21:58,185][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.6090, lr=0.001
[2025-05-04 23:22:17,807][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.6092, lr=0.001
[2025-05-04 23:22:17,827][meta_train][INFO] - epoch_32 saved !
[2025-05-04 23:22:37,679][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.6098, lr=0.001
[2025-05-04 23:22:57,274][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.6090, lr=0.001
[2025-05-04 23:23:15,729][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=4.6569, lr=0.001
[2025-05-04 23:23:34,371][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.6086, lr=0.001
[2025-05-04 23:23:53,079][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=4.6191, lr=0.001
[2025-05-04 23:24:12,365][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.6114, lr=0.001
[2025-05-04 23:24:31,077][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6113, lr=0.001
[2025-05-04 23:24:50,867][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6090, lr=0.001
[2025-05-04 23:24:50,883][meta_train][INFO] - epoch_33 saved !
[2025-05-04 23:25:11,030][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.6090, lr=0.001
[2025-05-04 23:25:30,647][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.6112, lr=0.001
[2025-05-04 23:25:49,081][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6112, lr=0.001
[2025-05-04 23:26:08,336][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6090, lr=0.001
[2025-05-04 23:26:26,954][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.6089, lr=0.001
[2025-05-04 23:26:46,808][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.6098, lr=0.001
[2025-05-04 23:27:05,239][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=4.6180, lr=0.001
[2025-05-04 23:27:24,154][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=4.6507, lr=0.001
[2025-05-04 23:27:24,174][meta_train][INFO] - epoch_34 saved !
[2025-05-04 23:27:42,737][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=4.6174, lr=0.001
[2025-05-04 23:28:02,147][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6098, lr=0.001
[2025-05-04 23:28:21,682][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.6118, lr=0.001
[2025-05-04 23:28:39,673][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=4.6483, lr=0.001
[2025-05-04 23:28:58,276][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.6090, lr=0.001
[2025-05-04 23:29:16,508][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6102, lr=0.001
[2025-05-04 23:29:36,818][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6087, lr=0.001
[2025-05-04 23:29:57,065][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.6100, lr=0.001
[2025-05-04 23:29:57,085][meta_train][INFO] - epoch_35 saved !
[2025-05-04 23:30:16,813][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6087, lr=0.001
[2025-05-04 23:30:36,200][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.6112, lr=0.001
[2025-05-04 23:30:54,788][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=4.6163, lr=0.001
[2025-05-04 23:31:14,734][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.6103, lr=0.001
[2025-05-04 23:31:33,172][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6097, lr=0.001
[2025-05-04 23:31:50,814][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=4.6442, lr=0.001
[2025-05-04 23:32:09,982][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.6088, lr=0.001
[2025-05-04 23:32:28,998][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6092, lr=0.001
[2025-05-04 23:32:29,016][meta_train][INFO] - epoch_36 saved !
[2025-05-04 23:32:47,788][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.6087, lr=0.001
[2025-05-04 23:33:07,809][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6085, lr=0.001
[2025-05-04 23:33:26,542][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6099, lr=0.001
[2025-05-04 23:33:45,019][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=4.6157, lr=0.001
[2025-05-04 23:34:03,939][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6094, lr=0.001
[2025-05-04 23:34:22,636][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.6379, lr=0.001
[2025-05-04 23:34:41,991][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.6103, lr=0.001
[2025-05-04 23:35:01,300][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.6110, lr=0.001
[2025-05-04 23:35:01,322][meta_train][INFO] - epoch_37 saved !
[2025-05-04 23:35:21,345][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.6096, lr=0.001
[2025-05-04 23:35:40,224][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6087, lr=0.001
[2025-05-04 23:36:00,543][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6079, lr=0.001
[2025-05-04 23:36:19,115][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.6083, lr=0.001
[2025-05-04 23:36:37,451][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.6384, lr=0.001
[2025-05-04 23:36:55,779][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=4.6143, lr=0.001
[2025-05-04 23:37:15,188][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.6104, lr=0.001
[2025-05-04 23:37:33,868][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6092, lr=0.001
[2025-05-04 23:37:33,895][meta_train][INFO] - epoch_38 saved !
[2025-05-04 23:37:52,479][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.6084, lr=0.001
[2025-05-04 23:38:10,472][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6093, lr=0.001
[2025-05-04 23:38:30,551][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.6093, lr=0.001
[2025-05-04 23:38:49,764][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.6101, lr=0.001
[2025-05-04 23:39:09,042][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6089, lr=0.001
[2025-05-04 23:39:29,183][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6082, lr=0.001
[2025-05-04 23:39:47,814][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=4.6140, lr=0.001
[2025-05-04 23:40:06,611][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=4.6345, lr=0.001
[2025-05-04 23:40:06,631][meta_train][INFO] - epoch_39 saved !
[2025-05-04 23:40:24,900][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6088, lr=0.001
[2025-05-04 23:40:43,393][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=4.6339, lr=0.001
[2025-05-04 23:41:02,303][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=4.6104, lr=0.001
[2025-05-04 23:41:22,383][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.6094, lr=0.001
[2025-05-04 23:41:42,692][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6077, lr=0.001
[2025-05-04 23:42:01,042][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=4.6139, lr=0.001
[2025-05-04 23:42:20,640][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6080, lr=0.001
[2025-05-04 23:42:39,627][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=4.6080, lr=0.001
[2025-05-04 23:42:39,643][meta_train][INFO] - epoch_40 saved !
[2025-05-04 23:42:58,902][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6081, lr=0.001
[2025-05-04 23:43:17,743][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=4.6079, lr=0.001
[2025-05-04 23:43:38,109][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.6087, lr=0.001
[2025-05-04 23:43:39,095][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-04 23:43:39,146][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 23:43:39,146][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 23:43:39,146][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=20']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 123, in main
    new_model = get_new_model(metanetwork)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 112, in get_new_model
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 4.78 GiB already allocated; 158.06 MiB free; 5.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-04 23:43:57,008][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6087, lr=0.001
[2025-05-04 23:44:15,495][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=4.6132, lr=0.001
[2025-05-04 23:44:34,818][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=4.6093, lr=0.001
[2025-05-04 23:44:53,186][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=4.6286, lr=0.001
[2025-05-04 23:45:13,517][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6078, lr=0.001
[2025-05-04 23:45:13,533][meta_train][INFO] - epoch_41 saved !
[2025-05-04 23:45:32,818][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.6097, lr=0.001
[2025-05-04 23:45:46,813][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-04 23:45:46,884][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 23:45:46,884][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 23:45:46,885][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 23:45:51,547][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=4.6293, lr=0.001
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=20']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 123, in main
    new_model = get_new_model(metanetwork)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 112, in get_new_model
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 4.78 GiB already allocated; 158.06 MiB free; 5.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-04 23:46:12,014][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.6089, lr=0.001
[2025-05-04 23:46:29,492][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-04 23:46:29,542][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 23:46:29,542][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 23:46:29,542][get_dataset_model_loader][INFO] - ==================================================
[2025-05-04 23:46:31,257][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6079, lr=0.001
[2025-05-04 23:46:38,222][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-04 23:46:38,272][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-04 23:46:38,273][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-04 23:46:38,273][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 23:46:43,712][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-04 23:46:50,237][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=4.6078, lr=0.001
[2025-05-04 23:46:52,252][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6116, lr=0.0100
[2025-05-04 23:46:52,636][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-04 23:47:00,405][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6111, lr=0.0100
[2025-05-04 23:47:00,949][train][INFO] - Epoch 1/100, Val Acc=0.0507, Val Loss=4.1364, lr=0.0100
[2025-05-04 23:47:08,738][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6097, lr=0.0100
[2025-05-04 23:47:09,001][train][INFO] - Epoch 2/100, Val Acc=0.1210, Val Loss=3.4927, lr=0.0100
[2025-05-04 23:47:11,222][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6067, lr=0.001
[2025-05-04 23:47:16,534][train][INFO] - Epoch 3/100, Val Acc=0.2169, Val Loss=2.9763, lr=0.0100
[2025-05-04 23:47:17,016][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6097, lr=0.0100
[2025-05-04 23:47:23,707][train][INFO] - Epoch 4/100, Val Acc=0.2680, Val Loss=2.7280, lr=0.0100
[2025-05-04 23:47:24,709][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6097, lr=0.0100
[2025-05-04 23:47:30,450][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=4.6120, lr=0.001
[2025-05-04 23:47:31,167][train][INFO] - Epoch 5/100, Val Acc=0.3002, Val Loss=2.6599, lr=0.0100
[2025-05-04 23:47:32,017][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6102, lr=0.0100
[2025-05-04 23:47:38,448][train][INFO] - Epoch 6/100, Val Acc=0.3081, Val Loss=2.6049, lr=0.0100
[2025-05-04 23:47:40,172][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6084, lr=0.0100
[2025-05-04 23:47:45,836][train][INFO] - Epoch 7/100, Val Acc=0.3699, Val Loss=2.3543, lr=0.0100
[2025-05-04 23:47:48,549][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6081, lr=0.0100
[2025-05-04 23:47:49,679][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6086, lr=0.001
[2025-05-04 23:47:49,700][meta_train][INFO] - epoch_42 saved !
[2025-05-04 23:47:53,134][train][INFO] - Epoch 8/100, Val Acc=0.3786, Val Loss=2.3744, lr=0.0100
[2025-05-04 23:47:56,225][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6081, lr=0.0100
[2025-05-04 23:48:00,894][train][INFO] - Epoch 9/100, Val Acc=0.3725, Val Loss=2.4264, lr=0.0100
[2025-05-04 23:48:04,075][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6075, lr=0.0100
[2025-05-04 23:48:08,507][train][INFO] - Epoch 10/100, Val Acc=0.4182, Val Loss=2.2069, lr=0.0100
[2025-05-04 23:48:08,930][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=4.6241, lr=0.001
[2025-05-04 23:48:12,084][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6076, lr=0.0100
[2025-05-04 23:48:16,313][train][INFO] - Epoch 11/100, Val Acc=0.4343, Val Loss=2.1613, lr=0.0100
[2025-05-04 23:48:19,473][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6075, lr=0.0100
[2025-05-04 23:48:23,805][train][INFO] - Epoch 12/100, Val Acc=0.4416, Val Loss=2.1435, lr=0.0100
[2025-05-04 23:48:27,542][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-04 23:48:28,101][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=4.6123, lr=0.001
[2025-05-04 23:48:31,521][train][INFO] - Epoch 13/100, Val Acc=0.3635, Val Loss=2.6280, lr=0.0100
[2025-05-04 23:48:35,722][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-04 23:48:39,111][train][INFO] - Epoch 14/100, Val Acc=0.4740, Val Loss=1.9634, lr=0.0100
[2025-05-04 23:48:43,309][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6072, lr=0.0100
[2025-05-04 23:48:47,060][train][INFO] - Epoch 15/100, Val Acc=0.4812, Val Loss=1.9435, lr=0.0100
[2025-05-04 23:48:49,017][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6082, lr=0.001
[2025-05-04 23:48:51,385][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6069, lr=0.0100
[2025-05-04 23:48:54,859][train][INFO] - Epoch 16/100, Val Acc=0.4695, Val Loss=2.0360, lr=0.0100
[2025-05-04 23:48:59,552][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6063, lr=0.0100
[2025-05-04 23:49:02,637][train][INFO] - Epoch 17/100, Val Acc=0.4816, Val Loss=1.9592, lr=0.0100
[2025-05-04 23:49:06,692][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6064, lr=0.0100
[2025-05-04 23:49:08,357][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=4.6090, lr=0.001
[2025-05-04 23:49:10,728][train][INFO] - Epoch 18/100, Val Acc=0.4992, Val Loss=1.8495, lr=0.0100
[2025-05-04 23:49:14,933][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6062, lr=0.0100
[2025-05-04 23:49:18,505][train][INFO] - Epoch 19/100, Val Acc=0.5079, Val Loss=1.8317, lr=0.0100
[2025-05-04 23:49:21,938][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-04 23:49:26,238][train][INFO] - Epoch 20/100, Val Acc=0.4726, Val Loss=2.1047, lr=0.0100
[2025-05-04 23:49:27,665][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6086, lr=0.001
[2025-05-04 23:49:29,714][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-04 23:49:33,898][train][INFO] - Epoch 21/100, Val Acc=0.5005, Val Loss=1.9019, lr=0.0100
[2025-05-04 23:49:36,838][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-04 23:49:41,489][train][INFO] - Epoch 22/100, Val Acc=0.5098, Val Loss=1.8570, lr=0.0100
[2025-05-04 23:49:44,935][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6059, lr=0.0100
[2025-05-04 23:49:48,507][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.6097, lr=0.001
[2025-05-04 23:49:48,743][train][INFO] - Epoch 23/100, Val Acc=0.5235, Val Loss=1.7831, lr=0.0100
[2025-05-04 23:49:53,256][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6057, lr=0.0100
[2025-05-04 23:49:56,561][train][INFO] - Epoch 24/100, Val Acc=0.5351, Val Loss=1.7133, lr=0.0100
[2025-05-04 23:50:01,034][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-04 23:50:04,067][train][INFO] - Epoch 25/100, Val Acc=0.5471, Val Loss=1.6765, lr=0.0100
[2025-05-04 23:50:09,066][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6088, lr=0.001
[2025-05-04 23:50:09,449][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-04 23:50:11,562][train][INFO] - Epoch 26/100, Val Acc=0.5006, Val Loss=1.9996, lr=0.0100
[2025-05-04 23:50:17,449][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-04 23:50:19,210][train][INFO] - Epoch 27/100, Val Acc=0.5511, Val Loss=1.6824, lr=0.0100
[2025-05-04 23:50:24,451][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-04 23:50:26,967][train][INFO] - Epoch 28/100, Val Acc=0.5340, Val Loss=1.8226, lr=0.0100
[2025-05-04 23:50:28,839][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.6090, lr=0.001
[2025-05-04 23:50:28,871][meta_train][INFO] - epoch_43 saved !
[2025-05-04 23:50:32,417][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-04 23:50:34,922][train][INFO] - Epoch 29/100, Val Acc=0.5502, Val Loss=1.7443, lr=0.0100
[2025-05-04 23:50:40,456][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-04 23:50:43,159][train][INFO] - Epoch 30/100, Val Acc=0.5522, Val Loss=1.7138, lr=0.0100
[2025-05-04 23:50:47,986][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-04 23:50:50,044][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6066, lr=0.001
[2025-05-04 23:50:51,021][train][INFO] - Epoch 31/100, Val Acc=0.5565, Val Loss=1.7170, lr=0.0100
[2025-05-04 23:50:56,185][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:50:58,882][train][INFO] - Epoch 32/100, Val Acc=0.5676, Val Loss=1.6490, lr=0.0100
[2025-05-04 23:51:04,318][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:06,566][train][INFO] - Epoch 33/100, Val Acc=0.5583, Val Loss=1.7074, lr=0.0100
[2025-05-04 23:51:09,695][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=4.6073, lr=0.001
[2025-05-04 23:51:12,191][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:14,559][train][INFO] - Epoch 34/100, Val Acc=0.5557, Val Loss=1.6988, lr=0.0100
[2025-05-04 23:51:20,603][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:22,060][train][INFO] - Epoch 35/100, Val Acc=0.5401, Val Loss=1.7872, lr=0.0100
[2025-05-04 23:51:27,745][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:29,780][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6071, lr=0.001
[2025-05-04 23:51:29,909][train][INFO] - Epoch 36/100, Val Acc=0.5683, Val Loss=1.6626, lr=0.0100
[2025-05-04 23:51:36,025][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:37,499][train][INFO] - Epoch 37/100, Val Acc=0.5694, Val Loss=1.6607, lr=0.0100
[2025-05-04 23:51:44,313][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:45,279][train][INFO] - Epoch 38/100, Val Acc=0.5759, Val Loss=1.6207, lr=0.0100
[2025-05-04 23:51:50,131][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=4.6082, lr=0.001
[2025-05-04 23:51:52,587][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-04 23:51:52,792][train][INFO] - Epoch 39/100, Val Acc=0.5464, Val Loss=1.7809, lr=0.0100
[2025-05-04 23:52:00,412][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:00,663][train][INFO] - Epoch 40/100, Val Acc=0.5477, Val Loss=1.8036, lr=0.0100
[2025-05-04 23:52:08,553][train][INFO] - Epoch 41/100, Val Acc=0.5719, Val Loss=1.6940, lr=0.0100
[2025-05-04 23:52:08,795][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:09,380][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=4.6110, lr=0.001
[2025-05-04 23:52:16,544][train][INFO] - Epoch 42/100, Val Acc=0.5494, Val Loss=1.7877, lr=0.0100
[2025-05-04 23:52:17,035][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:24,490][train][INFO] - Epoch 43/100, Val Acc=0.5644, Val Loss=1.7265, lr=0.0100
[2025-05-04 23:52:25,263][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:29,789][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.6095, lr=0.001
[2025-05-04 23:52:32,580][train][INFO] - Epoch 44/100, Val Acc=0.5789, Val Loss=1.6479, lr=0.0100
[2025-05-04 23:52:33,512][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:39,822][train][INFO] - Epoch 45/100, Val Acc=0.5754, Val Loss=1.6757, lr=0.0100
[2025-05-04 23:52:41,202][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:47,597][train][INFO] - Epoch 46/100, Val Acc=0.5493, Val Loss=1.8522, lr=0.0100
[2025-05-04 23:52:49,226][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6083, lr=0.001
[2025-05-04 23:52:49,310][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:52:55,595][train][INFO] - Epoch 47/100, Val Acc=0.5714, Val Loss=1.7267, lr=0.0100
[2025-05-04 23:52:57,386][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:02,787][train][INFO] - Epoch 48/100, Val Acc=0.5629, Val Loss=1.7249, lr=0.0100
[2025-05-04 23:53:05,707][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:08,313][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=4.6260, lr=0.001
[2025-05-04 23:53:08,336][meta_train][INFO] - epoch_44 saved !
[2025-05-04 23:53:10,848][train][INFO] - Epoch 49/100, Val Acc=0.5767, Val Loss=1.7205, lr=0.0100
[2025-05-04 23:53:14,113][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:18,669][train][INFO] - Epoch 50/100, Val Acc=0.5872, Val Loss=1.6458, lr=0.0100
[2025-05-04 23:53:22,015][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:26,422][train][INFO] - Epoch 51/100, Val Acc=0.5699, Val Loss=1.7161, lr=0.0100
[2025-05-04 23:53:27,988][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=4.6085, lr=0.001
[2025-05-04 23:53:29,846][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:34,472][train][INFO] - Epoch 52/100, Val Acc=0.5923, Val Loss=1.6737, lr=0.0100
[2025-05-04 23:53:37,485][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:42,641][train][INFO] - Epoch 53/100, Val Acc=0.5565, Val Loss=1.8423, lr=0.0100
[2025-05-04 23:53:45,356][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:47,153][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=4.6262, lr=0.001
[2025-05-04 23:53:50,868][train][INFO] - Epoch 54/100, Val Acc=0.5745, Val Loss=1.6870, lr=0.0100
[2025-05-04 23:53:53,517][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:53:58,713][train][INFO] - Epoch 55/100, Val Acc=0.5809, Val Loss=1.7002, lr=0.0100
[2025-05-04 23:54:00,977][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:06,377][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6084, lr=0.001
[2025-05-04 23:54:06,612][train][INFO] - Epoch 56/100, Val Acc=0.5752, Val Loss=1.6953, lr=0.0100
[2025-05-04 23:54:09,049][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:14,396][train][INFO] - Epoch 57/100, Val Acc=0.5712, Val Loss=1.7913, lr=0.0100
[2025-05-04 23:54:17,173][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:22,378][train][INFO] - Epoch 58/100, Val Acc=0.5546, Val Loss=1.8606, lr=0.0100
[2025-05-04 23:54:25,194][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:25,826][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=4.6116, lr=0.001
[2025-05-04 23:54:30,316][train][INFO] - Epoch 59/100, Val Acc=0.5601, Val Loss=1.7738, lr=0.0100
[2025-05-04 23:54:33,004][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:37,948][train][INFO] - Epoch 60/100, Val Acc=0.5782, Val Loss=1.7340, lr=0.0100
[2025-05-04 23:54:41,046][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-04 23:54:46,138][train][INFO] - Epoch 61/100, Val Acc=0.6521, Val Loss=1.3906, lr=0.0010
[2025-05-04 23:54:46,876][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6085, lr=0.001
[2025-05-04 23:54:49,310][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:54:53,740][train][INFO] - Epoch 62/100, Val Acc=0.6534, Val Loss=1.3758, lr=0.0010
[2025-05-04 23:54:57,332][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:01,353][train][INFO] - Epoch 63/100, Val Acc=0.6609, Val Loss=1.3797, lr=0.0010
[2025-05-04 23:55:04,692][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:07,027][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.6099, lr=0.001
[2025-05-04 23:55:09,026][train][INFO] - Epoch 64/100, Val Acc=0.6586, Val Loss=1.3918, lr=0.0010
[2025-05-04 23:55:12,882][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:16,714][train][INFO] - Epoch 65/100, Val Acc=0.6586, Val Loss=1.4060, lr=0.0010
[2025-05-04 23:55:20,456][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:24,476][train][INFO] - Epoch 66/100, Val Acc=0.6596, Val Loss=1.3966, lr=0.0010
[2025-05-04 23:55:27,051][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6082, lr=0.001
[2025-05-04 23:55:29,030][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:31,654][train][INFO] - Epoch 67/100, Val Acc=0.6595, Val Loss=1.4124, lr=0.0010
[2025-05-04 23:55:37,005][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:39,414][train][INFO] - Epoch 68/100, Val Acc=0.6569, Val Loss=1.4206, lr=0.0010
[2025-05-04 23:55:44,680][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:47,507][train][INFO] - Epoch 69/100, Val Acc=0.6602, Val Loss=1.4195, lr=0.0010
[2025-05-04 23:55:47,940][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6075, lr=0.001
[2025-05-04 23:55:47,972][meta_train][INFO] - epoch_45 saved !
[2025-05-04 23:55:52,310][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:55:54,946][train][INFO] - Epoch 70/100, Val Acc=0.6590, Val Loss=1.4297, lr=0.0010
[2025-05-04 23:56:00,345][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:02,801][train][INFO] - Epoch 71/100, Val Acc=0.6596, Val Loss=1.4375, lr=0.0010
[2025-05-04 23:56:07,477][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=4.6111, lr=0.001
[2025-05-04 23:56:08,298][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:10,656][train][INFO] - Epoch 72/100, Val Acc=0.6566, Val Loss=1.4517, lr=0.0010
[2025-05-04 23:56:16,381][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:18,417][train][INFO] - Epoch 73/100, Val Acc=0.6612, Val Loss=1.4466, lr=0.0010
[2025-05-04 23:56:24,608][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:25,733][train][INFO] - Epoch 74/100, Val Acc=0.6566, Val Loss=1.4674, lr=0.0010
[2025-05-04 23:56:27,494][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-04 23:56:32,465][train][INFO] - Epoch 75/100, Val Acc=0.6577, Val Loss=1.4611, lr=0.0010
[2025-05-04 23:56:32,836][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:39,345][train][INFO] - Epoch 76/100, Val Acc=0.6645, Val Loss=1.4557, lr=0.0010
[2025-05-04 23:56:40,749][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:46,767][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6081, lr=0.001
[2025-05-04 23:56:47,092][train][INFO] - Epoch 77/100, Val Acc=0.6602, Val Loss=1.4787, lr=0.0010
[2025-05-04 23:56:48,876][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:56:55,090][train][INFO] - Epoch 78/100, Val Acc=0.6591, Val Loss=1.4854, lr=0.0010
[2025-05-04 23:56:57,112][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:02,619][train][INFO] - Epoch 79/100, Val Acc=0.6569, Val Loss=1.5005, lr=0.0010
[2025-05-04 23:57:05,118][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:06,468][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=4.6089, lr=0.001
[2025-05-04 23:57:10,311][train][INFO] - Epoch 80/100, Val Acc=0.6603, Val Loss=1.4985, lr=0.0010
[2025-05-04 23:57:13,292][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:17,963][train][INFO] - Epoch 81/100, Val Acc=0.6578, Val Loss=1.5041, lr=0.0010
[2025-05-04 23:57:21,500][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:25,110][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=4.6192, lr=0.001
[2025-05-04 23:57:26,019][train][INFO] - Epoch 82/100, Val Acc=0.6599, Val Loss=1.5115, lr=0.0010
[2025-05-04 23:57:29,543][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:33,847][train][INFO] - Epoch 83/100, Val Acc=0.6621, Val Loss=1.5035, lr=0.0010
[2025-05-04 23:57:37,804][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:42,172][train][INFO] - Epoch 84/100, Val Acc=0.6550, Val Loss=1.5255, lr=0.0010
[2025-05-04 23:57:45,891][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:46,406][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6103, lr=0.001
[2025-05-04 23:57:50,161][train][INFO] - Epoch 85/100, Val Acc=0.6565, Val Loss=1.5162, lr=0.0010
[2025-05-04 23:57:53,402][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:57:58,310][train][INFO] - Epoch 86/100, Val Acc=0.6601, Val Loss=1.5308, lr=0.0010
[2025-05-04 23:58:01,837][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:05,651][train][INFO] - Epoch 87/100, Val Acc=0.6574, Val Loss=1.5341, lr=0.0010
[2025-05-04 23:58:07,151][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6080, lr=0.001
[2025-05-04 23:58:10,027][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:13,371][train][INFO] - Epoch 88/100, Val Acc=0.6541, Val Loss=1.5514, lr=0.0010
[2025-05-04 23:58:18,301][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:21,073][train][INFO] - Epoch 89/100, Val Acc=0.6547, Val Loss=1.5561, lr=0.0010
[2025-05-04 23:58:25,706][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:27,571][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6085, lr=0.001
[2025-05-04 23:58:27,601][meta_train][INFO] - epoch_46 saved !
[2025-05-04 23:58:28,460][train][INFO] - Epoch 90/100, Val Acc=0.6565, Val Loss=1.5643, lr=0.0010
[2025-05-04 23:58:33,964][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:36,522][train][INFO] - Epoch 91/100, Val Acc=0.6584, Val Loss=1.5479, lr=0.0001
[2025-05-04 23:58:41,948][train][INFO] - Epoch 90/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-04 23:58:44,686][train][INFO] - Epoch 92/100, Val Acc=0.6598, Val Loss=1.5492, lr=0.0001
[2025-05-04 23:58:47,812][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.6082, lr=0.001
[2025-05-04 23:58:50,025][train][INFO] - Epoch 91/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:58:52,316][train][INFO] - Epoch 93/100, Val Acc=0.6597, Val Loss=1.5434, lr=0.0001
[2025-05-04 23:58:57,743][train][INFO] - Epoch 92/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:00,132][train][INFO] - Epoch 94/100, Val Acc=0.6586, Val Loss=1.5433, lr=0.0001
[2025-05-04 23:59:05,841][train][INFO] - Epoch 93/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:06,760][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=4.6111, lr=0.001
[2025-05-04 23:59:08,454][train][INFO] - Epoch 95/100, Val Acc=0.6584, Val Loss=1.5426, lr=0.0001
[2025-05-04 23:59:14,173][train][INFO] - Epoch 94/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:16,667][train][INFO] - Epoch 96/100, Val Acc=0.6608, Val Loss=1.5419, lr=0.0001
[2025-05-04 23:59:22,513][train][INFO] - Epoch 95/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:24,728][train][INFO] - Epoch 97/100, Val Acc=0.6582, Val Loss=1.5531, lr=0.0001
[2025-05-04 23:59:26,067][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6082, lr=0.001
[2025-05-04 23:59:30,633][train][INFO] - Epoch 96/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:32,891][train][INFO] - Epoch 98/100, Val Acc=0.6600, Val Loss=1.5399, lr=0.0001
[2025-05-04 23:59:38,808][train][INFO] - Epoch 97/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:40,356][train][INFO] - Epoch 99/100, Val Acc=0.6568, Val Loss=1.5565, lr=0.0001
[2025-05-04 23:59:46,615][train][INFO] - Epoch 98/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-04 23:59:46,998][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6066, lr=0.001
[2025-05-04 23:59:48,208][train][INFO] - Epoch 100/100, Val Acc=0.6596, Val Loss=1.5441, lr=0.0001
[2025-05-04 23:59:53,226][train][INFO] - After training : Train Acc=0.9209  Val Acc=0.6645
[2025-05-04 23:59:53,233][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-04 23:59:54,071][train][INFO] - Epoch 99/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-05 00:00:01,990][train][INFO] - Epoch 100/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0001
[2025-05-05 00:00:07,346][train][INFO] - After training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 00:00:07,351][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 00:00:08,325][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6079, lr=0.001
[2025-05-05 00:00:27,899][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=4.6080, lr=0.001
[2025-05-05 00:00:48,432][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.6082, lr=0.001
[2025-05-05 00:01:08,304][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=4.6185, lr=0.001
[2025-05-05 00:01:08,333][meta_train][INFO] - epoch_47 saved !
[2025-05-05 00:01:28,474][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.6085, lr=0.001
[2025-05-05 00:01:33,720][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 00:01:49,740][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6083, lr=0.001
[2025-05-05 00:01:51,582][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 00:02:09,163][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=4.6209, lr=0.001
[2025-05-05 00:02:29,611][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.6075, lr=0.001
[2025-05-05 00:02:49,507][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=4.6106, lr=0.001
[2025-05-05 00:03:08,714][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6082, lr=0.001
[2025-05-05 00:03:21,977][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 00:03:22,150][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 00:03:22,480][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 00:03:22,608][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 00:03:29,680][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6070, lr=0.001
[2025-05-05 00:03:48,771][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.6085, lr=0.001
[2025-05-05 00:03:48,787][meta_train][INFO] - epoch_48 saved !
[2025-05-05 00:04:07,655][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.6087, lr=0.001
[2025-05-05 00:04:27,148][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6073, lr=0.001
[2025-05-05 00:04:46,346][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.6080, lr=0.001
[2025-05-05 00:05:06,310][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6080, lr=0.001
[2025-05-05 00:05:25,044][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6081, lr=0.001
[2025-05-05 00:05:44,565][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.6074, lr=0.001
[2025-05-05 00:06:02,932][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=4.6100, lr=0.001
[2025-05-05 00:06:21,157][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=4.6186, lr=0.001
[2025-05-05 00:06:21,174][meta_train][INFO] - epoch_49 saved !
[2025-05-05 00:06:39,830][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6082, lr=0.001
[2025-05-05 00:07:00,420][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6074, lr=0.001
[2025-05-05 00:07:19,053][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.6084, lr=0.001
[2025-05-05 00:07:37,902][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.6192, lr=0.001
[2025-05-05 00:07:57,302][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.6078, lr=0.001
[2025-05-05 00:08:15,960][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=4.6098, lr=0.001
[2025-05-05 00:08:35,114][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.6076, lr=0.001
[2025-05-05 00:08:54,978][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6075, lr=0.001
[2025-05-05 00:08:55,007][meta_train][INFO] - epoch_50 saved !
[2025-05-05 00:09:14,825][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6084, lr=0.001
[2025-05-05 00:09:32,890][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6086, lr=0.001
[2025-05-05 00:09:51,396][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.6098, lr=0.001
[2025-05-05 00:10:10,189][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=4.6171, lr=0.001
[2025-05-05 00:10:29,367][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.6084, lr=0.001
[2025-05-05 00:10:48,411][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.6079, lr=0.001
[2025-05-05 00:11:08,352][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6066, lr=0.001
[2025-05-05 00:11:27,110][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=4.6096, lr=0.001
[2025-05-05 00:11:27,126][meta_train][INFO] - epoch_51 saved !
[2025-05-05 00:11:46,934][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6073, lr=0.001
[2025-05-05 00:12:05,930][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.6077, lr=0.001
[2025-05-05 00:12:25,125][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.6080, lr=0.001
[2025-05-05 00:12:43,901][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.6089, lr=0.001
[2025-05-05 00:13:02,113][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.6158, lr=0.001
[2025-05-05 00:13:20,541][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=4.6093, lr=0.001
[2025-05-05 00:13:40,666][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6072, lr=0.001
[2025-05-05 00:13:59,083][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6080, lr=0.001
[2025-05-05 00:13:59,100][meta_train][INFO] - epoch_52 saved !
[2025-05-05 00:14:17,525][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6081, lr=0.001
[2025-05-05 00:14:35,759][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.6171, lr=0.001
[2025-05-05 00:14:55,853][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6073, lr=0.001
[2025-05-05 00:15:15,137][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.6080, lr=0.001
[2025-05-05 00:15:34,752][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6080, lr=0.001
[2025-05-05 00:15:53,926][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.6079, lr=0.001
[2025-05-05 00:16:13,181][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.6072, lr=0.001
[2025-05-05 00:16:31,356][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=4.6089, lr=0.001
[2025-05-05 00:16:31,372][meta_train][INFO] - epoch_53 saved !
[2025-05-05 00:16:51,543][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6070, lr=0.001
[2025-05-05 00:17:09,572][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6085, lr=0.001
[2025-05-05 00:17:29,390][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6092, lr=0.001
[2025-05-05 00:17:47,864][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=4.6092, lr=0.001
[2025-05-05 00:18:06,725][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.6089, lr=0.001
[2025-05-05 00:18:25,819][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.6076, lr=0.001
[2025-05-05 00:18:45,279][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.6072, lr=0.001
[2025-05-05 00:19:02,988][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.6168, lr=0.001
[2025-05-05 00:19:03,004][meta_train][INFO] - epoch_54 saved !
[2025-05-05 00:19:21,111][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.6157, lr=0.001
[2025-05-05 00:19:41,161][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-05 00:19:59,907][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6084, lr=0.001
[2025-05-05 00:20:18,204][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=4.6089, lr=0.001
[2025-05-05 00:20:37,527][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.6091, lr=0.001
[2025-05-05 00:20:56,318][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.6096, lr=0.001
[2025-05-05 00:21:16,766][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6073, lr=0.001
[2025-05-05 00:21:35,608][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.6072, lr=0.001
[2025-05-05 00:21:35,630][meta_train][INFO] - epoch_55 saved !
[2025-05-05 00:21:55,361][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.6069, lr=0.001
[2025-05-05 00:22:15,456][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6064, lr=0.001
[2025-05-05 00:22:34,059][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.6081, lr=0.001
[2025-05-05 00:22:54,313][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6088, lr=0.001
[2025-05-05 00:23:12,269][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6089, lr=0.001
[2025-05-05 00:23:31,917][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.6088, lr=0.001
[2025-05-05 00:23:50,373][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.6143, lr=0.001
[2025-05-05 00:24:08,321][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=4.6091, lr=0.001
[2025-05-05 00:24:08,337][meta_train][INFO] - epoch_56 saved !
[2025-05-05 00:24:28,342][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6078, lr=0.001
[2025-05-05 00:24:35,607][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 5

[2025-05-05 00:24:35,657][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:24:35,657][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:24:35,657][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:24:45,250][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '100'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 7

[2025-05-05 00:24:45,318][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:24:45,318][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:24:45,318][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 00:24:47,973][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.6072, lr=0.001
[2025-05-05 00:24:49,328][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:24:57,291][train][INFO] - Epoch 1/100, Val Acc=0.5941, Val Loss=1.7772, lr=0.0100
[2025-05-05 00:24:59,623][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 00:25:05,784][train][INFO] - Epoch 2/100, Val Acc=0.6139, Val Loss=1.6790, lr=0.0100
[2025-05-05 00:25:08,189][train][INFO] - Epoch 1/100, Val Acc=0.4988, Val Loss=2.0276, lr=0.0100
[2025-05-05 00:25:13,957][train][INFO] - Epoch 3/100, Val Acc=0.6050, Val Loss=1.7317, lr=0.0100
[2025-05-05 00:25:16,270][train][INFO] - Epoch 2/100, Val Acc=0.5670, Val Loss=1.6989, lr=0.0100
[2025-05-05 00:25:22,226][train][INFO] - Epoch 4/100, Val Acc=0.6305, Val Loss=1.6416, lr=0.0100
[2025-05-05 00:25:24,171][train][INFO] - Epoch 3/100, Val Acc=0.5868, Val Loss=1.6777, lr=0.0100
[2025-05-05 00:25:30,727][train][INFO] - Epoch 5/100, Val Acc=0.6264, Val Loss=1.6774, lr=0.0100
[2025-05-05 00:25:32,101][train][INFO] - Epoch 4/100, Val Acc=0.6204, Val Loss=1.5244, lr=0.0100
[2025-05-05 00:25:39,317][train][INFO] - Epoch 6/100, Val Acc=0.6375, Val Loss=1.6003, lr=0.0100
[2025-05-05 00:25:40,403][train][INFO] - Epoch 5/100, Val Acc=0.6158, Val Loss=1.6094, lr=0.0100
[2025-05-05 00:25:47,417][train][INFO] - Epoch 7/100, Val Acc=0.6418, Val Loss=1.6029, lr=0.0100
[2025-05-05 00:25:48,829][train][INFO] - Epoch 6/100, Val Acc=0.6150, Val Loss=1.5842, lr=0.0100
[2025-05-05 00:25:56,047][train][INFO] - Epoch 8/100, Val Acc=0.6547, Val Loss=1.5696, lr=0.0100
[2025-05-05 00:25:56,892][train][INFO] - Epoch 7/100, Val Acc=0.6415, Val Loss=1.4936, lr=0.0100
[2025-05-05 00:26:04,329][train][INFO] - Epoch 9/100, Val Acc=0.6462, Val Loss=1.5665, lr=0.0100
[2025-05-05 00:26:05,487][train][INFO] - Epoch 8/100, Val Acc=0.6310, Val Loss=1.5655, lr=0.0100
[2025-05-05 00:26:12,547][train][INFO] - Epoch 10/100, Val Acc=0.6366, Val Loss=1.6677, lr=0.0100
[2025-05-05 00:26:13,167][train][INFO] - Epoch 9/100, Val Acc=0.6369, Val Loss=1.5389, lr=0.0100
[2025-05-05 00:26:21,070][train][INFO] - Epoch 11/100, Val Acc=0.6394, Val Loss=1.6473, lr=0.0100
[2025-05-05 00:26:21,598][train][INFO] - Epoch 10/100, Val Acc=0.6178, Val Loss=1.6629, lr=0.0100
[2025-05-05 00:26:28,293][train][INFO] - Epoch 12/100, Val Acc=0.6411, Val Loss=1.6338, lr=0.0100
[2025-05-05 00:26:29,634][train][INFO] - Epoch 11/100, Val Acc=0.6564, Val Loss=1.4655, lr=0.0100
[2025-05-05 00:26:36,361][train][INFO] - Epoch 13/100, Val Acc=0.6417, Val Loss=1.6314, lr=0.0100
[2025-05-05 00:26:37,587][train][INFO] - Epoch 12/100, Val Acc=0.6408, Val Loss=1.5154, lr=0.0100
[2025-05-05 00:26:44,240][train][INFO] - Epoch 14/100, Val Acc=0.6477, Val Loss=1.6170, lr=0.0100
[2025-05-05 00:26:45,694][train][INFO] - Epoch 13/100, Val Acc=0.6377, Val Loss=1.5714, lr=0.0100
[2025-05-05 00:26:52,366][train][INFO] - Epoch 15/100, Val Acc=0.6428, Val Loss=1.6436, lr=0.0100
[2025-05-05 00:26:53,670][train][INFO] - Epoch 14/100, Val Acc=0.6263, Val Loss=1.6614, lr=0.0100
[2025-05-05 00:27:00,548][train][INFO] - Epoch 16/100, Val Acc=0.6402, Val Loss=1.6253, lr=0.0100
[2025-05-05 00:27:01,927][train][INFO] - Epoch 15/100, Val Acc=0.6432, Val Loss=1.5492, lr=0.0100
[2025-05-05 00:27:09,036][train][INFO] - Epoch 17/100, Val Acc=0.6468, Val Loss=1.6012, lr=0.0100
[2025-05-05 00:27:10,160][train][INFO] - Epoch 16/100, Val Acc=0.6477, Val Loss=1.4970, lr=0.0100
[2025-05-05 00:27:17,270][train][INFO] - Epoch 18/100, Val Acc=0.6488, Val Loss=1.6612, lr=0.0100
[2025-05-05 00:27:18,533][train][INFO] - Epoch 17/100, Val Acc=0.6545, Val Loss=1.4623, lr=0.0100
[2025-05-05 00:27:25,833][train][INFO] - Epoch 19/100, Val Acc=0.6536, Val Loss=1.6175, lr=0.0100
[2025-05-05 00:27:26,613][train][INFO] - Epoch 18/100, Val Acc=0.6559, Val Loss=1.5266, lr=0.0100
[2025-05-05 00:27:34,191][train][INFO] - Epoch 20/100, Val Acc=0.6536, Val Loss=1.5763, lr=0.0100
[2025-05-05 00:27:34,320][train][INFO] - Epoch 19/100, Val Acc=0.6572, Val Loss=1.4789, lr=0.0100
[2025-05-05 00:27:42,017][train][INFO] - Epoch 21/100, Val Acc=0.6511, Val Loss=1.6322, lr=0.0100
[2025-05-05 00:27:42,107][train][INFO] - Epoch 20/100, Val Acc=0.6465, Val Loss=1.5655, lr=0.0100
[2025-05-05 00:27:50,168][train][INFO] - Epoch 21/100, Val Acc=0.6492, Val Loss=1.5961, lr=0.0100
[2025-05-05 00:27:50,357][train][INFO] - Epoch 22/100, Val Acc=0.6587, Val Loss=1.5629, lr=0.0100
[2025-05-05 00:27:57,472][train][INFO] - Epoch 22/100, Val Acc=0.6270, Val Loss=1.6893, lr=0.0100
[2025-05-05 00:27:57,886][train][INFO] - Epoch 23/100, Val Acc=0.6560, Val Loss=1.6047, lr=0.0100
[2025-05-05 00:28:04,932][train][INFO] - Epoch 23/100, Val Acc=0.6542, Val Loss=1.5464, lr=0.0100
[2025-05-05 00:28:05,889][train][INFO] - Epoch 24/100, Val Acc=0.6432, Val Loss=1.7172, lr=0.0100
[2025-05-05 00:28:12,907][train][INFO] - Epoch 24/100, Val Acc=0.6462, Val Loss=1.6364, lr=0.0100
[2025-05-05 00:28:13,861][train][INFO] - Epoch 25/100, Val Acc=0.6427, Val Loss=1.6589, lr=0.0100
[2025-05-05 00:28:21,185][train][INFO] - Epoch 25/100, Val Acc=0.6468, Val Loss=1.5913, lr=0.0100
[2025-05-05 00:28:22,116][train][INFO] - Epoch 26/100, Val Acc=0.6390, Val Loss=1.7667, lr=0.0100
[2025-05-05 00:28:29,591][train][INFO] - Epoch 26/100, Val Acc=0.6496, Val Loss=1.6139, lr=0.0100
[2025-05-05 00:28:29,669][train][INFO] - Epoch 27/100, Val Acc=0.6450, Val Loss=1.6357, lr=0.0100
[2025-05-05 00:28:37,636][train][INFO] - Epoch 27/100, Val Acc=0.6597, Val Loss=1.5286, lr=0.0100
[2025-05-05 00:28:38,083][train][INFO] - Epoch 28/100, Val Acc=0.6409, Val Loss=1.6940, lr=0.0100
[2025-05-05 00:28:45,576][train][INFO] - Epoch 29/100, Val Acc=0.6394, Val Loss=1.7111, lr=0.0100
[2025-05-05 00:28:46,090][train][INFO] - Epoch 28/100, Val Acc=0.6410, Val Loss=1.6560, lr=0.0100
[2025-05-05 00:28:53,676][train][INFO] - Epoch 30/100, Val Acc=0.6573, Val Loss=1.5738, lr=0.0100
[2025-05-05 00:28:54,468][train][INFO] - Epoch 29/100, Val Acc=0.6514, Val Loss=1.5886, lr=0.0100
[2025-05-05 00:29:02,123][train][INFO] - Epoch 31/100, Val Acc=0.6484, Val Loss=1.6773, lr=0.0100
[2025-05-05 00:29:02,652][train][INFO] - Epoch 30/100, Val Acc=0.6519, Val Loss=1.5711, lr=0.0100
[2025-05-05 00:29:10,593][train][INFO] - Epoch 32/100, Val Acc=0.6613, Val Loss=1.5545, lr=0.0100
[2025-05-05 00:29:10,944][train][INFO] - Epoch 31/100, Val Acc=0.6405, Val Loss=1.6639, lr=0.0100
[2025-05-05 00:29:18,358][train][INFO] - Epoch 33/100, Val Acc=0.6541, Val Loss=1.6282, lr=0.0100
[2025-05-05 00:29:19,253][train][INFO] - Epoch 32/100, Val Acc=0.6505, Val Loss=1.6115, lr=0.0100
[2025-05-05 00:29:26,261][train][INFO] - Epoch 34/100, Val Acc=0.6560, Val Loss=1.6061, lr=0.0100
[2025-05-05 00:29:26,738][train][INFO] - Epoch 33/100, Val Acc=0.6463, Val Loss=1.6258, lr=0.0100
[2025-05-05 00:29:34,538][train][INFO] - Epoch 35/100, Val Acc=0.6510, Val Loss=1.6214, lr=0.0100
[2025-05-05 00:29:34,852][train][INFO] - Epoch 34/100, Val Acc=0.6586, Val Loss=1.5804, lr=0.0100
[2025-05-05 00:29:43,000][train][INFO] - Epoch 35/100, Val Acc=0.6457, Val Loss=1.6214, lr=0.0100
[2025-05-05 00:29:43,126][train][INFO] - Epoch 36/100, Val Acc=0.6476, Val Loss=1.6829, lr=0.0100
[2025-05-05 00:29:51,051][train][INFO] - Epoch 37/100, Val Acc=0.6467, Val Loss=1.7193, lr=0.0100
[2025-05-05 00:29:51,115][train][INFO] - Epoch 36/100, Val Acc=0.6476, Val Loss=1.6220, lr=0.0100
[2025-05-05 00:29:59,180][train][INFO] - Epoch 38/100, Val Acc=0.6590, Val Loss=1.5966, lr=0.0100
[2025-05-05 00:29:59,599][train][INFO] - Epoch 37/100, Val Acc=0.6522, Val Loss=1.6148, lr=0.0100
[2025-05-05 00:30:06,908][train][INFO] - Epoch 38/100, Val Acc=0.6541, Val Loss=1.5928, lr=0.0100
[2025-05-05 00:30:07,597][train][INFO] - Epoch 39/100, Val Acc=0.6625, Val Loss=1.5778, lr=0.0100
[2025-05-05 00:30:15,188][train][INFO] - Epoch 39/100, Val Acc=0.6565, Val Loss=1.5763, lr=0.0100
[2025-05-05 00:30:16,118][train][INFO] - Epoch 40/100, Val Acc=0.6467, Val Loss=1.6733, lr=0.0100
[2025-05-05 00:30:22,990][train][INFO] - Epoch 40/100, Val Acc=0.6408, Val Loss=1.6627, lr=0.0100
[2025-05-05 00:30:24,071][train][INFO] - Epoch 41/100, Val Acc=0.6545, Val Loss=1.6391, lr=0.0100
[2025-05-05 00:30:31,281][train][INFO] - Epoch 41/100, Val Acc=0.6554, Val Loss=1.5831, lr=0.0100
[2025-05-05 00:30:32,248][train][INFO] - Epoch 42/100, Val Acc=0.6537, Val Loss=1.6382, lr=0.0100
[2025-05-05 00:30:39,578][train][INFO] - Epoch 42/100, Val Acc=0.6549, Val Loss=1.5815, lr=0.0100
[2025-05-05 00:30:40,477][train][INFO] - Epoch 43/100, Val Acc=0.6577, Val Loss=1.6208, lr=0.0100
[2025-05-05 00:30:48,186][train][INFO] - Epoch 43/100, Val Acc=0.6666, Val Loss=1.5348, lr=0.0100
[2025-05-05 00:30:48,975][train][INFO] - Epoch 44/100, Val Acc=0.6423, Val Loss=1.6718, lr=0.0100
[2025-05-05 00:30:56,300][train][INFO] - Epoch 44/100, Val Acc=0.6302, Val Loss=1.7559, lr=0.0100
[2025-05-05 00:30:57,444][train][INFO] - Epoch 45/100, Val Acc=0.6439, Val Loss=1.6988, lr=0.0100
[2025-05-05 00:31:04,294][train][INFO] - Epoch 45/100, Val Acc=0.6480, Val Loss=1.6687, lr=0.0100
[2025-05-05 00:31:05,526][train][INFO] - Epoch 46/100, Val Acc=0.6431, Val Loss=1.6831, lr=0.0100
[2025-05-05 00:31:12,235][train][INFO] - Epoch 46/100, Val Acc=0.6588, Val Loss=1.5679, lr=0.0100
[2025-05-05 00:31:14,153][train][INFO] - Epoch 47/100, Val Acc=0.6538, Val Loss=1.6118, lr=0.0100
[2025-05-05 00:31:19,951][train][INFO] - Epoch 47/100, Val Acc=0.6613, Val Loss=1.5740, lr=0.0100
[2025-05-05 00:31:22,210][train][INFO] - Epoch 48/100, Val Acc=0.6485, Val Loss=1.6308, lr=0.0100
[2025-05-05 00:31:28,272][train][INFO] - Epoch 48/100, Val Acc=0.6530, Val Loss=1.5762, lr=0.0100
[2025-05-05 00:31:30,502][train][INFO] - Epoch 49/100, Val Acc=0.6595, Val Loss=1.6180, lr=0.0100
[2025-05-05 00:31:36,290][train][INFO] - Epoch 49/100, Val Acc=0.6488, Val Loss=1.6603, lr=0.0100
[2025-05-05 00:31:38,759][train][INFO] - Epoch 50/100, Val Acc=0.6562, Val Loss=1.6006, lr=0.0100
[2025-05-05 00:31:43,666][train][INFO] - Epoch 50/100, Val Acc=0.6608, Val Loss=1.5998, lr=0.0100
[2025-05-05 00:31:47,235][train][INFO] - Epoch 51/100, Val Acc=0.6367, Val Loss=1.6977, lr=0.0100
[2025-05-05 00:31:51,470][train][INFO] - Epoch 51/100, Val Acc=0.6494, Val Loss=1.6343, lr=0.0100
[2025-05-05 00:31:54,093][train][INFO] - Epoch 52/100, Val Acc=0.6471, Val Loss=1.6727, lr=0.0100
[2025-05-05 00:32:00,098][train][INFO] - Epoch 52/100, Val Acc=0.6532, Val Loss=1.6331, lr=0.0100
[2025-05-05 00:32:02,637][train][INFO] - Epoch 53/100, Val Acc=0.6569, Val Loss=1.5895, lr=0.0100
[2025-05-05 00:32:07,388][train][INFO] - Epoch 53/100, Val Acc=0.6464, Val Loss=1.6427, lr=0.0100
[2025-05-05 00:32:10,643][train][INFO] - Epoch 54/100, Val Acc=0.6548, Val Loss=1.6509, lr=0.0100
[2025-05-05 00:32:15,550][train][INFO] - Epoch 54/100, Val Acc=0.6441, Val Loss=1.6547, lr=0.0100
[2025-05-05 00:32:18,901][train][INFO] - Epoch 55/100, Val Acc=0.6597, Val Loss=1.6307, lr=0.0100
[2025-05-05 00:32:23,787][train][INFO] - Epoch 55/100, Val Acc=0.6547, Val Loss=1.6375, lr=0.0100
[2025-05-05 00:32:27,276][train][INFO] - Epoch 56/100, Val Acc=0.6424, Val Loss=1.7348, lr=0.0100
[2025-05-05 00:32:31,946][train][INFO] - Epoch 56/100, Val Acc=0.6442, Val Loss=1.6668, lr=0.0100
[2025-05-05 00:32:35,310][train][INFO] - Epoch 57/100, Val Acc=0.6525, Val Loss=1.6364, lr=0.0100
[2025-05-05 00:32:40,110][train][INFO] - Epoch 57/100, Val Acc=0.6623, Val Loss=1.5586, lr=0.0100
[2025-05-05 00:32:43,266][train][INFO] - Epoch 58/100, Val Acc=0.6461, Val Loss=1.6695, lr=0.0100
[2025-05-05 00:32:48,080][train][INFO] - Epoch 58/100, Val Acc=0.6642, Val Loss=1.5954, lr=0.0100
[2025-05-05 00:32:49,892][train][INFO] - Epoch 59/100, Val Acc=0.6588, Val Loss=1.5789, lr=0.0100
[2025-05-05 00:32:55,708][train][INFO] - Epoch 59/100, Val Acc=0.6415, Val Loss=1.6897, lr=0.0100
[2025-05-05 00:32:58,217][train][INFO] - Epoch 60/100, Val Acc=0.6541, Val Loss=1.6551, lr=0.0100
[2025-05-05 00:33:04,157][train][INFO] - Epoch 60/100, Val Acc=0.6568, Val Loss=1.5880, lr=0.0100
[2025-05-05 00:33:06,672][train][INFO] - Epoch 61/100, Val Acc=0.7121, Val Loss=1.3372, lr=0.0010
[2025-05-05 00:33:11,430][train][INFO] - Epoch 61/100, Val Acc=0.7136, Val Loss=1.3302, lr=0.0010
[2025-05-05 00:33:14,842][train][INFO] - Epoch 62/100, Val Acc=0.7144, Val Loss=1.3289, lr=0.0010
[2025-05-05 00:33:19,250][train][INFO] - Epoch 62/100, Val Acc=0.7170, Val Loss=1.3272, lr=0.0010
[2025-05-05 00:33:22,800][train][INFO] - Epoch 63/100, Val Acc=0.7155, Val Loss=1.3360, lr=0.0010
[2025-05-05 00:33:26,827][train][INFO] - Epoch 63/100, Val Acc=0.7176, Val Loss=1.3323, lr=0.0010
[2025-05-05 00:33:31,121][train][INFO] - Epoch 64/100, Val Acc=0.7170, Val Loss=1.3391, lr=0.0010
[2025-05-05 00:33:34,793][train][INFO] - Epoch 64/100, Val Acc=0.7207, Val Loss=1.3311, lr=0.0010
[2025-05-05 00:33:39,591][train][INFO] - Epoch 65/100, Val Acc=0.7221, Val Loss=1.3374, lr=0.0010
[2025-05-05 00:33:42,648][train][INFO] - Epoch 65/100, Val Acc=0.7189, Val Loss=1.3433, lr=0.0010
[2025-05-05 00:33:47,814][train][INFO] - Epoch 66/100, Val Acc=0.7198, Val Loss=1.3498, lr=0.0010
[2025-05-05 00:33:49,937][train][INFO] - Epoch 66/100, Val Acc=0.7193, Val Loss=1.3470, lr=0.0010
[2025-05-05 00:33:55,666][train][INFO] - Epoch 67/100, Val Acc=0.7192, Val Loss=1.3461, lr=0.0010
[2025-05-05 00:33:58,135][train][INFO] - Epoch 67/100, Val Acc=0.7193, Val Loss=1.3508, lr=0.0010
[2025-05-05 00:34:02,625][train][INFO] - Epoch 68/100, Val Acc=0.7213, Val Loss=1.3485, lr=0.0010
[2025-05-05 00:34:06,049][train][INFO] - Epoch 68/100, Val Acc=0.7196, Val Loss=1.3560, lr=0.0010
[2025-05-05 00:34:10,992][train][INFO] - Epoch 69/100, Val Acc=0.7204, Val Loss=1.3569, lr=0.0010
[2025-05-05 00:34:13,994][train][INFO] - Epoch 69/100, Val Acc=0.7183, Val Loss=1.3566, lr=0.0010
[2025-05-05 00:34:19,218][train][INFO] - Epoch 70/100, Val Acc=0.7221, Val Loss=1.3572, lr=0.0010
[2025-05-05 00:34:22,321][train][INFO] - Epoch 70/100, Val Acc=0.7217, Val Loss=1.3613, lr=0.0010
[2025-05-05 00:34:27,567][train][INFO] - Epoch 71/100, Val Acc=0.7224, Val Loss=1.3636, lr=0.0010
[2025-05-05 00:34:30,435][train][INFO] - Epoch 71/100, Val Acc=0.7212, Val Loss=1.3593, lr=0.0010
[2025-05-05 00:34:35,922][train][INFO] - Epoch 72/100, Val Acc=0.7228, Val Loss=1.3684, lr=0.0010
[2025-05-05 00:34:38,162][train][INFO] - Epoch 72/100, Val Acc=0.7223, Val Loss=1.3631, lr=0.0010
[2025-05-05 00:34:43,835][train][INFO] - Epoch 73/100, Val Acc=0.7226, Val Loss=1.3701, lr=0.0010
[2025-05-05 00:34:45,924][train][INFO] - Epoch 73/100, Val Acc=0.7209, Val Loss=1.3673, lr=0.0010
[2025-05-05 00:34:52,116][train][INFO] - Epoch 74/100, Val Acc=0.7222, Val Loss=1.3668, lr=0.0010
[2025-05-05 00:34:54,178][train][INFO] - Epoch 74/100, Val Acc=0.7228, Val Loss=1.3666, lr=0.0010
[2025-05-05 00:35:00,304][train][INFO] - Epoch 75/100, Val Acc=0.7222, Val Loss=1.3698, lr=0.0010
[2025-05-05 00:35:02,443][train][INFO] - Epoch 75/100, Val Acc=0.7214, Val Loss=1.3683, lr=0.0010
[2025-05-05 00:35:08,317][train][INFO] - Epoch 76/100, Val Acc=0.7233, Val Loss=1.3689, lr=0.0010
[2025-05-05 00:35:10,260][train][INFO] - Epoch 76/100, Val Acc=0.7243, Val Loss=1.3619, lr=0.0010
[2025-05-05 00:35:16,136][train][INFO] - Epoch 77/100, Val Acc=0.7219, Val Loss=1.3726, lr=0.0010
[2025-05-05 00:35:18,560][train][INFO] - Epoch 77/100, Val Acc=0.7213, Val Loss=1.3695, lr=0.0010
[2025-05-05 00:35:24,132][train][INFO] - Epoch 78/100, Val Acc=0.7228, Val Loss=1.3651, lr=0.0010
[2025-05-05 00:35:26,495][train][INFO] - Epoch 78/100, Val Acc=0.7237, Val Loss=1.3698, lr=0.0010
[2025-05-05 00:35:32,487][train][INFO] - Epoch 79/100, Val Acc=0.7259, Val Loss=1.3756, lr=0.0010
[2025-05-05 00:35:34,777][train][INFO] - Epoch 79/100, Val Acc=0.7239, Val Loss=1.3827, lr=0.0010
[2025-05-05 00:35:40,915][train][INFO] - Epoch 80/100, Val Acc=0.7235, Val Loss=1.3727, lr=0.0010
[2025-05-05 00:35:42,796][train][INFO] - Epoch 80/100, Val Acc=0.7211, Val Loss=1.3753, lr=0.0010
[2025-05-05 00:35:49,398][train][INFO] - Epoch 81/100, Val Acc=0.7201, Val Loss=1.3720, lr=0.0010
[2025-05-05 00:35:51,305][train][INFO] - Epoch 81/100, Val Acc=0.7232, Val Loss=1.3832, lr=0.0010
[2025-05-05 00:35:57,693][train][INFO] - Epoch 82/100, Val Acc=0.7209, Val Loss=1.3723, lr=0.0010
[2025-05-05 00:35:59,521][train][INFO] - Epoch 82/100, Val Acc=0.7207, Val Loss=1.3800, lr=0.0010
[2025-05-05 00:36:05,817][train][INFO] - Epoch 83/100, Val Acc=0.7257, Val Loss=1.3698, lr=0.0010
[2025-05-05 00:36:07,537][train][INFO] - Epoch 83/100, Val Acc=0.7240, Val Loss=1.3818, lr=0.0010
[2025-05-05 00:36:13,866][train][INFO] - Epoch 84/100, Val Acc=0.7248, Val Loss=1.3696, lr=0.0010
[2025-05-05 00:36:15,106][train][INFO] - Epoch 84/100, Val Acc=0.7217, Val Loss=1.3816, lr=0.0010
[2025-05-05 00:36:21,536][train][INFO] - Epoch 85/100, Val Acc=0.7231, Val Loss=1.3758, lr=0.0010
[2025-05-05 00:36:23,421][train][INFO] - Epoch 85/100, Val Acc=0.7236, Val Loss=1.3800, lr=0.0010
[2025-05-05 00:36:29,599][train][INFO] - Epoch 86/100, Val Acc=0.7231, Val Loss=1.3798, lr=0.0010
[2025-05-05 00:36:31,564][train][INFO] - Epoch 86/100, Val Acc=0.7236, Val Loss=1.3799, lr=0.0010
[2025-05-05 00:36:37,771][train][INFO] - Epoch 87/100, Val Acc=0.7257, Val Loss=1.3725, lr=0.0010
[2025-05-05 00:36:39,668][train][INFO] - Epoch 87/100, Val Acc=0.7239, Val Loss=1.3891, lr=0.0010
[2025-05-05 00:36:46,036][train][INFO] - Epoch 88/100, Val Acc=0.7250, Val Loss=1.3729, lr=0.0010
[2025-05-05 00:36:47,890][train][INFO] - Epoch 88/100, Val Acc=0.7242, Val Loss=1.3793, lr=0.0010
[2025-05-05 00:36:54,499][train][INFO] - Epoch 89/100, Val Acc=0.7242, Val Loss=1.3746, lr=0.0010
[2025-05-05 00:36:56,379][train][INFO] - Epoch 89/100, Val Acc=0.7231, Val Loss=1.3826, lr=0.0010
[2025-05-05 00:37:02,039][train][INFO] - Epoch 90/100, Val Acc=0.7261, Val Loss=1.3768, lr=0.0010
[2025-05-05 00:37:04,622][train][INFO] - Epoch 90/100, Val Acc=0.7220, Val Loss=1.3835, lr=0.0010
[2025-05-05 00:37:10,139][train][INFO] - Epoch 91/100, Val Acc=0.7266, Val Loss=1.3754, lr=0.0001
[2025-05-05 00:37:13,092][train][INFO] - Epoch 91/100, Val Acc=0.7233, Val Loss=1.3751, lr=0.0001
[2025-05-05 00:37:18,517][train][INFO] - Epoch 92/100, Val Acc=0.7254, Val Loss=1.3775, lr=0.0001
[2025-05-05 00:37:21,145][train][INFO] - Epoch 92/100, Val Acc=0.7241, Val Loss=1.3815, lr=0.0001
[2025-05-05 00:37:26,473][train][INFO] - Epoch 93/100, Val Acc=0.7271, Val Loss=1.3705, lr=0.0001
[2025-05-05 00:37:29,017][train][INFO] - Epoch 93/100, Val Acc=0.7236, Val Loss=1.3786, lr=0.0001
[2025-05-05 00:37:34,473][train][INFO] - Epoch 94/100, Val Acc=0.7260, Val Loss=1.3705, lr=0.0001
[2025-05-05 00:37:37,294][train][INFO] - Epoch 94/100, Val Acc=0.7247, Val Loss=1.3759, lr=0.0001
[2025-05-05 00:37:42,445][train][INFO] - Epoch 95/100, Val Acc=0.7268, Val Loss=1.3761, lr=0.0001
[2025-05-05 00:37:44,918][train][INFO] - Epoch 95/100, Val Acc=0.7252, Val Loss=1.3805, lr=0.0001
[2025-05-05 00:37:50,609][train][INFO] - Epoch 96/100, Val Acc=0.7272, Val Loss=1.3703, lr=0.0001
[2025-05-05 00:37:53,047][train][INFO] - Epoch 96/100, Val Acc=0.7261, Val Loss=1.3732, lr=0.0001
[2025-05-05 00:37:58,640][train][INFO] - Epoch 97/100, Val Acc=0.7263, Val Loss=1.3738, lr=0.0001
[2025-05-05 00:38:01,161][train][INFO] - Epoch 97/100, Val Acc=0.7251, Val Loss=1.3755, lr=0.0001
[2025-05-05 00:38:06,575][train][INFO] - Epoch 98/100, Val Acc=0.7251, Val Loss=1.3731, lr=0.0001
[2025-05-05 00:38:09,487][train][INFO] - Epoch 98/100, Val Acc=0.7249, Val Loss=1.3746, lr=0.0001
[2025-05-05 00:38:15,141][train][INFO] - Epoch 99/100, Val Acc=0.7260, Val Loss=1.3790, lr=0.0001
[2025-05-05 00:38:17,574][train][INFO] - Epoch 99/100, Val Acc=0.7241, Val Loss=1.3808, lr=0.0001
[2025-05-05 00:38:22,986][train][INFO] - Epoch 100/100, Val Acc=0.7269, Val Loss=1.3742, lr=0.0001
[2025-05-05 00:38:25,413][train][INFO] - Epoch 100/100, Val Acc=0.7242, Val Loss=1.3803, lr=0.0001
[2025-05-05 00:38:28,121][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7272
[2025-05-05 00:38:28,132][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 00:38:30,533][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7261
[2025-05-05 00:38:30,538][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 00:40:13,079][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 00:40:17,374][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 00:42:02,777][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 00:42:03,207][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 00:42:10,836][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 00:42:11,275][Visualize acc speed up curve][INFO] - End visualizing
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 5, in <module>
    import hydra
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/__init__.py", line 5, in <module>
    from hydra import utils
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/utils.py", line 8, in <module>
    import hydra._internal.instantiate._instantiate2
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 9, in <module>
    from omegaconf import OmegaConf, SCMode
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/__init__.py", line 1, in <module>
    from .base import Container, DictKeyType, Node, SCMode, UnionNode
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/base.py", line 9, in <module>
    from antlr4 import ParserRuleContext
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/antlr4/__init__.py", line 13, in <module>
    from antlr4.atn.ParserATNSimulator import ParserATNSimulator
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/antlr4/atn/ParserATNSimulator.py", line 257, in <module>
    class ParserATNSimulator(ATNSimulator):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/antlr4/atn/ParserATNSimulator.py", line 1487, in ParserATNSimulator
    def getConflictingAltsOrUniqueAlt(self, configs:ATNConfigSet):
KeyboardInterrupt
[2025-05-05 00:45:14,944][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-05 00:45:15,014][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:45:15,014][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:45:15,014][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:45:37,383][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.3092, lr=0.001
[2025-05-05 00:45:55,749][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0919, lr=0.001
[2025-05-05 00:46:13,793][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.5286, lr=0.001
[2025-05-05 00:46:34,149][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.4285, lr=0.001
[2025-05-05 00:46:54,756][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=3.8184, lr=0.001
[2025-05-05 00:47:13,671][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=2.1088, lr=0.001
[2025-05-05 00:47:33,607][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7206, lr=0.001
[2025-05-05 00:47:40,819][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 6

[2025-05-05 00:47:40,876][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:47:40,876][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:47:40,876][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:47:52,304][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4979, lr=0.001
[2025-05-05 00:47:52,333][meta_train][INFO] - epoch_1 saved !
[2025-05-05 00:47:54,788][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 00:48:02,664][train][INFO] - Epoch 1/100, Val Acc=0.5828, Val Loss=1.7266, lr=0.0100
[2025-05-05 00:48:09,799][train][INFO] - Epoch 2/100, Val Acc=0.5876, Val Loss=1.7437, lr=0.0100
Traceback (most recent call last):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/resource_sharer.py", line 138, in _serve
    with self._listener.accept() as conn:
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/connection.py", line 465, in accept
    deliver_challenge(c, self._authkey)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
[2025-05-05 00:48:12,799][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=1.0962, lr=0.001
[2025-05-05 00:48:25,847][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 8

[2025-05-05 00:48:25,918][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:48:25,918][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:48:25,918][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 00:48:31,532][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=1.2402, lr=0.001
[2025-05-05 00:48:34,276][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Kitty
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 9

[2025-05-05 00:48:34,361][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 00:48:34,361][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 00:48:34,361][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:48:39,615][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 00:48:47,910][train][INFO] - Epoch 1/100, Val Acc=0.1929, Val Loss=3.1892, lr=0.0100
[2025-05-05 00:48:48,746][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 00:48:50,120][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2247, lr=0.001
[2025-05-05 00:48:55,880][train][INFO] - Epoch 2/100, Val Acc=0.3910, Val Loss=2.2436, lr=0.0100
[2025-05-05 00:48:56,785][train][INFO] - Epoch 1/100, Val Acc=0.0815, Val Loss=4.3211, lr=0.0100
[2025-05-05 00:49:03,910][train][INFO] - Epoch 3/100, Val Acc=0.4835, Val Loss=1.9569, lr=0.0100
[2025-05-05 00:49:05,157][train][INFO] - Epoch 2/100, Val Acc=0.2008, Val Loss=2.9929, lr=0.0100
[2025-05-05 00:49:09,416][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.0867, lr=0.001
[2025-05-05 00:49:11,651][train][INFO] - Epoch 4/100, Val Acc=0.5087, Val Loss=1.8912, lr=0.0100
[2025-05-05 00:49:12,884][train][INFO] - Epoch 3/100, Val Acc=0.2160, Val Loss=3.1152, lr=0.0100
[2025-05-05 00:49:19,084][train][INFO] - Epoch 5/100, Val Acc=0.5608, Val Loss=1.6501, lr=0.0100
[2025-05-05 00:49:20,725][train][INFO] - Epoch 4/100, Val Acc=0.2885, Val Loss=2.7841, lr=0.0100
[2025-05-05 00:49:27,276][train][INFO] - Epoch 6/100, Val Acc=0.5069, Val Loss=2.0370, lr=0.0100
[2025-05-05 00:49:28,481][train][INFO] - Epoch 5/100, Val Acc=0.3313, Val Loss=2.5120, lr=0.0100
[2025-05-05 00:49:29,016][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0615, lr=0.001
[2025-05-05 00:49:35,131][train][INFO] - Epoch 7/100, Val Acc=0.5852, Val Loss=1.6115, lr=0.0100
[2025-05-05 00:49:36,533][train][INFO] - Epoch 6/100, Val Acc=0.3985, Val Loss=2.2458, lr=0.0100
[2025-05-05 00:49:42,966][train][INFO] - Epoch 8/100, Val Acc=0.5990, Val Loss=1.5608, lr=0.0100
[2025-05-05 00:49:44,615][train][INFO] - Epoch 7/100, Val Acc=0.4466, Val Loss=1.9815, lr=0.0100
[2025-05-05 00:49:50,193][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0551, lr=0.001
[2025-05-05 00:49:50,865][train][INFO] - Epoch 9/100, Val Acc=0.6105, Val Loss=1.5105, lr=0.0100
[2025-05-05 00:49:52,377][train][INFO] - Epoch 8/100, Val Acc=0.4496, Val Loss=2.1031, lr=0.0100
[2025-05-05 00:49:58,904][train][INFO] - Epoch 10/100, Val Acc=0.5880, Val Loss=1.6645, lr=0.0100
[2025-05-05 00:50:00,066][train][INFO] - Epoch 9/100, Val Acc=0.4182, Val Loss=2.3054, lr=0.0100
[2025-05-05 00:50:06,907][train][INFO] - Epoch 11/100, Val Acc=0.6302, Val Loss=1.4710, lr=0.0100
[2025-05-05 00:50:08,199][train][INFO] - Epoch 10/100, Val Acc=0.4739, Val Loss=2.0265, lr=0.0100
[2025-05-05 00:50:10,303][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0856, lr=0.001
[2025-05-05 00:50:15,031][train][INFO] - Epoch 12/100, Val Acc=0.5973, Val Loss=1.6709, lr=0.0100
[2025-05-05 00:50:16,060][train][INFO] - Epoch 11/100, Val Acc=0.5090, Val Loss=1.7954, lr=0.0100
[2025-05-05 00:50:23,067][train][INFO] - Epoch 13/100, Val Acc=0.6183, Val Loss=1.5842, lr=0.0100
[2025-05-05 00:50:24,141][train][INFO] - Epoch 12/100, Val Acc=0.5053, Val Loss=1.8630, lr=0.0100
[2025-05-05 00:50:30,024][train][INFO] - Epoch 14/100, Val Acc=0.6119, Val Loss=1.6276, lr=0.0100
[2025-05-05 00:50:30,992][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.1053, lr=0.001
[2025-05-05 00:50:31,026][meta_train][INFO] - epoch_2 saved !
[2025-05-05 00:50:32,010][train][INFO] - Epoch 13/100, Val Acc=0.5221, Val Loss=1.8074, lr=0.0100
[2025-05-05 00:50:38,131][train][INFO] - Epoch 15/100, Val Acc=0.6289, Val Loss=1.4934, lr=0.0100
[2025-05-05 00:50:39,765][train][INFO] - Epoch 14/100, Val Acc=0.5218, Val Loss=1.8563, lr=0.0100
[2025-05-05 00:50:46,112][train][INFO] - Epoch 16/100, Val Acc=0.6307, Val Loss=1.5097, lr=0.0100
[2025-05-05 00:50:47,433][train][INFO] - Epoch 15/100, Val Acc=0.5394, Val Loss=1.7392, lr=0.0100
[2025-05-05 00:50:52,233][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1365, lr=0.001
[2025-05-05 00:50:53,944][train][INFO] - Epoch 17/100, Val Acc=0.6366, Val Loss=1.5029, lr=0.0100
[2025-05-05 00:50:55,382][train][INFO] - Epoch 16/100, Val Acc=0.5290, Val Loss=1.7802, lr=0.0100
[2025-05-05 00:51:01,627][train][INFO] - Epoch 18/100, Val Acc=0.6413, Val Loss=1.4955, lr=0.0100
[2025-05-05 00:51:03,266][train][INFO] - Epoch 17/100, Val Acc=0.5635, Val Loss=1.6718, lr=0.0100
[2025-05-05 00:51:09,303][train][INFO] - Epoch 19/100, Val Acc=0.6360, Val Loss=1.4801, lr=0.0100
[2025-05-05 00:51:11,117][train][INFO] - Epoch 18/100, Val Acc=0.5511, Val Loss=1.7448, lr=0.0100
[2025-05-05 00:51:11,780][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.1831, lr=0.001
[2025-05-05 00:51:16,866][train][INFO] - Epoch 20/100, Val Acc=0.6293, Val Loss=1.5815, lr=0.0100
[2025-05-05 00:51:18,477][train][INFO] - Epoch 19/100, Val Acc=0.5745, Val Loss=1.5890, lr=0.0100
[2025-05-05 00:51:24,860][train][INFO] - Epoch 21/100, Val Acc=0.6243, Val Loss=1.6012, lr=0.0100
[2025-05-05 00:51:25,799][train][INFO] - Epoch 20/100, Val Acc=0.5638, Val Loss=1.7043, lr=0.0100
[2025-05-05 00:51:31,404][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.8700, lr=0.001
[2025-05-05 00:51:32,334][train][INFO] - Epoch 22/100, Val Acc=0.6248, Val Loss=1.6015, lr=0.0100
[2025-05-05 00:51:33,483][train][INFO] - Epoch 21/100, Val Acc=0.5584, Val Loss=1.7276, lr=0.0100
[2025-05-05 00:51:40,176][train][INFO] - Epoch 23/100, Val Acc=0.6258, Val Loss=1.6251, lr=0.0100
[2025-05-05 00:51:40,966][train][INFO] - Epoch 22/100, Val Acc=0.5665, Val Loss=1.6658, lr=0.0100
[2025-05-05 00:51:47,916][train][INFO] - Epoch 24/100, Val Acc=0.6356, Val Loss=1.5748, lr=0.0100
[2025-05-05 00:51:49,034][train][INFO] - Epoch 23/100, Val Acc=0.5837, Val Loss=1.6153, lr=0.0100
[2025-05-05 00:51:50,328][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.3916, lr=0.001
[2025-05-05 00:51:55,842][train][INFO] - Epoch 25/100, Val Acc=0.6445, Val Loss=1.4840, lr=0.0100
[2025-05-05 00:51:56,987][train][INFO] - Epoch 24/100, Val Acc=0.5724, Val Loss=1.7144, lr=0.0100
[2025-05-05 00:52:04,120][train][INFO] - Epoch 26/100, Val Acc=0.6344, Val Loss=1.5954, lr=0.0100
[2025-05-05 00:52:04,696][train][INFO] - Epoch 25/100, Val Acc=0.5866, Val Loss=1.5921, lr=0.0100
[2025-05-05 00:52:09,533][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2930, lr=0.001
[2025-05-05 00:52:11,915][train][INFO] - Epoch 27/100, Val Acc=0.6249, Val Loss=1.6530, lr=0.0100
[2025-05-05 00:52:12,383][train][INFO] - Epoch 26/100, Val Acc=0.5802, Val Loss=1.6646, lr=0.0100
[2025-05-05 00:52:19,383][train][INFO] - Epoch 28/100, Val Acc=0.6086, Val Loss=1.7980, lr=0.0100
[2025-05-05 00:52:20,182][train][INFO] - Epoch 27/100, Val Acc=0.5938, Val Loss=1.6073, lr=0.0100
[2025-05-05 00:52:27,186][train][INFO] - Epoch 29/100, Val Acc=0.6404, Val Loss=1.5923, lr=0.0100
[2025-05-05 00:52:28,062][train][INFO] - Epoch 28/100, Val Acc=0.6045, Val Loss=1.5530, lr=0.0100
[2025-05-05 00:52:30,240][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.4007, lr=0.001
[2025-05-05 00:52:34,903][train][INFO] - Epoch 30/100, Val Acc=0.6456, Val Loss=1.5424, lr=0.0100
[2025-05-05 00:52:36,115][train][INFO] - Epoch 29/100, Val Acc=0.5920, Val Loss=1.6297, lr=0.0100
[2025-05-05 00:52:42,981][train][INFO] - Epoch 31/100, Val Acc=0.6421, Val Loss=1.5986, lr=0.0100
[2025-05-05 00:52:43,966][train][INFO] - Epoch 30/100, Val Acc=0.6045, Val Loss=1.5660, lr=0.0100
[2025-05-05 00:52:50,415][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.5278, lr=0.001
[2025-05-05 00:52:50,498][train][INFO] - Epoch 32/100, Val Acc=0.6475, Val Loss=1.5755, lr=0.0100
[2025-05-05 00:52:51,540][train][INFO] - Epoch 31/100, Val Acc=0.5958, Val Loss=1.6405, lr=0.0100
[2025-05-05 00:52:58,384][train][INFO] - Epoch 33/100, Val Acc=0.6403, Val Loss=1.5957, lr=0.0100
[2025-05-05 00:52:59,570][train][INFO] - Epoch 32/100, Val Acc=0.5845, Val Loss=1.7391, lr=0.0100
[2025-05-05 00:53:05,862][train][INFO] - Epoch 34/100, Val Acc=0.6450, Val Loss=1.6060, lr=0.0100
[2025-05-05 00:53:07,722][train][INFO] - Epoch 33/100, Val Acc=0.6053, Val Loss=1.6140, lr=0.0100
[2025-05-05 00:53:10,326][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.6882, lr=0.001
[2025-05-05 00:53:10,355][meta_train][INFO] - epoch_3 saved !
[2025-05-05 00:53:13,008][train][INFO] - Epoch 35/100, Val Acc=0.6531, Val Loss=1.5238, lr=0.0100
[2025-05-05 00:53:15,480][train][INFO] - Epoch 34/100, Val Acc=0.5958, Val Loss=1.6698, lr=0.0100
[2025-05-05 00:53:20,838][train][INFO] - Epoch 36/100, Val Acc=0.6407, Val Loss=1.6263, lr=0.0100
[2025-05-05 00:53:23,508][train][INFO] - Epoch 35/100, Val Acc=0.5939, Val Loss=1.6450, lr=0.0100
[2025-05-05 00:53:28,766][train][INFO] - Epoch 37/100, Val Acc=0.6383, Val Loss=1.6225, lr=0.0100
[2025-05-05 00:53:29,615][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.5922, lr=0.001
[2025-05-05 00:53:31,346][train][INFO] - Epoch 36/100, Val Acc=0.5987, Val Loss=1.6416, lr=0.0100
[2025-05-05 00:53:36,677][train][INFO] - Epoch 38/100, Val Acc=0.6315, Val Loss=1.6573, lr=0.0100
[2025-05-05 00:53:39,016][train][INFO] - Epoch 37/100, Val Acc=0.5914, Val Loss=1.6524, lr=0.0100
[2025-05-05 00:53:44,720][train][INFO] - Epoch 39/100, Val Acc=0.6408, Val Loss=1.6369, lr=0.0100
[2025-05-05 00:53:47,049][train][INFO] - Epoch 38/100, Val Acc=0.5848, Val Loss=1.7233, lr=0.0100
[2025-05-05 00:53:49,602][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=1.2647, lr=0.001
[2025-05-05 00:53:52,775][train][INFO] - Epoch 40/100, Val Acc=0.6447, Val Loss=1.5997, lr=0.0100
[2025-05-05 00:53:54,484][train][INFO] - Epoch 39/100, Val Acc=0.5991, Val Loss=1.6563, lr=0.0100
[2025-05-05 00:54:00,412][train][INFO] - Epoch 41/100, Val Acc=0.6504, Val Loss=1.5638, lr=0.0100
[2025-05-05 00:54:02,097][train][INFO] - Epoch 40/100, Val Acc=0.6274, Val Loss=1.5316, lr=0.0100
[2025-05-05 00:54:08,539][train][INFO] - Epoch 42/100, Val Acc=0.6435, Val Loss=1.6172, lr=0.0100
[2025-05-05 00:54:10,058][train][INFO] - Epoch 41/100, Val Acc=0.6151, Val Loss=1.6227, lr=0.0100
[2025-05-05 00:54:10,691][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=1.4745, lr=0.001
[2025-05-05 00:54:16,164][train][INFO] - Epoch 43/100, Val Acc=0.6481, Val Loss=1.5963, lr=0.0100
[2025-05-05 00:54:17,549][train][INFO] - Epoch 42/100, Val Acc=0.6046, Val Loss=1.6776, lr=0.0100
[2025-05-05 00:54:23,999][train][INFO] - Epoch 44/100, Val Acc=0.6436, Val Loss=1.5978, lr=0.0100
[2025-05-05 00:54:25,316][train][INFO] - Epoch 43/100, Val Acc=0.5988, Val Loss=1.6768, lr=0.0100
[2025-05-05 00:54:31,204][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=1.8241, lr=0.001
[2025-05-05 00:54:31,739][train][INFO] - Epoch 45/100, Val Acc=0.6331, Val Loss=1.6631, lr=0.0100
[2025-05-05 00:54:33,350][train][INFO] - Epoch 44/100, Val Acc=0.6150, Val Loss=1.6359, lr=0.0100
[2025-05-05 00:54:39,684][train][INFO] - Epoch 46/100, Val Acc=0.6190, Val Loss=1.7870, lr=0.0100
[2025-05-05 00:54:40,152][train][INFO] - Epoch 45/100, Val Acc=0.6051, Val Loss=1.6904, lr=0.0100
[2025-05-05 00:54:47,809][train][INFO] - Epoch 47/100, Val Acc=0.6493, Val Loss=1.5992, lr=0.0100
[2025-05-05 00:54:47,967][train][INFO] - Epoch 46/100, Val Acc=0.6169, Val Loss=1.6352, lr=0.0100
[2025-05-05 00:54:50,574][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=2.0053, lr=0.001
[2025-05-05 00:54:55,244][train][INFO] - Epoch 47/100, Val Acc=0.5949, Val Loss=1.7389, lr=0.0100
[2025-05-05 00:54:56,137][train][INFO] - Epoch 48/100, Val Acc=0.6531, Val Loss=1.5570, lr=0.0100
[2025-05-05 00:55:01,912][train][INFO] - Epoch 48/100, Val Acc=0.6185, Val Loss=1.5868, lr=0.0100
[2025-05-05 00:55:04,124][train][INFO] - Epoch 49/100, Val Acc=0.6541, Val Loss=1.6229, lr=0.0100
[2025-05-05 00:55:09,562][train][INFO] - Epoch 49/100, Val Acc=0.6146, Val Loss=1.6965, lr=0.0100
[2025-05-05 00:55:11,839][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=2.7444, lr=0.001
[2025-05-05 00:55:12,182][train][INFO] - Epoch 50/100, Val Acc=0.6384, Val Loss=1.6819, lr=0.0100
[2025-05-05 00:55:17,393][train][INFO] - Epoch 50/100, Val Acc=0.6165, Val Loss=1.6674, lr=0.0100
[2025-05-05 00:55:19,966][train][INFO] - Epoch 51/100, Val Acc=0.6375, Val Loss=1.6547, lr=0.0100
[2025-05-05 00:55:24,723][train][INFO] - Epoch 51/100, Val Acc=0.6195, Val Loss=1.6288, lr=0.0100
[2025-05-05 00:55:27,837][train][INFO] - Epoch 52/100, Val Acc=0.6468, Val Loss=1.6573, lr=0.0100
[2025-05-05 00:55:30,962][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=3.4555, lr=0.001
[2025-05-05 00:55:33,112][train][INFO] - Epoch 52/100, Val Acc=0.6146, Val Loss=1.6857, lr=0.0100
[2025-05-05 00:55:35,450][train][INFO] - Epoch 53/100, Val Acc=0.6410, Val Loss=1.6507, lr=0.0100
[2025-05-05 00:55:41,117][train][INFO] - Epoch 53/100, Val Acc=0.6159, Val Loss=1.7136, lr=0.0100
[2025-05-05 00:55:43,393][train][INFO] - Epoch 54/100, Val Acc=0.6404, Val Loss=1.6400, lr=0.0100
[2025-05-05 00:55:49,259][train][INFO] - Epoch 54/100, Val Acc=0.6225, Val Loss=1.6676, lr=0.0100
[2025-05-05 00:55:50,140][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=5.7571, lr=0.001
[2025-05-05 00:55:50,171][meta_train][INFO] - epoch_4 saved !
[2025-05-05 00:55:51,501][train][INFO] - Epoch 55/100, Val Acc=0.6451, Val Loss=1.6322, lr=0.0100
[2025-05-05 00:55:57,123][train][INFO] - Epoch 55/100, Val Acc=0.6267, Val Loss=1.5993, lr=0.0100
[2025-05-05 00:55:59,354][train][INFO] - Epoch 56/100, Val Acc=0.6429, Val Loss=1.6255, lr=0.0100
[2025-05-05 00:56:04,812][train][INFO] - Epoch 56/100, Val Acc=0.6264, Val Loss=1.6430, lr=0.0100
[2025-05-05 00:56:07,619][train][INFO] - Epoch 57/100, Val Acc=0.6474, Val Loss=1.6047, lr=0.0100
[2025-05-05 00:56:11,044][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=3.8050, lr=0.001
[2025-05-05 00:56:13,304][train][INFO] - Epoch 57/100, Val Acc=0.6187, Val Loss=1.6919, lr=0.0100
[2025-05-05 00:56:15,764][train][INFO] - Epoch 58/100, Val Acc=0.6462, Val Loss=1.6545, lr=0.0100
[2025-05-05 00:56:21,169][train][INFO] - Epoch 58/100, Val Acc=0.6226, Val Loss=1.5862, lr=0.0100
[2025-05-05 00:56:23,821][train][INFO] - Epoch 59/100, Val Acc=0.6386, Val Loss=1.6735, lr=0.0100
[2025-05-05 00:56:28,829][train][INFO] - Epoch 59/100, Val Acc=0.6285, Val Loss=1.6061, lr=0.0100
[2025-05-05 00:56:30,646][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.7332, lr=0.001
[2025-05-05 00:56:31,472][train][INFO] - Epoch 60/100, Val Acc=0.6427, Val Loss=1.6644, lr=0.0100
[2025-05-05 00:56:36,530][train][INFO] - Epoch 60/100, Val Acc=0.6143, Val Loss=1.7168, lr=0.0100
[2025-05-05 00:56:38,711][train][INFO] - Epoch 61/100, Val Acc=0.7044, Val Loss=1.3294, lr=0.0010
[2025-05-05 00:56:44,621][train][INFO] - Epoch 61/100, Val Acc=0.6793, Val Loss=1.3559, lr=0.0010
[2025-05-05 00:56:45,989][train][INFO] - Epoch 62/100, Val Acc=0.7075, Val Loss=1.3326, lr=0.0010
[2025-05-05 00:56:50,818][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=4.8864, lr=0.001
[2025-05-05 00:56:52,144][train][INFO] - Epoch 62/100, Val Acc=0.6847, Val Loss=1.3533, lr=0.0010
[2025-05-05 00:56:53,892][train][INFO] - Epoch 63/100, Val Acc=0.7095, Val Loss=1.3326, lr=0.0010
[2025-05-05 00:56:59,102][train][INFO] - Epoch 63/100, Val Acc=0.6845, Val Loss=1.3649, lr=0.0010
[2025-05-05 00:57:01,855][train][INFO] - Epoch 64/100, Val Acc=0.7092, Val Loss=1.3372, lr=0.0010
[2025-05-05 00:57:06,785][train][INFO] - Epoch 64/100, Val Acc=0.6835, Val Loss=1.3696, lr=0.0010
[2025-05-05 00:57:09,760][train][INFO] - Epoch 65/100, Val Acc=0.7116, Val Loss=1.3414, lr=0.0010
[2025-05-05 00:57:10,182][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=6.7454, lr=0.001
[2025-05-05 00:57:15,029][train][INFO] - Epoch 65/100, Val Acc=0.6865, Val Loss=1.3765, lr=0.0010
[2025-05-05 00:57:17,908][train][INFO] - Epoch 66/100, Val Acc=0.7119, Val Loss=1.3498, lr=0.0010
[2025-05-05 00:57:22,439][train][INFO] - Epoch 66/100, Val Acc=0.6854, Val Loss=1.3861, lr=0.0010
[2025-05-05 00:57:26,312][train][INFO] - Epoch 67/100, Val Acc=0.7109, Val Loss=1.3540, lr=0.0010
[2025-05-05 00:57:29,148][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.9151, lr=0.001
[2025-05-05 00:57:30,293][train][INFO] - Epoch 67/100, Val Acc=0.6839, Val Loss=1.4062, lr=0.0010
[2025-05-05 00:57:34,135][train][INFO] - Epoch 68/100, Val Acc=0.7116, Val Loss=1.3599, lr=0.0010
[2025-05-05 00:57:38,371][train][INFO] - Epoch 68/100, Val Acc=0.6862, Val Loss=1.4090, lr=0.0010
[2025-05-05 00:57:41,466][train][INFO] - Epoch 69/100, Val Acc=0.7129, Val Loss=1.3592, lr=0.0010
[2025-05-05 00:57:46,530][train][INFO] - Epoch 69/100, Val Acc=0.6886, Val Loss=1.4095, lr=0.0010
[2025-05-05 00:57:48,628][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=7.6931, lr=0.001
[2025-05-05 00:57:49,390][train][INFO] - Epoch 70/100, Val Acc=0.7132, Val Loss=1.3602, lr=0.0010
[2025-05-05 00:57:53,376][train][INFO] - Epoch 70/100, Val Acc=0.6884, Val Loss=1.4236, lr=0.0010
[2025-05-05 00:57:57,120][train][INFO] - Epoch 71/100, Val Acc=0.7119, Val Loss=1.3671, lr=0.0010
[2025-05-05 00:58:01,169][train][INFO] - Epoch 71/100, Val Acc=0.6897, Val Loss=1.4149, lr=0.0010
[2025-05-05 00:58:05,117][train][INFO] - Epoch 72/100, Val Acc=0.7120, Val Loss=1.3646, lr=0.0010
[2025-05-05 00:58:09,057][train][INFO] - Epoch 72/100, Val Acc=0.6882, Val Loss=1.4246, lr=0.0010
[2025-05-05 00:58:09,480][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9433, lr=0.001
[2025-05-05 00:58:13,337][train][INFO] - Epoch 73/100, Val Acc=0.7104, Val Loss=1.3774, lr=0.0010
[2025-05-05 00:58:16,768][train][INFO] - Epoch 73/100, Val Acc=0.6875, Val Loss=1.4249, lr=0.0010
[2025-05-05 00:58:21,537][train][INFO] - Epoch 74/100, Val Acc=0.7123, Val Loss=1.3743, lr=0.0010
[2025-05-05 00:58:24,117][train][INFO] - Epoch 74/100, Val Acc=0.6877, Val Loss=1.4326, lr=0.0010
[2025-05-05 00:58:29,697][train][INFO] - Epoch 75/100, Val Acc=0.7175, Val Loss=1.3727, lr=0.0010
[2025-05-05 00:58:30,126][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.9208, lr=0.001
[2025-05-05 00:58:30,153][meta_train][INFO] - epoch_5 saved !
[2025-05-05 00:58:32,677][train][INFO] - Epoch 75/100, Val Acc=0.6911, Val Loss=1.4296, lr=0.0010
[2025-05-05 00:58:37,473][train][INFO] - Epoch 76/100, Val Acc=0.7126, Val Loss=1.3762, lr=0.0010
[2025-05-05 00:58:40,133][train][INFO] - Epoch 76/100, Val Acc=0.6909, Val Loss=1.4348, lr=0.0010
[2025-05-05 00:58:45,134][train][INFO] - Epoch 77/100, Val Acc=0.7129, Val Loss=1.3816, lr=0.0010
[2025-05-05 00:58:48,037][train][INFO] - Epoch 77/100, Val Acc=0.6868, Val Loss=1.4609, lr=0.0010
[2025-05-05 00:58:49,256][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.4155, lr=0.001
[2025-05-05 00:58:53,305][train][INFO] - Epoch 78/100, Val Acc=0.7142, Val Loss=1.3822, lr=0.0010
[2025-05-05 00:58:55,529][train][INFO] - Epoch 78/100, Val Acc=0.6858, Val Loss=1.4559, lr=0.0010
[2025-05-05 00:59:00,645][train][INFO] - Epoch 79/100, Val Acc=0.7150, Val Loss=1.3808, lr=0.0010
[2025-05-05 00:59:03,618][train][INFO] - Epoch 79/100, Val Acc=0.6865, Val Loss=1.4616, lr=0.0010
[2025-05-05 00:59:08,258][train][INFO] - Epoch 80/100, Val Acc=0.7173, Val Loss=1.3823, lr=0.0010
[2025-05-05 00:59:08,864][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=5.3798, lr=0.001
[2025-05-05 00:59:11,514][train][INFO] - Epoch 80/100, Val Acc=0.6904, Val Loss=1.4654, lr=0.0010
[2025-05-05 00:59:16,155][train][INFO] - Epoch 81/100, Val Acc=0.7155, Val Loss=1.3889, lr=0.0010
[2025-05-05 00:59:19,178][train][INFO] - Epoch 81/100, Val Acc=0.6910, Val Loss=1.4625, lr=0.0010
[2025-05-05 00:59:24,033][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3850, lr=0.0010
[2025-05-05 00:59:26,769][train][INFO] - Epoch 82/100, Val Acc=0.6890, Val Loss=1.4836, lr=0.0010
[2025-05-05 00:59:29,951][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.8268, lr=0.001
[2025-05-05 00:59:31,827][train][INFO] - Epoch 83/100, Val Acc=0.7137, Val Loss=1.3925, lr=0.0010
[2025-05-05 00:59:34,523][train][INFO] - Epoch 83/100, Val Acc=0.6909, Val Loss=1.4772, lr=0.0010
[2025-05-05 00:59:39,951][train][INFO] - Epoch 84/100, Val Acc=0.7180, Val Loss=1.3901, lr=0.0010
[2025-05-05 00:59:42,570][train][INFO] - Epoch 84/100, Val Acc=0.6897, Val Loss=1.4862, lr=0.0010
[2025-05-05 00:59:47,893][train][INFO] - Epoch 85/100, Val Acc=0.7139, Val Loss=1.3990, lr=0.0010
[2025-05-05 00:59:50,271][train][INFO] - Epoch 85/100, Val Acc=0.6899, Val Loss=1.4859, lr=0.0010
[2025-05-05 00:59:50,832][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.0371, lr=0.001
[2025-05-05 00:59:55,860][train][INFO] - Epoch 86/100, Val Acc=0.7124, Val Loss=1.3928, lr=0.0010
[2025-05-05 00:59:57,979][train][INFO] - Epoch 86/100, Val Acc=0.6874, Val Loss=1.4887, lr=0.0010
[2025-05-05 01:00:03,704][train][INFO] - Epoch 87/100, Val Acc=0.7152, Val Loss=1.3998, lr=0.0010
[2025-05-05 01:00:05,438][train][INFO] - Epoch 87/100, Val Acc=0.6910, Val Loss=1.4962, lr=0.0010
[2025-05-05 01:00:09,575][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=7.7631, lr=0.001
[2025-05-05 01:00:11,587][train][INFO] - Epoch 88/100, Val Acc=0.7128, Val Loss=1.3987, lr=0.0010
[2025-05-05 01:00:13,450][train][INFO] - Epoch 88/100, Val Acc=0.6873, Val Loss=1.5032, lr=0.0010
[2025-05-05 01:00:19,610][train][INFO] - Epoch 89/100, Val Acc=0.7129, Val Loss=1.3956, lr=0.0010
[2025-05-05 01:00:21,421][train][INFO] - Epoch 89/100, Val Acc=0.6893, Val Loss=1.5113, lr=0.0010
[2025-05-05 01:00:27,388][train][INFO] - Epoch 90/100, Val Acc=0.7141, Val Loss=1.3995, lr=0.0010
[2025-05-05 01:00:29,606][train][INFO] - Epoch 90/100, Val Acc=0.6878, Val Loss=1.5039, lr=0.0010
[2025-05-05 01:00:29,851][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=5.8688, lr=0.001
[2025-05-05 01:00:35,341][train][INFO] - Epoch 91/100, Val Acc=0.7133, Val Loss=1.3956, lr=0.0001
[2025-05-05 01:00:37,596][train][INFO] - Epoch 91/100, Val Acc=0.6908, Val Loss=1.4995, lr=0.0001
[2025-05-05 01:00:43,538][train][INFO] - Epoch 92/100, Val Acc=0.7160, Val Loss=1.3949, lr=0.0001
[2025-05-05 01:00:45,405][train][INFO] - Epoch 92/100, Val Acc=0.6901, Val Loss=1.5021, lr=0.0001
[2025-05-05 01:00:49,473][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=5.0059, lr=0.001
[2025-05-05 01:00:51,248][train][INFO] - Epoch 93/100, Val Acc=0.7150, Val Loss=1.3958, lr=0.0001
[2025-05-05 01:00:53,470][train][INFO] - Epoch 93/100, Val Acc=0.6910, Val Loss=1.5012, lr=0.0001
[2025-05-05 01:00:59,283][train][INFO] - Epoch 94/100, Val Acc=0.7142, Val Loss=1.3935, lr=0.0001
[2025-05-05 01:01:01,581][train][INFO] - Epoch 94/100, Val Acc=0.6907, Val Loss=1.4934, lr=0.0001
[2025-05-05 01:01:07,155][train][INFO] - Epoch 95/100, Val Acc=0.7153, Val Loss=1.3954, lr=0.0001
[2025-05-05 01:01:09,382][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=8.3281, lr=0.001
[2025-05-05 01:01:09,425][meta_train][INFO] - epoch_6 saved !
[2025-05-05 01:01:09,467][train][INFO] - Epoch 95/100, Val Acc=0.6906, Val Loss=1.5044, lr=0.0001
[2025-05-05 01:01:14,358][train][INFO] - Epoch 96/100, Val Acc=0.7164, Val Loss=1.3949, lr=0.0001
[2025-05-05 01:01:17,210][train][INFO] - Epoch 96/100, Val Acc=0.6910, Val Loss=1.4925, lr=0.0001
[2025-05-05 01:01:21,673][train][INFO] - Epoch 97/100, Val Acc=0.7145, Val Loss=1.3957, lr=0.0001
[2025-05-05 01:01:24,901][train][INFO] - Epoch 97/100, Val Acc=0.6901, Val Loss=1.5008, lr=0.0001
[2025-05-05 01:01:29,135][train][INFO] - Epoch 98/100, Val Acc=0.7158, Val Loss=1.3916, lr=0.0001
[2025-05-05 01:01:29,790][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.9874, lr=0.001
[2025-05-05 01:01:32,781][train][INFO] - Epoch 98/100, Val Acc=0.6920, Val Loss=1.4958, lr=0.0001
[2025-05-05 01:01:37,144][train][INFO] - Epoch 99/100, Val Acc=0.7146, Val Loss=1.3989, lr=0.0001
[2025-05-05 01:01:40,447][train][INFO] - Epoch 99/100, Val Acc=0.6924, Val Loss=1.5032, lr=0.0001
[2025-05-05 01:01:44,931][train][INFO] - Epoch 100/100, Val Acc=0.7158, Val Loss=1.3953, lr=0.0001
[2025-05-05 01:01:48,230][train][INFO] - Epoch 100/100, Val Acc=0.6912, Val Loss=1.4984, lr=0.0001
[2025-05-05 01:01:49,394][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=7.0864, lr=0.001
[2025-05-05 01:01:50,064][train][INFO] - After training : Train Acc=0.9968  Val Acc=0.7180
[2025-05-05 01:01:50,071][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 01:01:53,284][train][INFO] - After training : Train Acc=0.9897  Val Acc=0.6924
[2025-05-05 01:01:53,289][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 01:02:08,801][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=8.5477, lr=0.001
[2025-05-05 01:02:29,762][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7421, lr=0.001
[2025-05-05 01:02:50,618][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=5.0420, lr=0.001
[2025-05-05 01:03:10,243][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=5.7017, lr=0.001
[2025-05-05 01:03:29,774][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=8.2784, lr=0.001
[2025-05-05 01:03:32,703][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 01:03:33,628][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 01:03:49,956][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=6.2093, lr=0.001
[2025-05-05 01:03:49,973][meta_train][INFO] - epoch_7 saved !
[2025-05-05 01:04:09,311][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=8.2074, lr=0.0001
[2025-05-05 01:04:29,994][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=6.1988, lr=0.0001
[2025-05-05 01:04:50,838][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=5.0138, lr=0.0001
[2025-05-05 01:05:11,940][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.8598, lr=0.0001
[2025-05-05 01:05:20,665][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 01:05:21,145][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 01:05:23,710][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 01:05:24,138][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 01:05:31,160][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=8.7768, lr=0.0001
[2025-05-05 01:05:49,755][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=5.6787, lr=0.0001
[2025-05-05 01:06:09,492][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7615, lr=0.0001
[2025-05-05 01:06:28,149][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=7.0779, lr=0.0001
[2025-05-05 01:06:28,165][meta_train][INFO] - epoch_8 saved !
[2025-05-05 01:06:47,033][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=5.6857, lr=0.0001
[2025-05-05 01:07:05,281][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=8.2956, lr=0.0001
[2025-05-05 01:07:24,080][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=8.8010, lr=0.0001
[2025-05-05 01:07:44,367][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7625, lr=0.0001
[2025-05-05 01:08:04,101][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.8548, lr=0.0001
[2025-05-05 01:08:22,494][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=7.0522, lr=0.0001
[2025-05-05 01:08:42,144][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=6.2115, lr=0.0001
[2025-05-05 01:09:01,304][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=5.0050, lr=0.0001
[2025-05-05 01:09:01,328][meta_train][INFO] - epoch_9 saved !
[2025-05-05 01:09:20,183][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=5.6671, lr=0.0001
[2025-05-05 01:09:38,865][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=8.8096, lr=0.0001
[2025-05-05 01:09:57,966][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=5.0010, lr=0.0001
[2025-05-05 01:10:16,700][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=7.0029, lr=0.0001
[2025-05-05 01:10:34,969][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=8.2818, lr=0.0001
[2025-05-05 01:10:55,133][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.7620, lr=0.0001
[2025-05-05 01:11:14,468][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=6.1951, lr=0.0001
[2025-05-05 01:11:34,681][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.8410, lr=0.0001
[2025-05-05 01:11:34,701][meta_train][INFO] - epoch_10 saved !
[2025-05-05 01:11:52,965][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=8.2884, lr=0.0001
[2025-05-05 01:12:13,035][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.8391, lr=0.0001
[2025-05-05 01:12:31,421][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=8.7981, lr=0.0001
[2025-05-05 01:12:50,631][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=6.1797, lr=0.0001
[2025-05-05 01:13:08,672][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=6.9585, lr=0.0001
[2025-05-05 01:13:28,824][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.7602, lr=0.0001
[2025-05-05 01:13:48,619][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.9897, lr=0.0001
[2025-05-05 01:14:07,148][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=5.6426, lr=0.0001
[2025-05-05 01:14:07,164][meta_train][INFO] - epoch_11 saved !
[2025-05-05 01:14:25,637][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=8.2621, lr=0.0001
[2025-05-05 01:14:44,093][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=8.7789, lr=0.0001
[2025-05-05 01:15:03,398][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=6.1620, lr=0.0001
[2025-05-05 01:15:23,823][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.8286, lr=0.0001
[2025-05-05 01:15:43,311][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.7590, lr=0.0001
[2025-05-05 01:16:02,633][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.9846, lr=0.0001
[2025-05-05 01:16:21,611][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=6.9095, lr=0.0001
[2025-05-05 01:16:40,256][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=5.6297, lr=0.0001
[2025-05-05 01:16:40,273][meta_train][INFO] - epoch_12 saved !
[2025-05-05 01:16:58,191][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=8.2430, lr=0.0001
[2025-05-05 01:17:16,543][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=6.8879, lr=0.0001
[2025-05-05 01:17:35,083][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=5.6195, lr=0.0001
[2025-05-05 01:17:54,542][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.9789, lr=0.0001
[2025-05-05 01:18:14,823][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.8208, lr=0.0001
[2025-05-05 01:18:34,148][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=6.1268, lr=0.0001
[2025-05-05 01:18:54,120][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.7571, lr=0.0001
[2025-05-05 01:19:12,778][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=8.7322, lr=0.0001
[2025-05-05 01:19:12,795][meta_train][INFO] - epoch_13 saved !
[2025-05-05 01:19:31,638][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=5.6112, lr=0.0001
[2025-05-05 01:19:50,843][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.9752, lr=0.0001
[2025-05-05 01:20:10,863][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.8173, lr=0.0001
[2025-05-05 01:20:31,080][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.7556, lr=0.0001
[2025-05-05 01:20:49,229][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=6.8336, lr=0.0001
[2025-05-05 01:21:08,350][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=6.1108, lr=0.0001
[2025-05-05 01:21:26,813][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=8.2065, lr=0.0001
[2025-05-05 01:21:45,378][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=8.7012, lr=0.0001
[2025-05-05 01:21:45,395][meta_train][INFO] - epoch_14 saved !
[2025-05-05 01:22:03,555][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=6.8001, lr=0.0001
[2025-05-05 01:22:23,496][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.7540, lr=0.0001
[2025-05-05 01:22:42,019][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=8.1714, lr=0.0001
[2025-05-05 01:23:01,965][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.8100, lr=0.0001
[2025-05-05 01:23:21,763][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=6.0802, lr=0.0001
[2025-05-05 01:23:28,492][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-05 01:23:28,545][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 01:23:28,545][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 01:23:28,545][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 01:23:39,280][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 14

[2025-05-05 01:23:39,336][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 01:23:39,336][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 01:23:39,336][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 01:23:41,016][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.9656, lr=0.0001
[2025-05-05 01:23:42,333][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 01:23:51,049][train][INFO] - Epoch 1/100, Val Acc=0.4674, Val Loss=2.0601, lr=0.0100
[2025-05-05 01:23:53,660][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 01:23:58,907][train][INFO] - Epoch 2/100, Val Acc=0.5508, Val Loss=1.7528, lr=0.0100
[2025-05-05 01:24:00,339][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=5.5797, lr=0.0001
[2025-05-05 01:24:01,119][train][INFO] - Epoch 1/100, Val Acc=0.3145, Val Loss=2.6099, lr=0.0100
[2025-05-05 01:24:07,079][train][INFO] - Epoch 3/100, Val Acc=0.5519, Val Loss=1.8014, lr=0.0100
[2025-05-05 01:24:09,238][train][INFO] - Epoch 2/100, Val Acc=0.5184, Val Loss=1.7797, lr=0.0100
[2025-05-05 01:24:15,718][train][INFO] - Epoch 4/100, Val Acc=0.6095, Val Loss=1.5514, lr=0.0100
[2025-05-05 01:24:17,367][train][INFO] - Epoch 3/100, Val Acc=0.5696, Val Loss=1.6480, lr=0.0100
[2025-05-05 01:24:19,860][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=8.6572, lr=0.0001
[2025-05-05 01:24:19,878][meta_train][INFO] - epoch_15 saved !
[2025-05-05 01:24:23,924][train][INFO] - Epoch 5/100, Val Acc=0.5969, Val Loss=1.6453, lr=0.0100
[2025-05-05 01:24:25,248][train][INFO] - Epoch 4/100, Val Acc=0.5913, Val Loss=1.5663, lr=0.0100
[2025-05-05 01:24:31,649][train][INFO] - Epoch 6/100, Val Acc=0.6036, Val Loss=1.6499, lr=0.0100
[2025-05-05 01:24:33,380][train][INFO] - Epoch 5/100, Val Acc=0.5947, Val Loss=1.6279, lr=0.0100
[2025-05-05 01:24:38,859][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=6.7554, lr=0.0001
[2025-05-05 01:24:39,565][train][INFO] - Epoch 7/100, Val Acc=0.6218, Val Loss=1.5171, lr=0.0100
[2025-05-05 01:24:41,172][train][INFO] - Epoch 6/100, Val Acc=0.5924, Val Loss=1.6410, lr=0.0100
[2025-05-05 01:24:47,499][train][INFO] - Epoch 8/100, Val Acc=0.6147, Val Loss=1.6171, lr=0.0100
[2025-05-05 01:24:48,763][train][INFO] - Epoch 7/100, Val Acc=0.6360, Val Loss=1.4580, lr=0.0100
[2025-05-05 01:24:55,679][train][INFO] - Epoch 9/100, Val Acc=0.6300, Val Loss=1.5482, lr=0.0100
[2025-05-05 01:24:56,683][train][INFO] - Epoch 8/100, Val Acc=0.6154, Val Loss=1.5807, lr=0.0100
[2025-05-05 01:24:59,011][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.9621, lr=0.0001
[2025-05-05 01:25:02,050][train][INFO] - Epoch 10/100, Val Acc=0.6136, Val Loss=1.6291, lr=0.0100
[2025-05-05 01:25:04,987][train][INFO] - Epoch 9/100, Val Acc=0.6157, Val Loss=1.5624, lr=0.0100
[2025-05-05 01:25:09,870][train][INFO] - Epoch 11/100, Val Acc=0.6268, Val Loss=1.5887, lr=0.0100
[2025-05-05 01:25:12,429][train][INFO] - Epoch 10/100, Val Acc=0.6287, Val Loss=1.5110, lr=0.0100
[2025-05-05 01:25:17,409][train][INFO] - Epoch 12/100, Val Acc=0.6526, Val Loss=1.4502, lr=0.0100
[2025-05-05 01:25:18,913][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=5.5667, lr=0.0001
[2025-05-05 01:25:20,333][train][INFO] - Epoch 11/100, Val Acc=0.6417, Val Loss=1.4398, lr=0.0100
[2025-05-05 01:25:24,943][train][INFO] - Epoch 13/100, Val Acc=0.6421, Val Loss=1.5210, lr=0.0100
[2025-05-05 01:25:27,807][train][INFO] - Epoch 12/100, Val Acc=0.6176, Val Loss=1.6037, lr=0.0100
[2025-05-05 01:25:32,433][train][INFO] - Epoch 14/100, Val Acc=0.6333, Val Loss=1.5462, lr=0.0100
[2025-05-05 01:25:35,474][train][INFO] - Epoch 13/100, Val Acc=0.6388, Val Loss=1.4867, lr=0.0100
[2025-05-05 01:25:38,256][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=8.6332, lr=0.0001
[2025-05-05 01:25:40,836][train][INFO] - Epoch 15/100, Val Acc=0.6454, Val Loss=1.5458, lr=0.0100
[2025-05-05 01:25:43,522][train][INFO] - Epoch 14/100, Val Acc=0.6268, Val Loss=1.5495, lr=0.0100
[2025-05-05 01:25:48,916][train][INFO] - Epoch 16/100, Val Acc=0.6396, Val Loss=1.5535, lr=0.0100
[2025-05-05 01:25:51,750][train][INFO] - Epoch 15/100, Val Acc=0.6478, Val Loss=1.5009, lr=0.0100
[2025-05-05 01:25:56,462][train][INFO] - Epoch 17/100, Val Acc=0.6464, Val Loss=1.5784, lr=0.0100
[2025-05-05 01:25:57,421][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=8.1262, lr=0.0001
[2025-05-05 01:25:59,695][train][INFO] - Epoch 16/100, Val Acc=0.6462, Val Loss=1.4939, lr=0.0100
[2025-05-05 01:26:04,712][train][INFO] - Epoch 18/100, Val Acc=0.6466, Val Loss=1.5756, lr=0.0100
[2025-05-05 01:26:07,431][train][INFO] - Epoch 17/100, Val Acc=0.6427, Val Loss=1.4947, lr=0.0100
[2025-05-05 01:26:12,924][train][INFO] - Epoch 19/100, Val Acc=0.6591, Val Loss=1.4969, lr=0.0100
[2025-05-05 01:26:15,212][train][INFO] - Epoch 18/100, Val Acc=0.6422, Val Loss=1.5638, lr=0.0100
[2025-05-05 01:26:17,773][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.8027, lr=0.0001
[2025-05-05 01:26:19,245][train][INFO] - Epoch 20/100, Val Acc=0.6560, Val Loss=1.5054, lr=0.0100
[2025-05-05 01:26:23,170][train][INFO] - Epoch 19/100, Val Acc=0.6610, Val Loss=1.4246, lr=0.0100
[2025-05-05 01:26:27,132][train][INFO] - Epoch 21/100, Val Acc=0.6488, Val Loss=1.5461, lr=0.0100
[2025-05-05 01:26:30,614][train][INFO] - Epoch 20/100, Val Acc=0.6526, Val Loss=1.5028, lr=0.0100
[2025-05-05 01:26:35,398][train][INFO] - Epoch 22/100, Val Acc=0.6431, Val Loss=1.6086, lr=0.0100
[2025-05-05 01:26:38,218][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=6.0454, lr=0.0001
[2025-05-05 01:26:38,630][train][INFO] - Epoch 21/100, Val Acc=0.6542, Val Loss=1.4940, lr=0.0100
[2025-05-05 01:26:43,212][train][INFO] - Epoch 23/100, Val Acc=0.6549, Val Loss=1.5370, lr=0.0100
[2025-05-05 01:26:46,555][train][INFO] - Epoch 22/100, Val Acc=0.6367, Val Loss=1.6043, lr=0.0100
[2025-05-05 01:26:50,887][train][INFO] - Epoch 24/100, Val Acc=0.6527, Val Loss=1.5105, lr=0.0100
[2025-05-05 01:26:54,296][train][INFO] - Epoch 23/100, Val Acc=0.6447, Val Loss=1.5372, lr=0.0100
[2025-05-05 01:26:58,909][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.7502, lr=0.0001
[2025-05-05 01:26:58,937][meta_train][INFO] - epoch_16 saved !
[2025-05-05 01:26:58,945][train][INFO] - Epoch 25/100, Val Acc=0.6405, Val Loss=1.6036, lr=0.0100
[2025-05-05 01:27:02,212][train][INFO] - Epoch 24/100, Val Acc=0.6476, Val Loss=1.5416, lr=0.0100
[2025-05-05 01:27:06,853][train][INFO] - Epoch 26/100, Val Acc=0.6555, Val Loss=1.5576, lr=0.0100
[2025-05-05 01:27:09,318][train][INFO] - Epoch 25/100, Val Acc=0.6541, Val Loss=1.4942, lr=0.0100
[2025-05-05 01:27:14,794][train][INFO] - Epoch 27/100, Val Acc=0.6369, Val Loss=1.6571, lr=0.0100
[2025-05-05 01:27:17,127][train][INFO] - Epoch 26/100, Val Acc=0.6460, Val Loss=1.6260, lr=0.0100
[2025-05-05 01:27:18,251][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=6.7058, lr=0.0001
[2025-05-05 01:27:23,193][train][INFO] - Epoch 28/100, Val Acc=0.6487, Val Loss=1.6421, lr=0.0100
[2025-05-05 01:27:25,136][train][INFO] - Epoch 27/100, Val Acc=0.6461, Val Loss=1.5820, lr=0.0100
[2025-05-05 01:27:31,125][train][INFO] - Epoch 29/100, Val Acc=0.6491, Val Loss=1.5979, lr=0.0100
[2025-05-05 01:27:33,287][train][INFO] - Epoch 28/100, Val Acc=0.6370, Val Loss=1.6223, lr=0.0100
[2025-05-05 01:27:38,993][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.8011, lr=0.0001
[2025-05-05 01:27:39,344][train][INFO] - Epoch 30/100, Val Acc=0.6667, Val Loss=1.5052, lr=0.0100
[2025-05-05 01:27:40,871][train][INFO] - Epoch 29/100, Val Acc=0.6522, Val Loss=1.5355, lr=0.0100
[2025-05-05 01:27:47,510][train][INFO] - Epoch 31/100, Val Acc=0.6376, Val Loss=1.6305, lr=0.0100
[2025-05-05 01:27:48,470][train][INFO] - Epoch 30/100, Val Acc=0.6524, Val Loss=1.5688, lr=0.0100
[2025-05-05 01:27:55,659][train][INFO] - Epoch 32/100, Val Acc=0.6492, Val Loss=1.6014, lr=0.0100
[2025-05-05 01:27:56,969][train][INFO] - Epoch 31/100, Val Acc=0.6422, Val Loss=1.6290, lr=0.0100
[2025-05-05 01:27:59,811][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.7497, lr=0.0001
[2025-05-05 01:28:03,672][train][INFO] - Epoch 33/100, Val Acc=0.6504, Val Loss=1.6257, lr=0.0100
[2025-05-05 01:28:04,628][train][INFO] - Epoch 32/100, Val Acc=0.6476, Val Loss=1.5788, lr=0.0100
[2025-05-05 01:28:11,719][train][INFO] - Epoch 34/100, Val Acc=0.6580, Val Loss=1.6117, lr=0.0100
[2025-05-05 01:28:12,133][train][INFO] - Epoch 33/100, Val Acc=0.6413, Val Loss=1.6042, lr=0.0100
[2025-05-05 01:28:19,248][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=8.1145, lr=0.0001
[2025-05-05 01:28:19,944][train][INFO] - Epoch 34/100, Val Acc=0.6571, Val Loss=1.5525, lr=0.0100
[2025-05-05 01:28:20,081][train][INFO] - Epoch 35/100, Val Acc=0.6350, Val Loss=1.7272, lr=0.0100
[2025-05-05 01:28:27,559][train][INFO] - Epoch 36/100, Val Acc=0.6490, Val Loss=1.5865, lr=0.0100
[2025-05-05 01:28:28,110][train][INFO] - Epoch 35/100, Val Acc=0.6599, Val Loss=1.5456, lr=0.0100
[2025-05-05 01:28:35,866][train][INFO] - Epoch 37/100, Val Acc=0.6523, Val Loss=1.5543, lr=0.0100
[2025-05-05 01:28:36,157][train][INFO] - Epoch 36/100, Val Acc=0.6468, Val Loss=1.5866, lr=0.0100
[2025-05-05 01:28:39,318][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=6.0399, lr=0.0001
[2025-05-05 01:28:43,016][train][INFO] - Epoch 38/100, Val Acc=0.6548, Val Loss=1.5922, lr=0.0100
[2025-05-05 01:28:44,145][train][INFO] - Epoch 37/100, Val Acc=0.6542, Val Loss=1.5581, lr=0.0100
[2025-05-05 01:28:51,045][train][INFO] - Epoch 39/100, Val Acc=0.6555, Val Loss=1.5990, lr=0.0100
[2025-05-05 01:28:51,616][train][INFO] - Epoch 38/100, Val Acc=0.6566, Val Loss=1.5323, lr=0.0100
[2025-05-05 01:28:58,978][train][INFO] - Epoch 40/100, Val Acc=0.6565, Val Loss=1.5582, lr=0.0100
[2025-05-05 01:28:59,007][train][INFO] - Epoch 39/100, Val Acc=0.6524, Val Loss=1.5878, lr=0.0100
[2025-05-05 01:28:59,431][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.9543, lr=0.0001
[2025-05-05 01:29:07,254][train][INFO] - Epoch 41/100, Val Acc=0.6548, Val Loss=1.5831, lr=0.0100
[2025-05-05 01:29:07,309][train][INFO] - Epoch 40/100, Val Acc=0.6563, Val Loss=1.5545, lr=0.0100
[2025-05-05 01:29:15,555][train][INFO] - Epoch 42/100, Val Acc=0.6287, Val Loss=1.7296, lr=0.0100
[2025-05-05 01:29:15,630][train][INFO] - Epoch 41/100, Val Acc=0.6610, Val Loss=1.5659, lr=0.0100
[2025-05-05 01:29:19,222][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=5.5454, lr=0.0001
[2025-05-05 01:29:23,393][train][INFO] - Epoch 43/100, Val Acc=0.6483, Val Loss=1.5996, lr=0.0100
[2025-05-05 01:29:23,831][train][INFO] - Epoch 42/100, Val Acc=0.6358, Val Loss=1.7035, lr=0.0100
[2025-05-05 01:29:30,638][train][INFO] - Epoch 44/100, Val Acc=0.6578, Val Loss=1.5907, lr=0.0100
[2025-05-05 01:29:31,988][train][INFO] - Epoch 43/100, Val Acc=0.6538, Val Loss=1.5793, lr=0.0100
[2025-05-05 01:29:38,062][train][INFO] - Epoch 45/100, Val Acc=0.6340, Val Loss=1.7221, lr=0.0100
[2025-05-05 01:29:38,458][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=8.5718, lr=0.0001
[2025-05-05 01:29:38,481][meta_train][INFO] - epoch_17 saved !
[2025-05-05 01:29:40,200][train][INFO] - Epoch 44/100, Val Acc=0.6231, Val Loss=1.7443, lr=0.0100
[2025-05-05 01:29:46,480][train][INFO] - Epoch 46/100, Val Acc=0.6488, Val Loss=1.6128, lr=0.0100
[2025-05-05 01:29:48,349][train][INFO] - Epoch 45/100, Val Acc=0.6469, Val Loss=1.5871, lr=0.0100
[2025-05-05 01:29:54,790][train][INFO] - Epoch 47/100, Val Acc=0.6468, Val Loss=1.6431, lr=0.0100
[2025-05-05 01:29:56,524][train][INFO] - Epoch 46/100, Val Acc=0.6407, Val Loss=1.6593, lr=0.0100
[2025-05-05 01:29:57,380][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=8.5646, lr=0.0001
[2025-05-05 01:30:03,316][train][INFO] - Epoch 48/100, Val Acc=0.6586, Val Loss=1.6003, lr=0.0100
[2025-05-05 01:30:04,050][train][INFO] - Epoch 47/100, Val Acc=0.6462, Val Loss=1.6231, lr=0.0100
[2025-05-05 01:30:11,892][train][INFO] - Epoch 48/100, Val Acc=0.6525, Val Loss=1.5721, lr=0.0100
[2025-05-05 01:30:11,939][train][INFO] - Epoch 49/100, Val Acc=0.6545, Val Loss=1.6393, lr=0.0100
[2025-05-05 01:30:17,977][train][INFO] - Epoch 49/100, Val Acc=0.6622, Val Loss=1.5365, lr=0.0100
[2025-05-05 01:30:18,561][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.7958, lr=0.0001
[2025-05-05 01:30:19,275][train][INFO] - Epoch 50/100, Val Acc=0.6470, Val Loss=1.6889, lr=0.0100
[2025-05-05 01:30:25,080][train][INFO] - Epoch 50/100, Val Acc=0.6459, Val Loss=1.6463, lr=0.0100
[2025-05-05 01:30:27,625][train][INFO] - Epoch 51/100, Val Acc=0.6599, Val Loss=1.5679, lr=0.0100
[2025-05-05 01:30:33,244][train][INFO] - Epoch 51/100, Val Acc=0.6535, Val Loss=1.6107, lr=0.0100
[2025-05-05 01:30:35,777][train][INFO] - Epoch 52/100, Val Acc=0.6412, Val Loss=1.7272, lr=0.0100
[2025-05-05 01:30:38,544][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.9495, lr=0.0001
[2025-05-05 01:30:40,311][train][INFO] - Epoch 52/100, Val Acc=0.6521, Val Loss=1.6013, lr=0.0100
[2025-05-05 01:30:44,032][train][INFO] - Epoch 53/100, Val Acc=0.6604, Val Loss=1.5560, lr=0.0100
[2025-05-05 01:30:47,863][train][INFO] - Epoch 53/100, Val Acc=0.6556, Val Loss=1.5828, lr=0.0100
[2025-05-05 01:30:51,883][train][INFO] - Epoch 54/100, Val Acc=0.6575, Val Loss=1.5747, lr=0.0100
[2025-05-05 01:30:55,770][train][INFO] - Epoch 54/100, Val Acc=0.6543, Val Loss=1.6247, lr=0.0100
[2025-05-05 01:30:57,714][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=6.6440, lr=0.0001
[2025-05-05 01:31:00,303][train][INFO] - Epoch 55/100, Val Acc=0.6442, Val Loss=1.6605, lr=0.0100
[2025-05-05 01:31:03,217][train][INFO] - Epoch 55/100, Val Acc=0.6462, Val Loss=1.6297, lr=0.0100
[2025-05-05 01:31:07,798][train][INFO] - Epoch 56/100, Val Acc=0.6504, Val Loss=1.6343, lr=0.0100
[2025-05-05 01:31:10,417][train][INFO] - Epoch 56/100, Val Acc=0.6511, Val Loss=1.5746, lr=0.0100
[2025-05-05 01:31:14,842][train][INFO] - Epoch 57/100, Val Acc=0.6600, Val Loss=1.5587, lr=0.0100
[2025-05-05 01:31:17,427][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=5.5331, lr=0.0001
[2025-05-05 01:31:18,295][train][INFO] - Epoch 57/100, Val Acc=0.6508, Val Loss=1.6338, lr=0.0100
[2025-05-05 01:31:23,182][train][INFO] - Epoch 58/100, Val Acc=0.6541, Val Loss=1.6106, lr=0.0100
[2025-05-05 01:31:26,056][train][INFO] - Epoch 58/100, Val Acc=0.6682, Val Loss=1.5133, lr=0.0100
[2025-05-05 01:31:30,918][train][INFO] - Epoch 59/100, Val Acc=0.6502, Val Loss=1.5802, lr=0.0100
[2025-05-05 01:31:34,143][train][INFO] - Epoch 59/100, Val Acc=0.6455, Val Loss=1.6571, lr=0.0100
[2025-05-05 01:31:38,036][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.7467, lr=0.0001
[2025-05-05 01:31:38,923][train][INFO] - Epoch 60/100, Val Acc=0.6546, Val Loss=1.6187, lr=0.0100
[2025-05-05 01:31:42,220][train][INFO] - Epoch 60/100, Val Acc=0.6499, Val Loss=1.6378, lr=0.0100
[2025-05-05 01:31:46,278][train][INFO] - Epoch 61/100, Val Acc=0.7076, Val Loss=1.3237, lr=0.0010
[2025-05-05 01:31:50,178][train][INFO] - Epoch 61/100, Val Acc=0.7089, Val Loss=1.3258, lr=0.0010
[2025-05-05 01:31:54,505][train][INFO] - Epoch 62/100, Val Acc=0.7127, Val Loss=1.3204, lr=0.0010
[2025-05-05 01:31:57,885][train][INFO] - Epoch 62/100, Val Acc=0.7130, Val Loss=1.3134, lr=0.0010
[2025-05-05 01:31:58,110][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=6.0141, lr=0.0001
[2025-05-05 01:32:02,276][train][INFO] - Epoch 63/100, Val Acc=0.7146, Val Loss=1.3257, lr=0.0010
[2025-05-05 01:32:06,288][train][INFO] - Epoch 63/100, Val Acc=0.7142, Val Loss=1.3234, lr=0.0010
[2025-05-05 01:32:10,754][train][INFO] - Epoch 64/100, Val Acc=0.7150, Val Loss=1.3310, lr=0.0010
[2025-05-05 01:32:14,439][train][INFO] - Epoch 64/100, Val Acc=0.7170, Val Loss=1.3238, lr=0.0010
[2025-05-05 01:32:17,735][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=8.0808, lr=0.0001
[2025-05-05 01:32:17,765][meta_train][INFO] - epoch_18 saved !
[2025-05-05 01:32:18,550][train][INFO] - Epoch 65/100, Val Acc=0.7148, Val Loss=1.3318, lr=0.0010
[2025-05-05 01:32:22,084][train][INFO] - Epoch 65/100, Val Acc=0.7201, Val Loss=1.3292, lr=0.0010
[2025-05-05 01:32:26,762][train][INFO] - Epoch 66/100, Val Acc=0.7149, Val Loss=1.3478, lr=0.0010
[2025-05-05 01:32:29,292][train][INFO] - Epoch 66/100, Val Acc=0.7180, Val Loss=1.3437, lr=0.0010
[2025-05-05 01:32:34,912][train][INFO] - Epoch 67/100, Val Acc=0.7172, Val Loss=1.3461, lr=0.0010
[2025-05-05 01:32:36,858][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=8.5229, lr=0.0001
[2025-05-05 01:32:37,126][train][INFO] - Epoch 67/100, Val Acc=0.7214, Val Loss=1.3359, lr=0.0010
[2025-05-05 01:32:43,019][train][INFO] - Epoch 68/100, Val Acc=0.7173, Val Loss=1.3456, lr=0.0010
[2025-05-05 01:32:45,274][train][INFO] - Epoch 68/100, Val Acc=0.7228, Val Loss=1.3326, lr=0.0010
[2025-05-05 01:32:50,515][train][INFO] - Epoch 69/100, Val Acc=0.7148, Val Loss=1.3548, lr=0.0010
[2025-05-05 01:32:52,972][train][INFO] - Epoch 69/100, Val Acc=0.7214, Val Loss=1.3440, lr=0.0010
[2025-05-05 01:32:55,972][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=6.6229, lr=0.0001
[2025-05-05 01:32:58,965][train][INFO] - Epoch 70/100, Val Acc=0.7203, Val Loss=1.3531, lr=0.0010
[2025-05-05 01:33:00,829][train][INFO] - Epoch 70/100, Val Acc=0.7206, Val Loss=1.3536, lr=0.0010
[2025-05-05 01:33:06,559][train][INFO] - Epoch 71/100, Val Acc=0.7189, Val Loss=1.3526, lr=0.0010
[2025-05-05 01:33:08,200][train][INFO] - Epoch 71/100, Val Acc=0.7195, Val Loss=1.3534, lr=0.0010
[2025-05-05 01:33:14,822][train][INFO] - Epoch 72/100, Val Acc=0.7164, Val Loss=1.3562, lr=0.0010
[2025-05-05 01:33:15,390][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=8.0504, lr=0.0001
[2025-05-05 01:33:15,611][train][INFO] - Epoch 72/100, Val Acc=0.7205, Val Loss=1.3511, lr=0.0010
[2025-05-05 01:33:21,369][train][INFO] - Epoch 73/100, Val Acc=0.7190, Val Loss=1.3518, lr=0.0010
[2025-05-05 01:33:23,996][train][INFO] - Epoch 73/100, Val Acc=0.7218, Val Loss=1.3540, lr=0.0010
[2025-05-05 01:33:29,900][train][INFO] - Epoch 74/100, Val Acc=0.7190, Val Loss=1.3619, lr=0.0010
[2025-05-05 01:33:31,515][train][INFO] - Epoch 74/100, Val Acc=0.7221, Val Loss=1.3516, lr=0.0010
[2025-05-05 01:33:35,933][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.7446, lr=0.0001
[2025-05-05 01:33:38,269][train][INFO] - Epoch 75/100, Val Acc=0.7199, Val Loss=1.3669, lr=0.0010
[2025-05-05 01:33:39,650][train][INFO] - Epoch 75/100, Val Acc=0.7203, Val Loss=1.3524, lr=0.0010
[2025-05-05 01:33:45,860][train][INFO] - Epoch 76/100, Val Acc=0.7197, Val Loss=1.3670, lr=0.0010
[2025-05-05 01:33:47,428][train][INFO] - Epoch 76/100, Val Acc=0.7274, Val Loss=1.3509, lr=0.0010
[2025-05-05 01:33:54,328][train][INFO] - Epoch 77/100, Val Acc=0.7188, Val Loss=1.3743, lr=0.0010
[2025-05-05 01:33:55,522][train][INFO] - Epoch 77/100, Val Acc=0.7240, Val Loss=1.3543, lr=0.0010
[2025-05-05 01:33:56,932][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.7894, lr=0.0001
[2025-05-05 01:34:01,714][train][INFO] - Epoch 78/100, Val Acc=0.7203, Val Loss=1.3673, lr=0.0010
[2025-05-05 01:34:02,953][train][INFO] - Epoch 78/100, Val Acc=0.7269, Val Loss=1.3571, lr=0.0010
[2025-05-05 01:34:10,043][train][INFO] - Epoch 79/100, Val Acc=0.7204, Val Loss=1.3692, lr=0.0010
[2025-05-05 01:34:11,024][train][INFO] - Epoch 79/100, Val Acc=0.7243, Val Loss=1.3638, lr=0.0010
[2025-05-05 01:34:16,422][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=5.5132, lr=0.0001
[2025-05-05 01:34:18,476][train][INFO] - Epoch 80/100, Val Acc=0.7221, Val Loss=1.3625, lr=0.0010
[2025-05-05 01:34:18,621][train][INFO] - Epoch 80/100, Val Acc=0.7266, Val Loss=1.3558, lr=0.0010
[2025-05-05 01:34:25,862][train][INFO] - Epoch 81/100, Val Acc=0.7206, Val Loss=1.3639, lr=0.0010
[2025-05-05 01:34:26,565][train][INFO] - Epoch 81/100, Val Acc=0.7268, Val Loss=1.3634, lr=0.0010
[2025-05-05 01:34:34,273][train][INFO] - Epoch 82/100, Val Acc=0.7222, Val Loss=1.3701, lr=0.0010
[2025-05-05 01:34:34,421][train][INFO] - Epoch 82/100, Val Acc=0.7258, Val Loss=1.3614, lr=0.0010
[2025-05-05 01:34:36,625][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.9432, lr=0.0001
[2025-05-05 01:34:42,590][train][INFO] - Epoch 83/100, Val Acc=0.7214, Val Loss=1.3707, lr=0.0010
[2025-05-05 01:34:42,721][train][INFO] - Epoch 83/100, Val Acc=0.7250, Val Loss=1.3698, lr=0.0010
[2025-05-05 01:34:50,717][train][INFO] - Epoch 84/100, Val Acc=0.7244, Val Loss=1.3779, lr=0.0010
[2025-05-05 01:34:51,025][train][INFO] - Epoch 84/100, Val Acc=0.7215, Val Loss=1.3719, lr=0.0010
[2025-05-05 01:34:57,086][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=5.9877, lr=0.0001
[2025-05-05 01:34:57,105][meta_train][INFO] - epoch_19 saved !
[2025-05-05 01:34:58,165][train][INFO] - Epoch 85/100, Val Acc=0.7236, Val Loss=1.3724, lr=0.0010
[2025-05-05 01:34:59,165][train][INFO] - Epoch 85/100, Val Acc=0.7191, Val Loss=1.3813, lr=0.0010
[2025-05-05 01:35:05,928][train][INFO] - Epoch 86/100, Val Acc=0.7271, Val Loss=1.3757, lr=0.0010
[2025-05-05 01:35:06,930][train][INFO] - Epoch 86/100, Val Acc=0.7198, Val Loss=1.3773, lr=0.0010
[2025-05-05 01:35:13,985][train][INFO] - Epoch 87/100, Val Acc=0.7263, Val Loss=1.3722, lr=0.0010
[2025-05-05 01:35:14,653][train][INFO] - Epoch 87/100, Val Acc=0.7205, Val Loss=1.3689, lr=0.0010
[2025-05-05 01:35:16,338][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=5.5149, lr=0.0001
[2025-05-05 01:35:21,651][train][INFO] - Epoch 88/100, Val Acc=0.7257, Val Loss=1.3699, lr=0.0010
[2025-05-05 01:35:23,090][train][INFO] - Epoch 88/100, Val Acc=0.7215, Val Loss=1.3628, lr=0.0010
[2025-05-05 01:35:29,982][train][INFO] - Epoch 89/100, Val Acc=0.7250, Val Loss=1.3813, lr=0.0010
[2025-05-05 01:35:31,238][train][INFO] - Epoch 89/100, Val Acc=0.7221, Val Loss=1.3649, lr=0.0010
[2025-05-05 01:35:36,730][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=5.9784, lr=0.0001
[2025-05-05 01:35:38,309][train][INFO] - Epoch 90/100, Val Acc=0.7261, Val Loss=1.3745, lr=0.0010
[2025-05-05 01:35:39,727][train][INFO] - Epoch 90/100, Val Acc=0.7243, Val Loss=1.3783, lr=0.0010
[2025-05-05 01:35:46,372][train][INFO] - Epoch 91/100, Val Acc=0.7287, Val Loss=1.3669, lr=0.0001
[2025-05-05 01:35:47,400][train][INFO] - Epoch 91/100, Val Acc=0.7236, Val Loss=1.3720, lr=0.0001
[2025-05-05 01:35:54,976][train][INFO] - Epoch 92/100, Val Acc=0.7279, Val Loss=1.3750, lr=0.0001
[2025-05-05 01:35:55,420][train][INFO] - Epoch 92/100, Val Acc=0.7237, Val Loss=1.3730, lr=0.0001
[2025-05-05 01:35:56,104][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=6.5736, lr=0.0001
[2025-05-05 01:36:03,154][train][INFO] - Epoch 93/100, Val Acc=0.7295, Val Loss=1.3685, lr=0.0001
[2025-05-05 01:36:03,436][train][INFO] - Epoch 93/100, Val Acc=0.7256, Val Loss=1.3701, lr=0.0001
[2025-05-05 01:36:11,146][train][INFO] - Epoch 94/100, Val Acc=0.7283, Val Loss=1.3647, lr=0.0001
[2025-05-05 01:36:11,828][train][INFO] - Epoch 94/100, Val Acc=0.7246, Val Loss=1.3668, lr=0.0001
[2025-05-05 01:36:15,062][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=8.4467, lr=0.0001
[2025-05-05 01:36:19,103][train][INFO] - Epoch 95/100, Val Acc=0.7284, Val Loss=1.3680, lr=0.0001
[2025-05-05 01:36:19,874][train][INFO] - Epoch 95/100, Val Acc=0.7248, Val Loss=1.3720, lr=0.0001
[2025-05-05 01:36:27,069][train][INFO] - Epoch 96/100, Val Acc=0.7290, Val Loss=1.3626, lr=0.0001
[2025-05-05 01:36:27,204][train][INFO] - Epoch 96/100, Val Acc=0.7249, Val Loss=1.3677, lr=0.0001
[2025-05-05 01:36:35,503][train][INFO] - Epoch 97/100, Val Acc=0.7280, Val Loss=1.3647, lr=0.0001
[2025-05-05 01:36:35,876][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.7420, lr=0.0001
[2025-05-05 01:36:35,915][train][INFO] - Epoch 97/100, Val Acc=0.7260, Val Loss=1.3695, lr=0.0001
[2025-05-05 01:36:43,559][train][INFO] - Epoch 98/100, Val Acc=0.7296, Val Loss=1.3617, lr=0.0001
[2025-05-05 01:36:43,612][train][INFO] - Epoch 98/100, Val Acc=0.7245, Val Loss=1.3646, lr=0.0001
[2025-05-05 01:36:51,631][train][INFO] - Epoch 99/100, Val Acc=0.7279, Val Loss=1.3663, lr=0.0001
[2025-05-05 01:36:51,648][train][INFO] - Epoch 99/100, Val Acc=0.7258, Val Loss=1.3724, lr=0.0001
[2025-05-05 01:36:56,991][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.7852, lr=0.0001
[2025-05-05 01:36:59,378][train][INFO] - Epoch 100/100, Val Acc=0.7270, Val Loss=1.3695, lr=0.0001
[2025-05-05 01:36:59,768][train][INFO] - Epoch 100/100, Val Acc=0.7261, Val Loss=1.3686, lr=0.0001
[2025-05-05 01:37:04,489][train][INFO] - After training : Train Acc=0.9982  Val Acc=0.7296
[2025-05-05 01:37:04,500][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 01:37:04,896][train][INFO] - After training : Train Acc=0.9983  Val Acc=0.7261
[2025-05-05 01:37:04,901][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 01:37:15,987][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=8.0162, lr=0.0001
[2025-05-05 01:37:36,552][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.9375, lr=0.0001
[2025-05-05 01:37:36,571][meta_train][INFO] - epoch_20 saved !
[2025-05-05 01:37:55,913][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=8.0159, lr=0.0001
[2025-05-05 01:38:15,714][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=8.4146, lr=0.0001
[2025-05-05 01:38:35,845][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=5.9405, lr=0.0001
[2025-05-05 01:38:47,084][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 01:38:56,385][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 01:38:56,763][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.7815, lr=0.0001
[2025-05-05 01:39:17,019][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=5.4758, lr=0.0001
[2025-05-05 01:39:37,919][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.7394, lr=0.0001
[2025-05-05 01:39:57,762][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=6.5120, lr=0.0001
[2025-05-05 01:40:18,220][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.9322, lr=0.0001
[2025-05-05 01:40:18,253][meta_train][INFO] - epoch_21 saved !
[2025-05-05 01:40:37,680][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 01:40:38,175][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 01:40:38,254][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.9319, lr=0.0001
[2025-05-05 01:40:54,366][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 01:40:54,830][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 01:40:58,432][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=5.9310, lr=0.0001
[2025-05-05 01:41:16,453][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=6.4991, lr=0.0001
[2025-05-05 01:41:36,230][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.7786, lr=0.0001
[2025-05-05 01:41:56,696][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.7376, lr=0.0001
[2025-05-05 01:42:14,596][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=7.9652, lr=0.0001
[2025-05-05 01:42:32,703][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=8.3309, lr=0.0001
[2025-05-05 01:42:51,253][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=5.4623, lr=0.0001
[2025-05-05 01:42:51,270][meta_train][INFO] - epoch_22 saved !
[2025-05-05 01:43:11,063][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.7763, lr=0.0001
[2025-05-05 01:43:30,364][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=5.8984, lr=0.0001
[2025-05-05 01:43:49,353][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=5.4549, lr=0.0001
[2025-05-05 01:44:08,999][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.9244, lr=0.0001
[2025-05-05 01:44:28,890][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.7356, lr=0.0001
[2025-05-05 01:44:47,086][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=8.2901, lr=0.0001
[2025-05-05 01:45:05,844][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=6.4508, lr=0.0001
[2025-05-05 01:45:23,879][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=7.9319, lr=0.0001
[2025-05-05 01:45:23,895][meta_train][INFO] - epoch_23 saved !
[2025-05-05 01:45:42,066][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=6.4253, lr=0.0001
[2025-05-05 01:46:02,162][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.7340, lr=0.0001
[2025-05-05 01:46:21,221][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.9200, lr=0.0001
[2025-05-05 01:46:40,390][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=5.4380, lr=0.0001
[2025-05-05 01:46:58,764][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=8.2373, lr=0.0001
[2025-05-05 01:47:19,015][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.7702, lr=0.0001
[2025-05-05 01:47:37,461][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=7.8976, lr=0.0001
[2025-05-05 01:47:56,817][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=5.8467, lr=0.0001
[2025-05-05 01:47:56,839][meta_train][INFO] - epoch_24 saved !
[2025-05-05 01:48:15,026][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=6.3756, lr=0.0001
[2025-05-05 01:48:34,412][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=5.8296, lr=0.0001
[2025-05-05 01:48:52,171][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=7.8595, lr=0.0001
[2025-05-05 01:49:10,563][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=8.1693, lr=0.0001
[2025-05-05 01:49:30,982][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7310, lr=0.0001
[2025-05-05 01:49:49,947][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.9119, lr=0.0001
[2025-05-05 01:50:10,021][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.7645, lr=0.0001
[2025-05-05 01:50:29,327][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=5.4064, lr=0.0001
[2025-05-05 01:50:29,348][meta_train][INFO] - epoch_25 saved !
[2025-05-05 01:50:49,113][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.7299, lr=0.0001
[2025-05-05 01:51:08,536][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.9095, lr=0.0001
[2025-05-05 01:51:26,749][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=7.8319, lr=0.0001
[2025-05-05 01:51:45,330][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=6.3256, lr=0.0001
[2025-05-05 01:52:03,843][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=8.1039, lr=0.0001
[2025-05-05 01:52:22,756][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=5.7882, lr=0.0001
[2025-05-05 01:52:41,980][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=5.3830, lr=0.0001
[2025-05-05 01:53:01,740][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.7599, lr=0.0001
[2025-05-05 01:53:01,756][meta_train][INFO] - epoch_26 saved !
[2025-05-05 01:53:21,753][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.7597, lr=0.0001
[2025-05-05 01:53:40,868][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.9034, lr=0.0001
[2025-05-05 01:53:59,599][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=8.0614, lr=0.0001
[2025-05-05 01:54:18,296][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=7.7974, lr=0.0001
[2025-05-05 01:54:38,187][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.7269, lr=0.0001
[2025-05-05 01:54:57,595][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=5.7633, lr=0.0001
[2025-05-05 01:55:16,442][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=5.3703, lr=0.0001
[2025-05-05 01:55:35,300][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=6.2660, lr=0.0001
[2025-05-05 01:55:35,316][meta_train][INFO] - epoch_27 saved !
[2025-05-05 01:55:54,481][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.8988, lr=0.0001
[2025-05-05 01:56:13,850][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=5.7522, lr=0.0001
[2025-05-05 01:56:32,031][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=7.7645, lr=0.0001
[2025-05-05 01:56:50,472][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=7.9822, lr=0.0001
[2025-05-05 01:57:10,617][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.7543, lr=0.0001
[2025-05-05 01:57:29,168][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=6.2206, lr=0.0001
[2025-05-05 01:57:47,871][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=5.3459, lr=0.0001
[2025-05-05 01:58:07,774][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7242, lr=0.0001
[2025-05-05 01:58:07,805][meta_train][INFO] - epoch_28 saved !
[2025-05-05 01:58:26,556][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=7.9436, lr=0.0001
[2025-05-05 01:58:46,400][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.7523, lr=0.0001
[2025-05-05 01:59:04,942][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=7.7144, lr=0.0001
[2025-05-05 01:59:24,159][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.8885, lr=0.0001
[2025-05-05 01:59:43,961][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=5.6967, lr=0.0001
[2025-05-05 02:00:04,269][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.7225, lr=0.0001
[2025-05-05 02:00:22,890][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=5.3304, lr=0.0001
[2025-05-05 02:00:41,210][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=6.1839, lr=0.0001
[2025-05-05 02:00:41,227][meta_train][INFO] - epoch_29 saved !
[2025-05-05 02:01:01,188][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.8857, lr=0.0001
[2025-05-05 02:01:21,091][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7216, lr=0.0001
[2025-05-05 02:01:40,574][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=5.6841, lr=0.0001
[2025-05-05 02:01:58,883][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=6.1608, lr=0.0001
[2025-05-05 02:02:17,563][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=5.3157, lr=0.0001
[2025-05-05 02:02:35,776][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=7.6842, lr=0.0001
[2025-05-05 02:02:55,702][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.7474, lr=0.0001
[2025-05-05 02:03:14,241][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=7.8304, lr=0.0001
[2025-05-05 02:03:14,256][meta_train][INFO] - epoch_30 saved !
[2025-05-05 02:03:34,660][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.7466, lr=0.0001
[2025-05-05 02:03:53,838][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.8787, lr=0.0001
[2025-05-05 02:04:13,235][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=5.6575, lr=0.0001
[2025-05-05 02:04:32,312][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=5.3017, lr=0.0001
[2025-05-05 02:04:50,868][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=7.7893, lr=0.0001
[2025-05-05 02:05:10,988][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.7188, lr=0.0001
[2025-05-05 02:05:29,406][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=6.1103, lr=0.0001
[2025-05-05 02:05:48,013][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=7.6395, lr=0.0001
[2025-05-05 02:05:48,029][meta_train][INFO] - epoch_31 saved !
[2025-05-05 02:06:07,983][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.7180, lr=0.0001
[2025-05-05 02:06:26,316][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=7.6267, lr=0.0001
[2025-05-05 02:06:45,799][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=5.6253, lr=0.0001
[2025-05-05 02:07:04,048][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=7.7250, lr=0.0001
[2025-05-05 02:07:24,028][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.7407, lr=0.0001
[2025-05-05 02:07:42,373][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=6.0634, lr=0.0001
[2025-05-05 02:08:00,914][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=5.2714, lr=0.0001
[2025-05-05 02:08:20,335][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.8665, lr=0.0001
[2025-05-05 02:08:20,356][meta_train][INFO] - epoch_32 saved !
[2025-05-05 02:08:40,218][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.7390, lr=0.0001
[2025-05-05 02:08:59,734][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.8652, lr=0.0001
[2025-05-05 02:09:18,224][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=7.5776, lr=0.0001
[2025-05-05 02:09:36,447][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=5.2606, lr=0.0001
[2025-05-05 02:09:55,021][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=7.6507, lr=0.0001
[2025-05-05 02:10:14,417][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=5.5796, lr=0.0001
[2025-05-05 02:10:32,870][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=6.0110, lr=0.0001
[2025-05-05 02:10:52,809][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.7143, lr=0.0001
[2025-05-05 02:10:52,832][meta_train][INFO] - epoch_33 saved !
[2025-05-05 02:11:13,114][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.7140, lr=0.0001
[2025-05-05 02:11:32,845][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=5.5717, lr=0.0001
[2025-05-05 02:11:51,325][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=6.0118, lr=0.0001
[2025-05-05 02:12:10,661][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.8565, lr=0.0001
[2025-05-05 02:12:29,234][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=5.2398, lr=0.0001
[2025-05-05 02:12:49,277][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.7344, lr=0.0001
[2025-05-05 02:13:07,829][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=7.5834, lr=0.0001
[2025-05-05 02:13:26,778][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=7.5414, lr=0.0001
[2025-05-05 02:13:26,795][meta_train][INFO] - epoch_34 saved !
[2025-05-05 02:13:45,309][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=7.5612, lr=0.0001
[2025-05-05 02:14:04,332][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.8501, lr=0.0001
[2025-05-05 02:14:23,931][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=5.5367, lr=0.0001
[2025-05-05 02:14:41,903][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=7.5035, lr=0.0001
[2025-05-05 02:15:00,849][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=5.2225, lr=0.0001
[2025-05-05 02:15:19,185][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=5.9463, lr=0.0001
[2025-05-05 02:15:39,438][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.7106, lr=0.0001
[2025-05-05 02:15:59,706][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.7290, lr=0.0001
[2025-05-05 02:15:59,726][meta_train][INFO] - epoch_35 saved !
[2025-05-05 02:16:19,803][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.7100, lr=0.0001
[2025-05-05 02:16:39,032][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=5.5125, lr=0.0001
[2025-05-05 02:16:57,367][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=7.4763, lr=0.0001
[2025-05-05 02:17:17,290][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.7277, lr=0.0001
[2025-05-05 02:17:35,705][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=5.9115, lr=0.0001
[2025-05-05 02:17:53,918][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=7.4463, lr=0.0001
[2025-05-05 02:18:13,001][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=5.1974, lr=0.0001
[2025-05-05 02:18:32,134][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.8388, lr=0.0001
[2025-05-05 02:18:32,153][meta_train][INFO] - epoch_36 saved !
[2025-05-05 02:18:50,768][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=5.1974, lr=0.0001
[2025-05-05 02:19:10,818][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.7080, lr=0.0001
[2025-05-05 02:19:29,482][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=5.8930, lr=0.0001
[2025-05-05 02:19:47,907][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=7.4057, lr=0.0001
[2025-05-05 02:20:07,268][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.8338, lr=0.0001
[2025-05-05 02:20:25,874][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=7.4074, lr=0.0001
[2025-05-05 02:20:45,580][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.7235, lr=0.0001
[2025-05-05 02:21:04,966][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=5.4685, lr=0.0001
[2025-05-05 02:21:04,982][meta_train][INFO] - epoch_37 saved !
[2025-05-05 02:21:24,720][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.7229, lr=0.0001
[2025-05-05 02:21:43,767][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.8314, lr=0.0001
[2025-05-05 02:22:04,038][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.7057, lr=0.0001
[2025-05-05 02:22:22,616][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=5.1747, lr=0.0001
[2025-05-05 02:22:40,819][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=7.3921, lr=0.0001
[2025-05-05 02:22:59,487][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=7.3359, lr=0.0001
[2025-05-05 02:23:18,972][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=5.4417, lr=0.0001
[2025-05-05 02:23:37,841][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=5.8264, lr=0.0001
[2025-05-05 02:23:37,857][meta_train][INFO] - epoch_38 saved !
[2025-05-05 02:23:56,593][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=5.1594, lr=0.0001
[2025-05-05 02:24:15,135][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=5.8248, lr=0.0001
[2025-05-05 02:24:35,429][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.7191, lr=0.0001
[2025-05-05 02:24:54,604][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=5.4276, lr=0.0001
[2025-05-05 02:25:13,841][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.8208, lr=0.0001
[2025-05-05 02:25:33,848][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.7034, lr=0.0001
[2025-05-05 02:25:52,366][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=7.2574, lr=0.0001
[2025-05-05 02:26:11,157][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=7.3297, lr=0.0001
[2025-05-05 02:26:11,186][meta_train][INFO] - epoch_39 saved !
[2025-05-05 02:26:29,399][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=5.7920, lr=0.0001
[2025-05-05 02:26:47,566][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=7.3195, lr=0.0001
[2025-05-05 02:27:06,657][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=5.3942, lr=0.0001
[2025-05-05 02:27:26,988][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=4.7139, lr=0.0001
[2025-05-05 02:27:47,333][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.7017, lr=0.0001
[2025-05-05 02:28:05,643][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=7.1932, lr=0.0001
[2025-05-05 02:28:25,141][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.8118, lr=0.0001
[2025-05-05 02:28:44,409][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=5.1254, lr=0.0001
[2025-05-05 02:28:44,437][meta_train][INFO] - epoch_40 saved !
[2025-05-05 02:29:03,533][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.8096, lr=0.0001
[2025-05-05 02:29:22,263][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=5.1234, lr=0.0001
[2025-05-05 02:29:42,483][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.7121, lr=0.0001
[2025-05-05 02:30:00,921][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=5.7436, lr=0.0001
[2025-05-05 02:30:18,940][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=7.1508, lr=0.0001
[2025-05-05 02:30:38,175][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=5.3602, lr=0.0001
[2025-05-05 02:30:56,364][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=7.2499, lr=0.0001
[2025-05-05 02:31:16,442][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6992, lr=0.0001
[2025-05-05 02:31:16,472][meta_train][INFO] - epoch_41 saved !
[2025-05-05 02:31:35,465][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=5.3558, lr=0.0001
[2025-05-05 02:31:54,190][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=7.2380, lr=0.0001
[2025-05-05 02:32:14,147][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.7087, lr=0.0001
[2025-05-05 02:32:33,331][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.8016, lr=0.0001
[2025-05-05 02:32:52,108][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=5.1023, lr=0.0001
[2025-05-05 02:33:12,381][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6979, lr=0.0001
[2025-05-05 02:33:30,922][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=7.0749, lr=0.0001
[2025-05-05 02:33:49,256][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=5.6861, lr=0.0001
[2025-05-05 02:33:49,285][meta_train][INFO] - epoch_42 saved !
[2025-05-05 02:34:07,657][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=7.1893, lr=0.0001
[2025-05-05 02:34:25,979][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=7.0470, lr=0.0001
[2025-05-05 02:34:45,995][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6967, lr=0.0001
[2025-05-05 02:35:04,718][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=5.0920, lr=0.0001
[2025-05-05 02:35:23,227][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=5.6710, lr=0.0001
[2025-05-05 02:35:43,163][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.7038, lr=0.0001
[2025-05-05 02:36:02,915][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.7926, lr=0.0001
[2025-05-05 02:36:22,005][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=5.3028, lr=0.0001
[2025-05-05 02:36:22,036][meta_train][INFO] - epoch_43 saved !
[2025-05-05 02:36:42,495][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6952, lr=0.0001
[2025-05-05 02:37:00,957][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=5.0822, lr=0.0001
[2025-05-05 02:37:20,356][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.7928, lr=0.0001
[2025-05-05 02:37:40,103][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=5.2987, lr=0.0001
[2025-05-05 02:37:58,735][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=6.9745, lr=0.0001
[2025-05-05 02:38:18,604][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.7017, lr=0.0001
[2025-05-05 02:38:37,180][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=5.6472, lr=0.0001
[2025-05-05 02:38:55,200][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=7.1737, lr=0.0001
[2025-05-05 02:38:55,217][meta_train][INFO] - epoch_44 saved !
[2025-05-05 02:39:14,166][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=5.0721, lr=0.0001
[2025-05-05 02:39:32,109][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=7.1513, lr=0.0001
[2025-05-05 02:39:50,604][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=5.6173, lr=0.0001
[2025-05-05 02:40:09,361][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=6.9190, lr=0.0001
[2025-05-05 02:40:29,532][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6930, lr=0.0001
[2025-05-05 02:40:48,939][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=5.2639, lr=0.0001
[2025-05-05 02:41:08,302][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.7815, lr=0.0001
[2025-05-05 02:41:28,412][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.6972, lr=0.0001
[2025-05-05 02:41:28,429][meta_train][INFO] - epoch_45 saved !
[2025-05-05 02:41:46,913][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=6.8783, lr=0.0001
[2025-05-05 02:42:05,942][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=5.2470, lr=0.0001
[2025-05-05 02:42:24,175][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=5.5687, lr=0.0001
[2025-05-05 02:42:43,020][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=5.0398, lr=0.0001
[2025-05-05 02:43:00,908][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=7.0670, lr=0.0001
[2025-05-05 02:43:21,229][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.6950, lr=0.0001
[2025-05-05 02:43:41,219][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.6908, lr=0.0001
[2025-05-05 02:44:00,740][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.7713, lr=0.0001
[2025-05-05 02:44:00,768][meta_train][INFO] - epoch_46 saved !
[2025-05-05 02:44:20,248][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=5.2252, lr=0.0001
[2025-05-05 02:44:38,645][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=6.8118, lr=0.0001
[2025-05-05 02:44:57,112][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=5.5427, lr=0.0001
[2025-05-05 02:45:17,357][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.6897, lr=0.0001
[2025-05-05 02:45:37,671][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.6924, lr=0.0001
[2025-05-05 02:45:56,135][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=5.0272, lr=0.0001
[2025-05-05 02:46:15,607][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.7700, lr=0.0001
[2025-05-05 02:46:34,045][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=7.0410, lr=0.0001
[2025-05-05 02:46:34,065][meta_train][INFO] - epoch_47 saved !
[2025-05-05 02:46:53,149][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=5.2088, lr=0.0001
[2025-05-05 02:47:13,259][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.6905, lr=0.0001
[2025-05-05 02:47:31,444][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=7.0179, lr=0.0001
[2025-05-05 02:47:50,810][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.7678, lr=0.0001
[2025-05-05 02:48:09,555][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=6.7495, lr=0.0001
[2025-05-05 02:48:27,661][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=5.5038, lr=0.0001
[2025-05-05 02:48:47,871][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.6874, lr=0.0001
[2025-05-05 02:49:06,907][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=5.0048, lr=0.0001
[2025-05-05 02:49:06,927][meta_train][INFO] - epoch_48 saved !
[2025-05-05 02:49:25,901][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=5.0123, lr=0.0001
[2025-05-05 02:49:45,631][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.6864, lr=0.0001
[2025-05-05 02:50:04,880][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.7619, lr=0.0001
[2025-05-05 02:50:24,953][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.6870, lr=0.0001
[2025-05-05 02:50:42,962][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=5.4859, lr=0.0001
[2025-05-05 02:51:02,240][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=5.1835, lr=0.0001
[2025-05-05 02:51:20,696][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=6.6906, lr=0.0001
[2025-05-05 02:51:39,110][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=6.9744, lr=0.0001
[2025-05-05 02:51:39,130][meta_train][INFO] - epoch_49 saved !
[2025-05-05 02:51:57,495][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=5.4789, lr=0.0001
[2025-05-05 02:52:17,810][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.6847, lr=0.0001
[2025-05-05 02:52:36,933][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=5.1670, lr=0.0001
[2025-05-05 02:52:55,427][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=6.9335, lr=0.0001
[2025-05-05 02:53:14,578][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.7544, lr=0.0001
[2025-05-05 02:53:32,734][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=6.6279, lr=0.0001
[2025-05-05 02:53:51,660][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.9782, lr=0.0001
[2025-05-05 02:54:11,422][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.6827, lr=0.0001
[2025-05-05 02:54:11,447][meta_train][INFO] - epoch_50 saved !
[2025-05-05 02:54:31,805][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.6827, lr=0.0001
[2025-05-05 02:54:50,146][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=5.4444, lr=0.0001
[2025-05-05 02:55:08,900][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=4.9759, lr=0.0001
[2025-05-05 02:55:27,493][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=6.8813, lr=0.0001
[2025-05-05 02:55:46,999][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=5.1354, lr=0.0001
[2025-05-05 02:56:06,239][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.7433, lr=0.0001
[2025-05-05 02:56:25,924][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6817, lr=0.0001
[2025-05-05 02:56:44,675][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=6.5595, lr=0.0001
[2025-05-05 02:56:44,691][meta_train][INFO] - epoch_51 saved !
[2025-05-05 02:57:04,572][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.6798, lr=0.0001
[2025-05-05 02:57:23,766][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.7432, lr=0.0001
[2025-05-05 02:57:43,075][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=5.1271, lr=0.0001
[2025-05-05 02:58:01,917][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.9612, lr=0.0001
[2025-05-05 02:58:20,476][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=6.8630, lr=0.0001
[2025-05-05 02:58:38,758][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=6.5299, lr=0.0001
[2025-05-05 02:58:58,710][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6798, lr=0.0001
[2025-05-05 02:59:17,113][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=5.3993, lr=0.0001
[2025-05-05 02:59:17,133][meta_train][INFO] - epoch_52 saved !
[2025-05-05 02:59:35,690][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=5.3987, lr=0.0001
[2025-05-05 02:59:54,187][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=6.8330, lr=0.0001
[2025-05-05 03:00:14,006][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6787, lr=0.0001
[2025-05-05 03:00:33,399][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.7356, lr=0.0001
[2025-05-05 03:00:53,481][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.6757, lr=0.0001
[2025-05-05 03:01:12,763][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.9469, lr=0.0001
[2025-05-05 03:01:31,660][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=5.0997, lr=0.0001
[2025-05-05 03:01:49,981][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=6.4593, lr=0.0001
[2025-05-05 03:01:49,997][meta_train][INFO] - epoch_53 saved !
[2025-05-05 03:02:10,277][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6772, lr=0.0001
[2025-05-05 03:02:28,077][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=5.3648, lr=0.0001
[2025-05-05 03:02:48,095][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.6746, lr=0.0001
[2025-05-05 03:03:06,744][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=6.4456, lr=0.0001
[2025-05-05 03:03:25,632][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.9364, lr=0.0001
[2025-05-05 03:03:44,845][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=5.0807, lr=0.0001
[2025-05-05 03:04:04,656][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.7311, lr=0.0001
[2025-05-05 03:04:22,619][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=6.7961, lr=0.0001
[2025-05-05 03:04:22,647][meta_train][INFO] - epoch_54 saved !
[2025-05-05 03:04:40,839][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=6.7857, lr=0.0001
[2025-05-05 03:05:00,771][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.6720, lr=0.0001
[2025-05-05 03:05:19,279][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=5.3413, lr=0.0001
[2025-05-05 03:05:37,582][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=6.3852, lr=0.0001
[2025-05-05 03:05:56,969][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=5.0628, lr=0.0001
[2025-05-05 03:06:15,663][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.9176, lr=0.0001
[2025-05-05 03:06:36,001][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6736, lr=0.0001
[2025-05-05 03:06:54,699][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.7250, lr=0.0001
[2025-05-05 03:06:54,727][meta_train][INFO] - epoch_55 saved !
[2025-05-05 03:07:14,412][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.7242, lr=0.0001
[2025-05-05 03:07:34,820][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6729, lr=0.0001
[2025-05-05 03:07:53,430][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.9118, lr=0.0001
[2025-05-05 03:08:13,879][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.6686, lr=0.0001
[2025-05-05 03:08:32,142][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=5.3189, lr=0.0001
[2025-05-05 03:08:51,677][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=5.0514, lr=0.0001
[2025-05-05 03:09:10,223][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=6.7200, lr=0.0001
[2025-05-05 03:09:28,608][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=6.3202, lr=0.0001
[2025-05-05 03:09:28,635][meta_train][INFO] - epoch_56 saved !
[2025-05-05 03:09:48,724][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.6674, lr=0.0001
[2025-05-05 03:10:08,303][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=5.0421, lr=0.0001
[2025-05-05 03:10:26,429][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=5.2960, lr=0.0001
[2025-05-05 03:10:46,533][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6705, lr=0.0001
[2025-05-05 03:11:04,721][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=6.6808, lr=0.0001
[2025-05-05 03:11:23,205][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=6.2805, lr=0.0001
[2025-05-05 03:11:42,174][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.8950, lr=0.0001
[2025-05-05 03:12:01,602][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.7124, lr=0.0001
[2025-05-05 03:12:01,619][meta_train][INFO] - epoch_57 saved !
[2025-05-05 03:12:22,032][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6693, lr=0.0001
[2025-05-05 03:12:41,178][meta_train][INFO] - Epoch 58/100, iter 2/8, train loss=5.0176, lr=0.0001
[2025-05-05 03:13:00,128][meta_train][INFO] - Epoch 58/100, iter 3/8, train loss=6.2416, lr=0.0001
[2025-05-05 03:13:18,445][meta_train][INFO] - Epoch 58/100, iter 4/8, train loss=5.2641, lr=0.0001
[2025-05-05 03:13:37,180][meta_train][INFO] - Epoch 58/100, iter 5/8, train loss=4.8873, lr=0.0001
[2025-05-05 03:13:55,497][meta_train][INFO] - Epoch 58/100, iter 6/8, train loss=6.6366, lr=0.0001
[2025-05-05 03:14:15,605][meta_train][INFO] - Epoch 58/100, iter 7/8, train loss=4.6624, lr=0.0001
[2025-05-05 03:14:34,911][meta_train][INFO] - Epoch 58/100, iter 8/8, train loss=4.7083, lr=0.0001
[2025-05-05 03:14:34,932][meta_train][INFO] - epoch_58 saved !
[2025-05-05 03:14:53,770][meta_train][INFO] - Epoch 59/100, iter 1/8, train loss=4.8806, lr=0.0001
[2025-05-05 03:15:13,728][meta_train][INFO] - Epoch 59/100, iter 2/8, train loss=4.6668, lr=0.0001
[2025-05-05 03:15:32,458][meta_train][INFO] - Epoch 59/100, iter 3/8, train loss=6.6061, lr=0.0001
[2025-05-05 03:15:51,033][meta_train][INFO] - Epoch 59/100, iter 4/8, train loss=5.2409, lr=0.0001
[2025-05-05 03:16:09,311][meta_train][INFO] - Epoch 59/100, iter 5/8, train loss=6.1804, lr=0.0001
[2025-05-05 03:16:28,577][meta_train][INFO] - Epoch 59/100, iter 6/8, train loss=4.9903, lr=0.0001
[2025-05-05 03:16:48,730][meta_train][INFO] - Epoch 59/100, iter 7/8, train loss=4.6600, lr=0.0001
[2025-05-05 03:17:07,698][meta_train][INFO] - Epoch 59/100, iter 8/8, train loss=4.7067, lr=0.0001
[2025-05-05 03:17:07,716][meta_train][INFO] - epoch_59 saved !
[2025-05-05 03:17:26,118][meta_train][INFO] - Epoch 60/100, iter 1/8, train loss=6.1598, lr=0.0001
[2025-05-05 03:17:44,841][meta_train][INFO] - Epoch 60/100, iter 2/8, train loss=4.8636, lr=0.0001
[2025-05-05 03:18:02,820][meta_train][INFO] - Epoch 60/100, iter 3/8, train loss=6.5608, lr=0.0001
[2025-05-05 03:18:22,908][meta_train][INFO] - Epoch 60/100, iter 4/8, train loss=4.6585, lr=0.0001
[2025-05-05 03:18:42,176][meta_train][INFO] - Epoch 60/100, iter 5/8, train loss=4.9804, lr=0.0001
[2025-05-05 03:19:01,537][meta_train][INFO] - Epoch 60/100, iter 6/8, train loss=4.7004, lr=0.0001
[2025-05-05 03:19:21,618][meta_train][INFO] - Epoch 60/100, iter 7/8, train loss=4.6633, lr=0.0001
[2025-05-05 03:19:40,473][meta_train][INFO] - Epoch 60/100, iter 8/8, train loss=5.2019, lr=0.0001
[2025-05-05 03:19:40,501][meta_train][INFO] - epoch_60 saved !
[2025-05-05 03:19:58,997][meta_train][INFO] - Epoch 61/100, iter 1/8, train loss=4.8591, lr=0.0001
[2025-05-05 03:20:18,737][meta_train][INFO] - Epoch 61/100, iter 2/8, train loss=4.7005, lr=0.0001
[2025-05-05 03:20:37,375][meta_train][INFO] - Epoch 61/100, iter 3/8, train loss=5.1992, lr=0.0001
[2025-05-05 03:20:57,305][meta_train][INFO] - Epoch 61/100, iter 4/8, train loss=4.6561, lr=0.0001
[2025-05-05 03:21:16,854][meta_train][INFO] - Epoch 61/100, iter 5/8, train loss=4.9659, lr=0.0001
[2025-05-05 03:21:36,820][meta_train][INFO] - Epoch 61/100, iter 6/8, train loss=4.6617, lr=0.0001
[2025-05-05 03:21:55,571][meta_train][INFO] - Epoch 61/100, iter 7/8, train loss=6.0913, lr=0.0001
[2025-05-05 03:22:14,000][meta_train][INFO] - Epoch 61/100, iter 8/8, train loss=6.5119, lr=0.0001
[2025-05-05 03:22:14,017][meta_train][INFO] - epoch_61 saved !
[2025-05-05 03:22:32,637][meta_train][INFO] - Epoch 62/100, iter 1/8, train loss=4.8475, lr=0.0001
[2025-05-05 03:22:53,130][meta_train][INFO] - Epoch 62/100, iter 2/8, train loss=4.6608, lr=0.0001
[2025-05-05 03:23:11,945][meta_train][INFO] - Epoch 62/100, iter 3/8, train loss=4.9578, lr=0.0001
[2025-05-05 03:23:31,955][meta_train][INFO] - Epoch 62/100, iter 4/8, train loss=4.6543, lr=0.0001
[2025-05-05 03:23:51,001][meta_train][INFO] - Epoch 62/100, iter 5/8, train loss=4.6976, lr=0.0001
[2025-05-05 03:24:09,306][meta_train][INFO] - Epoch 62/100, iter 6/8, train loss=5.1811, lr=0.0001
[2025-05-05 03:24:27,750][meta_train][INFO] - Epoch 62/100, iter 7/8, train loss=6.4775, lr=0.0001
[2025-05-05 03:24:46,165][meta_train][INFO] - Epoch 62/100, iter 8/8, train loss=6.0372, lr=0.0001
[2025-05-05 03:24:46,183][meta_train][INFO] - epoch_62 saved !
[2025-05-05 03:25:04,645][meta_train][INFO] - Epoch 63/100, iter 1/8, train loss=5.1564, lr=0.0001
[2025-05-05 03:25:24,832][meta_train][INFO] - Epoch 63/100, iter 2/8, train loss=4.6521, lr=0.0001
[2025-05-05 03:25:44,742][meta_train][INFO] - Epoch 63/100, iter 3/8, train loss=4.6584, lr=0.0001
[2025-05-05 03:26:02,848][meta_train][INFO] - Epoch 63/100, iter 4/8, train loss=6.4457, lr=0.0001
[2025-05-05 03:26:22,262][meta_train][INFO] - Epoch 63/100, iter 5/8, train loss=4.9346, lr=0.0001
[2025-05-05 03:26:41,454][meta_train][INFO] - Epoch 63/100, iter 6/8, train loss=4.6901, lr=0.0001
[2025-05-05 03:27:00,293][meta_train][INFO] - Epoch 63/100, iter 7/8, train loss=4.8268, lr=0.0001
[2025-05-05 03:27:18,629][meta_train][INFO] - Epoch 63/100, iter 8/8, train loss=5.9881, lr=0.0001
[2025-05-05 03:27:18,648][meta_train][INFO] - epoch_63 saved !
[2025-05-05 03:27:37,186][meta_train][INFO] - Epoch 64/100, iter 1/8, train loss=5.9777, lr=0.0001
[2025-05-05 03:27:55,668][meta_train][INFO] - Epoch 64/100, iter 2/8, train loss=6.3918, lr=0.0001
[2025-05-05 03:28:15,503][meta_train][INFO] - Epoch 64/100, iter 3/8, train loss=4.6491, lr=0.0001
[2025-05-05 03:28:34,495][meta_train][INFO] - Epoch 64/100, iter 4/8, train loss=4.8231, lr=0.0001
[2025-05-05 03:28:53,094][meta_train][INFO] - Epoch 64/100, iter 5/8, train loss=5.1362, lr=0.0001
[2025-05-05 03:29:12,328][meta_train][INFO] - Epoch 64/100, iter 6/8, train loss=4.6843, lr=0.0001
[2025-05-05 03:29:32,856][meta_train][INFO] - Epoch 64/100, iter 7/8, train loss=4.6549, lr=0.0001
[2025-05-05 03:29:52,007][meta_train][INFO] - Epoch 64/100, iter 8/8, train loss=4.9024, lr=0.0001
[2025-05-05 03:29:52,039][meta_train][INFO] - epoch_64 saved !
[2025-05-05 03:30:12,171][meta_train][INFO] - Epoch 65/100, iter 1/8, train loss=4.6544, lr=0.0001
[2025-05-05 03:30:30,418][meta_train][INFO] - Epoch 65/100, iter 2/8, train loss=5.1256, lr=0.0001
[2025-05-05 03:30:48,443][meta_train][INFO] - Epoch 65/100, iter 3/8, train loss=6.3628, lr=0.0001
[2025-05-05 03:31:08,471][meta_train][INFO] - Epoch 65/100, iter 4/8, train loss=4.6472, lr=0.0001
[2025-05-05 03:31:27,426][meta_train][INFO] - Epoch 65/100, iter 5/8, train loss=4.9021, lr=0.0001
[2025-05-05 03:31:45,766][meta_train][INFO] - Epoch 65/100, iter 6/8, train loss=5.9086, lr=0.0001
[2025-05-05 03:32:05,387][meta_train][INFO] - Epoch 65/100, iter 7/8, train loss=4.6811, lr=0.0001
[2025-05-05 03:32:24,005][meta_train][INFO] - Epoch 65/100, iter 8/8, train loss=4.8077, lr=0.0001
[2025-05-05 03:32:24,030][meta_train][INFO] - epoch_65 saved !
[2025-05-05 03:32:43,485][meta_train][INFO] - Epoch 66/100, iter 1/8, train loss=4.6820, lr=0.0001
[2025-05-05 03:33:03,841][meta_train][INFO] - Epoch 66/100, iter 2/8, train loss=4.6461, lr=0.0001
[2025-05-05 03:33:22,346][meta_train][INFO] - Epoch 66/100, iter 3/8, train loss=4.8064, lr=0.0001
[2025-05-05 03:33:40,849][meta_train][INFO] - Epoch 66/100, iter 4/8, train loss=5.1035, lr=0.0001
[2025-05-05 03:34:00,217][meta_train][INFO] - Epoch 66/100, iter 5/8, train loss=4.8984, lr=0.0001
[2025-05-05 03:34:18,361][meta_train][INFO] - Epoch 66/100, iter 6/8, train loss=6.3221, lr=0.0001
[2025-05-05 03:34:38,640][meta_train][INFO] - Epoch 66/100, iter 7/8, train loss=4.6506, lr=0.0001
[2025-05-05 03:34:57,013][meta_train][INFO] - Epoch 66/100, iter 8/8, train loss=5.8674, lr=0.0001
[2025-05-05 03:34:57,042][meta_train][INFO] - epoch_66 saved !
[2025-05-05 03:35:16,586][meta_train][INFO] - Epoch 67/100, iter 1/8, train loss=4.8881, lr=0.0001
[2025-05-05 03:35:36,489][meta_train][INFO] - Epoch 67/100, iter 2/8, train loss=4.6497, lr=0.0001
[2025-05-05 03:35:54,330][meta_train][INFO] - Epoch 67/100, iter 3/8, train loss=6.2734, lr=0.0001
[2025-05-05 03:36:13,001][meta_train][INFO] - Epoch 67/100, iter 4/8, train loss=5.8388, lr=0.0001
[2025-05-05 03:36:32,507][meta_train][INFO] - Epoch 67/100, iter 5/8, train loss=4.6736, lr=0.0001
[2025-05-05 03:36:52,209][meta_train][INFO] - Epoch 67/100, iter 6/8, train loss=4.6421, lr=0.0001
[2025-05-05 03:37:11,278][meta_train][INFO] - Epoch 67/100, iter 7/8, train loss=4.7870, lr=0.0001
[2025-05-05 03:37:29,437][meta_train][INFO] - Epoch 67/100, iter 8/8, train loss=5.0612, lr=0.0001
[2025-05-05 03:37:29,462][meta_train][INFO] - epoch_67 saved !
[2025-05-05 03:37:49,164][meta_train][INFO] - Epoch 68/100, iter 1/8, train loss=4.8672, lr=0.0001
[2025-05-05 03:38:09,203][meta_train][INFO] - Epoch 68/100, iter 2/8, train loss=4.6470, lr=0.0001
[2025-05-05 03:38:27,502][meta_train][INFO] - Epoch 68/100, iter 3/8, train loss=5.0525, lr=0.0001
[2025-05-05 03:38:46,611][meta_train][INFO] - Epoch 68/100, iter 4/8, train loss=4.6726, lr=0.0001
[2025-05-05 03:39:05,733][meta_train][INFO] - Epoch 68/100, iter 5/8, train loss=4.7849, lr=0.0001
[2025-05-05 03:39:25,606][meta_train][INFO] - Epoch 68/100, iter 6/8, train loss=4.6411, lr=0.0001
[2025-05-05 03:39:44,437][meta_train][INFO] - Epoch 68/100, iter 7/8, train loss=6.2360, lr=0.0001
[2025-05-05 03:40:02,805][meta_train][INFO] - Epoch 68/100, iter 8/8, train loss=5.7893, lr=0.0001
[2025-05-05 03:40:02,834][meta_train][INFO] - epoch_68 saved !
[2025-05-05 03:40:21,863][meta_train][INFO] - Epoch 69/100, iter 1/8, train loss=4.7793, lr=0.0001
[2025-05-05 03:40:41,488][meta_train][INFO] - Epoch 69/100, iter 2/8, train loss=4.6406, lr=0.0001
[2025-05-05 03:41:01,089][meta_train][INFO] - Epoch 69/100, iter 3/8, train loss=4.6713, lr=0.0001
[2025-05-05 03:41:19,510][meta_train][INFO] - Epoch 69/100, iter 4/8, train loss=6.2035, lr=0.0001
[2025-05-05 03:41:38,664][meta_train][INFO] - Epoch 69/100, iter 5/8, train loss=4.8512, lr=0.0001
[2025-05-05 03:41:59,072][meta_train][INFO] - Epoch 69/100, iter 6/8, train loss=4.6441, lr=0.0001
[2025-05-05 03:42:17,474][meta_train][INFO] - Epoch 69/100, iter 7/8, train loss=5.7568, lr=0.0001
[2025-05-05 03:42:35,953][meta_train][INFO] - Epoch 69/100, iter 8/8, train loss=5.0326, lr=0.0001
[2025-05-05 03:42:35,980][meta_train][INFO] - epoch_69 saved !
[2025-05-05 03:42:55,439][meta_train][INFO] - Epoch 70/100, iter 1/8, train loss=4.8458, lr=0.0001
[2025-05-05 03:43:13,793][meta_train][INFO] - Epoch 70/100, iter 2/8, train loss=4.7673, lr=0.0001
[2025-05-05 03:43:33,239][meta_train][INFO] - Epoch 70/100, iter 3/8, train loss=4.6651, lr=0.0001
[2025-05-05 03:43:52,151][meta_train][INFO] - Epoch 70/100, iter 4/8, train loss=5.7331, lr=0.0001
[2025-05-05 03:44:12,419][meta_train][INFO] - Epoch 70/100, iter 5/8, train loss=4.6422, lr=0.0001
[2025-05-05 03:44:32,173][meta_train][INFO] - Epoch 70/100, iter 6/8, train loss=4.6367, lr=0.0001
[2025-05-05 03:44:50,327][meta_train][INFO] - Epoch 70/100, iter 7/8, train loss=6.1468, lr=0.0001
[2025-05-05 03:45:08,806][meta_train][INFO] - Epoch 70/100, iter 8/8, train loss=5.0235, lr=0.0001
[2025-05-05 03:45:08,828][meta_train][INFO] - epoch_70 saved !
[2025-05-05 03:45:28,890][meta_train][INFO] - Epoch 71/100, iter 1/8, train loss=4.6370, lr=0.0001
[2025-05-05 03:45:46,986][meta_train][INFO] - Epoch 71/100, iter 2/8, train loss=6.1342, lr=0.0001
[2025-05-05 03:46:05,535][meta_train][INFO] - Epoch 71/100, iter 3/8, train loss=4.7584, lr=0.0001
[2025-05-05 03:46:23,836][meta_train][INFO] - Epoch 71/100, iter 4/8, train loss=5.6932, lr=0.0001
[2025-05-05 03:46:43,140][meta_train][INFO] - Epoch 71/100, iter 5/8, train loss=4.6611, lr=0.0001
[2025-05-05 03:47:03,033][meta_train][INFO] - Epoch 71/100, iter 6/8, train loss=4.6398, lr=0.0001
[2025-05-05 03:47:22,590][meta_train][INFO] - Epoch 71/100, iter 7/8, train loss=4.8226, lr=0.0001
[2025-05-05 03:47:41,054][meta_train][INFO] - Epoch 71/100, iter 8/8, train loss=4.9924, lr=0.0001
[2025-05-05 03:47:41,071][meta_train][INFO] - epoch_71 saved !
[2025-05-05 03:48:00,090][meta_train][INFO] - Epoch 72/100, iter 1/8, train loss=4.8255, lr=0.0001
[2025-05-05 03:48:20,268][meta_train][INFO] - Epoch 72/100, iter 2/8, train loss=4.6395, lr=0.0001
[2025-05-05 03:48:38,770][meta_train][INFO] - Epoch 72/100, iter 3/8, train loss=6.0756, lr=0.0001
[2025-05-05 03:48:58,009][meta_train][INFO] - Epoch 72/100, iter 4/8, train loss=4.6570, lr=0.0001
[2025-05-05 03:49:16,307][meta_train][INFO] - Epoch 72/100, iter 5/8, train loss=4.7508, lr=0.0001
[2025-05-05 03:49:34,721][meta_train][INFO] - Epoch 72/100, iter 6/8, train loss=4.9907, lr=0.0001
[2025-05-05 03:49:53,504][meta_train][INFO] - Epoch 72/100, iter 7/8, train loss=5.6468, lr=0.0001
[2025-05-05 03:50:13,760][meta_train][INFO] - Epoch 72/100, iter 8/8, train loss=4.6329, lr=0.0001
[2025-05-05 03:50:13,777][meta_train][INFO] - epoch_72 saved !
[2025-05-05 03:50:32,774][meta_train][INFO] - Epoch 73/100, iter 1/8, train loss=4.8112, lr=0.0001
[2025-05-05 03:50:51,936][meta_train][INFO] - Epoch 73/100, iter 2/8, train loss=4.7493, lr=0.0001
[2025-05-05 03:51:10,165][meta_train][INFO] - Epoch 73/100, iter 3/8, train loss=6.0619, lr=0.0001
[2025-05-05 03:51:30,703][meta_train][INFO] - Epoch 73/100, iter 4/8, train loss=4.6376, lr=0.0001
[2025-05-05 03:51:50,466][meta_train][INFO] - Epoch 73/100, iter 5/8, train loss=4.6320, lr=0.0001
[2025-05-05 03:52:09,142][meta_train][INFO] - Epoch 73/100, iter 6/8, train loss=5.6089, lr=0.0001
[2025-05-05 03:52:28,848][meta_train][INFO] - Epoch 73/100, iter 7/8, train loss=4.6552, lr=0.0001
[2025-05-05 03:52:46,817][meta_train][INFO] - Epoch 73/100, iter 8/8, train loss=4.9759, lr=0.0001
[2025-05-05 03:52:46,849][meta_train][INFO] - epoch_73 saved !
[2025-05-05 03:53:06,316][meta_train][INFO] - Epoch 74/100, iter 1/8, train loss=4.6541, lr=0.0001
[2025-05-05 03:53:24,987][meta_train][INFO] - Epoch 74/100, iter 2/8, train loss=5.5919, lr=0.0001
[2025-05-05 03:53:43,128][meta_train][INFO] - Epoch 74/100, iter 3/8, train loss=4.9608, lr=0.0001
[2025-05-05 03:54:03,287][meta_train][INFO] - Epoch 74/100, iter 4/8, train loss=4.6318, lr=0.0001
[2025-05-05 03:54:22,751][meta_train][INFO] - Epoch 74/100, iter 5/8, train loss=4.8091, lr=0.0001
[2025-05-05 03:54:42,301][meta_train][INFO] - Epoch 74/100, iter 6/8, train loss=4.6356, lr=0.0001
[2025-05-05 03:55:01,326][meta_train][INFO] - Epoch 74/100, iter 7/8, train loss=4.7364, lr=0.0001
[2025-05-05 03:55:19,388][meta_train][INFO] - Epoch 74/100, iter 8/8, train loss=5.9977, lr=0.0001
[2025-05-05 03:55:19,405][meta_train][INFO] - epoch_74 saved !
[2025-05-05 03:55:38,009][meta_train][INFO] - Epoch 75/100, iter 1/8, train loss=4.7408, lr=0.0001
[2025-05-05 03:55:57,267][meta_train][INFO] - Epoch 75/100, iter 2/8, train loss=4.6525, lr=0.0001
[2025-05-05 03:56:15,850][meta_train][INFO] - Epoch 75/100, iter 3/8, train loss=5.9857, lr=0.0001
[2025-05-05 03:56:35,748][meta_train][INFO] - Epoch 75/100, iter 4/8, train loss=4.6296, lr=0.0001
[2025-05-05 03:56:53,799][meta_train][INFO] - Epoch 75/100, iter 5/8, train loss=5.5482, lr=0.0001
[2025-05-05 03:57:12,689][meta_train][INFO] - Epoch 75/100, iter 6/8, train loss=4.7942, lr=0.0001
[2025-05-05 03:57:31,169][meta_train][INFO] - Epoch 75/100, iter 7/8, train loss=4.9431, lr=0.0001
[2025-05-05 03:57:51,191][meta_train][INFO] - Epoch 75/100, iter 8/8, train loss=4.6324, lr=0.0001
[2025-05-05 03:57:51,207][meta_train][INFO] - epoch_75 saved !
[2025-05-05 03:58:09,762][meta_train][INFO] - Epoch 76/100, iter 1/8, train loss=5.9252, lr=0.0001
[2025-05-05 03:58:29,879][meta_train][INFO] - Epoch 76/100, iter 2/8, train loss=4.6286, lr=0.0001
[2025-05-05 03:58:47,681][meta_train][INFO] - Epoch 76/100, iter 3/8, train loss=5.5220, lr=0.0001
[2025-05-05 03:59:07,113][meta_train][INFO] - Epoch 76/100, iter 4/8, train loss=4.6461, lr=0.0001
[2025-05-05 03:59:26,059][meta_train][INFO] - Epoch 76/100, iter 5/8, train loss=4.7230, lr=0.0001
[2025-05-05 03:59:44,758][meta_train][INFO] - Epoch 76/100, iter 6/8, train loss=4.7806, lr=0.0001
[2025-05-05 04:00:03,455][meta_train][INFO] - Epoch 76/100, iter 7/8, train loss=4.9281, lr=0.0001
[2025-05-05 04:00:23,276][meta_train][INFO] - Epoch 76/100, iter 8/8, train loss=4.6317, lr=0.0001
[2025-05-05 04:00:23,296][meta_train][INFO] - epoch_76 saved !
[2025-05-05 04:00:43,653][meta_train][INFO] - Epoch 77/100, iter 1/8, train loss=4.6311, lr=0.0001
[2025-05-05 04:01:01,746][meta_train][INFO] - Epoch 77/100, iter 2/8, train loss=5.8961, lr=0.0001
[2025-05-05 04:01:21,248][meta_train][INFO] - Epoch 77/100, iter 3/8, train loss=4.6455, lr=0.0001
[2025-05-05 04:01:40,051][meta_train][INFO] - Epoch 77/100, iter 4/8, train loss=4.7247, lr=0.0001
[2025-05-05 04:01:58,147][meta_train][INFO] - Epoch 77/100, iter 5/8, train loss=4.9251, lr=0.0001
[2025-05-05 04:02:17,669][meta_train][INFO] - Epoch 77/100, iter 6/8, train loss=4.7760, lr=0.0001
[2025-05-05 04:02:35,575][meta_train][INFO] - Epoch 77/100, iter 7/8, train loss=5.4725, lr=0.0001
[2025-05-05 04:02:55,365][meta_train][INFO] - Epoch 77/100, iter 8/8, train loss=4.6271, lr=0.0001
[2025-05-05 04:02:55,383][meta_train][INFO] - epoch_77 saved !
[2025-05-05 04:03:13,749][meta_train][INFO] - Epoch 78/100, iter 1/8, train loss=5.8827, lr=0.0001
[2025-05-05 04:03:33,471][meta_train][INFO] - Epoch 78/100, iter 2/8, train loss=4.6271, lr=0.0001
[2025-05-05 04:03:52,664][meta_train][INFO] - Epoch 78/100, iter 3/8, train loss=4.6428, lr=0.0001
[2025-05-05 04:04:11,628][meta_train][INFO] - Epoch 78/100, iter 4/8, train loss=4.7158, lr=0.0001
[2025-05-05 04:04:31,937][meta_train][INFO] - Epoch 78/100, iter 5/8, train loss=4.6301, lr=0.0001
[2025-05-05 04:04:50,441][meta_train][INFO] - Epoch 78/100, iter 6/8, train loss=5.4556, lr=0.0001
[2025-05-05 04:05:09,644][meta_train][INFO] - Epoch 78/100, iter 7/8, train loss=4.7702, lr=0.0001
[2025-05-05 04:05:28,025][meta_train][INFO] - Epoch 78/100, iter 8/8, train loss=4.9056, lr=0.0001
[2025-05-05 04:05:28,048][meta_train][INFO] - epoch_78 saved !
[2025-05-05 04:05:47,884][meta_train][INFO] - Epoch 79/100, iter 1/8, train loss=4.6261, lr=0.0001
[2025-05-05 04:06:08,061][meta_train][INFO] - Epoch 79/100, iter 2/8, train loss=4.6296, lr=0.0001
[2025-05-05 04:06:26,455][meta_train][INFO] - Epoch 79/100, iter 3/8, train loss=4.9048, lr=0.0001
[2025-05-05 04:06:45,353][meta_train][INFO] - Epoch 79/100, iter 4/8, train loss=4.7136, lr=0.0001
[2025-05-05 04:07:04,883][meta_train][INFO] - Epoch 79/100, iter 5/8, train loss=4.6423, lr=0.0001
[2025-05-05 04:07:24,103][meta_train][INFO] - Epoch 79/100, iter 6/8, train loss=4.7680, lr=0.0001
[2025-05-05 04:07:42,459][meta_train][INFO] - Epoch 79/100, iter 7/8, train loss=5.4239, lr=0.0001
[2025-05-05 04:08:00,889][meta_train][INFO] - Epoch 79/100, iter 8/8, train loss=5.8249, lr=0.0001
[2025-05-05 04:08:00,905][meta_train][INFO] - epoch_79 saved !
[2025-05-05 04:08:21,074][meta_train][INFO] - Epoch 80/100, iter 1/8, train loss=4.6281, lr=0.0001
[2025-05-05 04:08:41,341][meta_train][INFO] - Epoch 80/100, iter 2/8, train loss=4.6250, lr=0.0001
[2025-05-05 04:09:00,365][meta_train][INFO] - Epoch 80/100, iter 3/8, train loss=4.6411, lr=0.0001
[2025-05-05 04:09:18,639][meta_train][INFO] - Epoch 80/100, iter 4/8, train loss=4.8931, lr=0.0001
[2025-05-05 04:09:37,522][meta_train][INFO] - Epoch 80/100, iter 5/8, train loss=5.8079, lr=0.0001
[2025-05-05 04:09:56,716][meta_train][INFO] - Epoch 80/100, iter 6/8, train loss=4.7563, lr=0.0001
[2025-05-05 04:10:14,944][meta_train][INFO] - Epoch 80/100, iter 7/8, train loss=5.3903, lr=0.0001
[2025-05-05 04:10:33,908][meta_train][INFO] - Epoch 80/100, iter 8/8, train loss=4.7071, lr=0.0001
[2025-05-05 04:10:33,936][meta_train][INFO] - epoch_80 saved !
[2025-05-05 04:10:52,295][meta_train][INFO] - Epoch 81/100, iter 1/8, train loss=5.7927, lr=0.0001
[2025-05-05 04:11:10,459][meta_train][INFO] - Epoch 81/100, iter 2/8, train loss=4.8770, lr=0.0001
[2025-05-05 04:11:29,032][meta_train][INFO] - Epoch 81/100, iter 3/8, train loss=5.3647, lr=0.0001
[2025-05-05 04:11:49,017][meta_train][INFO] - Epoch 81/100, iter 4/8, train loss=4.6227, lr=0.0001
[2025-05-05 04:12:09,095][meta_train][INFO] - Epoch 81/100, iter 5/8, train loss=4.6255, lr=0.0001
[2025-05-05 04:12:28,664][meta_train][INFO] - Epoch 81/100, iter 6/8, train loss=4.6361, lr=0.0001
[2025-05-05 04:12:47,390][meta_train][INFO] - Epoch 81/100, iter 7/8, train loss=4.6987, lr=0.0001
[2025-05-05 04:13:06,880][meta_train][INFO] - Epoch 81/100, iter 8/8, train loss=4.7453, lr=0.0001
[2025-05-05 04:13:06,916][meta_train][INFO] - epoch_81 saved !
[2025-05-05 04:13:27,023][meta_train][INFO] - Epoch 82/100, iter 1/8, train loss=4.6249, lr=0.0001
[2025-05-05 04:13:45,729][meta_train][INFO] - Epoch 82/100, iter 2/8, train loss=4.8656, lr=0.0001
[2025-05-05 04:14:03,571][meta_train][INFO] - Epoch 82/100, iter 3/8, train loss=5.3433, lr=0.0001
[2025-05-05 04:14:22,498][meta_train][INFO] - Epoch 82/100, iter 4/8, train loss=4.6996, lr=0.0001
[2025-05-05 04:14:42,713][meta_train][INFO] - Epoch 82/100, iter 5/8, train loss=4.6225, lr=0.0001
[2025-05-05 04:15:01,076][meta_train][INFO] - Epoch 82/100, iter 6/8, train loss=5.7455, lr=0.0001
[2025-05-05 04:15:20,019][meta_train][INFO] - Epoch 82/100, iter 7/8, train loss=4.7413, lr=0.0001
[2025-05-05 04:15:39,287][meta_train][INFO] - Epoch 82/100, iter 8/8, train loss=4.6347, lr=0.0001
[2025-05-05 04:15:39,303][meta_train][INFO] - epoch_82 saved !
[2025-05-05 04:15:57,980][meta_train][INFO] - Epoch 83/100, iter 1/8, train loss=5.3268, lr=0.0001
[2025-05-05 04:16:17,851][meta_train][INFO] - Epoch 83/100, iter 2/8, train loss=4.6221, lr=0.0001
[2025-05-05 04:16:36,570][meta_train][INFO] - Epoch 83/100, iter 3/8, train loss=4.6963, lr=0.0001
[2025-05-05 04:16:56,588][meta_train][INFO] - Epoch 83/100, iter 4/8, train loss=4.6237, lr=0.0001
[2025-05-05 04:17:14,802][meta_train][INFO] - Epoch 83/100, iter 5/8, train loss=5.7262, lr=0.0001
[2025-05-05 04:17:34,436][meta_train][INFO] - Epoch 83/100, iter 6/8, train loss=4.6346, lr=0.0001
[2025-05-05 04:17:52,755][meta_train][INFO] - Epoch 83/100, iter 7/8, train loss=4.8618, lr=0.0001
[2025-05-05 04:18:12,473][meta_train][INFO] - Epoch 83/100, iter 8/8, train loss=4.7404, lr=0.0001
[2025-05-05 04:18:12,493][meta_train][INFO] - epoch_83 saved !
[2025-05-05 04:18:30,770][meta_train][INFO] - Epoch 84/100, iter 1/8, train loss=4.8525, lr=0.0001
[2025-05-05 04:18:50,164][meta_train][INFO] - Epoch 84/100, iter 2/8, train loss=4.6325, lr=0.0001
[2025-05-05 04:19:08,471][meta_train][INFO] - Epoch 84/100, iter 3/8, train loss=5.2935, lr=0.0001
[2025-05-05 04:19:29,139][meta_train][INFO] - Epoch 84/100, iter 4/8, train loss=4.6229, lr=0.0001
[2025-05-05 04:19:47,839][meta_train][INFO] - Epoch 84/100, iter 5/8, train loss=4.6917, lr=0.0001
[2025-05-05 04:20:07,719][meta_train][INFO] - Epoch 84/100, iter 6/8, train loss=4.6206, lr=0.0001
[2025-05-05 04:20:26,397][meta_train][INFO] - Epoch 84/100, iter 7/8, train loss=5.6951, lr=0.0001
[2025-05-05 04:20:45,560][meta_train][INFO] - Epoch 84/100, iter 8/8, train loss=4.7324, lr=0.0001
[2025-05-05 04:20:45,588][meta_train][INFO] - epoch_84 saved !
[2025-05-05 04:21:05,112][meta_train][INFO] - Epoch 85/100, iter 1/8, train loss=4.6313, lr=0.0001
[2025-05-05 04:21:23,549][meta_train][INFO] - Epoch 85/100, iter 2/8, train loss=5.6734, lr=0.0001
[2025-05-05 04:21:41,662][meta_train][INFO] - Epoch 85/100, iter 3/8, train loss=4.8423, lr=0.0001
[2025-05-05 04:22:00,276][meta_train][INFO] - Epoch 85/100, iter 4/8, train loss=5.2629, lr=0.0001
[2025-05-05 04:22:18,870][meta_train][INFO] - Epoch 85/100, iter 5/8, train loss=4.6840, lr=0.0001
[2025-05-05 04:22:39,176][meta_train][INFO] - Epoch 85/100, iter 6/8, train loss=4.6210, lr=0.0001
[2025-05-05 04:22:58,828][meta_train][INFO] - Epoch 85/100, iter 7/8, train loss=4.6190, lr=0.0001
[2025-05-05 04:23:18,455][meta_train][INFO] - Epoch 85/100, iter 8/8, train loss=4.7247, lr=0.0001
[2025-05-05 04:23:18,471][meta_train][INFO] - epoch_85 saved !
[2025-05-05 04:23:36,768][meta_train][INFO] - Epoch 86/100, iter 1/8, train loss=4.8315, lr=0.0001
[2025-05-05 04:23:55,443][meta_train][INFO] - Epoch 86/100, iter 2/8, train loss=4.6832, lr=0.0001
[2025-05-05 04:24:15,094][meta_train][INFO] - Epoch 86/100, iter 3/8, train loss=4.6190, lr=0.0001
[2025-05-05 04:24:34,542][meta_train][INFO] - Epoch 86/100, iter 4/8, train loss=4.6294, lr=0.0001
[2025-05-05 04:24:53,894][meta_train][INFO] - Epoch 86/100, iter 5/8, train loss=4.7233, lr=0.0001
[2025-05-05 04:25:12,470][meta_train][INFO] - Epoch 86/100, iter 6/8, train loss=5.2357, lr=0.0001
[2025-05-05 04:25:30,525][meta_train][INFO] - Epoch 86/100, iter 7/8, train loss=5.6304, lr=0.0001
[2025-05-05 04:25:50,280][meta_train][INFO] - Epoch 86/100, iter 8/8, train loss=4.6203, lr=0.0001
[2025-05-05 04:25:50,296][meta_train][INFO] - epoch_86 saved !
[2025-05-05 04:26:08,993][meta_train][INFO] - Epoch 87/100, iter 1/8, train loss=4.8258, lr=0.0001
[2025-05-05 04:26:27,110][meta_train][INFO] - Epoch 87/100, iter 2/8, train loss=4.6794, lr=0.0001
[2025-05-05 04:26:45,861][meta_train][INFO] - Epoch 87/100, iter 3/8, train loss=5.6170, lr=0.0001
[2025-05-05 04:27:03,957][meta_train][INFO] - Epoch 87/100, iter 4/8, train loss=5.2168, lr=0.0001
[2025-05-05 04:27:24,135][meta_train][INFO] - Epoch 87/100, iter 5/8, train loss=4.6193, lr=0.0001
[2025-05-05 04:27:44,256][meta_train][INFO] - Epoch 87/100, iter 6/8, train loss=4.6176, lr=0.0001
[2025-05-05 04:28:02,972][meta_train][INFO] - Epoch 87/100, iter 7/8, train loss=4.7154, lr=0.0001
[2025-05-05 04:28:22,410][meta_train][INFO] - Epoch 87/100, iter 8/8, train loss=4.6279, lr=0.0001
[2025-05-05 04:28:22,427][meta_train][INFO] - epoch_87 saved !
[2025-05-05 04:28:42,196][meta_train][INFO] - Epoch 88/100, iter 1/8, train loss=4.6175, lr=0.0001
[2025-05-05 04:29:01,553][meta_train][INFO] - Epoch 88/100, iter 2/8, train loss=4.6266, lr=0.0001
[2025-05-05 04:29:19,780][meta_train][INFO] - Epoch 88/100, iter 3/8, train loss=5.1938, lr=0.0001
[2025-05-05 04:29:38,821][meta_train][INFO] - Epoch 88/100, iter 4/8, train loss=4.6769, lr=0.0001
[2025-05-05 04:29:56,953][meta_train][INFO] - Epoch 88/100, iter 5/8, train loss=5.5932, lr=0.0001
[2025-05-05 04:30:16,632][meta_train][INFO] - Epoch 88/100, iter 6/8, train loss=4.7134, lr=0.0001
[2025-05-05 04:30:36,684][meta_train][INFO] - Epoch 88/100, iter 7/8, train loss=4.6182, lr=0.0001
[2025-05-05 04:30:55,399][meta_train][INFO] - Epoch 88/100, iter 8/8, train loss=4.8063, lr=0.0001
[2025-05-05 04:30:55,419][meta_train][INFO] - epoch_88 saved !
[2025-05-05 04:31:15,548][meta_train][INFO] - Epoch 89/100, iter 1/8, train loss=4.6182, lr=0.0001
[2025-05-05 04:31:34,936][meta_train][INFO] - Epoch 89/100, iter 2/8, train loss=4.7119, lr=0.0001
[2025-05-05 04:31:53,099][meta_train][INFO] - Epoch 89/100, iter 3/8, train loss=5.1729, lr=0.0001
[2025-05-05 04:32:11,543][meta_train][INFO] - Epoch 89/100, iter 4/8, train loss=4.8045, lr=0.0001
[2025-05-05 04:32:30,096][meta_train][INFO] - Epoch 89/100, iter 5/8, train loss=4.6716, lr=0.0001
[2025-05-05 04:32:49,383][meta_train][INFO] - Epoch 89/100, iter 6/8, train loss=4.6262, lr=0.0001
[2025-05-05 04:33:07,972][meta_train][INFO] - Epoch 89/100, iter 7/8, train loss=5.5664, lr=0.0001
[2025-05-05 04:33:27,923][meta_train][INFO] - Epoch 89/100, iter 8/8, train loss=4.6162, lr=0.0001
[2025-05-05 04:33:27,951][meta_train][INFO] - epoch_89 saved !
[2025-05-05 04:33:47,478][meta_train][INFO] - Epoch 90/100, iter 1/8, train loss=4.6249, lr=0.0001
[2025-05-05 04:34:06,679][meta_train][INFO] - Epoch 90/100, iter 2/8, train loss=4.7061, lr=0.0001
[2025-05-05 04:34:25,048][meta_train][INFO] - Epoch 90/100, iter 3/8, train loss=4.8021, lr=0.0001
[2025-05-05 04:34:45,052][meta_train][INFO] - Epoch 90/100, iter 4/8, train loss=4.6171, lr=0.0001
[2025-05-05 04:35:05,342][meta_train][INFO] - Epoch 90/100, iter 5/8, train loss=4.6158, lr=0.0001
[2025-05-05 04:35:24,374][meta_train][INFO] - Epoch 90/100, iter 6/8, train loss=4.6687, lr=0.0001
[2025-05-05 04:35:42,452][meta_train][INFO] - Epoch 90/100, iter 7/8, train loss=5.1498, lr=0.0001
[2025-05-05 04:36:00,913][meta_train][INFO] - Epoch 90/100, iter 8/8, train loss=5.5469, lr=0.0001
[2025-05-05 04:36:00,936][meta_train][INFO] - epoch_90 saved !
[2025-05-05 04:36:20,027][meta_train][INFO] - Epoch 91/100, iter 1/8, train loss=4.6241, lr=0.0001
[2025-05-05 04:36:39,350][meta_train][INFO] - Epoch 91/100, iter 2/8, train loss=4.7015, lr=0.0001
[2025-05-05 04:36:58,369][meta_train][INFO] - Epoch 91/100, iter 3/8, train loss=4.6679, lr=0.0001
[2025-05-05 04:37:16,964][meta_train][INFO] - Epoch 91/100, iter 4/8, train loss=5.1351, lr=0.0001
[2025-05-05 04:37:35,235][meta_train][INFO] - Epoch 91/100, iter 5/8, train loss=4.7933, lr=0.0001
[2025-05-05 04:37:53,660][meta_train][INFO] - Epoch 91/100, iter 6/8, train loss=5.5144, lr=0.0001
[2025-05-05 04:38:14,133][meta_train][INFO] - Epoch 91/100, iter 7/8, train loss=4.6160, lr=0.0001
[2025-05-05 04:38:33,929][meta_train][INFO] - Epoch 91/100, iter 8/8, train loss=4.6151, lr=0.0001
[2025-05-05 04:38:33,947][meta_train][INFO] - epoch_91 saved !
[2025-05-05 04:38:52,459][meta_train][INFO] - Epoch 92/100, iter 1/8, train loss=5.1163, lr=0.0001
[2025-05-05 04:39:10,245][meta_train][INFO] - Epoch 92/100, iter 2/8, train loss=5.4963, lr=0.0001
[2025-05-05 04:39:29,080][meta_train][INFO] - Epoch 92/100, iter 3/8, train loss=4.6623, lr=0.0001
[2025-05-05 04:39:49,418][meta_train][INFO] - Epoch 92/100, iter 4/8, train loss=4.6145, lr=0.0001
[2025-05-05 04:40:08,582][meta_train][INFO] - Epoch 92/100, iter 5/8, train loss=4.6951, lr=0.0001
[2025-05-05 04:40:28,408][meta_train][INFO] - Epoch 92/100, iter 6/8, train loss=4.6153, lr=0.0001
[2025-05-05 04:40:47,291][meta_train][INFO] - Epoch 92/100, iter 7/8, train loss=4.7762, lr=0.0001
[2025-05-05 04:41:06,164][meta_train][INFO] - Epoch 92/100, iter 8/8, train loss=4.6219, lr=0.0001
[2025-05-05 04:41:06,180][meta_train][INFO] - epoch_92 saved !
[2025-05-05 04:41:25,056][meta_train][INFO] - Epoch 93/100, iter 1/8, train loss=4.6614, lr=0.0001
[2025-05-05 04:41:44,547][meta_train][INFO] - Epoch 93/100, iter 2/8, train loss=4.6938, lr=0.0001
[2025-05-05 04:42:02,781][meta_train][INFO] - Epoch 93/100, iter 3/8, train loss=4.7746, lr=0.0001
[2025-05-05 04:42:21,334][meta_train][INFO] - Epoch 93/100, iter 4/8, train loss=5.4549, lr=0.0001
[2025-05-05 04:42:41,350][meta_train][INFO] - Epoch 93/100, iter 5/8, train loss=4.6148, lr=0.0001
[2025-05-05 04:43:01,592][meta_train][INFO] - Epoch 93/100, iter 6/8, train loss=4.6140, lr=0.0001
[2025-05-05 04:43:21,252][meta_train][INFO] - Epoch 93/100, iter 7/8, train loss=4.6214, lr=0.0001
[2025-05-05 04:43:39,359][meta_train][INFO] - Epoch 93/100, iter 8/8, train loss=5.0767, lr=0.0001
[2025-05-05 04:43:39,375][meta_train][INFO] - epoch_93 saved !
[2025-05-05 04:43:57,692][meta_train][INFO] - Epoch 94/100, iter 1/8, train loss=5.4497, lr=0.0001
[2025-05-05 04:44:17,540][meta_train][INFO] - Epoch 94/100, iter 2/8, train loss=4.6137, lr=0.0001
[2025-05-05 04:44:37,559][meta_train][INFO] - Epoch 94/100, iter 3/8, train loss=4.6144, lr=0.0001
[2025-05-05 04:44:55,871][meta_train][INFO] - Epoch 94/100, iter 4/8, train loss=4.7680, lr=0.0001
[2025-05-05 04:45:15,177][meta_train][INFO] - Epoch 94/100, iter 5/8, train loss=4.6202, lr=0.0001
[2025-05-05 04:45:33,865][meta_train][INFO] - Epoch 94/100, iter 6/8, train loss=4.6563, lr=0.0001
[2025-05-05 04:45:52,333][meta_train][INFO] - Epoch 94/100, iter 7/8, train loss=5.0632, lr=0.0001
[2025-05-05 04:46:12,123][meta_train][INFO] - Epoch 94/100, iter 8/8, train loss=4.6871, lr=0.0001
[2025-05-05 04:46:12,147][meta_train][INFO] - epoch_94 saved !
[2025-05-05 04:46:30,645][meta_train][INFO] - Epoch 95/100, iter 1/8, train loss=4.7651, lr=0.0001
[2025-05-05 04:46:50,140][meta_train][INFO] - Epoch 95/100, iter 2/8, train loss=4.6202, lr=0.0001
[2025-05-05 04:47:09,103][meta_train][INFO] - Epoch 95/100, iter 3/8, train loss=4.6562, lr=0.0001
[2025-05-05 04:47:27,246][meta_train][INFO] - Epoch 95/100, iter 4/8, train loss=5.4359, lr=0.0001
[2025-05-05 04:47:46,005][meta_train][INFO] - Epoch 95/100, iter 5/8, train loss=5.0506, lr=0.0001
[2025-05-05 04:48:04,886][meta_train][INFO] - Epoch 95/100, iter 6/8, train loss=4.6849, lr=0.0001
[2025-05-05 04:48:24,910][meta_train][INFO] - Epoch 95/100, iter 7/8, train loss=4.6130, lr=0.0001
[2025-05-05 04:48:44,837][meta_train][INFO] - Epoch 95/100, iter 8/8, train loss=4.6135, lr=0.0001
[2025-05-05 04:48:44,853][meta_train][INFO] - epoch_95 saved !
[2025-05-05 04:49:04,149][meta_train][INFO] - Epoch 96/100, iter 1/8, train loss=4.6837, lr=0.0001
[2025-05-05 04:49:24,394][meta_train][INFO] - Epoch 96/100, iter 2/8, train loss=4.6133, lr=0.0001
[2025-05-05 04:49:42,640][meta_train][INFO] - Epoch 96/100, iter 3/8, train loss=5.4027, lr=0.0001
[2025-05-05 04:50:01,315][meta_train][INFO] - Epoch 96/100, iter 4/8, train loss=5.0335, lr=0.0001
[2025-05-05 04:50:21,200][meta_train][INFO] - Epoch 96/100, iter 5/8, train loss=4.6126, lr=0.0001
[2025-05-05 04:50:40,608][meta_train][INFO] - Epoch 96/100, iter 6/8, train loss=4.6189, lr=0.0001
[2025-05-05 04:50:59,755][meta_train][INFO] - Epoch 96/100, iter 7/8, train loss=4.6511, lr=0.0001
[2025-05-05 04:51:17,932][meta_train][INFO] - Epoch 96/100, iter 8/8, train loss=4.7525, lr=0.0001
[2025-05-05 04:51:17,954][meta_train][INFO] - epoch_96 saved !
[2025-05-05 04:51:36,672][meta_train][INFO] - Epoch 97/100, iter 1/8, train loss=5.0190, lr=0.0001
[2025-05-05 04:51:55,784][meta_train][INFO] - Epoch 97/100, iter 2/8, train loss=4.6507, lr=0.0001
[2025-05-05 04:52:15,845][meta_train][INFO] - Epoch 97/100, iter 3/8, train loss=4.6122, lr=0.0001
[2025-05-05 04:52:34,520][meta_train][INFO] - Epoch 97/100, iter 4/8, train loss=5.3826, lr=0.0001
[2025-05-05 04:52:53,729][meta_train][INFO] - Epoch 97/100, iter 5/8, train loss=4.6772, lr=0.0001
[2025-05-05 04:53:14,066][meta_train][INFO] - Epoch 97/100, iter 6/8, train loss=4.6125, lr=0.0001
[2025-05-05 04:53:32,040][meta_train][INFO] - Epoch 97/100, iter 7/8, train loss=4.7481, lr=0.0001
[2025-05-05 04:53:50,974][meta_train][INFO] - Epoch 97/100, iter 8/8, train loss=4.6183, lr=0.0001
[2025-05-05 04:53:50,995][meta_train][INFO] - epoch_97 saved !
[2025-05-05 04:54:10,703][meta_train][INFO] - Epoch 98/100, iter 1/8, train loss=4.6182, lr=0.0001
[2025-05-05 04:54:28,858][meta_train][INFO] - Epoch 98/100, iter 2/8, train loss=4.7473, lr=0.0001
[2025-05-05 04:54:48,112][meta_train][INFO] - Epoch 98/100, iter 3/8, train loss=4.6753, lr=0.0001
[2025-05-05 04:55:08,333][meta_train][INFO] - Epoch 98/100, iter 4/8, train loss=4.6122, lr=0.0001
[2025-05-05 04:55:28,220][meta_train][INFO] - Epoch 98/100, iter 5/8, train loss=4.6119, lr=0.0001
[2025-05-05 04:55:46,452][meta_train][INFO] - Epoch 98/100, iter 6/8, train loss=5.3613, lr=0.0001
[2025-05-05 04:56:04,460][meta_train][INFO] - Epoch 98/100, iter 7/8, train loss=4.9980, lr=0.0001
[2025-05-05 04:56:23,361][meta_train][INFO] - Epoch 98/100, iter 8/8, train loss=4.6477, lr=0.0001
[2025-05-05 04:56:23,378][meta_train][INFO] - epoch_98 saved !
[2025-05-05 04:56:43,368][meta_train][INFO] - Epoch 99/100, iter 1/8, train loss=4.6116, lr=0.0001
[2025-05-05 04:57:02,450][meta_train][INFO] - Epoch 99/100, iter 2/8, train loss=4.6475, lr=0.0001
[2025-05-05 04:57:20,939][meta_train][INFO] - Epoch 99/100, iter 3/8, train loss=4.9896, lr=0.0001
[2025-05-05 04:57:40,461][meta_train][INFO] - Epoch 99/100, iter 4/8, train loss=4.6737, lr=0.0001
[2025-05-05 04:57:58,715][meta_train][INFO] - Epoch 99/100, iter 5/8, train loss=4.7424, lr=0.0001
[2025-05-05 04:58:18,940][meta_train][INFO] - Epoch 99/100, iter 6/8, train loss=4.6117, lr=0.0001
[2025-05-05 04:58:37,414][meta_train][INFO] - Epoch 99/100, iter 7/8, train loss=5.3368, lr=0.0001
[2025-05-05 04:58:56,829][meta_train][INFO] - Epoch 99/100, iter 8/8, train loss=4.6169, lr=0.0001
[2025-05-05 04:58:56,846][meta_train][INFO] - epoch_99 saved !
[2025-05-05 04:59:16,567][meta_train][INFO] - Epoch 100/100, iter 1/8, train loss=4.6170, lr=0.0001
[2025-05-05 04:59:36,434][meta_train][INFO] - Epoch 100/100, iter 2/8, train loss=4.6112, lr=0.0001
[2025-05-05 04:59:54,632][meta_train][INFO] - Epoch 100/100, iter 3/8, train loss=5.3229, lr=0.0001
[2025-05-05 05:00:14,924][meta_train][INFO] - Epoch 100/100, iter 4/8, train loss=4.6114, lr=0.0001
[2025-05-05 05:00:34,105][meta_train][INFO] - Epoch 100/100, iter 5/8, train loss=4.6691, lr=0.0001
[2025-05-05 05:00:52,402][meta_train][INFO] - Epoch 100/100, iter 6/8, train loss=4.9667, lr=0.0001
[2025-05-05 05:01:10,929][meta_train][INFO] - Epoch 100/100, iter 7/8, train loss=4.7353, lr=0.0001
[2025-05-05 05:01:29,859][meta_train][INFO] - Epoch 100/100, iter 8/8, train loss=4.6433, lr=0.0001
[2025-05-05 05:01:29,875][meta_train][INFO] - epoch_100 saved !
[2025-05-05 11:09:24,051][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-05 11:09:24,117][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:09:24,117][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:09:24,117][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:09:35,170][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-05-05 11:09:35,228][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:09:35,228][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:09:35,228][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 11:09:37,798][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 11:09:42,940][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-05 11:09:43,007][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:09:43,007][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:09:43,007][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:09:46,322][train][INFO] - Epoch 1/100, Val Acc=0.0804, Val Loss=4.1404, lr=0.0100
[2025-05-05 11:09:49,292][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:09:54,049][train][INFO] - Epoch 2/100, Val Acc=0.1891, Val Loss=3.1578, lr=0.0100
[2025-05-05 11:09:56,776][train][INFO] - Epoch 1/100, Val Acc=0.0664, Val Loss=3.9728, lr=0.0100
[2025-05-05 11:09:57,453][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 11:10:01,046][train][INFO] - Epoch 3/100, Val Acc=0.2336, Val Loss=3.2054, lr=0.0100
[2025-05-05 11:10:04,479][train][INFO] - Epoch 2/100, Val Acc=0.1184, Val Loss=3.5361, lr=0.0100
[2025-05-05 11:10:04,673][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6128, lr=0.0100
[2025-05-05 11:10:08,628][train][INFO] - Epoch 4/100, Val Acc=0.3230, Val Loss=2.5584, lr=0.0100
[2025-05-05 11:10:12,042][train][INFO] - Epoch 3/100, Val Acc=0.1530, Val Loss=3.4303, lr=0.0100
[2025-05-05 11:10:12,428][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6121, lr=0.0100
[2025-05-05 11:10:16,283][train][INFO] - Epoch 5/100, Val Acc=0.3687, Val Loss=2.3383, lr=0.0100
[2025-05-05 11:10:19,787][train][INFO] - Epoch 3/100, Val Acc=0.0300, Val Loss=4.3064, lr=0.0100
[2025-05-05 11:10:19,813][train][INFO] - Epoch 4/100, Val Acc=0.1755, Val Loss=3.1658, lr=0.0100
[2025-05-05 11:10:24,029][train][INFO] - Epoch 6/100, Val Acc=0.3791, Val Loss=2.3241, lr=0.0100
[2025-05-05 11:10:27,069][train][INFO] - Epoch 5/100, Val Acc=0.2110, Val Loss=3.0767, lr=0.0100
[2025-05-05 11:10:27,371][train][INFO] - Epoch 4/100, Val Acc=0.0393, Val Loss=4.4273, lr=0.0100
[2025-05-05 11:10:31,542][train][INFO] - Epoch 7/100, Val Acc=0.4494, Val Loss=2.0314, lr=0.0100
[2025-05-05 11:10:33,916][train][INFO] - Epoch 6/100, Val Acc=0.2169, Val Loss=3.1587, lr=0.0100
[2025-05-05 11:10:34,672][train][INFO] - Epoch 5/100, Val Acc=0.0719, Val Loss=3.9093, lr=0.0100
[2025-05-05 11:10:38,876][train][INFO] - Epoch 8/100, Val Acc=0.4468, Val Loss=2.0943, lr=0.0100
[2025-05-05 11:10:41,465][train][INFO] - Epoch 7/100, Val Acc=0.2723, Val Loss=2.7278, lr=0.0100
[2025-05-05 11:10:42,134][train][INFO] - Epoch 6/100, Val Acc=0.0520, Val Loss=4.3819, lr=0.0100
[2025-05-05 11:10:46,214][train][INFO] - Epoch 9/100, Val Acc=0.4382, Val Loss=2.1385, lr=0.0100
[2025-05-05 11:10:48,983][train][INFO] - Epoch 8/100, Val Acc=0.2486, Val Loss=2.9273, lr=0.0100
[2025-05-05 11:10:49,093][train][INFO] - Epoch 7/100, Val Acc=0.0853, Val Loss=3.8253, lr=0.0100
[2025-05-05 11:10:53,825][train][INFO] - Epoch 10/100, Val Acc=0.4803, Val Loss=1.9978, lr=0.0100
[2025-05-05 11:10:56,393][train][INFO] - Epoch 8/100, Val Acc=0.0463, Val Loss=5.3522, lr=0.0100
[2025-05-05 11:10:56,697][train][INFO] - Epoch 9/100, Val Acc=0.2722, Val Loss=2.7820, lr=0.0100
[2025-05-05 11:11:01,272][train][INFO] - Epoch 11/100, Val Acc=0.4882, Val Loss=1.9134, lr=0.0100
[2025-05-05 11:11:03,573][train][INFO] - Epoch 9/100, Val Acc=0.1060, Val Loss=3.7892, lr=0.0100
[2025-05-05 11:11:04,001][train][INFO] - Epoch 10/100, Val Acc=0.2353, Val Loss=3.1727, lr=0.0100
[2025-05-05 11:11:09,003][train][INFO] - Epoch 12/100, Val Acc=0.5014, Val Loss=1.8808, lr=0.0100
[2025-05-05 11:11:10,371][train][INFO] - Epoch 10/100, Val Acc=0.0595, Val Loss=5.1488, lr=0.0100
[2025-05-05 11:11:11,287][train][INFO] - Epoch 11/100, Val Acc=0.3567, Val Loss=2.3389, lr=0.0100
[2025-05-05 11:11:16,697][train][INFO] - Epoch 13/100, Val Acc=0.5037, Val Loss=1.8478, lr=0.0100
[2025-05-05 11:11:17,839][train][INFO] - Epoch 11/100, Val Acc=0.1136, Val Loss=4.2107, lr=0.0100
[2025-05-05 11:11:18,787][train][INFO] - Epoch 12/100, Val Acc=0.3419, Val Loss=2.4389, lr=0.0100
[2025-05-05 11:11:24,403][train][INFO] - Epoch 14/100, Val Acc=0.5029, Val Loss=1.9328, lr=0.0100
[2025-05-05 11:11:25,305][train][INFO] - Epoch 12/100, Val Acc=0.1193, Val Loss=4.0406, lr=0.0100
[2025-05-05 11:11:26,316][train][INFO] - Epoch 13/100, Val Acc=0.3511, Val Loss=2.4302, lr=0.0100
[2025-05-05 11:11:32,176][train][INFO] - Epoch 15/100, Val Acc=0.5275, Val Loss=1.8388, lr=0.0100
[2025-05-05 11:11:32,867][train][INFO] - Epoch 13/100, Val Acc=0.1456, Val Loss=3.6182, lr=0.0100
[2025-05-05 11:11:33,674][train][INFO] - Epoch 14/100, Val Acc=0.3419, Val Loss=2.4569, lr=0.0100
[2025-05-05 11:11:39,908][train][INFO] - Epoch 16/100, Val Acc=0.4811, Val Loss=2.1029, lr=0.0100
[2025-05-05 11:11:40,361][train][INFO] - Epoch 14/100, Val Acc=0.1745, Val Loss=3.3353, lr=0.0100
[2025-05-05 11:11:41,190][train][INFO] - Epoch 15/100, Val Acc=0.3452, Val Loss=2.4667, lr=0.0100
[2025-05-05 11:11:47,423][train][INFO] - Epoch 17/100, Val Acc=0.5169, Val Loss=1.8745, lr=0.0100
[2025-05-05 11:11:48,139][train][INFO] - Epoch 15/100, Val Acc=0.1802, Val Loss=3.3089, lr=0.0100
[2025-05-05 11:11:48,551][train][INFO] - Epoch 16/100, Val Acc=0.3719, Val Loss=2.3648, lr=0.0100
[2025-05-05 11:11:54,998][train][INFO] - Epoch 18/100, Val Acc=0.5414, Val Loss=1.7938, lr=0.0100
[2025-05-05 11:11:55,484][train][INFO] - Epoch 16/100, Val Acc=0.1774, Val Loss=3.3624, lr=0.0100
[2025-05-05 11:11:55,949][train][INFO] - Epoch 17/100, Val Acc=0.3804, Val Loss=2.3119, lr=0.0100
[2025-05-05 11:12:02,918][train][INFO] - Epoch 19/100, Val Acc=0.5431, Val Loss=1.7544, lr=0.0100
[2025-05-05 11:12:03,105][train][INFO] - Epoch 17/100, Val Acc=0.1966, Val Loss=3.1952, lr=0.0100
[2025-05-05 11:12:03,414][train][INFO] - Epoch 18/100, Val Acc=0.3702, Val Loss=2.3684, lr=0.0100
[2025-05-05 11:12:10,089][train][INFO] - Epoch 18/100, Val Acc=0.2310, Val Loss=2.9862, lr=0.0100
[2025-05-05 11:12:10,626][train][INFO] - Epoch 20/100, Val Acc=0.5628, Val Loss=1.6527, lr=0.0100
[2025-05-05 11:12:10,976][train][INFO] - Epoch 19/100, Val Acc=0.4196, Val Loss=2.1066, lr=0.0100
[2025-05-05 11:12:17,755][train][INFO] - Epoch 21/100, Val Acc=0.5284, Val Loss=1.8882, lr=0.0100
[2025-05-05 11:12:17,798][train][INFO] - Epoch 19/100, Val Acc=0.1783, Val Loss=3.4429, lr=0.0100
[2025-05-05 11:12:18,225][train][INFO] - Epoch 20/100, Val Acc=0.4119, Val Loss=2.1616, lr=0.0100
[2025-05-05 11:12:25,722][train][INFO] - Epoch 20/100, Val Acc=0.1518, Val Loss=3.6607, lr=0.0100
[2025-05-05 11:12:25,774][train][INFO] - Epoch 22/100, Val Acc=0.5354, Val Loss=1.8796, lr=0.0100
[2025-05-05 11:12:25,777][train][INFO] - Epoch 21/100, Val Acc=0.3885, Val Loss=2.3080, lr=0.0100
[2025-05-05 11:12:32,492][train][INFO] - Epoch 23/100, Val Acc=0.5703, Val Loss=1.6691, lr=0.0100
[2025-05-05 11:12:33,197][train][INFO] - Epoch 22/100, Val Acc=0.4229, Val Loss=2.1214, lr=0.0100
[2025-05-05 11:12:33,257][train][INFO] - Epoch 21/100, Val Acc=0.2003, Val Loss=3.2690, lr=0.0100
[2025-05-05 11:12:40,093][train][INFO] - Epoch 24/100, Val Acc=0.5730, Val Loss=1.6750, lr=0.0100
[2025-05-05 11:12:40,848][train][INFO] - Epoch 22/100, Val Acc=0.1721, Val Loss=3.4683, lr=0.0100
[2025-05-05 11:12:40,954][train][INFO] - Epoch 23/100, Val Acc=0.4454, Val Loss=1.9976, lr=0.0100
[2025-05-05 11:12:47,455][train][INFO] - Epoch 25/100, Val Acc=0.5888, Val Loss=1.6182, lr=0.0100
[2025-05-05 11:12:48,384][train][INFO] - Epoch 23/100, Val Acc=0.1824, Val Loss=3.3831, lr=0.0100
[2025-05-05 11:12:48,591][train][INFO] - Epoch 24/100, Val Acc=0.4583, Val Loss=1.9638, lr=0.0100
[2025-05-05 11:12:54,982][train][INFO] - Epoch 26/100, Val Acc=0.5898, Val Loss=1.6225, lr=0.0100
[2025-05-05 11:12:55,703][train][INFO] - Epoch 24/100, Val Acc=0.2144, Val Loss=3.1893, lr=0.0100
[2025-05-05 11:12:56,271][train][INFO] - Epoch 25/100, Val Acc=0.4464, Val Loss=2.0293, lr=0.0100
[2025-05-05 11:13:02,485][train][INFO] - Epoch 27/100, Val Acc=0.5716, Val Loss=1.6954, lr=0.0100
[2025-05-05 11:13:02,985][train][INFO] - Epoch 25/100, Val Acc=0.2648, Val Loss=2.8220, lr=0.0100
[2025-05-05 11:13:03,268][train][INFO] - Epoch 26/100, Val Acc=0.4526, Val Loss=2.0028, lr=0.0100
[2025-05-05 11:13:10,195][train][INFO] - Epoch 26/100, Val Acc=0.1961, Val Loss=3.3841, lr=0.0100
[2025-05-05 11:13:10,230][train][INFO] - Epoch 28/100, Val Acc=0.5960, Val Loss=1.6342, lr=0.0100
[2025-05-05 11:13:10,595][train][INFO] - Epoch 27/100, Val Acc=0.4503, Val Loss=2.0172, lr=0.0100
[2025-05-05 11:13:17,403][train][INFO] - Epoch 29/100, Val Acc=0.5706, Val Loss=1.7430, lr=0.0100
[2025-05-05 11:13:17,977][train][INFO] - Epoch 27/100, Val Acc=0.1922, Val Loss=3.2811, lr=0.0100
[2025-05-05 11:13:18,252][train][INFO] - Epoch 28/100, Val Acc=0.4205, Val Loss=2.2109, lr=0.0100
[2025-05-05 11:13:25,119][train][INFO] - Epoch 30/100, Val Acc=0.5842, Val Loss=1.6528, lr=0.0100
[2025-05-05 11:13:25,178][train][INFO] - Epoch 28/100, Val Acc=0.2672, Val Loss=2.8075, lr=0.0100
[2025-05-05 11:13:25,526][train][INFO] - Epoch 29/100, Val Acc=0.4338, Val Loss=2.1523, lr=0.0100
[2025-05-05 11:13:32,553][train][INFO] - Epoch 30/100, Val Acc=0.4596, Val Loss=1.9779, lr=0.0100
[2025-05-05 11:13:32,595][train][INFO] - Epoch 29/100, Val Acc=0.2186, Val Loss=3.1440, lr=0.0100
[2025-05-05 11:13:32,877][train][INFO] - Epoch 31/100, Val Acc=0.6090, Val Loss=1.5433, lr=0.0100
[2025-05-05 11:13:39,981][train][INFO] - Epoch 31/100, Val Acc=0.4815, Val Loss=1.8589, lr=0.0100
[2025-05-05 11:13:40,522][train][INFO] - Epoch 30/100, Val Acc=0.1346, Val Loss=4.2915, lr=0.0100
[2025-05-05 11:13:40,791][train][INFO] - Epoch 32/100, Val Acc=0.5870, Val Loss=1.6671, lr=0.0100
[2025-05-05 11:13:47,515][train][INFO] - Epoch 32/100, Val Acc=0.4771, Val Loss=1.9280, lr=0.0100
[2025-05-05 11:13:48,117][train][INFO] - Epoch 31/100, Val Acc=0.2666, Val Loss=2.8414, lr=0.0100
[2025-05-05 11:13:48,374][train][INFO] - Epoch 33/100, Val Acc=0.5909, Val Loss=1.6639, lr=0.0100
[2025-05-05 11:13:55,258][train][INFO] - Epoch 33/100, Val Acc=0.4603, Val Loss=1.9747, lr=0.0100
[2025-05-05 11:13:55,615][train][INFO] - Epoch 32/100, Val Acc=0.2139, Val Loss=3.2269, lr=0.0100
[2025-05-05 11:13:55,945][train][INFO] - Epoch 34/100, Val Acc=0.5950, Val Loss=1.6378, lr=0.0100
[2025-05-05 11:14:02,732][train][INFO] - Epoch 35/100, Val Acc=0.5760, Val Loss=1.7780, lr=0.0100
[2025-05-05 11:14:02,757][train][INFO] - Epoch 33/100, Val Acc=0.2511, Val Loss=2.9651, lr=0.0100
[2025-05-05 11:14:02,985][train][INFO] - Epoch 34/100, Val Acc=0.4397, Val Loss=2.0693, lr=0.0100
[2025-05-05 11:14:10,100][train][INFO] - Epoch 35/100, Val Acc=0.4941, Val Loss=1.8368, lr=0.0100
[2025-05-05 11:14:10,219][train][INFO] - Epoch 34/100, Val Acc=0.2209, Val Loss=3.0719, lr=0.0100
[2025-05-05 11:14:10,391][train][INFO] - Epoch 36/100, Val Acc=0.5825, Val Loss=1.6856, lr=0.0100
[2025-05-05 11:14:17,498][train][INFO] - Epoch 36/100, Val Acc=0.5059, Val Loss=1.7991, lr=0.0100
[2025-05-05 11:14:17,669][train][INFO] - Epoch 35/100, Val Acc=0.2444, Val Loss=2.9865, lr=0.0100
[2025-05-05 11:14:17,855][train][INFO] - Epoch 37/100, Val Acc=0.6052, Val Loss=1.5971, lr=0.0100
[2025-05-05 11:14:24,785][train][INFO] - Epoch 37/100, Val Acc=0.4662, Val Loss=1.9431, lr=0.0100
[2025-05-05 11:14:25,193][train][INFO] - Epoch 36/100, Val Acc=0.2297, Val Loss=3.0467, lr=0.0100
[2025-05-05 11:14:25,381][train][INFO] - Epoch 38/100, Val Acc=0.5972, Val Loss=1.6429, lr=0.0100
[2025-05-05 11:14:32,339][train][INFO] - Epoch 38/100, Val Acc=0.4999, Val Loss=1.8274, lr=0.0100
[2025-05-05 11:14:33,090][train][INFO] - Epoch 37/100, Val Acc=0.2357, Val Loss=3.1293, lr=0.0100
[2025-05-05 11:14:33,212][train][INFO] - Epoch 39/100, Val Acc=0.5840, Val Loss=1.7716, lr=0.0100
[2025-05-05 11:14:39,600][train][INFO] - Epoch 39/100, Val Acc=0.4645, Val Loss=1.9664, lr=0.0100
[2025-05-05 11:14:40,507][train][INFO] - Epoch 38/100, Val Acc=0.2754, Val Loss=2.7931, lr=0.0100
[2025-05-05 11:14:41,178][train][INFO] - Epoch 40/100, Val Acc=0.6052, Val Loss=1.6018, lr=0.0100
[2025-05-05 11:14:47,041][train][INFO] - Epoch 40/100, Val Acc=0.4847, Val Loss=1.9121, lr=0.0100
[2025-05-05 11:14:47,754][train][INFO] - Epoch 39/100, Val Acc=0.2914, Val Loss=2.7142, lr=0.0100
[2025-05-05 11:14:48,725][train][INFO] - Epoch 41/100, Val Acc=0.5954, Val Loss=1.6825, lr=0.0100
[2025-05-05 11:14:54,325][train][INFO] - Epoch 41/100, Val Acc=0.5004, Val Loss=1.8456, lr=0.0100
[2025-05-05 11:14:55,533][train][INFO] - Epoch 40/100, Val Acc=0.3168, Val Loss=2.5732, lr=0.0100
[2025-05-05 11:14:56,210][train][INFO] - Epoch 42/100, Val Acc=0.6060, Val Loss=1.6118, lr=0.0100
[2025-05-05 11:15:01,554][train][INFO] - Epoch 42/100, Val Acc=0.4844, Val Loss=1.9031, lr=0.0100
[2025-05-05 11:15:03,098][train][INFO] - Epoch 41/100, Val Acc=0.2328, Val Loss=3.0776, lr=0.0100
[2025-05-05 11:15:03,670][train][INFO] - Epoch 43/100, Val Acc=0.5913, Val Loss=1.7197, lr=0.0100
[2025-05-05 11:15:09,114][train][INFO] - Epoch 43/100, Val Acc=0.4828, Val Loss=1.8903, lr=0.0100
[2025-05-05 11:15:10,193][train][INFO] - Epoch 42/100, Val Acc=0.2729, Val Loss=2.8196, lr=0.0100
[2025-05-05 11:15:11,156][train][INFO] - Epoch 44/100, Val Acc=0.6009, Val Loss=1.6388, lr=0.0100
[2025-05-05 11:15:16,454][train][INFO] - Epoch 44/100, Val Acc=0.5071, Val Loss=1.8113, lr=0.0100
[2025-05-05 11:15:17,696][train][INFO] - Epoch 43/100, Val Acc=0.2850, Val Loss=2.7991, lr=0.0100
[2025-05-05 11:15:18,285][train][INFO] - Epoch 45/100, Val Acc=0.5819, Val Loss=1.7334, lr=0.0100
[2025-05-05 11:15:23,909][train][INFO] - Epoch 45/100, Val Acc=0.5195, Val Loss=1.7462, lr=0.0100
[2025-05-05 11:15:25,412][train][INFO] - Epoch 44/100, Val Acc=0.2713, Val Loss=2.8596, lr=0.0100
[2025-05-05 11:15:25,453][train][INFO] - Epoch 46/100, Val Acc=0.6148, Val Loss=1.6381, lr=0.0100
[2025-05-05 11:15:31,133][train][INFO] - Epoch 46/100, Val Acc=0.5130, Val Loss=1.7971, lr=0.0100
[2025-05-05 11:15:32,746][train][INFO] - Epoch 45/100, Val Acc=0.2830, Val Loss=2.7362, lr=0.0100
[2025-05-05 11:15:33,270][train][INFO] - Epoch 47/100, Val Acc=0.6046, Val Loss=1.6380, lr=0.0100
[2025-05-05 11:15:38,388][train][INFO] - Epoch 47/100, Val Acc=0.4716, Val Loss=1.9982, lr=0.0100
[2025-05-05 11:15:40,283][train][INFO] - Epoch 46/100, Val Acc=0.2553, Val Loss=2.8966, lr=0.0100
[2025-05-05 11:15:40,812][train][INFO] - Epoch 48/100, Val Acc=0.6021, Val Loss=1.6666, lr=0.0100
[2025-05-05 11:15:46,009][train][INFO] - Epoch 48/100, Val Acc=0.5075, Val Loss=1.7852, lr=0.0100
[2025-05-05 11:15:47,506][train][INFO] - Epoch 47/100, Val Acc=0.3089, Val Loss=2.6175, lr=0.0100
[2025-05-05 11:15:48,462][train][INFO] - Epoch 49/100, Val Acc=0.6109, Val Loss=1.6376, lr=0.0100
[2025-05-05 11:15:53,361][train][INFO] - Epoch 49/100, Val Acc=0.4863, Val Loss=1.9434, lr=0.0100
[2025-05-05 11:15:55,604][train][INFO] - Epoch 48/100, Val Acc=0.2260, Val Loss=3.2370, lr=0.0100
[2025-05-05 11:15:56,121][train][INFO] - Epoch 50/100, Val Acc=0.5956, Val Loss=1.7206, lr=0.0100
[2025-05-05 11:16:00,082][train][INFO] - Epoch 50/100, Val Acc=0.5129, Val Loss=1.7573, lr=0.0100
[2025-05-05 11:16:03,092][train][INFO] - Epoch 49/100, Val Acc=0.2649, Val Loss=2.8898, lr=0.0100
[2025-05-05 11:16:03,806][train][INFO] - Epoch 51/100, Val Acc=0.6215, Val Loss=1.6214, lr=0.0100
[2025-05-05 11:16:07,202][train][INFO] - Epoch 51/100, Val Acc=0.5228, Val Loss=1.7472, lr=0.0100
[2025-05-05 11:16:10,292][train][INFO] - Epoch 50/100, Val Acc=0.2837, Val Loss=2.7281, lr=0.0100
[2025-05-05 11:16:11,482][train][INFO] - Epoch 52/100, Val Acc=0.5923, Val Loss=1.7948, lr=0.0100
[2025-05-05 11:16:14,840][train][INFO] - Epoch 52/100, Val Acc=0.5293, Val Loss=1.7291, lr=0.0100
[2025-05-05 11:16:17,524][train][INFO] - Epoch 51/100, Val Acc=0.2131, Val Loss=3.3995, lr=0.0100
[2025-05-05 11:16:18,976][train][INFO] - Epoch 53/100, Val Acc=0.5915, Val Loss=1.7771, lr=0.0100
[2025-05-05 11:16:22,657][train][INFO] - Epoch 53/100, Val Acc=0.5126, Val Loss=1.8038, lr=0.0100
[2025-05-05 11:16:24,964][train][INFO] - Epoch 52/100, Val Acc=0.2970, Val Loss=2.6775, lr=0.0100
[2025-05-05 11:16:26,248][train][INFO] - Epoch 54/100, Val Acc=0.5980, Val Loss=1.7148, lr=0.0100
[2025-05-05 11:16:30,057][train][INFO] - Epoch 54/100, Val Acc=0.5196, Val Loss=1.7451, lr=0.0100
[2025-05-05 11:16:32,439][train][INFO] - Epoch 53/100, Val Acc=0.2970, Val Loss=2.7012, lr=0.0100
[2025-05-05 11:16:34,047][train][INFO] - Epoch 55/100, Val Acc=0.6205, Val Loss=1.6219, lr=0.0100
[2025-05-05 11:16:37,646][train][INFO] - Epoch 55/100, Val Acc=0.5169, Val Loss=1.7561, lr=0.0100
[2025-05-05 11:16:39,886][train][INFO] - Epoch 54/100, Val Acc=0.2792, Val Loss=2.8162, lr=0.0100
[2025-05-05 11:16:41,775][train][INFO] - Epoch 56/100, Val Acc=0.5798, Val Loss=1.8664, lr=0.0100
[2025-05-05 11:16:44,876][train][INFO] - Epoch 56/100, Val Acc=0.5253, Val Loss=1.7583, lr=0.0100
[2025-05-05 11:16:47,233][train][INFO] - Epoch 55/100, Val Acc=0.2238, Val Loss=3.2067, lr=0.0100
[2025-05-05 11:16:49,172][train][INFO] - Epoch 57/100, Val Acc=0.5915, Val Loss=1.7545, lr=0.0100
[2025-05-05 11:16:52,372][train][INFO] - Epoch 57/100, Val Acc=0.5276, Val Loss=1.7094, lr=0.0100
[2025-05-05 11:16:54,828][train][INFO] - Epoch 56/100, Val Acc=0.3055, Val Loss=2.6987, lr=0.0100
[2025-05-05 11:16:56,747][train][INFO] - Epoch 58/100, Val Acc=0.6099, Val Loss=1.7258, lr=0.0100
[2025-05-05 11:16:59,902][train][INFO] - Epoch 58/100, Val Acc=0.5046, Val Loss=1.8145, lr=0.0100
[2025-05-05 11:17:02,332][train][INFO] - Epoch 57/100, Val Acc=0.3180, Val Loss=2.5983, lr=0.0100
[2025-05-05 11:17:03,768][train][INFO] - Epoch 59/100, Val Acc=0.6129, Val Loss=1.7326, lr=0.0100
[2025-05-05 11:17:07,287][train][INFO] - Epoch 59/100, Val Acc=0.5246, Val Loss=1.7405, lr=0.0100
[2025-05-05 11:17:09,960][train][INFO] - Epoch 58/100, Val Acc=0.2985, Val Loss=2.7387, lr=0.0100
[2025-05-05 11:17:11,436][train][INFO] - Epoch 60/100, Val Acc=0.6112, Val Loss=1.6867, lr=0.0100
[2025-05-05 11:17:14,500][train][INFO] - Epoch 60/100, Val Acc=0.5219, Val Loss=1.7642, lr=0.0100
[2025-05-05 11:17:17,732][train][INFO] - Epoch 59/100, Val Acc=0.2585, Val Loss=2.9123, lr=0.0100
[2025-05-05 11:17:19,263][train][INFO] - Epoch 61/100, Val Acc=0.6692, Val Loss=1.3923, lr=0.0010
[2025-05-05 11:17:21,957][train][INFO] - Epoch 61/100, Val Acc=0.5926, Val Loss=1.4331, lr=0.0010
[2025-05-05 11:17:25,177][train][INFO] - Epoch 60/100, Val Acc=0.2833, Val Loss=2.7614, lr=0.0100
[2025-05-05 11:17:26,819][train][INFO] - Epoch 62/100, Val Acc=0.6710, Val Loss=1.3873, lr=0.0010
[2025-05-05 11:17:29,276][train][INFO] - Epoch 62/100, Val Acc=0.5963, Val Loss=1.4249, lr=0.0010
[2025-05-05 11:17:32,653][train][INFO] - Epoch 61/100, Val Acc=0.3796, Val Loss=2.2881, lr=0.0010
[2025-05-05 11:17:34,199][train][INFO] - Epoch 63/100, Val Acc=0.6730, Val Loss=1.3993, lr=0.0010
[2025-05-05 11:17:36,783][train][INFO] - Epoch 63/100, Val Acc=0.5984, Val Loss=1.4192, lr=0.0010
[2025-05-05 11:17:40,463][train][INFO] - Epoch 62/100, Val Acc=0.3779, Val Loss=2.2969, lr=0.0010
[2025-05-05 11:17:41,657][train][INFO] - Epoch 64/100, Val Acc=0.6716, Val Loss=1.4106, lr=0.0010
[2025-05-05 11:17:43,984][train][INFO] - Epoch 64/100, Val Acc=0.5957, Val Loss=1.4214, lr=0.0010
[2025-05-05 11:17:48,342][train][INFO] - Epoch 63/100, Val Acc=0.3784, Val Loss=2.2947, lr=0.0010
[2025-05-05 11:17:49,262][train][INFO] - Epoch 65/100, Val Acc=0.6749, Val Loss=1.4065, lr=0.0010
[2025-05-05 11:17:51,225][train][INFO] - Epoch 65/100, Val Acc=0.5958, Val Loss=1.4260, lr=0.0010
[2025-05-05 11:17:56,197][train][INFO] - Epoch 64/100, Val Acc=0.3810, Val Loss=2.2735, lr=0.0010
[2025-05-05 11:17:57,033][train][INFO] - Epoch 66/100, Val Acc=0.6753, Val Loss=1.4184, lr=0.0010
[2025-05-05 11:17:59,136][train][INFO] - Epoch 66/100, Val Acc=0.6017, Val Loss=1.4150, lr=0.0010
[2025-05-05 11:18:03,935][train][INFO] - Epoch 65/100, Val Acc=0.3850, Val Loss=2.2683, lr=0.0010
[2025-05-05 11:18:04,856][train][INFO] - Epoch 67/100, Val Acc=0.6766, Val Loss=1.4346, lr=0.0010
[2025-05-05 11:18:06,578][train][INFO] - Epoch 67/100, Val Acc=0.6036, Val Loss=1.4130, lr=0.0010
[2025-05-05 11:18:11,571][train][INFO] - Epoch 66/100, Val Acc=0.3862, Val Loss=2.2711, lr=0.0010
[2025-05-05 11:18:12,168][train][INFO] - Epoch 68/100, Val Acc=0.6755, Val Loss=1.4439, lr=0.0010
[2025-05-05 11:18:14,093][train][INFO] - Epoch 68/100, Val Acc=0.6031, Val Loss=1.4144, lr=0.0010
[2025-05-05 11:18:19,189][train][INFO] - Epoch 67/100, Val Acc=0.3857, Val Loss=2.2716, lr=0.0010
[2025-05-05 11:18:19,399][train][INFO] - Epoch 69/100, Val Acc=0.6754, Val Loss=1.4475, lr=0.0010
[2025-05-05 11:18:21,306][train][INFO] - Epoch 69/100, Val Acc=0.6044, Val Loss=1.4162, lr=0.0010
[2025-05-05 11:18:26,217][train][INFO] - Epoch 70/100, Val Acc=0.6762, Val Loss=1.4598, lr=0.0010
[2025-05-05 11:18:26,673][train][INFO] - Epoch 68/100, Val Acc=0.3849, Val Loss=2.2617, lr=0.0010
[2025-05-05 11:18:27,736][train][INFO] - Epoch 70/100, Val Acc=0.6009, Val Loss=1.4187, lr=0.0010
[2025-05-05 11:18:33,866][train][INFO] - Epoch 71/100, Val Acc=0.6778, Val Loss=1.4599, lr=0.0010
[2025-05-05 11:18:33,948][train][INFO] - Epoch 69/100, Val Acc=0.3870, Val Loss=2.2601, lr=0.0010
[2025-05-05 11:18:35,430][train][INFO] - Epoch 71/100, Val Acc=0.6027, Val Loss=1.4140, lr=0.0010
[2025-05-05 11:18:41,116][train][INFO] - Epoch 72/100, Val Acc=0.6750, Val Loss=1.4570, lr=0.0010
[2025-05-05 11:18:41,275][train][INFO] - Epoch 70/100, Val Acc=0.3846, Val Loss=2.2548, lr=0.0010
[2025-05-05 11:18:42,926][train][INFO] - Epoch 72/100, Val Acc=0.6027, Val Loss=1.4267, lr=0.0010
[2025-05-05 11:18:48,692][train][INFO] - Epoch 71/100, Val Acc=0.3839, Val Loss=2.2693, lr=0.0010
[2025-05-05 11:18:49,026][train][INFO] - Epoch 73/100, Val Acc=0.6804, Val Loss=1.4586, lr=0.0010
[2025-05-05 11:18:50,185][train][INFO] - Epoch 73/100, Val Acc=0.6041, Val Loss=1.4054, lr=0.0010
[2025-05-05 11:18:56,140][train][INFO] - Epoch 72/100, Val Acc=0.3865, Val Loss=2.2464, lr=0.0010
[2025-05-05 11:18:56,715][train][INFO] - Epoch 74/100, Val Acc=0.6773, Val Loss=1.4765, lr=0.0010
[2025-05-05 11:18:57,150][train][INFO] - Epoch 74/100, Val Acc=0.6046, Val Loss=1.4184, lr=0.0010
[2025-05-05 11:19:03,349][train][INFO] - Epoch 73/100, Val Acc=0.3838, Val Loss=2.2652, lr=0.0010
[2025-05-05 11:19:04,579][train][INFO] - Epoch 75/100, Val Acc=0.6813, Val Loss=1.4815, lr=0.0010
[2025-05-05 11:19:04,597][train][INFO] - Epoch 75/100, Val Acc=0.6012, Val Loss=1.4247, lr=0.0010
[2025-05-05 11:19:10,892][train][INFO] - Epoch 74/100, Val Acc=0.3848, Val Loss=2.2678, lr=0.0010
[2025-05-05 11:19:11,936][train][INFO] - Epoch 76/100, Val Acc=0.6811, Val Loss=1.4767, lr=0.0010
[2025-05-05 11:19:12,032][train][INFO] - Epoch 76/100, Val Acc=0.6035, Val Loss=1.4098, lr=0.0010
[2025-05-05 11:19:18,606][train][INFO] - Epoch 75/100, Val Acc=0.3873, Val Loss=2.2568, lr=0.0010
[2025-05-05 11:19:19,318][train][INFO] - Epoch 77/100, Val Acc=0.6785, Val Loss=1.4958, lr=0.0010
[2025-05-05 11:19:19,347][train][INFO] - Epoch 77/100, Val Acc=0.6021, Val Loss=1.4232, lr=0.0010
[2025-05-05 11:19:25,859][train][INFO] - Epoch 76/100, Val Acc=0.3890, Val Loss=2.2522, lr=0.0010
[2025-05-05 11:19:26,034][train][INFO] - Epoch 78/100, Val Acc=0.6042, Val Loss=1.4246, lr=0.0010
[2025-05-05 11:19:26,770][train][INFO] - Epoch 78/100, Val Acc=0.6803, Val Loss=1.4932, lr=0.0010
[2025-05-05 11:19:33,286][train][INFO] - Epoch 77/100, Val Acc=0.3902, Val Loss=2.2495, lr=0.0010
[2025-05-05 11:19:33,825][train][INFO] - Epoch 79/100, Val Acc=0.6055, Val Loss=1.4301, lr=0.0010
[2025-05-05 11:19:33,959][train][INFO] - Epoch 79/100, Val Acc=0.6812, Val Loss=1.4964, lr=0.0010
[2025-05-05 11:19:40,377][train][INFO] - Epoch 78/100, Val Acc=0.3872, Val Loss=2.2688, lr=0.0010
[2025-05-05 11:19:41,458][train][INFO] - Epoch 80/100, Val Acc=0.6033, Val Loss=1.4292, lr=0.0010
[2025-05-05 11:19:41,596][train][INFO] - Epoch 80/100, Val Acc=0.6790, Val Loss=1.5076, lr=0.0010
[2025-05-05 11:19:47,758][train][INFO] - Epoch 79/100, Val Acc=0.3840, Val Loss=2.2790, lr=0.0010
[2025-05-05 11:19:49,043][train][INFO] - Epoch 81/100, Val Acc=0.6084, Val Loss=1.4232, lr=0.0010
[2025-05-05 11:19:49,141][train][INFO] - Epoch 81/100, Val Acc=0.6788, Val Loss=1.5065, lr=0.0010
[2025-05-05 11:19:55,606][train][INFO] - Epoch 80/100, Val Acc=0.3877, Val Loss=2.2556, lr=0.0010
[2025-05-05 11:19:56,645][train][INFO] - Epoch 82/100, Val Acc=0.6025, Val Loss=1.4337, lr=0.0010
[2025-05-05 11:19:56,918][train][INFO] - Epoch 82/100, Val Acc=0.6783, Val Loss=1.5181, lr=0.0010
[2025-05-05 11:20:03,597][train][INFO] - Epoch 81/100, Val Acc=0.3840, Val Loss=2.2581, lr=0.0010
[2025-05-05 11:20:04,104][train][INFO] - Epoch 83/100, Val Acc=0.6019, Val Loss=1.4343, lr=0.0010
[2025-05-05 11:20:04,872][train][INFO] - Epoch 83/100, Val Acc=0.6808, Val Loss=1.5215, lr=0.0010
[2025-05-05 11:20:11,321][train][INFO] - Epoch 82/100, Val Acc=0.3934, Val Loss=2.2276, lr=0.0010
[2025-05-05 11:20:11,527][train][INFO] - Epoch 84/100, Val Acc=0.6050, Val Loss=1.4340, lr=0.0010
[2025-05-05 11:20:12,157][train][INFO] - Epoch 84/100, Val Acc=0.6815, Val Loss=1.5331, lr=0.0010
[2025-05-05 11:20:18,935][train][INFO] - Epoch 85/100, Val Acc=0.6801, Val Loss=1.5356, lr=0.0010
[2025-05-05 11:20:19,157][train][INFO] - Epoch 83/100, Val Acc=0.3844, Val Loss=2.2643, lr=0.0010
[2025-05-05 11:20:19,494][train][INFO] - Epoch 85/100, Val Acc=0.6008, Val Loss=1.4387, lr=0.0010
[2025-05-05 11:20:25,879][train][INFO] - Epoch 86/100, Val Acc=0.6823, Val Loss=1.5397, lr=0.0010
[2025-05-05 11:20:26,567][train][INFO] - Epoch 84/100, Val Acc=0.3878, Val Loss=2.2369, lr=0.0010
[2025-05-05 11:20:26,636][train][INFO] - Epoch 86/100, Val Acc=0.6023, Val Loss=1.4412, lr=0.0010
[2025-05-05 11:20:33,356][train][INFO] - Epoch 87/100, Val Acc=0.6840, Val Loss=1.5432, lr=0.0010
[2025-05-05 11:20:34,125][train][INFO] - Epoch 85/100, Val Acc=0.3892, Val Loss=2.2437, lr=0.0010
[2025-05-05 11:20:34,304][train][INFO] - Epoch 87/100, Val Acc=0.6063, Val Loss=1.4342, lr=0.0010
[2025-05-05 11:20:40,433][train][INFO] - Epoch 88/100, Val Acc=0.6792, Val Loss=1.5487, lr=0.0010
[2025-05-05 11:20:41,645][train][INFO] - Epoch 86/100, Val Acc=0.3898, Val Loss=2.2361, lr=0.0010
[2025-05-05 11:20:41,776][train][INFO] - Epoch 88/100, Val Acc=0.6072, Val Loss=1.4321, lr=0.0010
[2025-05-05 11:20:47,839][train][INFO] - Epoch 89/100, Val Acc=0.6829, Val Loss=1.5551, lr=0.0010
[2025-05-05 11:20:49,104][train][INFO] - Epoch 87/100, Val Acc=0.3871, Val Loss=2.2287, lr=0.0010
[2025-05-05 11:20:49,109][train][INFO] - Epoch 89/100, Val Acc=0.6058, Val Loss=1.4470, lr=0.0010
[2025-05-05 11:20:55,323][train][INFO] - Epoch 90/100, Val Acc=0.6793, Val Loss=1.5639, lr=0.0010
[2025-05-05 11:20:56,481][train][INFO] - Epoch 90/100, Val Acc=0.6036, Val Loss=1.4469, lr=0.0010
[2025-05-05 11:20:56,643][train][INFO] - Epoch 88/100, Val Acc=0.3899, Val Loss=2.2374, lr=0.0010
[2025-05-05 11:21:02,719][train][INFO] - Epoch 91/100, Val Acc=0.6820, Val Loss=1.5529, lr=0.0001
[2025-05-05 11:21:04,328][train][INFO] - Epoch 91/100, Val Acc=0.6079, Val Loss=1.4271, lr=0.0001
[2025-05-05 11:21:04,485][train][INFO] - Epoch 89/100, Val Acc=0.3840, Val Loss=2.2706, lr=0.0010
[2025-05-05 11:21:09,941][train][INFO] - Epoch 92/100, Val Acc=0.6804, Val Loss=1.5591, lr=0.0001
[2025-05-05 11:21:11,954][train][INFO] - Epoch 90/100, Val Acc=0.3852, Val Loss=2.2457, lr=0.0010
[2025-05-05 11:21:11,977][train][INFO] - Epoch 92/100, Val Acc=0.6044, Val Loss=1.4301, lr=0.0001
[2025-05-05 11:21:16,820][train][INFO] - Epoch 93/100, Val Acc=0.6830, Val Loss=1.5443, lr=0.0001
[2025-05-05 11:21:19,002][train][INFO] - Epoch 93/100, Val Acc=0.6097, Val Loss=1.4247, lr=0.0001
[2025-05-05 11:21:19,453][train][INFO] - Epoch 91/100, Val Acc=0.3946, Val Loss=2.2095, lr=0.0001
[2025-05-05 11:21:24,658][train][INFO] - Epoch 94/100, Val Acc=0.6817, Val Loss=1.5424, lr=0.0001
[2025-05-05 11:21:26,566][train][INFO] - Epoch 94/100, Val Acc=0.6098, Val Loss=1.4179, lr=0.0001
[2025-05-05 11:21:27,031][train][INFO] - Epoch 92/100, Val Acc=0.3952, Val Loss=2.2068, lr=0.0001
[2025-05-05 11:21:32,287][train][INFO] - Epoch 95/100, Val Acc=0.6810, Val Loss=1.5514, lr=0.0001
[2025-05-05 11:21:34,104][train][INFO] - Epoch 95/100, Val Acc=0.6098, Val Loss=1.4192, lr=0.0001
[2025-05-05 11:21:34,479][train][INFO] - Epoch 93/100, Val Acc=0.3945, Val Loss=2.2121, lr=0.0001
[2025-05-05 11:21:39,708][train][INFO] - Epoch 96/100, Val Acc=0.6826, Val Loss=1.5442, lr=0.0001
[2025-05-05 11:21:41,563][train][INFO] - Epoch 94/100, Val Acc=0.3974, Val Loss=2.2002, lr=0.0001
[2025-05-05 11:21:41,654][train][INFO] - Epoch 96/100, Val Acc=0.6083, Val Loss=1.4184, lr=0.0001
[2025-05-05 11:21:47,362][train][INFO] - Epoch 97/100, Val Acc=0.6836, Val Loss=1.5492, lr=0.0001
[2025-05-05 11:21:49,063][train][INFO] - Epoch 97/100, Val Acc=0.6089, Val Loss=1.4248, lr=0.0001
[2025-05-05 11:21:49,166][train][INFO] - Epoch 95/100, Val Acc=0.3963, Val Loss=2.2080, lr=0.0001
[2025-05-05 11:21:55,066][train][INFO] - Epoch 98/100, Val Acc=0.6834, Val Loss=1.5450, lr=0.0001
[2025-05-05 11:21:56,368][train][INFO] - Epoch 96/100, Val Acc=0.3966, Val Loss=2.2019, lr=0.0001
[2025-05-05 11:21:56,602][train][INFO] - Epoch 98/100, Val Acc=0.6095, Val Loss=1.4204, lr=0.0001
[2025-05-05 11:22:02,258][train][INFO] - Epoch 99/100, Val Acc=0.6813, Val Loss=1.5486, lr=0.0001
[2025-05-05 11:22:04,042][train][INFO] - Epoch 97/100, Val Acc=0.3951, Val Loss=2.2070, lr=0.0001
[2025-05-05 11:22:04,103][train][INFO] - Epoch 99/100, Val Acc=0.6096, Val Loss=1.4260, lr=0.0001
[2025-05-05 11:22:09,779][train][INFO] - Epoch 100/100, Val Acc=0.6818, Val Loss=1.5518, lr=0.0001
[2025-05-05 11:22:11,252][train][INFO] - Epoch 98/100, Val Acc=0.3940, Val Loss=2.2054, lr=0.0001
[2025-05-05 11:22:11,569][train][INFO] - Epoch 100/100, Val Acc=0.6103, Val Loss=1.4206, lr=0.0001
[2025-05-05 11:22:14,925][train][INFO] - After training : Train Acc=0.9827  Val Acc=0.6840
[2025-05-05 11:22:14,930][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 11:22:16,739][train][INFO] - After training : Train Acc=0.7513  Val Acc=0.6103
[2025-05-05 11:22:16,746][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 11:22:18,712][train][INFO] - Epoch 99/100, Val Acc=0.3947, Val Loss=2.2080, lr=0.0001
[2025-05-05 11:22:25,994][train][INFO] - Epoch 100/100, Val Acc=0.3966, Val Loss=2.2044, lr=0.0001
[2025-05-05 11:22:31,161][train][INFO] - After training : Train Acc=0.4097  Val Acc=0.3974
[2025-05-05 11:22:31,166][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 11:24:03,153][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 11:24:04,815][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 11:24:16,882][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 11:25:36,552][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 11:25:37,028][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 11:25:41,409][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 11:25:41,821][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 11:26:00,524][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 11:26:00,934][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 11:49:07,966][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-05 11:49:08,051][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:49:08,051][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:49:08,051][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:49:19,179][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-05 11:49:19,239][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:49:19,239][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:49:19,239][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 11:49:21,672][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:49:29,936][train][INFO] - Epoch 1/100, Val Acc=0.1577, Val Loss=3.3296, lr=0.0100
[2025-05-05 11:49:33,384][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 11:49:38,392][train][INFO] - Epoch 2/100, Val Acc=0.3635, Val Loss=2.4141, lr=0.0100
[2025-05-05 11:49:40,948][train][INFO] - Epoch 1/100, Val Acc=0.1243, Val Loss=3.4677, lr=0.0100
[2025-05-05 11:49:41,537][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 11:49:41,591][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 11:49:41,591][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 11:49:41,592][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 11:49:46,565][train][INFO] - Epoch 3/100, Val Acc=0.4327, Val Loss=2.0928, lr=0.0100
[2025-05-05 11:49:49,420][train][INFO] - Epoch 2/100, Val Acc=0.2144, Val Loss=3.1136, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 11:49:54,524][train][INFO] - Epoch 4/100, Val Acc=0.4947, Val Loss=1.8791, lr=0.0100
[2025-05-05 11:49:56,018][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 11:49:57,372][train][INFO] - Epoch 3/100, Val Acc=0.2104, Val Loss=3.5578, lr=0.0100
[2025-05-05 11:50:02,410][train][INFO] - Epoch 5/100, Val Acc=0.5280, Val Loss=1.7670, lr=0.0100
[2025-05-05 11:50:03,432][train][INFO] - Epoch 1/100, Val Acc=0.2505, Val Loss=2.8838, lr=0.0100
[2025-05-05 11:50:05,027][train][INFO] - Epoch 4/100, Val Acc=0.3918, Val Loss=2.2622, lr=0.0100
[2025-05-05 11:50:09,917][train][INFO] - Epoch 6/100, Val Acc=0.5283, Val Loss=1.8656, lr=0.0100
[2025-05-05 11:50:10,097][train][INFO] - Epoch 2/100, Val Acc=0.4556, Val Loss=2.0225, lr=0.0100
[2025-05-05 11:50:11,949][train][INFO] - Epoch 5/100, Val Acc=0.3694, Val Loss=2.3837, lr=0.0100
[2025-05-05 11:50:16,764][train][INFO] - Epoch 7/100, Val Acc=0.5347, Val Loss=1.8302, lr=0.0100
[2025-05-05 11:50:18,132][train][INFO] - Epoch 3/100, Val Acc=0.5092, Val Loss=1.8887, lr=0.0100
[2025-05-05 11:50:19,625][train][INFO] - Epoch 6/100, Val Acc=0.4652, Val Loss=1.9748, lr=0.0100
[2025-05-05 11:50:24,648][train][INFO] - Epoch 8/100, Val Acc=0.5859, Val Loss=1.5801, lr=0.0100
[2025-05-05 11:50:25,661][train][INFO] - Epoch 4/100, Val Acc=0.5465, Val Loss=1.7416, lr=0.0100
[2025-05-05 11:50:27,522][train][INFO] - Epoch 7/100, Val Acc=0.4782, Val Loss=1.9643, lr=0.0100
[2025-05-05 11:50:32,187][train][INFO] - Epoch 9/100, Val Acc=0.5766, Val Loss=1.6506, lr=0.0100
[2025-05-05 11:50:33,043][train][INFO] - Epoch 5/100, Val Acc=0.5728, Val Loss=1.6605, lr=0.0100
[2025-05-05 11:50:34,919][train][INFO] - Epoch 8/100, Val Acc=0.5280, Val Loss=1.7707, lr=0.0100
[2025-05-05 11:50:39,816][train][INFO] - Epoch 10/100, Val Acc=0.6010, Val Loss=1.5615, lr=0.0100
[2025-05-05 11:50:40,820][train][INFO] - Epoch 6/100, Val Acc=0.5776, Val Loss=1.6386, lr=0.0100
[2025-05-05 11:50:42,913][train][INFO] - Epoch 9/100, Val Acc=0.5036, Val Loss=1.9350, lr=0.0100
[2025-05-05 11:50:47,485][train][INFO] - Epoch 11/100, Val Acc=0.6089, Val Loss=1.5011, lr=0.0100
[2025-05-05 11:50:47,948][train][INFO] - Epoch 7/100, Val Acc=0.6162, Val Loss=1.4876, lr=0.0100
[2025-05-05 11:50:50,451][train][INFO] - Epoch 10/100, Val Acc=0.5359, Val Loss=1.7538, lr=0.0100
[2025-05-05 11:50:55,098][train][INFO] - Epoch 12/100, Val Acc=0.5922, Val Loss=1.6466, lr=0.0100
[2025-05-05 11:50:55,428][train][INFO] - Epoch 8/100, Val Acc=0.5950, Val Loss=1.6438, lr=0.0100
[2025-05-05 11:50:58,245][train][INFO] - Epoch 11/100, Val Acc=0.5591, Val Loss=1.6914, lr=0.0100
[2025-05-05 11:51:03,016][train][INFO] - Epoch 13/100, Val Acc=0.6036, Val Loss=1.5865, lr=0.0100
[2025-05-05 11:51:03,153][train][INFO] - Epoch 9/100, Val Acc=0.6101, Val Loss=1.5373, lr=0.0100
[2025-05-05 11:51:05,838][train][INFO] - Epoch 12/100, Val Acc=0.5534, Val Loss=1.6936, lr=0.0100
[2025-05-05 11:51:09,550][train][INFO] - Epoch 10/100, Val Acc=0.6084, Val Loss=1.5730, lr=0.0100
[2025-05-05 11:51:10,799][train][INFO] - Epoch 14/100, Val Acc=0.6130, Val Loss=1.5642, lr=0.0100
[2025-05-05 11:51:14,062][train][INFO] - Epoch 13/100, Val Acc=0.5422, Val Loss=1.7611, lr=0.0100
[2025-05-05 11:51:17,345][train][INFO] - Epoch 11/100, Val Acc=0.6368, Val Loss=1.4474, lr=0.0100
[2025-05-05 11:51:18,136][train][INFO] - Epoch 15/100, Val Acc=0.6110, Val Loss=1.5924, lr=0.0100
[2025-05-05 11:51:22,246][train][INFO] - Epoch 14/100, Val Acc=0.5712, Val Loss=1.6550, lr=0.0100
[2025-05-05 11:51:25,143][train][INFO] - Epoch 12/100, Val Acc=0.6155, Val Loss=1.5780, lr=0.0100
[2025-05-05 11:51:25,679][train][INFO] - Epoch 16/100, Val Acc=0.5992, Val Loss=1.6565, lr=0.0100
[2025-05-05 11:51:30,315][train][INFO] - Epoch 15/100, Val Acc=0.5647, Val Loss=1.6498, lr=0.0100
[2025-05-05 11:51:32,038][train][INFO] - Epoch 13/100, Val Acc=0.6244, Val Loss=1.5574, lr=0.0100
[2025-05-05 11:51:32,677][train][INFO] - Epoch 17/100, Val Acc=0.6250, Val Loss=1.4985, lr=0.0100
[2025-05-05 11:51:38,127][train][INFO] - Epoch 16/100, Val Acc=0.5761, Val Loss=1.6378, lr=0.0100
[2025-05-05 11:51:39,726][train][INFO] - Epoch 14/100, Val Acc=0.6376, Val Loss=1.4839, lr=0.0100
[2025-05-05 11:51:40,159][train][INFO] - Epoch 18/100, Val Acc=0.6260, Val Loss=1.5538, lr=0.0100
[2025-05-05 11:51:46,007][train][INFO] - Epoch 17/100, Val Acc=0.5694, Val Loss=1.7246, lr=0.0100
[2025-05-05 11:51:47,135][train][INFO] - Epoch 15/100, Val Acc=0.6270, Val Loss=1.5513, lr=0.0100
[2025-05-05 11:51:47,227][train][INFO] - Epoch 19/100, Val Acc=0.6159, Val Loss=1.5863, lr=0.0100
[2025-05-05 11:51:53,287][train][INFO] - Epoch 18/100, Val Acc=0.5727, Val Loss=1.7548, lr=0.0100
[2025-05-05 11:51:54,825][train][INFO] - Epoch 16/100, Val Acc=0.6368, Val Loss=1.4887, lr=0.0100
[2025-05-05 11:51:54,965][train][INFO] - Epoch 20/100, Val Acc=0.6368, Val Loss=1.5093, lr=0.0100
[2025-05-05 11:52:00,838][train][INFO] - Epoch 19/100, Val Acc=0.5976, Val Loss=1.5499, lr=0.0100
[2025-05-05 11:52:01,886][train][INFO] - Epoch 17/100, Val Acc=0.6311, Val Loss=1.5867, lr=0.0100
[2025-05-05 11:52:02,732][train][INFO] - Epoch 21/100, Val Acc=0.6289, Val Loss=1.5634, lr=0.0100
[2025-05-05 11:52:08,330][train][INFO] - Epoch 20/100, Val Acc=0.5944, Val Loss=1.5749, lr=0.0100
[2025-05-05 11:52:09,527][train][INFO] - Epoch 18/100, Val Acc=0.6429, Val Loss=1.5122, lr=0.0100
[2025-05-05 11:52:10,154][train][INFO] - Epoch 22/100, Val Acc=0.6387, Val Loss=1.5073, lr=0.0100
[2025-05-05 11:52:15,744][train][INFO] - Epoch 21/100, Val Acc=0.6005, Val Loss=1.5581, lr=0.0100
[2025-05-05 11:52:16,842][train][INFO] - Epoch 19/100, Val Acc=0.6503, Val Loss=1.4388, lr=0.0100
[2025-05-05 11:52:17,995][train][INFO] - Epoch 23/100, Val Acc=0.6111, Val Loss=1.6496, lr=0.0100
[2025-05-05 11:52:23,422][train][INFO] - Epoch 22/100, Val Acc=0.5676, Val Loss=1.8065, lr=0.0100
[2025-05-05 11:52:24,280][train][INFO] - Epoch 20/100, Val Acc=0.6447, Val Loss=1.5121, lr=0.0100
[2025-05-05 11:52:25,272][train][INFO] - Epoch 24/100, Val Acc=0.6215, Val Loss=1.6173, lr=0.0100
[2025-05-05 11:52:30,662][train][INFO] - Epoch 23/100, Val Acc=0.6143, Val Loss=1.4916, lr=0.0100
[2025-05-05 11:52:32,071][train][INFO] - Epoch 21/100, Val Acc=0.6501, Val Loss=1.4567, lr=0.0100
[2025-05-05 11:52:33,191][train][INFO] - Epoch 25/100, Val Acc=0.6293, Val Loss=1.5588, lr=0.0100
[2025-05-05 11:52:38,282][train][INFO] - Epoch 24/100, Val Acc=0.6160, Val Loss=1.5620, lr=0.0100
[2025-05-05 11:52:39,939][train][INFO] - Epoch 22/100, Val Acc=0.6182, Val Loss=1.6556, lr=0.0100
[2025-05-05 11:52:40,920][train][INFO] - Epoch 26/100, Val Acc=0.6272, Val Loss=1.6077, lr=0.0100
[2025-05-05 11:52:45,985][train][INFO] - Epoch 25/100, Val Acc=0.6039, Val Loss=1.6388, lr=0.0100
[2025-05-05 11:52:47,094][train][INFO] - Epoch 23/100, Val Acc=0.6429, Val Loss=1.5438, lr=0.0100
[2025-05-05 11:52:48,568][train][INFO] - Epoch 27/100, Val Acc=0.6273, Val Loss=1.6279, lr=0.0100
[2025-05-05 11:52:53,726][train][INFO] - Epoch 26/100, Val Acc=0.6033, Val Loss=1.6363, lr=0.0100
[2025-05-05 11:52:54,898][train][INFO] - Epoch 24/100, Val Acc=0.6590, Val Loss=1.4446, lr=0.0100
[2025-05-05 11:52:56,342][train][INFO] - Epoch 28/100, Val Acc=0.6327, Val Loss=1.6055, lr=0.0100
[2025-05-05 11:53:01,007][train][INFO] - Epoch 27/100, Val Acc=0.5934, Val Loss=1.7445, lr=0.0100
[2025-05-05 11:53:02,289][train][INFO] - Epoch 25/100, Val Acc=0.6476, Val Loss=1.4919, lr=0.0100
[2025-05-05 11:53:02,963][train][INFO] - Epoch 29/100, Val Acc=0.6412, Val Loss=1.5198, lr=0.0100
[2025-05-05 11:53:08,954][train][INFO] - Epoch 28/100, Val Acc=0.6271, Val Loss=1.5145, lr=0.0100
[2025-05-05 11:53:09,736][train][INFO] - Epoch 26/100, Val Acc=0.6420, Val Loss=1.5597, lr=0.0100
[2025-05-05 11:53:10,332][train][INFO] - Epoch 30/100, Val Acc=0.6466, Val Loss=1.5375, lr=0.0100
[2025-05-05 11:53:16,863][train][INFO] - Epoch 29/100, Val Acc=0.5993, Val Loss=1.7208, lr=0.0100
[2025-05-05 11:53:17,267][train][INFO] - Epoch 27/100, Val Acc=0.6429, Val Loss=1.5432, lr=0.0100
[2025-05-05 11:53:18,012][train][INFO] - Epoch 31/100, Val Acc=0.6327, Val Loss=1.6095, lr=0.0100
[2025-05-05 11:53:24,612][train][INFO] - Epoch 28/100, Val Acc=0.6444, Val Loss=1.5682, lr=0.0100
[2025-05-05 11:53:24,761][train][INFO] - Epoch 30/100, Val Acc=0.6072, Val Loss=1.6033, lr=0.0100
[2025-05-05 11:53:25,889][train][INFO] - Epoch 32/100, Val Acc=0.6433, Val Loss=1.5484, lr=0.0100
[2025-05-05 11:53:32,476][train][INFO] - Epoch 31/100, Val Acc=0.6156, Val Loss=1.5919, lr=0.0100
[2025-05-05 11:53:32,577][train][INFO] - Epoch 29/100, Val Acc=0.6394, Val Loss=1.5485, lr=0.0100
[2025-05-05 11:53:33,605][train][INFO] - Epoch 33/100, Val Acc=0.6306, Val Loss=1.6068, lr=0.0100
[2025-05-05 11:53:39,647][train][INFO] - Epoch 30/100, Val Acc=0.6397, Val Loss=1.5599, lr=0.0100
[2025-05-05 11:53:40,251][train][INFO] - Epoch 32/100, Val Acc=0.6165, Val Loss=1.5961, lr=0.0100
[2025-05-05 11:53:40,800][train][INFO] - Epoch 34/100, Val Acc=0.6425, Val Loss=1.5678, lr=0.0100
[2025-05-05 11:53:47,214][train][INFO] - Epoch 31/100, Val Acc=0.6432, Val Loss=1.5711, lr=0.0100
[2025-05-05 11:53:48,193][train][INFO] - Epoch 33/100, Val Acc=0.6277, Val Loss=1.5790, lr=0.0100
[2025-05-05 11:53:48,541][train][INFO] - Epoch 35/100, Val Acc=0.6394, Val Loss=1.5941, lr=0.0100
[2025-05-05 11:53:54,371][train][INFO] - Epoch 32/100, Val Acc=0.6553, Val Loss=1.5149, lr=0.0100
[2025-05-05 11:53:55,911][train][INFO] - Epoch 34/100, Val Acc=0.6255, Val Loss=1.5593, lr=0.0100
[2025-05-05 11:53:55,960][train][INFO] - Epoch 36/100, Val Acc=0.6303, Val Loss=1.6240, lr=0.0100
[2025-05-05 11:54:02,064][train][INFO] - Epoch 33/100, Val Acc=0.6464, Val Loss=1.5382, lr=0.0100
[2025-05-05 11:54:03,397][train][INFO] - Epoch 35/100, Val Acc=0.6246, Val Loss=1.6329, lr=0.0100
[2025-05-05 11:54:04,084][train][INFO] - Epoch 37/100, Val Acc=0.6348, Val Loss=1.6449, lr=0.0100
[2025-05-05 11:54:09,464][train][INFO] - Epoch 34/100, Val Acc=0.6416, Val Loss=1.5724, lr=0.0100
[2025-05-05 11:54:10,896][train][INFO] - Epoch 36/100, Val Acc=0.6115, Val Loss=1.6608, lr=0.0100
[2025-05-05 11:54:11,426][train][INFO] - Epoch 38/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-05 11:54:16,774][train][INFO] - Epoch 35/100, Val Acc=0.6436, Val Loss=1.5976, lr=0.0100
[2025-05-05 11:54:18,714][train][INFO] - Epoch 37/100, Val Acc=0.6124, Val Loss=1.6762, lr=0.0100
[2025-05-05 11:54:19,355][train][INFO] - Epoch 39/100, Val Acc=0.6420, Val Loss=1.6029, lr=0.0100
[2025-05-05 11:54:23,710][train][INFO] - Epoch 36/100, Val Acc=0.6483, Val Loss=1.5729, lr=0.0100
[2025-05-05 11:54:26,701][train][INFO] - Epoch 38/100, Val Acc=0.6327, Val Loss=1.5198, lr=0.0100
[2025-05-05 11:54:26,941][train][INFO] - Epoch 40/100, Val Acc=0.6386, Val Loss=1.6069, lr=0.0100
[2025-05-05 11:54:31,392][train][INFO] - Epoch 37/100, Val Acc=0.6545, Val Loss=1.5314, lr=0.0100
[2025-05-05 11:54:34,667][train][INFO] - Epoch 39/100, Val Acc=0.6176, Val Loss=1.6937, lr=0.0100
[2025-05-05 11:54:34,690][train][INFO] - Epoch 41/100, Val Acc=0.6439, Val Loss=1.6088, lr=0.0100
[2025-05-05 11:54:38,780][train][INFO] - Epoch 38/100, Val Acc=0.6297, Val Loss=1.7314, lr=0.0100
[2025-05-05 11:54:41,790][train][INFO] - Epoch 42/100, Val Acc=0.6219, Val Loss=1.6998, lr=0.0100
[2025-05-05 11:54:42,382][train][INFO] - Epoch 40/100, Val Acc=0.6135, Val Loss=1.6814, lr=0.0100
[2025-05-05 11:54:45,600][train][INFO] - Epoch 39/100, Val Acc=0.6464, Val Loss=1.6116, lr=0.0100
[2025-05-05 11:54:49,385][train][INFO] - Epoch 43/100, Val Acc=0.6423, Val Loss=1.6399, lr=0.0100
[2025-05-05 11:54:50,180][train][INFO] - Epoch 41/100, Val Acc=0.6220, Val Loss=1.6187, lr=0.0100
[2025-05-05 11:54:53,099][train][INFO] - Epoch 40/100, Val Acc=0.6559, Val Loss=1.5331, lr=0.0100
[2025-05-05 11:54:57,404][train][INFO] - Epoch 44/100, Val Acc=0.6280, Val Loss=1.6860, lr=0.0100
[2025-05-05 11:54:58,118][train][INFO] - Epoch 42/100, Val Acc=0.6233, Val Loss=1.6436, lr=0.0100
[2025-05-05 11:55:01,114][train][INFO] - Epoch 41/100, Val Acc=0.6492, Val Loss=1.5879, lr=0.0100
[2025-05-05 11:55:05,294][train][INFO] - Epoch 45/100, Val Acc=0.6340, Val Loss=1.6459, lr=0.0100
[2025-05-05 11:55:05,919][train][INFO] - Epoch 43/100, Val Acc=0.6127, Val Loss=1.6797, lr=0.0100
[2025-05-05 11:55:08,493][train][INFO] - Epoch 42/100, Val Acc=0.6482, Val Loss=1.6061, lr=0.0100
[2025-05-05 11:55:12,868][train][INFO] - Epoch 46/100, Val Acc=0.6413, Val Loss=1.6074, lr=0.0100
[2025-05-05 11:55:13,696][train][INFO] - Epoch 44/100, Val Acc=0.6217, Val Loss=1.6428, lr=0.0100
[2025-05-05 11:55:15,517][train][INFO] - Epoch 43/100, Val Acc=0.6402, Val Loss=1.6533, lr=0.0100
[2025-05-05 11:55:20,759][train][INFO] - Epoch 47/100, Val Acc=0.6336, Val Loss=1.6733, lr=0.0100
[2025-05-05 11:55:22,088][train][INFO] - Epoch 45/100, Val Acc=0.6198, Val Loss=1.6318, lr=0.0100
[2025-05-05 11:55:22,938][train][INFO] - Epoch 44/100, Val Acc=0.6341, Val Loss=1.7037, lr=0.0100
[2025-05-05 11:55:28,581][train][INFO] - Epoch 48/100, Val Acc=0.6446, Val Loss=1.5907, lr=0.0100
[2025-05-05 11:55:30,070][train][INFO] - Epoch 46/100, Val Acc=0.6274, Val Loss=1.6337, lr=0.0100
[2025-05-05 11:55:30,224][train][INFO] - Epoch 45/100, Val Acc=0.6469, Val Loss=1.5789, lr=0.0100
[2025-05-05 11:55:36,353][train][INFO] - Epoch 49/100, Val Acc=0.6470, Val Loss=1.5903, lr=0.0100
[2025-05-05 11:55:37,596][train][INFO] - Epoch 46/100, Val Acc=0.6390, Val Loss=1.7001, lr=0.0100
[2025-05-05 11:55:37,859][train][INFO] - Epoch 47/100, Val Acc=0.6168, Val Loss=1.6955, lr=0.0100
[2025-05-05 11:55:43,536][train][INFO] - Epoch 50/100, Val Acc=0.6465, Val Loss=1.5903, lr=0.0100
[2025-05-05 11:55:44,858][train][INFO] - Epoch 47/100, Val Acc=0.6412, Val Loss=1.6508, lr=0.0100
[2025-05-05 11:55:45,452][train][INFO] - Epoch 48/100, Val Acc=0.6334, Val Loss=1.5860, lr=0.0100
[2025-05-05 11:55:50,982][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6533, lr=0.0100
[2025-05-05 11:55:52,369][train][INFO] - Epoch 48/100, Val Acc=0.6526, Val Loss=1.5607, lr=0.0100
[2025-05-05 11:55:53,628][train][INFO] - Epoch 49/100, Val Acc=0.6294, Val Loss=1.6062, lr=0.0100
[2025-05-05 11:55:58,730][train][INFO] - Epoch 52/100, Val Acc=0.6307, Val Loss=1.6962, lr=0.0100
[2025-05-05 11:55:59,669][train][INFO] - Epoch 49/100, Val Acc=0.6560, Val Loss=1.5794, lr=0.0100
[2025-05-05 11:56:01,019][train][INFO] - Epoch 50/100, Val Acc=0.6342, Val Loss=1.5930, lr=0.0100
[2025-05-05 11:56:06,257][train][INFO] - Epoch 53/100, Val Acc=0.6374, Val Loss=1.6606, lr=0.0100
[2025-05-05 11:56:07,243][train][INFO] - Epoch 50/100, Val Acc=0.6469, Val Loss=1.6455, lr=0.0100
[2025-05-05 11:56:08,822][train][INFO] - Epoch 51/100, Val Acc=0.6248, Val Loss=1.6625, lr=0.0100
[2025-05-05 11:56:13,814][train][INFO] - Epoch 54/100, Val Acc=0.6352, Val Loss=1.6768, lr=0.0100
[2025-05-05 11:56:14,991][train][INFO] - Epoch 51/100, Val Acc=0.6387, Val Loss=1.6781, lr=0.0100
[2025-05-05 11:56:16,555][train][INFO] - Epoch 52/100, Val Acc=0.6223, Val Loss=1.6883, lr=0.0100
[2025-05-05 11:56:21,293][train][INFO] - Epoch 55/100, Val Acc=0.6336, Val Loss=1.7275, lr=0.0100
[2025-05-05 11:56:22,274][train][INFO] - Epoch 52/100, Val Acc=0.6422, Val Loss=1.6613, lr=0.0100
[2025-05-05 11:56:23,984][train][INFO] - Epoch 53/100, Val Acc=0.6350, Val Loss=1.6011, lr=0.0100
[2025-05-05 11:56:28,614][train][INFO] - Epoch 56/100, Val Acc=0.6301, Val Loss=1.6911, lr=0.0100
[2025-05-05 11:56:29,871][train][INFO] - Epoch 53/100, Val Acc=0.6386, Val Loss=1.6429, lr=0.0100
[2025-05-05 11:56:31,951][train][INFO] - Epoch 54/100, Val Acc=0.6203, Val Loss=1.7305, lr=0.0100
[2025-05-05 11:56:36,242][train][INFO] - Epoch 57/100, Val Acc=0.6364, Val Loss=1.7036, lr=0.0100
[2025-05-05 11:56:37,346][train][INFO] - Epoch 54/100, Val Acc=0.6437, Val Loss=1.6218, lr=0.0100
[2025-05-05 11:56:39,915][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6972, lr=0.0100
[2025-05-05 11:56:43,754][train][INFO] - Epoch 58/100, Val Acc=0.6195, Val Loss=1.7899, lr=0.0100
[2025-05-05 11:56:45,322][train][INFO] - Epoch 55/100, Val Acc=0.6420, Val Loss=1.6428, lr=0.0100
[2025-05-05 11:56:47,770][train][INFO] - Epoch 56/100, Val Acc=0.6283, Val Loss=1.6679, lr=0.0100
[2025-05-05 11:56:51,528][train][INFO] - Epoch 59/100, Val Acc=0.6369, Val Loss=1.6542, lr=0.0100
[2025-05-05 11:56:52,363][train][INFO] - Epoch 56/100, Val Acc=0.6469, Val Loss=1.6637, lr=0.0100
[2025-05-05 11:56:55,070][train][INFO] - Epoch 57/100, Val Acc=0.6189, Val Loss=1.7435, lr=0.0100
[2025-05-05 11:56:58,856][train][INFO] - Epoch 57/100, Val Acc=0.6391, Val Loss=1.6646, lr=0.0100
[2025-05-05 11:56:59,442][train][INFO] - Epoch 60/100, Val Acc=0.6361, Val Loss=1.7176, lr=0.0100
[2025-05-05 11:57:03,032][train][INFO] - Epoch 58/100, Val Acc=0.6154, Val Loss=1.7788, lr=0.0100
[2025-05-05 11:57:06,338][train][INFO] - Epoch 58/100, Val Acc=0.6600, Val Loss=1.6111, lr=0.0100
[2025-05-05 11:57:06,828][train][INFO] - Epoch 61/100, Val Acc=0.7002, Val Loss=1.3470, lr=0.0010
[2025-05-05 11:57:10,734][train][INFO] - Epoch 59/100, Val Acc=0.6274, Val Loss=1.6840, lr=0.0100
[2025-05-05 11:57:13,284][train][INFO] - Epoch 59/100, Val Acc=0.6454, Val Loss=1.6256, lr=0.0100
[2025-05-05 11:57:14,727][train][INFO] - Epoch 62/100, Val Acc=0.7021, Val Loss=1.3435, lr=0.0010
[2025-05-05 11:57:18,493][train][INFO] - Epoch 60/100, Val Acc=0.6355, Val Loss=1.6562, lr=0.0100
[2025-05-05 11:57:20,906][train][INFO] - Epoch 60/100, Val Acc=0.6594, Val Loss=1.5858, lr=0.0100
[2025-05-05 11:57:22,164][train][INFO] - Epoch 63/100, Val Acc=0.7037, Val Loss=1.3430, lr=0.0010
[2025-05-05 11:57:26,295][train][INFO] - Epoch 61/100, Val Acc=0.6910, Val Loss=1.3330, lr=0.0010
[2025-05-05 11:57:28,112][train][INFO] - Epoch 61/100, Val Acc=0.7068, Val Loss=1.3268, lr=0.0010
[2025-05-05 11:57:29,858][train][INFO] - Epoch 64/100, Val Acc=0.7071, Val Loss=1.3501, lr=0.0010
[2025-05-05 11:57:34,472][train][INFO] - Epoch 62/100, Val Acc=0.6990, Val Loss=1.3231, lr=0.0010
[2025-05-05 11:57:35,849][train][INFO] - Epoch 62/100, Val Acc=0.7087, Val Loss=1.3174, lr=0.0010
[2025-05-05 11:57:37,529][train][INFO] - Epoch 65/100, Val Acc=0.7069, Val Loss=1.3532, lr=0.0010
[2025-05-05 11:57:42,116][train][INFO] - Epoch 63/100, Val Acc=0.6973, Val Loss=1.3335, lr=0.0010
[2025-05-05 11:57:43,355][train][INFO] - Epoch 63/100, Val Acc=0.7128, Val Loss=1.3294, lr=0.0010
[2025-05-05 11:57:45,110][train][INFO] - Epoch 66/100, Val Acc=0.7082, Val Loss=1.3601, lr=0.0010
[2025-05-05 11:57:50,141][train][INFO] - Epoch 64/100, Val Acc=0.6975, Val Loss=1.3458, lr=0.0010
[2025-05-05 11:57:50,890][train][INFO] - Epoch 64/100, Val Acc=0.7140, Val Loss=1.3416, lr=0.0010
[2025-05-05 11:57:52,505][train][INFO] - Epoch 67/100, Val Acc=0.7085, Val Loss=1.3621, lr=0.0010
[2025-05-05 11:57:57,915][train][INFO] - Epoch 65/100, Val Acc=0.6985, Val Loss=1.3463, lr=0.0010
[2025-05-05 11:57:58,731][train][INFO] - Epoch 65/100, Val Acc=0.7142, Val Loss=1.3431, lr=0.0010
[2025-05-05 11:58:00,092][train][INFO] - Epoch 68/100, Val Acc=0.7095, Val Loss=1.3662, lr=0.0010
[2025-05-05 11:58:05,180][train][INFO] - Epoch 66/100, Val Acc=0.6999, Val Loss=1.3541, lr=0.0010
[2025-05-05 11:58:06,200][train][INFO] - Epoch 66/100, Val Acc=0.7149, Val Loss=1.3516, lr=0.0010
[2025-05-05 11:58:07,715][train][INFO] - Epoch 69/100, Val Acc=0.7081, Val Loss=1.3731, lr=0.0010
[2025-05-05 11:58:12,610][train][INFO] - Epoch 67/100, Val Acc=0.6979, Val Loss=1.3657, lr=0.0010
[2025-05-05 11:58:13,697][train][INFO] - Epoch 67/100, Val Acc=0.7155, Val Loss=1.3565, lr=0.0010
[2025-05-05 11:58:15,536][train][INFO] - Epoch 70/100, Val Acc=0.7091, Val Loss=1.3775, lr=0.0010
[2025-05-05 11:58:19,885][train][INFO] - Epoch 68/100, Val Acc=0.7009, Val Loss=1.3705, lr=0.0010
[2025-05-05 11:58:21,248][train][INFO] - Epoch 68/100, Val Acc=0.7154, Val Loss=1.3594, lr=0.0010
[2025-05-05 11:58:22,905][train][INFO] - Epoch 71/100, Val Acc=0.7114, Val Loss=1.3812, lr=0.0010
[2025-05-05 11:58:27,721][train][INFO] - Epoch 69/100, Val Acc=0.7004, Val Loss=1.3642, lr=0.0010
[2025-05-05 11:58:28,845][train][INFO] - Epoch 69/100, Val Acc=0.7164, Val Loss=1.3684, lr=0.0010
[2025-05-05 11:58:30,405][train][INFO] - Epoch 72/100, Val Acc=0.7103, Val Loss=1.3815, lr=0.0010
[2025-05-05 11:58:35,288][train][INFO] - Epoch 70/100, Val Acc=0.7035, Val Loss=1.3745, lr=0.0010
[2025-05-05 11:58:36,251][train][INFO] - Epoch 70/100, Val Acc=0.7155, Val Loss=1.3682, lr=0.0010
[2025-05-05 11:58:38,336][train][INFO] - Epoch 73/100, Val Acc=0.7094, Val Loss=1.3795, lr=0.0010
[2025-05-05 11:58:43,079][train][INFO] - Epoch 71/100, Val Acc=0.7007, Val Loss=1.3815, lr=0.0010
[2025-05-05 11:58:43,802][train][INFO] - Epoch 71/100, Val Acc=0.7160, Val Loss=1.3635, lr=0.0010
[2025-05-05 11:58:45,908][train][INFO] - Epoch 74/100, Val Acc=0.7107, Val Loss=1.3922, lr=0.0010
[2025-05-05 11:58:50,538][train][INFO] - Epoch 72/100, Val Acc=0.7001, Val Loss=1.3885, lr=0.0010
[2025-05-05 11:58:50,896][train][INFO] - Epoch 72/100, Val Acc=0.7162, Val Loss=1.3717, lr=0.0010
[2025-05-05 11:58:53,658][train][INFO] - Epoch 75/100, Val Acc=0.7100, Val Loss=1.3973, lr=0.0010
[2025-05-05 11:58:58,197][train][INFO] - Epoch 73/100, Val Acc=0.7047, Val Loss=1.3850, lr=0.0010
[2025-05-05 11:58:58,324][train][INFO] - Epoch 73/100, Val Acc=0.7153, Val Loss=1.3632, lr=0.0010
[2025-05-05 11:59:01,215][train][INFO] - Epoch 76/100, Val Acc=0.7114, Val Loss=1.3910, lr=0.0010
[2025-05-05 11:59:05,531][train][INFO] - Epoch 74/100, Val Acc=0.7159, Val Loss=1.3698, lr=0.0010
[2025-05-05 11:59:05,939][train][INFO] - Epoch 74/100, Val Acc=0.7036, Val Loss=1.3889, lr=0.0010
[2025-05-05 11:59:09,183][train][INFO] - Epoch 77/100, Val Acc=0.7121, Val Loss=1.3958, lr=0.0010
[2025-05-05 11:59:13,100][train][INFO] - Epoch 75/100, Val Acc=0.7170, Val Loss=1.3705, lr=0.0010
[2025-05-05 11:59:13,524][train][INFO] - Epoch 75/100, Val Acc=0.7062, Val Loss=1.3951, lr=0.0010
[2025-05-05 11:59:16,807][train][INFO] - Epoch 78/100, Val Acc=0.7125, Val Loss=1.3950, lr=0.0010
[2025-05-05 11:59:20,685][train][INFO] - Epoch 76/100, Val Acc=0.7040, Val Loss=1.4001, lr=0.0010
[2025-05-05 11:59:20,900][train][INFO] - Epoch 76/100, Val Acc=0.7181, Val Loss=1.3755, lr=0.0010
[2025-05-05 11:59:24,542][train][INFO] - Epoch 79/100, Val Acc=0.7122, Val Loss=1.3974, lr=0.0010
[2025-05-05 11:59:28,568][train][INFO] - Epoch 77/100, Val Acc=0.7160, Val Loss=1.3734, lr=0.0010
[2025-05-05 11:59:28,855][train][INFO] - Epoch 77/100, Val Acc=0.7059, Val Loss=1.4042, lr=0.0010
[2025-05-05 11:59:32,168][train][INFO] - Epoch 80/100, Val Acc=0.7105, Val Loss=1.4005, lr=0.0010
[2025-05-05 11:59:36,330][train][INFO] - Epoch 78/100, Val Acc=0.7201, Val Loss=1.3776, lr=0.0010
[2025-05-05 11:59:36,626][train][INFO] - Epoch 78/100, Val Acc=0.6997, Val Loss=1.4160, lr=0.0010
[2025-05-05 11:59:39,610][train][INFO] - Epoch 81/100, Val Acc=0.7136, Val Loss=1.4006, lr=0.0010
[2025-05-05 11:59:44,161][train][INFO] - Epoch 79/100, Val Acc=0.7193, Val Loss=1.3850, lr=0.0010
[2025-05-05 11:59:44,265][train][INFO] - Epoch 79/100, Val Acc=0.7011, Val Loss=1.4245, lr=0.0010
[2025-05-05 11:59:46,703][train][INFO] - Epoch 82/100, Val Acc=0.7123, Val Loss=1.4073, lr=0.0010
[2025-05-05 11:59:51,811][train][INFO] - Epoch 80/100, Val Acc=0.7176, Val Loss=1.3808, lr=0.0010
[2025-05-05 11:59:52,383][train][INFO] - Epoch 80/100, Val Acc=0.7013, Val Loss=1.4228, lr=0.0010
[2025-05-05 11:59:54,539][train][INFO] - Epoch 83/100, Val Acc=0.7109, Val Loss=1.4145, lr=0.0010
[2025-05-05 11:59:59,559][train][INFO] - Epoch 81/100, Val Acc=0.7184, Val Loss=1.3891, lr=0.0010
[2025-05-05 11:59:59,850][train][INFO] - Epoch 81/100, Val Acc=0.7028, Val Loss=1.4262, lr=0.0010
[2025-05-05 12:00:02,271][train][INFO] - Epoch 84/100, Val Acc=0.7107, Val Loss=1.4185, lr=0.0010
[2025-05-05 12:00:06,727][train][INFO] - Epoch 82/100, Val Acc=0.7183, Val Loss=1.3941, lr=0.0010
[2025-05-05 12:00:07,974][train][INFO] - Epoch 82/100, Val Acc=0.7023, Val Loss=1.4333, lr=0.0010
[2025-05-05 12:00:10,163][train][INFO] - Epoch 85/100, Val Acc=0.7107, Val Loss=1.4082, lr=0.0010
[2025-05-05 12:00:14,566][train][INFO] - Epoch 83/100, Val Acc=0.7191, Val Loss=1.3921, lr=0.0010
[2025-05-05 12:00:15,919][train][INFO] - Epoch 83/100, Val Acc=0.7021, Val Loss=1.4370, lr=0.0010
[2025-05-05 12:00:17,622][train][INFO] - Epoch 86/100, Val Acc=0.7129, Val Loss=1.4149, lr=0.0010
[2025-05-05 12:00:21,929][train][INFO] - Epoch 84/100, Val Acc=0.7195, Val Loss=1.3931, lr=0.0010
[2025-05-05 12:00:23,443][train][INFO] - Epoch 84/100, Val Acc=0.7019, Val Loss=1.4373, lr=0.0010
[2025-05-05 12:00:25,739][train][INFO] - Epoch 87/100, Val Acc=0.7138, Val Loss=1.4129, lr=0.0010
[2025-05-05 12:00:29,535][train][INFO] - Epoch 85/100, Val Acc=0.7186, Val Loss=1.3925, lr=0.0010
[2025-05-05 12:00:31,338][train][INFO] - Epoch 85/100, Val Acc=0.7025, Val Loss=1.4495, lr=0.0010
[2025-05-05 12:00:33,421][train][INFO] - Epoch 88/100, Val Acc=0.7119, Val Loss=1.4126, lr=0.0010
[2025-05-05 12:00:36,542][train][INFO] - Epoch 86/100, Val Acc=0.7162, Val Loss=1.3899, lr=0.0010
[2025-05-05 12:00:38,598][train][INFO] - Epoch 86/100, Val Acc=0.7018, Val Loss=1.4454, lr=0.0010
[2025-05-05 12:00:40,751][train][INFO] - Epoch 89/100, Val Acc=0.7099, Val Loss=1.4180, lr=0.0010
[2025-05-05 12:00:43,860][train][INFO] - Epoch 87/100, Val Acc=0.7218, Val Loss=1.3910, lr=0.0010
[2025-05-05 12:00:46,525][train][INFO] - Epoch 87/100, Val Acc=0.7030, Val Loss=1.4425, lr=0.0010
[2025-05-05 12:00:48,163][train][INFO] - Epoch 90/100, Val Acc=0.7139, Val Loss=1.4194, lr=0.0010
[2025-05-05 12:00:51,486][train][INFO] - Epoch 88/100, Val Acc=0.7193, Val Loss=1.3921, lr=0.0010
[2025-05-05 12:00:53,756][train][INFO] - Epoch 88/100, Val Acc=0.7014, Val Loss=1.4433, lr=0.0010
[2025-05-05 12:00:55,684][train][INFO] - Epoch 91/100, Val Acc=0.7134, Val Loss=1.4145, lr=0.0001
[2025-05-05 12:00:59,075][train][INFO] - Epoch 89/100, Val Acc=0.7191, Val Loss=1.3985, lr=0.0010
[2025-05-05 12:01:01,530][train][INFO] - Epoch 89/100, Val Acc=0.7008, Val Loss=1.4569, lr=0.0010
[2025-05-05 12:01:03,209][train][INFO] - Epoch 92/100, Val Acc=0.7120, Val Loss=1.4193, lr=0.0001
[2025-05-05 12:01:06,784][train][INFO] - Epoch 90/100, Val Acc=0.7197, Val Loss=1.3965, lr=0.0010
[2025-05-05 12:01:09,151][train][INFO] - Epoch 90/100, Val Acc=0.7024, Val Loss=1.4636, lr=0.0010
[2025-05-05 12:01:10,582][train][INFO] - Epoch 93/100, Val Acc=0.7129, Val Loss=1.4172, lr=0.0001
[2025-05-05 12:01:14,564][train][INFO] - Epoch 91/100, Val Acc=0.7194, Val Loss=1.3901, lr=0.0001
[2025-05-05 12:01:16,744][train][INFO] - Epoch 91/100, Val Acc=0.7022, Val Loss=1.4532, lr=0.0001
[2025-05-05 12:01:18,338][train][INFO] - Epoch 94/100, Val Acc=0.7127, Val Loss=1.4138, lr=0.0001
[2025-05-05 12:01:21,563][train][INFO] - Epoch 92/100, Val Acc=0.7182, Val Loss=1.3956, lr=0.0001
[2025-05-05 12:01:24,269][train][INFO] - Epoch 92/100, Val Acc=0.7027, Val Loss=1.4558, lr=0.0001
[2025-05-05 12:01:25,871][train][INFO] - Epoch 95/100, Val Acc=0.7138, Val Loss=1.4145, lr=0.0001
[2025-05-05 12:01:28,926][train][INFO] - Epoch 93/100, Val Acc=0.7192, Val Loss=1.3929, lr=0.0001
[2025-05-05 12:01:32,291][train][INFO] - Epoch 93/100, Val Acc=0.7037, Val Loss=1.4555, lr=0.0001
[2025-05-05 12:01:33,343][train][INFO] - Epoch 96/100, Val Acc=0.7140, Val Loss=1.4123, lr=0.0001
[2025-05-05 12:01:36,525][train][INFO] - Epoch 94/100, Val Acc=0.7210, Val Loss=1.3907, lr=0.0001
[2025-05-05 12:01:40,403][train][INFO] - Epoch 94/100, Val Acc=0.7021, Val Loss=1.4520, lr=0.0001
[2025-05-05 12:01:41,381][train][INFO] - Epoch 97/100, Val Acc=0.7119, Val Loss=1.4211, lr=0.0001
[2025-05-05 12:01:43,551][train][INFO] - Epoch 95/100, Val Acc=0.7213, Val Loss=1.3924, lr=0.0001
[2025-05-05 12:01:48,183][train][INFO] - Epoch 95/100, Val Acc=0.7025, Val Loss=1.4524, lr=0.0001
[2025-05-05 12:01:49,261][train][INFO] - Epoch 98/100, Val Acc=0.7124, Val Loss=1.4139, lr=0.0001
[2025-05-05 12:01:51,159][train][INFO] - Epoch 96/100, Val Acc=0.7208, Val Loss=1.3905, lr=0.0001
[2025-05-05 12:01:56,391][train][INFO] - Epoch 96/100, Val Acc=0.7033, Val Loss=1.4493, lr=0.0001
[2025-05-05 12:01:56,647][train][INFO] - Epoch 99/100, Val Acc=0.7122, Val Loss=1.4213, lr=0.0001
[2025-05-05 12:01:58,511][train][INFO] - Epoch 97/100, Val Acc=0.7216, Val Loss=1.3928, lr=0.0001
[2025-05-05 12:02:03,533][train][INFO] - Epoch 100/100, Val Acc=0.7130, Val Loss=1.4135, lr=0.0001
[2025-05-05 12:02:03,589][train][INFO] - Epoch 97/100, Val Acc=0.7040, Val Loss=1.4533, lr=0.0001
[2025-05-05 12:02:05,458][train][INFO] - Epoch 98/100, Val Acc=0.7223, Val Loss=1.3880, lr=0.0001
[2025-05-05 12:02:08,573][train][INFO] - After training : Train Acc=0.9972  Val Acc=0.7140
[2025-05-05 12:02:08,581][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 12:02:11,197][train][INFO] - Epoch 98/100, Val Acc=0.7036, Val Loss=1.4457, lr=0.0001
[2025-05-05 12:02:12,986][train][INFO] - Epoch 99/100, Val Acc=0.7203, Val Loss=1.3955, lr=0.0001
[2025-05-05 12:02:19,034][train][INFO] - Epoch 99/100, Val Acc=0.7048, Val Loss=1.4540, lr=0.0001
[2025-05-05 12:02:20,685][train][INFO] - Epoch 100/100, Val Acc=0.7207, Val Loss=1.3929, lr=0.0001
[2025-05-05 12:02:25,778][train][INFO] - After training : Train Acc=0.9981  Val Acc=0.7223
[2025-05-05 12:02:25,790][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 12:02:26,820][train][INFO] - Epoch 100/100, Val Acc=0.7033, Val Loss=1.4512, lr=0.0001
[2025-05-05 12:02:32,231][train][INFO] - After training : Train Acc=0.9880  Val Acc=0.7062
[2025-05-05 12:02:32,239][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 12:03:58,725][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 12:04:10,351][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 12:04:22,088][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 12:05:54,309][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 12:05:54,816][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 12:06:06,316][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 12:06:06,799][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 12:06:19,258][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 12:06:19,696][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 12:08:46,031][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 5.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 12:08:46,119][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:08:46,120][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:08:46,120][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 12:08:56,308][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 5.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-05 12:08:56,383][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:08:56,383][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:08:56,383][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 12:08:59,741][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 12:09:08,162][train][INFO] - Epoch 1/100, Val Acc=0.2505, Val Loss=2.8838, lr=0.0100
[2025-05-05 12:09:10,450][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:09:16,775][train][INFO] - Epoch 2/100, Val Acc=0.4556, Val Loss=2.0225, lr=0.0100
[2025-05-05 12:09:18,396][train][INFO] - Epoch 1/100, Val Acc=0.1577, Val Loss=3.3296, lr=0.0100
[2025-05-05 12:09:19,501][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 5.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-05 12:09:19,558][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:09:19,558][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:09:19,558][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 12:09:25,023][train][INFO] - Epoch 3/100, Val Acc=0.5092, Val Loss=1.8887, lr=0.0100
[2025-05-05 12:09:27,005][train][INFO] - Epoch 2/100, Val Acc=0.3635, Val Loss=2.4141, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 12:09:33,584][train][INFO] - Epoch 4/100, Val Acc=0.5465, Val Loss=1.7416, lr=0.0100
[2025-05-05 12:09:34,256][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:09:35,552][train][INFO] - Epoch 3/100, Val Acc=0.4327, Val Loss=2.0928, lr=0.0100
[2025-05-05 12:09:41,926][train][INFO] - Epoch 5/100, Val Acc=0.5728, Val Loss=1.6605, lr=0.0100
[2025-05-05 12:09:41,952][train][INFO] - Epoch 1/100, Val Acc=0.1243, Val Loss=3.4677, lr=0.0100
[2025-05-05 12:09:44,021][train][INFO] - Epoch 4/100, Val Acc=0.4947, Val Loss=1.8791, lr=0.0100
[2025-05-05 12:09:49,654][train][INFO] - Epoch 2/100, Val Acc=0.2144, Val Loss=3.1136, lr=0.0100
[2025-05-05 12:09:49,988][train][INFO] - Epoch 6/100, Val Acc=0.5776, Val Loss=1.6386, lr=0.0100
[2025-05-05 12:09:51,803][train][INFO] - Epoch 5/100, Val Acc=0.5280, Val Loss=1.7670, lr=0.0100
[2025-05-05 12:09:57,423][train][INFO] - Epoch 3/100, Val Acc=0.2104, Val Loss=3.5578, lr=0.0100
[2025-05-05 12:09:58,006][train][INFO] - Epoch 7/100, Val Acc=0.6162, Val Loss=1.4876, lr=0.0100
[2025-05-05 12:10:00,079][train][INFO] - Epoch 6/100, Val Acc=0.5283, Val Loss=1.8656, lr=0.0100
[2025-05-05 12:10:05,340][train][INFO] - Epoch 4/100, Val Acc=0.3918, Val Loss=2.2622, lr=0.0100
[2025-05-05 12:10:05,586][train][INFO] - Epoch 8/100, Val Acc=0.5950, Val Loss=1.6438, lr=0.0100
[2025-05-05 12:10:08,855][train][INFO] - Epoch 7/100, Val Acc=0.5347, Val Loss=1.8302, lr=0.0100
[2025-05-05 12:10:13,117][train][INFO] - Epoch 5/100, Val Acc=0.3694, Val Loss=2.3837, lr=0.0100
[2025-05-05 12:10:13,538][train][INFO] - Epoch 9/100, Val Acc=0.6101, Val Loss=1.5373, lr=0.0100
[2025-05-05 12:10:16,755][train][INFO] - Epoch 8/100, Val Acc=0.5859, Val Loss=1.5801, lr=0.0100
[2025-05-05 12:10:21,106][train][INFO] - Epoch 10/100, Val Acc=0.6084, Val Loss=1.5730, lr=0.0100
[2025-05-05 12:10:21,183][train][INFO] - Epoch 6/100, Val Acc=0.4652, Val Loss=1.9748, lr=0.0100
[2025-05-05 12:10:24,359][train][INFO] - Epoch 9/100, Val Acc=0.5766, Val Loss=1.6506, lr=0.0100
[2025-05-05 12:10:28,519][train][INFO] - Epoch 11/100, Val Acc=0.6368, Val Loss=1.4474, lr=0.0100
[2025-05-05 12:10:29,168][train][INFO] - Epoch 7/100, Val Acc=0.4782, Val Loss=1.9643, lr=0.0100
[2025-05-05 12:10:32,329][train][INFO] - Epoch 10/100, Val Acc=0.6010, Val Loss=1.5615, lr=0.0100
[2025-05-05 12:10:35,821][train][INFO] - Epoch 12/100, Val Acc=0.6155, Val Loss=1.5780, lr=0.0100
[2025-05-05 12:10:37,450][train][INFO] - Epoch 8/100, Val Acc=0.5280, Val Loss=1.7707, lr=0.0100
[2025-05-05 12:10:39,763][train][INFO] - Epoch 11/100, Val Acc=0.6089, Val Loss=1.5011, lr=0.0100
[2025-05-05 12:10:43,346][train][INFO] - Epoch 13/100, Val Acc=0.6244, Val Loss=1.5574, lr=0.0100
[2025-05-05 12:10:44,808][train][INFO] - Epoch 9/100, Val Acc=0.5036, Val Loss=1.9350, lr=0.0100
[2025-05-05 12:10:46,719][train][INFO] - Epoch 12/100, Val Acc=0.5922, Val Loss=1.6466, lr=0.0100
[2025-05-05 12:10:50,968][train][INFO] - Epoch 14/100, Val Acc=0.6376, Val Loss=1.4839, lr=0.0100
[2025-05-05 12:10:52,109][train][INFO] - Epoch 10/100, Val Acc=0.5359, Val Loss=1.7538, lr=0.0100
[2025-05-05 12:10:54,476][train][INFO] - Epoch 13/100, Val Acc=0.6036, Val Loss=1.5865, lr=0.0100
[2025-05-05 12:10:58,235][train][INFO] - Epoch 15/100, Val Acc=0.6270, Val Loss=1.5513, lr=0.0100
[2025-05-05 12:10:59,635][train][INFO] - Epoch 11/100, Val Acc=0.5591, Val Loss=1.6914, lr=0.0100
[2025-05-05 12:11:02,376][train][INFO] - Epoch 14/100, Val Acc=0.6130, Val Loss=1.5642, lr=0.0100
[2025-05-05 12:11:05,819][train][INFO] - Epoch 16/100, Val Acc=0.6368, Val Loss=1.4887, lr=0.0100
[2025-05-05 12:11:07,365][train][INFO] - Epoch 12/100, Val Acc=0.5534, Val Loss=1.6936, lr=0.0100
[2025-05-05 12:11:09,622][train][INFO] - Epoch 15/100, Val Acc=0.6110, Val Loss=1.5924, lr=0.0100
[2025-05-05 12:11:12,886][train][INFO] - Epoch 17/100, Val Acc=0.6311, Val Loss=1.5867, lr=0.0100
[2025-05-05 12:11:14,867][train][INFO] - Epoch 13/100, Val Acc=0.5422, Val Loss=1.7611, lr=0.0100
[2025-05-05 12:11:17,532][train][INFO] - Epoch 16/100, Val Acc=0.5992, Val Loss=1.6565, lr=0.0100
[2025-05-05 12:11:20,358][train][INFO] - Epoch 18/100, Val Acc=0.6429, Val Loss=1.5122, lr=0.0100
[2025-05-05 12:11:22,306][train][INFO] - Epoch 14/100, Val Acc=0.5712, Val Loss=1.6550, lr=0.0100
[2025-05-05 12:11:25,106][train][INFO] - Epoch 17/100, Val Acc=0.6250, Val Loss=1.4985, lr=0.0100
[2025-05-05 12:11:28,015][train][INFO] - Epoch 19/100, Val Acc=0.6503, Val Loss=1.4388, lr=0.0100
[2025-05-05 12:11:29,884][train][INFO] - Epoch 15/100, Val Acc=0.5647, Val Loss=1.6498, lr=0.0100
[2025-05-05 12:11:32,865][train][INFO] - Epoch 18/100, Val Acc=0.6260, Val Loss=1.5538, lr=0.0100
[2025-05-05 12:11:35,854][train][INFO] - Epoch 20/100, Val Acc=0.6447, Val Loss=1.5121, lr=0.0100
[2025-05-05 12:11:37,288][train][INFO] - Epoch 16/100, Val Acc=0.5761, Val Loss=1.6378, lr=0.0100
[2025-05-05 12:11:40,571][train][INFO] - Epoch 19/100, Val Acc=0.6159, Val Loss=1.5863, lr=0.0100
[2025-05-05 12:11:43,465][train][INFO] - Epoch 21/100, Val Acc=0.6501, Val Loss=1.4567, lr=0.0100
[2025-05-05 12:11:45,001][train][INFO] - Epoch 17/100, Val Acc=0.5694, Val Loss=1.7246, lr=0.0100
[2025-05-05 12:11:48,248][train][INFO] - Epoch 20/100, Val Acc=0.6368, Val Loss=1.5093, lr=0.0100
[2025-05-05 12:11:50,558][train][INFO] - Epoch 22/100, Val Acc=0.6182, Val Loss=1.6556, lr=0.0100
[2025-05-05 12:11:53,043][train][INFO] - Epoch 18/100, Val Acc=0.5727, Val Loss=1.7548, lr=0.0100
[2025-05-05 12:11:55,771][train][INFO] - Epoch 21/100, Val Acc=0.6289, Val Loss=1.5634, lr=0.0100
[2025-05-05 12:11:58,284][train][INFO] - Epoch 23/100, Val Acc=0.6429, Val Loss=1.5438, lr=0.0100
[2025-05-05 12:12:01,134][train][INFO] - Epoch 19/100, Val Acc=0.5976, Val Loss=1.5499, lr=0.0100
[2025-05-05 12:12:03,171][train][INFO] - Epoch 22/100, Val Acc=0.6387, Val Loss=1.5073, lr=0.0100
[2025-05-05 12:12:06,182][train][INFO] - Epoch 24/100, Val Acc=0.6590, Val Loss=1.4446, lr=0.0100
[2025-05-05 12:12:08,693][train][INFO] - Epoch 20/100, Val Acc=0.5944, Val Loss=1.5749, lr=0.0100
[2025-05-05 12:12:10,765][train][INFO] - Epoch 23/100, Val Acc=0.6111, Val Loss=1.6496, lr=0.0100
[2025-05-05 12:12:13,544][train][INFO] - Epoch 25/100, Val Acc=0.6476, Val Loss=1.4919, lr=0.0100
[2025-05-05 12:12:16,252][train][INFO] - Epoch 21/100, Val Acc=0.6005, Val Loss=1.5581, lr=0.0100
[2025-05-05 12:12:18,642][train][INFO] - Epoch 24/100, Val Acc=0.6215, Val Loss=1.6173, lr=0.0100
[2025-05-05 12:12:21,299][train][INFO] - Epoch 26/100, Val Acc=0.6420, Val Loss=1.5597, lr=0.0100
[2025-05-05 12:12:23,678][train][INFO] - Epoch 22/100, Val Acc=0.5676, Val Loss=1.8065, lr=0.0100
[2025-05-05 12:12:26,523][train][INFO] - Epoch 25/100, Val Acc=0.6293, Val Loss=1.5588, lr=0.0100
[2025-05-05 12:12:28,555][train][INFO] - Epoch 27/100, Val Acc=0.6429, Val Loss=1.5432, lr=0.0100
[2025-05-05 12:12:31,213][train][INFO] - Epoch 23/100, Val Acc=0.6143, Val Loss=1.4916, lr=0.0100
[2025-05-05 12:12:33,748][train][INFO] - Epoch 26/100, Val Acc=0.6272, Val Loss=1.6077, lr=0.0100
[2025-05-05 12:12:35,938][train][INFO] - Epoch 28/100, Val Acc=0.6444, Val Loss=1.5682, lr=0.0100
[2025-05-05 12:12:39,040][train][INFO] - Epoch 24/100, Val Acc=0.6160, Val Loss=1.5620, lr=0.0100
[2025-05-05 12:12:41,482][train][INFO] - Epoch 27/100, Val Acc=0.6273, Val Loss=1.6279, lr=0.0100
[2025-05-05 12:12:43,294][train][INFO] - Epoch 29/100, Val Acc=0.6394, Val Loss=1.5485, lr=0.0100
[2025-05-05 12:12:46,300][train][INFO] - Epoch 25/100, Val Acc=0.6039, Val Loss=1.6388, lr=0.0100
[2025-05-05 12:12:49,147][train][INFO] - Epoch 28/100, Val Acc=0.6327, Val Loss=1.6055, lr=0.0100
[2025-05-05 12:12:50,999][train][INFO] - Epoch 30/100, Val Acc=0.6397, Val Loss=1.5599, lr=0.0100
[2025-05-05 12:12:53,596][train][INFO] - Epoch 26/100, Val Acc=0.6033, Val Loss=1.6363, lr=0.0100
[2025-05-05 12:12:56,732][train][INFO] - Epoch 29/100, Val Acc=0.6412, Val Loss=1.5198, lr=0.0100
[2025-05-05 12:12:58,718][train][INFO] - Epoch 31/100, Val Acc=0.6432, Val Loss=1.5711, lr=0.0100
[2025-05-05 12:13:00,936][train][INFO] - Epoch 27/100, Val Acc=0.5934, Val Loss=1.7445, lr=0.0100
[2025-05-05 12:13:04,413][train][INFO] - Epoch 30/100, Val Acc=0.6466, Val Loss=1.5375, lr=0.0100
[2025-05-05 12:13:05,580][train][INFO] - Epoch 32/100, Val Acc=0.6553, Val Loss=1.5149, lr=0.0100
[2025-05-05 12:13:08,323][train][INFO] - Epoch 28/100, Val Acc=0.6271, Val Loss=1.5145, lr=0.0100
[2025-05-05 12:13:12,120][train][INFO] - Epoch 31/100, Val Acc=0.6327, Val Loss=1.6095, lr=0.0100
[2025-05-05 12:13:13,283][train][INFO] - Epoch 33/100, Val Acc=0.6464, Val Loss=1.5382, lr=0.0100
[2025-05-05 12:13:15,811][train][INFO] - Epoch 29/100, Val Acc=0.5993, Val Loss=1.7208, lr=0.0100
[2025-05-05 12:13:19,827][train][INFO] - Epoch 32/100, Val Acc=0.6433, Val Loss=1.5484, lr=0.0100
[2025-05-05 12:13:21,015][train][INFO] - Epoch 34/100, Val Acc=0.6416, Val Loss=1.5724, lr=0.0100
[2025-05-05 12:13:23,600][train][INFO] - Epoch 30/100, Val Acc=0.6072, Val Loss=1.6033, lr=0.0100
[2025-05-05 12:13:27,104][train][INFO] - Epoch 33/100, Val Acc=0.6306, Val Loss=1.6068, lr=0.0100
[2025-05-05 12:13:28,407][train][INFO] - Epoch 35/100, Val Acc=0.6436, Val Loss=1.5976, lr=0.0100
[2025-05-05 12:13:31,253][train][INFO] - Epoch 31/100, Val Acc=0.6156, Val Loss=1.5919, lr=0.0100
[2025-05-05 12:13:34,551][train][INFO] - Epoch 34/100, Val Acc=0.6425, Val Loss=1.5678, lr=0.0100
[2025-05-05 12:13:35,760][train][INFO] - Epoch 36/100, Val Acc=0.6483, Val Loss=1.5729, lr=0.0100
[2025-05-05 12:13:39,132][train][INFO] - Epoch 32/100, Val Acc=0.6165, Val Loss=1.5961, lr=0.0100
[2025-05-05 12:13:42,530][train][INFO] - Epoch 35/100, Val Acc=0.6394, Val Loss=1.5941, lr=0.0100
[2025-05-05 12:13:43,290][train][INFO] - Epoch 37/100, Val Acc=0.6545, Val Loss=1.5314, lr=0.0100
[2025-05-05 12:13:46,585][train][INFO] - Epoch 33/100, Val Acc=0.6277, Val Loss=1.5790, lr=0.0100
[2025-05-05 12:13:50,254][train][INFO] - Epoch 36/100, Val Acc=0.6303, Val Loss=1.6240, lr=0.0100
[2025-05-05 12:13:51,086][train][INFO] - Epoch 38/100, Val Acc=0.6297, Val Loss=1.7314, lr=0.0100
[2025-05-05 12:13:53,750][train][INFO] - Epoch 34/100, Val Acc=0.6255, Val Loss=1.5593, lr=0.0100
[2025-05-05 12:13:57,862][train][INFO] - Epoch 37/100, Val Acc=0.6348, Val Loss=1.6449, lr=0.0100
[2025-05-05 12:13:58,592][train][INFO] - Epoch 39/100, Val Acc=0.6464, Val Loss=1.6116, lr=0.0100
[2025-05-05 12:14:01,448][train][INFO] - Epoch 35/100, Val Acc=0.6246, Val Loss=1.6329, lr=0.0100
[2025-05-05 12:14:04,976][train][INFO] - Epoch 38/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-05 12:14:05,876][train][INFO] - Epoch 40/100, Val Acc=0.6559, Val Loss=1.5331, lr=0.0100
[2025-05-05 12:14:09,140][train][INFO] - Epoch 36/100, Val Acc=0.6115, Val Loss=1.6608, lr=0.0100
[2025-05-05 12:14:12,621][train][INFO] - Epoch 39/100, Val Acc=0.6420, Val Loss=1.6029, lr=0.0100
[2025-05-05 12:14:13,455][train][INFO] - Epoch 41/100, Val Acc=0.6492, Val Loss=1.5879, lr=0.0100
[2025-05-05 12:14:17,123][train][INFO] - Epoch 37/100, Val Acc=0.6124, Val Loss=1.6762, lr=0.0100
[2025-05-05 12:14:20,157][train][INFO] - Epoch 40/100, Val Acc=0.6386, Val Loss=1.6069, lr=0.0100
[2025-05-05 12:14:21,303][train][INFO] - Epoch 42/100, Val Acc=0.6482, Val Loss=1.6061, lr=0.0100
[2025-05-05 12:14:24,685][train][INFO] - Epoch 38/100, Val Acc=0.6327, Val Loss=1.5198, lr=0.0100
[2025-05-05 12:14:27,946][train][INFO] - Epoch 41/100, Val Acc=0.6439, Val Loss=1.6088, lr=0.0100
[2025-05-05 12:14:29,052][train][INFO] - Epoch 43/100, Val Acc=0.6402, Val Loss=1.6533, lr=0.0100
[2025-05-05 12:14:31,947][train][INFO] - Epoch 39/100, Val Acc=0.6176, Val Loss=1.6937, lr=0.0100
[2025-05-05 12:14:35,288][train][INFO] - Epoch 42/100, Val Acc=0.6219, Val Loss=1.6998, lr=0.0100
[2025-05-05 12:14:36,316][train][INFO] - Epoch 44/100, Val Acc=0.6341, Val Loss=1.7037, lr=0.0100
[2025-05-05 12:14:39,495][train][INFO] - Epoch 40/100, Val Acc=0.6135, Val Loss=1.6814, lr=0.0100
[2025-05-05 12:14:42,927][train][INFO] - Epoch 43/100, Val Acc=0.6423, Val Loss=1.6399, lr=0.0100
[2025-05-05 12:14:44,024][train][INFO] - Epoch 45/100, Val Acc=0.6469, Val Loss=1.5789, lr=0.0100
[2025-05-05 12:14:46,896][train][INFO] - Epoch 41/100, Val Acc=0.6220, Val Loss=1.6187, lr=0.0100
[2025-05-05 12:14:50,501][train][INFO] - Epoch 44/100, Val Acc=0.6280, Val Loss=1.6860, lr=0.0100
[2025-05-05 12:14:51,747][train][INFO] - Epoch 46/100, Val Acc=0.6390, Val Loss=1.7001, lr=0.0100
[2025-05-05 12:14:54,069][train][INFO] - Epoch 42/100, Val Acc=0.6233, Val Loss=1.6436, lr=0.0100
[2025-05-05 12:14:57,712][train][INFO] - Epoch 45/100, Val Acc=0.6340, Val Loss=1.6459, lr=0.0100
[2025-05-05 12:14:59,143][train][INFO] - Epoch 47/100, Val Acc=0.6412, Val Loss=1.6508, lr=0.0100
[2025-05-05 12:15:01,557][train][INFO] - Epoch 43/100, Val Acc=0.6127, Val Loss=1.6797, lr=0.0100
[2025-05-05 12:15:05,894][train][INFO] - Epoch 46/100, Val Acc=0.6413, Val Loss=1.6074, lr=0.0100
[2025-05-05 12:15:06,704][train][INFO] - Epoch 48/100, Val Acc=0.6526, Val Loss=1.5607, lr=0.0100
[2025-05-05 12:15:09,340][train][INFO] - Epoch 44/100, Val Acc=0.6217, Val Loss=1.6428, lr=0.0100
[2025-05-05 12:15:13,318][train][INFO] - Epoch 47/100, Val Acc=0.6336, Val Loss=1.6733, lr=0.0100
[2025-05-05 12:15:14,343][train][INFO] - Epoch 49/100, Val Acc=0.6560, Val Loss=1.5794, lr=0.0100
[2025-05-05 12:15:16,710][train][INFO] - Epoch 45/100, Val Acc=0.6198, Val Loss=1.6318, lr=0.0100
[2025-05-05 12:15:20,415][train][INFO] - Epoch 48/100, Val Acc=0.6446, Val Loss=1.5907, lr=0.0100
[2025-05-05 12:15:21,915][train][INFO] - Epoch 50/100, Val Acc=0.6469, Val Loss=1.6455, lr=0.0100
[2025-05-05 12:15:24,483][train][INFO] - Epoch 46/100, Val Acc=0.6274, Val Loss=1.6337, lr=0.0100
[2025-05-05 12:15:28,252][train][INFO] - Epoch 49/100, Val Acc=0.6470, Val Loss=1.5903, lr=0.0100
[2025-05-05 12:15:29,573][train][INFO] - Epoch 51/100, Val Acc=0.6387, Val Loss=1.6781, lr=0.0100
[2025-05-05 12:15:32,021][train][INFO] - Epoch 47/100, Val Acc=0.6168, Val Loss=1.6955, lr=0.0100
[2025-05-05 12:15:35,668][train][INFO] - Epoch 50/100, Val Acc=0.6465, Val Loss=1.5903, lr=0.0100
[2025-05-05 12:15:36,999][train][INFO] - Epoch 52/100, Val Acc=0.6422, Val Loss=1.6613, lr=0.0100
[2025-05-05 12:15:39,589][train][INFO] - Epoch 48/100, Val Acc=0.6334, Val Loss=1.5860, lr=0.0100
[2025-05-05 12:15:43,678][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6533, lr=0.0100
[2025-05-05 12:15:44,278][train][INFO] - Epoch 53/100, Val Acc=0.6386, Val Loss=1.6429, lr=0.0100
[2025-05-05 12:15:46,691][train][INFO] - Epoch 49/100, Val Acc=0.6294, Val Loss=1.6062, lr=0.0100
[2025-05-05 12:15:51,682][train][INFO] - Epoch 52/100, Val Acc=0.6307, Val Loss=1.6962, lr=0.0100
[2025-05-05 12:15:51,804][train][INFO] - Epoch 54/100, Val Acc=0.6437, Val Loss=1.6218, lr=0.0100
[2025-05-05 12:15:54,030][train][INFO] - Epoch 50/100, Val Acc=0.6342, Val Loss=1.5930, lr=0.0100
[2025-05-05 12:15:58,766][train][INFO] - Epoch 53/100, Val Acc=0.6374, Val Loss=1.6606, lr=0.0100
[2025-05-05 12:15:59,573][train][INFO] - Epoch 55/100, Val Acc=0.6420, Val Loss=1.6428, lr=0.0100
[2025-05-05 12:16:01,505][train][INFO] - Epoch 51/100, Val Acc=0.6248, Val Loss=1.6625, lr=0.0100
[2025-05-05 12:16:06,528][train][INFO] - Epoch 54/100, Val Acc=0.6352, Val Loss=1.6768, lr=0.0100
[2025-05-05 12:16:07,360][train][INFO] - Epoch 56/100, Val Acc=0.6469, Val Loss=1.6637, lr=0.0100
[2025-05-05 12:16:09,331][train][INFO] - Epoch 52/100, Val Acc=0.6223, Val Loss=1.6883, lr=0.0100
[2025-05-05 12:16:14,294][train][INFO] - Epoch 55/100, Val Acc=0.6336, Val Loss=1.7275, lr=0.0100
[2025-05-05 12:16:15,094][train][INFO] - Epoch 57/100, Val Acc=0.6391, Val Loss=1.6646, lr=0.0100
[2025-05-05 12:16:16,983][train][INFO] - Epoch 53/100, Val Acc=0.6350, Val Loss=1.6011, lr=0.0100
[2025-05-05 12:16:22,025][train][INFO] - Epoch 56/100, Val Acc=0.6301, Val Loss=1.6911, lr=0.0100
[2025-05-05 12:16:22,721][train][INFO] - Epoch 58/100, Val Acc=0.6600, Val Loss=1.6111, lr=0.0100
[2025-05-05 12:16:24,351][train][INFO] - Epoch 54/100, Val Acc=0.6203, Val Loss=1.7305, lr=0.0100
[2025-05-05 12:16:29,637][train][INFO] - Epoch 57/100, Val Acc=0.6364, Val Loss=1.7036, lr=0.0100
[2025-05-05 12:16:30,527][train][INFO] - Epoch 59/100, Val Acc=0.6454, Val Loss=1.6256, lr=0.0100
[2025-05-05 12:16:32,046][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6972, lr=0.0100
[2025-05-05 12:16:36,882][train][INFO] - Epoch 58/100, Val Acc=0.6195, Val Loss=1.7899, lr=0.0100
[2025-05-05 12:16:38,191][train][INFO] - Epoch 60/100, Val Acc=0.6594, Val Loss=1.5858, lr=0.0100
[2025-05-05 12:16:39,426][train][INFO] - Epoch 56/100, Val Acc=0.6283, Val Loss=1.6679, lr=0.0100
[2025-05-05 12:16:44,392][train][INFO] - Epoch 59/100, Val Acc=0.6369, Val Loss=1.6542, lr=0.0100
[2025-05-05 12:16:45,885][train][INFO] - Epoch 61/100, Val Acc=0.7068, Val Loss=1.3268, lr=0.0010
[2025-05-05 12:16:47,129][train][INFO] - Epoch 57/100, Val Acc=0.6189, Val Loss=1.7435, lr=0.0100
[2025-05-05 12:16:52,322][train][INFO] - Epoch 60/100, Val Acc=0.6361, Val Loss=1.7176, lr=0.0100
[2025-05-05 12:16:53,287][train][INFO] - Epoch 62/100, Val Acc=0.7087, Val Loss=1.3174, lr=0.0010
[2025-05-05 12:16:54,847][train][INFO] - Epoch 58/100, Val Acc=0.6154, Val Loss=1.7788, lr=0.0100
[2025-05-05 12:16:59,782][train][INFO] - Epoch 61/100, Val Acc=0.7002, Val Loss=1.3470, lr=0.0010
[2025-05-05 12:17:00,846][train][INFO] - Epoch 63/100, Val Acc=0.7128, Val Loss=1.3294, lr=0.0010
[2025-05-05 12:17:02,485][train][INFO] - Epoch 59/100, Val Acc=0.6274, Val Loss=1.6840, lr=0.0100
[2025-05-05 12:17:06,999][train][INFO] - Epoch 62/100, Val Acc=0.7021, Val Loss=1.3435, lr=0.0010
[2025-05-05 12:17:08,311][train][INFO] - Epoch 64/100, Val Acc=0.7140, Val Loss=1.3416, lr=0.0010
[2025-05-05 12:17:10,407][train][INFO] - Epoch 60/100, Val Acc=0.6355, Val Loss=1.6562, lr=0.0100
[2025-05-05 12:17:14,827][train][INFO] - Epoch 63/100, Val Acc=0.7037, Val Loss=1.3430, lr=0.0010
[2025-05-05 12:17:15,535][train][INFO] - Epoch 65/100, Val Acc=0.7142, Val Loss=1.3431, lr=0.0010
[2025-05-05 12:17:18,033][train][INFO] - Epoch 61/100, Val Acc=0.6910, Val Loss=1.3330, lr=0.0010
[2025-05-05 12:17:23,015][train][INFO] - Epoch 64/100, Val Acc=0.7071, Val Loss=1.3501, lr=0.0010
[2025-05-05 12:17:23,026][train][INFO] - Epoch 66/100, Val Acc=0.7149, Val Loss=1.3516, lr=0.0010
[2025-05-05 12:17:25,872][train][INFO] - Epoch 62/100, Val Acc=0.6990, Val Loss=1.3231, lr=0.0010
[2025-05-05 12:17:30,754][train][INFO] - Epoch 65/100, Val Acc=0.7069, Val Loss=1.3532, lr=0.0010
[2025-05-05 12:17:30,754][train][INFO] - Epoch 67/100, Val Acc=0.7155, Val Loss=1.3565, lr=0.0010
[2025-05-05 12:17:33,674][train][INFO] - Epoch 63/100, Val Acc=0.6973, Val Loss=1.3335, lr=0.0010
[2025-05-05 12:17:38,065][train][INFO] - Epoch 68/100, Val Acc=0.7154, Val Loss=1.3594, lr=0.0010
[2025-05-05 12:17:38,455][train][INFO] - Epoch 66/100, Val Acc=0.7082, Val Loss=1.3601, lr=0.0010
[2025-05-05 12:17:41,015][train][INFO] - Epoch 64/100, Val Acc=0.6975, Val Loss=1.3458, lr=0.0010
[2025-05-05 12:17:45,750][train][INFO] - Epoch 69/100, Val Acc=0.7164, Val Loss=1.3684, lr=0.0010
[2025-05-05 12:17:46,550][train][INFO] - Epoch 67/100, Val Acc=0.7085, Val Loss=1.3621, lr=0.0010
[2025-05-05 12:17:48,215][train][INFO] - Epoch 65/100, Val Acc=0.6985, Val Loss=1.3463, lr=0.0010
[2025-05-05 12:17:53,480][train][INFO] - Epoch 70/100, Val Acc=0.7155, Val Loss=1.3682, lr=0.0010
[2025-05-05 12:17:54,390][train][INFO] - Epoch 68/100, Val Acc=0.7095, Val Loss=1.3662, lr=0.0010
[2025-05-05 12:17:55,998][train][INFO] - Epoch 66/100, Val Acc=0.6999, Val Loss=1.3541, lr=0.0010
[2025-05-05 12:18:01,331][train][INFO] - Epoch 71/100, Val Acc=0.7160, Val Loss=1.3635, lr=0.0010
[2025-05-05 12:18:02,111][train][INFO] - Epoch 69/100, Val Acc=0.7081, Val Loss=1.3731, lr=0.0010
[2025-05-05 12:18:03,375][train][INFO] - Epoch 67/100, Val Acc=0.6979, Val Loss=1.3657, lr=0.0010
[2025-05-05 12:18:08,882][train][INFO] - Epoch 72/100, Val Acc=0.7162, Val Loss=1.3717, lr=0.0010
[2025-05-05 12:18:09,935][train][INFO] - Epoch 70/100, Val Acc=0.7091, Val Loss=1.3775, lr=0.0010
[2025-05-05 12:18:11,196][train][INFO] - Epoch 68/100, Val Acc=0.7009, Val Loss=1.3705, lr=0.0010
[2025-05-05 12:18:16,714][train][INFO] - Epoch 73/100, Val Acc=0.7153, Val Loss=1.3632, lr=0.0010
[2025-05-05 12:18:17,541][train][INFO] - Epoch 71/100, Val Acc=0.7114, Val Loss=1.3812, lr=0.0010
[2025-05-05 12:18:18,831][train][INFO] - Epoch 69/100, Val Acc=0.7004, Val Loss=1.3642, lr=0.0010
[2025-05-05 12:18:24,565][train][INFO] - Epoch 74/100, Val Acc=0.7159, Val Loss=1.3698, lr=0.0010
[2025-05-05 12:18:24,838][train][INFO] - Epoch 72/100, Val Acc=0.7103, Val Loss=1.3815, lr=0.0010
[2025-05-05 12:18:26,763][train][INFO] - Epoch 70/100, Val Acc=0.7035, Val Loss=1.3745, lr=0.0010
[2025-05-05 12:18:32,565][train][INFO] - Epoch 75/100, Val Acc=0.7170, Val Loss=1.3705, lr=0.0010
[2025-05-05 12:18:32,581][train][INFO] - Epoch 73/100, Val Acc=0.7094, Val Loss=1.3795, lr=0.0010
[2025-05-05 12:18:34,597][train][INFO] - Epoch 71/100, Val Acc=0.7007, Val Loss=1.3815, lr=0.0010
[2025-05-05 12:18:40,237][train][INFO] - Epoch 74/100, Val Acc=0.7107, Val Loss=1.3922, lr=0.0010
[2025-05-05 12:18:40,346][train][INFO] - Epoch 76/100, Val Acc=0.7181, Val Loss=1.3755, lr=0.0010
[2025-05-05 12:18:42,665][train][INFO] - Epoch 72/100, Val Acc=0.7001, Val Loss=1.3885, lr=0.0010
[2025-05-05 12:18:47,663][train][INFO] - Epoch 75/100, Val Acc=0.7100, Val Loss=1.3973, lr=0.0010
[2025-05-05 12:18:47,841][train][INFO] - Epoch 77/100, Val Acc=0.7160, Val Loss=1.3734, lr=0.0010
[2025-05-05 12:18:49,761][train][INFO] - Epoch 73/100, Val Acc=0.7047, Val Loss=1.3850, lr=0.0010
[2025-05-05 12:18:55,093][train][INFO] - Epoch 76/100, Val Acc=0.7114, Val Loss=1.3910, lr=0.0010
[2025-05-05 12:18:55,301][train][INFO] - Epoch 78/100, Val Acc=0.7201, Val Loss=1.3776, lr=0.0010
[2025-05-05 12:18:57,108][train][INFO] - Epoch 74/100, Val Acc=0.7036, Val Loss=1.3889, lr=0.0010
[2025-05-05 12:19:02,946][train][INFO] - Epoch 77/100, Val Acc=0.7121, Val Loss=1.3958, lr=0.0010
[2025-05-05 12:19:03,238][train][INFO] - Epoch 79/100, Val Acc=0.7193, Val Loss=1.3850, lr=0.0010
[2025-05-05 12:19:04,517][train][INFO] - Epoch 75/100, Val Acc=0.7062, Val Loss=1.3951, lr=0.0010
[2025-05-05 12:19:10,104][train][INFO] - Epoch 80/100, Val Acc=0.7176, Val Loss=1.3808, lr=0.0010
[2025-05-05 12:19:10,743][train][INFO] - Epoch 78/100, Val Acc=0.7125, Val Loss=1.3950, lr=0.0010
[2025-05-05 12:19:12,179][train][INFO] - Epoch 76/100, Val Acc=0.7040, Val Loss=1.4001, lr=0.0010
[2025-05-05 12:19:17,568][train][INFO] - Epoch 81/100, Val Acc=0.7184, Val Loss=1.3891, lr=0.0010
[2025-05-05 12:19:18,343][train][INFO] - Epoch 79/100, Val Acc=0.7122, Val Loss=1.3974, lr=0.0010
[2025-05-05 12:19:19,922][train][INFO] - Epoch 77/100, Val Acc=0.7059, Val Loss=1.4042, lr=0.0010
[2025-05-05 12:19:25,364][train][INFO] - Epoch 82/100, Val Acc=0.7183, Val Loss=1.3941, lr=0.0010
[2025-05-05 12:19:26,193][train][INFO] - Epoch 80/100, Val Acc=0.7105, Val Loss=1.4005, lr=0.0010
[2025-05-05 12:19:27,413][train][INFO] - Epoch 78/100, Val Acc=0.6997, Val Loss=1.4160, lr=0.0010
[2025-05-05 12:19:33,234][train][INFO] - Epoch 83/100, Val Acc=0.7191, Val Loss=1.3921, lr=0.0010
[2025-05-05 12:19:33,633][train][INFO] - Epoch 81/100, Val Acc=0.7136, Val Loss=1.4006, lr=0.0010
[2025-05-05 12:19:34,653][train][INFO] - Epoch 79/100, Val Acc=0.7011, Val Loss=1.4245, lr=0.0010
[2025-05-05 12:19:40,969][train][INFO] - Epoch 84/100, Val Acc=0.7195, Val Loss=1.3931, lr=0.0010
[2025-05-05 12:19:41,409][train][INFO] - Epoch 82/100, Val Acc=0.7123, Val Loss=1.4073, lr=0.0010
[2025-05-05 12:19:42,171][train][INFO] - Epoch 80/100, Val Acc=0.7013, Val Loss=1.4228, lr=0.0010
[2025-05-05 12:19:48,288][train][INFO] - Epoch 85/100, Val Acc=0.7186, Val Loss=1.3925, lr=0.0010
[2025-05-05 12:19:49,094][train][INFO] - Epoch 83/100, Val Acc=0.7109, Val Loss=1.4145, lr=0.0010
[2025-05-05 12:19:50,252][train][INFO] - Epoch 81/100, Val Acc=0.7028, Val Loss=1.4262, lr=0.0010
[2025-05-05 12:19:55,759][train][INFO] - Epoch 86/100, Val Acc=0.7162, Val Loss=1.3899, lr=0.0010
[2025-05-05 12:19:56,703][train][INFO] - Epoch 84/100, Val Acc=0.7107, Val Loss=1.4185, lr=0.0010
[2025-05-05 12:19:57,885][train][INFO] - Epoch 82/100, Val Acc=0.7023, Val Loss=1.4333, lr=0.0010
[2025-05-05 12:20:03,207][train][INFO] - Epoch 87/100, Val Acc=0.7218, Val Loss=1.3910, lr=0.0010
[2025-05-05 12:20:04,711][train][INFO] - Epoch 85/100, Val Acc=0.7107, Val Loss=1.4082, lr=0.0010
[2025-05-05 12:20:05,044][train][INFO] - Epoch 83/100, Val Acc=0.7021, Val Loss=1.4370, lr=0.0010
[2025-05-05 12:20:10,298][train][INFO] - Epoch 88/100, Val Acc=0.7193, Val Loss=1.3921, lr=0.0010
[2025-05-05 12:20:12,230][train][INFO] - Epoch 86/100, Val Acc=0.7129, Val Loss=1.4149, lr=0.0010
[2025-05-05 12:20:12,531][train][INFO] - Epoch 84/100, Val Acc=0.7019, Val Loss=1.4373, lr=0.0010
[2025-05-05 12:20:17,925][train][INFO] - Epoch 89/100, Val Acc=0.7191, Val Loss=1.3985, lr=0.0010
[2025-05-05 12:20:19,820][train][INFO] - Epoch 85/100, Val Acc=0.7025, Val Loss=1.4495, lr=0.0010
[2025-05-05 12:20:19,907][train][INFO] - Epoch 87/100, Val Acc=0.7138, Val Loss=1.4129, lr=0.0010
[2025-05-05 12:20:25,542][train][INFO] - Epoch 90/100, Val Acc=0.7197, Val Loss=1.3965, lr=0.0010
[2025-05-05 12:20:27,006][train][INFO] - Epoch 86/100, Val Acc=0.7018, Val Loss=1.4454, lr=0.0010
[2025-05-05 12:20:27,785][train][INFO] - Epoch 88/100, Val Acc=0.7119, Val Loss=1.4126, lr=0.0010
[2025-05-05 12:20:32,994][train][INFO] - Epoch 91/100, Val Acc=0.7194, Val Loss=1.3901, lr=0.0001
[2025-05-05 12:20:34,596][train][INFO] - Epoch 87/100, Val Acc=0.7030, Val Loss=1.4425, lr=0.0010
[2025-05-05 12:20:35,180][train][INFO] - Epoch 89/100, Val Acc=0.7099, Val Loss=1.4180, lr=0.0010
[2025-05-05 12:20:40,583][train][INFO] - Epoch 92/100, Val Acc=0.7182, Val Loss=1.3956, lr=0.0001
[2025-05-05 12:20:42,170][train][INFO] - Epoch 88/100, Val Acc=0.7014, Val Loss=1.4433, lr=0.0010
[2025-05-05 12:20:42,927][train][INFO] - Epoch 90/100, Val Acc=0.7139, Val Loss=1.4194, lr=0.0010
[2025-05-05 12:20:48,351][train][INFO] - Epoch 93/100, Val Acc=0.7192, Val Loss=1.3929, lr=0.0001
[2025-05-05 12:20:49,672][train][INFO] - Epoch 89/100, Val Acc=0.7008, Val Loss=1.4569, lr=0.0010
[2025-05-05 12:20:50,301][train][INFO] - Epoch 91/100, Val Acc=0.7134, Val Loss=1.4145, lr=0.0001
[2025-05-05 12:20:55,491][train][INFO] - Epoch 94/100, Val Acc=0.7210, Val Loss=1.3907, lr=0.0001
[2025-05-05 12:20:57,528][train][INFO] - Epoch 90/100, Val Acc=0.7024, Val Loss=1.4636, lr=0.0010
[2025-05-05 12:20:57,746][train][INFO] - Epoch 92/100, Val Acc=0.7120, Val Loss=1.4193, lr=0.0001
[2025-05-05 12:21:03,178][train][INFO] - Epoch 95/100, Val Acc=0.7213, Val Loss=1.3924, lr=0.0001
[2025-05-05 12:21:04,683][train][INFO] - Epoch 91/100, Val Acc=0.7022, Val Loss=1.4532, lr=0.0001
[2025-05-05 12:21:05,450][train][INFO] - Epoch 93/100, Val Acc=0.7129, Val Loss=1.4172, lr=0.0001
[2025-05-05 12:21:10,703][train][INFO] - Epoch 96/100, Val Acc=0.7208, Val Loss=1.3905, lr=0.0001
[2025-05-05 12:21:11,973][train][INFO] - Epoch 92/100, Val Acc=0.7027, Val Loss=1.4558, lr=0.0001
[2025-05-05 12:21:12,879][train][INFO] - Epoch 94/100, Val Acc=0.7127, Val Loss=1.4138, lr=0.0001
[2025-05-05 12:21:18,199][train][INFO] - Epoch 97/100, Val Acc=0.7216, Val Loss=1.3928, lr=0.0001
[2025-05-05 12:21:19,478][train][INFO] - Epoch 93/100, Val Acc=0.7037, Val Loss=1.4555, lr=0.0001
[2025-05-05 12:21:20,430][train][INFO] - Epoch 95/100, Val Acc=0.7138, Val Loss=1.4145, lr=0.0001
[2025-05-05 12:21:25,808][train][INFO] - Epoch 98/100, Val Acc=0.7223, Val Loss=1.3880, lr=0.0001
[2025-05-05 12:21:27,144][train][INFO] - Epoch 94/100, Val Acc=0.7021, Val Loss=1.4520, lr=0.0001
[2025-05-05 12:21:28,189][train][INFO] - Epoch 96/100, Val Acc=0.7140, Val Loss=1.4123, lr=0.0001
[2025-05-05 12:21:33,130][train][INFO] - Epoch 99/100, Val Acc=0.7203, Val Loss=1.3955, lr=0.0001
[2025-05-05 12:21:35,012][train][INFO] - Epoch 95/100, Val Acc=0.7025, Val Loss=1.4524, lr=0.0001
[2025-05-05 12:21:35,913][train][INFO] - Epoch 97/100, Val Acc=0.7119, Val Loss=1.4211, lr=0.0001
[2025-05-05 12:21:40,906][train][INFO] - Epoch 100/100, Val Acc=0.7207, Val Loss=1.3929, lr=0.0001
[2025-05-05 12:21:42,107][train][INFO] - Epoch 96/100, Val Acc=0.7033, Val Loss=1.4493, lr=0.0001
[2025-05-05 12:21:43,291][train][INFO] - Epoch 98/100, Val Acc=0.7124, Val Loss=1.4139, lr=0.0001
[2025-05-05 12:21:46,284][train][INFO] - After training : Train Acc=0.9981  Val Acc=0.7223
[2025-05-05 12:21:50,038][train][INFO] - Epoch 97/100, Val Acc=0.7040, Val Loss=1.4533, lr=0.0001
[2025-05-05 12:21:51,540][train][INFO] - Epoch 99/100, Val Acc=0.7122, Val Loss=1.4213, lr=0.0001
[2025-05-05 12:21:54,547][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-05 12:21:54,547][Progressive pruning][INFO] - Current speed up: 1.67
[2025-05-05 12:21:57,740][train][INFO] - Epoch 98/100, Val Acc=0.7036, Val Loss=1.4457, lr=0.0001
[2025-05-05 12:21:59,546][train][INFO] - Epoch 100/100, Val Acc=0.7130, Val Loss=1.4135, lr=0.0001
[2025-05-05 12:21:59,784][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:22:04,844][train][INFO] - After training : Train Acc=0.9972  Val Acc=0.7140
[2025-05-05 12:22:05,384][train][INFO] - Epoch 99/100, Val Acc=0.7048, Val Loss=1.4540, lr=0.0001
[2025-05-05 12:22:07,481][train][INFO] - Epoch 1/140, Val Acc=0.1887, Val Loss=3.0552, lr=0.0100
[2025-05-05 12:22:13,192][Progressive pruning][INFO] - Train acc : 0.006339999847114086   Val acc : 0.007599999662488699
[2025-05-05 12:22:13,192][Progressive pruning][INFO] - Current speed up: 1.67
[2025-05-05 12:22:13,591][train][INFO] - Epoch 100/100, Val Acc=0.7033, Val Loss=1.4512, lr=0.0001
[2025-05-05 12:22:14,766][train][INFO] - Epoch 2/140, Val Acc=0.2742, Val Loss=2.6870, lr=0.0100
[2025-05-05 12:22:18,502][train][INFO] - Before training : Train Acc=0.0063  Val Acc=0.0076
[2025-05-05 12:22:18,766][train][INFO] - After training : Train Acc=0.9880  Val Acc=0.7062
[2025-05-05 12:22:22,313][train][INFO] - Epoch 3/140, Val Acc=0.2901, Val Loss=2.7227, lr=0.0100
[2025-05-05 12:22:26,407][train][INFO] - Epoch 1/140, Val Acc=0.3041, Val Loss=2.6752, lr=0.0100
[2025-05-05 12:22:27,405][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-05 12:22:27,406][Progressive pruning][INFO] - Current speed up: 1.66
[2025-05-05 12:22:29,863][train][INFO] - Epoch 4/140, Val Acc=0.3636, Val Loss=2.3698, lr=0.0100
[2025-05-05 12:22:32,723][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:22:33,981][train][INFO] - Epoch 2/140, Val Acc=0.3310, Val Loss=2.6915, lr=0.0100
[2025-05-05 12:22:37,594][train][INFO] - Epoch 5/140, Val Acc=0.3480, Val Loss=2.4948, lr=0.0100
[2025-05-05 12:22:39,769][train][INFO] - Epoch 1/140, Val Acc=0.5616, Val Loss=1.8397, lr=0.0100
[2025-05-05 12:22:41,744][train][INFO] - Epoch 3/140, Val Acc=0.4440, Val Loss=2.1118, lr=0.0100
[2025-05-05 12:22:45,506][train][INFO] - Epoch 6/140, Val Acc=0.4191, Val Loss=2.1386, lr=0.0100
[2025-05-05 12:22:47,149][train][INFO] - Epoch 2/140, Val Acc=0.5291, Val Loss=2.1399, lr=0.0100
[2025-05-05 12:22:49,350][train][INFO] - Epoch 4/140, Val Acc=0.4493, Val Loss=2.2554, lr=0.0100
[2025-05-05 12:22:52,905][train][INFO] - Epoch 7/140, Val Acc=0.4417, Val Loss=2.1345, lr=0.0100
[2025-05-05 12:22:54,964][train][INFO] - Epoch 3/140, Val Acc=0.5470, Val Loss=1.9985, lr=0.0100
[2025-05-05 12:22:57,000][train][INFO] - Epoch 5/140, Val Acc=0.4411, Val Loss=2.3071, lr=0.0100
[2025-05-05 12:23:00,377][train][INFO] - Epoch 8/140, Val Acc=0.4458, Val Loss=2.1238, lr=0.0100
[2025-05-05 12:23:02,254][train][INFO] - Epoch 4/140, Val Acc=0.5506, Val Loss=1.9672, lr=0.0100
[2025-05-05 12:23:04,340][train][INFO] - Epoch 6/140, Val Acc=0.4865, Val Loss=2.0331, lr=0.0100
[2025-05-05 12:23:07,931][train][INFO] - Epoch 9/140, Val Acc=0.4507, Val Loss=2.1199, lr=0.0100
[2025-05-05 12:23:09,590][train][INFO] - Epoch 5/140, Val Acc=0.5618, Val Loss=1.9417, lr=0.0100
[2025-05-05 12:23:11,549][train][INFO] - Epoch 7/140, Val Acc=0.4932, Val Loss=2.0402, lr=0.0100
[2025-05-05 12:23:15,257][train][INFO] - Epoch 10/140, Val Acc=0.4350, Val Loss=2.2067, lr=0.0100
[2025-05-05 12:23:17,006][train][INFO] - Epoch 6/140, Val Acc=0.5946, Val Loss=1.7631, lr=0.0100
[2025-05-05 12:23:19,222][train][INFO] - Epoch 8/140, Val Acc=0.5119, Val Loss=2.0238, lr=0.0100
[2025-05-05 12:23:22,816][train][INFO] - Epoch 11/140, Val Acc=0.4563, Val Loss=2.0992, lr=0.0100
[2025-05-05 12:23:24,290][train][INFO] - Epoch 7/140, Val Acc=0.5604, Val Loss=1.8918, lr=0.0100
[2025-05-05 12:23:26,732][train][INFO] - Epoch 9/140, Val Acc=0.5097, Val Loss=1.9512, lr=0.0100
[2025-05-05 12:23:29,891][train][INFO] - Epoch 12/140, Val Acc=0.4301, Val Loss=2.3874, lr=0.0100
[2025-05-05 12:23:31,881][train][INFO] - Epoch 8/140, Val Acc=0.6030, Val Loss=1.7195, lr=0.0100
[2025-05-05 12:23:33,968][train][INFO] - Epoch 10/140, Val Acc=0.4959, Val Loss=2.0721, lr=0.0100
[2025-05-05 12:23:37,012][train][INFO] - Epoch 13/140, Val Acc=0.4787, Val Loss=2.0031, lr=0.0100
[2025-05-05 12:23:39,294][train][INFO] - Epoch 9/140, Val Acc=0.5793, Val Loss=1.8505, lr=0.0100
[2025-05-05 12:23:41,632][train][INFO] - Epoch 11/140, Val Acc=0.5236, Val Loss=1.8983, lr=0.0100
[2025-05-05 12:23:44,593][train][INFO] - Epoch 14/140, Val Acc=0.4821, Val Loss=2.0243, lr=0.0100
[2025-05-05 12:23:46,567][train][INFO] - Epoch 10/140, Val Acc=0.6112, Val Loss=1.6534, lr=0.0100
[2025-05-05 12:23:49,124][train][INFO] - Epoch 12/140, Val Acc=0.5117, Val Loss=2.0123, lr=0.0100
[2025-05-05 12:23:52,563][train][INFO] - Epoch 15/140, Val Acc=0.4739, Val Loss=2.1164, lr=0.0100
[2025-05-05 12:23:54,296][train][INFO] - Epoch 11/140, Val Acc=0.5767, Val Loss=1.8618, lr=0.0100
[2025-05-05 12:23:57,035][train][INFO] - Epoch 13/140, Val Acc=0.4866, Val Loss=2.1874, lr=0.0100
[2025-05-05 12:24:00,601][train][INFO] - Epoch 16/140, Val Acc=0.4983, Val Loss=1.9240, lr=0.0100
[2025-05-05 12:24:01,742][train][INFO] - Epoch 12/140, Val Acc=0.5811, Val Loss=1.8600, lr=0.0100
[2025-05-05 12:24:04,599][train][INFO] - Epoch 14/140, Val Acc=0.5272, Val Loss=1.9324, lr=0.0100
[2025-05-05 12:24:07,838][train][INFO] - Epoch 17/140, Val Acc=0.5062, Val Loss=1.9063, lr=0.0100
[2025-05-05 12:24:08,781][train][INFO] - Epoch 13/140, Val Acc=0.5819, Val Loss=1.8223, lr=0.0100
[2025-05-05 12:24:11,743][train][INFO] - Epoch 15/140, Val Acc=0.5004, Val Loss=2.1962, lr=0.0100
[2025-05-05 12:24:15,596][train][INFO] - Epoch 18/140, Val Acc=0.5155, Val Loss=1.8826, lr=0.0100
[2025-05-05 12:24:16,220][train][INFO] - Epoch 14/140, Val Acc=0.5952, Val Loss=1.8090, lr=0.0100
[2025-05-05 12:24:18,750][train][INFO] - Epoch 16/140, Val Acc=0.5251, Val Loss=1.9825, lr=0.0100
[2025-05-05 12:24:22,798][train][INFO] - Epoch 19/140, Val Acc=0.4864, Val Loss=2.0594, lr=0.0100
[2025-05-05 12:24:23,945][train][INFO] - Epoch 15/140, Val Acc=0.5662, Val Loss=1.9829, lr=0.0100
[2025-05-05 12:24:26,591][train][INFO] - Epoch 17/140, Val Acc=0.5004, Val Loss=2.1988, lr=0.0100
[2025-05-05 12:24:30,081][train][INFO] - Epoch 20/140, Val Acc=0.4885, Val Loss=2.0477, lr=0.0100
[2025-05-05 12:24:31,304][train][INFO] - Epoch 16/140, Val Acc=0.6044, Val Loss=1.7753, lr=0.0100
[2025-05-05 12:24:33,907][train][INFO] - Epoch 18/140, Val Acc=0.5438, Val Loss=1.8787, lr=0.0100
[2025-05-05 12:24:37,933][train][INFO] - Epoch 21/140, Val Acc=0.5012, Val Loss=2.0546, lr=0.0100
[2025-05-05 12:24:38,631][train][INFO] - Epoch 17/140, Val Acc=0.6112, Val Loss=1.6951, lr=0.0100
[2025-05-05 12:24:41,438][train][INFO] - Epoch 19/140, Val Acc=0.5209, Val Loss=2.0116, lr=0.0100
[2025-05-05 12:24:45,436][train][INFO] - Epoch 22/140, Val Acc=0.5217, Val Loss=1.9010, lr=0.0100
[2025-05-05 12:24:46,112][train][INFO] - Epoch 18/140, Val Acc=0.5942, Val Loss=1.8035, lr=0.0100
[2025-05-05 12:24:48,958][train][INFO] - Epoch 20/140, Val Acc=0.5211, Val Loss=2.0519, lr=0.0100
[2025-05-05 12:24:53,086][train][INFO] - Epoch 23/140, Val Acc=0.5267, Val Loss=1.8543, lr=0.0100
[2025-05-05 12:24:54,082][train][INFO] - Epoch 19/140, Val Acc=0.5659, Val Loss=1.9461, lr=0.0100
[2025-05-05 12:24:56,349][train][INFO] - Epoch 21/140, Val Acc=0.5361, Val Loss=1.9395, lr=0.0100
[2025-05-05 12:25:00,579][train][INFO] - Epoch 24/140, Val Acc=0.5109, Val Loss=1.9352, lr=0.0100
[2025-05-05 12:25:01,476][train][INFO] - Epoch 20/140, Val Acc=0.5681, Val Loss=2.0033, lr=0.0100
[2025-05-05 12:25:03,962][train][INFO] - Epoch 22/140, Val Acc=0.5219, Val Loss=2.0095, lr=0.0100
[2025-05-05 12:25:07,900][train][INFO] - Epoch 25/140, Val Acc=0.5383, Val Loss=1.8524, lr=0.0100
[2025-05-05 12:25:09,066][train][INFO] - Epoch 21/140, Val Acc=0.5967, Val Loss=1.8184, lr=0.0100
[2025-05-05 12:25:11,758][train][INFO] - Epoch 23/140, Val Acc=0.5377, Val Loss=1.9374, lr=0.0100
[2025-05-05 12:25:15,285][train][INFO] - Epoch 26/140, Val Acc=0.5244, Val Loss=1.9478, lr=0.0100
[2025-05-05 12:25:16,544][train][INFO] - Epoch 22/140, Val Acc=0.5956, Val Loss=1.8117, lr=0.0100
[2025-05-05 12:25:19,181][train][INFO] - Epoch 24/140, Val Acc=0.5326, Val Loss=1.9642, lr=0.0100
[2025-05-05 12:25:22,897][train][INFO] - Epoch 27/140, Val Acc=0.5311, Val Loss=1.8686, lr=0.0100
[2025-05-05 12:25:23,843][train][INFO] - Epoch 23/140, Val Acc=0.6138, Val Loss=1.7348, lr=0.0100
[2025-05-05 12:25:26,978][train][INFO] - Epoch 25/140, Val Acc=0.5101, Val Loss=2.1377, lr=0.0100
[2025-05-05 12:25:31,180][train][INFO] - Epoch 28/140, Val Acc=0.5365, Val Loss=1.7945, lr=0.0100
[2025-05-05 12:25:31,215][train][INFO] - Epoch 24/140, Val Acc=0.5857, Val Loss=1.8928, lr=0.0100
[2025-05-05 12:25:34,557][train][INFO] - Epoch 26/140, Val Acc=0.5520, Val Loss=1.8665, lr=0.0100
[2025-05-05 12:25:38,597][train][INFO] - Epoch 25/140, Val Acc=0.6055, Val Loss=1.7928, lr=0.0100
[2025-05-05 12:25:38,768][train][INFO] - Epoch 29/140, Val Acc=0.5111, Val Loss=1.9880, lr=0.0100
[2025-05-05 12:25:42,165][train][INFO] - Epoch 27/140, Val Acc=0.5640, Val Loss=1.8175, lr=0.0100
[2025-05-05 12:25:46,071][train][INFO] - Epoch 30/140, Val Acc=0.5123, Val Loss=2.0225, lr=0.0100
[2025-05-05 12:25:46,513][train][INFO] - Epoch 26/140, Val Acc=0.6194, Val Loss=1.6830, lr=0.0100
[2025-05-05 12:25:49,001][train][INFO] - Epoch 28/140, Val Acc=0.5374, Val Loss=1.9623, lr=0.0100
[2025-05-05 12:25:53,600][train][INFO] - Epoch 27/140, Val Acc=0.6035, Val Loss=1.7950, lr=0.0100
[2025-05-05 12:25:53,912][train][INFO] - Epoch 31/140, Val Acc=0.5202, Val Loss=2.0023, lr=0.0100
[2025-05-05 12:25:56,505][train][INFO] - Epoch 29/140, Val Acc=0.5398, Val Loss=1.9598, lr=0.0100
[2025-05-05 12:26:00,834][train][INFO] - Epoch 32/140, Val Acc=0.5332, Val Loss=1.8724, lr=0.0100
[2025-05-05 12:26:01,157][train][INFO] - Epoch 28/140, Val Acc=0.6056, Val Loss=1.7886, lr=0.0100
[2025-05-05 12:26:03,992][train][INFO] - Epoch 30/140, Val Acc=0.5380, Val Loss=1.9910, lr=0.0100
[2025-05-05 12:26:08,491][train][INFO] - Epoch 33/140, Val Acc=0.5317, Val Loss=1.9185, lr=0.0100
[2025-05-05 12:26:08,825][train][INFO] - Epoch 29/140, Val Acc=0.6151, Val Loss=1.7251, lr=0.0100
[2025-05-05 12:26:11,783][train][INFO] - Epoch 31/140, Val Acc=0.5526, Val Loss=1.8580, lr=0.0100
[2025-05-05 12:26:15,802][train][INFO] - Epoch 34/140, Val Acc=0.5235, Val Loss=1.9256, lr=0.0100
[2025-05-05 12:26:15,918][train][INFO] - Epoch 30/140, Val Acc=0.6167, Val Loss=1.7391, lr=0.0100
[2025-05-05 12:26:19,223][train][INFO] - Epoch 32/140, Val Acc=0.5423, Val Loss=2.0052, lr=0.0100
[2025-05-05 12:26:23,534][train][INFO] - Epoch 35/140, Val Acc=0.5367, Val Loss=1.8677, lr=0.0100
[2025-05-05 12:26:23,657][train][INFO] - Epoch 31/140, Val Acc=0.6032, Val Loss=1.8362, lr=0.0100
[2025-05-05 12:26:26,655][train][INFO] - Epoch 33/140, Val Acc=0.5503, Val Loss=1.9032, lr=0.0100
[2025-05-05 12:26:31,141][train][INFO] - Epoch 36/140, Val Acc=0.5416, Val Loss=1.8525, lr=0.0100
[2025-05-05 12:26:31,372][train][INFO] - Epoch 32/140, Val Acc=0.6201, Val Loss=1.7251, lr=0.0100
[2025-05-05 12:26:34,226][train][INFO] - Epoch 34/140, Val Acc=0.5401, Val Loss=2.0075, lr=0.0100
[2025-05-05 12:26:38,410][train][INFO] - Epoch 33/140, Val Acc=0.5829, Val Loss=1.9501, lr=0.0100
[2025-05-05 12:26:38,678][train][INFO] - Epoch 37/140, Val Acc=0.5327, Val Loss=1.9156, lr=0.0100
[2025-05-05 12:26:41,399][train][INFO] - Epoch 35/140, Val Acc=0.5150, Val Loss=2.1341, lr=0.0100
[2025-05-05 12:26:45,692][train][INFO] - Epoch 38/140, Val Acc=0.5176, Val Loss=2.0202, lr=0.0100
[2025-05-05 12:26:46,181][train][INFO] - Epoch 34/140, Val Acc=0.6148, Val Loss=1.7837, lr=0.0100
[2025-05-05 12:26:48,702][train][INFO] - Epoch 36/140, Val Acc=0.5543, Val Loss=1.9252, lr=0.0100
[2025-05-05 12:26:53,065][train][INFO] - Epoch 39/140, Val Acc=0.5502, Val Loss=1.7962, lr=0.0100
[2025-05-05 12:26:54,109][train][INFO] - Epoch 35/140, Val Acc=0.6227, Val Loss=1.7000, lr=0.0100
[2025-05-05 12:26:56,243][train][INFO] - Epoch 37/140, Val Acc=0.5544, Val Loss=1.9257, lr=0.0100
[2025-05-05 12:27:00,430][train][INFO] - Epoch 40/140, Val Acc=0.5216, Val Loss=1.9706, lr=0.0100
[2025-05-05 12:27:01,378][train][INFO] - Epoch 36/140, Val Acc=0.6128, Val Loss=1.7822, lr=0.0100
[2025-05-05 12:27:03,488][train][INFO] - Epoch 38/140, Val Acc=0.5521, Val Loss=1.9160, lr=0.0100
[2025-05-05 12:27:08,359][train][INFO] - Epoch 41/140, Val Acc=0.5264, Val Loss=1.9565, lr=0.0100
[2025-05-05 12:27:08,538][train][INFO] - Epoch 37/140, Val Acc=0.6045, Val Loss=1.8133, lr=0.0100
[2025-05-05 12:27:11,125][train][INFO] - Epoch 39/140, Val Acc=0.5486, Val Loss=1.9163, lr=0.0100
[2025-05-05 12:27:16,141][train][INFO] - Epoch 42/140, Val Acc=0.5289, Val Loss=1.9385, lr=0.0100
[2025-05-05 12:27:16,273][train][INFO] - Epoch 38/140, Val Acc=0.6252, Val Loss=1.6909, lr=0.0100
[2025-05-05 12:27:18,285][train][INFO] - Epoch 40/140, Val Acc=0.5578, Val Loss=1.9042, lr=0.0100
[2025-05-05 12:27:23,766][train][INFO] - Epoch 43/140, Val Acc=0.5451, Val Loss=1.8389, lr=0.0100
[2025-05-05 12:27:23,827][train][INFO] - Epoch 39/140, Val Acc=0.6064, Val Loss=1.8010, lr=0.0100
[2025-05-05 12:27:25,877][train][INFO] - Epoch 41/140, Val Acc=0.5604, Val Loss=1.9096, lr=0.0100
[2025-05-05 12:27:31,346][train][INFO] - Epoch 44/140, Val Acc=0.5160, Val Loss=2.0373, lr=0.0100
[2025-05-05 12:27:31,370][train][INFO] - Epoch 40/140, Val Acc=0.5802, Val Loss=1.9744, lr=0.0100
[2025-05-05 12:27:33,636][train][INFO] - Epoch 42/140, Val Acc=0.5502, Val Loss=1.9282, lr=0.0100
[2025-05-05 12:27:38,123][train][INFO] - Epoch 45/140, Val Acc=0.5347, Val Loss=1.9158, lr=0.0100
[2025-05-05 12:27:38,894][train][INFO] - Epoch 41/140, Val Acc=0.6089, Val Loss=1.8042, lr=0.0100
[2025-05-05 12:27:41,039][train][INFO] - Epoch 43/140, Val Acc=0.5541, Val Loss=1.9548, lr=0.0100
[2025-05-05 12:27:45,710][train][INFO] - Epoch 46/140, Val Acc=0.5263, Val Loss=2.0005, lr=0.0100
[2025-05-05 12:27:45,991][train][INFO] - Epoch 42/140, Val Acc=0.6011, Val Loss=1.8350, lr=0.0100
[2025-05-05 12:27:48,698][train][INFO] - Epoch 44/140, Val Acc=0.5585, Val Loss=1.9517, lr=0.0100
[2025-05-05 12:27:53,324][train][INFO] - Epoch 47/140, Val Acc=0.5371, Val Loss=1.9014, lr=0.0100
[2025-05-05 12:27:53,849][train][INFO] - Epoch 43/140, Val Acc=0.6116, Val Loss=1.8001, lr=0.0100
[2025-05-05 12:27:56,539][train][INFO] - Epoch 45/140, Val Acc=0.5452, Val Loss=2.0236, lr=0.0100
[2025-05-05 12:28:00,622][train][INFO] - Epoch 48/140, Val Acc=0.5341, Val Loss=1.9266, lr=0.0100
[2025-05-05 12:28:00,813][train][INFO] - Epoch 44/140, Val Acc=0.6213, Val Loss=1.7282, lr=0.0100
[2025-05-05 12:28:04,187][train][INFO] - Epoch 46/140, Val Acc=0.5439, Val Loss=1.9957, lr=0.0100
[2025-05-05 12:28:08,224][train][INFO] - Epoch 49/140, Val Acc=0.5454, Val Loss=1.8494, lr=0.0100
[2025-05-05 12:28:08,261][train][INFO] - Epoch 45/140, Val Acc=0.6159, Val Loss=1.7519, lr=0.0100
[2025-05-05 12:28:12,174][train][INFO] - Epoch 47/140, Val Acc=0.5323, Val Loss=2.0504, lr=0.0100
[2025-05-05 12:28:15,883][train][INFO] - Epoch 46/140, Val Acc=0.5740, Val Loss=2.0665, lr=0.0100
[2025-05-05 12:28:16,126][train][INFO] - Epoch 50/140, Val Acc=0.5379, Val Loss=1.9646, lr=0.0100
[2025-05-05 12:28:20,060][train][INFO] - Epoch 48/140, Val Acc=0.5513, Val Loss=1.9641, lr=0.0100
[2025-05-05 12:28:23,097][train][INFO] - Epoch 51/140, Val Acc=0.5540, Val Loss=1.8495, lr=0.0100
[2025-05-05 12:28:23,312][train][INFO] - Epoch 47/140, Val Acc=0.6062, Val Loss=1.8407, lr=0.0100
[2025-05-05 12:28:27,256][train][INFO] - Epoch 49/140, Val Acc=0.5381, Val Loss=2.1447, lr=0.0100
[2025-05-05 12:28:30,385][train][INFO] - Epoch 48/140, Val Acc=0.6043, Val Loss=1.8224, lr=0.0100
[2025-05-05 12:28:30,540][train][INFO] - Epoch 52/140, Val Acc=0.5113, Val Loss=2.0411, lr=0.0100
[2025-05-05 12:28:35,089][train][INFO] - Epoch 50/140, Val Acc=0.5644, Val Loss=1.9128, lr=0.0100
[2025-05-05 12:28:37,244][train][INFO] - Epoch 49/140, Val Acc=0.6127, Val Loss=1.8002, lr=0.0100
[2025-05-05 12:28:38,224][train][INFO] - Epoch 53/140, Val Acc=0.5271, Val Loss=1.9656, lr=0.0100
[2025-05-05 12:28:42,707][train][INFO] - Epoch 51/140, Val Acc=0.5569, Val Loss=1.9584, lr=0.0100
[2025-05-05 12:28:44,524][train][INFO] - Epoch 50/140, Val Acc=0.6121, Val Loss=1.7954, lr=0.0100
[2025-05-05 12:28:45,848][train][INFO] - Epoch 54/140, Val Acc=0.5514, Val Loss=1.8476, lr=0.0100
[2025-05-05 12:28:50,637][train][INFO] - Epoch 52/140, Val Acc=0.5030, Val Loss=2.2749, lr=0.0100
[2025-05-05 12:28:51,106][train][INFO] - Epoch 51/140, Val Acc=0.6015, Val Loss=1.8672, lr=0.0100
[2025-05-05 12:28:52,956][train][INFO] - Epoch 55/140, Val Acc=0.5243, Val Loss=2.0133, lr=0.0100
[2025-05-05 12:28:57,990][train][INFO] - Epoch 52/140, Val Acc=0.6012, Val Loss=1.8931, lr=0.0100
[2025-05-05 12:28:58,313][train][INFO] - Epoch 53/140, Val Acc=0.5173, Val Loss=2.2256, lr=0.0100
[2025-05-05 12:29:00,452][train][INFO] - Epoch 56/140, Val Acc=0.5100, Val Loss=2.1107, lr=0.0100
[2025-05-05 12:29:05,197][train][INFO] - Epoch 53/140, Val Acc=0.6083, Val Loss=1.8277, lr=0.0100
[2025-05-05 12:29:06,136][train][INFO] - Epoch 54/140, Val Acc=0.5636, Val Loss=1.8892, lr=0.0100
[2025-05-05 12:29:07,504][train][INFO] - Epoch 57/140, Val Acc=0.5050, Val Loss=2.1915, lr=0.0100
[2025-05-05 12:29:12,881][train][INFO] - Epoch 54/140, Val Acc=0.6181, Val Loss=1.7789, lr=0.0100
[2025-05-05 12:29:13,748][train][INFO] - Epoch 55/140, Val Acc=0.5688, Val Loss=1.8814, lr=0.0100
[2025-05-05 12:29:15,356][train][INFO] - Epoch 58/140, Val Acc=0.5388, Val Loss=1.9376, lr=0.0100
[2025-05-05 12:29:20,485][train][INFO] - Epoch 55/140, Val Acc=0.5983, Val Loss=1.8885, lr=0.0100
[2025-05-05 12:29:21,543][train][INFO] - Epoch 56/140, Val Acc=0.5618, Val Loss=1.9472, lr=0.0100
[2025-05-05 12:29:22,773][train][INFO] - Epoch 59/140, Val Acc=0.5199, Val Loss=2.1189, lr=0.0100
[2025-05-05 12:29:28,185][train][INFO] - Epoch 56/140, Val Acc=0.6208, Val Loss=1.7237, lr=0.0100
[2025-05-05 12:29:29,109][train][INFO] - Epoch 57/140, Val Acc=0.5174, Val Loss=2.1727, lr=0.0100
[2025-05-05 12:29:30,129][train][INFO] - Epoch 60/140, Val Acc=0.5481, Val Loss=1.8890, lr=0.0100
[2025-05-05 12:29:35,773][train][INFO] - Epoch 57/140, Val Acc=0.6009, Val Loss=1.8700, lr=0.0100
[2025-05-05 12:29:36,559][train][INFO] - Epoch 58/140, Val Acc=0.5659, Val Loss=1.9708, lr=0.0100
[2025-05-05 12:29:37,773][train][INFO] - Epoch 61/140, Val Acc=0.5352, Val Loss=1.9721, lr=0.0100
[2025-05-05 12:29:43,284][train][INFO] - Epoch 58/140, Val Acc=0.6090, Val Loss=1.8168, lr=0.0100
[2025-05-05 12:29:44,403][train][INFO] - Epoch 59/140, Val Acc=0.5340, Val Loss=2.1271, lr=0.0100
[2025-05-05 12:29:45,551][train][INFO] - Epoch 62/140, Val Acc=0.5282, Val Loss=2.0279, lr=0.0100
[2025-05-05 12:29:50,102][train][INFO] - Epoch 59/140, Val Acc=0.6032, Val Loss=1.8265, lr=0.0100
[2025-05-05 12:29:52,226][train][INFO] - Epoch 60/140, Val Acc=0.5601, Val Loss=1.9579, lr=0.0100
[2025-05-05 12:29:53,006][train][INFO] - Epoch 63/140, Val Acc=0.5424, Val Loss=1.9329, lr=0.0100
[2025-05-05 12:29:57,785][train][INFO] - Epoch 60/140, Val Acc=0.6115, Val Loss=1.8296, lr=0.0100
[2025-05-05 12:29:59,515][train][INFO] - Epoch 61/140, Val Acc=0.5596, Val Loss=1.9715, lr=0.0100
[2025-05-05 12:30:00,091][train][INFO] - Epoch 64/140, Val Acc=0.5093, Val Loss=2.1240, lr=0.0100
[2025-05-05 12:30:05,898][train][INFO] - Epoch 61/140, Val Acc=0.6253, Val Loss=1.7331, lr=0.0100
[2025-05-05 12:30:07,639][train][INFO] - Epoch 65/140, Val Acc=0.5354, Val Loss=1.9868, lr=0.0100
[2025-05-05 12:30:07,649][train][INFO] - Epoch 62/140, Val Acc=0.5559, Val Loss=1.9808, lr=0.0100
[2025-05-05 12:30:13,389][train][INFO] - Epoch 62/140, Val Acc=0.6219, Val Loss=1.7251, lr=0.0100
[2025-05-05 12:30:15,194][train][INFO] - Epoch 66/140, Val Acc=0.5282, Val Loss=2.0109, lr=0.0100
[2025-05-05 12:30:15,415][train][INFO] - Epoch 63/140, Val Acc=0.5309, Val Loss=2.1457, lr=0.0100
[2025-05-05 12:30:21,223][train][INFO] - Epoch 63/140, Val Acc=0.6005, Val Loss=1.8733, lr=0.0100
[2025-05-05 12:30:22,887][train][INFO] - Epoch 67/140, Val Acc=0.5497, Val Loss=1.9268, lr=0.0100
[2025-05-05 12:30:23,001][train][INFO] - Epoch 64/140, Val Acc=0.5763, Val Loss=1.8503, lr=0.0100
[2025-05-05 12:30:28,576][train][INFO] - Epoch 64/140, Val Acc=0.6194, Val Loss=1.7513, lr=0.0100
[2025-05-05 12:30:30,129][train][INFO] - Epoch 68/140, Val Acc=0.5502, Val Loss=1.8820, lr=0.0100
[2025-05-05 12:30:30,315][train][INFO] - Epoch 65/140, Val Acc=0.5424, Val Loss=2.1263, lr=0.0100
[2025-05-05 12:30:35,916][train][INFO] - Epoch 65/140, Val Acc=0.5871, Val Loss=1.9758, lr=0.0100
[2025-05-05 12:30:37,782][train][INFO] - Epoch 69/140, Val Acc=0.5343, Val Loss=1.9731, lr=0.0100
[2025-05-05 12:30:37,908][train][INFO] - Epoch 66/140, Val Acc=0.5575, Val Loss=1.9971, lr=0.0100
[2025-05-05 12:30:42,897][train][INFO] - Epoch 66/140, Val Acc=0.6018, Val Loss=1.9325, lr=0.0100
[2025-05-05 12:30:45,588][train][INFO] - Epoch 70/140, Val Acc=0.5500, Val Loss=1.9317, lr=0.0100
[2025-05-05 12:30:45,666][train][INFO] - Epoch 67/140, Val Acc=0.5428, Val Loss=2.0882, lr=0.0100
[2025-05-05 12:30:50,537][train][INFO] - Epoch 67/140, Val Acc=0.6095, Val Loss=1.8626, lr=0.0100
[2025-05-05 12:30:52,441][train][INFO] - Epoch 71/140, Val Acc=0.5316, Val Loss=2.0197, lr=0.0100
[2025-05-05 12:30:53,440][train][INFO] - Epoch 68/140, Val Acc=0.5699, Val Loss=1.9288, lr=0.0100
[2025-05-05 12:30:58,090][train][INFO] - Epoch 68/140, Val Acc=0.6271, Val Loss=1.7619, lr=0.0100
[2025-05-05 12:31:00,114][train][INFO] - Epoch 72/140, Val Acc=0.5409, Val Loss=2.0081, lr=0.0100
[2025-05-05 12:31:01,257][train][INFO] - Epoch 69/140, Val Acc=0.5322, Val Loss=2.1430, lr=0.0100
[2025-05-05 12:31:05,385][train][INFO] - Epoch 69/140, Val Acc=0.6175, Val Loss=1.7863, lr=0.0100
[2025-05-05 12:31:07,493][train][INFO] - Epoch 73/140, Val Acc=0.5452, Val Loss=1.9499, lr=0.0100
[2025-05-05 12:31:08,649][train][INFO] - Epoch 70/140, Val Acc=0.5493, Val Loss=2.0170, lr=0.0100
[2025-05-05 12:31:12,859][train][INFO] - Epoch 70/140, Val Acc=0.6009, Val Loss=1.8641, lr=0.0100
[2025-05-05 12:31:14,856][train][INFO] - Epoch 74/140, Val Acc=0.5469, Val Loss=1.9432, lr=0.0100
[2025-05-05 12:31:16,429][train][INFO] - Epoch 71/140, Val Acc=0.5590, Val Loss=1.9553, lr=0.0100
[2025-05-05 12:31:20,138][train][INFO] - Epoch 71/140, Val Acc=0.6174, Val Loss=1.8048, lr=0.0100
[2025-05-05 12:31:22,555][train][INFO] - Epoch 75/140, Val Acc=0.5358, Val Loss=2.0114, lr=0.0100
[2025-05-05 12:31:23,926][train][INFO] - Epoch 72/140, Val Acc=0.5585, Val Loss=1.9453, lr=0.0100
[2025-05-05 12:31:27,276][train][INFO] - Epoch 72/140, Val Acc=0.6190, Val Loss=1.7757, lr=0.0100
[2025-05-05 12:31:29,975][train][INFO] - Epoch 76/140, Val Acc=0.5474, Val Loss=1.9644, lr=0.0100
[2025-05-05 12:31:31,732][train][INFO] - Epoch 73/140, Val Acc=0.5649, Val Loss=1.8912, lr=0.0100
[2025-05-05 12:31:34,636][train][INFO] - Epoch 73/140, Val Acc=0.6209, Val Loss=1.7827, lr=0.0100
[2025-05-05 12:31:37,398][train][INFO] - Epoch 77/140, Val Acc=0.5461, Val Loss=1.9508, lr=0.0100
[2025-05-05 12:31:39,404][train][INFO] - Epoch 74/140, Val Acc=0.5586, Val Loss=1.9841, lr=0.0100
[2025-05-05 12:31:42,002][train][INFO] - Epoch 74/140, Val Acc=0.6083, Val Loss=1.8665, lr=0.0100
[2025-05-05 12:31:44,563][train][INFO] - Epoch 78/140, Val Acc=0.5324, Val Loss=2.0301, lr=0.0100
[2025-05-05 12:31:47,134][train][INFO] - Epoch 75/140, Val Acc=0.5703, Val Loss=1.9167, lr=0.0100
[2025-05-05 12:31:49,838][train][INFO] - Epoch 75/140, Val Acc=0.6164, Val Loss=1.8239, lr=0.0100
[2025-05-05 12:31:52,377][train][INFO] - Epoch 79/140, Val Acc=0.5319, Val Loss=2.0279, lr=0.0100
[2025-05-05 12:31:54,734][train][INFO] - Epoch 76/140, Val Acc=0.5506, Val Loss=2.0607, lr=0.0100
[2025-05-05 12:31:57,035][train][INFO] - Epoch 76/140, Val Acc=0.6077, Val Loss=1.8495, lr=0.0100
[2025-05-05 12:32:00,081][train][INFO] - Epoch 80/140, Val Acc=0.5269, Val Loss=2.0410, lr=0.0100
[2025-05-05 12:32:02,504][train][INFO] - Epoch 77/140, Val Acc=0.5366, Val Loss=2.0715, lr=0.0100
[2025-05-05 12:32:04,379][train][INFO] - Epoch 77/140, Val Acc=0.5976, Val Loss=1.9566, lr=0.0100
[2025-05-05 12:32:07,875][train][INFO] - Epoch 81/140, Val Acc=0.5998, Val Loss=1.6571, lr=0.0010
[2025-05-05 12:32:10,318][train][INFO] - Epoch 78/140, Val Acc=0.5460, Val Loss=2.0121, lr=0.0100
[2025-05-05 12:32:11,686][train][INFO] - Epoch 78/140, Val Acc=0.6211, Val Loss=1.7343, lr=0.0100
[2025-05-05 12:32:15,255][train][INFO] - Epoch 82/140, Val Acc=0.6045, Val Loss=1.6640, lr=0.0010
[2025-05-05 12:32:18,196][train][INFO] - Epoch 79/140, Val Acc=0.5523, Val Loss=2.0438, lr=0.0100
[2025-05-05 12:32:19,024][train][INFO] - Epoch 79/140, Val Acc=0.6109, Val Loss=1.8075, lr=0.0100
[2025-05-05 12:32:22,870][train][INFO] - Epoch 83/140, Val Acc=0.6048, Val Loss=1.6775, lr=0.0010
[2025-05-05 12:32:25,713][train][INFO] - Epoch 80/140, Val Acc=0.5672, Val Loss=1.9095, lr=0.0100
[2025-05-05 12:32:26,125][train][INFO] - Epoch 80/140, Val Acc=0.6247, Val Loss=1.7385, lr=0.0100
[2025-05-05 12:32:30,273][train][INFO] - Epoch 84/140, Val Acc=0.6086, Val Loss=1.6893, lr=0.0010
[2025-05-05 12:32:33,630][train][INFO] - Epoch 81/140, Val Acc=0.6245, Val Loss=1.6070, lr=0.0010
[2025-05-05 12:32:33,877][train][INFO] - Epoch 81/140, Val Acc=0.6798, Val Loss=1.4521, lr=0.0010
[2025-05-05 12:32:37,786][train][INFO] - Epoch 85/140, Val Acc=0.6125, Val Loss=1.6925, lr=0.0010
[2025-05-05 12:32:41,477][train][INFO] - Epoch 82/140, Val Acc=0.6850, Val Loss=1.4520, lr=0.0010
[2025-05-05 12:32:41,702][train][INFO] - Epoch 82/140, Val Acc=0.6335, Val Loss=1.6118, lr=0.0010
[2025-05-05 12:32:45,452][train][INFO] - Epoch 86/140, Val Acc=0.6099, Val Loss=1.6920, lr=0.0010
[2025-05-05 12:32:48,937][train][INFO] - Epoch 83/140, Val Acc=0.6328, Val Loss=1.6212, lr=0.0010
[2025-05-05 12:32:49,087][train][INFO] - Epoch 83/140, Val Acc=0.6844, Val Loss=1.4588, lr=0.0010
[2025-05-05 12:32:53,221][train][INFO] - Epoch 87/140, Val Acc=0.6096, Val Loss=1.7105, lr=0.0010
[2025-05-05 12:32:56,463][train][INFO] - Epoch 84/140, Val Acc=0.6326, Val Loss=1.6363, lr=0.0010
[2025-05-05 12:32:56,685][train][INFO] - Epoch 84/140, Val Acc=0.6858, Val Loss=1.4681, lr=0.0010
[2025-05-05 12:33:00,551][train][INFO] - Epoch 88/140, Val Acc=0.6114, Val Loss=1.7177, lr=0.0010
[2025-05-05 12:33:03,884][train][INFO] - Epoch 85/140, Val Acc=0.6333, Val Loss=1.6446, lr=0.0010
[2025-05-05 12:33:04,255][train][INFO] - Epoch 85/140, Val Acc=0.6865, Val Loss=1.4705, lr=0.0010
[2025-05-05 12:33:08,340][train][INFO] - Epoch 89/140, Val Acc=0.6144, Val Loss=1.7276, lr=0.0010
[2025-05-05 12:33:11,310][train][INFO] - Epoch 86/140, Val Acc=0.6331, Val Loss=1.6465, lr=0.0010
[2025-05-05 12:33:11,372][train][INFO] - Epoch 86/140, Val Acc=0.6870, Val Loss=1.4720, lr=0.0010
[2025-05-05 12:33:15,359][train][INFO] - Epoch 90/140, Val Acc=0.6129, Val Loss=1.7241, lr=0.0010
[2025-05-05 12:33:18,736][train][INFO] - Epoch 87/140, Val Acc=0.6337, Val Loss=1.6490, lr=0.0010
[2025-05-05 12:33:18,802][train][INFO] - Epoch 87/140, Val Acc=0.6841, Val Loss=1.4747, lr=0.0010
[2025-05-05 12:33:23,056][train][INFO] - Epoch 91/140, Val Acc=0.6101, Val Loss=1.7368, lr=0.0010
[2025-05-05 12:33:25,866][train][INFO] - Epoch 88/140, Val Acc=0.6339, Val Loss=1.6666, lr=0.0010
[2025-05-05 12:33:26,316][train][INFO] - Epoch 88/140, Val Acc=0.6865, Val Loss=1.4806, lr=0.0010
[2025-05-05 12:33:30,667][train][INFO] - Epoch 92/140, Val Acc=0.6127, Val Loss=1.7541, lr=0.0010
[2025-05-05 12:33:33,498][train][INFO] - Epoch 89/140, Val Acc=0.6368, Val Loss=1.6568, lr=0.0010
[2025-05-05 12:33:33,709][train][INFO] - Epoch 89/140, Val Acc=0.6873, Val Loss=1.4894, lr=0.0010
[2025-05-05 12:33:37,763][train][INFO] - Epoch 93/140, Val Acc=0.6157, Val Loss=1.7445, lr=0.0010
[2025-05-05 12:33:41,108][train][INFO] - Epoch 90/140, Val Acc=0.6852, Val Loss=1.4899, lr=0.0010
[2025-05-05 12:33:41,314][train][INFO] - Epoch 90/140, Val Acc=0.6327, Val Loss=1.6842, lr=0.0010
[2025-05-05 12:33:45,132][train][INFO] - Epoch 94/140, Val Acc=0.6123, Val Loss=1.7665, lr=0.0010
[2025-05-05 12:33:48,861][train][INFO] - Epoch 91/140, Val Acc=0.6884, Val Loss=1.5004, lr=0.0010
[2025-05-05 12:33:49,008][train][INFO] - Epoch 91/140, Val Acc=0.6360, Val Loss=1.6954, lr=0.0010
[2025-05-05 12:33:51,687][train][INFO] - Epoch 95/140, Val Acc=0.6105, Val Loss=1.7692, lr=0.0010
[2025-05-05 12:33:56,218][train][INFO] - Epoch 92/140, Val Acc=0.6330, Val Loss=1.6929, lr=0.0010
[2025-05-05 12:33:56,633][train][INFO] - Epoch 92/140, Val Acc=0.6878, Val Loss=1.5041, lr=0.0010
[2025-05-05 12:33:59,234][train][INFO] - Epoch 96/140, Val Acc=0.6130, Val Loss=1.7756, lr=0.0010
[2025-05-05 12:34:03,709][train][INFO] - Epoch 93/140, Val Acc=0.6353, Val Loss=1.6924, lr=0.0010
[2025-05-05 12:34:03,734][train][INFO] - Epoch 93/140, Val Acc=0.6859, Val Loss=1.5074, lr=0.0010
[2025-05-05 12:34:06,600][train][INFO] - Epoch 97/140, Val Acc=0.6127, Val Loss=1.7825, lr=0.0010
[2025-05-05 12:34:11,257][train][INFO] - Epoch 94/140, Val Acc=0.6851, Val Loss=1.5111, lr=0.0010
[2025-05-05 12:34:11,675][train][INFO] - Epoch 94/140, Val Acc=0.6333, Val Loss=1.7207, lr=0.0010
[2025-05-05 12:34:14,235][train][INFO] - Epoch 98/140, Val Acc=0.6093, Val Loss=1.7912, lr=0.0010
[2025-05-05 12:34:18,585][train][INFO] - Epoch 95/140, Val Acc=0.6852, Val Loss=1.5178, lr=0.0010
[2025-05-05 12:34:19,584][train][INFO] - Epoch 95/140, Val Acc=0.6324, Val Loss=1.7181, lr=0.0010
[2025-05-05 12:34:21,410][train][INFO] - Epoch 99/140, Val Acc=0.6131, Val Loss=1.7935, lr=0.0010
[2025-05-05 12:34:26,190][train][INFO] - Epoch 96/140, Val Acc=0.6870, Val Loss=1.5217, lr=0.0010
[2025-05-05 12:34:27,497][train][INFO] - Epoch 96/140, Val Acc=0.6383, Val Loss=1.7124, lr=0.0010
[2025-05-05 12:34:28,236][train][INFO] - Epoch 100/140, Val Acc=0.6131, Val Loss=1.7995, lr=0.0010
[2025-05-05 12:34:33,883][train][INFO] - Epoch 97/140, Val Acc=0.6841, Val Loss=1.5199, lr=0.0010
[2025-05-05 12:34:35,213][train][INFO] - Epoch 97/140, Val Acc=0.6321, Val Loss=1.7210, lr=0.0010
[2025-05-05 12:34:35,613][train][INFO] - Epoch 101/140, Val Acc=0.6132, Val Loss=1.8027, lr=0.0010
[2025-05-05 12:34:41,436][train][INFO] - Epoch 98/140, Val Acc=0.6846, Val Loss=1.5275, lr=0.0010
[2025-05-05 12:34:43,078][train][INFO] - Epoch 98/140, Val Acc=0.6367, Val Loss=1.7276, lr=0.0010
[2025-05-05 12:34:43,159][train][INFO] - Epoch 102/140, Val Acc=0.6125, Val Loss=1.8105, lr=0.0010
[2025-05-05 12:34:48,516][train][INFO] - Epoch 99/140, Val Acc=0.6875, Val Loss=1.5323, lr=0.0010
[2025-05-05 12:34:50,133][train][INFO] - Epoch 103/140, Val Acc=0.6106, Val Loss=1.8177, lr=0.0010
[2025-05-05 12:34:50,775][train][INFO] - Epoch 99/140, Val Acc=0.6328, Val Loss=1.7292, lr=0.0010
[2025-05-05 12:34:55,429][train][INFO] - Epoch 100/140, Val Acc=0.6842, Val Loss=1.5435, lr=0.0010
[2025-05-05 12:34:58,099][train][INFO] - Epoch 104/140, Val Acc=0.6116, Val Loss=1.8218, lr=0.0010
[2025-05-05 12:34:58,112][train][INFO] - Epoch 100/140, Val Acc=0.6347, Val Loss=1.7489, lr=0.0010
[2025-05-05 12:35:02,981][train][INFO] - Epoch 101/140, Val Acc=0.6842, Val Loss=1.5334, lr=0.0010
[2025-05-05 12:35:05,613][train][INFO] - Epoch 101/140, Val Acc=0.6351, Val Loss=1.7401, lr=0.0010
[2025-05-05 12:35:05,896][train][INFO] - Epoch 105/140, Val Acc=0.6121, Val Loss=1.8266, lr=0.0010
[2025-05-05 12:35:10,679][train][INFO] - Epoch 102/140, Val Acc=0.6853, Val Loss=1.5352, lr=0.0010
[2025-05-05 12:35:12,975][train][INFO] - Epoch 102/140, Val Acc=0.6373, Val Loss=1.7401, lr=0.0010
[2025-05-05 12:35:13,701][train][INFO] - Epoch 106/140, Val Acc=0.6116, Val Loss=1.8318, lr=0.0010
[2025-05-05 12:35:18,426][train][INFO] - Epoch 103/140, Val Acc=0.6868, Val Loss=1.5317, lr=0.0010
[2025-05-05 12:35:20,565][train][INFO] - Epoch 103/140, Val Acc=0.6359, Val Loss=1.7497, lr=0.0010
[2025-05-05 12:35:21,520][train][INFO] - Epoch 107/140, Val Acc=0.6082, Val Loss=1.8316, lr=0.0010
[2025-05-05 12:35:26,051][train][INFO] - Epoch 104/140, Val Acc=0.6876, Val Loss=1.5309, lr=0.0010
[2025-05-05 12:35:28,099][train][INFO] - Epoch 104/140, Val Acc=0.6369, Val Loss=1.7599, lr=0.0010
[2025-05-05 12:35:28,732][train][INFO] - Epoch 108/140, Val Acc=0.6115, Val Loss=1.8384, lr=0.0010
[2025-05-05 12:35:33,473][train][INFO] - Epoch 105/140, Val Acc=0.6908, Val Loss=1.5420, lr=0.0010
[2025-05-05 12:35:35,762][train][INFO] - Epoch 105/140, Val Acc=0.6384, Val Loss=1.7699, lr=0.0010
[2025-05-05 12:35:36,303][train][INFO] - Epoch 109/140, Val Acc=0.6134, Val Loss=1.8552, lr=0.0010
[2025-05-05 12:35:41,429][train][INFO] - Epoch 106/140, Val Acc=0.6877, Val Loss=1.5462, lr=0.0010
[2025-05-05 12:35:43,538][train][INFO] - Epoch 106/140, Val Acc=0.6373, Val Loss=1.7669, lr=0.0010
[2025-05-05 12:35:44,009][train][INFO] - Epoch 110/140, Val Acc=0.6109, Val Loss=1.8550, lr=0.0010
[2025-05-05 12:35:49,093][train][INFO] - Epoch 107/140, Val Acc=0.6879, Val Loss=1.5480, lr=0.0010
[2025-05-05 12:35:51,111][train][INFO] - Epoch 111/140, Val Acc=0.6110, Val Loss=1.8717, lr=0.0010
[2025-05-05 12:35:51,175][train][INFO] - Epoch 107/140, Val Acc=0.6371, Val Loss=1.7831, lr=0.0010
[2025-05-05 12:35:56,066][train][INFO] - Epoch 108/140, Val Acc=0.6892, Val Loss=1.5488, lr=0.0010
[2025-05-05 12:35:58,734][train][INFO] - Epoch 112/140, Val Acc=0.6095, Val Loss=1.8761, lr=0.0010
[2025-05-05 12:35:58,796][train][INFO] - Epoch 108/140, Val Acc=0.6394, Val Loss=1.7745, lr=0.0010
[2025-05-05 12:36:03,455][train][INFO] - Epoch 109/140, Val Acc=0.6902, Val Loss=1.5436, lr=0.0010
[2025-05-05 12:36:06,349][train][INFO] - Epoch 109/140, Val Acc=0.6385, Val Loss=1.7910, lr=0.0010
[2025-05-05 12:36:06,438][train][INFO] - Epoch 113/140, Val Acc=0.6118, Val Loss=1.8731, lr=0.0010
[2025-05-05 12:36:10,524][train][INFO] - Epoch 110/140, Val Acc=0.6879, Val Loss=1.5596, lr=0.0010
[2025-05-05 12:36:13,556][train][INFO] - Epoch 110/140, Val Acc=0.6396, Val Loss=1.7795, lr=0.0010
[2025-05-05 12:36:13,738][train][INFO] - Epoch 114/140, Val Acc=0.6146, Val Loss=1.8726, lr=0.0010
[2025-05-05 12:36:17,936][train][INFO] - Epoch 111/140, Val Acc=0.6872, Val Loss=1.5570, lr=0.0010
[2025-05-05 12:36:20,596][train][INFO] - Epoch 111/140, Val Acc=0.6382, Val Loss=1.7894, lr=0.0010
[2025-05-05 12:36:21,398][train][INFO] - Epoch 115/140, Val Acc=0.6093, Val Loss=1.8879, lr=0.0010
[2025-05-05 12:36:24,991][train][INFO] - Epoch 112/140, Val Acc=0.6897, Val Loss=1.5592, lr=0.0010
[2025-05-05 12:36:27,863][train][INFO] - Epoch 112/140, Val Acc=0.6357, Val Loss=1.8012, lr=0.0010
[2025-05-05 12:36:28,811][train][INFO] - Epoch 116/140, Val Acc=0.6124, Val Loss=1.8768, lr=0.0010
[2025-05-05 12:36:32,681][train][INFO] - Epoch 113/140, Val Acc=0.6909, Val Loss=1.5586, lr=0.0010
[2025-05-05 12:36:35,647][train][INFO] - Epoch 113/140, Val Acc=0.6344, Val Loss=1.8023, lr=0.0010
[2025-05-05 12:36:36,269][train][INFO] - Epoch 117/140, Val Acc=0.6124, Val Loss=1.8972, lr=0.0010
[2025-05-05 12:36:40,321][train][INFO] - Epoch 114/140, Val Acc=0.6875, Val Loss=1.5592, lr=0.0010
[2025-05-05 12:36:43,293][train][INFO] - Epoch 114/140, Val Acc=0.6338, Val Loss=1.8149, lr=0.0010
[2025-05-05 12:36:43,786][train][INFO] - Epoch 118/140, Val Acc=0.6107, Val Loss=1.9010, lr=0.0010
[2025-05-05 12:36:47,814][train][INFO] - Epoch 115/140, Val Acc=0.6882, Val Loss=1.5674, lr=0.0010
[2025-05-05 12:36:50,923][train][INFO] - Epoch 115/140, Val Acc=0.6360, Val Loss=1.8099, lr=0.0010
[2025-05-05 12:36:51,496][train][INFO] - Epoch 119/140, Val Acc=0.6133, Val Loss=1.8958, lr=0.0010
[2025-05-05 12:36:55,522][train][INFO] - Epoch 116/140, Val Acc=0.6927, Val Loss=1.5616, lr=0.0010
[2025-05-05 12:36:58,535][train][INFO] - Epoch 116/140, Val Acc=0.6379, Val Loss=1.8044, lr=0.0010
[2025-05-05 12:36:59,042][train][INFO] - Epoch 120/140, Val Acc=0.6085, Val Loss=1.9169, lr=0.0010
[2025-05-05 12:37:03,023][train][INFO] - Epoch 117/140, Val Acc=0.6882, Val Loss=1.5713, lr=0.0010
[2025-05-05 12:37:05,512][train][INFO] - Epoch 117/140, Val Acc=0.6329, Val Loss=1.8156, lr=0.0010
[2025-05-05 12:37:06,918][train][INFO] - Epoch 121/140, Val Acc=0.6116, Val Loss=1.9028, lr=0.0001
[2025-05-05 12:37:10,442][train][INFO] - Epoch 118/140, Val Acc=0.6894, Val Loss=1.5693, lr=0.0010
[2025-05-05 12:37:12,758][train][INFO] - Epoch 118/140, Val Acc=0.6353, Val Loss=1.8226, lr=0.0010
[2025-05-05 12:37:14,579][train][INFO] - Epoch 122/140, Val Acc=0.6112, Val Loss=1.9099, lr=0.0001
[2025-05-05 12:37:18,131][train][INFO] - Epoch 119/140, Val Acc=0.6924, Val Loss=1.5698, lr=0.0010
[2025-05-05 12:37:20,557][train][INFO] - Epoch 119/140, Val Acc=0.6378, Val Loss=1.8343, lr=0.0010
[2025-05-05 12:37:22,469][train][INFO] - Epoch 123/140, Val Acc=0.6108, Val Loss=1.9004, lr=0.0001
[2025-05-05 12:37:25,669][train][INFO] - Epoch 120/140, Val Acc=0.6902, Val Loss=1.5710, lr=0.0010
[2025-05-05 12:37:28,223][train][INFO] - Epoch 120/140, Val Acc=0.6372, Val Loss=1.8342, lr=0.0010
[2025-05-05 12:37:30,065][train][INFO] - Epoch 124/140, Val Acc=0.6104, Val Loss=1.9042, lr=0.0001
[2025-05-05 12:37:33,234][train][INFO] - Epoch 121/140, Val Acc=0.6922, Val Loss=1.5655, lr=0.0001
[2025-05-05 12:37:35,781][train][INFO] - Epoch 121/140, Val Acc=0.6401, Val Loss=1.8203, lr=0.0001
[2025-05-05 12:37:37,403][train][INFO] - Epoch 125/140, Val Acc=0.6123, Val Loss=1.8993, lr=0.0001
[2025-05-05 12:37:40,830][train][INFO] - Epoch 122/140, Val Acc=0.6900, Val Loss=1.5690, lr=0.0001
[2025-05-05 12:37:42,811][train][INFO] - Epoch 122/140, Val Acc=0.6376, Val Loss=1.8243, lr=0.0001
[2025-05-05 12:37:45,069][train][INFO] - Epoch 126/140, Val Acc=0.6129, Val Loss=1.9004, lr=0.0001
[2025-05-05 12:37:48,587][train][INFO] - Epoch 123/140, Val Acc=0.6906, Val Loss=1.5682, lr=0.0001
[2025-05-05 12:37:50,388][train][INFO] - Epoch 123/140, Val Acc=0.6351, Val Loss=1.8225, lr=0.0001
[2025-05-05 12:37:52,735][train][INFO] - Epoch 127/140, Val Acc=0.6112, Val Loss=1.9073, lr=0.0001
[2025-05-05 12:37:56,496][train][INFO] - Epoch 124/140, Val Acc=0.6913, Val Loss=1.5689, lr=0.0001
[2025-05-05 12:37:57,909][train][INFO] - Epoch 124/140, Val Acc=0.6385, Val Loss=1.8215, lr=0.0001
[2025-05-05 12:38:00,232][train][INFO] - Epoch 128/140, Val Acc=0.6119, Val Loss=1.9024, lr=0.0001
[2025-05-05 12:38:03,976][train][INFO] - Epoch 125/140, Val Acc=0.6913, Val Loss=1.5708, lr=0.0001
[2025-05-05 12:38:05,519][train][INFO] - Epoch 125/140, Val Acc=0.6355, Val Loss=1.8230, lr=0.0001
[2025-05-05 12:38:07,749][train][INFO] - Epoch 129/140, Val Acc=0.6106, Val Loss=1.9015, lr=0.0001
[2025-05-05 12:38:11,674][train][INFO] - Epoch 126/140, Val Acc=0.6908, Val Loss=1.5657, lr=0.0001
[2025-05-05 12:38:13,100][train][INFO] - Epoch 126/140, Val Acc=0.6392, Val Loss=1.8171, lr=0.0001
[2025-05-05 12:38:15,075][train][INFO] - Epoch 130/140, Val Acc=0.6137, Val Loss=1.8983, lr=0.0001
[2025-05-05 12:38:18,754][train][INFO] - Epoch 127/140, Val Acc=0.6909, Val Loss=1.5733, lr=0.0001
[2025-05-05 12:38:20,747][train][INFO] - Epoch 127/140, Val Acc=0.6390, Val Loss=1.8279, lr=0.0001
[2025-05-05 12:38:22,463][train][INFO] - Epoch 131/140, Val Acc=0.6139, Val Loss=1.9027, lr=0.0001
[2025-05-05 12:38:26,089][train][INFO] - Epoch 128/140, Val Acc=0.6902, Val Loss=1.5693, lr=0.0001
[2025-05-05 12:38:28,334][train][INFO] - Epoch 128/140, Val Acc=0.6385, Val Loss=1.8183, lr=0.0001
[2025-05-05 12:38:30,248][train][INFO] - Epoch 132/140, Val Acc=0.6150, Val Loss=1.9131, lr=0.0001
[2025-05-05 12:38:33,784][train][INFO] - Epoch 129/140, Val Acc=0.6892, Val Loss=1.5695, lr=0.0001
[2025-05-05 12:38:35,988][train][INFO] - Epoch 129/140, Val Acc=0.6393, Val Loss=1.8235, lr=0.0001
[2025-05-05 12:38:38,021][train][INFO] - Epoch 133/140, Val Acc=0.6134, Val Loss=1.9058, lr=0.0001
[2025-05-05 12:38:41,110][train][INFO] - Epoch 130/140, Val Acc=0.6912, Val Loss=1.5641, lr=0.0001
[2025-05-05 12:38:43,309][train][INFO] - Epoch 130/140, Val Acc=0.6393, Val Loss=1.8230, lr=0.0001
[2025-05-05 12:38:45,863][train][INFO] - Epoch 134/140, Val Acc=0.6150, Val Loss=1.8992, lr=0.0001
[2025-05-05 12:38:48,530][train][INFO] - Epoch 131/140, Val Acc=0.6899, Val Loss=1.5718, lr=0.0001
[2025-05-05 12:38:51,018][train][INFO] - Epoch 131/140, Val Acc=0.6369, Val Loss=1.8274, lr=0.0001
[2025-05-05 12:38:53,108][train][INFO] - Epoch 135/140, Val Acc=0.6146, Val Loss=1.9061, lr=0.0001
[2025-05-05 12:38:55,709][train][INFO] - Epoch 132/140, Val Acc=0.6919, Val Loss=1.5737, lr=0.0001
[2025-05-05 12:38:58,369][train][INFO] - Epoch 132/140, Val Acc=0.6399, Val Loss=1.8303, lr=0.0001
[2025-05-05 12:39:00,604][train][INFO] - Epoch 136/140, Val Acc=0.6141, Val Loss=1.9021, lr=0.0001
[2025-05-05 12:39:03,183][train][INFO] - Epoch 133/140, Val Acc=0.6907, Val Loss=1.5697, lr=0.0001
[2025-05-05 12:39:06,181][train][INFO] - Epoch 133/140, Val Acc=0.6383, Val Loss=1.8259, lr=0.0001
[2025-05-05 12:39:08,184][train][INFO] - Epoch 137/140, Val Acc=0.6136, Val Loss=1.9017, lr=0.0001
[2025-05-05 12:39:10,841][train][INFO] - Epoch 134/140, Val Acc=0.6913, Val Loss=1.5696, lr=0.0001
[2025-05-05 12:39:13,574][train][INFO] - Epoch 134/140, Val Acc=0.6387, Val Loss=1.8209, lr=0.0001
[2025-05-05 12:39:15,892][train][INFO] - Epoch 138/140, Val Acc=0.6147, Val Loss=1.8984, lr=0.0001
[2025-05-05 12:39:18,506][train][INFO] - Epoch 135/140, Val Acc=0.6916, Val Loss=1.5661, lr=0.0001
[2025-05-05 12:39:21,514][train][INFO] - Epoch 135/140, Val Acc=0.6375, Val Loss=1.8253, lr=0.0001
[2025-05-05 12:39:23,116][train][INFO] - Epoch 139/140, Val Acc=0.6151, Val Loss=1.9021, lr=0.0001
[2025-05-05 12:39:25,765][train][INFO] - Epoch 136/140, Val Acc=0.6922, Val Loss=1.5596, lr=0.0001
[2025-05-05 12:39:29,168][train][INFO] - Epoch 136/140, Val Acc=0.6397, Val Loss=1.8197, lr=0.0001
[2025-05-05 12:39:30,744][train][INFO] - Epoch 140/140, Val Acc=0.6149, Val Loss=1.9048, lr=0.0001
[2025-05-05 12:39:33,224][train][INFO] - Epoch 137/140, Val Acc=0.6935, Val Loss=1.5651, lr=0.0001
[2025-05-05 12:39:35,997][train][INFO] - After training : Train Acc=0.9471  Val Acc=0.6157
[2025-05-05 12:39:36,029][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(16, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(66, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(122, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(250, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 162, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(162, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(6, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(21, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(25, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(20, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=52, out_features=100, bias=True)
)
[2025-05-05 12:39:36,029][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.6157000064849854
                      Speed up: 1.67   Final speed up: 5.05
[2025-05-05 12:39:36,686][train][INFO] - Epoch 137/140, Val Acc=0.6385, Val Loss=1.8233, lr=0.0001
[2025-05-05 12:39:40,364][train][INFO] - Epoch 138/140, Val Acc=0.6914, Val Loss=1.5668, lr=0.0001
[2025-05-05 12:39:44,746][train][INFO] - Epoch 138/140, Val Acc=0.6368, Val Loss=1.8220, lr=0.0001
[2025-05-05 12:39:48,321][train][INFO] - Epoch 139/140, Val Acc=0.6908, Val Loss=1.5716, lr=0.0001
[2025-05-05 12:39:52,907][train][INFO] - Epoch 139/140, Val Acc=0.6392, Val Loss=1.8235, lr=0.0001
[2025-05-05 12:39:56,309][train][INFO] - Epoch 140/140, Val Acc=0.6902, Val Loss=1.5725, lr=0.0001
[2025-05-05 12:40:01,431][train][INFO] - After training : Train Acc=0.9965  Val Acc=0.6935
[2025-05-05 12:40:01,454][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(10, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(81, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 249, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(249, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(249, 251, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(251, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(251, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(114, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(11, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(7, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(14, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(10, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(11, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(20, 105, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=105, out_features=100, bias=True)
)
[2025-05-05 12:40:01,455][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.6934999823570251
                      Speed up: 1.66   Final speed up: 5.03
[2025-05-05 12:40:01,574][train][INFO] - Epoch 140/140, Val Acc=0.6387, Val Loss=1.8285, lr=0.0001
[2025-05-05 12:40:06,631][train][INFO] - After training : Train Acc=0.9840  Val Acc=0.6401
[2025-05-05 12:40:06,660][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(9, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(79, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(124, 251, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(251, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(251, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(254, 123, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(123, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(2, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(19, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(6, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(21, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(25, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(13, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(10, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=93, out_features=100, bias=True)
)
[2025-05-05 12:40:06,660][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.6401000022888184
                      Speed up: 1.67   Final speed up: 5.05
[2025-05-05 12:58:09,511][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-05 12:58:09,561][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:58:09,561][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:58:09,561][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 12:58:13,749][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-05 12:58:13,819][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:58:13,819][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:58:13,819][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 12:58:17,342][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 12:58:17,394][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 12:58:17,394][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 12:58:17,394][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 12:58:23,113][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 12:58:27,592][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:58:30,435][train][INFO] - Epoch 1/100, Val Acc=0.1243, Val Loss=3.4677, lr=0.0100
[2025-05-05 12:58:31,570][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 12:58:35,402][train][INFO] - Epoch 1/100, Val Acc=0.1577, Val Loss=3.3296, lr=0.0100
[2025-05-05 12:58:37,969][train][INFO] - Epoch 2/100, Val Acc=0.2144, Val Loss=3.1136, lr=0.0100
[2025-05-05 12:58:39,243][train][INFO] - Epoch 1/100, Val Acc=0.2505, Val Loss=2.8838, lr=0.0100
[2025-05-05 12:58:42,848][train][INFO] - Epoch 2/100, Val Acc=0.3635, Val Loss=2.4141, lr=0.0100
[2025-05-05 12:58:46,162][train][INFO] - Epoch 3/100, Val Acc=0.2104, Val Loss=3.5578, lr=0.0100
[2025-05-05 12:58:47,180][train][INFO] - Epoch 2/100, Val Acc=0.4556, Val Loss=2.0225, lr=0.0100
[2025-05-05 12:58:50,606][train][INFO] - Epoch 3/100, Val Acc=0.4327, Val Loss=2.0928, lr=0.0100
[2025-05-05 12:58:54,377][train][INFO] - Epoch 4/100, Val Acc=0.3918, Val Loss=2.2622, lr=0.0100
[2025-05-05 12:58:55,218][train][INFO] - Epoch 3/100, Val Acc=0.5092, Val Loss=1.8887, lr=0.0100
[2025-05-05 12:58:58,209][train][INFO] - Epoch 4/100, Val Acc=0.4947, Val Loss=1.8791, lr=0.0100
[2025-05-05 12:59:02,310][train][INFO] - Epoch 5/100, Val Acc=0.3694, Val Loss=2.3837, lr=0.0100
[2025-05-05 12:59:03,493][train][INFO] - Epoch 4/100, Val Acc=0.5465, Val Loss=1.7416, lr=0.0100
[2025-05-05 12:59:06,526][train][INFO] - Epoch 5/100, Val Acc=0.5280, Val Loss=1.7670, lr=0.0100
[2025-05-05 12:59:10,328][train][INFO] - Epoch 6/100, Val Acc=0.4652, Val Loss=1.9748, lr=0.0100
[2025-05-05 12:59:11,721][train][INFO] - Epoch 5/100, Val Acc=0.5728, Val Loss=1.6605, lr=0.0100
[2025-05-05 12:59:14,238][train][INFO] - Epoch 6/100, Val Acc=0.5283, Val Loss=1.8656, lr=0.0100
[2025-05-05 12:59:18,365][train][INFO] - Epoch 7/100, Val Acc=0.4782, Val Loss=1.9643, lr=0.0100
[2025-05-05 12:59:20,243][train][INFO] - Epoch 6/100, Val Acc=0.5776, Val Loss=1.6386, lr=0.0100
[2025-05-05 12:59:22,132][train][INFO] - Epoch 7/100, Val Acc=0.5347, Val Loss=1.8302, lr=0.0100
[2025-05-05 12:59:26,763][train][INFO] - Epoch 8/100, Val Acc=0.5280, Val Loss=1.7707, lr=0.0100
[2025-05-05 12:59:27,300][train][INFO] - Epoch 7/100, Val Acc=0.6162, Val Loss=1.4876, lr=0.0100
[2025-05-05 12:59:29,943][train][INFO] - Epoch 8/100, Val Acc=0.5859, Val Loss=1.5801, lr=0.0100
[2025-05-05 12:59:34,467][train][INFO] - Epoch 9/100, Val Acc=0.5036, Val Loss=1.9350, lr=0.0100
[2025-05-05 12:59:35,060][train][INFO] - Epoch 8/100, Val Acc=0.5950, Val Loss=1.6438, lr=0.0100
[2025-05-05 12:59:37,662][train][INFO] - Epoch 9/100, Val Acc=0.5766, Val Loss=1.6506, lr=0.0100
[2025-05-05 12:59:41,971][train][INFO] - Epoch 10/100, Val Acc=0.5359, Val Loss=1.7538, lr=0.0100
[2025-05-05 12:59:42,323][train][INFO] - Epoch 9/100, Val Acc=0.6101, Val Loss=1.5373, lr=0.0100
[2025-05-05 12:59:45,052][train][INFO] - Epoch 10/100, Val Acc=0.6010, Val Loss=1.5615, lr=0.0100
[2025-05-05 12:59:49,233][train][INFO] - Epoch 10/100, Val Acc=0.6084, Val Loss=1.5730, lr=0.0100
[2025-05-05 12:59:49,279][train][INFO] - Epoch 11/100, Val Acc=0.5591, Val Loss=1.6914, lr=0.0100
[2025-05-05 12:59:52,242][train][INFO] - Epoch 11/100, Val Acc=0.6089, Val Loss=1.5011, lr=0.0100
[2025-05-05 12:59:56,745][train][INFO] - Epoch 11/100, Val Acc=0.6368, Val Loss=1.4474, lr=0.0100
[2025-05-05 12:59:57,026][train][INFO] - Epoch 12/100, Val Acc=0.5534, Val Loss=1.6936, lr=0.0100
[2025-05-05 13:00:00,347][train][INFO] - Epoch 12/100, Val Acc=0.5922, Val Loss=1.6466, lr=0.0100
[2025-05-05 13:00:04,469][train][INFO] - Epoch 12/100, Val Acc=0.6155, Val Loss=1.5780, lr=0.0100
[2025-05-05 13:00:04,651][train][INFO] - Epoch 13/100, Val Acc=0.5422, Val Loss=1.7611, lr=0.0100
[2025-05-05 13:00:07,880][train][INFO] - Epoch 13/100, Val Acc=0.6036, Val Loss=1.5865, lr=0.0100
[2025-05-05 13:00:11,666][train][INFO] - Epoch 13/100, Val Acc=0.6244, Val Loss=1.5574, lr=0.0100
[2025-05-05 13:00:12,273][train][INFO] - Epoch 14/100, Val Acc=0.5712, Val Loss=1.6550, lr=0.0100
[2025-05-05 13:00:15,176][train][INFO] - Epoch 14/100, Val Acc=0.6130, Val Loss=1.5642, lr=0.0100
[2025-05-05 13:00:19,385][train][INFO] - Epoch 14/100, Val Acc=0.6376, Val Loss=1.4839, lr=0.0100
[2025-05-05 13:00:20,131][train][INFO] - Epoch 15/100, Val Acc=0.5647, Val Loss=1.6498, lr=0.0100
[2025-05-05 13:00:22,752][train][INFO] - Epoch 15/100, Val Acc=0.6110, Val Loss=1.5924, lr=0.0100
[2025-05-05 13:00:27,185][train][INFO] - Epoch 15/100, Val Acc=0.6270, Val Loss=1.5513, lr=0.0100
[2025-05-05 13:00:27,337][train][INFO] - Epoch 16/100, Val Acc=0.5761, Val Loss=1.6378, lr=0.0100
[2025-05-05 13:00:29,996][train][INFO] - Epoch 16/100, Val Acc=0.5992, Val Loss=1.6565, lr=0.0100
[2025-05-05 13:00:34,605][train][INFO] - Epoch 16/100, Val Acc=0.6368, Val Loss=1.4887, lr=0.0100
[2025-05-05 13:00:34,731][train][INFO] - Epoch 17/100, Val Acc=0.5694, Val Loss=1.7246, lr=0.0100
[2025-05-05 13:00:37,410][train][INFO] - Epoch 17/100, Val Acc=0.6250, Val Loss=1.4985, lr=0.0100
[2025-05-05 13:00:41,384][train][INFO] - Epoch 17/100, Val Acc=0.6311, Val Loss=1.5867, lr=0.0100
[2025-05-05 13:00:42,104][train][INFO] - Epoch 18/100, Val Acc=0.5727, Val Loss=1.7548, lr=0.0100
[2025-05-05 13:00:44,677][train][INFO] - Epoch 18/100, Val Acc=0.6260, Val Loss=1.5538, lr=0.0100
[2025-05-05 13:00:49,019][train][INFO] - Epoch 18/100, Val Acc=0.6429, Val Loss=1.5122, lr=0.0100
[2025-05-05 13:00:49,464][train][INFO] - Epoch 19/100, Val Acc=0.5976, Val Loss=1.5499, lr=0.0100
[2025-05-05 13:00:51,973][train][INFO] - Epoch 19/100, Val Acc=0.6159, Val Loss=1.5863, lr=0.0100
[2025-05-05 13:00:56,629][train][INFO] - Epoch 19/100, Val Acc=0.6503, Val Loss=1.4388, lr=0.0100
[2025-05-05 13:00:56,945][train][INFO] - Epoch 20/100, Val Acc=0.5944, Val Loss=1.5749, lr=0.0100
[2025-05-05 13:00:59,606][train][INFO] - Epoch 20/100, Val Acc=0.6368, Val Loss=1.5093, lr=0.0100
[2025-05-05 13:01:03,988][train][INFO] - Epoch 21/100, Val Acc=0.6005, Val Loss=1.5581, lr=0.0100
[2025-05-05 13:01:04,266][train][INFO] - Epoch 20/100, Val Acc=0.6447, Val Loss=1.5121, lr=0.0100
[2025-05-05 13:01:07,432][train][INFO] - Epoch 21/100, Val Acc=0.6289, Val Loss=1.5634, lr=0.0100
[2025-05-05 13:01:11,712][train][INFO] - Epoch 22/100, Val Acc=0.5676, Val Loss=1.8065, lr=0.0100
[2025-05-05 13:01:11,976][train][INFO] - Epoch 21/100, Val Acc=0.6501, Val Loss=1.4567, lr=0.0100
[2025-05-05 13:01:14,695][train][INFO] - Epoch 22/100, Val Acc=0.6387, Val Loss=1.5073, lr=0.0100
[2025-05-05 13:01:19,059][train][INFO] - Epoch 22/100, Val Acc=0.6182, Val Loss=1.6556, lr=0.0100
[2025-05-05 13:01:19,084][train][INFO] - Epoch 23/100, Val Acc=0.6143, Val Loss=1.4916, lr=0.0100
[2025-05-05 13:01:22,243][train][INFO] - Epoch 23/100, Val Acc=0.6111, Val Loss=1.6496, lr=0.0100
[2025-05-05 13:01:26,567][train][INFO] - Epoch 23/100, Val Acc=0.6429, Val Loss=1.5438, lr=0.0100
[2025-05-05 13:01:26,582][train][INFO] - Epoch 24/100, Val Acc=0.6160, Val Loss=1.5620, lr=0.0100
[2025-05-05 13:01:29,584][train][INFO] - Epoch 24/100, Val Acc=0.6215, Val Loss=1.6173, lr=0.0100
[2025-05-05 13:01:33,891][train][INFO] - Epoch 24/100, Val Acc=0.6590, Val Loss=1.4446, lr=0.0100
[2025-05-05 13:01:34,348][train][INFO] - Epoch 25/100, Val Acc=0.6039, Val Loss=1.6388, lr=0.0100
[2025-05-05 13:01:37,352][train][INFO] - Epoch 25/100, Val Acc=0.6293, Val Loss=1.5588, lr=0.0100
[2025-05-05 13:01:40,655][train][INFO] - Epoch 25/100, Val Acc=0.6476, Val Loss=1.4919, lr=0.0100
[2025-05-05 13:01:41,473][train][INFO] - Epoch 26/100, Val Acc=0.6033, Val Loss=1.6363, lr=0.0100
[2025-05-05 13:01:44,847][train][INFO] - Epoch 26/100, Val Acc=0.6272, Val Loss=1.6077, lr=0.0100
[2025-05-05 13:01:47,609][train][INFO] - Epoch 26/100, Val Acc=0.6420, Val Loss=1.5597, lr=0.0100
[2025-05-05 13:01:48,923][train][INFO] - Epoch 27/100, Val Acc=0.5934, Val Loss=1.7445, lr=0.0100
[2025-05-05 13:01:51,838][train][INFO] - Epoch 27/100, Val Acc=0.6273, Val Loss=1.6279, lr=0.0100
[2025-05-05 13:01:54,720][train][INFO] - Epoch 27/100, Val Acc=0.6429, Val Loss=1.5432, lr=0.0100
[2025-05-05 13:01:55,997][train][INFO] - Epoch 28/100, Val Acc=0.6271, Val Loss=1.5145, lr=0.0100
[2025-05-05 13:01:59,305][train][INFO] - Epoch 28/100, Val Acc=0.6327, Val Loss=1.6055, lr=0.0100
[2025-05-05 13:02:02,095][train][INFO] - Epoch 28/100, Val Acc=0.6444, Val Loss=1.5682, lr=0.0100
[2025-05-05 13:02:03,590][train][INFO] - Epoch 29/100, Val Acc=0.5993, Val Loss=1.7208, lr=0.0100
[2025-05-05 13:02:06,972][train][INFO] - Epoch 29/100, Val Acc=0.6412, Val Loss=1.5198, lr=0.0100
[2025-05-05 13:02:09,747][train][INFO] - Epoch 29/100, Val Acc=0.6394, Val Loss=1.5485, lr=0.0100
[2025-05-05 13:02:10,953][train][INFO] - Epoch 30/100, Val Acc=0.6072, Val Loss=1.6033, lr=0.0100
[2025-05-05 13:02:14,528][train][INFO] - Epoch 30/100, Val Acc=0.6466, Val Loss=1.5375, lr=0.0100
[2025-05-05 13:02:17,134][train][INFO] - Epoch 30/100, Val Acc=0.6397, Val Loss=1.5599, lr=0.0100
[2025-05-05 13:02:18,544][train][INFO] - Epoch 31/100, Val Acc=0.6156, Val Loss=1.5919, lr=0.0100
[2025-05-05 13:02:21,592][train][INFO] - Epoch 31/100, Val Acc=0.6327, Val Loss=1.6095, lr=0.0100
[2025-05-05 13:02:24,769][train][INFO] - Epoch 31/100, Val Acc=0.6432, Val Loss=1.5711, lr=0.0100
[2025-05-05 13:02:26,280][train][INFO] - Epoch 32/100, Val Acc=0.6165, Val Loss=1.5961, lr=0.0100
[2025-05-05 13:02:29,134][train][INFO] - Epoch 32/100, Val Acc=0.6433, Val Loss=1.5484, lr=0.0100
[2025-05-05 13:02:32,238][train][INFO] - Epoch 32/100, Val Acc=0.6553, Val Loss=1.5149, lr=0.0100
[2025-05-05 13:02:33,921][train][INFO] - Epoch 33/100, Val Acc=0.6277, Val Loss=1.5790, lr=0.0100
[2025-05-05 13:02:36,911][train][INFO] - Epoch 33/100, Val Acc=0.6306, Val Loss=1.6068, lr=0.0100
[2025-05-05 13:02:39,932][train][INFO] - Epoch 33/100, Val Acc=0.6464, Val Loss=1.5382, lr=0.0100
[2025-05-05 13:02:41,410][train][INFO] - Epoch 34/100, Val Acc=0.6255, Val Loss=1.5593, lr=0.0100
[2025-05-05 13:02:44,501][train][INFO] - Epoch 34/100, Val Acc=0.6425, Val Loss=1.5678, lr=0.0100
[2025-05-05 13:02:47,727][train][INFO] - Epoch 34/100, Val Acc=0.6416, Val Loss=1.5724, lr=0.0100
[2025-05-05 13:02:49,031][train][INFO] - Epoch 35/100, Val Acc=0.6246, Val Loss=1.6329, lr=0.0100
[2025-05-05 13:02:51,971][train][INFO] - Epoch 35/100, Val Acc=0.6394, Val Loss=1.5941, lr=0.0100
[2025-05-05 13:02:55,215][train][INFO] - Epoch 35/100, Val Acc=0.6436, Val Loss=1.5976, lr=0.0100
[2025-05-05 13:02:56,540][train][INFO] - Epoch 36/100, Val Acc=0.6115, Val Loss=1.6608, lr=0.0100
[2025-05-05 13:02:59,359][train][INFO] - Epoch 36/100, Val Acc=0.6303, Val Loss=1.6240, lr=0.0100
[2025-05-05 13:03:02,205][train][INFO] - Epoch 36/100, Val Acc=0.6483, Val Loss=1.5729, lr=0.0100
[2025-05-05 13:03:03,938][train][INFO] - Epoch 37/100, Val Acc=0.6124, Val Loss=1.6762, lr=0.0100
[2025-05-05 13:03:06,931][train][INFO] - Epoch 37/100, Val Acc=0.6348, Val Loss=1.6449, lr=0.0100
[2025-05-05 13:03:09,186][train][INFO] - Epoch 37/100, Val Acc=0.6545, Val Loss=1.5314, lr=0.0100
[2025-05-05 13:03:11,104][train][INFO] - Epoch 38/100, Val Acc=0.6327, Val Loss=1.5198, lr=0.0100
[2025-05-05 13:03:14,412][train][INFO] - Epoch 38/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-05 13:03:16,479][train][INFO] - Epoch 38/100, Val Acc=0.6297, Val Loss=1.7314, lr=0.0100
[2025-05-05 13:03:18,716][train][INFO] - Epoch 39/100, Val Acc=0.6176, Val Loss=1.6937, lr=0.0100
[2025-05-05 13:03:21,850][train][INFO] - Epoch 39/100, Val Acc=0.6420, Val Loss=1.6029, lr=0.0100
[2025-05-05 13:03:23,653][train][INFO] - Epoch 39/100, Val Acc=0.6464, Val Loss=1.6116, lr=0.0100
[2025-05-05 13:03:26,213][train][INFO] - Epoch 40/100, Val Acc=0.6135, Val Loss=1.6814, lr=0.0100
[2025-05-05 13:03:29,554][train][INFO] - Epoch 40/100, Val Acc=0.6386, Val Loss=1.6069, lr=0.0100
[2025-05-05 13:03:31,396][train][INFO] - Epoch 40/100, Val Acc=0.6559, Val Loss=1.5331, lr=0.0100
[2025-05-05 13:03:33,956][train][INFO] - Epoch 41/100, Val Acc=0.6220, Val Loss=1.6187, lr=0.0100
[2025-05-05 13:03:36,852][train][INFO] - Epoch 41/100, Val Acc=0.6439, Val Loss=1.6088, lr=0.0100
[2025-05-05 13:03:38,937][train][INFO] - Epoch 41/100, Val Acc=0.6492, Val Loss=1.5879, lr=0.0100
[2025-05-05 13:03:41,624][train][INFO] - Epoch 42/100, Val Acc=0.6233, Val Loss=1.6436, lr=0.0100
[2025-05-05 13:03:44,635][train][INFO] - Epoch 42/100, Val Acc=0.6219, Val Loss=1.6998, lr=0.0100
[2025-05-05 13:03:46,005][train][INFO] - Epoch 42/100, Val Acc=0.6482, Val Loss=1.6061, lr=0.0100
[2025-05-05 13:03:49,006][train][INFO] - Epoch 43/100, Val Acc=0.6127, Val Loss=1.6797, lr=0.0100
[2025-05-05 13:03:52,068][train][INFO] - Epoch 43/100, Val Acc=0.6423, Val Loss=1.6399, lr=0.0100
[2025-05-05 13:03:52,940][train][INFO] - Epoch 43/100, Val Acc=0.6402, Val Loss=1.6533, lr=0.0100
[2025-05-05 13:03:56,771][train][INFO] - Epoch 44/100, Val Acc=0.6217, Val Loss=1.6428, lr=0.0100
[2025-05-05 13:03:59,160][train][INFO] - Epoch 44/100, Val Acc=0.6280, Val Loss=1.6860, lr=0.0100
[2025-05-05 13:03:59,950][train][INFO] - Epoch 44/100, Val Acc=0.6341, Val Loss=1.7037, lr=0.0100
[2025-05-05 13:04:04,491][train][INFO] - Epoch 45/100, Val Acc=0.6198, Val Loss=1.6318, lr=0.0100
[2025-05-05 13:04:06,948][train][INFO] - Epoch 45/100, Val Acc=0.6340, Val Loss=1.6459, lr=0.0100
[2025-05-05 13:04:07,184][train][INFO] - Epoch 45/100, Val Acc=0.6469, Val Loss=1.5789, lr=0.0100
[2025-05-05 13:04:11,935][train][INFO] - Epoch 46/100, Val Acc=0.6274, Val Loss=1.6337, lr=0.0100
[2025-05-05 13:04:14,609][train][INFO] - Epoch 46/100, Val Acc=0.6413, Val Loss=1.6074, lr=0.0100
[2025-05-05 13:04:15,054][train][INFO] - Epoch 46/100, Val Acc=0.6390, Val Loss=1.7001, lr=0.0100
[2025-05-05 13:04:19,390][train][INFO] - Epoch 47/100, Val Acc=0.6168, Val Loss=1.6955, lr=0.0100
[2025-05-05 13:04:22,005][train][INFO] - Epoch 47/100, Val Acc=0.6336, Val Loss=1.6733, lr=0.0100
[2025-05-05 13:04:22,349][train][INFO] - Epoch 47/100, Val Acc=0.6412, Val Loss=1.6508, lr=0.0100
[2025-05-05 13:04:27,152][train][INFO] - Epoch 48/100, Val Acc=0.6334, Val Loss=1.5860, lr=0.0100
[2025-05-05 13:04:29,641][train][INFO] - Epoch 48/100, Val Acc=0.6526, Val Loss=1.5607, lr=0.0100
[2025-05-05 13:04:29,737][train][INFO] - Epoch 48/100, Val Acc=0.6446, Val Loss=1.5907, lr=0.0100
[2025-05-05 13:04:34,547][train][INFO] - Epoch 49/100, Val Acc=0.6294, Val Loss=1.6062, lr=0.0100
[2025-05-05 13:04:37,107][train][INFO] - Epoch 49/100, Val Acc=0.6560, Val Loss=1.5794, lr=0.0100
[2025-05-05 13:04:37,495][train][INFO] - Epoch 49/100, Val Acc=0.6470, Val Loss=1.5903, lr=0.0100
[2025-05-05 13:04:42,081][train][INFO] - Epoch 50/100, Val Acc=0.6342, Val Loss=1.5930, lr=0.0100
[2025-05-05 13:04:44,487][train][INFO] - Epoch 50/100, Val Acc=0.6469, Val Loss=1.6455, lr=0.0100
[2025-05-05 13:04:44,949][train][INFO] - Epoch 50/100, Val Acc=0.6465, Val Loss=1.5903, lr=0.0100
[2025-05-05 13:04:49,204][train][INFO] - Epoch 51/100, Val Acc=0.6248, Val Loss=1.6625, lr=0.0100
[2025-05-05 13:04:51,940][train][INFO] - Epoch 51/100, Val Acc=0.6387, Val Loss=1.6781, lr=0.0100
[2025-05-05 13:04:52,691][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6533, lr=0.0100
[2025-05-05 13:04:57,005][train][INFO] - Epoch 52/100, Val Acc=0.6223, Val Loss=1.6883, lr=0.0100
[2025-05-05 13:04:59,460][train][INFO] - Epoch 52/100, Val Acc=0.6422, Val Loss=1.6613, lr=0.0100
[2025-05-05 13:04:59,914][train][INFO] - Epoch 52/100, Val Acc=0.6307, Val Loss=1.6962, lr=0.0100
[2025-05-05 13:05:04,684][train][INFO] - Epoch 53/100, Val Acc=0.6350, Val Loss=1.6011, lr=0.0100
[2025-05-05 13:05:07,100][train][INFO] - Epoch 53/100, Val Acc=0.6386, Val Loss=1.6429, lr=0.0100
[2025-05-05 13:05:07,281][train][INFO] - Epoch 53/100, Val Acc=0.6374, Val Loss=1.6606, lr=0.0100
[2025-05-05 13:05:12,011][train][INFO] - Epoch 54/100, Val Acc=0.6203, Val Loss=1.7305, lr=0.0100
[2025-05-05 13:05:14,879][train][INFO] - Epoch 54/100, Val Acc=0.6437, Val Loss=1.6218, lr=0.0100
[2025-05-05 13:05:15,089][train][INFO] - Epoch 54/100, Val Acc=0.6352, Val Loss=1.6768, lr=0.0100
[2025-05-05 13:05:19,544][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6972, lr=0.0100
[2025-05-05 13:05:21,969][train][INFO] - Epoch 55/100, Val Acc=0.6420, Val Loss=1.6428, lr=0.0100
[2025-05-05 13:05:22,212][train][INFO] - Epoch 55/100, Val Acc=0.6336, Val Loss=1.7275, lr=0.0100
[2025-05-05 13:05:27,263][train][INFO] - Epoch 56/100, Val Acc=0.6283, Val Loss=1.6679, lr=0.0100
[2025-05-05 13:05:29,193][train][INFO] - Epoch 56/100, Val Acc=0.6469, Val Loss=1.6637, lr=0.0100
[2025-05-05 13:05:29,873][train][INFO] - Epoch 56/100, Val Acc=0.6301, Val Loss=1.6911, lr=0.0100
[2025-05-05 13:05:34,888][train][INFO] - Epoch 57/100, Val Acc=0.6189, Val Loss=1.7435, lr=0.0100
[2025-05-05 13:05:36,451][train][INFO] - Epoch 57/100, Val Acc=0.6391, Val Loss=1.6646, lr=0.0100
[2025-05-05 13:05:37,611][train][INFO] - Epoch 57/100, Val Acc=0.6364, Val Loss=1.7036, lr=0.0100
[2025-05-05 13:05:42,392][train][INFO] - Epoch 58/100, Val Acc=0.6154, Val Loss=1.7788, lr=0.0100
[2025-05-05 13:05:44,072][train][INFO] - Epoch 58/100, Val Acc=0.6600, Val Loss=1.6111, lr=0.0100
[2025-05-05 13:05:45,264][train][INFO] - Epoch 58/100, Val Acc=0.6195, Val Loss=1.7899, lr=0.0100
[2025-05-05 13:05:49,543][train][INFO] - Epoch 59/100, Val Acc=0.6274, Val Loss=1.6840, lr=0.0100
[2025-05-05 13:05:51,507][train][INFO] - Epoch 59/100, Val Acc=0.6454, Val Loss=1.6256, lr=0.0100
[2025-05-05 13:05:52,457][train][INFO] - Epoch 59/100, Val Acc=0.6369, Val Loss=1.6542, lr=0.0100
[2025-05-05 13:05:56,796][train][INFO] - Epoch 60/100, Val Acc=0.6355, Val Loss=1.6562, lr=0.0100
[2025-05-05 13:05:58,909][train][INFO] - Epoch 60/100, Val Acc=0.6594, Val Loss=1.5858, lr=0.0100
[2025-05-05 13:06:00,199][train][INFO] - Epoch 60/100, Val Acc=0.6361, Val Loss=1.7176, lr=0.0100
[2025-05-05 13:06:03,839][train][INFO] - Epoch 61/100, Val Acc=0.6910, Val Loss=1.3330, lr=0.0010
[2025-05-05 13:06:06,423][train][INFO] - Epoch 61/100, Val Acc=0.7068, Val Loss=1.3268, lr=0.0010
[2025-05-05 13:06:07,867][train][INFO] - Epoch 61/100, Val Acc=0.7002, Val Loss=1.3470, lr=0.0010
[2025-05-05 13:06:11,023][train][INFO] - Epoch 62/100, Val Acc=0.6990, Val Loss=1.3231, lr=0.0010
[2025-05-05 13:06:14,093][train][INFO] - Epoch 62/100, Val Acc=0.7087, Val Loss=1.3174, lr=0.0010
[2025-05-05 13:06:15,535][train][INFO] - Epoch 62/100, Val Acc=0.7021, Val Loss=1.3435, lr=0.0010
[2025-05-05 13:06:18,647][train][INFO] - Epoch 63/100, Val Acc=0.6973, Val Loss=1.3335, lr=0.0010
[2025-05-05 13:06:21,138][train][INFO] - Epoch 63/100, Val Acc=0.7128, Val Loss=1.3294, lr=0.0010
[2025-05-05 13:06:22,674][train][INFO] - Epoch 63/100, Val Acc=0.7037, Val Loss=1.3430, lr=0.0010
[2025-05-05 13:06:25,953][train][INFO] - Epoch 64/100, Val Acc=0.6975, Val Loss=1.3458, lr=0.0010
[2025-05-05 13:06:27,966][train][INFO] - Epoch 64/100, Val Acc=0.7140, Val Loss=1.3416, lr=0.0010
[2025-05-05 13:06:29,949][train][INFO] - Epoch 64/100, Val Acc=0.7071, Val Loss=1.3501, lr=0.0010
[2025-05-05 13:06:33,226][train][INFO] - Epoch 65/100, Val Acc=0.6985, Val Loss=1.3463, lr=0.0010
[2025-05-05 13:06:35,839][train][INFO] - Epoch 65/100, Val Acc=0.7142, Val Loss=1.3431, lr=0.0010
[2025-05-05 13:06:37,304][train][INFO] - Epoch 65/100, Val Acc=0.7069, Val Loss=1.3532, lr=0.0010
[2025-05-05 13:06:40,859][train][INFO] - Epoch 66/100, Val Acc=0.6999, Val Loss=1.3541, lr=0.0010
[2025-05-05 13:06:43,176][train][INFO] - Epoch 66/100, Val Acc=0.7149, Val Loss=1.3516, lr=0.0010
[2025-05-05 13:06:44,923][train][INFO] - Epoch 66/100, Val Acc=0.7082, Val Loss=1.3601, lr=0.0010
[2025-05-05 13:06:48,174][train][INFO] - Epoch 67/100, Val Acc=0.6979, Val Loss=1.3657, lr=0.0010
[2025-05-05 13:06:50,840][train][INFO] - Epoch 67/100, Val Acc=0.7155, Val Loss=1.3565, lr=0.0010
[2025-05-05 13:06:52,610][train][INFO] - Epoch 67/100, Val Acc=0.7085, Val Loss=1.3621, lr=0.0010
[2025-05-05 13:06:55,636][train][INFO] - Epoch 68/100, Val Acc=0.7009, Val Loss=1.3705, lr=0.0010
[2025-05-05 13:06:58,726][train][INFO] - Epoch 68/100, Val Acc=0.7154, Val Loss=1.3594, lr=0.0010
[2025-05-05 13:06:59,377][train][INFO] - Epoch 68/100, Val Acc=0.7095, Val Loss=1.3662, lr=0.0010
[2025-05-05 13:07:02,731][train][INFO] - Epoch 69/100, Val Acc=0.7004, Val Loss=1.3642, lr=0.0010
[2025-05-05 13:07:05,959][train][INFO] - Epoch 69/100, Val Acc=0.7164, Val Loss=1.3684, lr=0.0010
[2025-05-05 13:07:06,864][train][INFO] - Epoch 69/100, Val Acc=0.7081, Val Loss=1.3731, lr=0.0010
[2025-05-05 13:07:10,055][train][INFO] - Epoch 70/100, Val Acc=0.7035, Val Loss=1.3745, lr=0.0010
[2025-05-05 13:07:13,448][train][INFO] - Epoch 70/100, Val Acc=0.7155, Val Loss=1.3682, lr=0.0010
[2025-05-05 13:07:14,212][train][INFO] - Epoch 70/100, Val Acc=0.7091, Val Loss=1.3775, lr=0.0010
[2025-05-05 13:07:17,757][train][INFO] - Epoch 71/100, Val Acc=0.7007, Val Loss=1.3815, lr=0.0010
[2025-05-05 13:07:20,774][train][INFO] - Epoch 71/100, Val Acc=0.7160, Val Loss=1.3635, lr=0.0010
[2025-05-05 13:07:21,541][train][INFO] - Epoch 71/100, Val Acc=0.7114, Val Loss=1.3812, lr=0.0010
[2025-05-05 13:07:25,578][train][INFO] - Epoch 72/100, Val Acc=0.7001, Val Loss=1.3885, lr=0.0010
[2025-05-05 13:07:28,481][train][INFO] - Epoch 72/100, Val Acc=0.7162, Val Loss=1.3717, lr=0.0010
[2025-05-05 13:07:29,537][train][INFO] - Epoch 72/100, Val Acc=0.7103, Val Loss=1.3815, lr=0.0010
[2025-05-05 13:07:33,309][train][INFO] - Epoch 73/100, Val Acc=0.7047, Val Loss=1.3850, lr=0.0010
[2025-05-05 13:07:35,907][train][INFO] - Epoch 73/100, Val Acc=0.7153, Val Loss=1.3632, lr=0.0010
[2025-05-05 13:07:36,943][train][INFO] - Epoch 73/100, Val Acc=0.7094, Val Loss=1.3795, lr=0.0010
[2025-05-05 13:07:40,765][train][INFO] - Epoch 74/100, Val Acc=0.7036, Val Loss=1.3889, lr=0.0010
[2025-05-05 13:07:43,571][train][INFO] - Epoch 74/100, Val Acc=0.7159, Val Loss=1.3698, lr=0.0010
[2025-05-05 13:07:44,651][train][INFO] - Epoch 74/100, Val Acc=0.7107, Val Loss=1.3922, lr=0.0010
[2025-05-05 13:07:48,246][train][INFO] - Epoch 75/100, Val Acc=0.7062, Val Loss=1.3951, lr=0.0010
[2025-05-05 13:07:51,348][train][INFO] - Epoch 75/100, Val Acc=0.7170, Val Loss=1.3705, lr=0.0010
[2025-05-05 13:07:52,413][train][INFO] - Epoch 75/100, Val Acc=0.7100, Val Loss=1.3973, lr=0.0010
[2025-05-05 13:07:56,163][train][INFO] - Epoch 76/100, Val Acc=0.7040, Val Loss=1.4001, lr=0.0010
[2025-05-05 13:07:59,176][train][INFO] - Epoch 76/100, Val Acc=0.7181, Val Loss=1.3755, lr=0.0010
[2025-05-05 13:07:59,985][train][INFO] - Epoch 76/100, Val Acc=0.7114, Val Loss=1.3910, lr=0.0010
[2025-05-05 13:08:03,737][train][INFO] - Epoch 77/100, Val Acc=0.7059, Val Loss=1.4042, lr=0.0010
[2025-05-05 13:08:06,990][train][INFO] - Epoch 77/100, Val Acc=0.7160, Val Loss=1.3734, lr=0.0010
[2025-05-05 13:08:07,442][train][INFO] - Epoch 77/100, Val Acc=0.7121, Val Loss=1.3958, lr=0.0010
[2025-05-05 13:08:11,056][train][INFO] - Epoch 78/100, Val Acc=0.6997, Val Loss=1.4160, lr=0.0010
[2025-05-05 13:08:14,566][train][INFO] - Epoch 78/100, Val Acc=0.7125, Val Loss=1.3950, lr=0.0010
[2025-05-05 13:08:14,770][train][INFO] - Epoch 78/100, Val Acc=0.7201, Val Loss=1.3776, lr=0.0010
[2025-05-05 13:08:18,523][train][INFO] - Epoch 79/100, Val Acc=0.7011, Val Loss=1.4245, lr=0.0010
[2025-05-05 13:08:21,806][train][INFO] - Epoch 79/100, Val Acc=0.7193, Val Loss=1.3850, lr=0.0010
[2025-05-05 13:08:22,241][train][INFO] - Epoch 79/100, Val Acc=0.7122, Val Loss=1.3974, lr=0.0010
[2025-05-05 13:08:25,897][train][INFO] - Epoch 80/100, Val Acc=0.7013, Val Loss=1.4228, lr=0.0010
[2025-05-05 13:08:29,210][train][INFO] - Epoch 80/100, Val Acc=0.7176, Val Loss=1.3808, lr=0.0010
[2025-05-05 13:08:29,832][train][INFO] - Epoch 80/100, Val Acc=0.7105, Val Loss=1.4005, lr=0.0010
[2025-05-05 13:08:33,149][train][INFO] - Epoch 81/100, Val Acc=0.7028, Val Loss=1.4262, lr=0.0010
[2025-05-05 13:08:36,674][train][INFO] - Epoch 81/100, Val Acc=0.7184, Val Loss=1.3891, lr=0.0010
[2025-05-05 13:08:37,476][train][INFO] - Epoch 81/100, Val Acc=0.7136, Val Loss=1.4006, lr=0.0010
[2025-05-05 13:08:40,936][train][INFO] - Epoch 82/100, Val Acc=0.7023, Val Loss=1.4333, lr=0.0010
[2025-05-05 13:08:44,039][train][INFO] - Epoch 82/100, Val Acc=0.7183, Val Loss=1.3941, lr=0.0010
[2025-05-05 13:08:45,216][train][INFO] - Epoch 82/100, Val Acc=0.7123, Val Loss=1.4073, lr=0.0010
[2025-05-05 13:08:48,877][train][INFO] - Epoch 83/100, Val Acc=0.7021, Val Loss=1.4370, lr=0.0010
[2025-05-05 13:08:51,429][train][INFO] - Epoch 83/100, Val Acc=0.7191, Val Loss=1.3921, lr=0.0010
[2025-05-05 13:08:52,684][train][INFO] - Epoch 83/100, Val Acc=0.7109, Val Loss=1.4145, lr=0.0010
[2025-05-05 13:08:56,925][train][INFO] - Epoch 84/100, Val Acc=0.7019, Val Loss=1.4373, lr=0.0010
[2025-05-05 13:08:59,288][train][INFO] - Epoch 84/100, Val Acc=0.7195, Val Loss=1.3931, lr=0.0010
[2025-05-05 13:09:00,764][train][INFO] - Epoch 84/100, Val Acc=0.7107, Val Loss=1.4185, lr=0.0010
[2025-05-05 13:09:04,791][train][INFO] - Epoch 85/100, Val Acc=0.7025, Val Loss=1.4495, lr=0.0010
[2025-05-05 13:09:06,659][train][INFO] - Epoch 85/100, Val Acc=0.7186, Val Loss=1.3925, lr=0.0010
[2025-05-05 13:09:08,638][train][INFO] - Epoch 85/100, Val Acc=0.7107, Val Loss=1.4082, lr=0.0010
[2025-05-05 13:09:12,426][train][INFO] - Epoch 86/100, Val Acc=0.7018, Val Loss=1.4454, lr=0.0010
[2025-05-05 13:09:13,918][train][INFO] - Epoch 86/100, Val Acc=0.7162, Val Loss=1.3899, lr=0.0010
[2025-05-05 13:09:15,959][train][INFO] - Epoch 86/100, Val Acc=0.7129, Val Loss=1.4149, lr=0.0010
[2025-05-05 13:09:20,472][train][INFO] - Epoch 87/100, Val Acc=0.7030, Val Loss=1.4425, lr=0.0010
[2025-05-05 13:09:21,466][train][INFO] - Epoch 87/100, Val Acc=0.7218, Val Loss=1.3910, lr=0.0010
[2025-05-05 13:09:23,400][train][INFO] - Epoch 87/100, Val Acc=0.7138, Val Loss=1.4129, lr=0.0010
[2025-05-05 13:09:27,690][train][INFO] - Epoch 88/100, Val Acc=0.7014, Val Loss=1.4433, lr=0.0010
[2025-05-05 13:09:28,742][train][INFO] - Epoch 88/100, Val Acc=0.7193, Val Loss=1.3921, lr=0.0010
[2025-05-05 13:09:30,711][train][INFO] - Epoch 88/100, Val Acc=0.7119, Val Loss=1.4126, lr=0.0010
[2025-05-05 13:09:35,658][train][INFO] - Epoch 89/100, Val Acc=0.7008, Val Loss=1.4569, lr=0.0010
[2025-05-05 13:09:36,186][train][INFO] - Epoch 89/100, Val Acc=0.7191, Val Loss=1.3985, lr=0.0010
[2025-05-05 13:09:38,401][train][INFO] - Epoch 89/100, Val Acc=0.7099, Val Loss=1.4180, lr=0.0010
[2025-05-05 13:09:42,974][train][INFO] - Epoch 90/100, Val Acc=0.7024, Val Loss=1.4636, lr=0.0010
[2025-05-05 13:09:44,008][train][INFO] - Epoch 90/100, Val Acc=0.7197, Val Loss=1.3965, lr=0.0010
[2025-05-05 13:09:45,623][train][INFO] - Epoch 90/100, Val Acc=0.7139, Val Loss=1.4194, lr=0.0010
[2025-05-05 13:09:50,956][train][INFO] - Epoch 91/100, Val Acc=0.7022, Val Loss=1.4532, lr=0.0001
[2025-05-05 13:09:51,294][train][INFO] - Epoch 91/100, Val Acc=0.7194, Val Loss=1.3901, lr=0.0001
[2025-05-05 13:09:53,328][train][INFO] - Epoch 91/100, Val Acc=0.7134, Val Loss=1.4145, lr=0.0001
[2025-05-05 13:09:58,042][train][INFO] - Epoch 92/100, Val Acc=0.7182, Val Loss=1.3956, lr=0.0001
[2025-05-05 13:09:58,343][train][INFO] - Epoch 92/100, Val Acc=0.7027, Val Loss=1.4558, lr=0.0001
[2025-05-05 13:10:01,103][train][INFO] - Epoch 92/100, Val Acc=0.7120, Val Loss=1.4193, lr=0.0001
[2025-05-05 13:10:05,626][train][INFO] - Epoch 93/100, Val Acc=0.7192, Val Loss=1.3929, lr=0.0001
[2025-05-05 13:10:05,783][train][INFO] - Epoch 93/100, Val Acc=0.7037, Val Loss=1.4555, lr=0.0001
[2025-05-05 13:10:08,839][train][INFO] - Epoch 93/100, Val Acc=0.7129, Val Loss=1.4172, lr=0.0001
[2025-05-05 13:10:12,829][train][INFO] - Epoch 94/100, Val Acc=0.7210, Val Loss=1.3907, lr=0.0001
[2025-05-05 13:10:13,109][train][INFO] - Epoch 94/100, Val Acc=0.7021, Val Loss=1.4520, lr=0.0001
[2025-05-05 13:10:16,159][train][INFO] - Epoch 94/100, Val Acc=0.7127, Val Loss=1.4138, lr=0.0001
[2025-05-05 13:10:20,303][train][INFO] - Epoch 95/100, Val Acc=0.7213, Val Loss=1.3924, lr=0.0001
[2025-05-05 13:10:20,569][train][INFO] - Epoch 95/100, Val Acc=0.7025, Val Loss=1.4524, lr=0.0001
[2025-05-05 13:10:23,575][train][INFO] - Epoch 95/100, Val Acc=0.7138, Val Loss=1.4145, lr=0.0001
[2025-05-05 13:10:28,085][train][INFO] - Epoch 96/100, Val Acc=0.7208, Val Loss=1.3905, lr=0.0001
[2025-05-05 13:10:28,414][train][INFO] - Epoch 96/100, Val Acc=0.7033, Val Loss=1.4493, lr=0.0001
[2025-05-05 13:10:30,712][train][INFO] - Epoch 96/100, Val Acc=0.7140, Val Loss=1.4123, lr=0.0001
[2025-05-05 13:10:35,034][train][INFO] - Epoch 97/100, Val Acc=0.7216, Val Loss=1.3928, lr=0.0001
[2025-05-05 13:10:36,087][train][INFO] - Epoch 97/100, Val Acc=0.7040, Val Loss=1.4533, lr=0.0001
[2025-05-05 13:10:38,081][train][INFO] - Epoch 97/100, Val Acc=0.7119, Val Loss=1.4211, lr=0.0001
[2025-05-05 13:10:42,601][train][INFO] - Epoch 98/100, Val Acc=0.7223, Val Loss=1.3880, lr=0.0001
[2025-05-05 13:10:43,172][train][INFO] - Epoch 98/100, Val Acc=0.7036, Val Loss=1.4457, lr=0.0001
[2025-05-05 13:10:45,839][train][INFO] - Epoch 98/100, Val Acc=0.7124, Val Loss=1.4139, lr=0.0001
[2025-05-05 13:10:49,932][train][INFO] - Epoch 99/100, Val Acc=0.7203, Val Loss=1.3955, lr=0.0001
[2025-05-05 13:10:50,898][train][INFO] - Epoch 99/100, Val Acc=0.7048, Val Loss=1.4540, lr=0.0001
[2025-05-05 13:10:52,828][train][INFO] - Epoch 99/100, Val Acc=0.7122, Val Loss=1.4213, lr=0.0001
[2025-05-05 13:10:57,412][train][INFO] - Epoch 100/100, Val Acc=0.7207, Val Loss=1.3929, lr=0.0001
[2025-05-05 13:10:58,517][train][INFO] - Epoch 100/100, Val Acc=0.7033, Val Loss=1.4512, lr=0.0001
[2025-05-05 13:10:59,927][train][INFO] - Epoch 100/100, Val Acc=0.7130, Val Loss=1.4135, lr=0.0001
[2025-05-05 13:11:02,659][train][INFO] - After training : Train Acc=0.9981  Val Acc=0.7223
[2025-05-05 13:11:03,703][train][INFO] - After training : Train Acc=0.9880  Val Acc=0.7062
[2025-05-05 13:11:05,052][train][INFO] - After training : Train Acc=0.9972  Val Acc=0.7140
[2025-05-05 13:11:09,395][Progressive pruning][INFO] - Train acc : 0.09417999535799026   Val acc : 0.07800000160932541
[2025-05-05 13:11:09,395][Progressive pruning][INFO] - Current speed up: 1.33
[2025-05-05 13:11:10,630][Progressive pruning][INFO] - Train acc : 0.9680599570274353   Val acc : 0.6784999966621399
[2025-05-05 13:11:10,630][Progressive pruning][INFO] - Current speed up: 1.33
[2025-05-05 13:11:12,041][Progressive pruning][INFO] - Train acc : 0.4582599997520447   Val acc : 0.33319997787475586
[2025-05-05 13:11:12,042][Progressive pruning][INFO] - Current speed up: 1.32
[2025-05-05 13:11:14,557][train][INFO] - Before training : Train Acc=0.0935  Val Acc=0.0780
[2025-05-05 13:11:15,756][train][INFO] - Before training : Train Acc=0.9682  Val Acc=0.6785
[2025-05-05 13:11:17,218][train][INFO] - Before training : Train Acc=0.4590  Val Acc=0.3332
[2025-05-05 13:11:22,127][train][INFO] - Epoch 1/140, Val Acc=0.5429, Val Loss=1.9561, lr=0.0100
[2025-05-05 13:11:23,558][train][INFO] - Epoch 1/140, Val Acc=0.6095, Val Loss=1.7961, lr=0.0100
[2025-05-05 13:11:24,908][train][INFO] - Epoch 1/140, Val Acc=0.5896, Val Loss=1.8988, lr=0.0100
[2025-05-05 13:11:30,220][train][INFO] - Epoch 2/140, Val Acc=0.5887, Val Loss=1.7901, lr=0.0100
[2025-05-05 13:11:31,415][train][INFO] - Epoch 2/140, Val Acc=0.6203, Val Loss=1.6995, lr=0.0100
[2025-05-05 13:11:32,503][train][INFO] - Epoch 2/140, Val Acc=0.6060, Val Loss=1.7889, lr=0.0100
[2025-05-05 13:11:37,734][train][INFO] - Epoch 3/140, Val Acc=0.5882, Val Loss=1.7977, lr=0.0100
[2025-05-05 13:11:38,594][train][INFO] - Epoch 3/140, Val Acc=0.6166, Val Loss=1.7139, lr=0.0100
[2025-05-05 13:11:39,541][train][INFO] - Epoch 3/140, Val Acc=0.6140, Val Loss=1.7094, lr=0.0100
[2025-05-05 13:11:44,977][train][INFO] - Epoch 4/140, Val Acc=0.5961, Val Loss=1.8226, lr=0.0100
[2025-05-05 13:11:46,396][train][INFO] - Epoch 4/140, Val Acc=0.6261, Val Loss=1.7285, lr=0.0100
[2025-05-05 13:11:46,932][train][INFO] - Epoch 4/140, Val Acc=0.6097, Val Loss=1.7647, lr=0.0100
[2025-05-05 13:11:52,360][train][INFO] - Epoch 5/140, Val Acc=0.6100, Val Loss=1.7319, lr=0.0100
[2025-05-05 13:11:54,129][train][INFO] - Epoch 5/140, Val Acc=0.6294, Val Loss=1.6785, lr=0.0100
[2025-05-05 13:11:54,410][train][INFO] - Epoch 5/140, Val Acc=0.6066, Val Loss=1.7571, lr=0.0100
[2025-05-05 13:11:59,514][train][INFO] - Epoch 6/140, Val Acc=0.6243, Val Loss=1.6347, lr=0.0100
[2025-05-05 13:12:01,638][train][INFO] - Epoch 6/140, Val Acc=0.6167, Val Loss=1.7130, lr=0.0100
[2025-05-05 13:12:01,915][train][INFO] - Epoch 6/140, Val Acc=0.6297, Val Loss=1.6601, lr=0.0100
[2025-05-05 13:12:07,316][train][INFO] - Epoch 7/140, Val Acc=0.6072, Val Loss=1.7451, lr=0.0100
[2025-05-05 13:12:09,082][train][INFO] - Epoch 7/140, Val Acc=0.6236, Val Loss=1.6901, lr=0.0100
[2025-05-05 13:12:09,545][train][INFO] - Epoch 7/140, Val Acc=0.6345, Val Loss=1.6494, lr=0.0100
[2025-05-05 13:12:14,782][train][INFO] - Epoch 8/140, Val Acc=0.6149, Val Loss=1.7028, lr=0.0100
[2025-05-05 13:12:16,894][train][INFO] - Epoch 8/140, Val Acc=0.6313, Val Loss=1.6583, lr=0.0100
[2025-05-05 13:12:17,101][train][INFO] - Epoch 8/140, Val Acc=0.6323, Val Loss=1.6465, lr=0.0100
[2025-05-05 13:12:22,178][train][INFO] - Epoch 9/140, Val Acc=0.6237, Val Loss=1.6444, lr=0.0100
[2025-05-05 13:12:24,312][train][INFO] - Epoch 9/140, Val Acc=0.6175, Val Loss=1.7274, lr=0.0100
[2025-05-05 13:12:24,975][train][INFO] - Epoch 9/140, Val Acc=0.6109, Val Loss=1.8244, lr=0.0100
[2025-05-05 13:12:29,325][train][INFO] - Epoch 10/140, Val Acc=0.6124, Val Loss=1.7356, lr=0.0100
[2025-05-05 13:12:32,078][train][INFO] - Epoch 10/140, Val Acc=0.6265, Val Loss=1.7207, lr=0.0100
[2025-05-05 13:12:32,888][train][INFO] - Epoch 10/140, Val Acc=0.6191, Val Loss=1.7311, lr=0.0100
[2025-05-05 13:12:36,738][train][INFO] - Epoch 11/140, Val Acc=0.6192, Val Loss=1.6980, lr=0.0100
[2025-05-05 13:12:39,801][train][INFO] - Epoch 11/140, Val Acc=0.6305, Val Loss=1.6974, lr=0.0100
[2025-05-05 13:12:40,957][train][INFO] - Epoch 11/140, Val Acc=0.6191, Val Loss=1.7366, lr=0.0100
[2025-05-05 13:12:44,036][train][INFO] - Epoch 12/140, Val Acc=0.6127, Val Loss=1.7193, lr=0.0100
[2025-05-05 13:12:47,687][train][INFO] - Epoch 12/140, Val Acc=0.6202, Val Loss=1.7173, lr=0.0100
[2025-05-05 13:12:48,367][train][INFO] - Epoch 12/140, Val Acc=0.6191, Val Loss=1.7667, lr=0.0100
[2025-05-05 13:12:51,613][train][INFO] - Epoch 13/140, Val Acc=0.6072, Val Loss=1.8149, lr=0.0100
[2025-05-05 13:12:55,305][train][INFO] - Epoch 13/140, Val Acc=0.6262, Val Loss=1.7087, lr=0.0100
[2025-05-05 13:12:55,335][train][INFO] - Epoch 13/140, Val Acc=0.6351, Val Loss=1.6799, lr=0.0100
[2025-05-05 13:12:59,214][train][INFO] - Epoch 14/140, Val Acc=0.6232, Val Loss=1.6851, lr=0.0100
[2025-05-05 13:13:02,650][train][INFO] - Epoch 14/140, Val Acc=0.6355, Val Loss=1.7047, lr=0.0100
[2025-05-05 13:13:03,106][train][INFO] - Epoch 14/140, Val Acc=0.6398, Val Loss=1.6441, lr=0.0100
[2025-05-05 13:13:06,921][train][INFO] - Epoch 15/140, Val Acc=0.6359, Val Loss=1.6387, lr=0.0100
[2025-05-05 13:13:10,384][train][INFO] - Epoch 15/140, Val Acc=0.6191, Val Loss=1.7533, lr=0.0100
[2025-05-05 13:13:10,852][train][INFO] - Epoch 15/140, Val Acc=0.6349, Val Loss=1.6426, lr=0.0100
[2025-05-05 13:13:14,564][train][INFO] - Epoch 16/140, Val Acc=0.6479, Val Loss=1.6046, lr=0.0100
[2025-05-05 13:13:17,722][train][INFO] - Epoch 16/140, Val Acc=0.6291, Val Loss=1.7173, lr=0.0100
[2025-05-05 13:13:18,530][train][INFO] - Epoch 16/140, Val Acc=0.6235, Val Loss=1.7431, lr=0.0100
[2025-05-05 13:13:22,176][train][INFO] - Epoch 17/140, Val Acc=0.6256, Val Loss=1.7220, lr=0.0100
[2025-05-05 13:13:24,974][train][INFO] - Epoch 17/140, Val Acc=0.6320, Val Loss=1.6874, lr=0.0100
[2025-05-05 13:13:26,194][train][INFO] - Epoch 17/140, Val Acc=0.6270, Val Loss=1.7359, lr=0.0100
[2025-05-05 13:13:29,396][train][INFO] - Epoch 18/140, Val Acc=0.6046, Val Loss=1.8021, lr=0.0100
[2025-05-05 13:13:32,681][train][INFO] - Epoch 18/140, Val Acc=0.6451, Val Loss=1.6445, lr=0.0100
[2025-05-05 13:13:33,301][train][INFO] - Epoch 18/140, Val Acc=0.6372, Val Loss=1.6864, lr=0.0100
[2025-05-05 13:13:36,738][train][INFO] - Epoch 19/140, Val Acc=0.6329, Val Loss=1.6166, lr=0.0100
[2025-05-05 13:13:40,161][train][INFO] - Epoch 19/140, Val Acc=0.6197, Val Loss=1.7431, lr=0.0100
[2025-05-05 13:13:40,279][train][INFO] - Epoch 19/140, Val Acc=0.6354, Val Loss=1.6634, lr=0.0100
[2025-05-05 13:13:44,554][train][INFO] - Epoch 20/140, Val Acc=0.6305, Val Loss=1.6798, lr=0.0100
[2025-05-05 13:13:47,473][train][INFO] - Epoch 20/140, Val Acc=0.6337, Val Loss=1.6886, lr=0.0100
[2025-05-05 13:13:47,974][train][INFO] - Epoch 20/140, Val Acc=0.6396, Val Loss=1.6555, lr=0.0100
[2025-05-05 13:13:51,707][train][INFO] - Epoch 21/140, Val Acc=0.6204, Val Loss=1.7341, lr=0.0100
[2025-05-05 13:13:55,333][train][INFO] - Epoch 21/140, Val Acc=0.6297, Val Loss=1.7161, lr=0.0100
[2025-05-05 13:13:55,642][train][INFO] - Epoch 21/140, Val Acc=0.6323, Val Loss=1.7151, lr=0.0100
[2025-05-05 13:13:59,283][train][INFO] - Epoch 22/140, Val Acc=0.6379, Val Loss=1.6278, lr=0.0100
[2025-05-05 13:14:02,598][train][INFO] - Epoch 22/140, Val Acc=0.6466, Val Loss=1.5975, lr=0.0100
[2025-05-05 13:14:03,356][train][INFO] - Epoch 22/140, Val Acc=0.6370, Val Loss=1.6869, lr=0.0100
[2025-05-05 13:14:06,712][train][INFO] - Epoch 23/140, Val Acc=0.6432, Val Loss=1.5991, lr=0.0100
[2025-05-05 13:14:10,137][train][INFO] - Epoch 23/140, Val Acc=0.6364, Val Loss=1.6770, lr=0.0100
[2025-05-05 13:14:10,900][train][INFO] - Epoch 23/140, Val Acc=0.6256, Val Loss=1.7608, lr=0.0100
[2025-05-05 13:14:13,934][train][INFO] - Epoch 24/140, Val Acc=0.6185, Val Loss=1.7574, lr=0.0100
[2025-05-05 13:14:17,732][train][INFO] - Epoch 24/140, Val Acc=0.6351, Val Loss=1.6807, lr=0.0100
[2025-05-05 13:14:18,114][train][INFO] - Epoch 24/140, Val Acc=0.6264, Val Loss=1.7368, lr=0.0100
[2025-05-05 13:14:20,948][train][INFO] - Epoch 25/140, Val Acc=0.6254, Val Loss=1.7670, lr=0.0100
[2025-05-05 13:14:25,559][train][INFO] - Epoch 25/140, Val Acc=0.6355, Val Loss=1.6958, lr=0.0100
[2025-05-05 13:14:25,615][train][INFO] - Epoch 25/140, Val Acc=0.6448, Val Loss=1.7060, lr=0.0100
[2025-05-05 13:14:28,018][train][INFO] - Epoch 26/140, Val Acc=0.6351, Val Loss=1.6833, lr=0.0100
[2025-05-05 13:14:32,795][train][INFO] - Epoch 26/140, Val Acc=0.6060, Val Loss=1.9306, lr=0.0100
[2025-05-05 13:14:33,355][train][INFO] - Epoch 26/140, Val Acc=0.6327, Val Loss=1.7464, lr=0.0100
[2025-05-05 13:14:35,455][train][INFO] - Epoch 27/140, Val Acc=0.6279, Val Loss=1.7212, lr=0.0100
[2025-05-05 13:14:40,266][train][INFO] - Epoch 27/140, Val Acc=0.6357, Val Loss=1.7221, lr=0.0100
[2025-05-05 13:14:40,820][train][INFO] - Epoch 27/140, Val Acc=0.6211, Val Loss=1.7669, lr=0.0100
[2025-05-05 13:14:43,292][train][INFO] - Epoch 28/140, Val Acc=0.6062, Val Loss=1.8423, lr=0.0100
[2025-05-05 13:14:47,862][train][INFO] - Epoch 28/140, Val Acc=0.6360, Val Loss=1.6597, lr=0.0100
[2025-05-05 13:14:48,670][train][INFO] - Epoch 28/140, Val Acc=0.6500, Val Loss=1.6579, lr=0.0100
[2025-05-05 13:14:50,781][train][INFO] - Epoch 29/140, Val Acc=0.6390, Val Loss=1.6358, lr=0.0100
[2025-05-05 13:14:55,774][train][INFO] - Epoch 29/140, Val Acc=0.6404, Val Loss=1.6553, lr=0.0100
[2025-05-05 13:14:56,137][train][INFO] - Epoch 29/140, Val Acc=0.6422, Val Loss=1.6384, lr=0.0100
[2025-05-05 13:14:58,237][train][INFO] - Epoch 30/140, Val Acc=0.6084, Val Loss=1.8511, lr=0.0100
[2025-05-05 13:15:03,625][train][INFO] - Epoch 30/140, Val Acc=0.6287, Val Loss=1.7391, lr=0.0100
[2025-05-05 13:15:03,714][train][INFO] - Epoch 30/140, Val Acc=0.6301, Val Loss=1.7477, lr=0.0100
[2025-05-05 13:15:05,755][train][INFO] - Epoch 31/140, Val Acc=0.6204, Val Loss=1.7585, lr=0.0100
[2025-05-05 13:15:10,990][train][INFO] - Epoch 31/140, Val Acc=0.6239, Val Loss=1.7802, lr=0.0100
[2025-05-05 13:15:11,276][train][INFO] - Epoch 31/140, Val Acc=0.6291, Val Loss=1.7375, lr=0.0100
[2025-05-05 13:15:13,524][train][INFO] - Epoch 32/140, Val Acc=0.6345, Val Loss=1.6570, lr=0.0100
[2025-05-05 13:15:18,660][train][INFO] - Epoch 32/140, Val Acc=0.6392, Val Loss=1.6722, lr=0.0100
[2025-05-05 13:15:18,766][train][INFO] - Epoch 32/140, Val Acc=0.6295, Val Loss=1.7475, lr=0.0100
[2025-05-05 13:15:20,958][train][INFO] - Epoch 33/140, Val Acc=0.6305, Val Loss=1.6834, lr=0.0100
[2025-05-05 13:15:26,366][train][INFO] - Epoch 33/140, Val Acc=0.6136, Val Loss=1.8289, lr=0.0100
[2025-05-05 13:15:26,547][train][INFO] - Epoch 33/140, Val Acc=0.6444, Val Loss=1.6462, lr=0.0100
[2025-05-05 13:15:28,648][train][INFO] - Epoch 34/140, Val Acc=0.6326, Val Loss=1.6720, lr=0.0100
[2025-05-05 13:15:34,097][train][INFO] - Epoch 34/140, Val Acc=0.6343, Val Loss=1.6978, lr=0.0100
[2025-05-05 13:15:34,256][train][INFO] - Epoch 34/140, Val Acc=0.6353, Val Loss=1.6709, lr=0.0100
[2025-05-05 13:15:35,982][train][INFO] - Epoch 35/140, Val Acc=0.6323, Val Loss=1.7023, lr=0.0100
[2025-05-05 13:15:41,996][train][INFO] - Epoch 35/140, Val Acc=0.6181, Val Loss=1.8073, lr=0.0100
[2025-05-05 13:15:42,159][train][INFO] - Epoch 35/140, Val Acc=0.6264, Val Loss=1.7612, lr=0.0100
[2025-05-05 13:15:43,990][train][INFO] - Epoch 36/140, Val Acc=0.6305, Val Loss=1.7476, lr=0.0100
[2025-05-05 13:15:49,205][train][INFO] - Epoch 36/140, Val Acc=0.6294, Val Loss=1.7784, lr=0.0100
[2025-05-05 13:15:50,152][train][INFO] - Epoch 36/140, Val Acc=0.6357, Val Loss=1.7333, lr=0.0100
[2025-05-05 13:15:51,413][train][INFO] - Epoch 37/140, Val Acc=0.6170, Val Loss=1.8224, lr=0.0100
[2025-05-05 13:15:56,914][train][INFO] - Epoch 37/140, Val Acc=0.6343, Val Loss=1.7013, lr=0.0100
[2025-05-05 13:15:57,740][train][INFO] - Epoch 37/140, Val Acc=0.6464, Val Loss=1.6494, lr=0.0100
[2025-05-05 13:15:59,224][train][INFO] - Epoch 38/140, Val Acc=0.6278, Val Loss=1.7308, lr=0.0100
[2025-05-05 13:16:04,637][train][INFO] - Epoch 38/140, Val Acc=0.6388, Val Loss=1.7120, lr=0.0100
[2025-05-05 13:16:05,474][train][INFO] - Epoch 38/140, Val Acc=0.6412, Val Loss=1.6905, lr=0.0100
[2025-05-05 13:16:07,062][train][INFO] - Epoch 39/140, Val Acc=0.6310, Val Loss=1.7553, lr=0.0100
[2025-05-05 13:16:12,140][train][INFO] - Epoch 39/140, Val Acc=0.6411, Val Loss=1.6758, lr=0.0100
[2025-05-05 13:16:12,894][train][INFO] - Epoch 39/140, Val Acc=0.6091, Val Loss=1.8814, lr=0.0100
[2025-05-05 13:16:14,199][train][INFO] - Epoch 40/140, Val Acc=0.6326, Val Loss=1.7074, lr=0.0100
[2025-05-05 13:16:20,023][train][INFO] - Epoch 40/140, Val Acc=0.6347, Val Loss=1.7611, lr=0.0100
[2025-05-05 13:16:20,695][train][INFO] - Epoch 40/140, Val Acc=0.6242, Val Loss=1.8134, lr=0.0100
[2025-05-05 13:16:21,705][train][INFO] - Epoch 41/140, Val Acc=0.6305, Val Loss=1.6966, lr=0.0100
[2025-05-05 13:16:27,834][train][INFO] - Epoch 41/140, Val Acc=0.6232, Val Loss=1.7266, lr=0.0100
[2025-05-05 13:16:28,574][train][INFO] - Epoch 41/140, Val Acc=0.6304, Val Loss=1.7383, lr=0.0100
[2025-05-05 13:16:29,452][train][INFO] - Epoch 42/140, Val Acc=0.6496, Val Loss=1.6508, lr=0.0100
[2025-05-05 13:16:35,530][train][INFO] - Epoch 42/140, Val Acc=0.6364, Val Loss=1.7004, lr=0.0100
[2025-05-05 13:16:36,376][train][INFO] - Epoch 42/140, Val Acc=0.6320, Val Loss=1.7216, lr=0.0100
[2025-05-05 13:16:37,198][train][INFO] - Epoch 43/140, Val Acc=0.6355, Val Loss=1.6611, lr=0.0100
[2025-05-05 13:16:42,993][train][INFO] - Epoch 43/140, Val Acc=0.6367, Val Loss=1.7284, lr=0.0100
[2025-05-05 13:16:44,452][train][INFO] - Epoch 43/140, Val Acc=0.6310, Val Loss=1.7194, lr=0.0100
[2025-05-05 13:16:45,181][train][INFO] - Epoch 44/140, Val Acc=0.6205, Val Loss=1.8149, lr=0.0100
[2025-05-05 13:16:50,650][train][INFO] - Epoch 44/140, Val Acc=0.6334, Val Loss=1.7173, lr=0.0100
[2025-05-05 13:16:52,215][train][INFO] - Epoch 44/140, Val Acc=0.6365, Val Loss=1.6804, lr=0.0100
[2025-05-05 13:16:52,931][train][INFO] - Epoch 45/140, Val Acc=0.6305, Val Loss=1.7323, lr=0.0100
[2025-05-05 13:16:58,232][train][INFO] - Epoch 45/140, Val Acc=0.6343, Val Loss=1.7111, lr=0.0100
[2025-05-05 13:16:59,939][train][INFO] - Epoch 45/140, Val Acc=0.6274, Val Loss=1.7509, lr=0.0100
[2025-05-05 13:17:00,052][train][INFO] - Epoch 46/140, Val Acc=0.6177, Val Loss=1.8632, lr=0.0100
[2025-05-05 13:17:05,565][train][INFO] - Epoch 46/140, Val Acc=0.6360, Val Loss=1.7242, lr=0.0100
[2025-05-05 13:17:07,312][train][INFO] - Epoch 46/140, Val Acc=0.6242, Val Loss=1.8143, lr=0.0100
[2025-05-05 13:17:07,630][train][INFO] - Epoch 47/140, Val Acc=0.6302, Val Loss=1.7189, lr=0.0100
[2025-05-05 13:17:13,231][train][INFO] - Epoch 47/140, Val Acc=0.6386, Val Loss=1.6990, lr=0.0100
[2025-05-05 13:17:14,848][train][INFO] - Epoch 47/140, Val Acc=0.6121, Val Loss=1.9101, lr=0.0100
[2025-05-05 13:17:15,225][train][INFO] - Epoch 48/140, Val Acc=0.6371, Val Loss=1.6958, lr=0.0100
[2025-05-05 13:17:20,401][train][INFO] - Epoch 48/140, Val Acc=0.6360, Val Loss=1.6912, lr=0.0100
[2025-05-05 13:17:22,550][train][INFO] - Epoch 48/140, Val Acc=0.6327, Val Loss=1.7165, lr=0.0100
[2025-05-05 13:17:22,735][train][INFO] - Epoch 49/140, Val Acc=0.6250, Val Loss=1.7522, lr=0.0100
[2025-05-05 13:17:28,153][train][INFO] - Epoch 49/140, Val Acc=0.6299, Val Loss=1.7819, lr=0.0100
[2025-05-05 13:17:30,148][train][INFO] - Epoch 50/140, Val Acc=0.6409, Val Loss=1.6991, lr=0.0100
[2025-05-05 13:17:30,285][train][INFO] - Epoch 49/140, Val Acc=0.6322, Val Loss=1.7562, lr=0.0100
[2025-05-05 13:17:35,693][train][INFO] - Epoch 50/140, Val Acc=0.6307, Val Loss=1.7276, lr=0.0100
[2025-05-05 13:17:37,565][train][INFO] - Epoch 51/140, Val Acc=0.6310, Val Loss=1.6949, lr=0.0100
[2025-05-05 13:17:38,016][train][INFO] - Epoch 50/140, Val Acc=0.6213, Val Loss=1.8065, lr=0.0100
[2025-05-05 13:17:42,994][train][INFO] - Epoch 51/140, Val Acc=0.6361, Val Loss=1.7426, lr=0.0100
[2025-05-05 13:17:44,891][train][INFO] - Epoch 52/140, Val Acc=0.6246, Val Loss=1.8132, lr=0.0100
[2025-05-05 13:17:45,647][train][INFO] - Epoch 51/140, Val Acc=0.6386, Val Loss=1.7084, lr=0.0100
[2025-05-05 13:17:50,542][train][INFO] - Epoch 52/140, Val Acc=0.6222, Val Loss=1.8331, lr=0.0100
[2025-05-05 13:17:52,588][train][INFO] - Epoch 53/140, Val Acc=0.6185, Val Loss=1.8198, lr=0.0100
[2025-05-05 13:17:52,996][train][INFO] - Epoch 52/140, Val Acc=0.6270, Val Loss=1.7787, lr=0.0100
[2025-05-05 13:17:58,107][train][INFO] - Epoch 53/140, Val Acc=0.6285, Val Loss=1.7488, lr=0.0100
[2025-05-05 13:17:59,959][train][INFO] - Epoch 54/140, Val Acc=0.6489, Val Loss=1.6329, lr=0.0100
[2025-05-05 13:18:00,847][train][INFO] - Epoch 53/140, Val Acc=0.6337, Val Loss=1.7517, lr=0.0100
[2025-05-05 13:18:05,409][train][INFO] - Epoch 54/140, Val Acc=0.6423, Val Loss=1.6983, lr=0.0100
[2025-05-05 13:18:07,847][train][INFO] - Epoch 55/140, Val Acc=0.6334, Val Loss=1.7126, lr=0.0100
[2025-05-05 13:18:08,676][train][INFO] - Epoch 54/140, Val Acc=0.6349, Val Loss=1.7325, lr=0.0100
[2025-05-05 13:18:13,173][train][INFO] - Epoch 55/140, Val Acc=0.6473, Val Loss=1.6455, lr=0.0100
[2025-05-05 13:18:15,520][train][INFO] - Epoch 56/140, Val Acc=0.6267, Val Loss=1.7481, lr=0.0100
[2025-05-05 13:18:16,727][train][INFO] - Epoch 55/140, Val Acc=0.6330, Val Loss=1.7548, lr=0.0100
[2025-05-05 13:18:20,383][train][INFO] - Epoch 56/140, Val Acc=0.6306, Val Loss=1.8060, lr=0.0100
[2025-05-05 13:18:22,659][train][INFO] - Epoch 57/140, Val Acc=0.6226, Val Loss=1.7752, lr=0.0100
[2025-05-05 13:18:24,539][train][INFO] - Epoch 56/140, Val Acc=0.6384, Val Loss=1.6910, lr=0.0100
[2025-05-05 13:18:27,663][train][INFO] - Epoch 57/140, Val Acc=0.6334, Val Loss=1.7496, lr=0.0100
[2025-05-05 13:18:29,901][train][INFO] - Epoch 58/140, Val Acc=0.6403, Val Loss=1.7149, lr=0.0100
[2025-05-05 13:18:31,909][train][INFO] - Epoch 57/140, Val Acc=0.6279, Val Loss=1.7731, lr=0.0100
[2025-05-05 13:18:35,323][train][INFO] - Epoch 58/140, Val Acc=0.6255, Val Loss=1.7708, lr=0.0100
[2025-05-05 13:18:37,637][train][INFO] - Epoch 59/140, Val Acc=0.6304, Val Loss=1.8162, lr=0.0100
[2025-05-05 13:18:39,245][train][INFO] - Epoch 58/140, Val Acc=0.6263, Val Loss=1.8071, lr=0.0100
[2025-05-05 13:18:43,018][train][INFO] - Epoch 59/140, Val Acc=0.6304, Val Loss=1.7269, lr=0.0100
[2025-05-05 13:18:44,859][train][INFO] - Epoch 60/140, Val Acc=0.6422, Val Loss=1.6428, lr=0.0100
[2025-05-05 13:18:47,259][train][INFO] - Epoch 59/140, Val Acc=0.6340, Val Loss=1.7205, lr=0.0100
[2025-05-05 13:18:50,781][train][INFO] - Epoch 60/140, Val Acc=0.6401, Val Loss=1.6762, lr=0.0100
[2025-05-05 13:18:52,717][train][INFO] - Epoch 61/140, Val Acc=0.6259, Val Loss=1.7901, lr=0.0100
[2025-05-05 13:18:54,476][train][INFO] - Epoch 60/140, Val Acc=0.6409, Val Loss=1.6639, lr=0.0100
[2025-05-05 13:18:57,951][train][INFO] - Epoch 61/140, Val Acc=0.6367, Val Loss=1.7087, lr=0.0100
[2025-05-05 13:19:00,228][train][INFO] - Epoch 62/140, Val Acc=0.6345, Val Loss=1.7447, lr=0.0100
[2025-05-05 13:19:01,934][train][INFO] - Epoch 61/140, Val Acc=0.6348, Val Loss=1.7097, lr=0.0100
[2025-05-05 13:19:05,692][train][INFO] - Epoch 62/140, Val Acc=0.6380, Val Loss=1.7088, lr=0.0100
[2025-05-05 13:19:07,596][train][INFO] - Epoch 63/140, Val Acc=0.6390, Val Loss=1.6873, lr=0.0100
[2025-05-05 13:19:09,726][train][INFO] - Epoch 62/140, Val Acc=0.6296, Val Loss=1.7622, lr=0.0100
[2025-05-05 13:19:13,548][train][INFO] - Epoch 63/140, Val Acc=0.6399, Val Loss=1.6960, lr=0.0100
[2025-05-05 13:19:15,265][train][INFO] - Epoch 64/140, Val Acc=0.6186, Val Loss=1.7794, lr=0.0100
[2025-05-05 13:19:16,991][train][INFO] - Epoch 63/140, Val Acc=0.6278, Val Loss=1.7312, lr=0.0100
[2025-05-05 13:19:20,956][train][INFO] - Epoch 64/140, Val Acc=0.6398, Val Loss=1.7282, lr=0.0100
[2025-05-05 13:19:22,934][train][INFO] - Epoch 65/140, Val Acc=0.6234, Val Loss=1.8262, lr=0.0100
[2025-05-05 13:19:24,826][train][INFO] - Epoch 64/140, Val Acc=0.6297, Val Loss=1.7890, lr=0.0100
[2025-05-05 13:19:28,560][train][INFO] - Epoch 65/140, Val Acc=0.6425, Val Loss=1.7019, lr=0.0100
[2025-05-05 13:19:30,583][train][INFO] - Epoch 66/140, Val Acc=0.6213, Val Loss=1.8069, lr=0.0100
[2025-05-05 13:19:32,441][train][INFO] - Epoch 65/140, Val Acc=0.6361, Val Loss=1.7051, lr=0.0100
[2025-05-05 13:19:35,706][train][INFO] - Epoch 66/140, Val Acc=0.6289, Val Loss=1.7508, lr=0.0100
[2025-05-05 13:19:38,240][train][INFO] - Epoch 67/140, Val Acc=0.6172, Val Loss=1.8876, lr=0.0100
[2025-05-05 13:19:39,960][train][INFO] - Epoch 66/140, Val Acc=0.6197, Val Loss=1.8105, lr=0.0100
[2025-05-05 13:19:43,247][train][INFO] - Epoch 67/140, Val Acc=0.6094, Val Loss=1.8510, lr=0.0100
[2025-05-05 13:19:45,660][train][INFO] - Epoch 68/140, Val Acc=0.6285, Val Loss=1.7394, lr=0.0100
[2025-05-05 13:19:47,619][train][INFO] - Epoch 67/140, Val Acc=0.6280, Val Loss=1.7696, lr=0.0100
[2025-05-05 13:19:50,715][train][INFO] - Epoch 68/140, Val Acc=0.6380, Val Loss=1.7072, lr=0.0100
[2025-05-05 13:19:52,991][train][INFO] - Epoch 69/140, Val Acc=0.6272, Val Loss=1.7180, lr=0.0100
[2025-05-05 13:19:55,256][train][INFO] - Epoch 68/140, Val Acc=0.6286, Val Loss=1.7399, lr=0.0100
[2025-05-05 13:19:58,523][train][INFO] - Epoch 69/140, Val Acc=0.6450, Val Loss=1.6894, lr=0.0100
[2025-05-05 13:20:00,635][train][INFO] - Epoch 70/140, Val Acc=0.6106, Val Loss=1.8567, lr=0.0100
[2025-05-05 13:20:02,925][train][INFO] - Epoch 69/140, Val Acc=0.6260, Val Loss=1.8114, lr=0.0100
[2025-05-05 13:20:06,059][train][INFO] - Epoch 70/140, Val Acc=0.6360, Val Loss=1.7153, lr=0.0100
[2025-05-05 13:20:08,271][train][INFO] - Epoch 71/140, Val Acc=0.6261, Val Loss=1.7711, lr=0.0100
[2025-05-05 13:20:10,517][train][INFO] - Epoch 70/140, Val Acc=0.6321, Val Loss=1.7501, lr=0.0100
[2025-05-05 13:20:13,634][train][INFO] - Epoch 71/140, Val Acc=0.6261, Val Loss=1.7951, lr=0.0100
[2025-05-05 13:20:15,802][train][INFO] - Epoch 72/140, Val Acc=0.6344, Val Loss=1.7040, lr=0.0100
[2025-05-05 13:20:18,042][train][INFO] - Epoch 71/140, Val Acc=0.6437, Val Loss=1.6971, lr=0.0100
[2025-05-05 13:20:21,378][train][INFO] - Epoch 72/140, Val Acc=0.6336, Val Loss=1.7889, lr=0.0100
[2025-05-05 13:20:23,589][train][INFO] - Epoch 73/140, Val Acc=0.6236, Val Loss=1.7785, lr=0.0100
[2025-05-05 13:20:25,748][train][INFO] - Epoch 72/140, Val Acc=0.6312, Val Loss=1.7297, lr=0.0100
[2025-05-05 13:20:29,071][train][INFO] - Epoch 73/140, Val Acc=0.6384, Val Loss=1.7319, lr=0.0100
[2025-05-05 13:20:31,196][train][INFO] - Epoch 74/140, Val Acc=0.6147, Val Loss=1.8280, lr=0.0100
[2025-05-05 13:20:33,615][train][INFO] - Epoch 73/140, Val Acc=0.6216, Val Loss=1.8105, lr=0.0100
[2025-05-05 13:20:36,434][train][INFO] - Epoch 74/140, Val Acc=0.6266, Val Loss=1.8073, lr=0.0100
[2025-05-05 13:20:38,690][train][INFO] - Epoch 75/140, Val Acc=0.6464, Val Loss=1.6274, lr=0.0100
[2025-05-05 13:20:41,369][train][INFO] - Epoch 74/140, Val Acc=0.6328, Val Loss=1.7950, lr=0.0100
[2025-05-05 13:20:44,115][train][INFO] - Epoch 75/140, Val Acc=0.6436, Val Loss=1.7176, lr=0.0100
[2025-05-05 13:20:45,854][train][INFO] - Epoch 76/140, Val Acc=0.6290, Val Loss=1.7996, lr=0.0100
[2025-05-05 13:20:49,035][train][INFO] - Epoch 75/140, Val Acc=0.6258, Val Loss=1.7547, lr=0.0100
[2025-05-05 13:20:51,671][train][INFO] - Epoch 76/140, Val Acc=0.6423, Val Loss=1.6850, lr=0.0100
[2025-05-05 13:20:53,203][train][INFO] - Epoch 77/140, Val Acc=0.6247, Val Loss=1.7882, lr=0.0100
[2025-05-05 13:20:56,877][train][INFO] - Epoch 76/140, Val Acc=0.6411, Val Loss=1.7055, lr=0.0100
[2025-05-05 13:20:59,427][train][INFO] - Epoch 77/140, Val Acc=0.6291, Val Loss=1.8067, lr=0.0100
[2025-05-05 13:21:00,596][train][INFO] - Epoch 78/140, Val Acc=0.6247, Val Loss=1.7549, lr=0.0100
[2025-05-05 13:21:04,853][train][INFO] - Epoch 77/140, Val Acc=0.6390, Val Loss=1.7284, lr=0.0100
[2025-05-05 13:21:07,030][train][INFO] - Epoch 78/140, Val Acc=0.6267, Val Loss=1.8043, lr=0.0100
[2025-05-05 13:21:08,323][train][INFO] - Epoch 79/140, Val Acc=0.6327, Val Loss=1.7573, lr=0.0100
[2025-05-05 13:21:12,681][train][INFO] - Epoch 78/140, Val Acc=0.6380, Val Loss=1.7262, lr=0.0100
[2025-05-05 13:21:14,445][train][INFO] - Epoch 79/140, Val Acc=0.6355, Val Loss=1.7311, lr=0.0100
[2025-05-05 13:21:16,029][train][INFO] - Epoch 80/140, Val Acc=0.6339, Val Loss=1.7207, lr=0.0100
[2025-05-05 13:21:20,542][train][INFO] - Epoch 79/140, Val Acc=0.6416, Val Loss=1.7092, lr=0.0100
[2025-05-05 13:21:22,265][train][INFO] - Epoch 80/140, Val Acc=0.6320, Val Loss=1.7584, lr=0.0100
[2025-05-05 13:21:23,310][train][INFO] - Epoch 81/140, Val Acc=0.6919, Val Loss=1.4150, lr=0.0010
[2025-05-05 13:21:28,337][train][INFO] - Epoch 80/140, Val Acc=0.6219, Val Loss=1.7673, lr=0.0100
[2025-05-05 13:21:29,771][train][INFO] - Epoch 81/140, Val Acc=0.6915, Val Loss=1.4179, lr=0.0010
[2025-05-05 13:21:30,759][train][INFO] - Epoch 82/140, Val Acc=0.6950, Val Loss=1.4166, lr=0.0010
[2025-05-05 13:21:36,214][train][INFO] - Epoch 81/140, Val Acc=0.6927, Val Loss=1.4215, lr=0.0010
[2025-05-05 13:21:37,259][train][INFO] - Epoch 82/140, Val Acc=0.6926, Val Loss=1.4196, lr=0.0010
[2025-05-05 13:21:38,370][train][INFO] - Epoch 83/140, Val Acc=0.6992, Val Loss=1.4221, lr=0.0010
[2025-05-05 13:21:43,958][train][INFO] - Epoch 82/140, Val Acc=0.6945, Val Loss=1.4200, lr=0.0010
[2025-05-05 13:21:44,117][train][INFO] - Epoch 83/140, Val Acc=0.6953, Val Loss=1.4201, lr=0.0010
[2025-05-05 13:21:46,069][train][INFO] - Epoch 84/140, Val Acc=0.6984, Val Loss=1.4292, lr=0.0010
[2025-05-05 13:21:51,516][train][INFO] - Epoch 83/140, Val Acc=0.6934, Val Loss=1.4284, lr=0.0010
[2025-05-05 13:21:52,045][train][INFO] - Epoch 84/140, Val Acc=0.6964, Val Loss=1.4242, lr=0.0010
[2025-05-05 13:21:53,927][train][INFO] - Epoch 85/140, Val Acc=0.6989, Val Loss=1.4360, lr=0.0010
[2025-05-05 13:21:59,287][train][INFO] - Epoch 84/140, Val Acc=0.6963, Val Loss=1.4390, lr=0.0010
[2025-05-05 13:21:59,413][train][INFO] - Epoch 85/140, Val Acc=0.6988, Val Loss=1.4284, lr=0.0010
[2025-05-05 13:22:01,081][train][INFO] - Epoch 86/140, Val Acc=0.6993, Val Loss=1.4406, lr=0.0010
[2025-05-05 13:22:06,879][train][INFO] - Epoch 85/140, Val Acc=0.6987, Val Loss=1.4405, lr=0.0010
[2025-05-05 13:22:06,935][train][INFO] - Epoch 86/140, Val Acc=0.6981, Val Loss=1.4358, lr=0.0010
[2025-05-05 13:22:08,682][train][INFO] - Epoch 87/140, Val Acc=0.7006, Val Loss=1.4397, lr=0.0010
[2025-05-05 13:22:14,458][train][INFO] - Epoch 86/140, Val Acc=0.7001, Val Loss=1.4378, lr=0.0010
[2025-05-05 13:22:14,890][train][INFO] - Epoch 87/140, Val Acc=0.7017, Val Loss=1.4330, lr=0.0010
[2025-05-05 13:22:16,045][train][INFO] - Epoch 88/140, Val Acc=0.7022, Val Loss=1.4421, lr=0.0010
[2025-05-05 13:22:22,265][train][INFO] - Epoch 88/140, Val Acc=0.7019, Val Loss=1.4298, lr=0.0010
[2025-05-05 13:22:22,412][train][INFO] - Epoch 87/140, Val Acc=0.6979, Val Loss=1.4410, lr=0.0010
[2025-05-05 13:22:23,426][train][INFO] - Epoch 89/140, Val Acc=0.7021, Val Loss=1.4450, lr=0.0010
[2025-05-05 13:22:29,970][train][INFO] - Epoch 89/140, Val Acc=0.7017, Val Loss=1.4412, lr=0.0010
[2025-05-05 13:22:29,983][train][INFO] - Epoch 88/140, Val Acc=0.7003, Val Loss=1.4491, lr=0.0010
[2025-05-05 13:22:31,086][train][INFO] - Epoch 90/140, Val Acc=0.7047, Val Loss=1.4506, lr=0.0010
[2025-05-05 13:22:37,713][train][INFO] - Epoch 89/140, Val Acc=0.7002, Val Loss=1.4441, lr=0.0010
[2025-05-05 13:22:37,880][train][INFO] - Epoch 90/140, Val Acc=0.7006, Val Loss=1.4432, lr=0.0010
[2025-05-05 13:22:38,589][train][INFO] - Epoch 91/140, Val Acc=0.7020, Val Loss=1.4490, lr=0.0010
[2025-05-05 13:22:45,343][train][INFO] - Epoch 91/140, Val Acc=0.7019, Val Loss=1.4380, lr=0.0010
[2025-05-05 13:22:45,396][train][INFO] - Epoch 90/140, Val Acc=0.7016, Val Loss=1.4455, lr=0.0010
[2025-05-05 13:22:46,563][train][INFO] - Epoch 92/140, Val Acc=0.7001, Val Loss=1.4582, lr=0.0010
[2025-05-05 13:22:52,919][train][INFO] - Epoch 91/140, Val Acc=0.6999, Val Loss=1.4497, lr=0.0010
[2025-05-05 13:22:53,036][train][INFO] - Epoch 92/140, Val Acc=0.7035, Val Loss=1.4470, lr=0.0010
[2025-05-05 13:22:54,229][train][INFO] - Epoch 93/140, Val Acc=0.6995, Val Loss=1.4585, lr=0.0010
[2025-05-05 13:23:00,755][train][INFO] - Epoch 92/140, Val Acc=0.7037, Val Loss=1.4501, lr=0.0010
[2025-05-05 13:23:01,211][train][INFO] - Epoch 93/140, Val Acc=0.7026, Val Loss=1.4550, lr=0.0010
[2025-05-05 13:23:02,031][train][INFO] - Epoch 94/140, Val Acc=0.7004, Val Loss=1.4654, lr=0.0010
[2025-05-05 13:23:08,448][train][INFO] - Epoch 93/140, Val Acc=0.6999, Val Loss=1.4595, lr=0.0010
[2025-05-05 13:23:08,650][train][INFO] - Epoch 94/140, Val Acc=0.7030, Val Loss=1.4500, lr=0.0010
[2025-05-05 13:23:09,622][train][INFO] - Epoch 95/140, Val Acc=0.7019, Val Loss=1.4635, lr=0.0010
[2025-05-05 13:23:15,670][train][INFO] - Epoch 94/140, Val Acc=0.6995, Val Loss=1.4622, lr=0.0010
[2025-05-05 13:23:16,307][train][INFO] - Epoch 95/140, Val Acc=0.7056, Val Loss=1.4500, lr=0.0010
[2025-05-05 13:23:17,303][train][INFO] - Epoch 96/140, Val Acc=0.6984, Val Loss=1.4726, lr=0.0010
[2025-05-05 13:23:22,894][train][INFO] - Epoch 95/140, Val Acc=0.6999, Val Loss=1.4644, lr=0.0010
[2025-05-05 13:23:23,772][train][INFO] - Epoch 96/140, Val Acc=0.7035, Val Loss=1.4532, lr=0.0010
[2025-05-05 13:23:24,692][train][INFO] - Epoch 97/140, Val Acc=0.6996, Val Loss=1.4732, lr=0.0010
[2025-05-05 13:23:30,525][train][INFO] - Epoch 96/140, Val Acc=0.7009, Val Loss=1.4709, lr=0.0010
[2025-05-05 13:23:30,798][train][INFO] - Epoch 97/140, Val Acc=0.7044, Val Loss=1.4571, lr=0.0010
[2025-05-05 13:23:31,995][train][INFO] - Epoch 98/140, Val Acc=0.7013, Val Loss=1.4701, lr=0.0010
[2025-05-05 13:23:37,807][train][INFO] - Epoch 97/140, Val Acc=0.7009, Val Loss=1.4702, lr=0.0010
[2025-05-05 13:23:38,477][train][INFO] - Epoch 98/140, Val Acc=0.7031, Val Loss=1.4558, lr=0.0010
[2025-05-05 13:23:39,484][train][INFO] - Epoch 99/140, Val Acc=0.7012, Val Loss=1.4679, lr=0.0010
[2025-05-05 13:23:45,093][train][INFO] - Epoch 98/140, Val Acc=0.7006, Val Loss=1.4770, lr=0.0010
[2025-05-05 13:23:45,927][train][INFO] - Epoch 99/140, Val Acc=0.7051, Val Loss=1.4600, lr=0.0010
[2025-05-05 13:23:47,037][train][INFO] - Epoch 100/140, Val Acc=0.7023, Val Loss=1.4671, lr=0.0010
[2025-05-05 13:23:53,025][train][INFO] - Epoch 99/140, Val Acc=0.7019, Val Loss=1.4739, lr=0.0010
[2025-05-05 13:23:53,277][train][INFO] - Epoch 100/140, Val Acc=0.7030, Val Loss=1.4623, lr=0.0010
[2025-05-05 13:23:54,476][train][INFO] - Epoch 101/140, Val Acc=0.7038, Val Loss=1.4699, lr=0.0010
[2025-05-05 13:24:00,431][train][INFO] - Epoch 101/140, Val Acc=0.7047, Val Loss=1.4593, lr=0.0010
[2025-05-05 13:24:00,665][train][INFO] - Epoch 100/140, Val Acc=0.6996, Val Loss=1.4721, lr=0.0010
[2025-05-05 13:24:02,192][train][INFO] - Epoch 102/140, Val Acc=0.7014, Val Loss=1.4733, lr=0.0010
[2025-05-05 13:24:08,208][train][INFO] - Epoch 102/140, Val Acc=0.7050, Val Loss=1.4679, lr=0.0010
[2025-05-05 13:24:08,314][train][INFO] - Epoch 101/140, Val Acc=0.7026, Val Loss=1.4672, lr=0.0010
[2025-05-05 13:24:09,890][train][INFO] - Epoch 103/140, Val Acc=0.7018, Val Loss=1.4805, lr=0.0010
[2025-05-05 13:24:15,731][train][INFO] - Epoch 102/140, Val Acc=0.7001, Val Loss=1.4736, lr=0.0010
[2025-05-05 13:24:15,939][train][INFO] - Epoch 103/140, Val Acc=0.7050, Val Loss=1.4642, lr=0.0010
[2025-05-05 13:24:17,644][train][INFO] - Epoch 104/140, Val Acc=0.7037, Val Loss=1.4806, lr=0.0010
[2025-05-05 13:24:23,444][train][INFO] - Epoch 103/140, Val Acc=0.7024, Val Loss=1.4717, lr=0.0010
[2025-05-05 13:24:24,014][train][INFO] - Epoch 104/140, Val Acc=0.7044, Val Loss=1.4625, lr=0.0010
[2025-05-05 13:24:25,492][train][INFO] - Epoch 105/140, Val Acc=0.7004, Val Loss=1.4807, lr=0.0010
[2025-05-05 13:24:30,834][train][INFO] - Epoch 104/140, Val Acc=0.7030, Val Loss=1.4698, lr=0.0010
[2025-05-05 13:24:31,892][train][INFO] - Epoch 105/140, Val Acc=0.7049, Val Loss=1.4643, lr=0.0010
[2025-05-05 13:24:33,089][train][INFO] - Epoch 106/140, Val Acc=0.7016, Val Loss=1.4887, lr=0.0010
[2025-05-05 13:24:38,546][train][INFO] - Epoch 105/140, Val Acc=0.7012, Val Loss=1.4795, lr=0.0010
[2025-05-05 13:24:39,231][train][INFO] - Epoch 106/140, Val Acc=0.7053, Val Loss=1.4604, lr=0.0010
[2025-05-05 13:24:40,847][train][INFO] - Epoch 107/140, Val Acc=0.7031, Val Loss=1.4787, lr=0.0010
[2025-05-05 13:24:46,543][train][INFO] - Epoch 106/140, Val Acc=0.7008, Val Loss=1.4822, lr=0.0010
[2025-05-05 13:24:46,656][train][INFO] - Epoch 107/140, Val Acc=0.7047, Val Loss=1.4619, lr=0.0010
[2025-05-05 13:24:48,450][train][INFO] - Epoch 108/140, Val Acc=0.7029, Val Loss=1.4769, lr=0.0010
[2025-05-05 13:24:53,893][train][INFO] - Epoch 107/140, Val Acc=0.7022, Val Loss=1.4747, lr=0.0010
[2025-05-05 13:24:54,424][train][INFO] - Epoch 108/140, Val Acc=0.7064, Val Loss=1.4626, lr=0.0010
[2025-05-05 13:24:56,056][train][INFO] - Epoch 109/140, Val Acc=0.7033, Val Loss=1.4720, lr=0.0010
[2025-05-05 13:25:01,524][train][INFO] - Epoch 108/140, Val Acc=0.7030, Val Loss=1.4766, lr=0.0010
[2025-05-05 13:25:01,938][train][INFO] - Epoch 109/140, Val Acc=0.7064, Val Loss=1.4691, lr=0.0010
[2025-05-05 13:25:03,727][train][INFO] - Epoch 110/140, Val Acc=0.7041, Val Loss=1.4818, lr=0.0010
[2025-05-05 13:25:09,111][train][INFO] - Epoch 109/140, Val Acc=0.7025, Val Loss=1.4843, lr=0.0010
[2025-05-05 13:25:09,559][train][INFO] - Epoch 110/140, Val Acc=0.7069, Val Loss=1.4669, lr=0.0010
[2025-05-05 13:25:11,420][train][INFO] - Epoch 111/140, Val Acc=0.7021, Val Loss=1.4856, lr=0.0010
[2025-05-05 13:25:16,452][train][INFO] - Epoch 110/140, Val Acc=0.7025, Val Loss=1.4791, lr=0.0010
[2025-05-05 13:25:17,286][train][INFO] - Epoch 111/140, Val Acc=0.7054, Val Loss=1.4673, lr=0.0010
[2025-05-05 13:25:19,336][train][INFO] - Epoch 112/140, Val Acc=0.7026, Val Loss=1.4846, lr=0.0010
[2025-05-05 13:25:23,613][train][INFO] - Epoch 111/140, Val Acc=0.7039, Val Loss=1.4815, lr=0.0010
[2025-05-05 13:25:25,436][train][INFO] - Epoch 112/140, Val Acc=0.7082, Val Loss=1.4662, lr=0.0010
[2025-05-05 13:25:26,908][train][INFO] - Epoch 113/140, Val Acc=0.7014, Val Loss=1.4837, lr=0.0010
[2025-05-05 13:25:31,162][train][INFO] - Epoch 112/140, Val Acc=0.6991, Val Loss=1.4837, lr=0.0010
[2025-05-05 13:25:33,108][train][INFO] - Epoch 113/140, Val Acc=0.7094, Val Loss=1.4632, lr=0.0010
[2025-05-05 13:25:34,197][train][INFO] - Epoch 114/140, Val Acc=0.7036, Val Loss=1.4819, lr=0.0010
[2025-05-05 13:25:38,817][train][INFO] - Epoch 113/140, Val Acc=0.7038, Val Loss=1.4810, lr=0.0010
[2025-05-05 13:25:40,754][train][INFO] - Epoch 114/140, Val Acc=0.7052, Val Loss=1.4597, lr=0.0010
[2025-05-05 13:25:41,834][train][INFO] - Epoch 115/140, Val Acc=0.7023, Val Loss=1.4833, lr=0.0010
[2025-05-05 13:25:46,494][train][INFO] - Epoch 114/140, Val Acc=0.7025, Val Loss=1.4758, lr=0.0010
[2025-05-05 13:25:48,406][train][INFO] - Epoch 115/140, Val Acc=0.7066, Val Loss=1.4585, lr=0.0010
[2025-05-05 13:25:48,777][train][INFO] - Epoch 116/140, Val Acc=0.7019, Val Loss=1.4807, lr=0.0010
[2025-05-05 13:25:54,048][train][INFO] - Epoch 115/140, Val Acc=0.7002, Val Loss=1.4759, lr=0.0010
[2025-05-05 13:25:56,303][train][INFO] - Epoch 117/140, Val Acc=0.7031, Val Loss=1.4815, lr=0.0010
[2025-05-05 13:25:56,563][train][INFO] - Epoch 116/140, Val Acc=0.7086, Val Loss=1.4676, lr=0.0010
[2025-05-05 13:26:01,281][train][INFO] - Epoch 116/140, Val Acc=0.7014, Val Loss=1.4802, lr=0.0010
[2025-05-05 13:26:03,921][train][INFO] - Epoch 118/140, Val Acc=0.7006, Val Loss=1.4819, lr=0.0010
[2025-05-05 13:26:04,002][train][INFO] - Epoch 117/140, Val Acc=0.7052, Val Loss=1.4706, lr=0.0010
[2025-05-05 13:26:08,845][train][INFO] - Epoch 117/140, Val Acc=0.7022, Val Loss=1.4861, lr=0.0010
[2025-05-05 13:26:11,610][train][INFO] - Epoch 119/140, Val Acc=0.7031, Val Loss=1.4812, lr=0.0010
[2025-05-05 13:26:11,694][train][INFO] - Epoch 118/140, Val Acc=0.7064, Val Loss=1.4738, lr=0.0010
[2025-05-05 13:26:16,781][train][INFO] - Epoch 118/140, Val Acc=0.7005, Val Loss=1.4850, lr=0.0010
[2025-05-05 13:26:19,155][train][INFO] - Epoch 120/140, Val Acc=0.7032, Val Loss=1.4829, lr=0.0010
[2025-05-05 13:26:19,284][train][INFO] - Epoch 119/140, Val Acc=0.7053, Val Loss=1.4720, lr=0.0010
[2025-05-05 13:26:24,439][train][INFO] - Epoch 119/140, Val Acc=0.7011, Val Loss=1.4882, lr=0.0010
[2025-05-05 13:26:26,672][train][INFO] - Epoch 121/140, Val Acc=0.7047, Val Loss=1.4820, lr=0.0001
[2025-05-05 13:26:26,937][train][INFO] - Epoch 120/140, Val Acc=0.7063, Val Loss=1.4718, lr=0.0010
[2025-05-05 13:26:31,865][train][INFO] - Epoch 120/140, Val Acc=0.7024, Val Loss=1.4859, lr=0.0010
[2025-05-05 13:26:34,366][train][INFO] - Epoch 121/140, Val Acc=0.7065, Val Loss=1.4707, lr=0.0001
[2025-05-05 13:26:34,686][train][INFO] - Epoch 122/140, Val Acc=0.7046, Val Loss=1.4808, lr=0.0001
[2025-05-05 13:26:39,136][train][INFO] - Epoch 121/140, Val Acc=0.7022, Val Loss=1.4851, lr=0.0001
[2025-05-05 13:26:41,768][train][INFO] - Epoch 123/140, Val Acc=0.7039, Val Loss=1.4748, lr=0.0001
[2025-05-05 13:26:42,243][train][INFO] - Epoch 122/140, Val Acc=0.7068, Val Loss=1.4731, lr=0.0001
[2025-05-05 13:26:46,675][train][INFO] - Epoch 122/140, Val Acc=0.7017, Val Loss=1.4854, lr=0.0001
[2025-05-05 13:26:48,967][train][INFO] - Epoch 124/140, Val Acc=0.7051, Val Loss=1.4806, lr=0.0001
[2025-05-05 13:26:49,270][train][INFO] - Epoch 123/140, Val Acc=0.7069, Val Loss=1.4657, lr=0.0001
[2025-05-05 13:26:54,563][train][INFO] - Epoch 123/140, Val Acc=0.7034, Val Loss=1.4827, lr=0.0001
[2025-05-05 13:26:56,725][train][INFO] - Epoch 125/140, Val Acc=0.7043, Val Loss=1.4796, lr=0.0001
[2025-05-05 13:26:56,803][train][INFO] - Epoch 124/140, Val Acc=0.7088, Val Loss=1.4654, lr=0.0001
[2025-05-05 13:27:02,255][train][INFO] - Epoch 124/140, Val Acc=0.7019, Val Loss=1.4841, lr=0.0001
[2025-05-05 13:27:04,288][train][INFO] - Epoch 126/140, Val Acc=0.7057, Val Loss=1.4762, lr=0.0001
[2025-05-05 13:27:04,457][train][INFO] - Epoch 125/140, Val Acc=0.7068, Val Loss=1.4685, lr=0.0001
[2025-05-05 13:27:09,726][train][INFO] - Epoch 125/140, Val Acc=0.7021, Val Loss=1.4881, lr=0.0001
[2025-05-05 13:27:11,576][train][INFO] - Epoch 126/140, Val Acc=0.7079, Val Loss=1.4641, lr=0.0001
[2025-05-05 13:27:11,897][train][INFO] - Epoch 127/140, Val Acc=0.7049, Val Loss=1.4822, lr=0.0001
[2025-05-05 13:27:17,620][train][INFO] - Epoch 126/140, Val Acc=0.7042, Val Loss=1.4798, lr=0.0001
[2025-05-05 13:27:18,962][train][INFO] - Epoch 127/140, Val Acc=0.7069, Val Loss=1.4648, lr=0.0001
[2025-05-05 13:27:19,589][train][INFO] - Epoch 128/140, Val Acc=0.7060, Val Loss=1.4758, lr=0.0001
[2025-05-05 13:27:24,900][train][INFO] - Epoch 127/140, Val Acc=0.7038, Val Loss=1.4840, lr=0.0001
[2025-05-05 13:27:26,323][train][INFO] - Epoch 128/140, Val Acc=0.7072, Val Loss=1.4637, lr=0.0001
[2025-05-05 13:27:27,079][train][INFO] - Epoch 129/140, Val Acc=0.7044, Val Loss=1.4758, lr=0.0001
[2025-05-05 13:27:32,887][train][INFO] - Epoch 128/140, Val Acc=0.7036, Val Loss=1.4811, lr=0.0001
[2025-05-05 13:27:34,312][train][INFO] - Epoch 129/140, Val Acc=0.7060, Val Loss=1.4655, lr=0.0001
[2025-05-05 13:27:34,908][train][INFO] - Epoch 130/140, Val Acc=0.7054, Val Loss=1.4801, lr=0.0001
[2025-05-05 13:27:40,422][train][INFO] - Epoch 129/140, Val Acc=0.7031, Val Loss=1.4820, lr=0.0001
[2025-05-05 13:27:42,212][train][INFO] - Epoch 130/140, Val Acc=0.7086, Val Loss=1.4636, lr=0.0001
[2025-05-05 13:27:42,856][train][INFO] - Epoch 131/140, Val Acc=0.7043, Val Loss=1.4840, lr=0.0001
[2025-05-05 13:27:48,302][train][INFO] - Epoch 130/140, Val Acc=0.7029, Val Loss=1.4809, lr=0.0001
[2025-05-05 13:27:50,028][train][INFO] - Epoch 131/140, Val Acc=0.7078, Val Loss=1.4629, lr=0.0001
[2025-05-05 13:27:50,708][train][INFO] - Epoch 132/140, Val Acc=0.7041, Val Loss=1.4791, lr=0.0001
[2025-05-05 13:27:56,010][train][INFO] - Epoch 131/140, Val Acc=0.7023, Val Loss=1.4821, lr=0.0001
[2025-05-05 13:27:57,553][train][INFO] - Epoch 132/140, Val Acc=0.7102, Val Loss=1.4666, lr=0.0001
[2025-05-05 13:27:58,154][train][INFO] - Epoch 133/140, Val Acc=0.7049, Val Loss=1.4816, lr=0.0001
[2025-05-05 13:28:03,507][train][INFO] - Epoch 132/140, Val Acc=0.7029, Val Loss=1.4841, lr=0.0001
[2025-05-05 13:28:05,294][train][INFO] - Epoch 133/140, Val Acc=0.7072, Val Loss=1.4639, lr=0.0001
[2025-05-05 13:28:05,964][train][INFO] - Epoch 134/140, Val Acc=0.7069, Val Loss=1.4760, lr=0.0001
[2025-05-05 13:28:10,782][train][INFO] - Epoch 133/140, Val Acc=0.7035, Val Loss=1.4841, lr=0.0001
[2025-05-05 13:28:12,721][train][INFO] - Epoch 134/140, Val Acc=0.7077, Val Loss=1.4661, lr=0.0001
[2025-05-05 13:28:13,711][train][INFO] - Epoch 135/140, Val Acc=0.7051, Val Loss=1.4804, lr=0.0001
[2025-05-05 13:28:18,656][train][INFO] - Epoch 134/140, Val Acc=0.7025, Val Loss=1.4843, lr=0.0001
[2025-05-05 13:28:19,713][train][INFO] - Epoch 135/140, Val Acc=0.7079, Val Loss=1.4637, lr=0.0001
[2025-05-05 13:28:21,147][train][INFO] - Epoch 136/140, Val Acc=0.7055, Val Loss=1.4787, lr=0.0001
[2025-05-05 13:28:26,023][train][INFO] - Epoch 135/140, Val Acc=0.7025, Val Loss=1.4856, lr=0.0001
[2025-05-05 13:28:26,988][train][INFO] - Epoch 136/140, Val Acc=0.7084, Val Loss=1.4664, lr=0.0001
[2025-05-05 13:28:28,940][train][INFO] - Epoch 137/140, Val Acc=0.7064, Val Loss=1.4764, lr=0.0001
[2025-05-05 13:28:33,571][train][INFO] - Epoch 136/140, Val Acc=0.7011, Val Loss=1.4822, lr=0.0001
[2025-05-05 13:28:34,750][train][INFO] - Epoch 137/140, Val Acc=0.7093, Val Loss=1.4623, lr=0.0001
[2025-05-05 13:28:36,542][train][INFO] - Epoch 138/140, Val Acc=0.7061, Val Loss=1.4793, lr=0.0001
[2025-05-05 13:28:40,932][train][INFO] - Epoch 137/140, Val Acc=0.7025, Val Loss=1.4824, lr=0.0001
[2025-05-05 13:28:42,501][train][INFO] - Epoch 138/140, Val Acc=0.7091, Val Loss=1.4669, lr=0.0001
[2025-05-05 13:28:44,434][train][INFO] - Epoch 139/140, Val Acc=0.7052, Val Loss=1.4804, lr=0.0001
[2025-05-05 13:28:48,788][train][INFO] - Epoch 138/140, Val Acc=0.7029, Val Loss=1.4854, lr=0.0001
[2025-05-05 13:28:50,403][train][INFO] - Epoch 139/140, Val Acc=0.7081, Val Loss=1.4634, lr=0.0001
[2025-05-05 13:28:52,089][train][INFO] - Epoch 140/140, Val Acc=0.7053, Val Loss=1.4801, lr=0.0001
[2025-05-05 13:28:56,237][train][INFO] - Epoch 139/140, Val Acc=0.7038, Val Loss=1.4836, lr=0.0001
[2025-05-05 13:28:57,325][train][INFO] - After training : Train Acc=0.9989  Val Acc=0.7069
[2025-05-05 13:28:57,364][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(85, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(253, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 245, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(245, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(36, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(8, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(28, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(36, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(19, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(34, 162, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=162, out_features=100, bias=True)
)
[2025-05-05 13:28:57,364][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.7069000005722046
                      Speed up: 1.33   Final speed up: 4.01
[2025-05-05 13:28:58,140][train][INFO] - Epoch 140/140, Val Acc=0.7082, Val Loss=1.4633, lr=0.0001
[2025-05-05 13:29:03,217][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7102
[2025-05-05 13:29:03,262][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(85, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(253, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(255, 222, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(222, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(51, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(29, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(7, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(19, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(27, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=164, out_features=100, bias=True)
)
[2025-05-05 13:29:03,262][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.7102000117301941
                      Speed up: 1.32   Final speed up: 4.01
[2025-05-05 13:29:03,984][train][INFO] - Epoch 140/140, Val Acc=0.7036, Val Loss=1.4854, lr=0.0001
[2025-05-05 13:29:09,010][train][INFO] - After training : Train Acc=0.9984  Val Acc=0.7042
[2025-05-05 13:29:09,036][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(85, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(253, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(254, 218, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(218, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(218, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(57, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(17, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(4, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(9, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(26, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(30, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(19, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(34, 169, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(169, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=169, out_features=100, bias=True)
)
[2025-05-05 13:29:09,037][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.7041999697685242
                      Speed up: 1.33   Final speed up: 4.01
[2025-05-05 14:12:55,488][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 14:12:55,569][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 14:12:55,569][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 14:12:55,569][get_dataset_model_loader][INFO] - ==================================================
[2025-05-05 14:13:00,326][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-05 14:13:00,402][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 14:13:00,402][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 14:13:00,402][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 14:13:05,084][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-05 14:13:05,136][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 14:13:05,136][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 14:13:05,136][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 14:13:09,115][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 14:13:14,310][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 14:13:17,313][train][INFO] - Epoch 1/100, Val Acc=0.2505, Val Loss=2.8838, lr=0.0100
[2025-05-05 14:13:19,361][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 14:13:21,808][train][INFO] - Epoch 1/100, Val Acc=0.1577, Val Loss=3.3296, lr=0.0100
[2025-05-05 14:13:25,475][train][INFO] - Epoch 2/100, Val Acc=0.4556, Val Loss=2.0225, lr=0.0100
[2025-05-05 14:13:26,844][train][INFO] - Epoch 1/100, Val Acc=0.1243, Val Loss=3.4677, lr=0.0100
[2025-05-05 14:13:29,545][train][INFO] - Epoch 2/100, Val Acc=0.3635, Val Loss=2.4141, lr=0.0100
[2025-05-05 14:13:33,349][train][INFO] - Epoch 3/100, Val Acc=0.5092, Val Loss=1.8887, lr=0.0100
[2025-05-05 14:13:35,397][train][INFO] - Epoch 2/100, Val Acc=0.2144, Val Loss=3.1136, lr=0.0100
[2025-05-05 14:13:37,536][train][INFO] - Epoch 3/100, Val Acc=0.4327, Val Loss=2.0928, lr=0.0100
[2025-05-05 14:13:41,511][train][INFO] - Epoch 4/100, Val Acc=0.5465, Val Loss=1.7416, lr=0.0100
[2025-05-05 14:13:43,658][train][INFO] - Epoch 3/100, Val Acc=0.2104, Val Loss=3.5578, lr=0.0100
[2025-05-05 14:13:44,864][train][INFO] - Epoch 4/100, Val Acc=0.4947, Val Loss=1.8791, lr=0.0100
[2025-05-05 14:13:49,838][train][INFO] - Epoch 5/100, Val Acc=0.5728, Val Loss=1.6605, lr=0.0100
[2025-05-05 14:13:51,992][train][INFO] - Epoch 4/100, Val Acc=0.3918, Val Loss=2.2622, lr=0.0100
[2025-05-05 14:13:52,995][train][INFO] - Epoch 5/100, Val Acc=0.5280, Val Loss=1.7670, lr=0.0100
[2025-05-05 14:13:58,272][train][INFO] - Epoch 6/100, Val Acc=0.5776, Val Loss=1.6386, lr=0.0100
[2025-05-05 14:13:59,968][train][INFO] - Epoch 5/100, Val Acc=0.3694, Val Loss=2.3837, lr=0.0100
[2025-05-05 14:14:00,998][train][INFO] - Epoch 6/100, Val Acc=0.5283, Val Loss=1.8656, lr=0.0100
[2025-05-05 14:14:06,944][train][INFO] - Epoch 7/100, Val Acc=0.6162, Val Loss=1.4876, lr=0.0100
[2025-05-05 14:14:07,866][train][INFO] - Epoch 6/100, Val Acc=0.4652, Val Loss=1.9748, lr=0.0100
[2025-05-05 14:14:09,397][train][INFO] - Epoch 7/100, Val Acc=0.5347, Val Loss=1.8302, lr=0.0100
[2025-05-05 14:14:15,003][train][INFO] - Epoch 8/100, Val Acc=0.5950, Val Loss=1.6438, lr=0.0100
[2025-05-05 14:14:15,957][train][INFO] - Epoch 7/100, Val Acc=0.4782, Val Loss=1.9643, lr=0.0100
[2025-05-05 14:14:17,038][train][INFO] - Epoch 8/100, Val Acc=0.5859, Val Loss=1.5801, lr=0.0100
[2025-05-05 14:14:22,680][train][INFO] - Epoch 9/100, Val Acc=0.6101, Val Loss=1.5373, lr=0.0100
[2025-05-05 14:14:23,182][train][INFO] - Epoch 8/100, Val Acc=0.5280, Val Loss=1.7707, lr=0.0100
[2025-05-05 14:14:24,188][train][INFO] - Epoch 9/100, Val Acc=0.5766, Val Loss=1.6506, lr=0.0100
[2025-05-05 14:14:30,698][train][INFO] - Epoch 9/100, Val Acc=0.5036, Val Loss=1.9350, lr=0.0100
[2025-05-05 14:14:30,934][train][INFO] - Epoch 10/100, Val Acc=0.6084, Val Loss=1.5730, lr=0.0100
[2025-05-05 14:14:31,057][train][INFO] - Epoch 10/100, Val Acc=0.6010, Val Loss=1.5615, lr=0.0100
[2025-05-05 14:14:38,438][train][INFO] - Epoch 11/100, Val Acc=0.6368, Val Loss=1.4474, lr=0.0100
[2025-05-05 14:14:38,542][train][INFO] - Epoch 11/100, Val Acc=0.6089, Val Loss=1.5011, lr=0.0100
[2025-05-05 14:14:38,624][train][INFO] - Epoch 10/100, Val Acc=0.5359, Val Loss=1.7538, lr=0.0100
[2025-05-05 14:14:45,676][train][INFO] - Epoch 12/100, Val Acc=0.5922, Val Loss=1.6466, lr=0.0100
[2025-05-05 14:14:46,098][train][INFO] - Epoch 11/100, Val Acc=0.5591, Val Loss=1.6914, lr=0.0100
[2025-05-05 14:14:46,273][train][INFO] - Epoch 12/100, Val Acc=0.6155, Val Loss=1.5780, lr=0.0100
[2025-05-05 14:14:53,362][train][INFO] - Epoch 13/100, Val Acc=0.6036, Val Loss=1.5865, lr=0.0100
[2025-05-05 14:14:53,694][train][INFO] - Epoch 12/100, Val Acc=0.5534, Val Loss=1.6936, lr=0.0100
[2025-05-05 14:14:54,038][train][INFO] - Epoch 13/100, Val Acc=0.6244, Val Loss=1.5574, lr=0.0100
[2025-05-05 14:15:00,607][train][INFO] - Epoch 14/100, Val Acc=0.6130, Val Loss=1.5642, lr=0.0100
[2025-05-05 14:15:01,289][train][INFO] - Epoch 13/100, Val Acc=0.5422, Val Loss=1.7611, lr=0.0100
[2025-05-05 14:15:01,524][train][INFO] - Epoch 14/100, Val Acc=0.6376, Val Loss=1.4839, lr=0.0100
[2025-05-05 14:15:08,118][train][INFO] - Epoch 15/100, Val Acc=0.6110, Val Loss=1.5924, lr=0.0100
[2025-05-05 14:15:09,272][train][INFO] - Epoch 15/100, Val Acc=0.6270, Val Loss=1.5513, lr=0.0100
[2025-05-05 14:15:09,343][train][INFO] - Epoch 14/100, Val Acc=0.5712, Val Loss=1.6550, lr=0.0100
[2025-05-05 14:15:15,175][train][INFO] - Epoch 16/100, Val Acc=0.5992, Val Loss=1.6565, lr=0.0100
[2025-05-05 14:15:16,948][train][INFO] - Epoch 15/100, Val Acc=0.5647, Val Loss=1.6498, lr=0.0100
[2025-05-05 14:15:17,214][train][INFO] - Epoch 16/100, Val Acc=0.6368, Val Loss=1.4887, lr=0.0100
[2025-05-05 14:15:22,711][train][INFO] - Epoch 17/100, Val Acc=0.6250, Val Loss=1.4985, lr=0.0100
[2025-05-05 14:15:24,527][train][INFO] - Epoch 16/100, Val Acc=0.5761, Val Loss=1.6378, lr=0.0100
[2025-05-05 14:15:25,335][train][INFO] - Epoch 17/100, Val Acc=0.6311, Val Loss=1.5867, lr=0.0100
[2025-05-05 14:15:30,054][train][INFO] - Epoch 18/100, Val Acc=0.6260, Val Loss=1.5538, lr=0.0100
[2025-05-05 14:15:32,361][train][INFO] - Epoch 17/100, Val Acc=0.5694, Val Loss=1.7246, lr=0.0100
[2025-05-05 14:15:32,673][train][INFO] - Epoch 18/100, Val Acc=0.6429, Val Loss=1.5122, lr=0.0100
[2025-05-05 14:15:37,705][train][INFO] - Epoch 19/100, Val Acc=0.6159, Val Loss=1.5863, lr=0.0100
[2025-05-05 14:15:40,191][train][INFO] - Epoch 18/100, Val Acc=0.5727, Val Loss=1.7548, lr=0.0100
[2025-05-05 14:15:40,421][train][INFO] - Epoch 19/100, Val Acc=0.6503, Val Loss=1.4388, lr=0.0100
[2025-05-05 14:15:45,761][train][INFO] - Epoch 20/100, Val Acc=0.6368, Val Loss=1.5093, lr=0.0100
[2025-05-05 14:15:48,155][train][INFO] - Epoch 19/100, Val Acc=0.5976, Val Loss=1.5499, lr=0.0100
[2025-05-05 14:15:48,289][train][INFO] - Epoch 20/100, Val Acc=0.6447, Val Loss=1.5121, lr=0.0100
[2025-05-05 14:15:53,461][train][INFO] - Epoch 21/100, Val Acc=0.6289, Val Loss=1.5634, lr=0.0100
[2025-05-05 14:15:55,315][train][INFO] - Epoch 20/100, Val Acc=0.5944, Val Loss=1.5749, lr=0.0100
[2025-05-05 14:15:56,207][train][INFO] - Epoch 21/100, Val Acc=0.6501, Val Loss=1.4567, lr=0.0100
[2025-05-05 14:16:01,193][train][INFO] - Epoch 22/100, Val Acc=0.6387, Val Loss=1.5073, lr=0.0100
[2025-05-05 14:16:02,577][train][INFO] - Epoch 21/100, Val Acc=0.6005, Val Loss=1.5581, lr=0.0100
[2025-05-05 14:16:04,287][train][INFO] - Epoch 22/100, Val Acc=0.6182, Val Loss=1.6556, lr=0.0100
[2025-05-05 14:16:08,708][train][INFO] - Epoch 23/100, Val Acc=0.6111, Val Loss=1.6496, lr=0.0100
[2025-05-05 14:16:10,430][train][INFO] - Epoch 22/100, Val Acc=0.5676, Val Loss=1.8065, lr=0.0100
[2025-05-05 14:16:11,839][train][INFO] - Epoch 23/100, Val Acc=0.6429, Val Loss=1.5438, lr=0.0100
[2025-05-05 14:16:15,965][train][INFO] - Epoch 24/100, Val Acc=0.6215, Val Loss=1.6173, lr=0.0100
[2025-05-05 14:16:18,109][train][INFO] - Epoch 23/100, Val Acc=0.6143, Val Loss=1.4916, lr=0.0100
[2025-05-05 14:16:19,484][train][INFO] - Epoch 24/100, Val Acc=0.6590, Val Loss=1.4446, lr=0.0100
[2025-05-05 14:16:23,674][train][INFO] - Epoch 25/100, Val Acc=0.6293, Val Loss=1.5588, lr=0.0100
[2025-05-05 14:16:25,773][train][INFO] - Epoch 24/100, Val Acc=0.6160, Val Loss=1.5620, lr=0.0100
[2025-05-05 14:16:26,837][train][INFO] - Epoch 25/100, Val Acc=0.6476, Val Loss=1.4919, lr=0.0100
[2025-05-05 14:16:31,190][train][INFO] - Epoch 26/100, Val Acc=0.6272, Val Loss=1.6077, lr=0.0100
[2025-05-05 14:16:33,570][train][INFO] - Epoch 25/100, Val Acc=0.6039, Val Loss=1.6388, lr=0.0100
[2025-05-05 14:16:34,263][train][INFO] - Epoch 26/100, Val Acc=0.6420, Val Loss=1.5597, lr=0.0100
[2025-05-05 14:16:38,416][train][INFO] - Epoch 27/100, Val Acc=0.6273, Val Loss=1.6279, lr=0.0100
[2025-05-05 14:16:41,366][train][INFO] - Epoch 26/100, Val Acc=0.6033, Val Loss=1.6363, lr=0.0100
[2025-05-05 14:16:41,725][train][INFO] - Epoch 27/100, Val Acc=0.6429, Val Loss=1.5432, lr=0.0100
[2025-05-05 14:16:45,702][train][INFO] - Epoch 28/100, Val Acc=0.6327, Val Loss=1.6055, lr=0.0100
[2025-05-05 14:16:49,075][train][INFO] - Epoch 27/100, Val Acc=0.5934, Val Loss=1.7445, lr=0.0100
[2025-05-05 14:16:49,728][train][INFO] - Epoch 28/100, Val Acc=0.6444, Val Loss=1.5682, lr=0.0100
[2025-05-05 14:16:52,999][train][INFO] - Epoch 29/100, Val Acc=0.6412, Val Loss=1.5198, lr=0.0100
[2025-05-05 14:16:56,525][train][INFO] - Epoch 28/100, Val Acc=0.6271, Val Loss=1.5145, lr=0.0100
[2025-05-05 14:16:57,691][train][INFO] - Epoch 29/100, Val Acc=0.6394, Val Loss=1.5485, lr=0.0100
[2025-05-05 14:17:00,422][train][INFO] - Epoch 30/100, Val Acc=0.6466, Val Loss=1.5375, lr=0.0100
[2025-05-05 14:17:04,666][train][INFO] - Epoch 29/100, Val Acc=0.5993, Val Loss=1.7208, lr=0.0100
[2025-05-05 14:17:05,866][train][INFO] - Epoch 30/100, Val Acc=0.6397, Val Loss=1.5599, lr=0.0100
[2025-05-05 14:17:07,654][train][INFO] - Epoch 31/100, Val Acc=0.6327, Val Loss=1.6095, lr=0.0100
[2025-05-05 14:17:12,470][train][INFO] - Epoch 30/100, Val Acc=0.6072, Val Loss=1.6033, lr=0.0100
[2025-05-05 14:17:13,568][train][INFO] - Epoch 31/100, Val Acc=0.6432, Val Loss=1.5711, lr=0.0100
[2025-05-05 14:17:14,925][train][INFO] - Epoch 32/100, Val Acc=0.6433, Val Loss=1.5484, lr=0.0100
[2025-05-05 14:17:20,080][train][INFO] - Epoch 31/100, Val Acc=0.6156, Val Loss=1.5919, lr=0.0100
[2025-05-05 14:17:21,566][train][INFO] - Epoch 32/100, Val Acc=0.6553, Val Loss=1.5149, lr=0.0100
[2025-05-05 14:17:22,515][train][INFO] - Epoch 33/100, Val Acc=0.6306, Val Loss=1.6068, lr=0.0100
[2025-05-05 14:17:27,482][train][INFO] - Epoch 32/100, Val Acc=0.6165, Val Loss=1.5961, lr=0.0100
[2025-05-05 14:17:29,289][train][INFO] - Epoch 33/100, Val Acc=0.6464, Val Loss=1.5382, lr=0.0100
[2025-05-05 14:17:29,347][train][INFO] - Epoch 34/100, Val Acc=0.6425, Val Loss=1.5678, lr=0.0100
[2025-05-05 14:17:35,003][train][INFO] - Epoch 33/100, Val Acc=0.6277, Val Loss=1.5790, lr=0.0100
[2025-05-05 14:17:36,870][train][INFO] - Epoch 35/100, Val Acc=0.6394, Val Loss=1.5941, lr=0.0100
[2025-05-05 14:17:37,154][train][INFO] - Epoch 34/100, Val Acc=0.6416, Val Loss=1.5724, lr=0.0100
[2025-05-05 14:17:42,866][train][INFO] - Epoch 34/100, Val Acc=0.6255, Val Loss=1.5593, lr=0.0100
[2025-05-05 14:17:44,730][train][INFO] - Epoch 36/100, Val Acc=0.6303, Val Loss=1.6240, lr=0.0100
[2025-05-05 14:17:45,362][train][INFO] - Epoch 35/100, Val Acc=0.6436, Val Loss=1.5976, lr=0.0100
[2025-05-05 14:17:51,031][train][INFO] - Epoch 35/100, Val Acc=0.6246, Val Loss=1.6329, lr=0.0100
[2025-05-05 14:17:52,429][train][INFO] - Epoch 37/100, Val Acc=0.6348, Val Loss=1.6449, lr=0.0100
[2025-05-05 14:17:52,587][train][INFO] - Epoch 36/100, Val Acc=0.6483, Val Loss=1.5729, lr=0.0100
[2025-05-05 14:17:58,619][train][INFO] - Epoch 36/100, Val Acc=0.6115, Val Loss=1.6608, lr=0.0100
[2025-05-05 14:17:59,376][train][INFO] - Epoch 38/100, Val Acc=0.6446, Val Loss=1.5713, lr=0.0100
[2025-05-05 14:18:00,742][train][INFO] - Epoch 37/100, Val Acc=0.6545, Val Loss=1.5314, lr=0.0100
[2025-05-05 14:18:06,340][train][INFO] - Epoch 37/100, Val Acc=0.6124, Val Loss=1.6762, lr=0.0100
[2025-05-05 14:18:06,718][train][INFO] - Epoch 39/100, Val Acc=0.6420, Val Loss=1.6029, lr=0.0100
[2025-05-05 14:18:08,533][train][INFO] - Epoch 38/100, Val Acc=0.6297, Val Loss=1.7314, lr=0.0100
[2025-05-05 14:18:14,214][train][INFO] - Epoch 38/100, Val Acc=0.6327, Val Loss=1.5198, lr=0.0100
[2025-05-05 14:18:14,469][train][INFO] - Epoch 40/100, Val Acc=0.6386, Val Loss=1.6069, lr=0.0100
[2025-05-05 14:18:16,429][train][INFO] - Epoch 39/100, Val Acc=0.6464, Val Loss=1.6116, lr=0.0100
[2025-05-05 14:18:21,630][train][INFO] - Epoch 41/100, Val Acc=0.6439, Val Loss=1.6088, lr=0.0100
[2025-05-05 14:18:21,937][train][INFO] - Epoch 39/100, Val Acc=0.6176, Val Loss=1.6937, lr=0.0100
[2025-05-05 14:18:24,033][train][INFO] - Epoch 40/100, Val Acc=0.6559, Val Loss=1.5331, lr=0.0100
[2025-05-05 14:18:28,765][train][INFO] - Epoch 42/100, Val Acc=0.6219, Val Loss=1.6998, lr=0.0100
[2025-05-05 14:18:29,572][train][INFO] - Epoch 40/100, Val Acc=0.6135, Val Loss=1.6814, lr=0.0100
[2025-05-05 14:18:32,019][train][INFO] - Epoch 41/100, Val Acc=0.6492, Val Loss=1.5879, lr=0.0100
[2025-05-05 14:18:36,275][train][INFO] - Epoch 43/100, Val Acc=0.6423, Val Loss=1.6399, lr=0.0100
[2025-05-05 14:18:36,926][train][INFO] - Epoch 41/100, Val Acc=0.6220, Val Loss=1.6187, lr=0.0100
[2025-05-05 14:18:39,729][train][INFO] - Epoch 42/100, Val Acc=0.6482, Val Loss=1.6061, lr=0.0100
[2025-05-05 14:18:43,978][train][INFO] - Epoch 44/100, Val Acc=0.6280, Val Loss=1.6860, lr=0.0100
[2025-05-05 14:18:44,194][train][INFO] - Epoch 42/100, Val Acc=0.6233, Val Loss=1.6436, lr=0.0100
[2025-05-05 14:18:47,243][train][INFO] - Epoch 43/100, Val Acc=0.6402, Val Loss=1.6533, lr=0.0100
[2025-05-05 14:18:51,500][train][INFO] - Epoch 45/100, Val Acc=0.6340, Val Loss=1.6459, lr=0.0100
[2025-05-05 14:18:51,740][train][INFO] - Epoch 43/100, Val Acc=0.6127, Val Loss=1.6797, lr=0.0100
[2025-05-05 14:18:54,948][train][INFO] - Epoch 44/100, Val Acc=0.6341, Val Loss=1.7037, lr=0.0100
[2025-05-05 14:18:58,996][train][INFO] - Epoch 46/100, Val Acc=0.6413, Val Loss=1.6074, lr=0.0100
[2025-05-05 14:18:59,281][train][INFO] - Epoch 44/100, Val Acc=0.6217, Val Loss=1.6428, lr=0.0100
[2025-05-05 14:19:02,739][train][INFO] - Epoch 45/100, Val Acc=0.6469, Val Loss=1.5789, lr=0.0100
[2025-05-05 14:19:06,314][train][INFO] - Epoch 45/100, Val Acc=0.6198, Val Loss=1.6318, lr=0.0100
[2025-05-05 14:19:06,585][train][INFO] - Epoch 47/100, Val Acc=0.6336, Val Loss=1.6733, lr=0.0100
[2025-05-05 14:19:10,359][train][INFO] - Epoch 46/100, Val Acc=0.6390, Val Loss=1.7001, lr=0.0100
[2025-05-05 14:19:14,339][train][INFO] - Epoch 46/100, Val Acc=0.6274, Val Loss=1.6337, lr=0.0100
[2025-05-05 14:19:14,509][train][INFO] - Epoch 48/100, Val Acc=0.6446, Val Loss=1.5907, lr=0.0100
[2025-05-05 14:19:17,445][train][INFO] - Epoch 47/100, Val Acc=0.6412, Val Loss=1.6508, lr=0.0100
[2025-05-05 14:19:21,922][train][INFO] - Epoch 47/100, Val Acc=0.6168, Val Loss=1.6955, lr=0.0100
[2025-05-05 14:19:22,133][train][INFO] - Epoch 49/100, Val Acc=0.6470, Val Loss=1.5903, lr=0.0100
[2025-05-05 14:19:24,971][train][INFO] - Epoch 48/100, Val Acc=0.6526, Val Loss=1.5607, lr=0.0100
[2025-05-05 14:19:28,768][train][INFO] - Epoch 50/100, Val Acc=0.6465, Val Loss=1.5903, lr=0.0100
[2025-05-05 14:19:29,694][train][INFO] - Epoch 48/100, Val Acc=0.6334, Val Loss=1.5860, lr=0.0100
[2025-05-05 14:19:32,885][train][INFO] - Epoch 49/100, Val Acc=0.6560, Val Loss=1.5794, lr=0.0100
[2025-05-05 14:19:36,575][train][INFO] - Epoch 51/100, Val Acc=0.6369, Val Loss=1.6533, lr=0.0100
[2025-05-05 14:19:37,282][train][INFO] - Epoch 49/100, Val Acc=0.6294, Val Loss=1.6062, lr=0.0100
[2025-05-05 14:19:40,674][train][INFO] - Epoch 50/100, Val Acc=0.6469, Val Loss=1.6455, lr=0.0100
[2025-05-05 14:19:43,698][train][INFO] - Epoch 52/100, Val Acc=0.6307, Val Loss=1.6962, lr=0.0100
[2025-05-05 14:19:45,046][train][INFO] - Epoch 50/100, Val Acc=0.6342, Val Loss=1.5930, lr=0.0100
[2025-05-05 14:19:48,395][train][INFO] - Epoch 51/100, Val Acc=0.6387, Val Loss=1.6781, lr=0.0100
[2025-05-05 14:19:51,099][train][INFO] - Epoch 53/100, Val Acc=0.6374, Val Loss=1.6606, lr=0.0100
[2025-05-05 14:19:52,525][train][INFO] - Epoch 51/100, Val Acc=0.6248, Val Loss=1.6625, lr=0.0100
[2025-05-05 14:19:56,041][train][INFO] - Epoch 52/100, Val Acc=0.6422, Val Loss=1.6613, lr=0.0100
[2025-05-05 14:19:58,995][train][INFO] - Epoch 54/100, Val Acc=0.6352, Val Loss=1.6768, lr=0.0100
[2025-05-05 14:20:00,377][train][INFO] - Epoch 52/100, Val Acc=0.6223, Val Loss=1.6883, lr=0.0100
[2025-05-05 14:20:04,060][train][INFO] - Epoch 53/100, Val Acc=0.6386, Val Loss=1.6429, lr=0.0100
[2025-05-05 14:20:06,302][train][INFO] - Epoch 55/100, Val Acc=0.6336, Val Loss=1.7275, lr=0.0100
[2025-05-05 14:20:08,324][train][INFO] - Epoch 53/100, Val Acc=0.6350, Val Loss=1.6011, lr=0.0100
[2025-05-05 14:20:11,836][train][INFO] - Epoch 54/100, Val Acc=0.6437, Val Loss=1.6218, lr=0.0100
[2025-05-05 14:20:13,626][train][INFO] - Epoch 56/100, Val Acc=0.6301, Val Loss=1.6911, lr=0.0100
[2025-05-05 14:20:15,246][train][INFO] - Epoch 54/100, Val Acc=0.6203, Val Loss=1.7305, lr=0.0100
[2025-05-05 14:20:19,470][train][INFO] - Epoch 55/100, Val Acc=0.6420, Val Loss=1.6428, lr=0.0100
[2025-05-05 14:20:20,992][train][INFO] - Epoch 57/100, Val Acc=0.6364, Val Loss=1.7036, lr=0.0100
[2025-05-05 14:20:22,896][train][INFO] - Epoch 55/100, Val Acc=0.6281, Val Loss=1.6972, lr=0.0100
[2025-05-05 14:20:27,046][train][INFO] - Epoch 56/100, Val Acc=0.6469, Val Loss=1.6637, lr=0.0100
[2025-05-05 14:20:28,336][train][INFO] - Epoch 58/100, Val Acc=0.6195, Val Loss=1.7899, lr=0.0100
[2025-05-05 14:20:30,659][train][INFO] - Epoch 56/100, Val Acc=0.6283, Val Loss=1.6679, lr=0.0100
[2025-05-05 14:20:35,052][train][INFO] - Epoch 57/100, Val Acc=0.6391, Val Loss=1.6646, lr=0.0100
[2025-05-05 14:20:35,246][train][INFO] - Epoch 59/100, Val Acc=0.6369, Val Loss=1.6542, lr=0.0100
[2025-05-05 14:20:38,108][train][INFO] - Epoch 57/100, Val Acc=0.6189, Val Loss=1.7435, lr=0.0100
[2025-05-05 14:20:42,880][train][INFO] - Epoch 58/100, Val Acc=0.6600, Val Loss=1.6111, lr=0.0100
[2025-05-05 14:20:42,943][train][INFO] - Epoch 60/100, Val Acc=0.6361, Val Loss=1.7176, lr=0.0100
[2025-05-05 14:20:45,998][train][INFO] - Epoch 58/100, Val Acc=0.6154, Val Loss=1.7788, lr=0.0100
[2025-05-05 14:20:50,301][train][INFO] - Epoch 59/100, Val Acc=0.6454, Val Loss=1.6256, lr=0.0100
[2025-05-05 14:20:50,479][train][INFO] - Epoch 61/100, Val Acc=0.7002, Val Loss=1.3470, lr=0.0010
[2025-05-05 14:20:53,531][train][INFO] - Epoch 59/100, Val Acc=0.6274, Val Loss=1.6840, lr=0.0100
[2025-05-05 14:20:57,870][train][INFO] - Epoch 60/100, Val Acc=0.6594, Val Loss=1.5858, lr=0.0100
[2025-05-05 14:20:58,075][train][INFO] - Epoch 62/100, Val Acc=0.7021, Val Loss=1.3435, lr=0.0010
[2025-05-05 14:21:01,431][train][INFO] - Epoch 60/100, Val Acc=0.6355, Val Loss=1.6562, lr=0.0100
[2025-05-05 14:21:05,494][train][INFO] - Epoch 61/100, Val Acc=0.7068, Val Loss=1.3268, lr=0.0010
[2025-05-05 14:21:05,563][train][INFO] - Epoch 63/100, Val Acc=0.7037, Val Loss=1.3430, lr=0.0010
[2025-05-05 14:21:09,321][train][INFO] - Epoch 61/100, Val Acc=0.6910, Val Loss=1.3330, lr=0.0010
[2025-05-05 14:21:13,411][train][INFO] - Epoch 62/100, Val Acc=0.7087, Val Loss=1.3174, lr=0.0010
[2025-05-05 14:21:13,572][train][INFO] - Epoch 64/100, Val Acc=0.7071, Val Loss=1.3501, lr=0.0010
[2025-05-05 14:21:17,113][train][INFO] - Epoch 62/100, Val Acc=0.6990, Val Loss=1.3231, lr=0.0010
[2025-05-05 14:21:20,965][train][INFO] - Epoch 65/100, Val Acc=0.7069, Val Loss=1.3532, lr=0.0010
[2025-05-05 14:21:21,329][train][INFO] - Epoch 63/100, Val Acc=0.7128, Val Loss=1.3294, lr=0.0010
[2025-05-05 14:21:24,186][train][INFO] - Epoch 63/100, Val Acc=0.6973, Val Loss=1.3335, lr=0.0010
[2025-05-05 14:21:28,194][train][INFO] - Epoch 66/100, Val Acc=0.7082, Val Loss=1.3601, lr=0.0010
[2025-05-05 14:21:28,967][train][INFO] - Epoch 64/100, Val Acc=0.7140, Val Loss=1.3416, lr=0.0010
[2025-05-05 14:21:31,488][train][INFO] - Epoch 64/100, Val Acc=0.6975, Val Loss=1.3458, lr=0.0010
[2025-05-05 14:21:35,618][train][INFO] - Epoch 67/100, Val Acc=0.7085, Val Loss=1.3621, lr=0.0010
[2025-05-05 14:21:36,756][train][INFO] - Epoch 65/100, Val Acc=0.7142, Val Loss=1.3431, lr=0.0010
[2025-05-05 14:21:38,777][train][INFO] - Epoch 65/100, Val Acc=0.6985, Val Loss=1.3463, lr=0.0010
[2025-05-05 14:21:43,202][train][INFO] - Epoch 68/100, Val Acc=0.7095, Val Loss=1.3662, lr=0.0010
[2025-05-05 14:21:43,989][train][INFO] - Epoch 66/100, Val Acc=0.7149, Val Loss=1.3516, lr=0.0010
[2025-05-05 14:21:46,409][train][INFO] - Epoch 66/100, Val Acc=0.6999, Val Loss=1.3541, lr=0.0010
[2025-05-05 14:21:50,407][train][INFO] - Epoch 69/100, Val Acc=0.7081, Val Loss=1.3731, lr=0.0010
[2025-05-05 14:21:51,728][train][INFO] - Epoch 67/100, Val Acc=0.7155, Val Loss=1.3565, lr=0.0010
[2025-05-05 14:21:53,794][train][INFO] - Epoch 67/100, Val Acc=0.6979, Val Loss=1.3657, lr=0.0010
[2025-05-05 14:21:57,707][train][INFO] - Epoch 70/100, Val Acc=0.7091, Val Loss=1.3775, lr=0.0010
[2025-05-05 14:21:59,272][train][INFO] - Epoch 68/100, Val Acc=0.7154, Val Loss=1.3594, lr=0.0010
[2025-05-05 14:22:01,769][train][INFO] - Epoch 68/100, Val Acc=0.7009, Val Loss=1.3705, lr=0.0010
[2025-05-05 14:22:05,294][train][INFO] - Epoch 71/100, Val Acc=0.7114, Val Loss=1.3812, lr=0.0010
[2025-05-05 14:22:07,322][train][INFO] - Epoch 69/100, Val Acc=0.7164, Val Loss=1.3684, lr=0.0010
[2025-05-05 14:22:09,384][train][INFO] - Epoch 69/100, Val Acc=0.7004, Val Loss=1.3642, lr=0.0010
[2025-05-05 14:22:12,844][train][INFO] - Epoch 72/100, Val Acc=0.7103, Val Loss=1.3815, lr=0.0010
[2025-05-05 14:22:14,810][train][INFO] - Epoch 70/100, Val Acc=0.7155, Val Loss=1.3682, lr=0.0010
[2025-05-05 14:22:16,958][train][INFO] - Epoch 70/100, Val Acc=0.7035, Val Loss=1.3745, lr=0.0010
[2025-05-05 14:22:19,552][train][INFO] - Epoch 73/100, Val Acc=0.7094, Val Loss=1.3795, lr=0.0010
[2025-05-05 14:22:22,484][train][INFO] - Epoch 71/100, Val Acc=0.7160, Val Loss=1.3635, lr=0.0010
[2025-05-05 14:22:24,249][train][INFO] - Epoch 71/100, Val Acc=0.7007, Val Loss=1.3815, lr=0.0010
[2025-05-05 14:22:27,218][train][INFO] - Epoch 74/100, Val Acc=0.7107, Val Loss=1.3922, lr=0.0010
[2025-05-05 14:22:30,335][train][INFO] - Epoch 72/100, Val Acc=0.7162, Val Loss=1.3717, lr=0.0010
[2025-05-05 14:22:31,901][train][INFO] - Epoch 72/100, Val Acc=0.7001, Val Loss=1.3885, lr=0.0010
[2025-05-05 14:22:34,268][train][INFO] - Epoch 75/100, Val Acc=0.7100, Val Loss=1.3973, lr=0.0010
[2025-05-05 14:22:37,781][train][INFO] - Epoch 73/100, Val Acc=0.7153, Val Loss=1.3632, lr=0.0010
[2025-05-05 14:22:39,546][train][INFO] - Epoch 73/100, Val Acc=0.7047, Val Loss=1.3850, lr=0.0010
[2025-05-05 14:22:41,592][train][INFO] - Epoch 76/100, Val Acc=0.7114, Val Loss=1.3910, lr=0.0010
[2025-05-05 14:22:45,402][train][INFO] - Epoch 74/100, Val Acc=0.7159, Val Loss=1.3698, lr=0.0010
[2025-05-05 14:22:46,744][train][INFO] - Epoch 74/100, Val Acc=0.7036, Val Loss=1.3889, lr=0.0010
[2025-05-05 14:22:48,863][train][INFO] - Epoch 77/100, Val Acc=0.7121, Val Loss=1.3958, lr=0.0010
[2025-05-05 14:22:53,305][train][INFO] - Epoch 75/100, Val Acc=0.7170, Val Loss=1.3705, lr=0.0010
[2025-05-05 14:22:54,597][train][INFO] - Epoch 75/100, Val Acc=0.7062, Val Loss=1.3951, lr=0.0010
[2025-05-05 14:22:56,742][train][INFO] - Epoch 78/100, Val Acc=0.7125, Val Loss=1.3950, lr=0.0010
[2025-05-05 14:23:00,993][train][INFO] - Epoch 76/100, Val Acc=0.7181, Val Loss=1.3755, lr=0.0010
[2025-05-05 14:23:02,438][train][INFO] - Epoch 76/100, Val Acc=0.7040, Val Loss=1.4001, lr=0.0010
[2025-05-05 14:23:04,234][train][INFO] - Epoch 79/100, Val Acc=0.7122, Val Loss=1.3974, lr=0.0010
[2025-05-05 14:23:08,140][train][INFO] - Epoch 77/100, Val Acc=0.7160, Val Loss=1.3734, lr=0.0010
[2025-05-05 14:23:09,468][train][INFO] - Epoch 77/100, Val Acc=0.7059, Val Loss=1.4042, lr=0.0010
[2025-05-05 14:23:11,511][train][INFO] - Epoch 80/100, Val Acc=0.7105, Val Loss=1.4005, lr=0.0010
[2025-05-05 14:23:15,896][train][INFO] - Epoch 78/100, Val Acc=0.7201, Val Loss=1.3776, lr=0.0010
[2025-05-05 14:23:16,821][train][INFO] - Epoch 78/100, Val Acc=0.6997, Val Loss=1.4160, lr=0.0010
[2025-05-05 14:23:19,078][train][INFO] - Epoch 81/100, Val Acc=0.7136, Val Loss=1.4006, lr=0.0010
[2025-05-05 14:23:24,054][train][INFO] - Epoch 79/100, Val Acc=0.7011, Val Loss=1.4245, lr=0.0010
[2025-05-05 14:23:24,138][train][INFO] - Epoch 79/100, Val Acc=0.7193, Val Loss=1.3850, lr=0.0010
[2025-05-05 14:23:26,555][train][INFO] - Epoch 82/100, Val Acc=0.7123, Val Loss=1.4073, lr=0.0010
[2025-05-05 14:23:31,837][train][INFO] - Epoch 80/100, Val Acc=0.7013, Val Loss=1.4228, lr=0.0010
[2025-05-05 14:23:31,933][train][INFO] - Epoch 80/100, Val Acc=0.7176, Val Loss=1.3808, lr=0.0010
[2025-05-05 14:23:33,828][train][INFO] - Epoch 83/100, Val Acc=0.7109, Val Loss=1.4145, lr=0.0010
[2025-05-05 14:23:39,511][train][INFO] - Epoch 81/100, Val Acc=0.7028, Val Loss=1.4262, lr=0.0010
[2025-05-05 14:23:39,814][train][INFO] - Epoch 81/100, Val Acc=0.7184, Val Loss=1.3891, lr=0.0010
[2025-05-05 14:23:41,164][train][INFO] - Epoch 84/100, Val Acc=0.7107, Val Loss=1.4185, lr=0.0010
[2025-05-05 14:23:47,240][train][INFO] - Epoch 82/100, Val Acc=0.7023, Val Loss=1.4333, lr=0.0010
[2025-05-05 14:23:47,545][train][INFO] - Epoch 82/100, Val Acc=0.7183, Val Loss=1.3941, lr=0.0010
[2025-05-05 14:23:48,214][train][INFO] - Epoch 85/100, Val Acc=0.7107, Val Loss=1.4082, lr=0.0010
[2025-05-05 14:23:54,698][train][INFO] - Epoch 83/100, Val Acc=0.7021, Val Loss=1.4370, lr=0.0010
[2025-05-05 14:23:55,387][train][INFO] - Epoch 83/100, Val Acc=0.7191, Val Loss=1.3921, lr=0.0010
[2025-05-05 14:23:55,484][train][INFO] - Epoch 86/100, Val Acc=0.7129, Val Loss=1.4149, lr=0.0010
[2025-05-05 14:24:02,591][train][INFO] - Epoch 84/100, Val Acc=0.7019, Val Loss=1.4373, lr=0.0010
[2025-05-05 14:24:02,781][train][INFO] - Epoch 87/100, Val Acc=0.7138, Val Loss=1.4129, lr=0.0010
[2025-05-05 14:24:03,291][train][INFO] - Epoch 84/100, Val Acc=0.7195, Val Loss=1.3931, lr=0.0010
[2025-05-05 14:24:10,041][train][INFO] - Epoch 85/100, Val Acc=0.7025, Val Loss=1.4495, lr=0.0010
[2025-05-05 14:24:10,264][train][INFO] - Epoch 88/100, Val Acc=0.7119, Val Loss=1.4126, lr=0.0010
[2025-05-05 14:24:11,221][train][INFO] - Epoch 85/100, Val Acc=0.7186, Val Loss=1.3925, lr=0.0010
[2025-05-05 14:24:17,478][train][INFO] - Epoch 86/100, Val Acc=0.7018, Val Loss=1.4454, lr=0.0010
[2025-05-05 14:24:17,662][train][INFO] - Epoch 89/100, Val Acc=0.7099, Val Loss=1.4180, lr=0.0010
[2025-05-05 14:24:18,381][train][INFO] - Epoch 86/100, Val Acc=0.7162, Val Loss=1.3899, lr=0.0010
[2025-05-05 14:24:25,607][train][INFO] - Epoch 90/100, Val Acc=0.7139, Val Loss=1.4194, lr=0.0010
[2025-05-05 14:24:25,672][train][INFO] - Epoch 87/100, Val Acc=0.7030, Val Loss=1.4425, lr=0.0010
[2025-05-05 14:24:26,439][train][INFO] - Epoch 87/100, Val Acc=0.7218, Val Loss=1.3910, lr=0.0010
[2025-05-05 14:24:33,502][train][INFO] - Epoch 91/100, Val Acc=0.7134, Val Loss=1.4145, lr=0.0001
[2025-05-05 14:24:33,536][train][INFO] - Epoch 88/100, Val Acc=0.7014, Val Loss=1.4433, lr=0.0010
[2025-05-05 14:24:34,255][train][INFO] - Epoch 88/100, Val Acc=0.7193, Val Loss=1.3921, lr=0.0010
[2025-05-05 14:24:41,130][train][INFO] - Epoch 92/100, Val Acc=0.7120, Val Loss=1.4193, lr=0.0001
[2025-05-05 14:24:41,301][train][INFO] - Epoch 89/100, Val Acc=0.7008, Val Loss=1.4569, lr=0.0010
[2025-05-05 14:24:42,299][train][INFO] - Epoch 89/100, Val Acc=0.7191, Val Loss=1.3985, lr=0.0010
[2025-05-05 14:24:48,128][train][INFO] - Epoch 93/100, Val Acc=0.7129, Val Loss=1.4172, lr=0.0001
[2025-05-05 14:24:48,626][train][INFO] - Epoch 90/100, Val Acc=0.7024, Val Loss=1.4636, lr=0.0010
[2025-05-05 14:24:49,946][train][INFO] - Epoch 90/100, Val Acc=0.7197, Val Loss=1.3965, lr=0.0010
[2025-05-05 14:24:55,677][train][INFO] - Epoch 94/100, Val Acc=0.7127, Val Loss=1.4138, lr=0.0001
[2025-05-05 14:24:55,945][train][INFO] - Epoch 91/100, Val Acc=0.7022, Val Loss=1.4532, lr=0.0001
[2025-05-05 14:24:57,534][train][INFO] - Epoch 91/100, Val Acc=0.7194, Val Loss=1.3901, lr=0.0001
[2025-05-05 14:25:03,098][train][INFO] - Epoch 92/100, Val Acc=0.7027, Val Loss=1.4558, lr=0.0001
[2025-05-05 14:25:03,179][train][INFO] - Epoch 95/100, Val Acc=0.7138, Val Loss=1.4145, lr=0.0001
[2025-05-05 14:25:04,886][train][INFO] - Epoch 92/100, Val Acc=0.7182, Val Loss=1.3956, lr=0.0001
[2025-05-05 14:25:10,247][train][INFO] - Epoch 96/100, Val Acc=0.7140, Val Loss=1.4123, lr=0.0001
[2025-05-05 14:25:10,417][train][INFO] - Epoch 93/100, Val Acc=0.7037, Val Loss=1.4555, lr=0.0001
[2025-05-05 14:25:12,180][train][INFO] - Epoch 93/100, Val Acc=0.7192, Val Loss=1.3929, lr=0.0001
[2025-05-05 14:25:17,657][train][INFO] - Epoch 97/100, Val Acc=0.7119, Val Loss=1.4211, lr=0.0001
[2025-05-05 14:25:18,534][train][INFO] - Epoch 94/100, Val Acc=0.7021, Val Loss=1.4520, lr=0.0001
[2025-05-05 14:25:20,249][train][INFO] - Epoch 94/100, Val Acc=0.7210, Val Loss=1.3907, lr=0.0001
[2025-05-05 14:25:24,580][train][INFO] - Epoch 98/100, Val Acc=0.7124, Val Loss=1.4139, lr=0.0001
[2025-05-05 14:25:25,837][train][INFO] - Epoch 95/100, Val Acc=0.7025, Val Loss=1.4524, lr=0.0001
[2025-05-05 14:25:27,555][train][INFO] - Epoch 95/100, Val Acc=0.7213, Val Loss=1.3924, lr=0.0001
[2025-05-05 14:25:31,725][train][INFO] - Epoch 99/100, Val Acc=0.7122, Val Loss=1.4213, lr=0.0001
[2025-05-05 14:25:33,178][train][INFO] - Epoch 96/100, Val Acc=0.7033, Val Loss=1.4493, lr=0.0001
[2025-05-05 14:25:34,948][train][INFO] - Epoch 96/100, Val Acc=0.7208, Val Loss=1.3905, lr=0.0001
[2025-05-05 14:25:39,407][train][INFO] - Epoch 100/100, Val Acc=0.7130, Val Loss=1.4135, lr=0.0001
[2025-05-05 14:25:40,888][train][INFO] - Epoch 97/100, Val Acc=0.7040, Val Loss=1.4533, lr=0.0001
[2025-05-05 14:25:42,650][train][INFO] - Epoch 97/100, Val Acc=0.7216, Val Loss=1.3928, lr=0.0001
[2025-05-05 14:25:44,539][train][INFO] - After training : Train Acc=0.9972  Val Acc=0.7140
[2025-05-05 14:25:49,139][train][INFO] - Epoch 98/100, Val Acc=0.7036, Val Loss=1.4457, lr=0.0001
[2025-05-05 14:25:50,929][train][INFO] - Epoch 98/100, Val Acc=0.7223, Val Loss=1.3880, lr=0.0001
[2025-05-05 14:25:51,979][Progressive pruning][INFO] - Train acc : 0.01759999990463257   Val acc : 0.015099999494850636
[2025-05-05 14:25:51,979][Progressive pruning][INFO] - Current speed up: 1.49
[2025-05-05 14:25:56,599][train][INFO] - Epoch 99/100, Val Acc=0.7048, Val Loss=1.4540, lr=0.0001
[2025-05-05 14:25:57,131][train][INFO] - Before training : Train Acc=0.0178  Val Acc=0.0151
[2025-05-05 14:25:58,701][train][INFO] - Epoch 99/100, Val Acc=0.7203, Val Loss=1.3955, lr=0.0001
[2025-05-05 14:26:04,258][train][INFO] - Epoch 100/100, Val Acc=0.7033, Val Loss=1.4512, lr=0.0001
[2025-05-05 14:26:04,485][train][INFO] - Epoch 1/140, Val Acc=0.4693, Val Loss=2.1743, lr=0.0100
[2025-05-05 14:26:06,560][train][INFO] - Epoch 100/100, Val Acc=0.7207, Val Loss=1.3929, lr=0.0001
[2025-05-05 14:26:09,470][train][INFO] - After training : Train Acc=0.9880  Val Acc=0.7062
[2025-05-05 14:26:11,819][train][INFO] - Epoch 2/140, Val Acc=0.5123, Val Loss=2.0057, lr=0.0100
[2025-05-05 14:26:11,897][train][INFO] - After training : Train Acc=0.9981  Val Acc=0.7223
[2025-05-05 14:26:17,099][Progressive pruning][INFO] - Train acc : 0.20419999957084656   Val acc : 0.17559999227523804
[2025-05-05 14:26:17,100][Progressive pruning][INFO] - Current speed up: 1.49
[2025-05-05 14:26:19,796][train][INFO] - Epoch 3/140, Val Acc=0.5407, Val Loss=1.9170, lr=0.0100
[2025-05-05 14:26:19,958][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-05 14:26:19,958][Progressive pruning][INFO] - Current speed up: 1.49
[2025-05-05 14:26:22,239][train][INFO] - Before training : Train Acc=0.2036  Val Acc=0.1756
[2025-05-05 14:26:25,432][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 14:26:27,124][train][INFO] - Epoch 4/140, Val Acc=0.5323, Val Loss=2.0262, lr=0.0100
[2025-05-05 14:26:29,652][train][INFO] - Epoch 1/140, Val Acc=0.5955, Val Loss=1.7863, lr=0.0100
[2025-05-05 14:26:33,283][train][INFO] - Epoch 1/140, Val Acc=0.3296, Val Loss=2.5990, lr=0.0100
[2025-05-05 14:26:34,417][train][INFO] - Epoch 5/140, Val Acc=0.5737, Val Loss=1.7203, lr=0.0100
[2025-05-05 14:26:37,040][train][INFO] - Epoch 2/140, Val Acc=0.6044, Val Loss=1.7438, lr=0.0100
[2025-05-05 14:26:40,784][train][INFO] - Epoch 2/140, Val Acc=0.4129, Val Loss=2.2903, lr=0.0100
[2025-05-05 14:26:42,144][train][INFO] - Epoch 6/140, Val Acc=0.5671, Val Loss=1.8565, lr=0.0100
[2025-05-05 14:26:44,838][train][INFO] - Epoch 3/140, Val Acc=0.6159, Val Loss=1.6313, lr=0.0100
[2025-05-05 14:26:48,276][train][INFO] - Epoch 3/140, Val Acc=0.4723, Val Loss=2.0200, lr=0.0100
[2025-05-05 14:26:49,650][train][INFO] - Epoch 7/140, Val Acc=0.5433, Val Loss=1.9864, lr=0.0100
[2025-05-05 14:26:52,580][train][INFO] - Epoch 4/140, Val Acc=0.6071, Val Loss=1.8082, lr=0.0100
[2025-05-05 14:26:56,051][train][INFO] - Epoch 4/140, Val Acc=0.4579, Val Loss=2.2082, lr=0.0100
[2025-05-05 14:26:56,976][train][INFO] - Epoch 8/140, Val Acc=0.5661, Val Loss=1.8416, lr=0.0100
[2025-05-05 14:27:00,322][train][INFO] - Epoch 5/140, Val Acc=0.6077, Val Loss=1.7241, lr=0.0100
[2025-05-05 14:27:04,283][train][INFO] - Epoch 5/140, Val Acc=0.4820, Val Loss=2.0499, lr=0.0100
[2025-05-05 14:27:04,339][train][INFO] - Epoch 9/140, Val Acc=0.5634, Val Loss=1.8271, lr=0.0100
[2025-05-05 14:27:08,051][train][INFO] - Epoch 6/140, Val Acc=0.6028, Val Loss=1.7667, lr=0.0100
[2025-05-05 14:27:12,002][train][INFO] - Epoch 10/140, Val Acc=0.5808, Val Loss=1.7419, lr=0.0100
[2025-05-05 14:27:12,034][train][INFO] - Epoch 6/140, Val Acc=0.5062, Val Loss=1.9796, lr=0.0100
[2025-05-05 14:27:15,717][train][INFO] - Epoch 7/140, Val Acc=0.6123, Val Loss=1.6829, lr=0.0100
[2025-05-05 14:27:19,243][train][INFO] - Epoch 7/140, Val Acc=0.5173, Val Loss=1.9048, lr=0.0100
[2025-05-05 14:27:19,355][train][INFO] - Epoch 11/140, Val Acc=0.5841, Val Loss=1.7379, lr=0.0100
[2025-05-05 14:27:23,006][train][INFO] - Epoch 8/140, Val Acc=0.6102, Val Loss=1.7397, lr=0.0100
[2025-05-05 14:27:26,781][train][INFO] - Epoch 8/140, Val Acc=0.5275, Val Loss=1.9541, lr=0.0100
[2025-05-05 14:27:26,967][train][INFO] - Epoch 12/140, Val Acc=0.5883, Val Loss=1.7551, lr=0.0100
[2025-05-05 14:27:30,713][train][INFO] - Epoch 9/140, Val Acc=0.6150, Val Loss=1.7203, lr=0.0100
[2025-05-05 14:27:34,764][train][INFO] - Epoch 13/140, Val Acc=0.5835, Val Loss=1.7742, lr=0.0100
[2025-05-05 14:27:35,045][train][INFO] - Epoch 9/140, Val Acc=0.5284, Val Loss=1.8918, lr=0.0100
[2025-05-05 14:27:38,509][train][INFO] - Epoch 10/140, Val Acc=0.6120, Val Loss=1.7501, lr=0.0100
[2025-05-05 14:27:41,888][train][INFO] - Epoch 14/140, Val Acc=0.5620, Val Loss=1.8960, lr=0.0100
[2025-05-05 14:27:42,879][train][INFO] - Epoch 10/140, Val Acc=0.5461, Val Loss=1.8393, lr=0.0100
[2025-05-05 14:27:46,748][train][INFO] - Epoch 11/140, Val Acc=0.6183, Val Loss=1.7131, lr=0.0100
[2025-05-05 14:27:49,470][train][INFO] - Epoch 15/140, Val Acc=0.5616, Val Loss=1.9167, lr=0.0100
[2025-05-05 14:27:50,833][train][INFO] - Epoch 11/140, Val Acc=0.5440, Val Loss=1.8394, lr=0.0100
[2025-05-05 14:27:54,044][train][INFO] - Epoch 12/140, Val Acc=0.6270, Val Loss=1.6189, lr=0.0100
[2025-05-05 14:27:56,937][train][INFO] - Epoch 16/140, Val Acc=0.5800, Val Loss=1.8274, lr=0.0100
[2025-05-05 14:27:58,717][train][INFO] - Epoch 12/140, Val Acc=0.5340, Val Loss=1.8725, lr=0.0100
[2025-05-05 14:28:01,552][train][INFO] - Epoch 13/140, Val Acc=0.6009, Val Loss=1.8232, lr=0.0100
[2025-05-05 14:28:04,957][train][INFO] - Epoch 17/140, Val Acc=0.5822, Val Loss=1.8435, lr=0.0100
[2025-05-05 14:28:06,649][train][INFO] - Epoch 13/140, Val Acc=0.5300, Val Loss=2.0224, lr=0.0100
[2025-05-05 14:28:08,893][train][INFO] - Epoch 14/140, Val Acc=0.6191, Val Loss=1.7443, lr=0.0100
[2025-05-05 14:28:12,712][train][INFO] - Epoch 18/140, Val Acc=0.5721, Val Loss=1.8858, lr=0.0100
[2025-05-05 14:28:14,866][train][INFO] - Epoch 14/140, Val Acc=0.5593, Val Loss=1.7887, lr=0.0100
[2025-05-05 14:28:16,807][train][INFO] - Epoch 15/140, Val Acc=0.5896, Val Loss=1.9037, lr=0.0100
[2025-05-05 14:28:19,910][train][INFO] - Epoch 19/140, Val Acc=0.5756, Val Loss=1.8605, lr=0.0100
[2025-05-05 14:28:22,280][train][INFO] - Epoch 15/140, Val Acc=0.5657, Val Loss=1.7628, lr=0.0100
[2025-05-05 14:28:24,495][train][INFO] - Epoch 16/140, Val Acc=0.6079, Val Loss=1.8159, lr=0.0100
[2025-05-05 14:28:27,620][train][INFO] - Epoch 20/140, Val Acc=0.5890, Val Loss=1.7838, lr=0.0100
[2025-05-05 14:28:29,794][train][INFO] - Epoch 16/140, Val Acc=0.5483, Val Loss=1.9263, lr=0.0100
[2025-05-05 14:28:31,188][train][INFO] - Epoch 17/140, Val Acc=0.6223, Val Loss=1.7074, lr=0.0100
[2025-05-05 14:28:35,259][train][INFO] - Epoch 21/140, Val Acc=0.5732, Val Loss=1.9619, lr=0.0100
[2025-05-05 14:28:37,388][train][INFO] - Epoch 17/140, Val Acc=0.5720, Val Loss=1.7140, lr=0.0100
[2025-05-05 14:28:38,964][train][INFO] - Epoch 18/140, Val Acc=0.6082, Val Loss=1.8015, lr=0.0100
[2025-05-05 14:28:42,574][train][INFO] - Epoch 22/140, Val Acc=0.5908, Val Loss=1.7767, lr=0.0100
[2025-05-05 14:28:45,415][train][INFO] - Epoch 18/140, Val Acc=0.5562, Val Loss=1.7931, lr=0.0100
[2025-05-05 14:28:46,710][train][INFO] - Epoch 19/140, Val Acc=0.6176, Val Loss=1.7478, lr=0.0100
[2025-05-05 14:28:49,889][train][INFO] - Epoch 23/140, Val Acc=0.5850, Val Loss=1.8272, lr=0.0100
[2025-05-05 14:28:53,181][train][INFO] - Epoch 19/140, Val Acc=0.5623, Val Loss=1.8617, lr=0.0100
[2025-05-05 14:28:54,463][train][INFO] - Epoch 20/140, Val Acc=0.6191, Val Loss=1.7664, lr=0.0100
[2025-05-05 14:28:57,473][train][INFO] - Epoch 24/140, Val Acc=0.5755, Val Loss=1.9246, lr=0.0100
[2025-05-05 14:29:01,034][train][INFO] - Epoch 20/140, Val Acc=0.5437, Val Loss=1.9912, lr=0.0100
[2025-05-05 14:29:02,406][train][INFO] - Epoch 21/140, Val Acc=0.6106, Val Loss=1.8145, lr=0.0100
[2025-05-05 14:29:04,807][train][INFO] - Epoch 25/140, Val Acc=0.6117, Val Loss=1.7100, lr=0.0100
[2025-05-05 14:29:08,648][train][INFO] - Epoch 21/140, Val Acc=0.5740, Val Loss=1.7931, lr=0.0100
[2025-05-05 14:29:10,246][train][INFO] - Epoch 22/140, Val Acc=0.6247, Val Loss=1.7073, lr=0.0100
[2025-05-05 14:29:12,166][train][INFO] - Epoch 26/140, Val Acc=0.5632, Val Loss=1.9548, lr=0.0100
[2025-05-05 14:29:16,591][train][INFO] - Epoch 22/140, Val Acc=0.5583, Val Loss=1.8666, lr=0.0100
[2025-05-05 14:29:17,584][train][INFO] - Epoch 23/140, Val Acc=0.5917, Val Loss=1.8644, lr=0.0100
[2025-05-05 14:29:19,460][train][INFO] - Epoch 27/140, Val Acc=0.6021, Val Loss=1.7491, lr=0.0100
[2025-05-05 14:29:24,242][train][INFO] - Epoch 23/140, Val Acc=0.5718, Val Loss=1.8006, lr=0.0100
[2025-05-05 14:29:24,871][train][INFO] - Epoch 24/140, Val Acc=0.6240, Val Loss=1.6968, lr=0.0100
[2025-05-05 14:29:26,292][train][INFO] - Epoch 28/140, Val Acc=0.5728, Val Loss=1.9406, lr=0.0100
[2025-05-05 14:29:31,830][train][INFO] - Epoch 24/140, Val Acc=0.5688, Val Loss=1.7970, lr=0.0100
[2025-05-05 14:29:32,151][train][INFO] - Epoch 25/140, Val Acc=0.6169, Val Loss=1.7874, lr=0.0100
[2025-05-05 14:29:33,772][train][INFO] - Epoch 29/140, Val Acc=0.6056, Val Loss=1.7375, lr=0.0100
[2025-05-05 14:29:39,694][train][INFO] - Epoch 25/140, Val Acc=0.5793, Val Loss=1.7769, lr=0.0100
[2025-05-05 14:29:39,767][train][INFO] - Epoch 26/140, Val Acc=0.6148, Val Loss=1.7712, lr=0.0100
[2025-05-05 14:29:40,916][train][INFO] - Epoch 30/140, Val Acc=0.5925, Val Loss=1.8314, lr=0.0100
[2025-05-05 14:29:47,013][train][INFO] - Epoch 27/140, Val Acc=0.6157, Val Loss=1.8113, lr=0.0100
[2025-05-05 14:29:47,092][train][INFO] - Epoch 26/140, Val Acc=0.5754, Val Loss=1.7726, lr=0.0100
[2025-05-05 14:29:48,385][train][INFO] - Epoch 31/140, Val Acc=0.5763, Val Loss=1.9512, lr=0.0100
[2025-05-05 14:29:55,010][train][INFO] - Epoch 28/140, Val Acc=0.6305, Val Loss=1.6890, lr=0.0100
[2025-05-05 14:29:55,256][train][INFO] - Epoch 27/140, Val Acc=0.5933, Val Loss=1.6975, lr=0.0100
[2025-05-05 14:29:56,125][train][INFO] - Epoch 32/140, Val Acc=0.5972, Val Loss=1.7843, lr=0.0100
[2025-05-05 14:30:02,677][train][INFO] - Epoch 29/140, Val Acc=0.6172, Val Loss=1.7774, lr=0.0100
[2025-05-05 14:30:03,076][train][INFO] - Epoch 33/140, Val Acc=0.5887, Val Loss=1.8328, lr=0.0100
[2025-05-05 14:30:03,294][train][INFO] - Epoch 28/140, Val Acc=0.5745, Val Loss=1.7967, lr=0.0100
[2025-05-05 14:30:10,131][train][INFO] - Epoch 34/140, Val Acc=0.5868, Val Loss=1.8610, lr=0.0100
[2025-05-05 14:30:10,254][train][INFO] - Epoch 30/140, Val Acc=0.6267, Val Loss=1.7881, lr=0.0100
[2025-05-05 14:30:11,322][train][INFO] - Epoch 29/140, Val Acc=0.5881, Val Loss=1.7385, lr=0.0100
[2025-05-05 14:30:18,123][train][INFO] - Epoch 35/140, Val Acc=0.6004, Val Loss=1.7655, lr=0.0100
[2025-05-05 14:30:18,282][train][INFO] - Epoch 31/140, Val Acc=0.6242, Val Loss=1.7266, lr=0.0100
[2025-05-05 14:30:19,152][train][INFO] - Epoch 30/140, Val Acc=0.5847, Val Loss=1.7709, lr=0.0100
[2025-05-05 14:30:25,570][train][INFO] - Epoch 32/140, Val Acc=0.6370, Val Loss=1.6529, lr=0.0100
[2025-05-05 14:30:25,913][train][INFO] - Epoch 36/140, Val Acc=0.5889, Val Loss=1.8448, lr=0.0100
[2025-05-05 14:30:27,126][train][INFO] - Epoch 31/140, Val Acc=0.5693, Val Loss=1.8933, lr=0.0100
[2025-05-05 14:30:33,437][train][INFO] - Epoch 33/140, Val Acc=0.6245, Val Loss=1.7416, lr=0.0100
[2025-05-05 14:30:33,523][train][INFO] - Epoch 37/140, Val Acc=0.6036, Val Loss=1.8081, lr=0.0100
[2025-05-05 14:30:35,170][train][INFO] - Epoch 32/140, Val Acc=0.5857, Val Loss=1.7079, lr=0.0100
[2025-05-05 14:30:40,649][train][INFO] - Epoch 38/140, Val Acc=0.6001, Val Loss=1.8081, lr=0.0100
[2025-05-05 14:30:41,082][train][INFO] - Epoch 34/140, Val Acc=0.6344, Val Loss=1.7071, lr=0.0100
[2025-05-05 14:30:43,158][train][INFO] - Epoch 33/140, Val Acc=0.5842, Val Loss=1.7712, lr=0.0100
[2025-05-05 14:30:47,958][train][INFO] - Epoch 39/140, Val Acc=0.5955, Val Loss=1.8135, lr=0.0100
[2025-05-05 14:30:48,926][train][INFO] - Epoch 35/140, Val Acc=0.6100, Val Loss=1.7923, lr=0.0100
[2025-05-05 14:30:51,272][train][INFO] - Epoch 34/140, Val Acc=0.5665, Val Loss=1.8845, lr=0.0100
[2025-05-05 14:30:55,085][train][INFO] - Epoch 40/140, Val Acc=0.6071, Val Loss=1.7657, lr=0.0100
[2025-05-05 14:30:56,164][train][INFO] - Epoch 36/140, Val Acc=0.6153, Val Loss=1.7703, lr=0.0100
[2025-05-05 14:30:59,021][train][INFO] - Epoch 35/140, Val Acc=0.5815, Val Loss=1.7726, lr=0.0100
[2025-05-05 14:31:02,889][train][INFO] - Epoch 41/140, Val Acc=0.6036, Val Loss=1.7926, lr=0.0100
[2025-05-05 14:31:04,028][train][INFO] - Epoch 37/140, Val Acc=0.6178, Val Loss=1.8030, lr=0.0100
[2025-05-05 14:31:06,821][train][INFO] - Epoch 36/140, Val Acc=0.5744, Val Loss=1.8517, lr=0.0100
[2025-05-05 14:31:10,632][train][INFO] - Epoch 42/140, Val Acc=0.5882, Val Loss=1.8508, lr=0.0100
[2025-05-05 14:31:11,753][train][INFO] - Epoch 38/140, Val Acc=0.6290, Val Loss=1.7177, lr=0.0100
[2025-05-05 14:31:14,818][train][INFO] - Epoch 37/140, Val Acc=0.5582, Val Loss=1.9567, lr=0.0100
[2025-05-05 14:31:18,327][train][INFO] - Epoch 43/140, Val Acc=0.5823, Val Loss=1.9177, lr=0.0100
[2025-05-05 14:31:19,450][train][INFO] - Epoch 39/140, Val Acc=0.6312, Val Loss=1.7027, lr=0.0100
[2025-05-05 14:31:22,569][train][INFO] - Epoch 38/140, Val Acc=0.5679, Val Loss=1.9276, lr=0.0100
[2025-05-05 14:31:25,765][train][INFO] - Epoch 44/140, Val Acc=0.6056, Val Loss=1.8344, lr=0.0100
[2025-05-05 14:31:27,187][train][INFO] - Epoch 40/140, Val Acc=0.6182, Val Loss=1.8119, lr=0.0100
[2025-05-05 14:31:30,664][train][INFO] - Epoch 39/140, Val Acc=0.5885, Val Loss=1.7335, lr=0.0100
[2025-05-05 14:31:32,956][train][INFO] - Epoch 45/140, Val Acc=0.5889, Val Loss=1.8843, lr=0.0100
[2025-05-05 14:31:34,739][train][INFO] - Epoch 41/140, Val Acc=0.6183, Val Loss=1.7723, lr=0.0100
[2025-05-05 14:31:38,427][train][INFO] - Epoch 40/140, Val Acc=0.5807, Val Loss=1.8229, lr=0.0100
[2025-05-05 14:31:40,368][train][INFO] - Epoch 46/140, Val Acc=0.5961, Val Loss=1.7803, lr=0.0100
[2025-05-05 14:31:42,516][train][INFO] - Epoch 42/140, Val Acc=0.6129, Val Loss=1.8326, lr=0.0100
[2025-05-05 14:31:46,412][train][INFO] - Epoch 41/140, Val Acc=0.5805, Val Loss=1.8339, lr=0.0100
[2025-05-05 14:31:48,008][train][INFO] - Epoch 47/140, Val Acc=0.5792, Val Loss=1.9103, lr=0.0100
[2025-05-05 14:31:50,031][train][INFO] - Epoch 43/140, Val Acc=0.6132, Val Loss=1.7945, lr=0.0100
[2025-05-05 14:31:54,008][train][INFO] - Epoch 42/140, Val Acc=0.5806, Val Loss=1.8245, lr=0.0100
[2025-05-05 14:31:55,614][train][INFO] - Epoch 48/140, Val Acc=0.6037, Val Loss=1.8030, lr=0.0100
[2025-05-05 14:31:57,853][train][INFO] - Epoch 44/140, Val Acc=0.6395, Val Loss=1.6935, lr=0.0100
[2025-05-05 14:32:01,753][train][INFO] - Epoch 43/140, Val Acc=0.5915, Val Loss=1.7818, lr=0.0100
[2025-05-05 14:32:02,942][train][INFO] - Epoch 49/140, Val Acc=0.6014, Val Loss=1.7818, lr=0.0100
[2025-05-05 14:32:05,434][train][INFO] - Epoch 45/140, Val Acc=0.6302, Val Loss=1.7059, lr=0.0100
[2025-05-05 14:32:09,485][train][INFO] - Epoch 44/140, Val Acc=0.5816, Val Loss=1.8178, lr=0.0100
[2025-05-05 14:32:10,661][train][INFO] - Epoch 50/140, Val Acc=0.6025, Val Loss=1.8049, lr=0.0100
[2025-05-05 14:32:13,169][train][INFO] - Epoch 46/140, Val Acc=0.6217, Val Loss=1.7787, lr=0.0100
[2025-05-05 14:32:17,455][train][INFO] - Epoch 45/140, Val Acc=0.5904, Val Loss=1.7415, lr=0.0100
[2025-05-05 14:32:18,266][train][INFO] - Epoch 51/140, Val Acc=0.6077, Val Loss=1.7556, lr=0.0100
[2025-05-05 14:32:20,881][train][INFO] - Epoch 47/140, Val Acc=0.6208, Val Loss=1.7444, lr=0.0100
[2025-05-05 14:32:25,155][train][INFO] - Epoch 46/140, Val Acc=0.5840, Val Loss=1.8406, lr=0.0100
[2025-05-05 14:32:25,832][train][INFO] - Epoch 52/140, Val Acc=0.5988, Val Loss=1.7995, lr=0.0100
[2025-05-05 14:32:28,487][train][INFO] - Epoch 48/140, Val Acc=0.6146, Val Loss=1.7805, lr=0.0100
[2025-05-05 14:32:33,093][train][INFO] - Epoch 47/140, Val Acc=0.5564, Val Loss=1.9893, lr=0.0100
[2025-05-05 14:32:33,854][train][INFO] - Epoch 53/140, Val Acc=0.5868, Val Loss=1.9219, lr=0.0100
[2025-05-05 14:32:36,168][train][INFO] - Epoch 49/140, Val Acc=0.6306, Val Loss=1.7111, lr=0.0100
[2025-05-05 14:32:40,939][train][INFO] - Epoch 48/140, Val Acc=0.5851, Val Loss=1.7984, lr=0.0100
[2025-05-05 14:32:41,378][train][INFO] - Epoch 54/140, Val Acc=0.6144, Val Loss=1.7401, lr=0.0100
[2025-05-05 14:32:44,199][train][INFO] - Epoch 50/140, Val Acc=0.6318, Val Loss=1.7079, lr=0.0100
[2025-05-05 14:32:48,388][train][INFO] - Epoch 49/140, Val Acc=0.5676, Val Loss=1.9024, lr=0.0100
[2025-05-05 14:32:49,022][train][INFO] - Epoch 55/140, Val Acc=0.6074, Val Loss=1.7584, lr=0.0100
[2025-05-05 14:32:51,971][train][INFO] - Epoch 51/140, Val Acc=0.6157, Val Loss=1.8160, lr=0.0100
[2025-05-05 14:32:55,830][train][INFO] - Epoch 50/140, Val Acc=0.5947, Val Loss=1.7832, lr=0.0100
[2025-05-05 14:32:56,742][train][INFO] - Epoch 56/140, Val Acc=0.5984, Val Loss=1.7737, lr=0.0100
[2025-05-05 14:32:59,498][train][INFO] - Epoch 52/140, Val Acc=0.6134, Val Loss=1.8587, lr=0.0100
[2025-05-05 14:33:03,638][train][INFO] - Epoch 51/140, Val Acc=0.5843, Val Loss=1.7965, lr=0.0100
[2025-05-05 14:33:04,272][train][INFO] - Epoch 57/140, Val Acc=0.5816, Val Loss=1.9410, lr=0.0100
[2025-05-05 14:33:07,343][train][INFO] - Epoch 53/140, Val Acc=0.5964, Val Loss=1.9239, lr=0.0100
[2025-05-05 14:33:11,110][train][INFO] - Epoch 52/140, Val Acc=0.5402, Val Loss=2.0773, lr=0.0100
[2025-05-05 14:33:11,417][train][INFO] - Epoch 58/140, Val Acc=0.6016, Val Loss=1.7540, lr=0.0100
[2025-05-05 14:33:15,176][train][INFO] - Epoch 54/140, Val Acc=0.6154, Val Loss=1.8496, lr=0.0100
[2025-05-05 14:33:19,163][train][INFO] - Epoch 53/140, Val Acc=0.5692, Val Loss=1.9104, lr=0.0100
[2025-05-05 14:33:19,201][train][INFO] - Epoch 59/140, Val Acc=0.6039, Val Loss=1.8128, lr=0.0100
[2025-05-05 14:33:22,917][train][INFO] - Epoch 55/140, Val Acc=0.6170, Val Loss=1.8172, lr=0.0100
[2025-05-05 14:33:26,322][train][INFO] - Epoch 60/140, Val Acc=0.5971, Val Loss=1.8177, lr=0.0100
[2025-05-05 14:33:27,314][train][INFO] - Epoch 54/140, Val Acc=0.5766, Val Loss=1.8719, lr=0.0100
[2025-05-05 14:33:30,683][train][INFO] - Epoch 56/140, Val Acc=0.6134, Val Loss=1.7771, lr=0.0100
[2025-05-05 14:33:33,342][train][INFO] - Epoch 61/140, Val Acc=0.5917, Val Loss=1.8799, lr=0.0100
[2025-05-05 14:33:35,036][train][INFO] - Epoch 55/140, Val Acc=0.5535, Val Loss=2.0529, lr=0.0100
[2025-05-05 14:33:37,921][train][INFO] - Epoch 57/140, Val Acc=0.6217, Val Loss=1.7512, lr=0.0100
[2025-05-05 14:33:41,135][train][INFO] - Epoch 62/140, Val Acc=0.5850, Val Loss=1.9258, lr=0.0100
[2025-05-05 14:33:42,829][train][INFO] - Epoch 56/140, Val Acc=0.5728, Val Loss=1.8876, lr=0.0100
[2025-05-05 14:33:45,258][train][INFO] - Epoch 58/140, Val Acc=0.6297, Val Loss=1.8011, lr=0.0100
[2025-05-05 14:33:48,740][train][INFO] - Epoch 63/140, Val Acc=0.5981, Val Loss=1.8362, lr=0.0100
[2025-05-05 14:33:50,677][train][INFO] - Epoch 57/140, Val Acc=0.5781, Val Loss=1.8394, lr=0.0100
[2025-05-05 14:33:53,069][train][INFO] - Epoch 59/140, Val Acc=0.6263, Val Loss=1.7763, lr=0.0100
[2025-05-05 14:33:56,197][train][INFO] - Epoch 64/140, Val Acc=0.6041, Val Loss=1.7430, lr=0.0100
[2025-05-05 14:33:58,671][train][INFO] - Epoch 58/140, Val Acc=0.5814, Val Loss=1.8627, lr=0.0100
[2025-05-05 14:34:00,956][train][INFO] - Epoch 60/140, Val Acc=0.6214, Val Loss=1.7870, lr=0.0100
[2025-05-05 14:34:03,689][train][INFO] - Epoch 65/140, Val Acc=0.5715, Val Loss=2.0051, lr=0.0100
[2025-05-05 14:34:06,363][train][INFO] - Epoch 59/140, Val Acc=0.5859, Val Loss=1.8349, lr=0.0100
[2025-05-05 14:34:08,723][train][INFO] - Epoch 61/140, Val Acc=0.6107, Val Loss=1.8976, lr=0.0100
[2025-05-05 14:34:11,673][train][INFO] - Epoch 66/140, Val Acc=0.5928, Val Loss=1.8248, lr=0.0100
[2025-05-05 14:34:14,439][train][INFO] - Epoch 60/140, Val Acc=0.5722, Val Loss=1.8855, lr=0.0100
[2025-05-05 14:34:16,599][train][INFO] - Epoch 62/140, Val Acc=0.6219, Val Loss=1.8117, lr=0.0100
[2025-05-05 14:34:19,362][train][INFO] - Epoch 67/140, Val Acc=0.5721, Val Loss=2.0762, lr=0.0100
[2025-05-05 14:34:22,306][train][INFO] - Epoch 61/140, Val Acc=0.5796, Val Loss=1.8667, lr=0.0100
[2025-05-05 14:34:24,350][train][INFO] - Epoch 63/140, Val Acc=0.6266, Val Loss=1.7472, lr=0.0100
[2025-05-05 14:34:26,824][train][INFO] - Epoch 68/140, Val Acc=0.5845, Val Loss=1.8527, lr=0.0100
[2025-05-05 14:34:30,203][train][INFO] - Epoch 62/140, Val Acc=0.5647, Val Loss=1.9708, lr=0.0100
[2025-05-05 14:34:31,989][train][INFO] - Epoch 64/140, Val Acc=0.6198, Val Loss=1.8558, lr=0.0100
[2025-05-05 14:34:33,653][train][INFO] - Epoch 69/140, Val Acc=0.6173, Val Loss=1.7443, lr=0.0100
[2025-05-05 14:34:37,992][train][INFO] - Epoch 63/140, Val Acc=0.5746, Val Loss=1.8964, lr=0.0100
[2025-05-05 14:34:39,993][train][INFO] - Epoch 65/140, Val Acc=0.6344, Val Loss=1.7183, lr=0.0100
[2025-05-05 14:34:41,078][train][INFO] - Epoch 70/140, Val Acc=0.6014, Val Loss=1.8476, lr=0.0100
[2025-05-05 14:34:45,780][train][INFO] - Epoch 64/140, Val Acc=0.5683, Val Loss=1.9639, lr=0.0100
[2025-05-05 14:34:47,533][train][INFO] - Epoch 66/140, Val Acc=0.6143, Val Loss=1.8603, lr=0.0100
[2025-05-05 14:34:48,764][train][INFO] - Epoch 71/140, Val Acc=0.6160, Val Loss=1.7492, lr=0.0100
[2025-05-05 14:34:53,461][train][INFO] - Epoch 65/140, Val Acc=0.5955, Val Loss=1.7544, lr=0.0100
[2025-05-05 14:34:55,674][train][INFO] - Epoch 67/140, Val Acc=0.5943, Val Loss=1.9770, lr=0.0100
[2025-05-05 14:34:56,616][train][INFO] - Epoch 72/140, Val Acc=0.6100, Val Loss=1.7827, lr=0.0100
[2025-05-05 14:35:01,553][train][INFO] - Epoch 66/140, Val Acc=0.5957, Val Loss=1.7750, lr=0.0100
[2025-05-05 14:35:03,504][train][INFO] - Epoch 68/140, Val Acc=0.6109, Val Loss=1.8398, lr=0.0100
[2025-05-05 14:35:03,999][train][INFO] - Epoch 73/140, Val Acc=0.5886, Val Loss=1.8739, lr=0.0100
[2025-05-05 14:35:09,148][train][INFO] - Epoch 67/140, Val Acc=0.5598, Val Loss=2.0259, lr=0.0100
[2025-05-05 14:35:10,688][train][INFO] - Epoch 69/140, Val Acc=0.6337, Val Loss=1.6654, lr=0.0100
[2025-05-05 14:35:11,404][train][INFO] - Epoch 74/140, Val Acc=0.6026, Val Loss=1.8206, lr=0.0100
[2025-05-05 14:35:16,596][train][INFO] - Epoch 68/140, Val Acc=0.5884, Val Loss=1.8253, lr=0.0100
[2025-05-05 14:35:18,276][train][INFO] - Epoch 70/140, Val Acc=0.6300, Val Loss=1.7135, lr=0.0100
[2025-05-05 14:35:18,768][train][INFO] - Epoch 75/140, Val Acc=0.5993, Val Loss=1.8567, lr=0.0100
[2025-05-05 14:35:24,554][train][INFO] - Epoch 69/140, Val Acc=0.5638, Val Loss=1.9314, lr=0.0100
[2025-05-05 14:35:25,805][train][INFO] - Epoch 71/140, Val Acc=0.6147, Val Loss=1.8376, lr=0.0100
[2025-05-05 14:35:26,094][train][INFO] - Epoch 76/140, Val Acc=0.5992, Val Loss=1.8283, lr=0.0100
[2025-05-05 14:35:32,284][train][INFO] - Epoch 70/140, Val Acc=0.5805, Val Loss=1.9125, lr=0.0100
[2025-05-05 14:35:33,699][train][INFO] - Epoch 72/140, Val Acc=0.6379, Val Loss=1.6730, lr=0.0100
[2025-05-05 14:35:33,724][train][INFO] - Epoch 77/140, Val Acc=0.5959, Val Loss=1.8473, lr=0.0100
[2025-05-05 14:35:39,972][train][INFO] - Epoch 71/140, Val Acc=0.5947, Val Loss=1.7821, lr=0.0100
[2025-05-05 14:35:41,134][train][INFO] - Epoch 78/140, Val Acc=0.6015, Val Loss=1.8315, lr=0.0100
[2025-05-05 14:35:41,313][train][INFO] - Epoch 73/140, Val Acc=0.6120, Val Loss=1.8945, lr=0.0100
[2025-05-05 14:35:48,203][train][INFO] - Epoch 72/140, Val Acc=0.5883, Val Loss=1.8261, lr=0.0100
[2025-05-05 14:35:48,506][train][INFO] - Epoch 79/140, Val Acc=0.6062, Val Loss=1.7812, lr=0.0100
[2025-05-05 14:35:49,346][train][INFO] - Epoch 74/140, Val Acc=0.6282, Val Loss=1.7667, lr=0.0100
[2025-05-05 14:35:55,883][train][INFO] - Epoch 80/140, Val Acc=0.6026, Val Loss=1.8156, lr=0.0100
[2025-05-05 14:35:55,884][train][INFO] - Epoch 73/140, Val Acc=0.5725, Val Loss=1.9193, lr=0.0100
[2025-05-05 14:35:56,896][train][INFO] - Epoch 75/140, Val Acc=0.6231, Val Loss=1.7894, lr=0.0100
[2025-05-05 14:36:03,197][train][INFO] - Epoch 81/140, Val Acc=0.6708, Val Loss=1.4473, lr=0.0010
[2025-05-05 14:36:03,521][train][INFO] - Epoch 74/140, Val Acc=0.5768, Val Loss=1.9080, lr=0.0100
[2025-05-05 14:36:04,500][train][INFO] - Epoch 76/140, Val Acc=0.6245, Val Loss=1.7965, lr=0.0100
[2025-05-05 14:36:10,339][train][INFO] - Epoch 82/140, Val Acc=0.6727, Val Loss=1.4465, lr=0.0010
[2025-05-05 14:36:10,861][train][INFO] - Epoch 75/140, Val Acc=0.5807, Val Loss=1.9190, lr=0.0100
[2025-05-05 14:36:11,783][train][INFO] - Epoch 77/140, Val Acc=0.6260, Val Loss=1.7304, lr=0.0100
[2025-05-05 14:36:17,804][train][INFO] - Epoch 83/140, Val Acc=0.6759, Val Loss=1.4581, lr=0.0010
[2025-05-05 14:36:18,390][train][INFO] - Epoch 76/140, Val Acc=0.5588, Val Loss=2.0690, lr=0.0100
[2025-05-05 14:36:18,783][train][INFO] - Epoch 78/140, Val Acc=0.6240, Val Loss=1.7933, lr=0.0100
[2025-05-05 14:36:25,153][train][INFO] - Epoch 84/140, Val Acc=0.6772, Val Loss=1.4638, lr=0.0010
[2025-05-05 14:36:26,338][train][INFO] - Epoch 77/140, Val Acc=0.5805, Val Loss=1.8878, lr=0.0100
[2025-05-05 14:36:26,455][train][INFO] - Epoch 79/140, Val Acc=0.6168, Val Loss=1.8378, lr=0.0100
[2025-05-05 14:36:32,614][train][INFO] - Epoch 85/140, Val Acc=0.6782, Val Loss=1.4606, lr=0.0010
[2025-05-05 14:36:34,445][train][INFO] - Epoch 80/140, Val Acc=0.6245, Val Loss=1.8379, lr=0.0100
[2025-05-05 14:36:34,622][train][INFO] - Epoch 78/140, Val Acc=0.5486, Val Loss=2.1117, lr=0.0100
[2025-05-05 14:36:40,282][train][INFO] - Epoch 86/140, Val Acc=0.6791, Val Loss=1.4804, lr=0.0010
[2025-05-05 14:36:42,569][train][INFO] - Epoch 81/140, Val Acc=0.6870, Val Loss=1.4575, lr=0.0010
[2025-05-05 14:36:42,672][train][INFO] - Epoch 79/140, Val Acc=0.5756, Val Loss=1.9044, lr=0.0100
[2025-05-05 14:36:47,757][train][INFO] - Epoch 87/140, Val Acc=0.6800, Val Loss=1.4755, lr=0.0010
[2025-05-05 14:36:50,006][train][INFO] - Epoch 82/140, Val Acc=0.6869, Val Loss=1.4410, lr=0.0010
[2025-05-05 14:36:50,650][train][INFO] - Epoch 80/140, Val Acc=0.5658, Val Loss=2.0187, lr=0.0100
[2025-05-05 14:36:55,496][train][INFO] - Epoch 88/140, Val Acc=0.6783, Val Loss=1.4884, lr=0.0010
[2025-05-05 14:36:57,957][train][INFO] - Epoch 83/140, Val Acc=0.6886, Val Loss=1.4578, lr=0.0010
[2025-05-05 14:36:58,607][train][INFO] - Epoch 81/140, Val Acc=0.6478, Val Loss=1.5330, lr=0.0010
[2025-05-05 14:37:02,931][train][INFO] - Epoch 89/140, Val Acc=0.6783, Val Loss=1.4917, lr=0.0010
[2025-05-05 14:37:05,486][train][INFO] - Epoch 84/140, Val Acc=0.6910, Val Loss=1.4618, lr=0.0010
[2025-05-05 14:37:06,315][train][INFO] - Epoch 82/140, Val Acc=0.6513, Val Loss=1.5390, lr=0.0010
[2025-05-05 14:37:10,610][train][INFO] - Epoch 90/140, Val Acc=0.6768, Val Loss=1.4912, lr=0.0010
[2025-05-05 14:37:12,505][train][INFO] - Epoch 85/140, Val Acc=0.6914, Val Loss=1.4598, lr=0.0010
[2025-05-05 14:37:13,988][train][INFO] - Epoch 83/140, Val Acc=0.6515, Val Loss=1.5451, lr=0.0010
[2025-05-05 14:37:18,321][train][INFO] - Epoch 91/140, Val Acc=0.6790, Val Loss=1.4886, lr=0.0010
[2025-05-05 14:37:20,306][train][INFO] - Epoch 86/140, Val Acc=0.6927, Val Loss=1.4662, lr=0.0010
[2025-05-05 14:37:21,409][train][INFO] - Epoch 84/140, Val Acc=0.6538, Val Loss=1.5497, lr=0.0010
[2025-05-05 14:37:26,019][train][INFO] - Epoch 92/140, Val Acc=0.6779, Val Loss=1.5019, lr=0.0010
[2025-05-05 14:37:28,240][train][INFO] - Epoch 87/140, Val Acc=0.6928, Val Loss=1.4686, lr=0.0010
[2025-05-05 14:37:29,075][train][INFO] - Epoch 85/140, Val Acc=0.6538, Val Loss=1.5676, lr=0.0010
[2025-05-05 14:37:33,636][train][INFO] - Epoch 93/140, Val Acc=0.6762, Val Loss=1.4982, lr=0.0010
[2025-05-05 14:37:35,986][train][INFO] - Epoch 88/140, Val Acc=0.6949, Val Loss=1.4685, lr=0.0010
[2025-05-05 14:37:36,727][train][INFO] - Epoch 86/140, Val Acc=0.6509, Val Loss=1.5729, lr=0.0010
[2025-05-05 14:37:41,012][train][INFO] - Epoch 94/140, Val Acc=0.6808, Val Loss=1.5047, lr=0.0010
[2025-05-05 14:37:42,930][train][INFO] - Epoch 89/140, Val Acc=0.6958, Val Loss=1.4723, lr=0.0010
[2025-05-05 14:37:44,030][train][INFO] - Epoch 87/140, Val Acc=0.6554, Val Loss=1.5833, lr=0.0010
[2025-05-05 14:37:48,676][train][INFO] - Epoch 95/140, Val Acc=0.6819, Val Loss=1.4989, lr=0.0010
[2025-05-05 14:37:50,361][train][INFO] - Epoch 90/140, Val Acc=0.6928, Val Loss=1.4731, lr=0.0010
[2025-05-05 14:37:51,591][train][INFO] - Epoch 88/140, Val Acc=0.6525, Val Loss=1.5843, lr=0.0010
[2025-05-05 14:37:56,308][train][INFO] - Epoch 96/140, Val Acc=0.6810, Val Loss=1.5024, lr=0.0010
[2025-05-05 14:37:57,659][train][INFO] - Epoch 91/140, Val Acc=0.6910, Val Loss=1.4848, lr=0.0010
[2025-05-05 14:37:59,416][train][INFO] - Epoch 89/140, Val Acc=0.6535, Val Loss=1.5942, lr=0.0010
[2025-05-05 14:38:03,142][train][INFO] - Epoch 97/140, Val Acc=0.6810, Val Loss=1.5108, lr=0.0010
[2025-05-05 14:38:05,357][train][INFO] - Epoch 92/140, Val Acc=0.6957, Val Loss=1.4841, lr=0.0010
[2025-05-05 14:38:07,018][train][INFO] - Epoch 90/140, Val Acc=0.6560, Val Loss=1.5869, lr=0.0010
[2025-05-05 14:38:10,579][train][INFO] - Epoch 98/140, Val Acc=0.6818, Val Loss=1.5145, lr=0.0010
[2025-05-05 14:38:12,749][train][INFO] - Epoch 93/140, Val Acc=0.6951, Val Loss=1.4818, lr=0.0010
[2025-05-05 14:38:14,813][train][INFO] - Epoch 91/140, Val Acc=0.6543, Val Loss=1.6035, lr=0.0010
[2025-05-05 14:38:18,130][train][INFO] - Epoch 99/140, Val Acc=0.6828, Val Loss=1.5200, lr=0.0010
[2025-05-05 14:38:20,242][train][INFO] - Epoch 94/140, Val Acc=0.6981, Val Loss=1.4879, lr=0.0010
[2025-05-05 14:38:22,875][train][INFO] - Epoch 92/140, Val Acc=0.6554, Val Loss=1.6075, lr=0.0010
[2025-05-05 14:38:25,689][train][INFO] - Epoch 100/140, Val Acc=0.6803, Val Loss=1.5295, lr=0.0010
[2025-05-05 14:38:28,023][train][INFO] - Epoch 95/140, Val Acc=0.6950, Val Loss=1.4967, lr=0.0010
[2025-05-05 14:38:30,275][train][INFO] - Epoch 93/140, Val Acc=0.6531, Val Loss=1.6102, lr=0.0010
[2025-05-05 14:38:33,175][train][INFO] - Epoch 101/140, Val Acc=0.6814, Val Loss=1.5238, lr=0.0010
[2025-05-05 14:38:35,564][train][INFO] - Epoch 96/140, Val Acc=0.6944, Val Loss=1.5006, lr=0.0010
[2025-05-05 14:38:38,281][train][INFO] - Epoch 94/140, Val Acc=0.6571, Val Loss=1.6081, lr=0.0010
[2025-05-05 14:38:40,758][train][INFO] - Epoch 102/140, Val Acc=0.6808, Val Loss=1.5242, lr=0.0010
[2025-05-05 14:38:42,882][train][INFO] - Epoch 97/140, Val Acc=0.6969, Val Loss=1.5005, lr=0.0010
[2025-05-05 14:38:46,410][train][INFO] - Epoch 95/140, Val Acc=0.6537, Val Loss=1.6145, lr=0.0010
[2025-05-05 14:38:47,843][train][INFO] - Epoch 103/140, Val Acc=0.6819, Val Loss=1.5234, lr=0.0010
[2025-05-05 14:38:50,492][train][INFO] - Epoch 98/140, Val Acc=0.6944, Val Loss=1.5003, lr=0.0010
[2025-05-05 14:38:54,064][train][INFO] - Epoch 96/140, Val Acc=0.6551, Val Loss=1.6279, lr=0.0010
[2025-05-05 14:38:55,568][train][INFO] - Epoch 104/140, Val Acc=0.6813, Val Loss=1.5347, lr=0.0010
[2025-05-05 14:38:58,106][train][INFO] - Epoch 99/140, Val Acc=0.6953, Val Loss=1.5077, lr=0.0010
[2025-05-05 14:39:01,840][train][INFO] - Epoch 97/140, Val Acc=0.6555, Val Loss=1.6290, lr=0.0010
[2025-05-05 14:39:02,741][train][INFO] - Epoch 105/140, Val Acc=0.6824, Val Loss=1.5376, lr=0.0010
[2025-05-05 14:39:05,685][train][INFO] - Epoch 100/140, Val Acc=0.6926, Val Loss=1.5099, lr=0.0010
[2025-05-05 14:39:09,734][train][INFO] - Epoch 98/140, Val Acc=0.6579, Val Loss=1.6367, lr=0.0010
[2025-05-05 14:39:10,364][train][INFO] - Epoch 106/140, Val Acc=0.6838, Val Loss=1.5498, lr=0.0010
[2025-05-05 14:39:13,401][train][INFO] - Epoch 101/140, Val Acc=0.6954, Val Loss=1.5037, lr=0.0010
[2025-05-05 14:39:17,184][train][INFO] - Epoch 99/140, Val Acc=0.6560, Val Loss=1.6448, lr=0.0010
[2025-05-05 14:39:17,724][train][INFO] - Epoch 107/140, Val Acc=0.6811, Val Loss=1.5437, lr=0.0010
[2025-05-05 14:39:21,261][train][INFO] - Epoch 102/140, Val Acc=0.6949, Val Loss=1.5110, lr=0.0010
[2025-05-05 14:39:25,060][train][INFO] - Epoch 100/140, Val Acc=0.6565, Val Loss=1.6467, lr=0.0010
[2025-05-05 14:39:25,388][train][INFO] - Epoch 108/140, Val Acc=0.6795, Val Loss=1.5463, lr=0.0010
[2025-05-05 14:39:28,327][train][INFO] - Epoch 103/140, Val Acc=0.6944, Val Loss=1.5177, lr=0.0010
[2025-05-05 14:39:32,880][train][INFO] - Epoch 101/140, Val Acc=0.6544, Val Loss=1.6444, lr=0.0010
[2025-05-05 14:39:33,175][train][INFO] - Epoch 109/140, Val Acc=0.6829, Val Loss=1.5517, lr=0.0010
[2025-05-05 14:39:36,019][train][INFO] - Epoch 104/140, Val Acc=0.6975, Val Loss=1.5130, lr=0.0010
[2025-05-05 14:39:40,305][train][INFO] - Epoch 102/140, Val Acc=0.6546, Val Loss=1.6426, lr=0.0010
[2025-05-05 14:39:40,668][train][INFO] - Epoch 110/140, Val Acc=0.6804, Val Loss=1.5560, lr=0.0010
[2025-05-05 14:39:43,864][train][INFO] - Epoch 105/140, Val Acc=0.6956, Val Loss=1.5145, lr=0.0010
[2025-05-05 14:39:47,702][train][INFO] - Epoch 103/140, Val Acc=0.6542, Val Loss=1.6527, lr=0.0010
[2025-05-05 14:39:47,903][train][INFO] - Epoch 111/140, Val Acc=0.6805, Val Loss=1.5527, lr=0.0010
[2025-05-05 14:39:51,351][train][INFO] - Epoch 106/140, Val Acc=0.6944, Val Loss=1.5153, lr=0.0010
[2025-05-05 14:39:55,313][train][INFO] - Epoch 104/140, Val Acc=0.6548, Val Loss=1.6643, lr=0.0010
[2025-05-05 14:39:55,388][train][INFO] - Epoch 112/140, Val Acc=0.6818, Val Loss=1.5509, lr=0.0010
[2025-05-05 14:39:59,049][train][INFO] - Epoch 107/140, Val Acc=0.6956, Val Loss=1.5187, lr=0.0010
[2025-05-05 14:40:02,928][train][INFO] - Epoch 113/140, Val Acc=0.6816, Val Loss=1.5580, lr=0.0010
[2025-05-05 14:40:03,522][train][INFO] - Epoch 105/140, Val Acc=0.6517, Val Loss=1.6681, lr=0.0010
[2025-05-05 14:40:06,613][train][INFO] - Epoch 108/140, Val Acc=0.6956, Val Loss=1.5138, lr=0.0010
[2025-05-05 14:40:10,699][train][INFO] - Epoch 114/140, Val Acc=0.6838, Val Loss=1.5643, lr=0.0010
[2025-05-05 14:40:11,444][train][INFO] - Epoch 106/140, Val Acc=0.6535, Val Loss=1.6760, lr=0.0010
[2025-05-05 14:40:14,238][train][INFO] - Epoch 109/140, Val Acc=0.6971, Val Loss=1.5222, lr=0.0010
[2025-05-05 14:40:18,079][train][INFO] - Epoch 115/140, Val Acc=0.6837, Val Loss=1.5563, lr=0.0010
[2025-05-05 14:40:19,409][train][INFO] - Epoch 107/140, Val Acc=0.6542, Val Loss=1.6765, lr=0.0010
[2025-05-05 14:40:21,992][train][INFO] - Epoch 110/140, Val Acc=0.6954, Val Loss=1.5176, lr=0.0010
[2025-05-05 14:40:25,525][train][INFO] - Epoch 116/140, Val Acc=0.6834, Val Loss=1.5552, lr=0.0010
[2025-05-05 14:40:27,281][train][INFO] - Epoch 108/140, Val Acc=0.6567, Val Loss=1.6721, lr=0.0010
[2025-05-05 14:40:29,915][train][INFO] - Epoch 111/140, Val Acc=0.6970, Val Loss=1.5190, lr=0.0010
[2025-05-05 14:40:32,814][train][INFO] - Epoch 117/140, Val Acc=0.6859, Val Loss=1.5581, lr=0.0010
[2025-05-05 14:40:35,192][train][INFO] - Epoch 109/140, Val Acc=0.6598, Val Loss=1.6732, lr=0.0010
[2025-05-05 14:40:37,377][train][INFO] - Epoch 112/140, Val Acc=0.6989, Val Loss=1.5175, lr=0.0010
[2025-05-05 14:40:40,475][train][INFO] - Epoch 118/140, Val Acc=0.6784, Val Loss=1.5672, lr=0.0010
[2025-05-05 14:40:42,816][train][INFO] - Epoch 110/140, Val Acc=0.6552, Val Loss=1.6824, lr=0.0010
[2025-05-05 14:40:44,968][train][INFO] - Epoch 113/140, Val Acc=0.6981, Val Loss=1.5185, lr=0.0010
[2025-05-05 14:40:48,249][train][INFO] - Epoch 119/140, Val Acc=0.6813, Val Loss=1.5579, lr=0.0010
[2025-05-05 14:40:50,609][train][INFO] - Epoch 111/140, Val Acc=0.6565, Val Loss=1.6805, lr=0.0010
[2025-05-05 14:40:52,836][train][INFO] - Epoch 114/140, Val Acc=0.6968, Val Loss=1.5193, lr=0.0010
[2025-05-05 14:40:55,601][train][INFO] - Epoch 120/140, Val Acc=0.6829, Val Loss=1.5628, lr=0.0010
[2025-05-05 14:40:57,807][train][INFO] - Epoch 112/140, Val Acc=0.6543, Val Loss=1.6920, lr=0.0010
[2025-05-05 14:41:00,305][train][INFO] - Epoch 115/140, Val Acc=0.6977, Val Loss=1.5249, lr=0.0010
[2025-05-05 14:41:03,201][train][INFO] - Epoch 121/140, Val Acc=0.6840, Val Loss=1.5595, lr=0.0001
[2025-05-05 14:41:05,417][train][INFO] - Epoch 113/140, Val Acc=0.6568, Val Loss=1.6999, lr=0.0010
[2025-05-05 14:41:07,455][train][INFO] - Epoch 116/140, Val Acc=0.7010, Val Loss=1.5258, lr=0.0010
[2025-05-05 14:41:10,028][train][INFO] - Epoch 122/140, Val Acc=0.6849, Val Loss=1.5628, lr=0.0001
[2025-05-05 14:41:13,546][train][INFO] - Epoch 114/140, Val Acc=0.6575, Val Loss=1.6986, lr=0.0010
[2025-05-05 14:41:14,901][train][INFO] - Epoch 117/140, Val Acc=0.7003, Val Loss=1.5247, lr=0.0010
[2025-05-05 14:41:17,959][train][INFO] - Epoch 123/140, Val Acc=0.6872, Val Loss=1.5571, lr=0.0001
[2025-05-05 14:41:21,133][train][INFO] - Epoch 115/140, Val Acc=0.6546, Val Loss=1.6918, lr=0.0010
[2025-05-05 14:41:22,418][train][INFO] - Epoch 118/140, Val Acc=0.6992, Val Loss=1.5289, lr=0.0010
[2025-05-05 14:41:25,198][train][INFO] - Epoch 124/140, Val Acc=0.6855, Val Loss=1.5581, lr=0.0001
[2025-05-05 14:41:28,976][train][INFO] - Epoch 116/140, Val Acc=0.6600, Val Loss=1.6834, lr=0.0010
[2025-05-05 14:41:29,954][train][INFO] - Epoch 119/140, Val Acc=0.6991, Val Loss=1.5246, lr=0.0010
[2025-05-05 14:41:32,778][train][INFO] - Epoch 125/140, Val Acc=0.6844, Val Loss=1.5608, lr=0.0001
[2025-05-05 14:41:37,003][train][INFO] - Epoch 117/140, Val Acc=0.6568, Val Loss=1.6928, lr=0.0010
[2025-05-05 14:41:37,467][train][INFO] - Epoch 120/140, Val Acc=0.6966, Val Loss=1.5353, lr=0.0010
[2025-05-05 14:41:40,354][train][INFO] - Epoch 126/140, Val Acc=0.6864, Val Loss=1.5556, lr=0.0001
[2025-05-05 14:41:44,902][train][INFO] - Epoch 118/140, Val Acc=0.6560, Val Loss=1.6977, lr=0.0010
[2025-05-05 14:41:45,387][train][INFO] - Epoch 121/140, Val Acc=0.6956, Val Loss=1.5342, lr=0.0001
[2025-05-05 14:41:47,681][train][INFO] - Epoch 127/140, Val Acc=0.6843, Val Loss=1.5627, lr=0.0001
[2025-05-05 14:41:52,726][train][INFO] - Epoch 119/140, Val Acc=0.6563, Val Loss=1.6992, lr=0.0010
[2025-05-05 14:41:52,959][train][INFO] - Epoch 122/140, Val Acc=0.6980, Val Loss=1.5336, lr=0.0001
[2025-05-05 14:41:55,436][train][INFO] - Epoch 128/140, Val Acc=0.6840, Val Loss=1.5547, lr=0.0001
[2025-05-05 14:41:59,927][train][INFO] - Epoch 120/140, Val Acc=0.6575, Val Loss=1.7005, lr=0.0010
[2025-05-05 14:42:00,560][train][INFO] - Epoch 123/140, Val Acc=0.6993, Val Loss=1.5301, lr=0.0001
[2025-05-05 14:42:02,974][train][INFO] - Epoch 129/140, Val Acc=0.6850, Val Loss=1.5585, lr=0.0001
[2025-05-05 14:42:08,024][train][INFO] - Epoch 121/140, Val Acc=0.6582, Val Loss=1.6945, lr=0.0001
[2025-05-05 14:42:08,295][train][INFO] - Epoch 124/140, Val Acc=0.6972, Val Loss=1.5333, lr=0.0001
[2025-05-05 14:42:10,791][train][INFO] - Epoch 130/140, Val Acc=0.6849, Val Loss=1.5563, lr=0.0001
[2025-05-05 14:42:15,808][train][INFO] - Epoch 125/140, Val Acc=0.6971, Val Loss=1.5346, lr=0.0001
[2025-05-05 14:42:15,937][train][INFO] - Epoch 122/140, Val Acc=0.6571, Val Loss=1.7018, lr=0.0001
[2025-05-05 14:42:18,403][train][INFO] - Epoch 131/140, Val Acc=0.6857, Val Loss=1.5648, lr=0.0001
[2025-05-05 14:42:23,756][train][INFO] - Epoch 126/140, Val Acc=0.7004, Val Loss=1.5265, lr=0.0001
[2025-05-05 14:42:23,946][train][INFO] - Epoch 123/140, Val Acc=0.6551, Val Loss=1.6954, lr=0.0001
[2025-05-05 14:42:26,055][train][INFO] - Epoch 132/140, Val Acc=0.6863, Val Loss=1.5582, lr=0.0001
[2025-05-05 14:42:31,340][train][INFO] - Epoch 127/140, Val Acc=0.7001, Val Loss=1.5301, lr=0.0001
[2025-05-05 14:42:31,491][train][INFO] - Epoch 124/140, Val Acc=0.6554, Val Loss=1.7028, lr=0.0001
[2025-05-05 14:42:33,797][train][INFO] - Epoch 133/140, Val Acc=0.6846, Val Loss=1.5576, lr=0.0001
[2025-05-05 14:42:38,916][train][INFO] - Epoch 128/140, Val Acc=0.6989, Val Loss=1.5267, lr=0.0001
[2025-05-05 14:42:39,215][train][INFO] - Epoch 125/140, Val Acc=0.6566, Val Loss=1.6948, lr=0.0001
[2025-05-05 14:42:41,092][train][INFO] - Epoch 134/140, Val Acc=0.6851, Val Loss=1.5584, lr=0.0001
[2025-05-05 14:42:46,337][train][INFO] - Epoch 129/140, Val Acc=0.6973, Val Loss=1.5294, lr=0.0001
[2025-05-05 14:42:47,093][train][INFO] - Epoch 126/140, Val Acc=0.6572, Val Loss=1.6969, lr=0.0001
[2025-05-05 14:42:48,287][train][INFO] - Epoch 135/140, Val Acc=0.6858, Val Loss=1.5612, lr=0.0001
[2025-05-05 14:42:53,401][train][INFO] - Epoch 130/140, Val Acc=0.7006, Val Loss=1.5269, lr=0.0001
[2025-05-05 14:42:54,723][train][INFO] - Epoch 127/140, Val Acc=0.6568, Val Loss=1.6956, lr=0.0001
[2025-05-05 14:42:55,614][train][INFO] - Epoch 136/140, Val Acc=0.6844, Val Loss=1.5559, lr=0.0001
[2025-05-05 14:43:00,972][train][INFO] - Epoch 131/140, Val Acc=0.6982, Val Loss=1.5242, lr=0.0001
[2025-05-05 14:43:02,630][train][INFO] - Epoch 128/140, Val Acc=0.6568, Val Loss=1.6916, lr=0.0001
[2025-05-05 14:43:03,020][train][INFO] - Epoch 137/140, Val Acc=0.6850, Val Loss=1.5603, lr=0.0001
[2025-05-05 14:43:08,462][train][INFO] - Epoch 132/140, Val Acc=0.6996, Val Loss=1.5274, lr=0.0001
[2025-05-05 14:43:10,165][train][INFO] - Epoch 129/140, Val Acc=0.6568, Val Loss=1.6996, lr=0.0001
[2025-05-05 14:43:10,333][train][INFO] - Epoch 138/140, Val Acc=0.6839, Val Loss=1.5569, lr=0.0001
[2025-05-05 14:43:16,535][train][INFO] - Epoch 133/140, Val Acc=0.6981, Val Loss=1.5262, lr=0.0001
[2025-05-05 14:43:17,998][train][INFO] - Epoch 139/140, Val Acc=0.6865, Val Loss=1.5574, lr=0.0001
[2025-05-05 14:43:18,015][train][INFO] - Epoch 130/140, Val Acc=0.6564, Val Loss=1.6911, lr=0.0001
[2025-05-05 14:43:24,214][train][INFO] - Epoch 134/140, Val Acc=0.6988, Val Loss=1.5261, lr=0.0001
[2025-05-05 14:43:25,293][train][INFO] - Epoch 131/140, Val Acc=0.6569, Val Loss=1.7004, lr=0.0001
[2025-05-05 14:43:25,396][train][INFO] - Epoch 140/140, Val Acc=0.6848, Val Loss=1.5610, lr=0.0001
[2025-05-05 14:43:30,477][train][INFO] - After training : Train Acc=0.9953  Val Acc=0.6872
[2025-05-05 14:43:30,506][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(10, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(83, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(253, 255, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(255, 178, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(178, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(5, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(25, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(7, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(26, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(29, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(19, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=134, out_features=100, bias=True)
)
[2025-05-05 14:43:30,507][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.6872000098228455
                      Speed up: 1.49   Final speed up: 4.50
[2025-05-05 14:43:32,084][train][INFO] - Epoch 135/140, Val Acc=0.6973, Val Loss=1.5267, lr=0.0001
[2025-05-05 14:43:32,861][train][INFO] - Epoch 132/140, Val Acc=0.6584, Val Loss=1.6963, lr=0.0001
[2025-05-05 14:43:40,500][train][INFO] - Epoch 136/140, Val Acc=0.6985, Val Loss=1.5240, lr=0.0001
[2025-05-05 14:43:41,259][train][INFO] - Epoch 133/140, Val Acc=0.6557, Val Loss=1.6954, lr=0.0001
[2025-05-05 14:43:48,267][train][INFO] - Epoch 137/140, Val Acc=0.6987, Val Loss=1.5295, lr=0.0001
[2025-05-05 14:43:49,302][train][INFO] - Epoch 134/140, Val Acc=0.6564, Val Loss=1.6943, lr=0.0001
[2025-05-05 14:43:56,295][train][INFO] - Epoch 138/140, Val Acc=0.6990, Val Loss=1.5289, lr=0.0001
[2025-05-05 14:43:56,673][train][INFO] - Epoch 135/140, Val Acc=0.6545, Val Loss=1.6980, lr=0.0001
[2025-05-05 14:44:03,813][train][INFO] - Epoch 136/140, Val Acc=0.6569, Val Loss=1.6943, lr=0.0001
[2025-05-05 14:44:03,986][train][INFO] - Epoch 139/140, Val Acc=0.6994, Val Loss=1.5323, lr=0.0001
[2025-05-05 14:44:11,996][train][INFO] - Epoch 137/140, Val Acc=0.6570, Val Loss=1.6949, lr=0.0001
[2025-05-05 14:44:12,108][train][INFO] - Epoch 140/140, Val Acc=0.7005, Val Loss=1.5274, lr=0.0001
[2025-05-05 14:44:17,358][train][INFO] - After training : Train Acc=0.9976  Val Acc=0.7010
[2025-05-05 14:44:17,385][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(85, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(252, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(254, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(160, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(26, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(8, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(22, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(19, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(15, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(27, 151, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(151, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=151, out_features=100, bias=True)
)
[2025-05-05 14:44:17,385][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.7009999752044678
                      Speed up: 1.49   Final speed up: 4.50
[2025-05-05 14:44:19,930][train][INFO] - Epoch 138/140, Val Acc=0.6564, Val Loss=1.7012, lr=0.0001
[2025-05-05 14:44:27,922][train][INFO] - Epoch 139/140, Val Acc=0.6558, Val Loss=1.7028, lr=0.0001
[2025-05-05 14:44:35,354][train][INFO] - Epoch 140/140, Val Acc=0.6567, Val Loss=1.7036, lr=0.0001
[2025-05-05 14:44:40,493][train][INFO] - After training : Train Acc=0.9913  Val Acc=0.6600
[2025-05-05 14:44:40,521][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(10, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(19, 74, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(74, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(74, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 253, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(253, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(256, 199, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(199, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(199, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(13, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(6, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(23, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(30, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(18, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(22, 74, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(74, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=74, out_features=100, bias=True)
)
[2025-05-05 14:44:40,522][Pruning][INFO] - Origin val acc : 0.7285999655723572 Final val acc : 0.6599999666213989
                      Speed up: 1.49   Final speed up: 4.51
[2025-05-05 22:48:38,480][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_metanetwork:
        epochs: 100
        lr: 0.001
        lr_decay_milestones: '80'
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 22:48:38,538][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 22:48:38,538][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 22:48:38,538][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 22:48:53,248][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 22:49:00,680][train][INFO] - Epoch 1/100, Val Acc=0.0966, Val Loss=3.8160, lr=0.0010
[2025-05-05 22:49:08,519][train][INFO] - Epoch 2/100, Val Acc=0.2664, Val Loss=2.8131, lr=0.0010
[2025-05-05 22:49:16,156][train][INFO] - Epoch 3/100, Val Acc=0.4165, Val Loss=2.1593, lr=0.0010
[2025-05-05 22:49:23,983][train][INFO] - Epoch 4/100, Val Acc=0.5332, Val Loss=1.7217, lr=0.0010
[2025-05-05 22:50:08,657][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_metanetwork:
        epochs: 100
        lr: 0.001
        lr_decay_milestones: '80'
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 22:50:08,758][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 22:50:08,758][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 22:50:08,758][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 22:50:29,446][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 22:50:37,104][train][INFO] - Epoch 1/100, Val Acc=0.0966, Val Loss=3.8160, lr=0.0010
[2025-05-05 22:50:44,967][train][INFO] - Epoch 2/100, Val Acc=0.2664, Val Loss=2.8131, lr=0.0010
[2025-05-05 22:50:52,676][train][INFO] - Epoch 3/100, Val Acc=0.4165, Val Loss=2.1593, lr=0.0010
[2025-05-05 22:51:00,002][train][INFO] - Epoch 4/100, Val Acc=0.5332, Val Loss=1.7217, lr=0.0010
[2025-05-05 22:51:06,868][train][INFO] - Epoch 5/100, Val Acc=0.5888, Val Loss=1.5584, lr=0.0010
[2025-05-05 22:51:13,853][train][INFO] - Epoch 6/100, Val Acc=0.6221, Val Loss=1.4408, lr=0.0010
[2025-05-05 22:51:21,334][train][INFO] - Epoch 7/100, Val Acc=0.6537, Val Loss=1.3260, lr=0.0010
[2025-05-05 22:51:28,434][train][INFO] - Epoch 8/100, Val Acc=0.6657, Val Loss=1.3085, lr=0.0010
[2025-05-05 22:51:35,238][train][INFO] - Epoch 9/100, Val Acc=0.6656, Val Loss=1.3186, lr=0.0010
[2025-05-05 22:51:42,488][train][INFO] - Epoch 10/100, Val Acc=0.6772, Val Loss=1.2814, lr=0.0010
[2025-05-05 22:51:50,051][train][INFO] - Epoch 11/100, Val Acc=0.6783, Val Loss=1.2996, lr=0.0010
[2025-05-05 22:51:57,084][train][INFO] - Epoch 12/100, Val Acc=0.6869, Val Loss=1.2834, lr=0.0010
[2025-05-05 22:52:04,363][train][INFO] - Epoch 13/100, Val Acc=0.6859, Val Loss=1.3023, lr=0.0010
[2025-05-05 22:52:11,701][train][INFO] - Epoch 14/100, Val Acc=0.6848, Val Loss=1.3183, lr=0.0010
[2025-05-05 22:52:18,979][train][INFO] - Epoch 15/100, Val Acc=0.6941, Val Loss=1.2976, lr=0.0010
[2025-05-05 22:52:26,388][train][INFO] - Epoch 16/100, Val Acc=0.6939, Val Loss=1.3045, lr=0.0010
[2025-05-05 22:52:33,739][train][INFO] - Epoch 17/100, Val Acc=0.6943, Val Loss=1.3294, lr=0.0010
[2025-05-05 22:52:40,854][train][INFO] - Epoch 18/100, Val Acc=0.6954, Val Loss=1.3211, lr=0.0010
[2025-05-05 22:52:48,092][train][INFO] - Epoch 19/100, Val Acc=0.6965, Val Loss=1.3237, lr=0.0010
[2025-05-05 22:52:55,740][train][INFO] - Epoch 20/100, Val Acc=0.6936, Val Loss=1.3660, lr=0.0010
[2025-05-05 22:53:02,764][train][INFO] - Epoch 21/100, Val Acc=0.6896, Val Loss=1.3886, lr=0.0010
[2025-05-05 22:53:10,198][train][INFO] - Epoch 22/100, Val Acc=0.6957, Val Loss=1.3664, lr=0.0010
[2025-05-05 22:53:17,740][train][INFO] - Epoch 23/100, Val Acc=0.6992, Val Loss=1.3705, lr=0.0010
[2025-05-05 22:53:25,205][train][INFO] - Epoch 24/100, Val Acc=0.6957, Val Loss=1.3953, lr=0.0010
[2025-05-05 22:53:32,368][train][INFO] - Epoch 25/100, Val Acc=0.6950, Val Loss=1.3832, lr=0.0010
[2025-05-05 22:53:40,090][train][INFO] - Epoch 26/100, Val Acc=0.7022, Val Loss=1.3706, lr=0.0010
[2025-05-05 22:53:47,938][train][INFO] - Epoch 27/100, Val Acc=0.6971, Val Loss=1.4098, lr=0.0010
[2025-05-05 22:53:55,407][train][INFO] - Epoch 28/100, Val Acc=0.6993, Val Loss=1.4157, lr=0.0010
[2025-05-05 22:54:03,051][train][INFO] - Epoch 29/100, Val Acc=0.6975, Val Loss=1.4083, lr=0.0010
[2025-05-05 22:54:10,498][train][INFO] - Epoch 30/100, Val Acc=0.6976, Val Loss=1.4015, lr=0.0010
[2025-05-05 22:54:17,858][train][INFO] - Epoch 31/100, Val Acc=0.6956, Val Loss=1.4277, lr=0.0010
[2025-05-05 22:54:25,367][train][INFO] - Epoch 32/100, Val Acc=0.6972, Val Loss=1.4328, lr=0.0010
[2025-05-05 22:54:32,929][train][INFO] - Epoch 33/100, Val Acc=0.7022, Val Loss=1.4235, lr=0.0010
[2025-05-05 22:54:39,981][train][INFO] - Epoch 34/100, Val Acc=0.7003, Val Loss=1.4308, lr=0.0010
[2025-05-05 22:54:47,399][train][INFO] - Epoch 35/100, Val Acc=0.7004, Val Loss=1.4216, lr=0.0010
[2025-05-05 22:54:54,909][train][INFO] - Epoch 36/100, Val Acc=0.6979, Val Loss=1.4410, lr=0.0010
[2025-05-05 22:55:02,610][train][INFO] - Epoch 37/100, Val Acc=0.6972, Val Loss=1.4571, lr=0.0010
[2025-05-05 22:55:09,674][train][INFO] - Epoch 38/100, Val Acc=0.7001, Val Loss=1.4411, lr=0.0010
[2025-05-05 22:55:17,469][train][INFO] - Epoch 39/100, Val Acc=0.6976, Val Loss=1.4591, lr=0.0010
[2025-05-05 22:55:24,962][train][INFO] - Epoch 40/100, Val Acc=0.6991, Val Loss=1.4713, lr=0.0010
[2025-05-05 22:55:32,390][train][INFO] - Epoch 41/100, Val Acc=0.7020, Val Loss=1.4325, lr=0.0010
[2025-05-05 22:55:39,266][train][INFO] - Epoch 42/100, Val Acc=0.7007, Val Loss=1.4760, lr=0.0010
[2025-05-05 22:55:46,641][train][INFO] - Epoch 43/100, Val Acc=0.7022, Val Loss=1.4584, lr=0.0010
[2025-05-05 22:55:53,171][train][INFO] - Epoch 44/100, Val Acc=0.7023, Val Loss=1.4470, lr=0.0010
[2025-05-05 22:56:00,504][train][INFO] - Epoch 45/100, Val Acc=0.7020, Val Loss=1.4520, lr=0.0010
[2025-05-05 22:56:07,827][train][INFO] - Epoch 46/100, Val Acc=0.7001, Val Loss=1.4706, lr=0.0010
[2025-05-05 22:56:15,295][train][INFO] - Epoch 47/100, Val Acc=0.6956, Val Loss=1.4709, lr=0.0010
[2025-05-05 22:56:22,667][train][INFO] - Epoch 48/100, Val Acc=0.7036, Val Loss=1.4758, lr=0.0010
[2025-05-05 22:56:30,062][train][INFO] - Epoch 49/100, Val Acc=0.6989, Val Loss=1.4856, lr=0.0010
[2025-05-05 22:56:37,354][train][INFO] - Epoch 50/100, Val Acc=0.7026, Val Loss=1.4644, lr=0.0010
[2025-05-05 22:56:44,557][train][INFO] - Epoch 51/100, Val Acc=0.7029, Val Loss=1.4522, lr=0.0010
[2025-05-05 22:56:51,805][train][INFO] - Epoch 52/100, Val Acc=0.7028, Val Loss=1.4870, lr=0.0010
[2025-05-05 22:56:59,353][train][INFO] - Epoch 53/100, Val Acc=0.7072, Val Loss=1.4658, lr=0.0010
[2025-05-05 22:57:06,525][train][INFO] - Epoch 54/100, Val Acc=0.7087, Val Loss=1.4581, lr=0.0010
[2025-05-05 22:57:13,677][train][INFO] - Epoch 55/100, Val Acc=0.7017, Val Loss=1.4916, lr=0.0010
[2025-05-05 22:57:20,849][train][INFO] - Epoch 56/100, Val Acc=0.7028, Val Loss=1.4958, lr=0.0010
[2025-05-05 22:57:28,024][train][INFO] - Epoch 57/100, Val Acc=0.7031, Val Loss=1.4845, lr=0.0010
[2025-05-05 22:57:35,542][train][INFO] - Epoch 58/100, Val Acc=0.7015, Val Loss=1.5039, lr=0.0010
[2025-05-05 22:57:43,191][train][INFO] - Epoch 59/100, Val Acc=0.7056, Val Loss=1.4718, lr=0.0010
[2025-05-05 22:57:50,417][train][INFO] - Epoch 60/100, Val Acc=0.7088, Val Loss=1.4880, lr=0.0010
[2025-05-05 22:57:57,195][train][INFO] - Epoch 61/100, Val Acc=0.7068, Val Loss=1.4848, lr=0.0010
[2025-05-05 22:58:04,857][train][INFO] - Epoch 62/100, Val Acc=0.7033, Val Loss=1.5130, lr=0.0010
[2025-05-05 22:58:12,041][train][INFO] - Epoch 63/100, Val Acc=0.7006, Val Loss=1.5186, lr=0.0010
[2025-05-05 22:58:19,557][train][INFO] - Epoch 64/100, Val Acc=0.7066, Val Loss=1.5304, lr=0.0010
[2025-05-05 22:58:27,096][train][INFO] - Epoch 65/100, Val Acc=0.7106, Val Loss=1.4868, lr=0.0010
[2025-05-05 22:58:34,495][train][INFO] - Epoch 66/100, Val Acc=0.7089, Val Loss=1.5122, lr=0.0010
[2025-05-05 22:58:42,010][train][INFO] - Epoch 67/100, Val Acc=0.7043, Val Loss=1.5167, lr=0.0010
[2025-05-05 22:58:49,232][train][INFO] - Epoch 68/100, Val Acc=0.7042, Val Loss=1.5479, lr=0.0010
[2025-05-05 22:58:56,679][train][INFO] - Epoch 69/100, Val Acc=0.7038, Val Loss=1.5225, lr=0.0010
[2025-05-05 22:59:03,922][train][INFO] - Epoch 70/100, Val Acc=0.7019, Val Loss=1.5155, lr=0.0010
[2025-05-05 22:59:10,729][train][INFO] - Epoch 71/100, Val Acc=0.7050, Val Loss=1.5051, lr=0.0010
[2025-05-05 22:59:18,272][train][INFO] - Epoch 72/100, Val Acc=0.7030, Val Loss=1.5248, lr=0.0010
[2025-05-05 22:59:25,899][train][INFO] - Epoch 73/100, Val Acc=0.7007, Val Loss=1.5205, lr=0.0010
[2025-05-05 22:59:33,553][train][INFO] - Epoch 74/100, Val Acc=0.7061, Val Loss=1.5089, lr=0.0010
[2025-05-05 22:59:41,198][train][INFO] - Epoch 75/100, Val Acc=0.7062, Val Loss=1.5131, lr=0.0010
[2025-05-05 22:59:48,707][train][INFO] - Epoch 76/100, Val Acc=0.7017, Val Loss=1.5278, lr=0.0010
[2025-05-05 22:59:55,774][train][INFO] - Epoch 77/100, Val Acc=0.7019, Val Loss=1.5199, lr=0.0010
[2025-05-05 23:00:03,297][train][INFO] - Epoch 78/100, Val Acc=0.7053, Val Loss=1.5160, lr=0.0010
[2025-05-05 23:00:10,190][train][INFO] - Epoch 79/100, Val Acc=0.7022, Val Loss=1.5338, lr=0.0010
[2025-05-05 23:00:17,444][train][INFO] - Epoch 80/100, Val Acc=0.7057, Val Loss=1.5205, lr=0.0010
[2025-05-05 23:00:24,947][train][INFO] - Epoch 81/100, Val Acc=0.7119, Val Loss=1.4878, lr=0.0001
[2025-05-05 23:00:32,342][train][INFO] - Epoch 82/100, Val Acc=0.7131, Val Loss=1.4738, lr=0.0001
[2025-05-05 23:00:39,964][train][INFO] - Epoch 83/100, Val Acc=0.7173, Val Loss=1.4736, lr=0.0001
[2025-05-05 23:00:47,306][train][INFO] - Epoch 84/100, Val Acc=0.7154, Val Loss=1.4743, lr=0.0001
[2025-05-05 23:00:54,793][train][INFO] - Epoch 85/100, Val Acc=0.7180, Val Loss=1.4670, lr=0.0001
[2025-05-05 23:01:02,083][train][INFO] - Epoch 86/100, Val Acc=0.7157, Val Loss=1.4733, lr=0.0001
[2025-05-05 23:01:09,550][train][INFO] - Epoch 87/100, Val Acc=0.7178, Val Loss=1.4702, lr=0.0001
[2025-05-05 23:01:16,883][train][INFO] - Epoch 88/100, Val Acc=0.7162, Val Loss=1.4624, lr=0.0001
[2025-05-05 23:01:24,187][train][INFO] - Epoch 89/100, Val Acc=0.7169, Val Loss=1.4653, lr=0.0001
[2025-05-05 23:01:31,230][train][INFO] - Epoch 90/100, Val Acc=0.7178, Val Loss=1.4678, lr=0.0001
[2025-05-05 23:01:38,767][train][INFO] - Epoch 91/100, Val Acc=0.7178, Val Loss=1.4604, lr=0.0001
[2025-05-05 23:01:46,503][train][INFO] - Epoch 92/100, Val Acc=0.7181, Val Loss=1.4664, lr=0.0001
[2025-05-05 23:01:53,657][train][INFO] - Epoch 93/100, Val Acc=0.7177, Val Loss=1.4600, lr=0.0001
[2025-05-05 23:02:01,172][train][INFO] - Epoch 94/100, Val Acc=0.7178, Val Loss=1.4596, lr=0.0001
[2025-05-05 23:02:07,934][train][INFO] - Epoch 95/100, Val Acc=0.7190, Val Loss=1.4686, lr=0.0001
[2025-05-05 23:02:15,354][train][INFO] - Epoch 96/100, Val Acc=0.7197, Val Loss=1.4649, lr=0.0001
[2025-05-05 23:02:22,803][train][INFO] - Epoch 97/100, Val Acc=0.7214, Val Loss=1.4667, lr=0.0001
[2025-05-05 23:02:29,812][train][INFO] - Epoch 98/100, Val Acc=0.7214, Val Loss=1.4651, lr=0.0001
[2025-05-05 23:02:37,589][train][INFO] - Epoch 99/100, Val Acc=0.7200, Val Loss=1.4664, lr=0.0001
[2025-05-05 23:02:45,078][train][INFO] - Epoch 100/100, Val Acc=0.7198, Val Loss=1.4613, lr=0.0001
[2025-05-05 23:02:50,085][train][INFO] - After training : Train Acc=0.9990  Val Acc=0.7214
[2025-05-05 23:02:50,090][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 23:04:29,284][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 23:06:07,482][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 23:06:07,962][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-05 23:10:05,455][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_metanetwork:
        epochs: 100
        lr: 0.001
        lr_decay_milestones: '20'
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Lucy
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 17

[2025-05-05 23:10:05,514][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-05 23:10:05,514][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-05 23:10:05,514][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-05 23:10:20,298][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-05 23:10:28,303][train][INFO] - Epoch 1/100, Val Acc=0.0966, Val Loss=3.8160, lr=0.0010
[2025-05-05 23:10:35,999][train][INFO] - Epoch 2/100, Val Acc=0.2664, Val Loss=2.8131, lr=0.0010
[2025-05-05 23:10:43,778][train][INFO] - Epoch 3/100, Val Acc=0.4165, Val Loss=2.1593, lr=0.0010
[2025-05-05 23:10:51,391][train][INFO] - Epoch 4/100, Val Acc=0.5332, Val Loss=1.7217, lr=0.0010
[2025-05-05 23:10:59,199][train][INFO] - Epoch 5/100, Val Acc=0.5888, Val Loss=1.5584, lr=0.0010
[2025-05-05 23:11:07,061][train][INFO] - Epoch 6/100, Val Acc=0.6221, Val Loss=1.4408, lr=0.0010
[2025-05-05 23:11:14,872][train][INFO] - Epoch 7/100, Val Acc=0.6537, Val Loss=1.3260, lr=0.0010
[2025-05-05 23:11:22,320][train][INFO] - Epoch 8/100, Val Acc=0.6657, Val Loss=1.3085, lr=0.0010
[2025-05-05 23:11:30,073][train][INFO] - Epoch 9/100, Val Acc=0.6656, Val Loss=1.3186, lr=0.0010
[2025-05-05 23:11:38,126][train][INFO] - Epoch 10/100, Val Acc=0.6772, Val Loss=1.2814, lr=0.0010
[2025-05-05 23:11:45,925][train][INFO] - Epoch 11/100, Val Acc=0.6783, Val Loss=1.2996, lr=0.0010
[2025-05-05 23:11:53,478][train][INFO] - Epoch 12/100, Val Acc=0.6869, Val Loss=1.2834, lr=0.0010
[2025-05-05 23:12:00,990][train][INFO] - Epoch 13/100, Val Acc=0.6859, Val Loss=1.3023, lr=0.0010
[2025-05-05 23:12:08,549][train][INFO] - Epoch 14/100, Val Acc=0.6848, Val Loss=1.3183, lr=0.0010
[2025-05-05 23:12:16,164][train][INFO] - Epoch 15/100, Val Acc=0.6941, Val Loss=1.2976, lr=0.0010
[2025-05-05 23:12:23,590][train][INFO] - Epoch 16/100, Val Acc=0.6939, Val Loss=1.3045, lr=0.0010
[2025-05-05 23:12:31,086][train][INFO] - Epoch 17/100, Val Acc=0.6943, Val Loss=1.3294, lr=0.0010
[2025-05-05 23:12:39,108][train][INFO] - Epoch 18/100, Val Acc=0.6954, Val Loss=1.3211, lr=0.0010
[2025-05-05 23:12:47,068][train][INFO] - Epoch 19/100, Val Acc=0.6965, Val Loss=1.3237, lr=0.0010
[2025-05-05 23:12:54,481][train][INFO] - Epoch 20/100, Val Acc=0.6936, Val Loss=1.3660, lr=0.0010
[2025-05-05 23:13:02,099][train][INFO] - Epoch 21/100, Val Acc=0.7054, Val Loss=1.3000, lr=0.0001
[2025-05-05 23:13:09,425][train][INFO] - Epoch 22/100, Val Acc=0.7079, Val Loss=1.2966, lr=0.0001
[2025-05-05 23:13:16,587][train][INFO] - Epoch 23/100, Val Acc=0.7096, Val Loss=1.2963, lr=0.0001
[2025-05-05 23:13:24,325][train][INFO] - Epoch 24/100, Val Acc=0.7096, Val Loss=1.2949, lr=0.0001
[2025-05-05 23:13:31,713][train][INFO] - Epoch 25/100, Val Acc=0.7120, Val Loss=1.2900, lr=0.0001
[2025-05-05 23:13:39,539][train][INFO] - Epoch 26/100, Val Acc=0.7110, Val Loss=1.2986, lr=0.0001
[2025-05-05 23:13:47,116][train][INFO] - Epoch 27/100, Val Acc=0.7117, Val Loss=1.2971, lr=0.0001
[2025-05-05 23:13:54,757][train][INFO] - Epoch 28/100, Val Acc=0.7121, Val Loss=1.2997, lr=0.0001
[2025-05-05 23:14:02,717][train][INFO] - Epoch 29/100, Val Acc=0.7100, Val Loss=1.3061, lr=0.0001
[2025-05-05 23:14:10,254][train][INFO] - Epoch 30/100, Val Acc=0.7109, Val Loss=1.3047, lr=0.0001
[2025-05-05 23:14:17,938][train][INFO] - Epoch 31/100, Val Acc=0.7116, Val Loss=1.3097, lr=0.0001
[2025-05-05 23:14:25,320][train][INFO] - Epoch 32/100, Val Acc=0.7132, Val Loss=1.3065, lr=0.0001
[2025-05-05 23:14:32,590][train][INFO] - Epoch 33/100, Val Acc=0.7125, Val Loss=1.3108, lr=0.0001
[2025-05-05 23:14:40,233][train][INFO] - Epoch 34/100, Val Acc=0.7146, Val Loss=1.3112, lr=0.0001
[2025-05-05 23:14:47,691][train][INFO] - Epoch 35/100, Val Acc=0.7116, Val Loss=1.3139, lr=0.0001
[2025-05-05 23:14:55,178][train][INFO] - Epoch 36/100, Val Acc=0.7136, Val Loss=1.3118, lr=0.0001
[2025-05-05 23:15:02,729][train][INFO] - Epoch 37/100, Val Acc=0.7114, Val Loss=1.3121, lr=0.0001
[2025-05-05 23:15:10,392][train][INFO] - Epoch 38/100, Val Acc=0.7116, Val Loss=1.3189, lr=0.0001
[2025-05-05 23:15:18,273][train][INFO] - Epoch 39/100, Val Acc=0.7122, Val Loss=1.3182, lr=0.0001
[2025-05-05 23:15:25,802][train][INFO] - Epoch 40/100, Val Acc=0.7119, Val Loss=1.3175, lr=0.0001
[2025-05-05 23:15:33,327][train][INFO] - Epoch 41/100, Val Acc=0.7134, Val Loss=1.3198, lr=0.0001
[2025-05-05 23:15:41,277][train][INFO] - Epoch 42/100, Val Acc=0.7150, Val Loss=1.3189, lr=0.0001
[2025-05-05 23:15:48,948][train][INFO] - Epoch 43/100, Val Acc=0.7131, Val Loss=1.3220, lr=0.0001
[2025-05-05 23:15:56,503][train][INFO] - Epoch 44/100, Val Acc=0.7108, Val Loss=1.3287, lr=0.0001
[2025-05-05 23:16:04,120][train][INFO] - Epoch 45/100, Val Acc=0.7133, Val Loss=1.3197, lr=0.0001
[2025-05-05 23:16:11,958][train][INFO] - Epoch 46/100, Val Acc=0.7131, Val Loss=1.3223, lr=0.0001
[2025-05-05 23:16:19,944][train][INFO] - Epoch 47/100, Val Acc=0.7139, Val Loss=1.3228, lr=0.0001
[2025-05-05 23:16:28,020][train][INFO] - Epoch 48/100, Val Acc=0.7155, Val Loss=1.3297, lr=0.0001
[2025-05-05 23:16:35,265][train][INFO] - Epoch 49/100, Val Acc=0.7152, Val Loss=1.3308, lr=0.0001
[2025-05-05 23:16:43,034][train][INFO] - Epoch 50/100, Val Acc=0.7137, Val Loss=1.3359, lr=0.0001
[2025-05-05 23:16:50,871][train][INFO] - Epoch 51/100, Val Acc=0.7125, Val Loss=1.3313, lr=0.0001
[2025-05-05 23:16:58,092][train][INFO] - Epoch 52/100, Val Acc=0.7130, Val Loss=1.3342, lr=0.0001
[2025-05-05 23:17:06,013][train][INFO] - Epoch 53/100, Val Acc=0.7151, Val Loss=1.3323, lr=0.0001
[2025-05-05 23:17:13,750][train][INFO] - Epoch 54/100, Val Acc=0.7116, Val Loss=1.3282, lr=0.0001
[2025-05-05 23:17:21,333][train][INFO] - Epoch 55/100, Val Acc=0.7146, Val Loss=1.3375, lr=0.0001
[2025-05-05 23:17:28,909][train][INFO] - Epoch 56/100, Val Acc=0.7129, Val Loss=1.3354, lr=0.0001
[2025-05-05 23:17:36,602][train][INFO] - Epoch 57/100, Val Acc=0.7145, Val Loss=1.3348, lr=0.0001
[2025-05-05 23:17:43,881][train][INFO] - Epoch 58/100, Val Acc=0.7125, Val Loss=1.3430, lr=0.0001
[2025-05-05 23:17:51,498][train][INFO] - Epoch 59/100, Val Acc=0.7140, Val Loss=1.3356, lr=0.0001
[2025-05-05 23:17:58,886][train][INFO] - Epoch 60/100, Val Acc=0.7153, Val Loss=1.3379, lr=0.0001
[2025-05-05 23:18:06,854][train][INFO] - Epoch 61/100, Val Acc=0.7143, Val Loss=1.3419, lr=0.0001
[2025-05-05 23:18:14,890][train][INFO] - Epoch 62/100, Val Acc=0.7143, Val Loss=1.3407, lr=0.0001
[2025-05-05 23:18:22,672][train][INFO] - Epoch 63/100, Val Acc=0.7146, Val Loss=1.3428, lr=0.0001
[2025-05-05 23:18:30,561][train][INFO] - Epoch 64/100, Val Acc=0.7149, Val Loss=1.3419, lr=0.0001
[2025-05-05 23:18:37,686][train][INFO] - Epoch 65/100, Val Acc=0.7131, Val Loss=1.3413, lr=0.0001
[2025-05-05 23:18:45,226][train][INFO] - Epoch 66/100, Val Acc=0.7137, Val Loss=1.3491, lr=0.0001
[2025-05-05 23:18:52,784][train][INFO] - Epoch 67/100, Val Acc=0.7141, Val Loss=1.3439, lr=0.0001
[2025-05-05 23:19:00,495][train][INFO] - Epoch 68/100, Val Acc=0.7150, Val Loss=1.3478, lr=0.0001
[2025-05-05 23:19:07,180][train][INFO] - Epoch 69/100, Val Acc=0.7160, Val Loss=1.3476, lr=0.0001
[2025-05-05 23:19:14,594][train][INFO] - Epoch 70/100, Val Acc=0.7138, Val Loss=1.3517, lr=0.0001
[2025-05-05 23:19:21,426][train][INFO] - Epoch 71/100, Val Acc=0.7157, Val Loss=1.3517, lr=0.0001
[2025-05-05 23:19:28,911][train][INFO] - Epoch 72/100, Val Acc=0.7157, Val Loss=1.3547, lr=0.0001
[2025-05-05 23:19:36,168][train][INFO] - Epoch 73/100, Val Acc=0.7161, Val Loss=1.3491, lr=0.0001
[2025-05-05 23:19:43,734][train][INFO] - Epoch 74/100, Val Acc=0.7154, Val Loss=1.3534, lr=0.0001
[2025-05-05 23:19:51,461][train][INFO] - Epoch 75/100, Val Acc=0.7157, Val Loss=1.3504, lr=0.0001
[2025-05-05 23:19:59,393][train][INFO] - Epoch 76/100, Val Acc=0.7158, Val Loss=1.3511, lr=0.0001
[2025-05-05 23:20:06,864][train][INFO] - Epoch 77/100, Val Acc=0.7130, Val Loss=1.3558, lr=0.0001
[2025-05-05 23:20:14,665][train][INFO] - Epoch 78/100, Val Acc=0.7146, Val Loss=1.3554, lr=0.0001
[2025-05-05 23:20:22,437][train][INFO] - Epoch 79/100, Val Acc=0.7145, Val Loss=1.3568, lr=0.0001
[2025-05-05 23:20:30,180][train][INFO] - Epoch 80/100, Val Acc=0.7131, Val Loss=1.3565, lr=0.0001
[2025-05-05 23:20:38,101][train][INFO] - Epoch 81/100, Val Acc=0.7140, Val Loss=1.3591, lr=0.0001
[2025-05-05 23:20:45,653][train][INFO] - Epoch 82/100, Val Acc=0.7153, Val Loss=1.3586, lr=0.0001
[2025-05-05 23:20:53,415][train][INFO] - Epoch 83/100, Val Acc=0.7139, Val Loss=1.3586, lr=0.0001
[2025-05-05 23:21:01,238][train][INFO] - Epoch 84/100, Val Acc=0.7131, Val Loss=1.3633, lr=0.0001
[2025-05-05 23:21:08,758][train][INFO] - Epoch 85/100, Val Acc=0.7134, Val Loss=1.3625, lr=0.0001
[2025-05-05 23:21:16,564][train][INFO] - Epoch 86/100, Val Acc=0.7169, Val Loss=1.3654, lr=0.0001
[2025-05-05 23:21:24,238][train][INFO] - Epoch 87/100, Val Acc=0.7150, Val Loss=1.3618, lr=0.0001
[2025-05-05 23:21:32,074][train][INFO] - Epoch 88/100, Val Acc=0.7159, Val Loss=1.3619, lr=0.0001
[2025-05-05 23:21:39,729][train][INFO] - Epoch 89/100, Val Acc=0.7123, Val Loss=1.3658, lr=0.0001
[2025-05-05 23:21:47,291][train][INFO] - Epoch 90/100, Val Acc=0.7152, Val Loss=1.3703, lr=0.0001
[2025-05-05 23:21:54,623][train][INFO] - Epoch 91/100, Val Acc=0.7141, Val Loss=1.3680, lr=0.0001
[2025-05-05 23:22:02,335][train][INFO] - Epoch 92/100, Val Acc=0.7154, Val Loss=1.3702, lr=0.0001
[2025-05-05 23:22:10,277][train][INFO] - Epoch 93/100, Val Acc=0.7148, Val Loss=1.3703, lr=0.0001
[2025-05-05 23:22:17,696][train][INFO] - Epoch 94/100, Val Acc=0.7147, Val Loss=1.3676, lr=0.0001
[2025-05-05 23:22:24,449][train][INFO] - Epoch 95/100, Val Acc=0.7133, Val Loss=1.3753, lr=0.0001
[2025-05-05 23:22:31,960][train][INFO] - Epoch 96/100, Val Acc=0.7154, Val Loss=1.3688, lr=0.0001
[2025-05-05 23:22:39,393][train][INFO] - Epoch 97/100, Val Acc=0.7138, Val Loss=1.3703, lr=0.0001
[2025-05-05 23:22:47,105][train][INFO] - Epoch 98/100, Val Acc=0.7141, Val Loss=1.3700, lr=0.0001
[2025-05-05 23:22:54,815][train][INFO] - Epoch 99/100, Val Acc=0.7162, Val Loss=1.3744, lr=0.0001
[2025-05-05 23:23:02,009][train][INFO] - Epoch 100/100, Val Acc=0.7131, Val Loss=1.3767, lr=0.0001
[2025-05-05 23:23:07,350][train][INFO] - After training : Train Acc=0.9957  Val Acc=0.7169
[2025-05-05 23:23:07,361][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-05 23:25:00,307][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-05 23:26:52,225][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-05 23:26:52,689][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 11:07:00,695][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 16
      hiddim: 128
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Maga
level: 1
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-06 11:07:00,745][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 11:07:00,745][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 11:07:00,745][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 11:07:23,381][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.3092, lr=0.001
[2025-05-06 11:07:42,087][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0919, lr=0.001
[2025-05-06 11:08:00,144][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=3.5286, lr=0.001
[2025-05-06 11:08:20,202][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.4285, lr=0.001
[2025-05-06 11:08:40,559][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=3.8184, lr=0.001
[2025-05-06 11:08:59,705][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=2.1087, lr=0.001
[2025-05-06 11:09:18,983][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.7206, lr=0.001
[2025-05-06 11:09:37,490][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.4979, lr=0.001
[2025-05-06 11:09:37,520][meta_train][INFO] - epoch_1 saved !
[2025-05-06 11:09:57,288][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=1.0962, lr=0.001
[2025-05-06 11:10:16,118][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=1.2402, lr=0.001
[2025-05-06 11:10:34,092][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2247, lr=0.001
[2025-05-06 11:10:52,663][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.0867, lr=0.001
[2025-05-06 11:11:11,284][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=0.0615, lr=0.001
[2025-05-06 11:11:31,382][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=0.0551, lr=0.001
[2025-05-06 11:11:50,388][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=0.0856, lr=0.001
[2025-05-06 11:12:09,891][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=0.1053, lr=0.001
[2025-05-06 11:12:09,909][meta_train][INFO] - epoch_2 saved !
[2025-05-06 11:12:30,056][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=0.1365, lr=0.001
[2025-05-06 11:12:48,498][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=0.1831, lr=0.001
[2025-05-06 11:13:07,316][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=0.8700, lr=0.001
[2025-05-06 11:13:25,549][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=0.3916, lr=0.001
[2025-05-06 11:13:44,158][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=0.2930, lr=0.001
[2025-05-06 11:14:03,616][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=0.4007, lr=0.001
[2025-05-06 11:14:23,057][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=0.5278, lr=0.001
[2025-05-06 11:14:42,265][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=0.6882, lr=0.001
[2025-05-06 11:14:42,289][meta_train][INFO] - epoch_3 saved !
[2025-05-06 11:15:00,742][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=1.5922, lr=0.001
[2025-05-06 11:15:19,991][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=1.2647, lr=0.001
[2025-05-06 11:15:40,109][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=1.4745, lr=0.001
[2025-05-06 11:15:59,508][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=1.8241, lr=0.001
[2025-05-06 11:16:17,829][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=2.0053, lr=0.001
[2025-05-06 11:16:38,098][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=2.7443, lr=0.001
[2025-05-06 11:16:56,146][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=3.4555, lr=0.001
[2025-05-06 11:17:14,952][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=5.7571, lr=0.001
[2025-05-06 11:17:14,983][meta_train][INFO] - epoch_4 saved !
[2025-05-06 11:17:34,768][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=3.8050, lr=0.001
[2025-05-06 11:17:53,181][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=3.7332, lr=0.001
[2025-05-06 11:18:12,587][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=4.8864, lr=0.001
[2025-05-06 11:18:30,655][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=6.7454, lr=0.001
[2025-05-06 11:18:48,733][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.9151, lr=0.001
[2025-05-06 11:19:07,128][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=7.6931, lr=0.001
[2025-05-06 11:19:26,650][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=4.9433, lr=0.001
[2025-05-06 11:19:46,093][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=4.9208, lr=0.001
[2025-05-06 11:19:46,126][meta_train][INFO] - epoch_5 saved !
[2025-05-06 11:20:04,266][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=6.4155, lr=0.001
[2025-05-06 11:20:22,806][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=5.3798, lr=0.001
[2025-05-06 11:20:42,787][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=4.8268, lr=0.001
[2025-05-06 11:21:02,868][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=5.0371, lr=0.001
[2025-05-06 11:21:20,919][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=7.7630, lr=0.001
[2025-05-06 11:21:39,969][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=5.8688, lr=0.001
[2025-05-06 11:21:59,010][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=5.0059, lr=0.001
[2025-05-06 11:22:18,038][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=8.3281, lr=0.001
[2025-05-06 11:22:18,054][meta_train][INFO] - epoch_6 saved !
[2025-05-06 11:22:37,911][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=4.9874, lr=0.001
[2025-05-06 11:22:56,773][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=7.0864, lr=0.001
[2025-05-06 11:23:14,649][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=8.5477, lr=0.001
[2025-05-06 11:23:34,127][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.7421, lr=0.001
[2025-05-06 11:23:53,875][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=5.0420, lr=0.001
[2025-05-06 11:24:12,495][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=5.7017, lr=0.001
[2025-05-06 11:24:30,919][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=8.2784, lr=0.001
[2025-05-06 11:24:50,103][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=6.2093, lr=0.001
[2025-05-06 11:24:50,136][meta_train][INFO] - epoch_7 saved !
[2025-05-06 11:25:08,284][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=8.2074, lr=0.0001
[2025-05-06 11:25:27,911][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=6.1988, lr=0.0001
[2025-05-06 11:25:47,373][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=5.0138, lr=0.0001
[2025-05-06 11:26:07,556][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=4.8598, lr=0.0001
[2025-05-06 11:26:25,992][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=8.7768, lr=0.0001
[2025-05-06 11:26:44,753][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=5.6788, lr=0.0001
[2025-05-06 11:27:04,718][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7615, lr=0.0001
[2025-05-06 11:27:23,401][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=7.0779, lr=0.0001
[2025-05-06 11:27:23,421][meta_train][INFO] - epoch_8 saved !
[2025-05-06 11:27:42,301][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=5.6857, lr=0.0001
[2025-05-06 11:28:00,346][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=8.2956, lr=0.0001
[2025-05-06 11:28:18,988][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=8.8010, lr=0.0001
[2025-05-06 11:28:39,482][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7625, lr=0.0001
[2025-05-06 11:28:59,593][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=4.8548, lr=0.0001
[2025-05-06 11:29:18,325][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=7.0522, lr=0.0001
[2025-05-06 11:29:37,229][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=6.2115, lr=0.0001
[2025-05-06 11:29:56,091][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=5.0050, lr=0.0001
[2025-05-06 11:29:56,109][meta_train][INFO] - epoch_9 saved !
[2025-05-06 11:30:14,816][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=5.6671, lr=0.0001
[2025-05-06 11:30:33,651][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=8.8096, lr=0.0001
[2025-05-06 11:30:52,749][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=5.0010, lr=0.0001
[2025-05-06 11:31:11,146][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=7.0029, lr=0.0001
[2025-05-06 11:31:29,311][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=8.2818, lr=0.0001
[2025-05-06 11:31:49,525][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.7620, lr=0.0001
[2025-05-06 11:32:08,680][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=6.1951, lr=0.0001
[2025-05-06 11:32:28,718][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=4.8410, lr=0.0001
[2025-05-06 11:32:28,736][meta_train][INFO] - epoch_10 saved !
[2025-05-06 11:32:46,664][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=8.2883, lr=0.0001
[2025-05-06 11:33:06,534][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=4.8391, lr=0.0001
[2025-05-06 11:33:24,639][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=8.7981, lr=0.0001
[2025-05-06 11:33:43,914][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=6.1797, lr=0.0001
[2025-05-06 11:34:01,758][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=6.9585, lr=0.0001
[2025-05-06 11:34:21,734][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.7602, lr=0.0001
[2025-05-06 11:34:41,379][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.9897, lr=0.0001
[2025-05-06 11:34:59,938][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=5.6426, lr=0.0001
[2025-05-06 11:34:59,954][meta_train][INFO] - epoch_11 saved !
[2025-05-06 11:35:18,105][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=8.2621, lr=0.0001
[2025-05-06 11:35:36,685][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=8.7789, lr=0.0001
[2025-05-06 11:35:55,864][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=6.1620, lr=0.0001
[2025-05-06 11:36:15,926][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=4.8286, lr=0.0001
[2025-05-06 11:36:35,740][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.7590, lr=0.0001
[2025-05-06 11:36:54,899][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.9846, lr=0.0001
[2025-05-06 11:37:13,901][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=6.9095, lr=0.0001
[2025-05-06 11:37:32,696][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=5.6297, lr=0.0001
[2025-05-06 11:37:32,725][meta_train][INFO] - epoch_12 saved !
[2025-05-06 11:37:51,154][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=8.2430, lr=0.0001
[2025-05-06 11:38:09,775][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=6.8879, lr=0.0001
[2025-05-06 11:38:28,567][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=5.6195, lr=0.0001
[2025-05-06 11:38:48,101][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.9789, lr=0.0001
[2025-05-06 11:39:08,439][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=4.8208, lr=0.0001
[2025-05-06 11:39:27,698][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=6.1268, lr=0.0001
[2025-05-06 11:39:47,833][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.7571, lr=0.0001
[2025-05-06 11:40:06,779][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=8.7322, lr=0.0001
[2025-05-06 11:40:06,813][meta_train][INFO] - epoch_13 saved !
[2025-05-06 11:40:26,127][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=5.6112, lr=0.0001
[2025-05-06 11:40:45,395][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.9752, lr=0.0001
[2025-05-06 11:41:05,569][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=4.8173, lr=0.0001
[2025-05-06 11:41:26,166][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.7556, lr=0.0001
[2025-05-06 11:41:44,307][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=6.8336, lr=0.0001
[2025-05-06 11:42:03,666][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=6.1108, lr=0.0001
[2025-05-06 11:42:22,491][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=8.2065, lr=0.0001
[2025-05-06 11:42:40,989][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=8.7012, lr=0.0001
[2025-05-06 11:42:41,006][meta_train][INFO] - epoch_14 saved !
[2025-05-06 11:42:59,636][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=6.8001, lr=0.0001
[2025-05-06 11:43:19,418][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.7540, lr=0.0001
[2025-05-06 11:43:38,294][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=8.1714, lr=0.0001
[2025-05-06 11:43:58,091][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=4.8100, lr=0.0001
[2025-05-06 11:44:17,724][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=6.0802, lr=0.0001
[2025-05-06 11:44:37,166][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.9656, lr=0.0001
[2025-05-06 11:44:56,076][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=5.5797, lr=0.0001
[2025-05-06 11:45:14,926][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=8.6572, lr=0.0001
[2025-05-06 11:45:14,961][meta_train][INFO] - epoch_15 saved !
[2025-05-06 11:45:33,208][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=6.7554, lr=0.0001
[2025-05-06 11:45:52,800][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.9621, lr=0.0001
[2025-05-06 11:46:11,858][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=5.5667, lr=0.0001
[2025-05-06 11:46:30,256][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=8.6332, lr=0.0001
[2025-05-06 11:46:48,925][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=8.1262, lr=0.0001
[2025-05-06 11:47:09,054][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=4.8027, lr=0.0001
[2025-05-06 11:47:28,516][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=6.0454, lr=0.0001
[2025-05-06 11:47:48,675][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.7502, lr=0.0001
[2025-05-06 11:47:48,694][meta_train][INFO] - epoch_16 saved !
[2025-05-06 11:48:07,655][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=6.7058, lr=0.0001
[2025-05-06 11:48:27,869][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=4.8011, lr=0.0001
[2025-05-06 11:48:48,024][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.7497, lr=0.0001
[2025-05-06 11:49:06,784][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=8.1145, lr=0.0001
[2025-05-06 11:49:25,949][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=6.0399, lr=0.0001
[2025-05-06 11:49:45,242][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.9543, lr=0.0001
[2025-05-06 11:50:04,535][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=5.5454, lr=0.0001
[2025-05-06 11:50:23,222][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=8.5718, lr=0.0001
[2025-05-06 11:50:23,241][meta_train][INFO] - epoch_17 saved !
[2025-05-06 11:50:41,983][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=8.5646, lr=0.0001
[2025-05-06 11:51:02,288][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=4.7958, lr=0.0001
[2025-05-06 11:51:21,862][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.9495, lr=0.0001
[2025-05-06 11:51:40,392][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=6.6440, lr=0.0001
[2025-05-06 11:51:59,149][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=5.5331, lr=0.0001
[2025-05-06 11:52:19,387][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.7467, lr=0.0001
[2025-05-06 11:52:38,930][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=6.0141, lr=0.0001
[2025-05-06 11:52:57,107][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=8.0808, lr=0.0001
[2025-05-06 11:52:57,130][meta_train][INFO] - epoch_18 saved !
[2025-05-06 11:53:15,828][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=8.5229, lr=0.0001
[2025-05-06 11:53:34,369][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=6.6229, lr=0.0001
[2025-05-06 11:53:52,659][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=8.0504, lr=0.0001
[2025-05-06 11:54:12,835][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.7446, lr=0.0001
[2025-05-06 11:54:33,129][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=4.7894, lr=0.0001
[2025-05-06 11:54:51,650][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=5.5131, lr=0.0001
[2025-05-06 11:55:11,031][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.9432, lr=0.0001
[2025-05-06 11:55:30,467][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=5.9877, lr=0.0001
[2025-05-06 11:55:30,497][meta_train][INFO] - epoch_19 saved !
[2025-05-06 11:55:49,564][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=5.5149, lr=0.0001
[2025-05-06 11:56:09,341][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=5.9784, lr=0.0001
[2025-05-06 11:56:27,685][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=6.5736, lr=0.0001
[2025-05-06 11:56:45,747][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=8.4467, lr=0.0001
[2025-05-06 11:57:06,494][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.7420, lr=0.0001
[2025-05-06 11:57:26,482][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=4.7852, lr=0.0001
[2025-05-06 11:57:44,971][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=8.0162, lr=0.0001
[2025-05-06 11:58:04,325][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.9375, lr=0.0001
[2025-05-06 11:58:04,342][meta_train][INFO] - epoch_20 saved !
[2025-05-06 11:58:22,718][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=8.0159, lr=0.0001
[2025-05-06 11:58:41,493][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=8.4146, lr=0.0001
[2025-05-06 11:59:00,835][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=5.9405, lr=0.0001
[2025-05-06 11:59:21,235][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=4.7815, lr=0.0001
[2025-05-06 11:59:40,219][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=5.4758, lr=0.0001
[2025-05-06 12:00:00,454][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.7394, lr=0.0001
[2025-05-06 12:00:21,515][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=6.5119, lr=0.0001
[2025-05-06 12:00:43,444][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.9322, lr=0.0001
[2025-05-06 12:00:43,466][meta_train][INFO] - epoch_21 saved !
[2025-05-06 12:01:04,081][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.9319, lr=0.0001
[2025-05-06 12:01:23,104][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=5.9309, lr=0.0001
[2025-05-06 12:01:41,844][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=6.4991, lr=0.0001
[2025-05-06 12:02:01,484][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.7786, lr=0.0001
[2025-05-06 12:02:21,564][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.7376, lr=0.0001
[2025-05-06 12:02:39,955][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=7.9651, lr=0.0001
[2025-05-06 12:02:58,715][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=8.3309, lr=0.0001
[2025-05-06 12:03:17,424][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=5.4623, lr=0.0001
[2025-05-06 12:03:17,453][meta_train][INFO] - epoch_22 saved !
[2025-05-06 12:03:38,463][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=4.7763, lr=0.0001
[2025-05-06 12:03:57,679][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=5.8984, lr=0.0001
[2025-05-06 12:04:16,595][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=5.4549, lr=0.0001
[2025-05-06 12:04:36,160][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.9244, lr=0.0001
[2025-05-06 12:04:55,822][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.7356, lr=0.0001
[2025-05-06 12:05:14,294][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=8.2901, lr=0.0001
[2025-05-06 12:05:32,621][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=6.4507, lr=0.0001
[2025-05-06 12:05:50,976][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=7.9319, lr=0.0001
[2025-05-06 12:05:50,993][meta_train][INFO] - epoch_23 saved !
[2025-05-06 12:06:09,424][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=6.4253, lr=0.0001
[2025-05-06 12:06:29,124][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.7341, lr=0.0001
[2025-05-06 12:06:48,412][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.9200, lr=0.0001
[2025-05-06 12:07:06,893][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=5.4380, lr=0.0001
[2025-05-06 12:07:25,695][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=8.2373, lr=0.0001
[2025-05-06 12:07:45,758][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.7702, lr=0.0001
[2025-05-06 12:08:03,597][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=7.8975, lr=0.0001
[2025-05-06 12:08:22,703][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=5.8467, lr=0.0001
[2025-05-06 12:08:22,732][meta_train][INFO] - epoch_24 saved !
[2025-05-06 12:08:41,191][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=6.3756, lr=0.0001
[2025-05-06 12:09:00,044][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=5.8296, lr=0.0001
[2025-05-06 12:09:18,111][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=7.8594, lr=0.0001
[2025-05-06 12:09:36,721][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=8.1693, lr=0.0001
[2025-05-06 12:09:56,775][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7310, lr=0.0001
[2025-05-06 12:10:15,381][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.9119, lr=0.0001
[2025-05-06 12:10:35,679][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.7645, lr=0.0001
[2025-05-06 12:10:54,132][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=5.4064, lr=0.0001
[2025-05-06 12:10:54,151][meta_train][INFO] - epoch_25 saved !
[2025-05-06 12:11:14,467][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.7299, lr=0.0001
[2025-05-06 12:11:33,335][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.9095, lr=0.0001
[2025-05-06 12:11:51,671][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=7.8319, lr=0.0001
[2025-05-06 12:12:09,669][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=6.3256, lr=0.0001
[2025-05-06 12:12:28,192][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=8.1039, lr=0.0001
[2025-05-06 12:12:47,217][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=5.7882, lr=0.0001
[2025-05-06 12:13:06,365][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=5.3830, lr=0.0001
[2025-05-06 12:13:26,096][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.7599, lr=0.0001
[2025-05-06 12:13:26,112][meta_train][INFO] - epoch_26 saved !
[2025-05-06 12:13:45,977][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.7597, lr=0.0001
[2025-05-06 12:14:05,112][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.9034, lr=0.0001
[2025-05-06 12:14:23,116][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=8.0613, lr=0.0001
[2025-05-06 12:14:41,306][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=7.7974, lr=0.0001
[2025-05-06 12:15:00,975][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.7269, lr=0.0001
[2025-05-06 12:15:20,563][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=5.7632, lr=0.0001
[2025-05-06 12:15:39,152][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=5.3702, lr=0.0001
[2025-05-06 12:15:57,864][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=6.2660, lr=0.0001
[2025-05-06 12:15:57,890][meta_train][INFO] - epoch_27 saved !
[2025-05-06 12:16:17,059][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.8988, lr=0.0001
[2025-05-06 12:16:35,929][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=5.7522, lr=0.0001
[2025-05-06 12:16:54,326][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=7.7645, lr=0.0001
[2025-05-06 12:17:12,504][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=7.9822, lr=0.0001
[2025-05-06 12:17:32,517][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.7543, lr=0.0001
[2025-05-06 12:17:50,808][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=6.2206, lr=0.0001
[2025-05-06 12:18:09,541][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=5.3459, lr=0.0001
[2025-05-06 12:18:29,203][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7242, lr=0.0001
[2025-05-06 12:18:29,220][meta_train][INFO] - epoch_28 saved !
[2025-05-06 12:18:47,607][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=7.9436, lr=0.0001
[2025-05-06 12:19:07,351][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.7523, lr=0.0001
[2025-05-06 12:19:25,582][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=7.7144, lr=0.0001
[2025-05-06 12:19:44,981][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.8885, lr=0.0001
[2025-05-06 12:20:04,539][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=5.6967, lr=0.0001
[2025-05-06 12:20:24,566][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.7225, lr=0.0001
[2025-05-06 12:20:43,110][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=5.3304, lr=0.0001
[2025-05-06 12:20:57,541][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 16
      hiddim: 128
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Maga
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-06 12:20:57,630][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 12:20:57,630][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 12:20:57,630][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 12:21:01,491][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=6.1839, lr=0.0001
[2025-05-06 12:21:01,507][meta_train][INFO] - epoch_29 saved !
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 12:21:07,268][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 16
      hiddim: 128
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Maga
level: 1
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-06 12:21:07,324][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 12:21:07,324][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 12:21:07,324][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 12:21:11,370][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 12:21:19,660][train][INFO] - Epoch 1/100, Val Acc=0.4607, Val Loss=2.1075, lr=0.0100
[2025-05-06 12:21:21,365][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 12:21:21,491][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.8857, lr=0.0001
[2025-05-06 12:21:26,701][train][INFO] - Epoch 2/100, Val Acc=0.5503, Val Loss=1.8120, lr=0.0100
[2025-05-06 12:21:29,826][train][INFO] - Epoch 1/100, Val Acc=0.1720, Val Loss=3.2283, lr=0.0100
[2025-05-06 12:21:34,998][train][INFO] - Epoch 3/100, Val Acc=0.5774, Val Loss=1.6895, lr=0.0100
[2025-05-06 12:21:37,851][train][INFO] - Epoch 2/100, Val Acc=0.3601, Val Loss=2.3629, lr=0.0100
[2025-05-06 12:21:41,822][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7216, lr=0.0001
[2025-05-06 12:21:42,344][train][INFO] - Epoch 4/100, Val Acc=0.5855, Val Loss=1.6816, lr=0.0100
[2025-05-06 12:21:45,406][train][INFO] - Epoch 3/100, Val Acc=0.3564, Val Loss=2.5580, lr=0.0100
[2025-05-06 12:21:50,204][train][INFO] - Epoch 5/100, Val Acc=0.6201, Val Loss=1.5397, lr=0.0100
[2025-05-06 12:21:52,946][train][INFO] - Epoch 4/100, Val Acc=0.4922, Val Loss=1.8621, lr=0.0100
[2025-05-06 12:21:58,294][train][INFO] - Epoch 6/100, Val Acc=0.6068, Val Loss=1.6048, lr=0.0100
[2025-05-06 12:22:00,561][train][INFO] - Epoch 5/100, Val Acc=0.5281, Val Loss=1.7775, lr=0.0100
[2025-05-06 12:22:02,245][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=5.6841, lr=0.0001
[2025-05-06 12:22:06,801][train][INFO] - Epoch 7/100, Val Acc=0.6122, Val Loss=1.6106, lr=0.0100
[2025-05-06 12:22:08,381][train][INFO] - Epoch 6/100, Val Acc=0.5207, Val Loss=1.8464, lr=0.0100
[2025-05-06 12:22:14,838][train][INFO] - Epoch 8/100, Val Acc=0.6282, Val Loss=1.5570, lr=0.0100
[2025-05-06 12:22:15,967][train][INFO] - Epoch 7/100, Val Acc=0.5346, Val Loss=1.8050, lr=0.0100
[2025-05-06 12:22:21,122][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=6.1608, lr=0.0001
[2025-05-06 12:22:22,480][train][INFO] - Epoch 9/100, Val Acc=0.6231, Val Loss=1.5935, lr=0.0100
[2025-05-06 12:22:23,676][train][INFO] - Epoch 8/100, Val Acc=0.5814, Val Loss=1.6315, lr=0.0100
[2025-05-06 12:22:30,504][train][INFO] - Epoch 10/100, Val Acc=0.6350, Val Loss=1.5335, lr=0.0100
[2025-05-06 12:22:31,685][train][INFO] - Epoch 9/100, Val Acc=0.5450, Val Loss=1.8402, lr=0.0100
[2025-05-06 12:22:38,663][train][INFO] - Epoch 10/100, Val Acc=0.5909, Val Loss=1.6238, lr=0.0100
[2025-05-06 12:22:38,965][train][INFO] - Epoch 11/100, Val Acc=0.6334, Val Loss=1.5619, lr=0.0100
[2025-05-06 12:22:40,870][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=5.3157, lr=0.0001
[2025-05-06 12:22:46,545][train][INFO] - Epoch 11/100, Val Acc=0.6100, Val Loss=1.5253, lr=0.0100
[2025-05-06 12:22:46,885][train][INFO] - Epoch 12/100, Val Acc=0.6388, Val Loss=1.5398, lr=0.0100
[2025-05-06 12:22:54,491][train][INFO] - Epoch 12/100, Val Acc=0.5936, Val Loss=1.6165, lr=0.0100
[2025-05-06 12:22:55,208][train][INFO] - Epoch 13/100, Val Acc=0.6367, Val Loss=1.5710, lr=0.0100
[2025-05-06 12:22:59,891][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=7.6841, lr=0.0001
[2025-05-06 12:23:02,841][train][INFO] - Epoch 13/100, Val Acc=0.6097, Val Loss=1.5835, lr=0.0100
[2025-05-06 12:23:03,214][train][INFO] - Epoch 14/100, Val Acc=0.6427, Val Loss=1.5392, lr=0.0100
[2025-05-06 12:23:09,879][train][INFO] - Epoch 14/100, Val Acc=0.6223, Val Loss=1.4950, lr=0.0100
[2025-05-06 12:23:10,817][train][INFO] - Epoch 15/100, Val Acc=0.6441, Val Loss=1.5316, lr=0.0100
[2025-05-06 12:23:17,552][train][INFO] - Epoch 15/100, Val Acc=0.6199, Val Loss=1.5208, lr=0.0100
[2025-05-06 12:23:18,436][train][INFO] - Epoch 16/100, Val Acc=0.6412, Val Loss=1.5526, lr=0.0100
[2025-05-06 12:23:20,578][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.7474, lr=0.0001
[2025-05-06 12:23:25,490][train][INFO] - Epoch 16/100, Val Acc=0.6134, Val Loss=1.5380, lr=0.0100
[2025-05-06 12:23:26,320][train][INFO] - Epoch 17/100, Val Acc=0.6287, Val Loss=1.6226, lr=0.0100
[2025-05-06 12:23:33,259][train][INFO] - Epoch 17/100, Val Acc=0.6299, Val Loss=1.4971, lr=0.0100
[2025-05-06 12:23:34,475][train][INFO] - Epoch 18/100, Val Acc=0.6604, Val Loss=1.4643, lr=0.0100
[2025-05-06 12:23:39,771][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=7.8304, lr=0.0001
[2025-05-06 12:23:39,800][meta_train][INFO] - epoch_30 saved !
[2025-05-06 12:23:41,068][train][INFO] - Epoch 18/100, Val Acc=0.6227, Val Loss=1.5375, lr=0.0100
[2025-05-06 12:23:41,537][train][INFO] - Epoch 19/100, Val Acc=0.6502, Val Loss=1.4929, lr=0.0100
[2025-05-06 12:23:48,650][train][INFO] - Epoch 19/100, Val Acc=0.6405, Val Loss=1.4495, lr=0.0100
[2025-05-06 12:23:49,617][train][INFO] - Epoch 20/100, Val Acc=0.6549, Val Loss=1.5190, lr=0.0100
[2025-05-06 12:23:56,151][train][INFO] - Epoch 20/100, Val Acc=0.6311, Val Loss=1.4858, lr=0.0100
[2025-05-06 12:23:57,496][train][INFO] - Epoch 21/100, Val Acc=0.6605, Val Loss=1.4920, lr=0.0100
[2025-05-06 12:24:01,094][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.7466, lr=0.0001
[2025-05-06 12:24:04,188][train][INFO] - Epoch 21/100, Val Acc=0.6264, Val Loss=1.5425, lr=0.0100
[2025-05-06 12:24:05,979][train][INFO] - Epoch 22/100, Val Acc=0.6448, Val Loss=1.5859, lr=0.0100
[2025-05-06 12:24:11,850][train][INFO] - Epoch 22/100, Val Acc=0.6441, Val Loss=1.4415, lr=0.0100
[2025-05-06 12:24:13,735][train][INFO] - Epoch 23/100, Val Acc=0.6437, Val Loss=1.5849, lr=0.0100
[2025-05-06 12:24:19,213][train][INFO] - Epoch 23/100, Val Acc=0.6327, Val Loss=1.5037, lr=0.0100
[2025-05-06 12:24:20,973][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.8787, lr=0.0001
[2025-05-06 12:24:21,878][train][INFO] - Epoch 24/100, Val Acc=0.6248, Val Loss=1.6832, lr=0.0100
[2025-05-06 12:24:27,247][train][INFO] - Epoch 24/100, Val Acc=0.6438, Val Loss=1.4822, lr=0.0100
[2025-05-06 12:24:29,070][train][INFO] - Epoch 25/100, Val Acc=0.6532, Val Loss=1.5105, lr=0.0100
[2025-05-06 12:24:34,755][train][INFO] - Epoch 25/100, Val Acc=0.6391, Val Loss=1.4835, lr=0.0100
[2025-05-06 12:24:37,291][train][INFO] - Epoch 26/100, Val Acc=0.6524, Val Loss=1.5702, lr=0.0100
[2025-05-06 12:24:41,139][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=5.6575, lr=0.0001
[2025-05-06 12:24:43,281][train][INFO] - Epoch 26/100, Val Acc=0.6081, Val Loss=1.7121, lr=0.0100
[2025-05-06 12:24:45,596][train][INFO] - Epoch 27/100, Val Acc=0.6437, Val Loss=1.6210, lr=0.0100
[2025-05-06 12:24:51,509][train][INFO] - Epoch 27/100, Val Acc=0.6295, Val Loss=1.5795, lr=0.0100
[2025-05-06 12:24:53,541][train][INFO] - Epoch 28/100, Val Acc=0.6335, Val Loss=1.7206, lr=0.0100
[2025-05-06 12:24:59,286][train][INFO] - Epoch 28/100, Val Acc=0.6170, Val Loss=1.6435, lr=0.0100
[2025-05-06 12:25:00,866][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=5.3017, lr=0.0001
[2025-05-06 12:25:01,022][train][INFO] - Epoch 29/100, Val Acc=0.6482, Val Loss=1.5632, lr=0.0100
[2025-05-06 12:25:07,399][train][INFO] - Epoch 29/100, Val Acc=0.6491, Val Loss=1.5030, lr=0.0100
[2025-05-06 12:25:08,858][train][INFO] - Epoch 30/100, Val Acc=0.6523, Val Loss=1.5760, lr=0.0100
[2025-05-06 12:25:15,320][train][INFO] - Epoch 30/100, Val Acc=0.6415, Val Loss=1.5305, lr=0.0100
[2025-05-06 12:25:16,465][train][INFO] - Epoch 31/100, Val Acc=0.6576, Val Loss=1.5169, lr=0.0100
[2025-05-06 12:25:20,044][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=7.7893, lr=0.0001
[2025-05-06 12:25:23,067][train][INFO] - Epoch 31/100, Val Acc=0.6284, Val Loss=1.5817, lr=0.0100
[2025-05-06 12:25:24,635][train][INFO] - Epoch 32/100, Val Acc=0.6515, Val Loss=1.5981, lr=0.0100
[2025-05-06 12:25:30,835][train][INFO] - Epoch 32/100, Val Acc=0.6381, Val Loss=1.6053, lr=0.0100
[2025-05-06 12:25:32,408][train][INFO] - Epoch 33/100, Val Acc=0.6499, Val Loss=1.5954, lr=0.0100
[2025-05-06 12:25:39,166][train][INFO] - Epoch 33/100, Val Acc=0.6280, Val Loss=1.6084, lr=0.0100
[2025-05-06 12:25:39,632][train][INFO] - Epoch 34/100, Val Acc=0.6516, Val Loss=1.5846, lr=0.0100
[2025-05-06 12:25:40,760][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.7188, lr=0.0001
[2025-05-06 12:25:47,466][train][INFO] - Epoch 34/100, Val Acc=0.6350, Val Loss=1.6354, lr=0.0100
[2025-05-06 12:25:47,577][train][INFO] - Epoch 35/100, Val Acc=0.6506, Val Loss=1.6146, lr=0.0100
[2025-05-06 12:25:55,330][train][INFO] - Epoch 36/100, Val Acc=0.6512, Val Loss=1.6162, lr=0.0100
[2025-05-06 12:25:55,650][train][INFO] - Epoch 35/100, Val Acc=0.6413, Val Loss=1.5766, lr=0.0100
[2025-05-06 12:25:59,729][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=6.1103, lr=0.0001
[2025-05-06 12:26:03,387][train][INFO] - Epoch 37/100, Val Acc=0.6518, Val Loss=1.6035, lr=0.0100
[2025-05-06 12:26:03,484][train][INFO] - Epoch 36/100, Val Acc=0.6484, Val Loss=1.5297, lr=0.0100
[2025-05-06 12:26:11,452][train][INFO] - Epoch 38/100, Val Acc=0.6544, Val Loss=1.5737, lr=0.0100
[2025-05-06 12:26:11,545][train][INFO] - Epoch 37/100, Val Acc=0.6517, Val Loss=1.5013, lr=0.0100
[2025-05-06 12:26:19,064][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=7.6395, lr=0.0001
[2025-05-06 12:26:19,095][meta_train][INFO] - epoch_31 saved !
[2025-05-06 12:26:19,262][train][INFO] - Epoch 38/100, Val Acc=0.6388, Val Loss=1.6080, lr=0.0100
[2025-05-06 12:26:19,458][train][INFO] - Epoch 39/100, Val Acc=0.6475, Val Loss=1.6481, lr=0.0100
[2025-05-06 12:26:27,597][train][INFO] - Epoch 39/100, Val Acc=0.6341, Val Loss=1.6607, lr=0.0100
[2025-05-06 12:26:27,656][train][INFO] - Epoch 40/100, Val Acc=0.6501, Val Loss=1.6038, lr=0.0100
[2025-05-06 12:26:35,395][train][INFO] - Epoch 40/100, Val Acc=0.6409, Val Loss=1.5990, lr=0.0100
[2025-05-06 12:26:35,581][train][INFO] - Epoch 41/100, Val Acc=0.6741, Val Loss=1.4748, lr=0.0100
[2025-05-06 12:26:39,803][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.7180, lr=0.0001
[2025-05-06 12:26:43,730][train][INFO] - Epoch 41/100, Val Acc=0.6382, Val Loss=1.6527, lr=0.0100
[2025-05-06 12:26:43,936][train][INFO] - Epoch 42/100, Val Acc=0.6512, Val Loss=1.6219, lr=0.0100
[2025-05-06 12:26:51,685][train][INFO] - Epoch 42/100, Val Acc=0.6324, Val Loss=1.6457, lr=0.0100
[2025-05-06 12:26:52,012][train][INFO] - Epoch 43/100, Val Acc=0.6552, Val Loss=1.6198, lr=0.0100
[2025-05-06 12:26:59,105][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=7.6266, lr=0.0001
[2025-05-06 12:26:59,663][train][INFO] - Epoch 43/100, Val Acc=0.6373, Val Loss=1.5943, lr=0.0100
[2025-05-06 12:27:00,449][train][INFO] - Epoch 44/100, Val Acc=0.6483, Val Loss=1.6154, lr=0.0100
[2025-05-06 12:27:07,125][train][INFO] - Epoch 44/100, Val Acc=0.6433, Val Loss=1.6326, lr=0.0100
[2025-05-06 12:27:08,574][train][INFO] - Epoch 45/100, Val Acc=0.6513, Val Loss=1.6049, lr=0.0100
[2025-05-06 12:27:14,463][train][INFO] - Epoch 45/100, Val Acc=0.6407, Val Loss=1.6106, lr=0.0100
[2025-05-06 12:27:15,850][train][INFO] - Epoch 46/100, Val Acc=0.6453, Val Loss=1.6676, lr=0.0100
[2025-05-06 12:27:19,323][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=5.6253, lr=0.0001
[2025-05-06 12:27:22,496][train][INFO] - Epoch 46/100, Val Acc=0.6477, Val Loss=1.5433, lr=0.0100
[2025-05-06 12:27:23,949][train][INFO] - Epoch 47/100, Val Acc=0.6598, Val Loss=1.5518, lr=0.0100
[2025-05-06 12:27:29,650][train][INFO] - Epoch 47/100, Val Acc=0.6334, Val Loss=1.6782, lr=0.0100
[2025-05-06 12:27:31,972][train][INFO] - Epoch 48/100, Val Acc=0.6601, Val Loss=1.6037, lr=0.0100
[2025-05-06 12:27:37,562][train][INFO] - Epoch 48/100, Val Acc=0.6433, Val Loss=1.6254, lr=0.0100
[2025-05-06 12:27:38,352][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=7.7250, lr=0.0001
[2025-05-06 12:27:39,364][train][INFO] - Epoch 49/100, Val Acc=0.6619, Val Loss=1.5768, lr=0.0100
[2025-05-06 12:27:45,902][train][INFO] - Epoch 49/100, Val Acc=0.6427, Val Loss=1.6261, lr=0.0100
[2025-05-06 12:27:47,859][train][INFO] - Epoch 50/100, Val Acc=0.6590, Val Loss=1.5947, lr=0.0100
[2025-05-06 12:27:53,609][train][INFO] - Epoch 50/100, Val Acc=0.6461, Val Loss=1.6149, lr=0.0100
[2025-05-06 12:27:55,078][train][INFO] - Epoch 51/100, Val Acc=0.6516, Val Loss=1.6185, lr=0.0100
[2025-05-06 12:27:59,189][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.7407, lr=0.0001
[2025-05-06 12:28:01,641][train][INFO] - Epoch 51/100, Val Acc=0.6466, Val Loss=1.5956, lr=0.0100
[2025-05-06 12:28:03,118][train][INFO] - Epoch 52/100, Val Acc=0.6588, Val Loss=1.6082, lr=0.0100
[2025-05-06 12:28:08,990][train][INFO] - Epoch 52/100, Val Acc=0.6358, Val Loss=1.6756, lr=0.0100
[2025-05-06 12:28:10,880][train][INFO] - Epoch 53/100, Val Acc=0.6440, Val Loss=1.6562, lr=0.0100
[2025-05-06 12:28:16,949][train][INFO] - Epoch 53/100, Val Acc=0.6358, Val Loss=1.6750, lr=0.0100
[2025-05-06 12:28:18,330][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=6.0634, lr=0.0001
[2025-05-06 12:28:18,609][train][INFO] - Epoch 54/100, Val Acc=0.6631, Val Loss=1.5394, lr=0.0100
[2025-05-06 12:28:25,129][train][INFO] - Epoch 54/100, Val Acc=0.6441, Val Loss=1.6655, lr=0.0100
[2025-05-06 12:28:26,180][train][INFO] - Epoch 55/100, Val Acc=0.6569, Val Loss=1.5974, lr=0.0100
[2025-05-06 12:28:33,562][train][INFO] - Epoch 55/100, Val Acc=0.6359, Val Loss=1.6783, lr=0.0100
[2025-05-06 12:28:34,010][train][INFO] - Epoch 56/100, Val Acc=0.6558, Val Loss=1.5827, lr=0.0100
[2025-05-06 12:28:37,487][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=5.2714, lr=0.0001
[2025-05-06 12:28:41,495][train][INFO] - Epoch 56/100, Val Acc=0.6467, Val Loss=1.6272, lr=0.0100
[2025-05-06 12:28:42,253][train][INFO] - Epoch 57/100, Val Acc=0.6542, Val Loss=1.6179, lr=0.0100
[2025-05-06 12:28:49,212][train][INFO] - Epoch 57/100, Val Acc=0.6488, Val Loss=1.5823, lr=0.0100
[2025-05-06 12:28:49,723][train][INFO] - Epoch 58/100, Val Acc=0.6585, Val Loss=1.5709, lr=0.0100
[2025-05-06 12:28:56,824][train][INFO] - Epoch 58/100, Val Acc=0.6465, Val Loss=1.6041, lr=0.0100
[2025-05-06 12:28:57,779][train][INFO] - Epoch 59/100, Val Acc=0.6459, Val Loss=1.6487, lr=0.0100
[2025-05-06 12:28:57,919][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.8665, lr=0.0001
[2025-05-06 12:28:57,942][meta_train][INFO] - epoch_32 saved !
[2025-05-06 12:29:05,152][train][INFO] - Epoch 59/100, Val Acc=0.6381, Val Loss=1.6059, lr=0.0100
[2025-05-06 12:29:05,439][train][INFO] - Epoch 60/100, Val Acc=0.6546, Val Loss=1.6309, lr=0.0100
[2025-05-06 12:29:13,146][train][INFO] - Epoch 61/100, Val Acc=0.7075, Val Loss=1.3304, lr=0.0010
[2025-05-06 12:29:13,400][train][INFO] - Epoch 60/100, Val Acc=0.6486, Val Loss=1.6195, lr=0.0100
[2025-05-06 12:29:18,520][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.7390, lr=0.0001
[2025-05-06 12:29:20,793][train][INFO] - Epoch 62/100, Val Acc=0.7140, Val Loss=1.3102, lr=0.0010
[2025-05-06 12:29:21,706][train][INFO] - Epoch 61/100, Val Acc=0.6992, Val Loss=1.3290, lr=0.0010
[2025-05-06 12:29:28,415][train][INFO] - Epoch 63/100, Val Acc=0.7158, Val Loss=1.3205, lr=0.0010
[2025-05-06 12:29:29,724][train][INFO] - Epoch 62/100, Val Acc=0.7042, Val Loss=1.3231, lr=0.0010
[2025-05-06 12:29:36,451][train][INFO] - Epoch 64/100, Val Acc=0.7151, Val Loss=1.3287, lr=0.0010
[2025-05-06 12:29:37,862][train][INFO] - Epoch 63/100, Val Acc=0.7054, Val Loss=1.3192, lr=0.0010
[2025-05-06 12:29:38,644][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.8652, lr=0.0001
[2025-05-06 12:29:44,592][train][INFO] - Epoch 65/100, Val Acc=0.7163, Val Loss=1.3330, lr=0.0010
[2025-05-06 12:29:45,662][train][INFO] - Epoch 64/100, Val Acc=0.7071, Val Loss=1.3230, lr=0.0010
[2025-05-06 12:29:51,764][train][INFO] - Epoch 66/100, Val Acc=0.7185, Val Loss=1.3413, lr=0.0010
[2025-05-06 12:29:53,726][train][INFO] - Epoch 65/100, Val Acc=0.7076, Val Loss=1.3272, lr=0.0010
[2025-05-06 12:29:57,665][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=7.5775, lr=0.0001
[2025-05-06 12:29:59,947][train][INFO] - Epoch 67/100, Val Acc=0.7199, Val Loss=1.3316, lr=0.0010
[2025-05-06 12:30:01,885][train][INFO] - Epoch 66/100, Val Acc=0.7083, Val Loss=1.3353, lr=0.0010
[2025-05-06 12:30:07,917][train][INFO] - Epoch 68/100, Val Acc=0.7205, Val Loss=1.3359, lr=0.0010
[2025-05-06 12:30:09,588][train][INFO] - Epoch 67/100, Val Acc=0.7104, Val Loss=1.3425, lr=0.0010
[2025-05-06 12:30:15,901][train][INFO] - Epoch 69/100, Val Acc=0.7169, Val Loss=1.3483, lr=0.0010
[2025-05-06 12:30:16,882][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=5.2606, lr=0.0001
[2025-05-06 12:30:17,591][train][INFO] - Epoch 68/100, Val Acc=0.7076, Val Loss=1.3405, lr=0.0010
[2025-05-06 12:30:24,327][train][INFO] - Epoch 70/100, Val Acc=0.7181, Val Loss=1.3496, lr=0.0010
[2025-05-06 12:30:25,324][train][INFO] - Epoch 69/100, Val Acc=0.7061, Val Loss=1.3499, lr=0.0010
[2025-05-06 12:30:32,053][train][INFO] - Epoch 71/100, Val Acc=0.7173, Val Loss=1.3493, lr=0.0010
[2025-05-06 12:30:33,359][train][INFO] - Epoch 70/100, Val Acc=0.7079, Val Loss=1.3530, lr=0.0010
[2025-05-06 12:30:36,141][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=7.6506, lr=0.0001
[2025-05-06 12:30:39,301][train][INFO] - Epoch 72/100, Val Acc=0.7189, Val Loss=1.3518, lr=0.0010
[2025-05-06 12:30:40,870][train][INFO] - Epoch 71/100, Val Acc=0.7083, Val Loss=1.3554, lr=0.0010
[2025-05-06 12:30:47,585][train][INFO] - Epoch 73/100, Val Acc=0.7195, Val Loss=1.3527, lr=0.0010
[2025-05-06 12:30:48,317][train][INFO] - Epoch 72/100, Val Acc=0.7083, Val Loss=1.3616, lr=0.0010
[2025-05-06 12:30:55,380][train][INFO] - Epoch 74/100, Val Acc=0.7210, Val Loss=1.3587, lr=0.0010
[2025-05-06 12:30:56,202][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=5.5796, lr=0.0001
[2025-05-06 12:30:56,432][train][INFO] - Epoch 73/100, Val Acc=0.7119, Val Loss=1.3570, lr=0.0010
[2025-05-06 12:31:03,149][train][INFO] - Epoch 75/100, Val Acc=0.7187, Val Loss=1.3521, lr=0.0010
[2025-05-06 12:31:04,553][train][INFO] - Epoch 74/100, Val Acc=0.7091, Val Loss=1.3582, lr=0.0010
[2025-05-06 12:31:10,893][train][INFO] - Epoch 76/100, Val Acc=0.7205, Val Loss=1.3565, lr=0.0010
[2025-05-06 12:31:12,286][train][INFO] - Epoch 75/100, Val Acc=0.7099, Val Loss=1.3628, lr=0.0010
[2025-05-06 12:31:15,491][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=6.0110, lr=0.0001
[2025-05-06 12:31:19,170][train][INFO] - Epoch 77/100, Val Acc=0.7239, Val Loss=1.3558, lr=0.0010
[2025-05-06 12:31:20,235][train][INFO] - Epoch 76/100, Val Acc=0.7117, Val Loss=1.3665, lr=0.0010
[2025-05-06 12:31:27,471][train][INFO] - Epoch 78/100, Val Acc=0.7229, Val Loss=1.3575, lr=0.0010
[2025-05-06 12:31:28,361][train][INFO] - Epoch 77/100, Val Acc=0.7105, Val Loss=1.3738, lr=0.0010
[2025-05-06 12:31:35,583][train][INFO] - Epoch 79/100, Val Acc=0.7201, Val Loss=1.3642, lr=0.0010
[2025-05-06 12:31:36,057][train][INFO] - Epoch 78/100, Val Acc=0.7111, Val Loss=1.3759, lr=0.0010
[2025-05-06 12:31:36,064][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.7143, lr=0.0001
[2025-05-06 12:31:36,092][meta_train][INFO] - epoch_33 saved !
[2025-05-06 12:31:43,546][train][INFO] - Epoch 80/100, Val Acc=0.7218, Val Loss=1.3628, lr=0.0010
[2025-05-06 12:31:43,991][train][INFO] - Epoch 79/100, Val Acc=0.7128, Val Loss=1.3850, lr=0.0010
[2025-05-06 12:31:51,929][train][INFO] - Epoch 81/100, Val Acc=0.7217, Val Loss=1.3645, lr=0.0010
[2025-05-06 12:31:52,147][train][INFO] - Epoch 80/100, Val Acc=0.7128, Val Loss=1.3818, lr=0.0010
[2025-05-06 12:31:56,936][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.7140, lr=0.0001
[2025-05-06 12:32:00,218][train][INFO] - Epoch 81/100, Val Acc=0.7081, Val Loss=1.3850, lr=0.0010
[2025-05-06 12:32:00,323][train][INFO] - Epoch 82/100, Val Acc=0.7219, Val Loss=1.3691, lr=0.0010
[2025-05-06 12:32:08,196][train][INFO] - Epoch 82/100, Val Acc=0.7102, Val Loss=1.3826, lr=0.0010
[2025-05-06 12:32:08,542][train][INFO] - Epoch 83/100, Val Acc=0.7237, Val Loss=1.3639, lr=0.0010
[2025-05-06 12:32:15,685][train][INFO] - Epoch 83/100, Val Acc=0.7124, Val Loss=1.3889, lr=0.0010
[2025-05-06 12:32:16,924][train][INFO] - Epoch 84/100, Val Acc=0.7230, Val Loss=1.3687, lr=0.0010
[2025-05-06 12:32:17,241][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=5.5717, lr=0.0001
[2025-05-06 12:32:23,865][train][INFO] - Epoch 84/100, Val Acc=0.7114, Val Loss=1.3879, lr=0.0010
[2025-05-06 12:32:25,279][train][INFO] - Epoch 85/100, Val Acc=0.7219, Val Loss=1.3747, lr=0.0010
[2025-05-06 12:32:31,870][train][INFO] - Epoch 85/100, Val Acc=0.7120, Val Loss=1.3978, lr=0.0010
[2025-05-06 12:32:33,343][train][INFO] - Epoch 86/100, Val Acc=0.7226, Val Loss=1.3728, lr=0.0010
[2025-05-06 12:32:36,358][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=6.0117, lr=0.0001
[2025-05-06 12:32:39,591][train][INFO] - Epoch 86/100, Val Acc=0.7096, Val Loss=1.3921, lr=0.0010
[2025-05-06 12:32:41,604][train][INFO] - Epoch 87/100, Val Acc=0.7214, Val Loss=1.3713, lr=0.0010
[2025-05-06 12:32:47,265][train][INFO] - Epoch 87/100, Val Acc=0.7119, Val Loss=1.3947, lr=0.0010
[2025-05-06 12:32:49,202][train][INFO] - Epoch 88/100, Val Acc=0.7228, Val Loss=1.3647, lr=0.0010
[2025-05-06 12:32:55,147][train][INFO] - Epoch 88/100, Val Acc=0.7115, Val Loss=1.3964, lr=0.0010
[2025-05-06 12:32:56,493][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.8565, lr=0.0001
[2025-05-06 12:32:57,225][train][INFO] - Epoch 89/100, Val Acc=0.7195, Val Loss=1.3712, lr=0.0010
[2025-05-06 12:33:03,256][train][INFO] - Epoch 89/100, Val Acc=0.7108, Val Loss=1.4017, lr=0.0010
[2025-05-06 12:33:05,255][train][INFO] - Epoch 90/100, Val Acc=0.7192, Val Loss=1.3769, lr=0.0010
[2025-05-06 12:33:10,806][train][INFO] - Epoch 90/100, Val Acc=0.7118, Val Loss=1.3929, lr=0.0010
[2025-05-06 12:33:13,508][train][INFO] - Epoch 91/100, Val Acc=0.7225, Val Loss=1.3725, lr=0.0001
[2025-05-06 12:33:15,751][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=5.2398, lr=0.0001
[2025-05-06 12:33:19,194][train][INFO] - Epoch 91/100, Val Acc=0.7128, Val Loss=1.3890, lr=0.0001
[2025-05-06 12:33:22,117][train][INFO] - Epoch 92/100, Val Acc=0.7227, Val Loss=1.3748, lr=0.0001
[2025-05-06 12:33:27,239][train][INFO] - Epoch 92/100, Val Acc=0.7116, Val Loss=1.3914, lr=0.0001
[2025-05-06 12:33:29,920][train][INFO] - Epoch 93/100, Val Acc=0.7210, Val Loss=1.3732, lr=0.0001
[2025-05-06 12:33:35,062][train][INFO] - Epoch 93/100, Val Acc=0.7140, Val Loss=1.3919, lr=0.0001
[2025-05-06 12:33:36,465][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.7344, lr=0.0001
[2025-05-06 12:33:37,650][train][INFO] - Epoch 94/100, Val Acc=0.7215, Val Loss=1.3704, lr=0.0001
[2025-05-06 12:33:42,952][train][INFO] - Epoch 94/100, Val Acc=0.7117, Val Loss=1.3885, lr=0.0001
[2025-05-06 12:33:45,255][train][INFO] - Epoch 95/100, Val Acc=0.7226, Val Loss=1.3732, lr=0.0001
[2025-05-06 12:33:50,468][train][INFO] - Epoch 95/100, Val Acc=0.7138, Val Loss=1.3916, lr=0.0001
[2025-05-06 12:33:52,588][train][INFO] - Epoch 96/100, Val Acc=0.7225, Val Loss=1.3706, lr=0.0001
[2025-05-06 12:33:55,660][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=7.5834, lr=0.0001
[2025-05-06 12:33:58,586][train][INFO] - Epoch 96/100, Val Acc=0.7137, Val Loss=1.3862, lr=0.0001
[2025-05-06 12:34:00,352][train][INFO] - Epoch 97/100, Val Acc=0.7208, Val Loss=1.3722, lr=0.0001
[2025-05-06 12:34:06,374][train][INFO] - Epoch 97/100, Val Acc=0.7104, Val Loss=1.3912, lr=0.0001
[2025-05-06 12:34:08,188][train][INFO] - Epoch 98/100, Val Acc=0.7243, Val Loss=1.3679, lr=0.0001
[2025-05-06 12:34:14,276][train][INFO] - Epoch 98/100, Val Acc=0.7139, Val Loss=1.3868, lr=0.0001
[2025-05-06 12:34:15,024][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=7.5414, lr=0.0001
[2025-05-06 12:34:15,049][meta_train][INFO] - epoch_34 saved !
[2025-05-06 12:34:16,217][train][INFO] - Epoch 99/100, Val Acc=0.7212, Val Loss=1.3773, lr=0.0001
[2025-05-06 12:34:21,922][train][INFO] - Epoch 99/100, Val Acc=0.7118, Val Loss=1.3955, lr=0.0001
[2025-05-06 12:34:24,046][train][INFO] - Epoch 100/100, Val Acc=0.7227, Val Loss=1.3709, lr=0.0001
[2025-05-06 12:34:29,257][train][INFO] - After training : Train Acc=0.9987  Val Acc=0.7243
[2025-05-06 12:34:29,268][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 12:34:29,520][train][INFO] - Epoch 100/100, Val Acc=0.7139, Val Loss=1.3912, lr=0.0001
[2025-05-06 12:34:34,075][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=7.5612, lr=0.0001
[2025-05-06 12:34:34,545][train][INFO] - After training : Train Acc=0.9968  Val Acc=0.7140
[2025-05-06 12:34:34,556][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 12:34:54,270][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.8501, lr=0.0001
[2025-05-06 12:35:14,827][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=5.5366, lr=0.0001
[2025-05-06 12:35:33,728][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=7.5034, lr=0.0001
[2025-05-06 12:35:53,630][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=5.2225, lr=0.0001
[2025-05-06 12:36:12,874][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=5.9463, lr=0.0001
[2025-05-06 12:36:13,633][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 12:36:15,263][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 12:36:34,199][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.7106, lr=0.0001
[2025-05-06 12:36:55,579][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.7290, lr=0.0001
[2025-05-06 12:36:55,619][meta_train][INFO] - epoch_35 saved !
[2025-05-06 12:37:16,662][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.7100, lr=0.0001
[2025-05-06 12:37:37,190][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=5.5124, lr=0.0001
[2025-05-06 12:37:56,734][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=7.4763, lr=0.0001
[2025-05-06 12:37:59,708][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 12:38:00,201][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 12:38:07,058][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 12:38:07,465][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 12:38:17,199][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.7277, lr=0.0001
[2025-05-06 12:38:35,442][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=5.9115, lr=0.0001
[2025-05-06 12:38:53,842][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=7.4462, lr=0.0001
[2025-05-06 12:39:12,293][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=5.1974, lr=0.0001
[2025-05-06 12:39:31,703][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.8387, lr=0.0001
[2025-05-06 12:39:31,719][meta_train][INFO] - epoch_36 saved !
[2025-05-06 12:39:50,173][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=5.1974, lr=0.0001
[2025-05-06 12:40:10,246][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.7080, lr=0.0001
[2025-05-06 12:40:28,926][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=5.8930, lr=0.0001
[2025-05-06 12:40:47,157][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=7.4057, lr=0.0001
[2025-05-06 12:41:06,313][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.8338, lr=0.0001
[2025-05-06 12:41:24,826][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=7.4073, lr=0.0001
[2025-05-06 12:41:44,591][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.7235, lr=0.0001
[2025-05-06 12:42:03,665][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=5.4684, lr=0.0001
[2025-05-06 12:42:03,681][meta_train][INFO] - epoch_37 saved !
[2025-05-06 12:42:23,686][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.7229, lr=0.0001
[2025-05-06 12:42:42,666][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.8314, lr=0.0001
[2025-05-06 12:43:02,659][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.7057, lr=0.0001
[2025-05-06 12:43:20,914][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=5.1746, lr=0.0001
[2025-05-06 12:43:39,081][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=7.3920, lr=0.0001
[2025-05-06 12:43:57,479][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=7.3359, lr=0.0001
[2025-05-06 12:44:16,693][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=5.4417, lr=0.0001
[2025-05-06 12:44:35,599][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=5.8264, lr=0.0001
[2025-05-06 12:44:35,624][meta_train][INFO] - epoch_38 saved !
[2025-05-06 12:44:54,100][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=5.1594, lr=0.0001
[2025-05-06 12:45:12,371][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=5.8247, lr=0.0001
[2025-05-06 12:45:32,353][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.7191, lr=0.0001
[2025-05-06 12:45:51,287][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=5.4276, lr=0.0001
[2025-05-06 12:46:10,745][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.8208, lr=0.0001
[2025-05-06 12:46:30,789][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.7034, lr=0.0001
[2025-05-06 12:46:49,458][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=7.2574, lr=0.0001
[2025-05-06 12:47:07,927][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=7.3297, lr=0.0001
[2025-05-06 12:47:07,958][meta_train][INFO] - epoch_39 saved !
[2025-05-06 12:47:26,456][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=5.7920, lr=0.0001
[2025-05-06 12:48:23,958][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 16
      hiddim: 128
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-06 12:48:24,037][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 12:48:24,037][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 12:48:24,037][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 90, in main
    metanetwork = meta_train(metanetwork, model_train_loader, big_train_loader, small_train_loader, cfg.meta_train, log=log,
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 189, in meta_train
    onetrainstep()
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 150, in onetrainstep
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 48, in forward
    ret_node2, ret_edge2 = self.convs[i].forward(self.norm(hidden), edge_index[[1, 0]], self.edgeInverter * edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 362.00 MiB (GPU 0; 23.65 GiB total capacity; 22.42 GiB already allocated; 141.62 MiB free; 22.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-06 12:50:06,004][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 128
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-06 12:50:06,090][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 12:50:06,090][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 12:50:06,090][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 12:50:34,639][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.1915, lr=0.001
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 90, in main
    metanetwork = meta_train(metanetwork, model_train_loader, big_train_loader, small_train_loader, cfg.meta_train, log=log,
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 189, in meta_train
    onetrainstep()
  File "/home/liuyewei/metanetwork/meta-pruning/utils/meta_train.py", line 150, in onetrainstep
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 47, in forward
    ret_node1, ret_edge1 = self.convs[i].forward(self.norm(hidden), edge_index, edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 230, in forward
    out = scatter(x, index, 0, dim_size, reduce=reduce)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 378.00 MiB (GPU 0; 23.65 GiB total capacity; 18.16 GiB already allocated; 173.62 MiB free; 22.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-06 12:50:52,051][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-06 12:50:52,145][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 12:50:52,145][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 12:50:52,145][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 12:51:17,062][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.7221, lr=0.001
[2025-05-06 12:51:39,019][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0752, lr=0.001
[2025-05-06 12:52:00,276][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=6.7445, lr=0.001
[2025-05-06 12:52:21,286][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.4691, lr=0.001
[2025-05-06 12:52:42,871][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.1404, lr=0.001
[2025-05-06 12:53:04,586][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.0666, lr=0.001
[2025-05-06 12:53:27,082][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.1115, lr=0.001
[2025-05-06 12:53:47,969][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.1369, lr=0.001
[2025-05-06 12:53:47,997][meta_train][INFO] - epoch_1 saved !
[2025-05-06 12:54:09,216][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3321, lr=0.001
[2025-05-06 12:54:30,016][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.7882, lr=0.001
[2025-05-06 12:54:51,199][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2825, lr=0.001
[2025-05-06 12:55:12,226][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.8541, lr=0.001
[2025-05-06 12:55:33,175][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=1.2056, lr=0.001
[2025-05-06 12:55:54,156][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=1.2128, lr=0.001
[2025-05-06 12:56:17,635][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=1.7640, lr=0.001
[2025-05-06 12:56:39,314][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=2.5024, lr=0.001
[2025-05-06 12:56:39,340][meta_train][INFO] - epoch_2 saved !
[2025-05-06 12:57:00,248][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=1.9302, lr=0.001
[2025-05-06 12:57:21,235][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=3.2847, lr=0.001
[2025-05-06 12:57:42,025][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=5.8211, lr=0.001
[2025-05-06 12:58:02,890][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=7.7546, lr=0.001
[2025-05-06 12:58:23,656][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=4.9053, lr=0.001
[2025-05-06 12:58:45,028][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=7.3963, lr=0.001
[2025-05-06 12:59:05,905][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=5.4984, lr=0.001
[2025-05-06 12:59:29,219][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=6.8477, lr=0.001
[2025-05-06 12:59:29,261][meta_train][INFO] - epoch_3 saved !
[2025-05-06 12:59:49,892][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=8.7966, lr=0.001
[2025-05-06 13:00:11,922][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=5.9952, lr=0.001
[2025-05-06 13:00:32,579][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=7.6472, lr=0.001
[2025-05-06 13:00:55,259][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=6.3559, lr=0.001
[2025-05-06 13:01:15,936][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=6.6162, lr=0.001
[2025-05-06 13:01:37,284][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=5.3872, lr=0.001
[2025-05-06 13:01:58,289][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=5.6640, lr=0.001
[2025-05-06 13:02:19,902][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=9.3651, lr=0.001
[2025-05-06 13:02:19,927][meta_train][INFO] - epoch_4 saved !
[2025-05-06 13:02:41,343][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=7.8716, lr=0.001
[2025-05-06 13:03:02,691][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=7.3455, lr=0.001
[2025-05-06 13:03:24,300][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=6.4451, lr=0.001
[2025-05-06 13:03:44,808][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=10.3915, lr=0.001
[2025-05-06 13:04:05,752][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.1769, lr=0.001
[2025-05-06 13:04:27,543][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=9.4011, lr=0.001
[2025-05-06 13:04:48,491][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=5.0879, lr=0.001
[2025-05-06 13:05:11,567][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=6.5669, lr=0.001
[2025-05-06 13:05:11,605][meta_train][INFO] - epoch_5 saved !
[2025-05-06 13:05:32,717][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=5.0680, lr=0.001
[2025-05-06 13:05:53,621][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=7.5907, lr=0.001
[2025-05-06 13:06:14,136][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=5.0069, lr=0.001
[2025-05-06 13:06:35,587][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=7.5499, lr=0.001
[2025-05-06 13:06:56,387][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=10.0500, lr=0.001
[2025-05-06 13:07:17,604][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=6.4803, lr=0.001
[2025-05-06 13:07:41,367][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=6.0424, lr=0.001
[2025-05-06 13:08:02,213][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=8.2574, lr=0.001
[2025-05-06 13:08:02,249][meta_train][INFO] - epoch_6 saved !
[2025-05-06 13:08:23,384][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=6.8503, lr=0.001
[2025-05-06 13:08:44,672][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=4.8458, lr=0.001
[2025-05-06 13:09:05,837][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=7.8005, lr=0.001
[2025-05-06 13:09:27,010][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=4.8389, lr=0.001
[2025-05-06 13:09:49,591][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=5.3476, lr=0.001
[2025-05-06 13:10:10,938][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=6.5809, lr=0.001
[2025-05-06 13:10:32,272][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=7.8579, lr=0.001
[2025-05-06 13:10:53,456][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=5.5768, lr=0.001
[2025-05-06 13:10:53,480][meta_train][INFO] - epoch_7 saved !
[2025-05-06 13:11:14,160][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=7.1369, lr=0.0001
[2025-05-06 13:11:35,597][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=5.4735, lr=0.0001
[2025-05-06 13:11:58,058][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=4.9777, lr=0.0001
[2025-05-06 13:12:18,974][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=5.6561, lr=0.0001
[2025-05-06 13:12:40,505][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=6.4670, lr=0.0001
[2025-05-06 13:13:01,147][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=5.9990, lr=0.0001
[2025-05-06 13:13:22,320][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.7895, lr=0.0001
[2025-05-06 13:13:43,193][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=4.6823, lr=0.0001
[2025-05-06 13:13:43,217][meta_train][INFO] - epoch_8 saved !
[2025-05-06 13:14:03,748][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=5.9974, lr=0.0001
[2025-05-06 13:14:24,295][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=6.9141, lr=0.0001
[2025-05-06 13:14:45,452][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=6.4181, lr=0.0001
[2025-05-06 13:15:06,092][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.7909, lr=0.0001
[2025-05-06 13:15:27,803][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=5.6051, lr=0.0001
[2025-05-06 13:15:48,794][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=4.6842, lr=0.0001
[2025-05-06 13:16:09,960][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=5.4025, lr=0.0001
[2025-05-06 13:16:33,135][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=4.9193, lr=0.0001
[2025-05-06 13:16:33,159][meta_train][INFO] - epoch_9 saved !
[2025-05-06 13:16:53,651][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=5.9260, lr=0.0001
[2025-05-06 13:17:15,102][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=6.3189, lr=0.0001
[2025-05-06 13:17:38,149][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=4.9009, lr=0.0001
[2025-05-06 13:17:59,550][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=4.6766, lr=0.0001
[2025-05-06 13:18:20,612][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=6.6505, lr=0.0001
[2025-05-06 13:18:41,184][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.7827, lr=0.0001
[2025-05-06 13:19:02,542][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=5.3864, lr=0.0001
[2025-05-06 13:19:23,861][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=5.5349, lr=0.0001
[2025-05-06 13:19:23,904][meta_train][INFO] - epoch_10 saved !
[2025-05-06 13:19:45,291][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=6.5971, lr=0.0001
[2025-05-06 13:20:06,362][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=5.5145, lr=0.0001
[2025-05-06 13:20:27,433][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=6.2187, lr=0.0001
[2025-05-06 13:20:48,969][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=5.3413, lr=0.0001
[2025-05-06 13:21:10,093][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=4.6679, lr=0.0001
[2025-05-06 13:21:30,986][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.7782, lr=0.0001
[2025-05-06 13:21:53,863][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=4.8725, lr=0.0001
[2025-05-06 13:22:14,862][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=5.8112, lr=0.0001
[2025-05-06 13:22:14,886][meta_train][INFO] - epoch_11 saved !
[2025-05-06 13:22:35,924][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=6.4371, lr=0.0001
[2025-05-06 13:22:56,968][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=6.1493, lr=0.0001
[2025-05-06 13:23:18,577][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=5.3094, lr=0.0001
[2025-05-06 13:23:39,264][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=5.4195, lr=0.0001
[2025-05-06 13:24:00,270][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.7733, lr=0.0001
[2025-05-06 13:24:23,695][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=4.8180, lr=0.0001
[2025-05-06 13:24:44,425][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=4.6589, lr=0.0001
[2025-05-06 13:24:51,973][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-06 13:24:52,025][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 13:24:52,025][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 13:24:52,025][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 13:25:04,069][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 13:25:05,225][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=5.7134, lr=0.0001
[2025-05-06 13:25:05,261][meta_train][INFO] - epoch_12 saved !
[2025-05-06 13:25:12,001][train][INFO] - Epoch 1/100, Val Acc=0.0385, Val Loss=4.0972, lr=0.0100
[2025-05-06 13:25:19,875][train][INFO] - Epoch 2/100, Val Acc=0.0839, Val Loss=3.7467, lr=0.0100
[2025-05-06 13:25:26,688][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=6.2528, lr=0.0001
[2025-05-06 13:25:27,095][train][INFO] - Epoch 3/100, Val Acc=0.0859, Val Loss=3.7538, lr=0.0100
[2025-05-06 13:25:34,766][train][INFO] - Epoch 4/100, Val Acc=0.1486, Val Loss=3.3232, lr=0.0100
[2025-05-06 13:25:42,617][train][INFO] - Epoch 5/100, Val Acc=0.1855, Val Loss=3.1554, lr=0.0100
[2025-05-06 13:25:48,107][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=4.6624, lr=0.0001
[2025-05-06 13:25:50,481][train][INFO] - Epoch 6/100, Val Acc=0.2614, Val Loss=2.7053, lr=0.0100
[2025-05-06 13:25:58,187][train][INFO] - Epoch 7/100, Val Acc=0.2821, Val Loss=2.6743, lr=0.0100
[2025-05-06 13:26:06,546][train][INFO] - Epoch 8/100, Val Acc=0.3269, Val Loss=2.4671, lr=0.0100
[2025-05-06 13:26:09,638][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=5.7178, lr=0.0001
[2025-05-06 13:26:13,480][train][INFO] - Epoch 9/100, Val Acc=0.3016, Val Loss=2.8018, lr=0.0100
[2025-05-06 13:26:21,479][train][INFO] - Epoch 10/100, Val Acc=0.3326, Val Loss=2.6371, lr=0.0100
[2025-05-06 13:26:29,558][train][INFO] - Epoch 11/100, Val Acc=0.4023, Val Loss=2.1740, lr=0.0100
[2025-05-06 13:26:32,623][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=4.8395, lr=0.0001
[2025-05-06 13:26:37,137][train][INFO] - Epoch 12/100, Val Acc=0.3764, Val Loss=2.3716, lr=0.0100
[2025-05-06 13:26:44,630][train][INFO] - Epoch 13/100, Val Acc=0.3892, Val Loss=2.3601, lr=0.0100
[2025-05-06 13:26:52,287][train][INFO] - Epoch 14/100, Val Acc=0.4436, Val Loss=2.0617, lr=0.0100
[2025-05-06 13:26:54,412][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=5.3823, lr=0.0001
[2025-05-06 13:26:59,841][train][INFO] - Epoch 15/100, Val Acc=0.4580, Val Loss=2.0137, lr=0.0100
[2025-05-06 13:27:07,870][train][INFO] - Epoch 16/100, Val Acc=0.4763, Val Loss=1.9389, lr=0.0100
[2025-05-06 13:27:15,545][train][INFO] - Epoch 17/100, Val Acc=0.4690, Val Loss=1.9387, lr=0.0100
[2025-05-06 13:27:16,655][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=5.2502, lr=0.0001
[2025-05-06 13:27:23,143][train][INFO] - Epoch 18/100, Val Acc=0.4709, Val Loss=1.9930, lr=0.0100
[2025-05-06 13:27:31,063][train][INFO] - Epoch 19/100, Val Acc=0.4899, Val Loss=1.8665, lr=0.0100
[2025-05-06 13:27:37,572][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.7635, lr=0.0001
[2025-05-06 13:27:39,263][train][INFO] - Epoch 20/100, Val Acc=0.4894, Val Loss=1.8443, lr=0.0100
[2025-05-06 13:27:47,393][train][INFO] - Epoch 21/100, Val Acc=0.5139, Val Loss=1.7558, lr=0.0100
[2025-05-06 13:27:55,123][train][INFO] - Epoch 22/100, Val Acc=0.4866, Val Loss=1.9522, lr=0.0100
[2025-05-06 13:27:58,936][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=5.9319, lr=0.0001
[2025-05-06 13:27:58,966][meta_train][INFO] - epoch_13 saved !
[2025-05-06 13:28:03,143][train][INFO] - Epoch 23/100, Val Acc=0.5227, Val Loss=1.7704, lr=0.0100
[2025-05-06 13:28:11,511][train][INFO] - Epoch 24/100, Val Acc=0.5299, Val Loss=1.7407, lr=0.0100
[2025-05-06 13:28:19,081][train][INFO] - Epoch 25/100, Val Acc=0.5256, Val Loss=1.7645, lr=0.0100
[2025-05-06 13:28:20,363][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=5.6158, lr=0.0001
[2025-05-06 13:28:26,658][train][INFO] - Epoch 26/100, Val Acc=0.5276, Val Loss=1.7848, lr=0.0100
[2025-05-06 13:28:34,804][train][INFO] - Epoch 27/100, Val Acc=0.5211, Val Loss=1.7869, lr=0.0100
[2025-05-06 13:28:42,722][train][INFO] - Epoch 28/100, Val Acc=0.5254, Val Loss=1.8140, lr=0.0100
[2025-05-06 13:28:43,748][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=4.7982, lr=0.0001
[2025-05-06 13:28:50,134][train][INFO] - Epoch 29/100, Val Acc=0.5357, Val Loss=1.8033, lr=0.0100
[2025-05-06 13:28:58,182][train][INFO] - Epoch 30/100, Val Acc=0.5576, Val Loss=1.6907, lr=0.0100
[2025-05-06 13:29:05,180][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=5.3235, lr=0.0001
[2025-05-06 13:29:06,344][train][INFO] - Epoch 31/100, Val Acc=0.5305, Val Loss=1.7728, lr=0.0100
[2025-05-06 13:29:13,711][train][INFO] - Epoch 32/100, Val Acc=0.5379, Val Loss=1.7920, lr=0.0100
[2025-05-06 13:29:21,541][train][INFO] - Epoch 33/100, Val Acc=0.5579, Val Loss=1.6821, lr=0.0100
[2025-05-06 13:29:26,735][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.7609, lr=0.0001
[2025-05-06 13:29:29,191][train][INFO] - Epoch 34/100, Val Acc=0.5446, Val Loss=1.7394, lr=0.0100
[2025-05-06 13:29:36,779][train][INFO] - Epoch 35/100, Val Acc=0.5443, Val Loss=1.7936, lr=0.0100
[2025-05-06 13:29:44,608][train][INFO] - Epoch 36/100, Val Acc=0.5616, Val Loss=1.6677, lr=0.0100
[2025-05-06 13:29:48,294][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.6528, lr=0.0001
[2025-05-06 13:29:52,346][train][INFO] - Epoch 37/100, Val Acc=0.5638, Val Loss=1.6708, lr=0.0100
[2025-05-06 13:30:00,244][train][INFO] - Epoch 38/100, Val Acc=0.5637, Val Loss=1.6634, lr=0.0100
[2025-05-06 13:30:08,155][train][INFO] - Epoch 39/100, Val Acc=0.5654, Val Loss=1.6680, lr=0.0100
[2025-05-06 13:30:10,083][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=5.2342, lr=0.0001
[2025-05-06 13:30:15,733][train][INFO] - Epoch 40/100, Val Acc=0.5716, Val Loss=1.6550, lr=0.0100
[2025-05-06 13:30:23,193][train][INFO] - Epoch 41/100, Val Acc=0.5522, Val Loss=1.7812, lr=0.0100
[2025-05-06 13:30:31,117][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=6.0189, lr=0.0001
[2025-05-06 13:30:31,376][train][INFO] - Epoch 42/100, Val Acc=0.5743, Val Loss=1.6224, lr=0.0100
[2025-05-06 13:30:39,199][train][INFO] - Epoch 43/100, Val Acc=0.5461, Val Loss=1.8077, lr=0.0100
[2025-05-06 13:30:47,693][train][INFO] - Epoch 44/100, Val Acc=0.5751, Val Loss=1.6508, lr=0.0100
[2025-05-06 13:30:52,930][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=5.8766, lr=0.0001
[2025-05-06 13:30:52,956][meta_train][INFO] - epoch_14 saved !
[2025-05-06 13:30:55,550][train][INFO] - Epoch 45/100, Val Acc=0.5655, Val Loss=1.7165, lr=0.0100
[2025-05-06 13:31:03,870][train][INFO] - Epoch 46/100, Val Acc=0.5575, Val Loss=1.8016, lr=0.0100
[2025-05-06 13:31:11,208][train][INFO] - Epoch 47/100, Val Acc=0.5728, Val Loss=1.6700, lr=0.0100
[2025-05-06 13:31:14,174][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.6496, lr=0.0001
[2025-05-06 13:31:18,709][train][INFO] - Epoch 48/100, Val Acc=0.5849, Val Loss=1.6208, lr=0.0100
[2025-05-06 13:31:27,111][train][INFO] - Epoch 49/100, Val Acc=0.5650, Val Loss=1.7453, lr=0.0100
[2025-05-06 13:31:34,903][train][INFO] - Epoch 50/100, Val Acc=0.5897, Val Loss=1.6493, lr=0.0100
[2025-05-06 13:31:35,149][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.7595, lr=0.0001
[2025-05-06 13:31:42,626][train][INFO] - Epoch 51/100, Val Acc=0.5808, Val Loss=1.6722, lr=0.0100
[2025-05-06 13:31:50,465][train][INFO] - Epoch 52/100, Val Acc=0.5564, Val Loss=1.8246, lr=0.0100
[2025-05-06 13:31:56,399][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=5.9309, lr=0.0001
[2025-05-06 13:31:58,587][train][INFO] - Epoch 53/100, Val Acc=0.5929, Val Loss=1.5985, lr=0.0100
[2025-05-06 13:32:06,694][train][INFO] - Epoch 54/100, Val Acc=0.5836, Val Loss=1.6912, lr=0.0100
[2025-05-06 13:32:14,060][train][INFO] - Epoch 55/100, Val Acc=0.5745, Val Loss=1.7257, lr=0.0100
[2025-05-06 13:32:18,247][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=5.2785, lr=0.0001
[2025-05-06 13:32:21,683][train][INFO] - Epoch 56/100, Val Acc=0.5587, Val Loss=1.8545, lr=0.0100
[2025-05-06 13:32:28,588][train][INFO] - Epoch 57/100, Val Acc=0.5882, Val Loss=1.6724, lr=0.0100
[2025-05-06 13:32:36,322][train][INFO] - Epoch 58/100, Val Acc=0.5857, Val Loss=1.6618, lr=0.0100
[2025-05-06 13:32:40,024][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=5.1979, lr=0.0001
[2025-05-06 13:32:44,461][train][INFO] - Epoch 59/100, Val Acc=0.5742, Val Loss=1.7078, lr=0.0100
[2025-05-06 13:32:52,444][train][INFO] - Epoch 60/100, Val Acc=0.5824, Val Loss=1.7296, lr=0.0100
[2025-05-06 13:33:00,355][train][INFO] - Epoch 61/100, Val Acc=0.6428, Val Loss=1.3806, lr=0.0010
[2025-05-06 13:33:03,221][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=4.7766, lr=0.0001
[2025-05-06 13:33:08,050][train][INFO] - Epoch 62/100, Val Acc=0.6514, Val Loss=1.3713, lr=0.0010
[2025-05-06 13:33:15,862][train][INFO] - Epoch 63/100, Val Acc=0.6533, Val Loss=1.3795, lr=0.0010
[2025-05-06 13:33:24,208][train][INFO] - Epoch 64/100, Val Acc=0.6545, Val Loss=1.3788, lr=0.0010
[2025-05-06 13:33:24,473][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=5.5215, lr=0.0001
[2025-05-06 13:33:31,293][train][INFO] - Epoch 65/100, Val Acc=0.6547, Val Loss=1.3808, lr=0.0010
[2025-05-06 13:33:38,856][train][INFO] - Epoch 66/100, Val Acc=0.6544, Val Loss=1.3870, lr=0.0010
[2025-05-06 13:33:46,424][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=5.7752, lr=0.0001
[2025-05-06 13:33:46,468][meta_train][INFO] - epoch_15 saved !
[2025-05-06 13:33:46,862][train][INFO] - Epoch 67/100, Val Acc=0.6551, Val Loss=1.3911, lr=0.0010
[2025-05-06 13:33:54,837][train][INFO] - Epoch 68/100, Val Acc=0.6559, Val Loss=1.3990, lr=0.0010
[2025-05-06 13:34:02,842][train][INFO] - Epoch 69/100, Val Acc=0.6580, Val Loss=1.3993, lr=0.0010
[2025-05-06 13:34:07,977][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.6446, lr=0.0001
[2025-05-06 13:34:10,327][train][INFO] - Epoch 70/100, Val Acc=0.6540, Val Loss=1.4101, lr=0.0010
[2025-05-06 13:34:18,016][train][INFO] - Epoch 71/100, Val Acc=0.6530, Val Loss=1.4179, lr=0.0010
[2025-05-06 13:34:26,089][train][INFO] - Epoch 72/100, Val Acc=0.6517, Val Loss=1.4258, lr=0.0010
[2025-05-06 13:34:31,595][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=4.7683, lr=0.0001
[2025-05-06 13:34:32,771][train][INFO] - Epoch 73/100, Val Acc=0.6539, Val Loss=1.4213, lr=0.0010
[2025-05-06 13:34:40,369][train][INFO] - Epoch 74/100, Val Acc=0.6551, Val Loss=1.4280, lr=0.0010
[2025-05-06 13:34:48,144][train][INFO] - Epoch 75/100, Val Acc=0.6554, Val Loss=1.4330, lr=0.0010
[2025-05-06 13:34:53,065][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=5.4934, lr=0.0001
[2025-05-06 13:34:55,918][train][INFO] - Epoch 76/100, Val Acc=0.6518, Val Loss=1.4371, lr=0.0010
[2025-05-06 13:35:03,546][train][INFO] - Epoch 77/100, Val Acc=0.6538, Val Loss=1.4434, lr=0.0010
[2025-05-06 13:35:11,334][train][INFO] - Epoch 78/100, Val Acc=0.6527, Val Loss=1.4461, lr=0.0010
[2025-05-06 13:35:14,581][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=5.7353, lr=0.0001
[2025-05-06 13:35:18,562][train][INFO] - Epoch 79/100, Val Acc=0.6540, Val Loss=1.4557, lr=0.0010
[2025-05-06 13:35:26,325][train][INFO] - Epoch 80/100, Val Acc=0.6550, Val Loss=1.4614, lr=0.0010
[2025-05-06 13:35:34,651][train][INFO] - Epoch 81/100, Val Acc=0.6517, Val Loss=1.4689, lr=0.0010
[2025-05-06 13:35:36,202][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=5.7787, lr=0.0001
[2025-05-06 13:35:42,388][train][INFO] - Epoch 82/100, Val Acc=0.6545, Val Loss=1.4751, lr=0.0010
[2025-05-06 13:35:50,487][train][INFO] - Epoch 83/100, Val Acc=0.6537, Val Loss=1.4769, lr=0.0010
[2025-05-06 13:35:57,431][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=5.2145, lr=0.0001
[2025-05-06 13:35:58,545][train][INFO] - Epoch 84/100, Val Acc=0.6499, Val Loss=1.4944, lr=0.0010
[2025-05-06 13:36:06,384][train][INFO] - Epoch 85/100, Val Acc=0.6476, Val Loss=1.5067, lr=0.0010
[2025-05-06 13:36:14,531][train][INFO] - Epoch 86/100, Val Acc=0.6490, Val Loss=1.4972, lr=0.0010
[2025-05-06 13:36:19,211][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=5.1394, lr=0.0001
[2025-05-06 13:36:22,588][train][INFO] - Epoch 87/100, Val Acc=0.6551, Val Loss=1.5041, lr=0.0010
[2025-05-06 13:36:30,516][train][INFO] - Epoch 88/100, Val Acc=0.6531, Val Loss=1.4989, lr=0.0010
[2025-05-06 13:36:38,720][train][INFO] - Epoch 89/100, Val Acc=0.6508, Val Loss=1.5163, lr=0.0010
[2025-05-06 13:36:40,596][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.7510, lr=0.0001
[2025-05-06 13:36:40,633][meta_train][INFO] - epoch_16 saved !
[2025-05-06 13:36:45,899][train][INFO] - Epoch 90/100, Val Acc=0.6532, Val Loss=1.5234, lr=0.0010
[2025-05-06 13:36:53,447][train][INFO] - Epoch 91/100, Val Acc=0.6540, Val Loss=1.5022, lr=0.0001
[2025-05-06 13:37:01,185][train][INFO] - Epoch 92/100, Val Acc=0.6531, Val Loss=1.5026, lr=0.0001
[2025-05-06 13:37:02,042][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.6377, lr=0.0001
[2025-05-06 13:37:09,092][train][INFO] - Epoch 93/100, Val Acc=0.6559, Val Loss=1.5022, lr=0.0001
[2025-05-06 13:37:16,827][train][INFO] - Epoch 94/100, Val Acc=0.6554, Val Loss=1.4944, lr=0.0001
[2025-05-06 13:37:23,919][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=5.1891, lr=0.0001
[2025-05-06 13:37:24,765][train][INFO] - Epoch 95/100, Val Acc=0.6548, Val Loss=1.5034, lr=0.0001
[2025-05-06 13:37:32,029][train][INFO] - Epoch 96/100, Val Acc=0.6559, Val Loss=1.4963, lr=0.0001
[2025-05-06 13:37:39,372][train][INFO] - Epoch 97/100, Val Acc=0.6555, Val Loss=1.5045, lr=0.0001
[2025-05-06 13:37:45,153][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.7487, lr=0.0001
[2025-05-06 13:37:47,243][train][INFO] - Epoch 98/100, Val Acc=0.6542, Val Loss=1.4983, lr=0.0001
[2025-05-06 13:37:54,557][train][INFO] - Epoch 99/100, Val Acc=0.6538, Val Loss=1.5057, lr=0.0001
[2025-05-06 13:38:02,281][train][INFO] - Epoch 100/100, Val Acc=0.6565, Val Loss=1.5066, lr=0.0001
[2025-05-06 13:38:06,619][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=5.6782, lr=0.0001
[2025-05-06 13:38:07,252][train][INFO] - After training : Train Acc=0.8884  Val Acc=0.6580
[2025-05-06 13:38:07,260][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 13:38:28,650][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=5.1218, lr=0.0001
[2025-05-06 13:38:52,846][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=4.7244, lr=0.0001
[2025-05-06 13:39:14,465][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=5.3564, lr=0.0001
[2025-05-06 13:39:15,058][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 13:39:36,707][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=5.5492, lr=0.0001
[2025-05-06 13:39:36,733][meta_train][INFO] - epoch_17 saved !
[2025-05-06 13:39:58,470][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=5.5282, lr=0.0001
[2025-05-06 13:40:20,492][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=5.1123, lr=0.0001
[2025-05-06 13:40:34,920][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 13:40:35,387][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 13:40:44,089][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=4.7025, lr=0.0001
[2025-05-06 13:41:05,249][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.6306, lr=0.0001
[2025-05-06 13:41:25,979][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=5.3256, lr=0.0001
[2025-05-06 13:41:46,335][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.7392, lr=0.0001
[2025-05-06 13:42:07,592][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=5.0909, lr=0.0001
[2025-05-06 13:42:28,456][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=5.5293, lr=0.0001
[2025-05-06 13:42:28,482][meta_train][INFO] - epoch_18 saved !
[2025-05-06 13:42:50,101][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=5.4682, lr=0.0001
[2025-05-06 13:43:11,722][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.6272, lr=0.0001
[2025-05-06 13:43:32,139][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=5.4552, lr=0.0001
[2025-05-06 13:43:53,174][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.7277, lr=0.0001
[2025-05-06 13:44:14,306][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=5.0639, lr=0.0001
[2025-05-06 13:44:35,570][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=5.2454, lr=0.0001
[2025-05-06 13:44:59,103][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=4.6893, lr=0.0001
[2025-05-06 13:45:20,860][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=5.0428, lr=0.0001
[2025-05-06 13:45:20,892][meta_train][INFO] - epoch_19 saved !
[2025-05-06 13:45:42,011][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=5.2294, lr=0.0001
[2025-05-06 13:46:03,403][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=5.0169, lr=0.0001
[2025-05-06 13:46:24,164][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.6249, lr=0.0001
[2025-05-06 13:46:45,698][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=5.3661, lr=0.0001
[2025-05-06 13:47:06,576][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.7217, lr=0.0001
[2025-05-06 13:47:27,979][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=5.0494, lr=0.0001
[2025-05-06 13:47:48,789][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=5.3802, lr=0.0001
[2025-05-06 13:48:12,610][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=4.6824, lr=0.0001
[2025-05-06 13:48:12,637][meta_train][INFO] - epoch_20 saved !
[2025-05-06 13:48:34,128][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=5.3547, lr=0.0001
[2025-05-06 13:48:55,639][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=5.3313, lr=0.0001
[2025-05-06 13:49:16,836][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=5.0043, lr=0.0001
[2025-05-06 13:49:38,554][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=5.0100, lr=0.0001
[2025-05-06 13:49:59,638][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=5.1546, lr=0.0001
[2025-05-06 13:50:20,675][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.7140, lr=0.0001
[2025-05-06 13:50:41,977][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.6237, lr=0.0001
[2025-05-06 13:51:05,397][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=4.6827, lr=0.0001
[2025-05-06 13:51:05,423][meta_train][INFO] - epoch_21 saved !
[2025-05-06 13:51:28,678][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.6836, lr=0.0001
[2025-05-06 13:51:51,082][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=5.0181, lr=0.0001
[2025-05-06 13:52:12,104][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.6224, lr=0.0001
[2025-05-06 13:52:33,885][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=4.9992, lr=0.0001
[2025-05-06 13:52:55,191][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.7088, lr=0.0001
[2025-05-06 13:53:16,941][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=5.2725, lr=0.0001
[2025-05-06 13:53:39,038][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=5.2937, lr=0.0001
[2025-05-06 13:54:00,134][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=5.1787, lr=0.0001
[2025-05-06 13:54:00,159][meta_train][INFO] - epoch_22 saved !
[2025-05-06 13:54:21,672][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=5.0170, lr=0.0001
[2025-05-06 13:54:43,311][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=5.0422, lr=0.0001
[2025-05-06 13:55:03,990][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=5.1475, lr=0.0001
[2025-05-06 13:55:27,477][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.6691, lr=0.0001
[2025-05-06 13:55:48,130][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.7068, lr=0.0001
[2025-05-06 13:56:09,443][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=5.2391, lr=0.0001
[2025-05-06 13:56:30,634][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6212, lr=0.0001
[2025-05-06 13:56:51,130][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=5.2134, lr=0.0001
[2025-05-06 13:56:51,156][meta_train][INFO] - epoch_23 saved !
[2025-05-06 13:57:12,729][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6218, lr=0.0001
[2025-05-06 13:57:33,607][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.7116, lr=0.0001
[2025-05-06 13:57:56,165][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.6759, lr=0.0001
[2025-05-06 13:58:17,650][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=5.1440, lr=0.0001
[2025-05-06 13:58:38,938][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=5.2424, lr=0.0001
[2025-05-06 13:59:00,304][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=4.9730, lr=0.0001
[2025-05-06 13:59:21,355][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=5.1726, lr=0.0001
[2025-05-06 13:59:43,213][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=4.9999, lr=0.0001
[2025-05-06 13:59:43,239][meta_train][INFO] - epoch_24 saved !
[2025-05-06 14:00:04,160][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6199, lr=0.0001
[2025-05-06 14:00:25,767][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=5.0227, lr=0.0001
[2025-05-06 14:00:46,577][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=5.1661, lr=0.0001
[2025-05-06 14:01:08,166][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=5.2118, lr=0.0001
[2025-05-06 14:01:28,901][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7084, lr=0.0001
[2025-05-06 14:01:52,225][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.6648, lr=0.0001
[2025-05-06 14:02:13,515][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=4.9498, lr=0.0001
[2025-05-06 14:02:34,904][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=5.0716, lr=0.0001
[2025-05-06 14:02:34,930][meta_train][INFO] - epoch_25 saved !
[2025-05-06 14:02:55,736][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.6980, lr=0.0001
[2025-05-06 14:03:19,307][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.6627, lr=0.0001
[2025-05-06 14:03:40,549][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=5.1096, lr=0.0001
[2025-05-06 14:04:01,637][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6201, lr=0.0001
[2025-05-06 14:04:23,226][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=5.1633, lr=0.0001
[2025-05-06 14:04:45,065][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=5.0160, lr=0.0001
[2025-05-06 14:05:06,129][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=5.0661, lr=0.0001
[2025-05-06 14:05:27,205][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=4.9299, lr=0.0001
[2025-05-06 14:05:27,241][meta_train][INFO] - epoch_26 saved !
[2025-05-06 14:05:48,933][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=4.9261, lr=0.0001
[2025-05-06 14:06:11,958][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.6577, lr=0.0001
[2025-05-06 14:06:33,507][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=5.1241, lr=0.0001
[2025-05-06 14:06:36,050][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 5

[2025-05-06 14:06:36,099][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 14:06:36,099][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 14:06:36,099][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 14:06:48,261][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 14:06:54,554][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=5.0585, lr=0.0001
[2025-05-06 14:06:56,154][train][INFO] - Epoch 1/100, Val Acc=0.5388, Val Loss=1.9143, lr=0.0100
[2025-05-06 14:06:58,391][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 7

[2025-05-06 14:06:58,443][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 14:06:58,444][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 14:06:58,444][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 14:07:03,978][train][INFO] - Epoch 2/100, Val Acc=0.5905, Val Loss=1.6652, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 14:07:10,726][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 14:07:11,931][train][INFO] - Epoch 3/100, Val Acc=0.6051, Val Loss=1.6288, lr=0.0100
[2025-05-06 14:07:16,068][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.6951, lr=0.0001
[2025-05-06 14:07:18,424][train][INFO] - Epoch 1/100, Val Acc=0.0524, Val Loss=3.9566, lr=0.0100
[2025-05-06 14:07:19,444][train][INFO] - Epoch 4/100, Val Acc=0.6142, Val Loss=1.6246, lr=0.0100
[2025-05-06 14:07:19,952][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '7'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Neo
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 3

[2025-05-06 14:07:20,008][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 14:07:20,008][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 14:07:20,009][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 14:07:25,936][train][INFO] - Epoch 2/100, Val Acc=0.0973, Val Loss=3.8141, lr=0.0100
[2025-05-06 14:07:27,537][train][INFO] - Epoch 5/100, Val Acc=0.6118, Val Loss=1.6471, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=3']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 123, in main
    new_model = get_new_model(metanetwork)
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 112, in get_new_model
    node_pred, edge_pred = metanetwork.forward(node_features.to(device), edge_index.to(device), edge_features.to(device))
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 47, in forward
    ret_node1, ret_edge1 = self.convs[i].forward(self.norm(hidden), edge_index, edge_attr)
  File "/home/liuyewei/metanetwork/meta-pruning/nn/GNN.py", line 17, in forward
    ret_node = self.downlin(self.propagate(edge_index, x=self.lin1(x), z=self.lin2(x), edge_attr=edge_attr))
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 484, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 608, in aggregate
    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/multi.py", line 163, in forward
    fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 116, in __call__
    raise e
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py", line 109, in __call__
    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/nn/aggr/fused.py", line 228, in forward
    out = scatter(x * x, index, 0, dim_size, reduce='sum')
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/torch_geometric/utils/scatter.py", line 74, in scatter
    return src.new_zeros(size).scatter_add_(dim, index, src)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 23.65 GiB total capacity; 1.33 GiB already allocated; 250.06 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-06 14:07:33,661][train][INFO] - Epoch 3/100, Val Acc=0.2465, Val Loss=2.8031, lr=0.0100
[2025-05-06 14:07:35,086][train][INFO] - Epoch 6/100, Val Acc=0.6022, Val Loss=1.7297, lr=0.0100
[2025-05-06 14:07:39,082][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=4.9820, lr=0.0001
[2025-05-06 14:07:40,802][train][INFO] - Epoch 4/100, Val Acc=0.3088, Val Loss=2.5281, lr=0.0100
[2025-05-06 14:07:42,775][train][INFO] - Epoch 7/100, Val Acc=0.6249, Val Loss=1.6023, lr=0.0100
[2025-05-06 14:07:48,554][train][INFO] - Epoch 5/100, Val Acc=0.3477, Val Loss=2.3915, lr=0.0100
[2025-05-06 14:07:50,645][train][INFO] - Epoch 8/100, Val Acc=0.6186, Val Loss=1.6731, lr=0.0100
[2025-05-06 14:07:56,520][train][INFO] - Epoch 6/100, Val Acc=0.3562, Val Loss=2.3438, lr=0.0100
[2025-05-06 14:07:58,232][train][INFO] - Epoch 9/100, Val Acc=0.6447, Val Loss=1.5564, lr=0.0100
[2025-05-06 14:08:00,807][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=5.0298, lr=0.0001
[2025-05-06 14:08:04,177][train][INFO] - Epoch 7/100, Val Acc=0.4136, Val Loss=2.1651, lr=0.0100
[2025-05-06 14:08:05,924][train][INFO] - Epoch 10/100, Val Acc=0.6253, Val Loss=1.6497, lr=0.0100
[2025-05-06 14:08:11,830][train][INFO] - Epoch 8/100, Val Acc=0.4321, Val Loss=2.0833, lr=0.0100
[2025-05-06 14:08:13,718][train][INFO] - Epoch 11/100, Val Acc=0.6188, Val Loss=1.6817, lr=0.0100
[2025-05-06 14:08:19,311][train][INFO] - Epoch 9/100, Val Acc=0.4025, Val Loss=2.3507, lr=0.0100
[2025-05-06 14:08:21,379][train][INFO] - Epoch 12/100, Val Acc=0.6385, Val Loss=1.6093, lr=0.0100
[2025-05-06 14:08:22,885][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6175, lr=0.0001
[2025-05-06 14:08:22,917][meta_train][INFO] - epoch_27 saved !
[2025-05-06 14:08:27,066][train][INFO] - Epoch 10/100, Val Acc=0.4405, Val Loss=2.1283, lr=0.0100
[2025-05-06 14:08:29,291][train][INFO] - Epoch 13/100, Val Acc=0.6486, Val Loss=1.5627, lr=0.0100
[2025-05-06 14:08:34,079][train][INFO] - Epoch 11/100, Val Acc=0.4728, Val Loss=1.9472, lr=0.0100
[2025-05-06 14:08:37,385][train][INFO] - Epoch 14/100, Val Acc=0.6550, Val Loss=1.5431, lr=0.0100
[2025-05-06 14:08:41,964][train][INFO] - Epoch 12/100, Val Acc=0.4766, Val Loss=1.9965, lr=0.0100
[2025-05-06 14:08:45,229][train][INFO] - Epoch 15/100, Val Acc=0.6370, Val Loss=1.6230, lr=0.0100
[2025-05-06 14:08:46,453][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.6542, lr=0.0001
[2025-05-06 14:08:50,092][train][INFO] - Epoch 13/100, Val Acc=0.4749, Val Loss=2.0047, lr=0.0100
[2025-05-06 14:08:52,975][train][INFO] - Epoch 16/100, Val Acc=0.6355, Val Loss=1.6119, lr=0.0100
[2025-05-06 14:08:57,630][train][INFO] - Epoch 14/100, Val Acc=0.5411, Val Loss=1.7201, lr=0.0100
[2025-05-06 14:09:00,240][train][INFO] - Epoch 17/100, Val Acc=0.6507, Val Loss=1.5960, lr=0.0100
[2025-05-06 14:09:05,297][train][INFO] - Epoch 15/100, Val Acc=0.5152, Val Loss=1.8630, lr=0.0100
[2025-05-06 14:09:08,329][train][INFO] - Epoch 18/100, Val Acc=0.6401, Val Loss=1.6551, lr=0.0100
[2025-05-06 14:09:08,921][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=4.9772, lr=0.0001
[2025-05-06 14:09:13,120][train][INFO] - Epoch 16/100, Val Acc=0.5345, Val Loss=1.7411, lr=0.0100
[2025-05-06 14:09:16,327][train][INFO] - Epoch 19/100, Val Acc=0.6459, Val Loss=1.6312, lr=0.0100
[2025-05-06 14:09:21,095][train][INFO] - Epoch 17/100, Val Acc=0.5299, Val Loss=1.8028, lr=0.0100
[2025-05-06 14:09:24,026][train][INFO] - Epoch 20/100, Val Acc=0.6418, Val Loss=1.6369, lr=0.0100
[2025-05-06 14:09:28,175][train][INFO] - Epoch 18/100, Val Acc=0.5335, Val Loss=1.7596, lr=0.0100
[2025-05-06 14:09:30,774][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=5.0327, lr=0.0001
[2025-05-06 14:09:32,041][train][INFO] - Epoch 21/100, Val Acc=0.6536, Val Loss=1.5908, lr=0.0100
[2025-05-06 14:09:35,534][train][INFO] - Epoch 19/100, Val Acc=0.5545, Val Loss=1.7116, lr=0.0100
[2025-05-06 14:09:39,969][train][INFO] - Epoch 22/100, Val Acc=0.6513, Val Loss=1.6205, lr=0.0100
[2025-05-06 14:09:43,146][train][INFO] - Epoch 20/100, Val Acc=0.5333, Val Loss=1.8023, lr=0.0100
[2025-05-06 14:09:47,546][train][INFO] - Epoch 23/100, Val Acc=0.6410, Val Loss=1.6584, lr=0.0100
[2025-05-06 14:09:50,917][train][INFO] - Epoch 21/100, Val Acc=0.5518, Val Loss=1.7542, lr=0.0100
[2025-05-06 14:09:53,160][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=5.0843, lr=0.0001
[2025-05-06 14:09:55,089][train][INFO] - Epoch 24/100, Val Acc=0.6472, Val Loss=1.5989, lr=0.0100
[2025-05-06 14:09:58,554][train][INFO] - Epoch 22/100, Val Acc=0.5487, Val Loss=1.7301, lr=0.0100
[2025-05-06 14:10:02,974][train][INFO] - Epoch 25/100, Val Acc=0.6483, Val Loss=1.6271, lr=0.0100
[2025-05-06 14:10:06,228][train][INFO] - Epoch 23/100, Val Acc=0.5521, Val Loss=1.7294, lr=0.0100
[2025-05-06 14:10:10,975][train][INFO] - Epoch 26/100, Val Acc=0.6412, Val Loss=1.7195, lr=0.0100
[2025-05-06 14:10:14,033][train][INFO] - Epoch 24/100, Val Acc=0.5757, Val Loss=1.6005, lr=0.0100
[2025-05-06 14:10:15,097][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=4.8860, lr=0.0001
[2025-05-06 14:10:18,971][train][INFO] - Epoch 27/100, Val Acc=0.6388, Val Loss=1.7254, lr=0.0100
[2025-05-06 14:10:21,302][train][INFO] - Epoch 25/100, Val Acc=0.5517, Val Loss=1.8015, lr=0.0100
[2025-05-06 14:10:27,108][train][INFO] - Epoch 28/100, Val Acc=0.6466, Val Loss=1.6468, lr=0.0100
[2025-05-06 14:10:28,633][train][INFO] - Epoch 26/100, Val Acc=0.5545, Val Loss=1.7868, lr=0.0100
[2025-05-06 14:10:34,985][train][INFO] - Epoch 29/100, Val Acc=0.6454, Val Loss=1.6481, lr=0.0100
[2025-05-06 14:10:35,514][train][INFO] - Epoch 27/100, Val Acc=0.5567, Val Loss=1.7422, lr=0.0100
[2025-05-06 14:10:37,051][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6153, lr=0.0001
[2025-05-06 14:10:42,205][train][INFO] - Epoch 30/100, Val Acc=0.6311, Val Loss=1.7156, lr=0.0100
[2025-05-06 14:10:43,573][train][INFO] - Epoch 28/100, Val Acc=0.5807, Val Loss=1.6454, lr=0.0100
[2025-05-06 14:10:49,235][train][INFO] - Epoch 31/100, Val Acc=0.6407, Val Loss=1.6991, lr=0.0100
[2025-05-06 14:10:51,009][train][INFO] - Epoch 29/100, Val Acc=0.5775, Val Loss=1.6527, lr=0.0100
[2025-05-06 14:10:56,485][train][INFO] - Epoch 32/100, Val Acc=0.6444, Val Loss=1.6233, lr=0.0100
[2025-05-06 14:10:58,768][train][INFO] - Epoch 30/100, Val Acc=0.5912, Val Loss=1.6222, lr=0.0100
[2025-05-06 14:10:58,957][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=4.9959, lr=0.0001
[2025-05-06 14:11:04,593][train][INFO] - Epoch 33/100, Val Acc=0.6542, Val Loss=1.5947, lr=0.0100
[2025-05-06 14:11:05,968][train][INFO] - Epoch 31/100, Val Acc=0.5730, Val Loss=1.7079, lr=0.0100
[2025-05-06 14:11:12,057][train][INFO] - Epoch 34/100, Val Acc=0.6461, Val Loss=1.6767, lr=0.0100
[2025-05-06 14:11:13,128][train][INFO] - Epoch 32/100, Val Acc=0.5983, Val Loss=1.5958, lr=0.0100
[2025-05-06 14:11:20,221][train][INFO] - Epoch 35/100, Val Acc=0.6455, Val Loss=1.6600, lr=0.0100
[2025-05-06 14:11:20,825][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7017, lr=0.0001
[2025-05-06 14:11:20,857][meta_train][INFO] - epoch_28 saved !
[2025-05-06 14:11:21,100][train][INFO] - Epoch 33/100, Val Acc=0.5797, Val Loss=1.7142, lr=0.0100
[2025-05-06 14:11:28,037][train][INFO] - Epoch 36/100, Val Acc=0.6568, Val Loss=1.6050, lr=0.0100
[2025-05-06 14:11:29,124][train][INFO] - Epoch 34/100, Val Acc=0.5807, Val Loss=1.7017, lr=0.0100
[2025-05-06 14:11:36,014][train][INFO] - Epoch 37/100, Val Acc=0.6486, Val Loss=1.6599, lr=0.0100
[2025-05-06 14:11:37,094][train][INFO] - Epoch 35/100, Val Acc=0.5986, Val Loss=1.6489, lr=0.0100
[2025-05-06 14:11:43,348][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=5.0940, lr=0.0001
[2025-05-06 14:11:44,002][train][INFO] - Epoch 38/100, Val Acc=0.6551, Val Loss=1.6265, lr=0.0100
[2025-05-06 14:11:44,986][train][INFO] - Epoch 36/100, Val Acc=0.5812, Val Loss=1.6837, lr=0.0100
[2025-05-06 14:11:51,797][train][INFO] - Epoch 39/100, Val Acc=0.6469, Val Loss=1.6729, lr=0.0100
[2025-05-06 14:11:52,122][train][INFO] - Epoch 37/100, Val Acc=0.6019, Val Loss=1.6179, lr=0.0100
[2025-05-06 14:11:59,451][train][INFO] - Epoch 40/100, Val Acc=0.6398, Val Loss=1.6846, lr=0.0100
[2025-05-06 14:12:00,100][train][INFO] - Epoch 38/100, Val Acc=0.6004, Val Loss=1.6103, lr=0.0100
[2025-05-06 14:12:05,179][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=4.9028, lr=0.0001
[2025-05-06 14:12:07,218][train][INFO] - Epoch 41/100, Val Acc=0.6542, Val Loss=1.6157, lr=0.0100
[2025-05-06 14:12:07,540][train][INFO] - Epoch 39/100, Val Acc=0.5772, Val Loss=1.7546, lr=0.0100
[2025-05-06 14:12:14,945][train][INFO] - Epoch 42/100, Val Acc=0.6492, Val Loss=1.6579, lr=0.0100
[2025-05-06 14:12:14,983][train][INFO] - Epoch 40/100, Val Acc=0.5951, Val Loss=1.6775, lr=0.0100
[2025-05-06 14:12:22,309][train][INFO] - Epoch 41/100, Val Acc=0.6058, Val Loss=1.6663, lr=0.0100
[2025-05-06 14:12:22,917][train][INFO] - Epoch 43/100, Val Acc=0.6419, Val Loss=1.6475, lr=0.0100
[2025-05-06 14:12:26,962][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=5.0150, lr=0.0001
[2025-05-06 14:12:29,926][train][INFO] - Epoch 42/100, Val Acc=0.5796, Val Loss=1.7886, lr=0.0100
[2025-05-06 14:12:30,529][train][INFO] - Epoch 44/100, Val Acc=0.6519, Val Loss=1.6398, lr=0.0100
[2025-05-06 14:12:37,782][train][INFO] - Epoch 43/100, Val Acc=0.5923, Val Loss=1.6648, lr=0.0100
[2025-05-06 14:12:38,348][train][INFO] - Epoch 45/100, Val Acc=0.6456, Val Loss=1.7105, lr=0.0100
[2025-05-06 14:12:45,102][train][INFO] - Epoch 44/100, Val Acc=0.6088, Val Loss=1.5991, lr=0.0100
[2025-05-06 14:12:45,915][train][INFO] - Epoch 46/100, Val Acc=0.6609, Val Loss=1.6186, lr=0.0100
[2025-05-06 14:12:50,813][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.6474, lr=0.0001
[2025-05-06 14:12:52,160][train][INFO] - Epoch 45/100, Val Acc=0.5958, Val Loss=1.6826, lr=0.0100
[2025-05-06 14:12:53,879][train][INFO] - Epoch 47/100, Val Acc=0.6402, Val Loss=1.7108, lr=0.0100
[2025-05-06 14:12:59,553][train][INFO] - Epoch 46/100, Val Acc=0.6021, Val Loss=1.6619, lr=0.0100
[2025-05-06 14:13:01,887][train][INFO] - Epoch 48/100, Val Acc=0.6447, Val Loss=1.7020, lr=0.0100
[2025-05-06 14:13:06,954][train][INFO] - Epoch 47/100, Val Acc=0.5869, Val Loss=1.7459, lr=0.0100
[2025-05-06 14:13:09,700][train][INFO] - Epoch 49/100, Val Acc=0.6357, Val Loss=1.7686, lr=0.0100
[2025-05-06 14:13:13,433][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=4.9404, lr=0.0001
[2025-05-06 14:13:14,805][train][INFO] - Epoch 48/100, Val Acc=0.5913, Val Loss=1.7663, lr=0.0100
[2025-05-06 14:13:17,221][train][INFO] - Epoch 50/100, Val Acc=0.6397, Val Loss=1.8058, lr=0.0100
[2025-05-06 14:13:21,423][train][INFO] - Epoch 49/100, Val Acc=0.6002, Val Loss=1.6627, lr=0.0100
[2025-05-06 14:13:25,129][train][INFO] - Epoch 51/100, Val Acc=0.6428, Val Loss=1.7441, lr=0.0100
[2025-05-06 14:13:28,872][train][INFO] - Epoch 50/100, Val Acc=0.6114, Val Loss=1.6472, lr=0.0100
[2025-05-06 14:13:32,199][train][INFO] - Epoch 52/100, Val Acc=0.6320, Val Loss=1.7522, lr=0.0100
[2025-05-06 14:13:35,031][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.6955, lr=0.0001
[2025-05-06 14:13:36,528][train][INFO] - Epoch 51/100, Val Acc=0.5937, Val Loss=1.7580, lr=0.0100
[2025-05-06 14:13:40,345][train][INFO] - Epoch 53/100, Val Acc=0.6471, Val Loss=1.6949, lr=0.0100
[2025-05-06 14:13:44,178][train][INFO] - Epoch 52/100, Val Acc=0.5821, Val Loss=1.8240, lr=0.0100
[2025-05-06 14:13:47,772][train][INFO] - Epoch 54/100, Val Acc=0.6570, Val Loss=1.5829, lr=0.0100
[2025-05-06 14:13:52,221][train][INFO] - Epoch 53/100, Val Acc=0.6033, Val Loss=1.6947, lr=0.0100
[2025-05-06 14:13:55,617][train][INFO] - Epoch 55/100, Val Acc=0.6527, Val Loss=1.7139, lr=0.0100
[2025-05-06 14:13:57,016][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=4.9809, lr=0.0001
[2025-05-06 14:13:59,674][train][INFO] - Epoch 54/100, Val Acc=0.6141, Val Loss=1.6550, lr=0.0100
[2025-05-06 14:14:02,912][train][INFO] - Epoch 56/100, Val Acc=0.6456, Val Loss=1.7097, lr=0.0100
[2025-05-06 14:14:06,759][train][INFO] - Epoch 55/100, Val Acc=0.5965, Val Loss=1.7805, lr=0.0100
[2025-05-06 14:14:10,445][train][INFO] - Epoch 57/100, Val Acc=0.6436, Val Loss=1.6978, lr=0.0100
[2025-05-06 14:14:14,237][train][INFO] - Epoch 56/100, Val Acc=0.5922, Val Loss=1.7766, lr=0.0100
[2025-05-06 14:14:18,276][train][INFO] - Epoch 58/100, Val Acc=0.6539, Val Loss=1.6660, lr=0.0100
[2025-05-06 14:14:19,344][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6170, lr=0.0001
[2025-05-06 14:14:19,380][meta_train][INFO] - epoch_29 saved !
[2025-05-06 14:14:21,799][train][INFO] - Epoch 57/100, Val Acc=0.5874, Val Loss=1.8184, lr=0.0100
[2025-05-06 14:14:26,531][train][INFO] - Epoch 59/100, Val Acc=0.6525, Val Loss=1.6183, lr=0.0100
[2025-05-06 14:14:29,110][train][INFO] - Epoch 58/100, Val Acc=0.6200, Val Loss=1.6121, lr=0.0100
[2025-05-06 14:14:34,080][train][INFO] - Epoch 60/100, Val Acc=0.6467, Val Loss=1.7003, lr=0.0100
[2025-05-06 14:14:36,901][train][INFO] - Epoch 59/100, Val Acc=0.5976, Val Loss=1.7469, lr=0.0100
[2025-05-06 14:14:42,044][train][INFO] - Epoch 61/100, Val Acc=0.7028, Val Loss=1.3693, lr=0.0010
[2025-05-06 14:14:43,396][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.6620, lr=0.0001
[2025-05-06 14:14:44,611][train][INFO] - Epoch 60/100, Val Acc=0.5998, Val Loss=1.7285, lr=0.0100
[2025-05-06 14:14:49,871][train][INFO] - Epoch 62/100, Val Acc=0.7082, Val Loss=1.3671, lr=0.0010
[2025-05-06 14:14:52,091][train][INFO] - Epoch 61/100, Val Acc=0.6699, Val Loss=1.3746, lr=0.0010
[2025-05-06 14:14:57,801][train][INFO] - Epoch 63/100, Val Acc=0.7103, Val Loss=1.3644, lr=0.0010
[2025-05-06 14:14:59,814][train][INFO] - Epoch 62/100, Val Acc=0.6735, Val Loss=1.3636, lr=0.0010
[2025-05-06 14:15:05,029][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7120, lr=0.0001
[2025-05-06 14:15:05,337][train][INFO] - Epoch 64/100, Val Acc=0.7099, Val Loss=1.3672, lr=0.0010
[2025-05-06 14:15:06,814][train][INFO] - Epoch 63/100, Val Acc=0.6765, Val Loss=1.3726, lr=0.0010
[2025-05-06 14:15:12,859][train][INFO] - Epoch 65/100, Val Acc=0.7142, Val Loss=1.3654, lr=0.0010
[2025-05-06 14:15:14,751][train][INFO] - Epoch 64/100, Val Acc=0.6764, Val Loss=1.3784, lr=0.0010
[2025-05-06 14:15:20,903][train][INFO] - Epoch 66/100, Val Acc=0.7140, Val Loss=1.3695, lr=0.0010
[2025-05-06 14:15:22,532][train][INFO] - Epoch 65/100, Val Acc=0.6804, Val Loss=1.3804, lr=0.0010
[2025-05-06 14:15:27,378][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=4.9761, lr=0.0001
[2025-05-06 14:15:28,857][train][INFO] - Epoch 67/100, Val Acc=0.7161, Val Loss=1.3731, lr=0.0010
[2025-05-06 14:15:30,203][train][INFO] - Epoch 66/100, Val Acc=0.6744, Val Loss=1.3914, lr=0.0010
[2025-05-06 14:15:36,474][train][INFO] - Epoch 68/100, Val Acc=0.7137, Val Loss=1.3751, lr=0.0010
[2025-05-06 14:15:37,399][train][INFO] - Epoch 67/100, Val Acc=0.6772, Val Loss=1.3992, lr=0.0010
[2025-05-06 14:15:43,959][train][INFO] - Epoch 69/100, Val Acc=0.7147, Val Loss=1.3752, lr=0.0010
[2025-05-06 14:15:44,588][train][INFO] - Epoch 68/100, Val Acc=0.6740, Val Loss=1.4093, lr=0.0010
[2025-05-06 14:15:49,309][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6190, lr=0.0001
[2025-05-06 14:15:51,100][train][INFO] - Epoch 70/100, Val Acc=0.7122, Val Loss=1.3849, lr=0.0010
[2025-05-06 14:15:52,393][train][INFO] - Epoch 69/100, Val Acc=0.6765, Val Loss=1.4186, lr=0.0010
[2025-05-06 14:15:58,884][train][INFO] - Epoch 71/100, Val Acc=0.7129, Val Loss=1.3853, lr=0.0010
[2025-05-06 14:16:00,259][train][INFO] - Epoch 70/100, Val Acc=0.6773, Val Loss=1.4223, lr=0.0010
[2025-05-06 14:16:06,446][train][INFO] - Epoch 72/100, Val Acc=0.7147, Val Loss=1.3902, lr=0.0010
[2025-05-06 14:16:08,159][train][INFO] - Epoch 71/100, Val Acc=0.6769, Val Loss=1.4321, lr=0.0010
[2025-05-06 14:16:11,376][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=5.0150, lr=0.0001
[2025-05-06 14:16:13,707][train][INFO] - Epoch 73/100, Val Acc=0.7156, Val Loss=1.3862, lr=0.0010
[2025-05-06 14:16:15,762][train][INFO] - Epoch 72/100, Val Acc=0.6764, Val Loss=1.4392, lr=0.0010
[2025-05-06 14:16:21,534][train][INFO] - Epoch 74/100, Val Acc=0.7134, Val Loss=1.3958, lr=0.0010
[2025-05-06 14:16:22,890][train][INFO] - Epoch 73/100, Val Acc=0.6777, Val Loss=1.4383, lr=0.0010
[2025-05-06 14:16:29,631][train][INFO] - Epoch 75/100, Val Acc=0.7160, Val Loss=1.3863, lr=0.0010
[2025-05-06 14:16:30,473][train][INFO] - Epoch 74/100, Val Acc=0.6795, Val Loss=1.4472, lr=0.0010
[2025-05-06 14:16:33,374][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=5.1941, lr=0.0001
[2025-05-06 14:16:37,518][train][INFO] - Epoch 76/100, Val Acc=0.7133, Val Loss=1.3988, lr=0.0010
[2025-05-06 14:16:38,377][train][INFO] - Epoch 75/100, Val Acc=0.6775, Val Loss=1.4454, lr=0.0010
[2025-05-06 14:16:45,580][train][INFO] - Epoch 77/100, Val Acc=0.7172, Val Loss=1.3941, lr=0.0010
[2025-05-06 14:16:45,619][train][INFO] - Epoch 76/100, Val Acc=0.6764, Val Loss=1.4556, lr=0.0010
[2025-05-06 14:16:52,994][train][INFO] - Epoch 78/100, Val Acc=0.7169, Val Loss=1.4005, lr=0.0010
[2025-05-06 14:16:53,428][train][INFO] - Epoch 77/100, Val Acc=0.6717, Val Loss=1.4753, lr=0.0010
[2025-05-06 14:16:55,613][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=4.8963, lr=0.0001
[2025-05-06 14:17:01,161][train][INFO] - Epoch 79/100, Val Acc=0.7152, Val Loss=1.4050, lr=0.0010
[2025-05-06 14:17:01,478][train][INFO] - Epoch 78/100, Val Acc=0.6743, Val Loss=1.4704, lr=0.0010
[2025-05-06 14:17:08,805][train][INFO] - Epoch 79/100, Val Acc=0.6756, Val Loss=1.4697, lr=0.0010
[2025-05-06 14:17:08,943][train][INFO] - Epoch 80/100, Val Acc=0.7199, Val Loss=1.3979, lr=0.0010
[2025-05-06 14:17:15,750][train][INFO] - Epoch 80/100, Val Acc=0.6750, Val Loss=1.4743, lr=0.0010
[2025-05-06 14:17:16,091][train][INFO] - Epoch 81/100, Val Acc=0.7148, Val Loss=1.3980, lr=0.0010
[2025-05-06 14:17:17,577][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=5.1337, lr=0.0001
[2025-05-06 14:17:17,603][meta_train][INFO] - epoch_30 saved !
[2025-05-06 14:17:23,700][train][INFO] - Epoch 81/100, Val Acc=0.6735, Val Loss=1.4841, lr=0.0010
[2025-05-06 14:17:24,154][train][INFO] - Epoch 82/100, Val Acc=0.7186, Val Loss=1.3932, lr=0.0010
[2025-05-06 14:17:31,304][train][INFO] - Epoch 83/100, Val Acc=0.7166, Val Loss=1.3970, lr=0.0010
[2025-05-06 14:17:31,603][train][INFO] - Epoch 82/100, Val Acc=0.6751, Val Loss=1.4951, lr=0.0010
[2025-05-06 14:17:39,430][train][INFO] - Epoch 84/100, Val Acc=0.7158, Val Loss=1.4038, lr=0.0010
[2025-05-06 14:17:39,457][train][INFO] - Epoch 83/100, Val Acc=0.6754, Val Loss=1.5001, lr=0.0010
[2025-05-06 14:17:39,749][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=4.8957, lr=0.0001
[2025-05-06 14:17:46,437][train][INFO] - Epoch 85/100, Val Acc=0.7162, Val Loss=1.4050, lr=0.0010
[2025-05-06 14:17:46,692][train][INFO] - Epoch 84/100, Val Acc=0.6739, Val Loss=1.5022, lr=0.0010
[2025-05-06 14:17:53,998][train][INFO] - Epoch 85/100, Val Acc=0.6729, Val Loss=1.5096, lr=0.0010
[2025-05-06 14:17:54,035][train][INFO] - Epoch 86/100, Val Acc=0.7180, Val Loss=1.4079, lr=0.0010
[2025-05-06 14:18:01,165][train][INFO] - Epoch 86/100, Val Acc=0.6756, Val Loss=1.5205, lr=0.0010
[2025-05-06 14:18:02,108][train][INFO] - Epoch 87/100, Val Acc=0.7149, Val Loss=1.4062, lr=0.0010
[2025-05-06 14:18:03,695][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.6797, lr=0.0001
[2025-05-06 14:18:08,498][train][INFO] - Epoch 87/100, Val Acc=0.6751, Val Loss=1.5312, lr=0.0010
[2025-05-06 14:18:09,850][train][INFO] - Epoch 88/100, Val Acc=0.7165, Val Loss=1.4074, lr=0.0010
[2025-05-06 14:18:15,657][train][INFO] - Epoch 88/100, Val Acc=0.6714, Val Loss=1.5303, lr=0.0010
[2025-05-06 14:18:17,827][train][INFO] - Epoch 89/100, Val Acc=0.7161, Val Loss=1.4096, lr=0.0010
[2025-05-06 14:18:23,220][train][INFO] - Epoch 89/100, Val Acc=0.6752, Val Loss=1.5226, lr=0.0010
[2025-05-06 14:18:25,252][train][INFO] - Epoch 90/100, Val Acc=0.7161, Val Loss=1.4155, lr=0.0010
[2025-05-06 14:18:26,259][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=4.9454, lr=0.0001
[2025-05-06 14:18:30,677][train][INFO] - Epoch 90/100, Val Acc=0.6761, Val Loss=1.5294, lr=0.0010
[2025-05-06 14:18:33,038][train][INFO] - Epoch 91/100, Val Acc=0.7160, Val Loss=1.4069, lr=0.0001
[2025-05-06 14:18:38,358][train][INFO] - Epoch 91/100, Val Acc=0.6768, Val Loss=1.5270, lr=0.0001
[2025-05-06 14:18:41,107][train][INFO] - Epoch 92/100, Val Acc=0.7176, Val Loss=1.4083, lr=0.0001
[2025-05-06 14:18:45,020][train][INFO] - Epoch 92/100, Val Acc=0.6751, Val Loss=1.5318, lr=0.0001
[2025-05-06 14:18:48,038][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=5.0104, lr=0.0001
[2025-05-06 14:18:48,779][train][INFO] - Epoch 93/100, Val Acc=0.7177, Val Loss=1.4067, lr=0.0001
[2025-05-06 14:18:52,520][train][INFO] - Epoch 93/100, Val Acc=0.6768, Val Loss=1.5207, lr=0.0001
[2025-05-06 14:18:56,313][train][INFO] - Epoch 94/100, Val Acc=0.7154, Val Loss=1.4057, lr=0.0001
[2025-05-06 14:18:59,698][train][INFO] - Epoch 94/100, Val Acc=0.6775, Val Loss=1.5206, lr=0.0001
[2025-05-06 14:19:04,173][train][INFO] - Epoch 95/100, Val Acc=0.7182, Val Loss=1.4054, lr=0.0001
[2025-05-06 14:19:07,322][train][INFO] - Epoch 95/100, Val Acc=0.6757, Val Loss=1.5264, lr=0.0001
[2025-05-06 14:19:10,416][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=5.1643, lr=0.0001
[2025-05-06 14:19:12,096][train][INFO] - Epoch 96/100, Val Acc=0.7179, Val Loss=1.4052, lr=0.0001
[2025-05-06 14:19:15,291][train][INFO] - Epoch 96/100, Val Acc=0.6779, Val Loss=1.5177, lr=0.0001
[2025-05-06 14:19:20,072][train][INFO] - Epoch 97/100, Val Acc=0.7167, Val Loss=1.4078, lr=0.0001
[2025-05-06 14:19:22,993][train][INFO] - Epoch 97/100, Val Acc=0.6779, Val Loss=1.5292, lr=0.0001
[2025-05-06 14:19:28,142][train][INFO] - Epoch 98/100, Val Acc=0.7162, Val Loss=1.4039, lr=0.0001
[2025-05-06 14:19:30,324][train][INFO] - Epoch 98/100, Val Acc=0.6771, Val Loss=1.5204, lr=0.0001
[2025-05-06 14:19:31,949][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.7832, lr=0.0001
[2025-05-06 14:19:35,987][train][INFO] - Epoch 99/100, Val Acc=0.7166, Val Loss=1.4085, lr=0.0001
[2025-05-06 14:19:37,971][train][INFO] - Epoch 99/100, Val Acc=0.6785, Val Loss=1.5280, lr=0.0001
[2025-05-06 14:19:43,383][train][INFO] - Epoch 100/100, Val Acc=0.7167, Val Loss=1.4029, lr=0.0001
[2025-05-06 14:19:45,693][train][INFO] - Epoch 100/100, Val Acc=0.6766, Val Loss=1.5244, lr=0.0001
[2025-05-06 14:19:48,424][train][INFO] - After training : Train Acc=0.9971  Val Acc=0.7199
[2025-05-06 14:19:48,437][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 14:19:50,556][train][INFO] - After training : Train Acc=0.9377  Val Acc=0.6804
[2025-05-06 14:19:50,561][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 14:19:54,135][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6197, lr=0.0001
[2025-05-06 14:20:16,482][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=5.4611, lr=0.0001
[2025-05-06 14:20:16,522][meta_train][INFO] - epoch_31 saved !
[2025-05-06 14:20:38,863][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.8151, lr=0.0001
[2025-05-06 14:20:55,326][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 14:20:58,531][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 14:21:00,852][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=5.4878, lr=0.0001
[2025-05-06 14:21:23,614][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=4.8996, lr=0.0001
[2025-05-06 14:21:46,433][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=5.1702, lr=0.0001
[2025-05-06 14:22:06,696][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 14:22:07,163][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 14:22:09,199][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=4.8913, lr=0.0001
[2025-05-06 14:22:12,262][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 14:22:12,753][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 14:22:30,539][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6169, lr=0.0001
[2025-05-06 14:22:51,587][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=4.9404, lr=0.0001
[2025-05-06 14:23:14,850][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.7405, lr=0.0001
[2025-05-06 14:23:14,875][meta_train][INFO] - epoch_32 saved !
[2025-05-06 14:23:35,758][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=4.9062, lr=0.0001
[2025-05-06 14:23:58,491][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.7668, lr=0.0001
[2025-05-06 14:24:20,030][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=5.4284, lr=0.0001
[2025-05-06 14:24:41,186][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=4.9686, lr=0.0001
[2025-05-06 14:25:02,546][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=5.1720, lr=0.0001
[2025-05-06 14:25:24,268][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=4.8816, lr=0.0001
[2025-05-06 14:25:45,823][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6191, lr=0.0001
[2025-05-06 14:26:06,698][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.7858, lr=0.0001
[2025-05-06 14:26:06,722][meta_train][INFO] - epoch_33 saved !
[2025-05-06 14:26:27,572][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.7833, lr=0.0001
[2025-05-06 14:26:49,059][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=4.9047, lr=0.0001
[2025-05-06 14:27:10,521][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6204, lr=0.0001
[2025-05-06 14:27:33,386][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.7948, lr=0.0001
[2025-05-06 14:27:54,703][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=4.9698, lr=0.0001
[2025-05-06 14:28:16,073][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=4.9169, lr=0.0001
[2025-05-06 14:28:37,466][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=5.2167, lr=0.0001
[2025-05-06 14:28:58,547][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=5.3373, lr=0.0001
[2025-05-06 14:28:58,571][meta_train][INFO] - epoch_34 saved !
[2025-05-06 14:29:19,951][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=5.1749, lr=0.0001
[2025-05-06 14:29:42,870][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.7952, lr=0.0001
[2025-05-06 14:30:04,285][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=4.8885, lr=0.0001
[2025-05-06 14:30:25,170][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=5.1193, lr=0.0001
[2025-05-06 14:30:46,274][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=4.9512, lr=0.0001
[2025-05-06 14:31:07,554][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6186, lr=0.0001
[2025-05-06 14:31:28,154][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.7388, lr=0.0001
[2025-05-06 14:31:49,751][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=4.8536, lr=0.0001
[2025-05-06 14:31:49,782][meta_train][INFO] - epoch_35 saved !
[2025-05-06 14:32:10,488][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.7211, lr=0.0001
[2025-05-06 14:32:32,100][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=4.8739, lr=0.0001
[2025-05-06 14:32:52,773][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=5.1227, lr=0.0001
[2025-05-06 14:33:13,830][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=4.8573, lr=0.0001
[2025-05-06 14:33:34,892][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6180, lr=0.0001
[2025-05-06 14:33:55,994][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=5.0247, lr=0.0001
[2025-05-06 14:34:16,806][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=4.9191, lr=0.0001
[2025-05-06 14:34:40,210][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.8043, lr=0.0001
[2025-05-06 14:34:40,237][meta_train][INFO] - epoch_36 saved !
[2025-05-06 14:35:00,933][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=4.9248, lr=0.0001
[2025-05-06 14:35:21,394][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6728, lr=0.0001
[2025-05-06 14:35:42,679][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6187, lr=0.0001
[2025-05-06 14:36:03,749][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=5.1023, lr=0.0001
[2025-05-06 14:36:26,211][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.8098, lr=0.0001
[2025-05-06 14:36:47,231][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=4.8987, lr=0.0001
[2025-05-06 14:37:08,677][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=4.8255, lr=0.0001
[2025-05-06 14:37:30,293][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=4.8538, lr=0.0001
[2025-05-06 14:37:30,318][meta_train][INFO] - epoch_37 saved !
[2025-05-06 14:37:51,372][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=4.8245, lr=0.0001
[2025-05-06 14:38:14,262][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.8066, lr=0.0001
[2025-05-06 14:38:34,797][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6799, lr=0.0001
[2025-05-06 14:38:56,086][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=4.9431, lr=0.0001
[2025-05-06 14:39:16,898][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=4.8517, lr=0.0001
[2025-05-06 14:39:38,593][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=5.0737, lr=0.0001
[2025-05-06 14:39:59,417][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=4.8539, lr=0.0001
[2025-05-06 14:40:20,328][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6173, lr=0.0001
[2025-05-06 14:40:20,353][meta_train][INFO] - epoch_38 saved !
[2025-05-06 14:40:41,337][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=4.9024, lr=0.0001
[2025-05-06 14:41:02,882][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6174, lr=0.0001
[2025-05-06 14:41:24,226][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=4.7996, lr=0.0001
[2025-05-06 14:41:45,195][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=4.8682, lr=0.0001
[2025-05-06 14:42:07,516][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.7779, lr=0.0001
[2025-05-06 14:42:28,090][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6945, lr=0.0001
[2025-05-06 14:42:49,211][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=5.0231, lr=0.0001
[2025-05-06 14:44:06,046][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: meta_train
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: train

[2025-05-06 14:44:06,095][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 14:44:06,095][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 14:44:06,095][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 14:44:31,051][meta_train][INFO] - Epoch 1/100, iter 1/8, train loss=0.7221, lr=0.001
[2025-05-06 14:44:52,324][meta_train][INFO] - Epoch 1/100, iter 2/8, train loss=0.0752, lr=0.001
[2025-05-06 14:45:13,302][meta_train][INFO] - Epoch 1/100, iter 3/8, train loss=6.7445, lr=0.001
[2025-05-06 14:45:34,283][meta_train][INFO] - Epoch 1/100, iter 4/8, train loss=5.4692, lr=0.001
[2025-05-06 14:45:55,776][meta_train][INFO] - Epoch 1/100, iter 5/8, train loss=0.1404, lr=0.001
[2025-05-06 14:46:17,365][meta_train][INFO] - Epoch 1/100, iter 6/8, train loss=0.0666, lr=0.001
[2025-05-06 14:46:40,202][meta_train][INFO] - Epoch 1/100, iter 7/8, train loss=0.1115, lr=0.001
[2025-05-06 14:47:01,287][meta_train][INFO] - Epoch 1/100, iter 8/8, train loss=0.1369, lr=0.001
[2025-05-06 14:47:01,319][meta_train][INFO] - epoch_1 saved !
[2025-05-06 14:47:22,319][meta_train][INFO] - Epoch 2/100, iter 1/8, train loss=0.3321, lr=0.001
[2025-05-06 14:47:43,560][meta_train][INFO] - Epoch 2/100, iter 2/8, train loss=0.7882, lr=0.001
[2025-05-06 14:48:04,915][meta_train][INFO] - Epoch 2/100, iter 3/8, train loss=1.2825, lr=0.001
[2025-05-06 14:48:25,936][meta_train][INFO] - Epoch 2/100, iter 4/8, train loss=0.8541, lr=0.001
[2025-05-06 14:48:46,715][meta_train][INFO] - Epoch 2/100, iter 5/8, train loss=1.2055, lr=0.001
[2025-05-06 14:49:07,341][meta_train][INFO] - Epoch 2/100, iter 6/8, train loss=1.2128, lr=0.001
[2025-05-06 14:49:30,636][meta_train][INFO] - Epoch 2/100, iter 7/8, train loss=1.7640, lr=0.001
[2025-05-06 14:49:52,345][meta_train][INFO] - Epoch 2/100, iter 8/8, train loss=2.5024, lr=0.001
[2025-05-06 14:49:52,371][meta_train][INFO] - epoch_2 saved !
[2025-05-06 14:50:13,126][meta_train][INFO] - Epoch 3/100, iter 1/8, train loss=1.9303, lr=0.001
[2025-05-06 14:50:34,430][meta_train][INFO] - Epoch 3/100, iter 2/8, train loss=3.2846, lr=0.001
[2025-05-06 14:50:55,532][meta_train][INFO] - Epoch 3/100, iter 3/8, train loss=5.8211, lr=0.001
[2025-05-06 14:51:16,314][meta_train][INFO] - Epoch 3/100, iter 4/8, train loss=7.7546, lr=0.001
[2025-05-06 14:51:37,130][meta_train][INFO] - Epoch 3/100, iter 5/8, train loss=4.9053, lr=0.001
[2025-05-06 14:51:58,764][meta_train][INFO] - Epoch 3/100, iter 6/8, train loss=7.3963, lr=0.001
[2025-05-06 14:52:19,935][meta_train][INFO] - Epoch 3/100, iter 7/8, train loss=5.4983, lr=0.001
[2025-05-06 14:52:42,921][meta_train][INFO] - Epoch 3/100, iter 8/8, train loss=6.8478, lr=0.001
[2025-05-06 14:52:42,945][meta_train][INFO] - epoch_3 saved !
[2025-05-06 14:53:04,219][meta_train][INFO] - Epoch 4/100, iter 1/8, train loss=8.7966, lr=0.001
[2025-05-06 14:53:25,954][meta_train][INFO] - Epoch 4/100, iter 2/8, train loss=5.9952, lr=0.001
[2025-05-06 14:53:47,289][meta_train][INFO] - Epoch 4/100, iter 3/8, train loss=7.6472, lr=0.001
[2025-05-06 14:54:10,425][meta_train][INFO] - Epoch 4/100, iter 4/8, train loss=6.3559, lr=0.001
[2025-05-06 14:54:31,587][meta_train][INFO] - Epoch 4/100, iter 5/8, train loss=6.6162, lr=0.001
[2025-05-06 14:54:52,612][meta_train][INFO] - Epoch 4/100, iter 6/8, train loss=5.3872, lr=0.001
[2025-05-06 14:55:13,368][meta_train][INFO] - Epoch 4/100, iter 7/8, train loss=5.6639, lr=0.001
[2025-05-06 14:55:34,806][meta_train][INFO] - Epoch 4/100, iter 8/8, train loss=9.3651, lr=0.001
[2025-05-06 14:55:34,830][meta_train][INFO] - epoch_4 saved !
[2025-05-06 14:55:55,996][meta_train][INFO] - Epoch 5/100, iter 1/8, train loss=7.8716, lr=0.001
[2025-05-06 14:56:16,758][meta_train][INFO] - Epoch 5/100, iter 2/8, train loss=7.3455, lr=0.001
[2025-05-06 14:56:37,975][meta_train][INFO] - Epoch 5/100, iter 3/8, train loss=6.4451, lr=0.001
[2025-05-06 14:56:58,970][meta_train][INFO] - Epoch 5/100, iter 4/8, train loss=10.3915, lr=0.001
[2025-05-06 14:57:19,722][meta_train][INFO] - Epoch 5/100, iter 5/8, train loss=5.1769, lr=0.001
[2025-05-06 14:57:40,564][meta_train][INFO] - Epoch 5/100, iter 6/8, train loss=9.4011, lr=0.001
[2025-05-06 14:58:01,349][meta_train][INFO] - Epoch 5/100, iter 7/8, train loss=5.0879, lr=0.001
[2025-05-06 14:58:25,096][meta_train][INFO] - Epoch 5/100, iter 8/8, train loss=6.5669, lr=0.001
[2025-05-06 14:58:25,123][meta_train][INFO] - epoch_5 saved !
[2025-05-06 14:58:45,978][meta_train][INFO] - Epoch 6/100, iter 1/8, train loss=5.0680, lr=0.0001
[2025-05-06 14:59:06,783][meta_train][INFO] - Epoch 6/100, iter 2/8, train loss=7.5887, lr=0.0001
[2025-05-06 14:59:27,030][meta_train][INFO] - Epoch 6/100, iter 3/8, train loss=5.0366, lr=0.0001
[2025-05-06 14:59:48,162][meta_train][INFO] - Epoch 6/100, iter 4/8, train loss=7.6784, lr=0.0001
[2025-05-06 15:00:09,298][meta_train][INFO] - Epoch 6/100, iter 5/8, train loss=10.3719, lr=0.0001
[2025-05-06 15:00:30,329][meta_train][INFO] - Epoch 6/100, iter 6/8, train loss=6.5657, lr=0.0001
[2025-05-06 15:00:53,756][meta_train][INFO] - Epoch 6/100, iter 7/8, train loss=6.3923, lr=0.0001
[2025-05-06 15:01:14,851][meta_train][INFO] - Epoch 6/100, iter 8/8, train loss=9.0968, lr=0.0001
[2025-05-06 15:01:14,876][meta_train][INFO] - epoch_6 saved !
[2025-05-06 15:01:36,256][meta_train][INFO] - Epoch 7/100, iter 1/8, train loss=7.6051, lr=0.0001
[2025-05-06 15:01:57,218][meta_train][INFO] - Epoch 7/100, iter 2/8, train loss=5.0477, lr=0.0001
[2025-05-06 15:02:18,894][meta_train][INFO] - Epoch 7/100, iter 3/8, train loss=9.0360, lr=0.0001
[2025-05-06 15:02:39,752][meta_train][INFO] - Epoch 7/100, iter 4/8, train loss=5.0088, lr=0.0001
[2025-05-06 15:03:02,986][meta_train][INFO] - Epoch 7/100, iter 5/8, train loss=6.3281, lr=0.0001
[2025-05-06 15:03:23,988][meta_train][INFO] - Epoch 7/100, iter 6/8, train loss=7.5683, lr=0.0001
[2025-05-06 15:03:44,855][meta_train][INFO] - Epoch 7/100, iter 7/8, train loss=10.1817, lr=0.0001
[2025-05-06 15:04:05,826][meta_train][INFO] - Epoch 7/100, iter 8/8, train loss=6.5370, lr=0.0001
[2025-05-06 15:04:05,851][meta_train][INFO] - epoch_7 saved !
[2025-05-06 15:04:26,630][meta_train][INFO] - Epoch 8/100, iter 1/8, train loss=10.1562, lr=0.0001
[2025-05-06 15:04:48,199][meta_train][INFO] - Epoch 8/100, iter 2/8, train loss=6.5336, lr=0.0001
[2025-05-06 15:05:11,239][meta_train][INFO] - Epoch 8/100, iter 3/8, train loss=6.3119, lr=0.0001
[2025-05-06 15:05:32,610][meta_train][INFO] - Epoch 8/100, iter 4/8, train loss=7.5169, lr=0.0001
[2025-05-06 15:05:53,377][meta_train][INFO] - Epoch 8/100, iter 5/8, train loss=8.9262, lr=0.0001
[2025-05-06 15:06:14,672][meta_train][INFO] - Epoch 8/100, iter 6/8, train loss=7.5429, lr=0.0001
[2025-05-06 15:06:35,333][meta_train][INFO] - Epoch 8/100, iter 7/8, train loss=4.9924, lr=0.0001
[2025-05-06 15:06:56,379][meta_train][INFO] - Epoch 8/100, iter 8/8, train loss=5.0177, lr=0.0001
[2025-05-06 15:06:56,404][meta_train][INFO] - epoch_8 saved !
[2025-05-06 15:07:16,939][meta_train][INFO] - Epoch 9/100, iter 1/8, train loss=7.5362, lr=0.0001
[2025-05-06 15:07:38,019][meta_train][INFO] - Epoch 9/100, iter 2/8, train loss=10.0459, lr=0.0001
[2025-05-06 15:07:59,720][meta_train][INFO] - Epoch 9/100, iter 3/8, train loss=8.8270, lr=0.0001
[2025-05-06 15:08:20,136][meta_train][INFO] - Epoch 9/100, iter 4/8, train loss=4.9866, lr=0.0001
[2025-05-06 15:08:41,328][meta_train][INFO] - Epoch 9/100, iter 5/8, train loss=7.4146, lr=0.0001
[2025-05-06 15:09:02,571][meta_train][INFO] - Epoch 9/100, iter 6/8, train loss=5.0060, lr=0.0001
[2025-05-06 15:09:23,503][meta_train][INFO] - Epoch 9/100, iter 7/8, train loss=6.4669, lr=0.0001
[2025-05-06 15:09:46,255][meta_train][INFO] - Epoch 9/100, iter 8/8, train loss=6.1841, lr=0.0001
[2025-05-06 15:09:46,292][meta_train][INFO] - epoch_9 saved !
[2025-05-06 15:10:06,927][meta_train][INFO] - Epoch 10/100, iter 1/8, train loss=7.4674, lr=0.0001
[2025-05-06 15:10:28,969][meta_train][INFO] - Epoch 10/100, iter 2/8, train loss=8.7134, lr=0.0001
[2025-05-06 15:10:51,686][meta_train][INFO] - Epoch 10/100, iter 3/8, train loss=6.1268, lr=0.0001
[2025-05-06 15:11:13,015][meta_train][INFO] - Epoch 10/100, iter 4/8, train loss=4.9816, lr=0.0001
[2025-05-06 15:11:34,149][meta_train][INFO] - Epoch 10/100, iter 5/8, train loss=9.7730, lr=0.0001
[2025-05-06 15:11:54,866][meta_train][INFO] - Epoch 10/100, iter 6/8, train loss=4.9637, lr=0.0001
[2025-05-06 15:12:16,242][meta_train][INFO] - Epoch 10/100, iter 7/8, train loss=6.4156, lr=0.0001
[2025-05-06 15:12:37,442][meta_train][INFO] - Epoch 10/100, iter 8/8, train loss=7.2680, lr=0.0001
[2025-05-06 15:12:37,468][meta_train][INFO] - epoch_10 saved !
[2025-05-06 15:12:58,501][meta_train][INFO] - Epoch 11/100, iter 1/8, train loss=9.7159, lr=0.0001
[2025-05-06 15:13:19,805][meta_train][INFO] - Epoch 11/100, iter 2/8, train loss=7.2473, lr=0.0001
[2025-05-06 15:13:40,489][meta_train][INFO] - Epoch 11/100, iter 3/8, train loss=8.5673, lr=0.0001
[2025-05-06 15:14:01,563][meta_train][INFO] - Epoch 11/100, iter 4/8, train loss=6.3830, lr=0.0001
[2025-05-06 15:14:23,044][meta_train][INFO] - Epoch 11/100, iter 5/8, train loss=4.9556, lr=0.0001
[2025-05-06 15:14:43,838][meta_train][INFO] - Epoch 11/100, iter 6/8, train loss=4.9540, lr=0.0001
[2025-05-06 15:15:06,826][meta_train][INFO] - Epoch 11/100, iter 7/8, train loss=6.0059, lr=0.0001
[2025-05-06 15:15:27,947][meta_train][INFO] - Epoch 11/100, iter 8/8, train loss=7.3139, lr=0.0001
[2025-05-06 15:15:27,972][meta_train][INFO] - epoch_11 saved !
[2025-05-06 15:15:48,682][meta_train][INFO] - Epoch 12/100, iter 1/8, train loss=9.5169, lr=0.0001
[2025-05-06 15:16:10,363][meta_train][INFO] - Epoch 12/100, iter 2/8, train loss=8.4454, lr=0.0001
[2025-05-06 15:16:31,890][meta_train][INFO] - Epoch 12/100, iter 3/8, train loss=6.3170, lr=0.0001
[2025-05-06 15:16:53,292][meta_train][INFO] - Epoch 12/100, iter 4/8, train loss=7.0891, lr=0.0001
[2025-05-06 15:17:14,175][meta_train][INFO] - Epoch 12/100, iter 5/8, train loss=4.9394, lr=0.0001
[2025-05-06 15:17:37,465][meta_train][INFO] - Epoch 12/100, iter 6/8, train loss=5.9288, lr=0.0001
[2025-05-06 15:17:58,170][meta_train][INFO] - Epoch 12/100, iter 7/8, train loss=4.9223, lr=0.0001
[2025-05-06 15:18:18,950][meta_train][INFO] - Epoch 12/100, iter 8/8, train loss=7.2139, lr=0.0001
[2025-05-06 15:18:18,978][meta_train][INFO] - epoch_12 saved !
[2025-05-06 15:18:40,297][meta_train][INFO] - Epoch 13/100, iter 1/8, train loss=9.3009, lr=0.0001
[2025-05-06 15:19:00,866][meta_train][INFO] - Epoch 13/100, iter 2/8, train loss=4.9150, lr=0.0001
[2025-05-06 15:19:22,170][meta_train][INFO] - Epoch 13/100, iter 3/8, train loss=7.1874, lr=0.0001
[2025-05-06 15:19:44,951][meta_train][INFO] - Epoch 13/100, iter 4/8, train loss=5.8780, lr=0.0001
[2025-05-06 15:20:06,244][meta_train][INFO] - Epoch 13/100, iter 5/8, train loss=6.9721, lr=0.0001
[2025-05-06 15:20:27,978][meta_train][INFO] - Epoch 13/100, iter 6/8, train loss=6.2271, lr=0.0001
[2025-05-06 15:20:48,582][meta_train][INFO] - Epoch 13/100, iter 7/8, train loss=4.9159, lr=0.0001
[2025-05-06 15:21:10,271][meta_train][INFO] - Epoch 13/100, iter 8/8, train loss=8.1779, lr=0.0001
[2025-05-06 15:21:10,297][meta_train][INFO] - epoch_13 saved !
[2025-05-06 15:21:31,480][meta_train][INFO] - Epoch 14/100, iter 1/8, train loss=7.0901, lr=0.0001
[2025-05-06 15:21:54,476][meta_train][INFO] - Epoch 14/100, iter 2/8, train loss=5.7884, lr=0.0001
[2025-05-06 15:22:15,664][meta_train][INFO] - Epoch 14/100, iter 3/8, train loss=6.8634, lr=0.0001
[2025-05-06 15:22:36,585][meta_train][INFO] - Epoch 14/100, iter 4/8, train loss=4.8975, lr=0.0001
[2025-05-06 15:22:57,875][meta_train][INFO] - Epoch 14/100, iter 5/8, train loss=4.8728, lr=0.0001
[2025-05-06 15:23:19,582][meta_train][INFO] - Epoch 14/100, iter 6/8, train loss=6.1539, lr=0.0001
[2025-05-06 15:23:39,751][meta_train][INFO] - Epoch 14/100, iter 7/8, train loss=8.9873, lr=0.0001
[2025-05-06 15:24:01,548][meta_train][INFO] - Epoch 14/100, iter 8/8, train loss=8.0495, lr=0.0001
[2025-05-06 15:24:01,573][meta_train][INFO] - epoch_14 saved !
[2025-05-06 15:24:22,645][meta_train][INFO] - Epoch 15/100, iter 1/8, train loss=4.8641, lr=0.0001
[2025-05-06 15:24:42,998][meta_train][INFO] - Epoch 15/100, iter 2/8, train loss=4.8871, lr=0.0001
[2025-05-06 15:25:04,036][meta_train][INFO] - Epoch 15/100, iter 3/8, train loss=8.8924, lr=0.0001
[2025-05-06 15:25:25,301][meta_train][INFO] - Epoch 15/100, iter 4/8, train loss=6.7579, lr=0.0001
[2025-05-06 15:25:46,151][meta_train][INFO] - Epoch 15/100, iter 5/8, train loss=6.1034, lr=0.0001
[2025-05-06 15:26:09,060][meta_train][INFO] - Epoch 15/100, iter 6/8, train loss=5.6499, lr=0.0001
[2025-05-06 15:26:30,516][meta_train][INFO] - Epoch 15/100, iter 7/8, train loss=6.9084, lr=0.0001
[2025-05-06 15:26:51,745][meta_train][INFO] - Epoch 15/100, iter 8/8, train loss=7.8746, lr=0.0001
[2025-05-06 15:26:51,771][meta_train][INFO] - epoch_15 saved !
[2025-05-06 15:27:12,358][meta_train][INFO] - Epoch 16/100, iter 1/8, train loss=4.8372, lr=0.0001
[2025-05-06 15:27:35,390][meta_train][INFO] - Epoch 16/100, iter 2/8, train loss=5.5968, lr=0.0001
[2025-05-06 15:27:56,566][meta_train][INFO] - Epoch 16/100, iter 3/8, train loss=6.8493, lr=0.0001
[2025-05-06 15:28:18,066][meta_train][INFO] - Epoch 16/100, iter 4/8, train loss=7.8104, lr=0.0001
[2025-05-06 15:28:39,046][meta_train][INFO] - Epoch 16/100, iter 5/8, train loss=8.5983, lr=0.0001
[2025-05-06 15:29:00,000][meta_train][INFO] - Epoch 16/100, iter 6/8, train loss=6.5826, lr=0.0001
[2025-05-06 15:29:21,251][meta_train][INFO] - Epoch 16/100, iter 7/8, train loss=5.9966, lr=0.0001
[2025-05-06 15:29:41,514][meta_train][INFO] - Epoch 16/100, iter 8/8, train loss=4.8342, lr=0.0001
[2025-05-06 15:29:41,538][meta_train][INFO] - epoch_16 saved !
[2025-05-06 15:30:02,044][meta_train][INFO] - Epoch 17/100, iter 1/8, train loss=4.8100, lr=0.0001
[2025-05-06 15:30:23,304][meta_train][INFO] - Epoch 17/100, iter 2/8, train loss=6.5158, lr=0.0001
[2025-05-06 15:30:44,060][meta_train][INFO] - Epoch 17/100, iter 3/8, train loss=4.8322, lr=0.0001
[2025-05-06 15:31:04,687][meta_train][INFO] - Epoch 17/100, iter 4/8, train loss=8.4102, lr=0.0001
[2025-05-06 15:31:25,432][meta_train][INFO] - Epoch 17/100, iter 5/8, train loss=5.9474, lr=0.0001
[2025-05-06 15:31:49,043][meta_train][INFO] - Epoch 17/100, iter 6/8, train loss=5.4362, lr=0.0001
[2025-05-06 15:32:09,300][meta_train][INFO] - Epoch 17/100, iter 7/8, train loss=6.6549, lr=0.0001
[2025-05-06 15:32:31,005][meta_train][INFO] - Epoch 17/100, iter 8/8, train loss=7.5244, lr=0.0001
[2025-05-06 15:32:31,055][meta_train][INFO] - epoch_17 saved !
[2025-05-06 15:32:51,957][meta_train][INFO] - Epoch 18/100, iter 1/8, train loss=7.4881, lr=0.0001
[2025-05-06 15:33:13,359][meta_train][INFO] - Epoch 18/100, iter 2/8, train loss=6.3448, lr=0.0001
[2025-05-06 15:33:36,842][meta_train][INFO] - Epoch 18/100, iter 3/8, train loss=5.3021, lr=0.0001
[2025-05-06 15:33:58,132][meta_train][INFO] - Epoch 18/100, iter 4/8, train loss=4.7771, lr=0.0001
[2025-05-06 15:34:19,451][meta_train][INFO] - Epoch 18/100, iter 5/8, train loss=6.5218, lr=0.0001
[2025-05-06 15:34:39,831][meta_train][INFO] - Epoch 18/100, iter 6/8, train loss=4.7952, lr=0.0001
[2025-05-06 15:35:01,751][meta_train][INFO] - Epoch 18/100, iter 7/8, train loss=5.8329, lr=0.0001
[2025-05-06 15:35:22,867][meta_train][INFO] - Epoch 18/100, iter 8/8, train loss=8.0023, lr=0.0001
[2025-05-06 15:35:22,895][meta_train][INFO] - epoch_18 saved !
[2025-05-06 15:35:34,934][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 10

[2025-05-06 15:35:34,984][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 15:35:34,984][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 15:35:34,984][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 15:35:44,017][meta_train][INFO] - Epoch 19/100, iter 1/8, train loss=7.3330, lr=0.0001
[2025-05-06 15:35:45,592][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 15

[2025-05-06 15:35:45,678][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 15:35:45,678][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 15:35:45,679][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 15:35:47,076][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 15:35:54,929][train][INFO] - Epoch 1/100, Val Acc=0.5396, Val Loss=1.8553, lr=0.0100
[2025-05-06 15:35:58,077][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 15:36:02,215][train][INFO] - Epoch 2/100, Val Acc=0.5688, Val Loss=1.7753, lr=0.0100
[2025-05-06 15:36:05,823][meta_train][INFO] - Epoch 19/100, iter 2/8, train loss=4.7625, lr=0.0001
[2025-05-06 15:36:06,201][train][INFO] - Epoch 1/100, Val Acc=0.4700, Val Loss=2.1928, lr=0.0100
[2025-05-06 15:36:09,859][train][INFO] - Epoch 3/100, Val Acc=0.5786, Val Loss=1.7301, lr=0.0100
[2025-05-06 15:36:13,807][train][INFO] - Epoch 2/100, Val Acc=0.5556, Val Loss=1.7498, lr=0.0100
[2025-05-06 15:36:17,622][train][INFO] - Epoch 4/100, Val Acc=0.6056, Val Loss=1.6524, lr=0.0100
[2025-05-06 15:36:20,764][train][INFO] - Epoch 3/100, Val Acc=0.5600, Val Loss=1.7897, lr=0.0100
[2025-05-06 15:36:25,584][train][INFO] - Epoch 5/100, Val Acc=0.6255, Val Loss=1.5656, lr=0.0100
[2025-05-06 15:36:27,534][meta_train][INFO] - Epoch 19/100, iter 3/8, train loss=7.8656, lr=0.0001
[2025-05-06 15:36:27,730][train][INFO] - Epoch 4/100, Val Acc=0.5898, Val Loss=1.6598, lr=0.0100
[2025-05-06 15:36:33,152][train][INFO] - Epoch 6/100, Val Acc=0.6129, Val Loss=1.6365, lr=0.0100
[2025-05-06 15:36:35,368][train][INFO] - Epoch 5/100, Val Acc=0.6124, Val Loss=1.6065, lr=0.0100
[2025-05-06 15:36:41,048][train][INFO] - Epoch 7/100, Val Acc=0.6157, Val Loss=1.6354, lr=0.0100
[2025-05-06 15:36:43,527][train][INFO] - Epoch 6/100, Val Acc=0.5757, Val Loss=1.7904, lr=0.0100
[2025-05-06 15:36:48,670][train][INFO] - Epoch 8/100, Val Acc=0.6210, Val Loss=1.5929, lr=0.0100
[2025-05-06 15:36:49,601][meta_train][INFO] - Epoch 19/100, iter 4/8, train loss=4.7676, lr=0.0001
[2025-05-06 15:36:50,665][train][INFO] - Epoch 7/100, Val Acc=0.6106, Val Loss=1.6409, lr=0.0100
[2025-05-06 15:36:56,518][train][INFO] - Epoch 9/100, Val Acc=0.6244, Val Loss=1.6202, lr=0.0100
[2025-05-06 15:36:58,101][train][INFO] - Epoch 8/100, Val Acc=0.6236, Val Loss=1.6313, lr=0.0100
[2025-05-06 15:37:04,382][train][INFO] - Epoch 10/100, Val Acc=0.6247, Val Loss=1.6052, lr=0.0100
[2025-05-06 15:37:05,595][train][INFO] - Epoch 9/100, Val Acc=0.6219, Val Loss=1.6026, lr=0.0100
[2025-05-06 15:37:11,599][meta_train][INFO] - Epoch 19/100, iter 5/8, train loss=6.1683, lr=0.0001
[2025-05-06 15:37:12,144][train][INFO] - Epoch 11/100, Val Acc=0.6401, Val Loss=1.5559, lr=0.0100
[2025-05-06 15:37:13,315][train][INFO] - Epoch 10/100, Val Acc=0.6181, Val Loss=1.6748, lr=0.0100
[2025-05-06 15:37:20,070][train][INFO] - Epoch 12/100, Val Acc=0.6434, Val Loss=1.5117, lr=0.0100
[2025-05-06 15:37:21,062][train][INFO] - Epoch 11/100, Val Acc=0.6244, Val Loss=1.5803, lr=0.0100
[2025-05-06 15:37:28,113][train][INFO] - Epoch 13/100, Val Acc=0.6165, Val Loss=1.7496, lr=0.0100
[2025-05-06 15:37:28,839][train][INFO] - Epoch 12/100, Val Acc=0.6351, Val Loss=1.5751, lr=0.0100
[2025-05-06 15:37:33,674][meta_train][INFO] - Epoch 19/100, iter 6/8, train loss=6.3714, lr=0.0001
[2025-05-06 15:37:36,404][train][INFO] - Epoch 13/100, Val Acc=0.6353, Val Loss=1.5797, lr=0.0100
[2025-05-06 15:37:36,407][train][INFO] - Epoch 14/100, Val Acc=0.6385, Val Loss=1.5739, lr=0.0100
[2025-05-06 15:37:44,201][train][INFO] - Epoch 14/100, Val Acc=0.6205, Val Loss=1.6260, lr=0.0100
[2025-05-06 15:37:44,252][train][INFO] - Epoch 15/100, Val Acc=0.6389, Val Loss=1.6217, lr=0.0100
[2025-05-06 15:37:51,971][train][INFO] - Epoch 16/100, Val Acc=0.6383, Val Loss=1.5936, lr=0.0100
[2025-05-06 15:37:52,023][train][INFO] - Epoch 15/100, Val Acc=0.6425, Val Loss=1.5324, lr=0.0100
[2025-05-06 15:37:57,441][meta_train][INFO] - Epoch 19/100, iter 7/8, train loss=5.1701, lr=0.0001
[2025-05-06 15:37:59,665][train][INFO] - Epoch 17/100, Val Acc=0.6429, Val Loss=1.5705, lr=0.0100
[2025-05-06 15:37:59,845][train][INFO] - Epoch 16/100, Val Acc=0.6419, Val Loss=1.5753, lr=0.0100
[2025-05-06 15:38:07,005][train][INFO] - Epoch 18/100, Val Acc=0.6428, Val Loss=1.6142, lr=0.0100
[2025-05-06 15:38:07,677][train][INFO] - Epoch 17/100, Val Acc=0.6447, Val Loss=1.5696, lr=0.0100
[2025-05-06 15:38:14,201][train][INFO] - Epoch 19/100, Val Acc=0.6379, Val Loss=1.6430, lr=0.0100
[2025-05-06 15:38:15,143][train][INFO] - Epoch 18/100, Val Acc=0.6592, Val Loss=1.5045, lr=0.0100
[2025-05-06 15:38:19,836][meta_train][INFO] - Epoch 19/100, iter 8/8, train loss=5.7212, lr=0.0001
[2025-05-06 15:38:19,865][meta_train][INFO] - epoch_19 saved !
[2025-05-06 15:38:22,426][train][INFO] - Epoch 20/100, Val Acc=0.6339, Val Loss=1.6769, lr=0.0100
[2025-05-06 15:38:22,514][train][INFO] - Epoch 19/100, Val Acc=0.6394, Val Loss=1.6215, lr=0.0100
[2025-05-06 15:38:30,119][train][INFO] - Epoch 20/100, Val Acc=0.6541, Val Loss=1.5307, lr=0.0100
[2025-05-06 15:38:30,185][train][INFO] - Epoch 21/100, Val Acc=0.6474, Val Loss=1.5779, lr=0.0100
[2025-05-06 15:38:37,389][train][INFO] - Epoch 21/100, Val Acc=0.6352, Val Loss=1.6424, lr=0.0100
[2025-05-06 15:38:37,925][train][INFO] - Epoch 22/100, Val Acc=0.6407, Val Loss=1.6139, lr=0.0100
[2025-05-06 15:38:41,620][meta_train][INFO] - Epoch 20/100, iter 1/8, train loss=6.3053, lr=0.0001
[2025-05-06 15:38:44,788][train][INFO] - Epoch 22/100, Val Acc=0.6390, Val Loss=1.6643, lr=0.0100
[2025-05-06 15:38:46,019][train][INFO] - Epoch 23/100, Val Acc=0.6472, Val Loss=1.5565, lr=0.0100
[2025-05-06 15:38:52,240][train][INFO] - Epoch 23/100, Val Acc=0.6354, Val Loss=1.6417, lr=0.0100
[2025-05-06 15:38:53,181][train][INFO] - Epoch 24/100, Val Acc=0.6440, Val Loss=1.5887, lr=0.0100
[2025-05-06 15:38:59,571][train][INFO] - Epoch 24/100, Val Acc=0.6573, Val Loss=1.5459, lr=0.0100
[2025-05-06 15:39:01,208][train][INFO] - Epoch 25/100, Val Acc=0.6446, Val Loss=1.6559, lr=0.0100
[2025-05-06 15:39:03,511][meta_train][INFO] - Epoch 20/100, iter 2/8, train loss=5.6857, lr=0.0001
[2025-05-06 15:39:07,179][train][INFO] - Epoch 25/100, Val Acc=0.6363, Val Loss=1.6689, lr=0.0100
[2025-05-06 15:39:09,092][train][INFO] - Epoch 26/100, Val Acc=0.6269, Val Loss=1.7539, lr=0.0100
[2025-05-06 15:39:14,201][train][INFO] - Epoch 26/100, Val Acc=0.6432, Val Loss=1.6761, lr=0.0100
[2025-05-06 15:39:16,842][train][INFO] - Epoch 27/100, Val Acc=0.6345, Val Loss=1.6828, lr=0.0100
[2025-05-06 15:39:22,053][train][INFO] - Epoch 27/100, Val Acc=0.6404, Val Loss=1.6341, lr=0.0100
[2025-05-06 15:39:24,943][train][INFO] - Epoch 28/100, Val Acc=0.6619, Val Loss=1.5331, lr=0.0100
[2025-05-06 15:39:25,483][meta_train][INFO] - Epoch 20/100, iter 3/8, train loss=4.7410, lr=0.0001
[2025-05-06 15:39:29,726][train][INFO] - Epoch 28/100, Val Acc=0.6302, Val Loss=1.6989, lr=0.0100
[2025-05-06 15:39:32,633][train][INFO] - Epoch 29/100, Val Acc=0.6570, Val Loss=1.6051, lr=0.0100
[2025-05-06 15:39:37,012][train][INFO] - Epoch 29/100, Val Acc=0.6547, Val Loss=1.6057, lr=0.0100
[2025-05-06 15:39:40,971][train][INFO] - Epoch 30/100, Val Acc=0.6490, Val Loss=1.6312, lr=0.0100
[2025-05-06 15:39:44,096][train][INFO] - Epoch 30/100, Val Acc=0.6395, Val Loss=1.6258, lr=0.0100
[2025-05-06 15:39:47,546][meta_train][INFO] - Epoch 20/100, iter 4/8, train loss=7.0658, lr=0.0001
[2025-05-06 15:39:48,900][train][INFO] - Epoch 31/100, Val Acc=0.6451, Val Loss=1.6741, lr=0.0100
[2025-05-06 15:39:51,490][train][INFO] - Epoch 31/100, Val Acc=0.6527, Val Loss=1.6022, lr=0.0100
[2025-05-06 15:39:56,605][train][INFO] - Epoch 32/100, Val Acc=0.6298, Val Loss=1.7385, lr=0.0100
[2025-05-06 15:39:58,804][train][INFO] - Epoch 32/100, Val Acc=0.6389, Val Loss=1.6946, lr=0.0100
[2025-05-06 15:40:04,179][train][INFO] - Epoch 33/100, Val Acc=0.6580, Val Loss=1.5836, lr=0.0100
[2025-05-06 15:40:06,292][train][INFO] - Epoch 33/100, Val Acc=0.6441, Val Loss=1.6411, lr=0.0100
[2025-05-06 15:40:09,249][meta_train][INFO] - Epoch 20/100, iter 5/8, train loss=4.7530, lr=0.0001
[2025-05-06 15:40:11,716][train][INFO] - Epoch 34/100, Val Acc=0.6474, Val Loss=1.6565, lr=0.0100
[2025-05-06 15:40:13,837][train][INFO] - Epoch 34/100, Val Acc=0.6481, Val Loss=1.6248, lr=0.0100
[2025-05-06 15:40:19,822][train][INFO] - Epoch 35/100, Val Acc=0.6546, Val Loss=1.6051, lr=0.0100
[2025-05-06 15:40:21,067][train][INFO] - Epoch 35/100, Val Acc=0.6478, Val Loss=1.6738, lr=0.0100
[2025-05-06 15:40:27,969][train][INFO] - Epoch 36/100, Val Acc=0.6529, Val Loss=1.6355, lr=0.0100
[2025-05-06 15:40:28,571][train][INFO] - Epoch 36/100, Val Acc=0.6492, Val Loss=1.6688, lr=0.0100
[2025-05-06 15:40:31,595][meta_train][INFO] - Epoch 20/100, iter 6/8, train loss=6.0457, lr=0.0001
[2025-05-06 15:40:35,374][train][INFO] - Epoch 37/100, Val Acc=0.6390, Val Loss=1.6992, lr=0.0100
[2025-05-06 15:40:36,161][train][INFO] - Epoch 37/100, Val Acc=0.6465, Val Loss=1.6501, lr=0.0100
[2025-05-06 15:40:43,267][train][INFO] - Epoch 38/100, Val Acc=0.6513, Val Loss=1.6280, lr=0.0100
[2025-05-06 15:40:44,098][train][INFO] - Epoch 38/100, Val Acc=0.6402, Val Loss=1.7213, lr=0.0100
[2025-05-06 15:40:51,465][train][INFO] - Epoch 39/100, Val Acc=0.6493, Val Loss=1.6523, lr=0.0100
[2025-05-06 15:40:51,691][train][INFO] - Epoch 39/100, Val Acc=0.6527, Val Loss=1.6049, lr=0.0100
[2025-05-06 15:40:53,347][meta_train][INFO] - Epoch 20/100, iter 7/8, train loss=7.5077, lr=0.0001
[2025-05-06 15:40:58,726][train][INFO] - Epoch 40/100, Val Acc=0.6567, Val Loss=1.5691, lr=0.0100
[2025-05-06 15:40:59,059][train][INFO] - Epoch 40/100, Val Acc=0.6435, Val Loss=1.6401, lr=0.0100
[2025-05-06 15:41:06,508][train][INFO] - Epoch 41/100, Val Acc=0.6604, Val Loss=1.6016, lr=0.0100
[2025-05-06 15:41:06,787][train][INFO] - Epoch 41/100, Val Acc=0.6404, Val Loss=1.7141, lr=0.0100
[2025-05-06 15:41:13,880][train][INFO] - Epoch 42/100, Val Acc=0.6385, Val Loss=1.7332, lr=0.0100
[2025-05-06 15:41:14,080][train][INFO] - Epoch 42/100, Val Acc=0.6439, Val Loss=1.6765, lr=0.0100
[2025-05-06 15:41:16,916][meta_train][INFO] - Epoch 20/100, iter 8/8, train loss=5.0552, lr=0.0001
[2025-05-06 15:41:16,955][meta_train][INFO] - epoch_20 saved !
[2025-05-06 15:41:21,422][train][INFO] - Epoch 43/100, Val Acc=0.6465, Val Loss=1.7121, lr=0.0100
[2025-05-06 15:41:21,769][train][INFO] - Epoch 43/100, Val Acc=0.6431, Val Loss=1.6606, lr=0.0100
[2025-05-06 15:41:29,089][train][INFO] - Epoch 44/100, Val Acc=0.6447, Val Loss=1.6553, lr=0.0100
[2025-05-06 15:41:29,766][train][INFO] - Epoch 44/100, Val Acc=0.6404, Val Loss=1.7164, lr=0.0100
[2025-05-06 15:41:36,281][train][INFO] - Epoch 45/100, Val Acc=0.6548, Val Loss=1.6057, lr=0.0100
[2025-05-06 15:41:37,757][train][INFO] - Epoch 45/100, Val Acc=0.6529, Val Loss=1.6596, lr=0.0100
[2025-05-06 15:41:39,039][meta_train][INFO] - Epoch 21/100, iter 1/8, train loss=7.4205, lr=0.0001
[2025-05-06 15:41:44,244][train][INFO] - Epoch 46/100, Val Acc=0.6428, Val Loss=1.7016, lr=0.0100
[2025-05-06 15:41:45,828][train][INFO] - Epoch 46/100, Val Acc=0.6592, Val Loss=1.6237, lr=0.0100
[2025-05-06 15:41:52,052][train][INFO] - Epoch 47/100, Val Acc=0.6478, Val Loss=1.6577, lr=0.0100
[2025-05-06 15:41:53,039][train][INFO] - Epoch 47/100, Val Acc=0.6472, Val Loss=1.6699, lr=0.0100
[2025-05-06 15:41:59,777][train][INFO] - Epoch 48/100, Val Acc=0.6469, Val Loss=1.6496, lr=0.0100
[2025-05-06 15:42:00,962][train][INFO] - Epoch 48/100, Val Acc=0.6397, Val Loss=1.7069, lr=0.0100
[2025-05-06 15:42:01,403][meta_train][INFO] - Epoch 21/100, iter 2/8, train loss=6.8925, lr=0.0001
[2025-05-06 15:42:07,109][train][INFO] - Epoch 49/100, Val Acc=0.6438, Val Loss=1.7206, lr=0.0100
[2025-05-06 15:42:08,945][train][INFO] - Epoch 49/100, Val Acc=0.6555, Val Loss=1.6542, lr=0.0100
[2025-05-06 15:42:14,383][train][INFO] - Epoch 50/100, Val Acc=0.6416, Val Loss=1.7157, lr=0.0100
[2025-05-06 15:42:16,570][train][INFO] - Epoch 50/100, Val Acc=0.6524, Val Loss=1.6389, lr=0.0100
[2025-05-06 15:42:22,045][train][INFO] - Epoch 51/100, Val Acc=0.6594, Val Loss=1.5880, lr=0.0100
[2025-05-06 15:42:23,466][meta_train][INFO] - Epoch 21/100, iter 3/8, train loss=5.5395, lr=0.0001
[2025-05-06 15:42:24,551][train][INFO] - Epoch 51/100, Val Acc=0.6683, Val Loss=1.5913, lr=0.0100
[2025-05-06 15:42:29,254][train][INFO] - Epoch 52/100, Val Acc=0.6367, Val Loss=1.6887, lr=0.0100
[2025-05-06 15:42:32,209][train][INFO] - Epoch 52/100, Val Acc=0.6503, Val Loss=1.6734, lr=0.0100
[2025-05-06 15:42:37,026][train][INFO] - Epoch 53/100, Val Acc=0.6477, Val Loss=1.6482, lr=0.0100
[2025-05-06 15:42:40,186][train][INFO] - Epoch 53/100, Val Acc=0.6552, Val Loss=1.6039, lr=0.0100
[2025-05-06 15:42:45,112][train][INFO] - Epoch 54/100, Val Acc=0.6220, Val Loss=1.8033, lr=0.0100
[2025-05-06 15:42:45,823][meta_train][INFO] - Epoch 21/100, iter 4/8, train loss=5.8951, lr=0.0001
[2025-05-06 15:42:48,085][train][INFO] - Epoch 54/100, Val Acc=0.6565, Val Loss=1.5953, lr=0.0100
[2025-05-06 15:42:52,921][train][INFO] - Epoch 55/100, Val Acc=0.6580, Val Loss=1.6279, lr=0.0100
[2025-05-06 15:42:55,788][train][INFO] - Epoch 55/100, Val Acc=0.6504, Val Loss=1.6609, lr=0.0100
[2025-05-06 15:43:00,134][train][INFO] - Epoch 56/100, Val Acc=0.6326, Val Loss=1.7548, lr=0.0100
[2025-05-06 15:43:03,921][train][INFO] - Epoch 56/100, Val Acc=0.6449, Val Loss=1.6749, lr=0.0100
[2025-05-06 15:43:07,764][meta_train][INFO] - Epoch 21/100, iter 5/8, train loss=6.0552, lr=0.0001
[2025-05-06 15:43:08,014][train][INFO] - Epoch 57/100, Val Acc=0.6585, Val Loss=1.5961, lr=0.0100
[2025-05-06 15:43:11,929][train][INFO] - Epoch 57/100, Val Acc=0.6520, Val Loss=1.6545, lr=0.0100
[2025-05-06 15:43:15,826][train][INFO] - Epoch 58/100, Val Acc=0.6555, Val Loss=1.6657, lr=0.0100
[2025-05-06 15:43:19,847][train][INFO] - Epoch 58/100, Val Acc=0.6518, Val Loss=1.6304, lr=0.0100
[2025-05-06 15:43:23,504][train][INFO] - Epoch 59/100, Val Acc=0.6507, Val Loss=1.6313, lr=0.0100
[2025-05-06 15:43:27,841][train][INFO] - Epoch 59/100, Val Acc=0.6451, Val Loss=1.6914, lr=0.0100
[2025-05-06 15:43:29,699][meta_train][INFO] - Epoch 21/100, iter 6/8, train loss=4.7291, lr=0.0001
[2025-05-06 15:43:31,361][train][INFO] - Epoch 60/100, Val Acc=0.6484, Val Loss=1.6766, lr=0.0100
[2025-05-06 15:43:36,178][train][INFO] - Epoch 60/100, Val Acc=0.6530, Val Loss=1.6272, lr=0.0100
[2025-05-06 15:43:39,413][train][INFO] - Epoch 61/100, Val Acc=0.7089, Val Loss=1.3458, lr=0.0010
[2025-05-06 15:43:43,623][train][INFO] - Epoch 61/100, Val Acc=0.7077, Val Loss=1.3556, lr=0.0010
[2025-05-06 15:43:47,071][train][INFO] - Epoch 62/100, Val Acc=0.7125, Val Loss=1.3291, lr=0.0010
[2025-05-06 15:43:51,481][train][INFO] - Epoch 62/100, Val Acc=0.7101, Val Loss=1.3526, lr=0.0010
[2025-05-06 15:43:51,706][meta_train][INFO] - Epoch 21/100, iter 7/8, train loss=4.7117, lr=0.0001
[2025-05-06 15:43:55,163][train][INFO] - Epoch 63/100, Val Acc=0.7164, Val Loss=1.3324, lr=0.0010
[2025-05-06 15:43:59,644][train][INFO] - Epoch 63/100, Val Acc=0.7129, Val Loss=1.3434, lr=0.0010
[2025-05-06 15:44:02,739][train][INFO] - Epoch 64/100, Val Acc=0.7144, Val Loss=1.3429, lr=0.0010
[2025-05-06 15:44:07,748][train][INFO] - Epoch 64/100, Val Acc=0.7111, Val Loss=1.3508, lr=0.0010
[2025-05-06 15:44:10,577][train][INFO] - Epoch 65/100, Val Acc=0.7179, Val Loss=1.3368, lr=0.0010
[2025-05-06 15:44:15,046][train][INFO] - Epoch 65/100, Val Acc=0.7141, Val Loss=1.3522, lr=0.0010
[2025-05-06 15:44:15,899][meta_train][INFO] - Epoch 21/100, iter 8/8, train loss=5.0004, lr=0.0001
[2025-05-06 15:44:15,936][meta_train][INFO] - epoch_21 saved !
[2025-05-06 15:44:18,455][train][INFO] - Epoch 66/100, Val Acc=0.7158, Val Loss=1.3447, lr=0.0010
[2025-05-06 15:44:23,055][train][INFO] - Epoch 66/100, Val Acc=0.7144, Val Loss=1.3610, lr=0.0010
[2025-05-06 15:44:25,924][train][INFO] - Epoch 67/100, Val Acc=0.7144, Val Loss=1.3463, lr=0.0010
[2025-05-06 15:44:30,424][train][INFO] - Epoch 67/100, Val Acc=0.7147, Val Loss=1.3616, lr=0.0010
[2025-05-06 15:44:34,029][train][INFO] - Epoch 68/100, Val Acc=0.7182, Val Loss=1.3369, lr=0.0010
[2025-05-06 15:44:37,959][train][INFO] - Epoch 68/100, Val Acc=0.7143, Val Loss=1.3603, lr=0.0010
[2025-05-06 15:44:39,616][meta_train][INFO] - Epoch 22/100, iter 1/8, train loss=4.9797, lr=0.0001
[2025-05-06 15:44:41,995][train][INFO] - Epoch 69/100, Val Acc=0.7211, Val Loss=1.3517, lr=0.0010
[2025-05-06 15:44:45,383][train][INFO] - Epoch 69/100, Val Acc=0.7128, Val Loss=1.3696, lr=0.0010
[2025-05-06 15:44:49,911][train][INFO] - Epoch 70/100, Val Acc=0.7179, Val Loss=1.3548, lr=0.0010
[2025-05-06 15:44:53,450][train][INFO] - Epoch 70/100, Val Acc=0.7152, Val Loss=1.3671, lr=0.0010
[2025-05-06 15:44:57,758][train][INFO] - Epoch 71/100, Val Acc=0.7185, Val Loss=1.3549, lr=0.0010
[2025-05-06 15:45:01,595][train][INFO] - Epoch 71/100, Val Acc=0.7147, Val Loss=1.3693, lr=0.0010
[2025-05-06 15:45:02,101][meta_train][INFO] - Epoch 22/100, iter 2/8, train loss=5.4787, lr=0.0001
[2025-05-06 15:45:05,379][train][INFO] - Epoch 72/100, Val Acc=0.7202, Val Loss=1.3655, lr=0.0010
[2025-05-06 15:45:08,774][train][INFO] - Epoch 72/100, Val Acc=0.7167, Val Loss=1.3747, lr=0.0010
[2025-05-06 15:45:12,921][train][INFO] - Epoch 73/100, Val Acc=0.7201, Val Loss=1.3644, lr=0.0010
[2025-05-06 15:45:16,631][train][INFO] - Epoch 73/100, Val Acc=0.7151, Val Loss=1.3769, lr=0.0010
[2025-05-06 15:45:20,632][train][INFO] - Epoch 74/100, Val Acc=0.7205, Val Loss=1.3635, lr=0.0010
[2025-05-06 15:45:24,056][meta_train][INFO] - Epoch 22/100, iter 3/8, train loss=4.7009, lr=0.0001
[2025-05-06 15:45:24,337][train][INFO] - Epoch 74/100, Val Acc=0.7170, Val Loss=1.3750, lr=0.0010
[2025-05-06 15:45:28,260][train][INFO] - Epoch 75/100, Val Acc=0.7218, Val Loss=1.3616, lr=0.0010
[2025-05-06 15:45:31,730][train][INFO] - Epoch 75/100, Val Acc=0.7201, Val Loss=1.3758, lr=0.0010
[2025-05-06 15:45:36,173][train][INFO] - Epoch 76/100, Val Acc=0.7195, Val Loss=1.3690, lr=0.0010
[2025-05-06 15:45:40,214][train][INFO] - Epoch 76/100, Val Acc=0.7177, Val Loss=1.3831, lr=0.0010
[2025-05-06 15:45:43,789][train][INFO] - Epoch 77/100, Val Acc=0.7220, Val Loss=1.3696, lr=0.0010
[2025-05-06 15:45:46,458][meta_train][INFO] - Epoch 22/100, iter 4/8, train loss=5.7828, lr=0.0001
[2025-05-06 15:45:48,641][train][INFO] - Epoch 77/100, Val Acc=0.7165, Val Loss=1.3859, lr=0.0010
[2025-05-06 15:45:51,374][train][INFO] - Epoch 78/100, Val Acc=0.7204, Val Loss=1.3762, lr=0.0010
[2025-05-06 15:45:56,852][train][INFO] - Epoch 78/100, Val Acc=0.7160, Val Loss=1.3898, lr=0.0010
[2025-05-06 15:45:59,407][train][INFO] - Epoch 79/100, Val Acc=0.7187, Val Loss=1.3721, lr=0.0010
[2025-05-06 15:46:04,481][train][INFO] - Epoch 79/100, Val Acc=0.7173, Val Loss=1.3933, lr=0.0010
[2025-05-06 15:46:07,298][train][INFO] - Epoch 80/100, Val Acc=0.7220, Val Loss=1.3766, lr=0.0010
[2025-05-06 15:46:08,553][meta_train][INFO] - Epoch 22/100, iter 5/8, train loss=4.7224, lr=0.0001
[2025-05-06 15:46:11,965][train][INFO] - Epoch 80/100, Val Acc=0.7184, Val Loss=1.3916, lr=0.0010
[2025-05-06 15:46:14,572][train][INFO] - Epoch 81/100, Val Acc=0.7210, Val Loss=1.3726, lr=0.0010
[2025-05-06 15:46:19,532][train][INFO] - Epoch 81/100, Val Acc=0.7174, Val Loss=1.3934, lr=0.0010
[2025-05-06 15:46:22,299][train][INFO] - Epoch 82/100, Val Acc=0.7209, Val Loss=1.3735, lr=0.0010
[2025-05-06 15:46:27,394][train][INFO] - Epoch 82/100, Val Acc=0.7183, Val Loss=1.3946, lr=0.0010
[2025-05-06 15:46:30,246][train][INFO] - Epoch 83/100, Val Acc=0.7203, Val Loss=1.3756, lr=0.0010
[2025-05-06 15:46:30,574][meta_train][INFO] - Epoch 22/100, iter 6/8, train loss=7.0976, lr=0.0001
[2025-05-06 15:46:34,934][train][INFO] - Epoch 83/100, Val Acc=0.7186, Val Loss=1.3970, lr=0.0010
[2025-05-06 15:46:38,261][train][INFO] - Epoch 84/100, Val Acc=0.7221, Val Loss=1.3796, lr=0.0010
[2025-05-06 15:46:43,285][train][INFO] - Epoch 84/100, Val Acc=0.7178, Val Loss=1.3962, lr=0.0010
[2025-05-06 15:46:46,015][train][INFO] - Epoch 85/100, Val Acc=0.7220, Val Loss=1.3784, lr=0.0010
[2025-05-06 15:46:51,606][train][INFO] - Epoch 85/100, Val Acc=0.7154, Val Loss=1.3986, lr=0.0010
[2025-05-06 15:46:52,448][meta_train][INFO] - Epoch 22/100, iter 7/8, train loss=6.7164, lr=0.0001
[2025-05-06 15:46:53,633][train][INFO] - Epoch 86/100, Val Acc=0.7216, Val Loss=1.3820, lr=0.0010
[2025-05-06 15:46:59,526][train][INFO] - Epoch 86/100, Val Acc=0.7185, Val Loss=1.3991, lr=0.0010
[2025-05-06 15:47:00,827][train][INFO] - Epoch 87/100, Val Acc=0.7198, Val Loss=1.3793, lr=0.0010
[2025-05-06 15:47:07,331][train][INFO] - Epoch 87/100, Val Acc=0.7193, Val Loss=1.3945, lr=0.0010
[2025-05-06 15:47:08,377][train][INFO] - Epoch 88/100, Val Acc=0.7217, Val Loss=1.3852, lr=0.0010
[2025-05-06 15:47:14,529][meta_train][INFO] - Epoch 22/100, iter 8/8, train loss=5.9746, lr=0.0001
[2025-05-06 15:47:14,567][meta_train][INFO] - epoch_22 saved !
[2025-05-06 15:47:15,326][train][INFO] - Epoch 88/100, Val Acc=0.7165, Val Loss=1.3967, lr=0.0010
[2025-05-06 15:47:15,664][train][INFO] - Epoch 89/100, Val Acc=0.7197, Val Loss=1.3851, lr=0.0010
[2025-05-06 15:47:22,891][train][INFO] - Epoch 90/100, Val Acc=0.7189, Val Loss=1.3906, lr=0.0010
[2025-05-06 15:47:23,765][train][INFO] - Epoch 89/100, Val Acc=0.7157, Val Loss=1.4041, lr=0.0010
[2025-05-06 15:47:31,012][train][INFO] - Epoch 91/100, Val Acc=0.7217, Val Loss=1.3826, lr=0.0001
[2025-05-06 15:47:32,099][train][INFO] - Epoch 90/100, Val Acc=0.7179, Val Loss=1.3979, lr=0.0010
[2025-05-06 15:47:36,742][meta_train][INFO] - Epoch 23/100, iter 1/8, train loss=5.7925, lr=0.0001
[2025-05-06 15:47:38,457][train][INFO] - Epoch 92/100, Val Acc=0.7197, Val Loss=1.3854, lr=0.0001
[2025-05-06 15:47:39,725][train][INFO] - Epoch 91/100, Val Acc=0.7178, Val Loss=1.3959, lr=0.0001
[2025-05-06 15:47:46,546][train][INFO] - Epoch 93/100, Val Acc=0.7222, Val Loss=1.3833, lr=0.0001
[2025-05-06 15:47:47,805][train][INFO] - Epoch 92/100, Val Acc=0.7165, Val Loss=1.3944, lr=0.0001
[2025-05-06 15:47:53,797][train][INFO] - Epoch 94/100, Val Acc=0.7222, Val Loss=1.3818, lr=0.0001
[2025-05-06 15:47:55,704][train][INFO] - Epoch 93/100, Val Acc=0.7198, Val Loss=1.3938, lr=0.0001
[2025-05-06 15:47:59,185][meta_train][INFO] - Epoch 23/100, iter 2/8, train loss=5.4487, lr=0.0001
[2025-05-06 15:48:01,530][train][INFO] - Epoch 95/100, Val Acc=0.7238, Val Loss=1.3815, lr=0.0001
[2025-05-06 15:48:03,582][train][INFO] - Epoch 94/100, Val Acc=0.7187, Val Loss=1.3938, lr=0.0001
[2025-05-06 15:48:09,543][train][INFO] - Epoch 96/100, Val Acc=0.7236, Val Loss=1.3822, lr=0.0001
[2025-05-06 15:48:10,839][train][INFO] - Epoch 95/100, Val Acc=0.7187, Val Loss=1.3931, lr=0.0001
[2025-05-06 15:48:17,398][train][INFO] - Epoch 97/100, Val Acc=0.7238, Val Loss=1.3822, lr=0.0001
[2025-05-06 15:48:18,797][train][INFO] - Epoch 96/100, Val Acc=0.7184, Val Loss=1.3886, lr=0.0001
[2025-05-06 15:48:20,871][meta_train][INFO] - Epoch 23/100, iter 3/8, train loss=5.8928, lr=0.0001
[2025-05-06 15:48:25,145][train][INFO] - Epoch 98/100, Val Acc=0.7224, Val Loss=1.3795, lr=0.0001
[2025-05-06 15:48:26,789][train][INFO] - Epoch 97/100, Val Acc=0.7191, Val Loss=1.3920, lr=0.0001
[2025-05-06 15:48:32,901][train][INFO] - Epoch 99/100, Val Acc=0.7234, Val Loss=1.3822, lr=0.0001
[2025-05-06 15:48:34,915][train][INFO] - Epoch 98/100, Val Acc=0.7193, Val Loss=1.3888, lr=0.0001
[2025-05-06 15:48:40,200][train][INFO] - Epoch 100/100, Val Acc=0.7224, Val Loss=1.3789, lr=0.0001
[2025-05-06 15:48:41,932][train][INFO] - Epoch 99/100, Val Acc=0.7190, Val Loss=1.3911, lr=0.0001
[2025-05-06 15:48:44,909][meta_train][INFO] - Epoch 23/100, iter 4/8, train loss=4.8686, lr=0.0001
[2025-05-06 15:48:45,088][train][INFO] - After training : Train Acc=0.9983  Val Acc=0.7238
[2025-05-06 15:48:45,100][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 15:48:49,920][train][INFO] - Epoch 100/100, Val Acc=0.7202, Val Loss=1.3910, lr=0.0001
[2025-05-06 15:48:54,906][train][INFO] - After training : Train Acc=0.9984  Val Acc=0.7202
[2025-05-06 15:48:54,919][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 15:49:06,699][meta_train][INFO] - Epoch 23/100, iter 5/8, train loss=4.7174, lr=0.0001
[2025-05-06 15:49:29,205][meta_train][INFO] - Epoch 23/100, iter 6/8, train loss=6.5505, lr=0.0001
[2025-05-06 15:49:50,059][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 15:49:51,741][meta_train][INFO] - Epoch 23/100, iter 7/8, train loss=4.6891, lr=0.0001
[2025-05-06 15:50:05,107][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 15:50:14,367][meta_train][INFO] - Epoch 23/100, iter 8/8, train loss=6.8934, lr=0.0001
[2025-05-06 15:50:14,423][meta_train][INFO] - epoch_23 saved !
[2025-05-06 15:50:37,197][meta_train][INFO] - Epoch 24/100, iter 1/8, train loss=4.6883, lr=0.0001
[2025-05-06 15:50:52,293][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 15:50:52,748][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 15:50:59,071][meta_train][INFO] - Epoch 24/100, iter 2/8, train loss=4.7201, lr=0.0001
[2025-05-06 15:51:15,195][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 15:51:15,642][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 15:51:22,724][meta_train][INFO] - Epoch 24/100, iter 3/8, train loss=4.8654, lr=0.0001
[2025-05-06 15:51:44,145][meta_train][INFO] - Epoch 24/100, iter 4/8, train loss=5.8170, lr=0.0001
[2025-05-06 15:52:05,874][meta_train][INFO] - Epoch 24/100, iter 5/8, train loss=6.4700, lr=0.0001
[2025-05-06 15:52:27,164][meta_train][INFO] - Epoch 24/100, iter 6/8, train loss=5.6315, lr=0.0001
[2025-05-06 15:52:48,348][meta_train][INFO] - Epoch 24/100, iter 7/8, train loss=6.7204, lr=0.0001
[2025-05-06 15:53:10,144][meta_train][INFO] - Epoch 24/100, iter 8/8, train loss=5.3505, lr=0.0001
[2025-05-06 15:53:10,198][meta_train][INFO] - epoch_24 saved !
[2025-05-06 15:53:31,723][meta_train][INFO] - Epoch 25/100, iter 1/8, train loss=4.6811, lr=0.0001
[2025-05-06 15:53:53,273][meta_train][INFO] - Epoch 25/100, iter 2/8, train loss=5.3509, lr=0.0001
[2025-05-06 15:54:14,354][meta_train][INFO] - Epoch 25/100, iter 3/8, train loss=6.6467, lr=0.0001
[2025-05-06 15:54:35,940][meta_train][INFO] - Epoch 25/100, iter 4/8, train loss=6.3741, lr=0.0001
[2025-05-06 15:54:57,143][meta_train][INFO] - Epoch 25/100, iter 5/8, train loss=4.7169, lr=0.0001
[2025-05-06 15:55:20,497][meta_train][INFO] - Epoch 25/100, iter 6/8, train loss=4.8031, lr=0.0001
[2025-05-06 15:55:41,695][meta_train][INFO] - Epoch 25/100, iter 7/8, train loss=5.5243, lr=0.0001
[2025-05-06 15:56:03,255][meta_train][INFO] - Epoch 25/100, iter 8/8, train loss=5.6575, lr=0.0001
[2025-05-06 15:56:03,293][meta_train][INFO] - epoch_25 saved !
[2025-05-06 15:56:24,156][meta_train][INFO] - Epoch 26/100, iter 1/8, train loss=4.7112, lr=0.0001
[2025-05-06 15:56:47,550][meta_train][INFO] - Epoch 26/100, iter 2/8, train loss=4.8040, lr=0.0001
[2025-05-06 15:57:08,769][meta_train][INFO] - Epoch 26/100, iter 3/8, train loss=6.4492, lr=0.0001
[2025-05-06 15:57:30,025][meta_train][INFO] - Epoch 26/100, iter 4/8, train loss=4.6694, lr=0.0001
[2025-05-06 15:57:51,765][meta_train][INFO] - Epoch 26/100, iter 5/8, train loss=6.2274, lr=0.0001
[2025-05-06 15:58:13,630][meta_train][INFO] - Epoch 26/100, iter 6/8, train loss=5.2575, lr=0.0001
[2025-05-06 15:58:34,665][meta_train][INFO] - Epoch 26/100, iter 7/8, train loss=5.6095, lr=0.0001
[2025-05-06 15:58:56,495][meta_train][INFO] - Epoch 26/100, iter 8/8, train loss=5.4561, lr=0.0001
[2025-05-06 15:58:56,529][meta_train][INFO] - epoch_26 saved !
[2025-05-06 15:59:18,270][meta_train][INFO] - Epoch 27/100, iter 1/8, train loss=5.4495, lr=0.0001
[2025-05-06 15:59:41,549][meta_train][INFO] - Epoch 27/100, iter 2/8, train loss=4.7748, lr=0.0001
[2025-05-06 16:00:03,529][meta_train][INFO] - Epoch 27/100, iter 3/8, train loss=6.1379, lr=0.0001
[2025-05-06 16:00:24,413][meta_train][INFO] - Epoch 27/100, iter 4/8, train loss=6.2287, lr=0.0001
[2025-05-06 16:00:45,449][meta_train][INFO] - Epoch 27/100, iter 5/8, train loss=4.7054, lr=0.0001
[2025-05-06 16:01:07,411][meta_train][INFO] - Epoch 27/100, iter 6/8, train loss=5.1716, lr=0.0001
[2025-05-06 16:01:28,457][meta_train][INFO] - Epoch 27/100, iter 7/8, train loss=5.4884, lr=0.0001
[2025-05-06 16:01:50,022][meta_train][INFO] - Epoch 27/100, iter 8/8, train loss=4.6550, lr=0.0001
[2025-05-06 16:01:50,064][meta_train][INFO] - epoch_27 saved !
[2025-05-06 16:02:13,589][meta_train][INFO] - Epoch 28/100, iter 1/8, train loss=4.7388, lr=0.0001
[2025-05-06 16:02:35,823][meta_train][INFO] - Epoch 28/100, iter 2/8, train loss=5.1666, lr=0.0001
[2025-05-06 16:02:57,205][meta_train][INFO] - Epoch 28/100, iter 3/8, train loss=6.1144, lr=0.0001
[2025-05-06 16:03:18,863][meta_train][INFO] - Epoch 28/100, iter 4/8, train loss=6.0044, lr=0.0001
[2025-05-06 16:03:40,331][meta_train][INFO] - Epoch 28/100, iter 5/8, train loss=5.3165, lr=0.0001
[2025-05-06 16:04:01,719][meta_train][INFO] - Epoch 28/100, iter 6/8, train loss=4.6497, lr=0.0001
[2025-05-06 16:04:23,406][meta_train][INFO] - Epoch 28/100, iter 7/8, train loss=5.4363, lr=0.0001
[2025-05-06 16:04:44,962][meta_train][INFO] - Epoch 28/100, iter 8/8, train loss=4.7089, lr=0.0001
[2025-05-06 16:04:44,987][meta_train][INFO] - epoch_28 saved !
[2025-05-06 16:05:07,074][meta_train][INFO] - Epoch 29/100, iter 1/8, train loss=5.9834, lr=0.0001
[2025-05-06 16:05:29,192][meta_train][INFO] - Epoch 29/100, iter 2/8, train loss=5.3283, lr=0.0001
[2025-05-06 16:05:50,029][meta_train][INFO] - Epoch 29/100, iter 3/8, train loss=5.9797, lr=0.0001
[2025-05-06 16:06:13,264][meta_train][INFO] - Epoch 29/100, iter 4/8, train loss=4.7144, lr=0.0001
[2025-05-06 16:06:35,292][meta_train][INFO] - Epoch 29/100, iter 5/8, train loss=5.1020, lr=0.0001
[2025-05-06 16:06:56,137][meta_train][INFO] - Epoch 29/100, iter 6/8, train loss=4.7001, lr=0.0001
[2025-05-06 16:07:17,420][meta_train][INFO] - Epoch 29/100, iter 7/8, train loss=5.3763, lr=0.0001
[2025-05-06 16:07:38,329][meta_train][INFO] - Epoch 29/100, iter 8/8, train loss=4.6474, lr=0.0001
[2025-05-06 16:07:38,355][meta_train][INFO] - epoch_29 saved !
[2025-05-06 16:08:01,497][meta_train][INFO] - Epoch 30/100, iter 1/8, train loss=4.7305, lr=0.0001
[2025-05-06 16:08:22,166][meta_train][INFO] - Epoch 30/100, iter 2/8, train loss=4.7069, lr=0.0001
[2025-05-06 16:08:43,754][meta_train][INFO] - Epoch 30/100, iter 3/8, train loss=5.1550, lr=0.0001
[2025-05-06 16:09:05,849][meta_train][INFO] - Epoch 30/100, iter 4/8, train loss=4.6509, lr=0.0001
[2025-05-06 16:09:27,204][meta_train][INFO] - Epoch 30/100, iter 5/8, train loss=5.4348, lr=0.0001
[2025-05-06 16:09:48,313][meta_train][INFO] - Epoch 30/100, iter 6/8, train loss=5.8973, lr=0.0001
[2025-05-06 16:10:09,721][meta_train][INFO] - Epoch 30/100, iter 7/8, train loss=5.2915, lr=0.0001
[2025-05-06 16:10:30,822][meta_train][INFO] - Epoch 30/100, iter 8/8, train loss=5.8941, lr=0.0001
[2025-05-06 16:10:30,847][meta_train][INFO] - epoch_30 saved !
[2025-05-06 16:10:52,139][meta_train][INFO] - Epoch 31/100, iter 1/8, train loss=5.2682, lr=0.0001
[2025-05-06 16:11:14,820][meta_train][INFO] - Epoch 31/100, iter 2/8, train loss=4.7252, lr=0.0001
[2025-05-06 16:11:36,542][meta_train][INFO] - Epoch 31/100, iter 3/8, train loss=5.1359, lr=0.0001
[2025-05-06 16:11:57,459][meta_train][INFO] - Epoch 31/100, iter 4/8, train loss=5.3852, lr=0.0001
[2025-05-06 16:12:19,430][meta_train][INFO] - Epoch 31/100, iter 5/8, train loss=5.8340, lr=0.0001
[2025-05-06 16:12:40,201][meta_train][INFO] - Epoch 31/100, iter 6/8, train loss=4.7021, lr=0.0001
[2025-05-06 16:13:01,397][meta_train][INFO] - Epoch 31/100, iter 7/8, train loss=4.6454, lr=0.0001
[2025-05-06 16:13:22,399][meta_train][INFO] - Epoch 31/100, iter 8/8, train loss=5.7441, lr=0.0001
[2025-05-06 16:13:22,433][meta_train][INFO] - epoch_31 saved !
[2025-05-06 16:13:42,983][meta_train][INFO] - Epoch 32/100, iter 1/8, train loss=4.7047, lr=0.0001
[2025-05-06 16:14:03,867][meta_train][INFO] - Epoch 32/100, iter 2/8, train loss=5.7013, lr=0.0001
[2025-05-06 16:14:26,337][meta_train][INFO] - Epoch 32/100, iter 3/8, train loss=5.0858, lr=0.0001
[2025-05-06 16:14:47,905][meta_train][INFO] - Epoch 32/100, iter 4/8, train loss=5.7137, lr=0.0001
[2025-05-06 16:15:09,419][meta_train][INFO] - Epoch 32/100, iter 5/8, train loss=5.1630, lr=0.0001
[2025-05-06 16:15:32,257][meta_train][INFO] - Epoch 32/100, iter 6/8, train loss=4.6387, lr=0.0001
[2025-05-06 16:15:53,938][meta_train][INFO] - Epoch 32/100, iter 7/8, train loss=5.2921, lr=0.0001
[2025-05-06 16:16:17,014][meta_train][INFO] - Epoch 32/100, iter 8/8, train loss=4.7072, lr=0.0001
[2025-05-06 16:16:17,057][meta_train][INFO] - epoch_32 saved !
[2025-05-06 16:16:38,689][meta_train][INFO] - Epoch 33/100, iter 1/8, train loss=5.1808, lr=0.0001
[2025-05-06 16:17:01,753][meta_train][INFO] - Epoch 33/100, iter 2/8, train loss=4.7004, lr=0.0001
[2025-05-06 16:17:22,956][meta_train][INFO] - Epoch 33/100, iter 3/8, train loss=5.5755, lr=0.0001
[2025-05-06 16:17:43,839][meta_train][INFO] - Epoch 33/100, iter 4/8, train loss=5.2754, lr=0.0001
[2025-05-06 16:18:05,247][meta_train][INFO] - Epoch 33/100, iter 5/8, train loss=5.6465, lr=0.0001
[2025-05-06 16:18:26,620][meta_train][INFO] - Epoch 33/100, iter 6/8, train loss=5.0720, lr=0.0001
[2025-05-06 16:18:47,741][meta_train][INFO] - Epoch 33/100, iter 7/8, train loss=4.6369, lr=0.0001
[2025-05-06 16:19:08,724][meta_train][INFO] - Epoch 33/100, iter 8/8, train loss=4.6987, lr=0.0001
[2025-05-06 16:19:08,763][meta_train][INFO] - epoch_33 saved !
[2025-05-06 16:19:29,773][meta_train][INFO] - Epoch 34/100, iter 1/8, train loss=4.7009, lr=0.0001
[2025-05-06 16:19:51,049][meta_train][INFO] - Epoch 34/100, iter 2/8, train loss=5.0859, lr=0.0001
[2025-05-06 16:20:12,307][meta_train][INFO] - Epoch 34/100, iter 3/8, train loss=4.6383, lr=0.0001
[2025-05-06 16:20:35,162][meta_train][INFO] - Epoch 34/100, iter 4/8, train loss=4.6910, lr=0.0001
[2025-05-06 16:20:57,135][meta_train][INFO] - Epoch 34/100, iter 5/8, train loss=5.2600, lr=0.0001
[2025-05-06 16:21:18,717][meta_train][INFO] - Epoch 34/100, iter 6/8, train loss=5.1360, lr=0.0001
[2025-05-06 16:21:39,649][meta_train][INFO] - Epoch 34/100, iter 7/8, train loss=5.6275, lr=0.0001
[2025-05-06 16:22:01,298][meta_train][INFO] - Epoch 34/100, iter 8/8, train loss=5.5009, lr=0.0001
[2025-05-06 16:22:01,333][meta_train][INFO] - epoch_34 saved !
[2025-05-06 16:22:23,031][meta_train][INFO] - Epoch 35/100, iter 1/8, train loss=5.6194, lr=0.0001
[2025-05-06 16:22:46,555][meta_train][INFO] - Epoch 35/100, iter 2/8, train loss=4.6983, lr=0.0001
[2025-05-06 16:23:07,794][meta_train][INFO] - Epoch 35/100, iter 3/8, train loss=5.0955, lr=0.0001
[2025-05-06 16:23:29,242][meta_train][INFO] - Epoch 35/100, iter 4/8, train loss=5.4604, lr=0.0001
[2025-05-06 16:23:50,069][meta_train][INFO] - Epoch 35/100, iter 5/8, train loss=5.2549, lr=0.0001
[2025-05-06 16:24:10,808][meta_train][INFO] - Epoch 35/100, iter 6/8, train loss=4.6357, lr=0.0001
[2025-05-06 16:24:31,513][meta_train][INFO] - Epoch 35/100, iter 7/8, train loss=4.6955, lr=0.0001
[2025-05-06 16:24:53,213][meta_train][INFO] - Epoch 35/100, iter 8/8, train loss=5.1116, lr=0.0001
[2025-05-06 16:24:53,238][meta_train][INFO] - epoch_35 saved !
[2025-05-06 16:25:13,651][meta_train][INFO] - Epoch 36/100, iter 1/8, train loss=4.6975, lr=0.0001
[2025-05-06 16:25:35,123][meta_train][INFO] - Epoch 36/100, iter 2/8, train loss=5.0619, lr=0.0001
[2025-05-06 16:25:56,103][meta_train][INFO] - Epoch 36/100, iter 3/8, train loss=5.5058, lr=0.0001
[2025-05-06 16:26:17,411][meta_train][INFO] - Epoch 36/100, iter 4/8, train loss=5.0618, lr=0.0001
[2025-05-06 16:26:38,628][meta_train][INFO] - Epoch 36/100, iter 5/8, train loss=4.6301, lr=0.0001
[2025-05-06 16:26:59,652][meta_train][INFO] - Epoch 36/100, iter 6/8, train loss=5.3466, lr=0.0001
[2025-05-06 16:27:20,657][meta_train][INFO] - Epoch 36/100, iter 7/8, train loss=5.1900, lr=0.0001
[2025-05-06 16:27:43,814][meta_train][INFO] - Epoch 36/100, iter 8/8, train loss=4.6823, lr=0.0001
[2025-05-06 16:27:43,849][meta_train][INFO] - epoch_36 saved !
[2025-05-06 16:28:05,015][meta_train][INFO] - Epoch 37/100, iter 1/8, train loss=5.1889, lr=0.0001
[2025-05-06 16:28:26,030][meta_train][INFO] - Epoch 37/100, iter 2/8, train loss=4.6900, lr=0.0001
[2025-05-06 16:28:47,306][meta_train][INFO] - Epoch 37/100, iter 3/8, train loss=4.6319, lr=0.0001
[2025-05-06 16:29:09,333][meta_train][INFO] - Epoch 37/100, iter 4/8, train loss=5.4844, lr=0.0001
[2025-05-06 16:29:32,402][meta_train][INFO] - Epoch 37/100, iter 5/8, train loss=4.6909, lr=0.0001
[2025-05-06 16:29:53,196][meta_train][INFO] - Epoch 37/100, iter 6/8, train loss=5.3317, lr=0.0001
[2025-05-06 16:30:14,773][meta_train][INFO] - Epoch 37/100, iter 7/8, train loss=5.0682, lr=0.0001
[2025-05-06 16:30:36,530][meta_train][INFO] - Epoch 37/100, iter 8/8, train loss=5.0636, lr=0.0001
[2025-05-06 16:30:36,554][meta_train][INFO] - epoch_37 saved !
[2025-05-06 16:30:57,627][meta_train][INFO] - Epoch 38/100, iter 1/8, train loss=5.0593, lr=0.0001
[2025-05-06 16:31:20,540][meta_train][INFO] - Epoch 38/100, iter 2/8, train loss=4.6815, lr=0.0001
[2025-05-06 16:31:41,266][meta_train][INFO] - Epoch 38/100, iter 3/8, train loss=4.6941, lr=0.0001
[2025-05-06 16:32:02,506][meta_train][INFO] - Epoch 38/100, iter 4/8, train loss=5.2086, lr=0.0001
[2025-05-06 16:32:23,725][meta_train][INFO] - Epoch 38/100, iter 5/8, train loss=5.2980, lr=0.0001
[2025-05-06 16:32:45,118][meta_train][INFO] - Epoch 38/100, iter 6/8, train loss=5.4180, lr=0.0001
[2025-05-06 16:33:06,544][meta_train][INFO] - Epoch 38/100, iter 7/8, train loss=5.0345, lr=0.0001
[2025-05-06 16:33:27,792][meta_train][INFO] - Epoch 38/100, iter 8/8, train loss=4.6271, lr=0.0001
[2025-05-06 16:33:27,823][meta_train][INFO] - epoch_38 saved !
[2025-05-06 16:33:48,927][meta_train][INFO] - Epoch 39/100, iter 1/8, train loss=5.1269, lr=0.0001
[2025-05-06 16:34:10,213][meta_train][INFO] - Epoch 39/100, iter 2/8, train loss=4.6290, lr=0.0001
[2025-05-06 16:34:31,729][meta_train][INFO] - Epoch 39/100, iter 3/8, train loss=5.0300, lr=0.0001
[2025-05-06 16:34:53,216][meta_train][INFO] - Epoch 39/100, iter 4/8, train loss=5.0481, lr=0.0001
[2025-05-06 16:35:15,678][meta_train][INFO] - Epoch 39/100, iter 5/8, train loss=4.6657, lr=0.0001
[2025-05-06 16:35:36,684][meta_train][INFO] - Epoch 39/100, iter 6/8, train loss=4.6845, lr=0.0001
[2025-05-06 16:35:58,073][meta_train][INFO] - Epoch 39/100, iter 7/8, train loss=5.3274, lr=0.0001
[2025-05-06 16:36:18,631][meta_train][INFO] - Epoch 39/100, iter 8/8, train loss=5.1879, lr=0.0001
[2025-05-06 16:36:18,656][meta_train][INFO] - epoch_39 saved !
[2025-05-06 16:36:39,562][meta_train][INFO] - Epoch 40/100, iter 1/8, train loss=4.6280, lr=0.0001
[2025-05-06 16:37:00,588][meta_train][INFO] - Epoch 40/100, iter 2/8, train loss=5.2033, lr=0.0001
[2025-05-06 16:37:22,288][meta_train][INFO] - Epoch 40/100, iter 3/8, train loss=5.0706, lr=0.0001
[2025-05-06 16:37:43,471][meta_train][INFO] - Epoch 40/100, iter 4/8, train loss=5.0137, lr=0.0001
[2025-05-06 16:38:04,381][meta_train][INFO] - Epoch 40/100, iter 5/8, train loss=4.6915, lr=0.0001
[2025-05-06 16:38:25,453][meta_train][INFO] - Epoch 40/100, iter 6/8, train loss=5.3232, lr=0.0001
[2025-05-06 16:38:48,409][meta_train][INFO] - Epoch 40/100, iter 7/8, train loss=4.6681, lr=0.0001
[2025-05-06 16:39:09,619][meta_train][INFO] - Epoch 40/100, iter 8/8, train loss=5.1074, lr=0.0001
[2025-05-06 16:39:09,644][meta_train][INFO] - epoch_40 saved !
[2025-05-06 16:39:32,864][meta_train][INFO] - Epoch 41/100, iter 1/8, train loss=4.6662, lr=0.0001
[2025-05-06 16:39:53,859][meta_train][INFO] - Epoch 41/100, iter 2/8, train loss=5.0986, lr=0.0001
[2025-05-06 16:40:14,510][meta_train][INFO] - Epoch 41/100, iter 3/8, train loss=4.9787, lr=0.0001
[2025-05-06 16:40:35,720][meta_train][INFO] - Epoch 41/100, iter 4/8, train loss=4.6269, lr=0.0001
[2025-05-06 16:40:57,174][meta_train][INFO] - Epoch 41/100, iter 5/8, train loss=5.2895, lr=0.0001
[2025-05-06 16:41:19,065][meta_train][INFO] - Epoch 41/100, iter 6/8, train loss=5.0499, lr=0.0001
[2025-05-06 16:41:40,510][meta_train][INFO] - Epoch 41/100, iter 7/8, train loss=5.1161, lr=0.0001
[2025-05-06 16:42:00,879][meta_train][INFO] - Epoch 41/100, iter 8/8, train loss=4.6837, lr=0.0001
[2025-05-06 16:42:01,090][meta_train][INFO] - epoch_41 saved !
[2025-05-06 16:42:22,534][meta_train][INFO] - Epoch 42/100, iter 1/8, train loss=4.9846, lr=0.0001
[2025-05-06 16:42:43,373][meta_train][INFO] - Epoch 42/100, iter 2/8, train loss=5.0779, lr=0.0001
[2025-05-06 16:43:04,715][meta_train][INFO] - Epoch 42/100, iter 3/8, train loss=4.9418, lr=0.0001
[2025-05-06 16:43:27,552][meta_train][INFO] - Epoch 42/100, iter 4/8, train loss=4.6513, lr=0.0001
[2025-05-06 16:43:48,582][meta_train][INFO] - Epoch 42/100, iter 5/8, train loss=5.0616, lr=0.0001
[2025-05-06 16:44:08,864][meta_train][INFO] - Epoch 42/100, iter 6/8, train loss=4.6853, lr=0.0001
[2025-05-06 16:44:30,616][meta_train][INFO] - Epoch 42/100, iter 7/8, train loss=5.2026, lr=0.0001
[2025-05-06 16:44:51,938][meta_train][INFO] - Epoch 42/100, iter 8/8, train loss=4.6227, lr=0.0001
[2025-05-06 16:44:51,964][meta_train][INFO] - epoch_42 saved !
[2025-05-06 16:45:12,562][meta_train][INFO] - Epoch 43/100, iter 1/8, train loss=5.0586, lr=0.0001
[2025-05-06 16:45:34,136][meta_train][INFO] - Epoch 43/100, iter 2/8, train loss=5.1872, lr=0.0001
[2025-05-06 16:45:54,887][meta_train][INFO] - Epoch 43/100, iter 3/8, train loss=4.6836, lr=0.0001
[2025-05-06 16:46:15,550][meta_train][INFO] - Epoch 43/100, iter 4/8, train loss=5.0442, lr=0.0001
[2025-05-06 16:46:36,766][meta_train][INFO] - Epoch 43/100, iter 5/8, train loss=4.6231, lr=0.0001
[2025-05-06 16:46:58,289][meta_train][INFO] - Epoch 43/100, iter 6/8, train loss=4.9353, lr=0.0001
[2025-05-06 16:47:21,455][meta_train][INFO] - Epoch 43/100, iter 7/8, train loss=4.6542, lr=0.0001
[2025-05-06 16:47:43,099][meta_train][INFO] - Epoch 43/100, iter 8/8, train loss=4.9941, lr=0.0001
[2025-05-06 16:47:43,142][meta_train][INFO] - epoch_43 saved !
[2025-05-06 16:48:03,807][meta_train][INFO] - Epoch 44/100, iter 1/8, train loss=4.6795, lr=0.0001
[2025-05-06 16:48:24,948][meta_train][INFO] - Epoch 44/100, iter 2/8, train loss=5.0437, lr=0.0001
[2025-05-06 16:48:47,876][meta_train][INFO] - Epoch 44/100, iter 3/8, train loss=4.6604, lr=0.0001
[2025-05-06 16:49:09,300][meta_train][INFO] - Epoch 44/100, iter 4/8, train loss=5.0081, lr=0.0001
[2025-05-06 16:49:31,081][meta_train][INFO] - Epoch 44/100, iter 5/8, train loss=5.2051, lr=0.0001
[2025-05-06 16:49:52,798][meta_train][INFO] - Epoch 44/100, iter 6/8, train loss=4.9333, lr=0.0001
[2025-05-06 16:50:14,040][meta_train][INFO] - Epoch 44/100, iter 7/8, train loss=4.6236, lr=0.0001
[2025-05-06 16:50:34,685][meta_train][INFO] - Epoch 44/100, iter 8/8, train loss=5.0567, lr=0.0001
[2025-05-06 16:50:34,721][meta_train][INFO] - epoch_44 saved !
[2025-05-06 16:50:55,879][meta_train][INFO] - Epoch 45/100, iter 1/8, train loss=5.0656, lr=0.0001
[2025-05-06 16:51:17,034][meta_train][INFO] - Epoch 45/100, iter 2/8, train loss=5.0546, lr=0.0001
[2025-05-06 16:51:37,864][meta_train][INFO] - Epoch 45/100, iter 3/8, train loss=4.6236, lr=0.0001
[2025-05-06 16:51:59,683][meta_train][INFO] - Epoch 45/100, iter 4/8, train loss=5.1596, lr=0.0001
[2025-05-06 16:52:20,504][meta_train][INFO] - Epoch 45/100, iter 5/8, train loss=4.6907, lr=0.0001
[2025-05-06 16:52:42,190][meta_train][INFO] - Epoch 45/100, iter 6/8, train loss=4.9788, lr=0.0001
[2025-05-06 16:53:05,219][meta_train][INFO] - Epoch 45/100, iter 7/8, train loss=4.6586, lr=0.0001
[2025-05-06 16:53:26,659][meta_train][INFO] - Epoch 45/100, iter 8/8, train loss=4.9043, lr=0.0001
[2025-05-06 16:53:26,685][meta_train][INFO] - epoch_45 saved !
[2025-05-06 16:53:48,403][meta_train][INFO] - Epoch 46/100, iter 1/8, train loss=5.1385, lr=0.0001
[2025-05-06 16:54:09,538][meta_train][INFO] - Epoch 46/100, iter 2/8, train loss=4.9601, lr=0.0001
[2025-05-06 16:54:30,691][meta_train][INFO] - Epoch 46/100, iter 3/8, train loss=4.6210, lr=0.0001
[2025-05-06 16:54:52,138][meta_train][INFO] - Epoch 46/100, iter 4/8, train loss=5.0155, lr=0.0001
[2025-05-06 16:55:13,521][meta_train][INFO] - Epoch 46/100, iter 5/8, train loss=5.0795, lr=0.0001
[2025-05-06 16:55:34,745][meta_train][INFO] - Epoch 46/100, iter 6/8, train loss=4.9118, lr=0.0001
[2025-05-06 16:55:55,335][meta_train][INFO] - Epoch 46/100, iter 7/8, train loss=4.7731, lr=0.0001
[2025-05-06 16:56:18,267][meta_train][INFO] - Epoch 46/100, iter 8/8, train loss=4.6743, lr=0.0001
[2025-05-06 16:56:18,295][meta_train][INFO] - epoch_46 saved !
[2025-05-06 16:56:39,663][meta_train][INFO] - Epoch 47/100, iter 1/8, train loss=4.9307, lr=0.0001
[2025-05-06 16:57:00,535][meta_train][INFO] - Epoch 47/100, iter 2/8, train loss=5.1946, lr=0.0001
[2025-05-06 16:57:21,920][meta_train][INFO] - Epoch 47/100, iter 3/8, train loss=4.6230, lr=0.0001
[2025-05-06 16:57:42,911][meta_train][INFO] - Epoch 47/100, iter 4/8, train loss=4.8335, lr=0.0001
[2025-05-06 16:58:04,089][meta_train][INFO] - Epoch 47/100, iter 5/8, train loss=4.9563, lr=0.0001
[2025-05-06 16:58:25,566][meta_train][INFO] - Epoch 47/100, iter 6/8, train loss=5.0322, lr=0.0001
[2025-05-06 16:58:48,543][meta_train][INFO] - Epoch 47/100, iter 7/8, train loss=4.8096, lr=0.0001
[2025-05-06 16:59:09,436][meta_train][INFO] - Epoch 47/100, iter 8/8, train loss=5.5311, lr=0.0001
[2025-05-06 16:59:09,482][meta_train][INFO] - epoch_47 saved !
[2025-05-06 16:59:31,058][meta_train][INFO] - Epoch 48/100, iter 1/8, train loss=4.8930, lr=0.0001
[2025-05-06 16:59:52,032][meta_train][INFO] - Epoch 48/100, iter 2/8, train loss=4.9429, lr=0.0001
[2025-05-06 17:00:13,084][meta_train][INFO] - Epoch 48/100, iter 3/8, train loss=5.3406, lr=0.0001
[2025-05-06 17:00:36,331][meta_train][INFO] - Epoch 48/100, iter 4/8, train loss=4.7691, lr=0.0001
[2025-05-06 17:00:57,186][meta_train][INFO] - Epoch 48/100, iter 5/8, train loss=5.1930, lr=0.0001
[2025-05-06 17:01:18,364][meta_train][INFO] - Epoch 48/100, iter 6/8, train loss=4.6234, lr=0.0001
[2025-05-06 17:01:35,219][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-06 17:01:35,268][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 17:01:35,268][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 17:01:35,268][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 17:01:38,871][meta_train][INFO] - Epoch 48/100, iter 7/8, train loss=4.7704, lr=0.0001
[2025-05-06 17:01:39,554][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-06 17:01:39,633][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 17:01:39,633][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 17:01:39,633][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 17:01:47,415][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 17:01:51,948][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 17:01:55,182][train][INFO] - Epoch 1/100, Val Acc=0.2791, Val Loss=2.7074, lr=0.0100
[2025-05-06 17:01:59,707][train][INFO] - Epoch 1/100, Val Acc=0.0323, Val Loss=5.4674, lr=0.0100
[2025-05-06 17:02:00,482][meta_train][INFO] - Epoch 48/100, iter 8/8, train loss=4.9683, lr=0.0001
[2025-05-06 17:02:00,522][meta_train][INFO] - epoch_48 saved !
[2025-05-06 17:02:02,636][train][INFO] - Epoch 2/100, Val Acc=0.4455, Val Loss=2.1093, lr=0.0100
[2025-05-06 17:02:06,742][train][INFO] - Epoch 2/100, Val Acc=0.0636, Val Loss=4.0115, lr=0.0100
[2025-05-06 17:02:10,270][train][INFO] - Epoch 3/100, Val Acc=0.5225, Val Loss=1.8399, lr=0.0100
[2025-05-06 17:02:14,328][train][INFO] - Epoch 3/100, Val Acc=0.0831, Val Loss=3.8544, lr=0.0100
[2025-05-06 17:02:18,286][train][INFO] - Epoch 4/100, Val Acc=0.5468, Val Loss=1.7334, lr=0.0100
[2025-05-06 17:02:22,005][train][INFO] - Epoch 4/100, Val Acc=0.0988, Val Loss=3.6032, lr=0.0100
[2025-05-06 17:02:22,752][meta_train][INFO] - Epoch 49/100, iter 1/8, train loss=4.9604, lr=0.0001
[2025-05-06 17:02:25,608][train][INFO] - Epoch 5/100, Val Acc=0.5448, Val Loss=1.8531, lr=0.0100
[2025-05-06 17:02:28,475][train][INFO] - Epoch 5/100, Val Acc=0.1267, Val Loss=3.4406, lr=0.0100
[2025-05-06 17:02:32,768][train][INFO] - Epoch 6/100, Val Acc=0.5342, Val Loss=1.9161, lr=0.0100
[2025-05-06 17:02:36,269][train][INFO] - Epoch 6/100, Val Acc=0.1495, Val Loss=3.2968, lr=0.0100
[2025-05-06 17:02:40,355][train][INFO] - Epoch 7/100, Val Acc=0.5971, Val Loss=1.5910, lr=0.0100
[2025-05-06 17:02:44,213][train][INFO] - Epoch 7/100, Val Acc=0.1917, Val Loss=3.0942, lr=0.0100
[2025-05-06 17:02:44,304][meta_train][INFO] - Epoch 49/100, iter 2/8, train loss=4.7343, lr=0.0001
[2025-05-06 17:02:48,578][train][INFO] - Epoch 8/100, Val Acc=0.6021, Val Loss=1.6013, lr=0.0100
[2025-05-06 17:02:51,539][train][INFO] - Epoch 8/100, Val Acc=0.1914, Val Loss=3.1417, lr=0.0100
[2025-05-06 17:02:56,776][train][INFO] - Epoch 9/100, Val Acc=0.6144, Val Loss=1.6196, lr=0.0100
[2025-05-06 17:02:59,025][train][INFO] - Epoch 9/100, Val Acc=0.2387, Val Loss=2.8352, lr=0.0100
[2025-05-06 17:03:04,706][train][INFO] - Epoch 10/100, Val Acc=0.6160, Val Loss=1.5647, lr=0.0100
[2025-05-06 17:03:05,804][train][INFO] - Epoch 10/100, Val Acc=0.2425, Val Loss=2.9457, lr=0.0100
[2025-05-06 17:03:08,297][meta_train][INFO] - Epoch 49/100, iter 3/8, train loss=4.7822, lr=0.0001
[2025-05-06 17:03:12,073][train][INFO] - Epoch 11/100, Val Acc=0.5846, Val Loss=1.7957, lr=0.0100
[2025-05-06 17:03:13,441][train][INFO] - Epoch 11/100, Val Acc=0.2907, Val Loss=2.6339, lr=0.0100
[2025-05-06 17:03:19,057][train][INFO] - Epoch 12/100, Val Acc=0.6180, Val Loss=1.5607, lr=0.0100
[2025-05-06 17:03:21,012][train][INFO] - Epoch 12/100, Val Acc=0.3103, Val Loss=2.5819, lr=0.0100
[2025-05-06 17:03:27,057][train][INFO] - Epoch 13/100, Val Acc=0.6179, Val Loss=1.5869, lr=0.0100
[2025-05-06 17:03:28,746][train][INFO] - Epoch 13/100, Val Acc=0.2952, Val Loss=2.6708, lr=0.0100
[2025-05-06 17:03:30,211][meta_train][INFO] - Epoch 49/100, iter 4/8, train loss=4.9003, lr=0.0001
[2025-05-06 17:03:35,280][train][INFO] - Epoch 14/100, Val Acc=0.6150, Val Loss=1.6106, lr=0.0100
[2025-05-06 17:03:36,181][train][INFO] - Epoch 14/100, Val Acc=0.3502, Val Loss=2.3950, lr=0.0100
[2025-05-06 17:03:42,409][train][INFO] - Epoch 15/100, Val Acc=0.6468, Val Loss=1.4658, lr=0.0100
[2025-05-06 17:03:43,315][train][INFO] - Epoch 15/100, Val Acc=0.3074, Val Loss=2.5927, lr=0.0100
[2025-05-06 17:03:49,930][train][INFO] - Epoch 16/100, Val Acc=0.6220, Val Loss=1.5813, lr=0.0100
[2025-05-06 17:03:50,904][train][INFO] - Epoch 16/100, Val Acc=0.3441, Val Loss=2.4308, lr=0.0100
[2025-05-06 17:03:52,214][meta_train][INFO] - Epoch 49/100, iter 5/8, train loss=4.6235, lr=0.0001
[2025-05-06 17:03:57,952][train][INFO] - Epoch 17/100, Val Acc=0.6341, Val Loss=1.5944, lr=0.0100
[2025-05-06 17:03:58,120][train][INFO] - Epoch 17/100, Val Acc=0.3590, Val Loss=2.3879, lr=0.0100
[2025-05-06 17:04:05,370][train][INFO] - Epoch 18/100, Val Acc=0.3871, Val Loss=2.2645, lr=0.0100
[2025-05-06 17:04:05,606][train][INFO] - Epoch 18/100, Val Acc=0.6451, Val Loss=1.5176, lr=0.0100
[2025-05-06 17:04:13,136][train][INFO] - Epoch 19/100, Val Acc=0.3874, Val Loss=2.2538, lr=0.0100
[2025-05-06 17:04:13,484][train][INFO] - Epoch 19/100, Val Acc=0.6271, Val Loss=1.6376, lr=0.0100
[2025-05-06 17:04:14,797][meta_train][INFO] - Epoch 49/100, iter 6/8, train loss=4.8748, lr=0.0001
[2025-05-06 17:04:20,368][train][INFO] - Epoch 20/100, Val Acc=0.3861, Val Loss=2.3092, lr=0.0100
[2025-05-06 17:04:21,047][train][INFO] - Epoch 20/100, Val Acc=0.6381, Val Loss=1.5640, lr=0.0100
[2025-05-06 17:04:27,496][train][INFO] - Epoch 21/100, Val Acc=0.3720, Val Loss=2.3418, lr=0.0100
[2025-05-06 17:04:29,152][train][INFO] - Epoch 21/100, Val Acc=0.6460, Val Loss=1.5288, lr=0.0100
[2025-05-06 17:04:34,762][train][INFO] - Epoch 22/100, Val Acc=0.4024, Val Loss=2.2493, lr=0.0100
[2025-05-06 17:04:37,034][train][INFO] - Epoch 22/100, Val Acc=0.6462, Val Loss=1.5187, lr=0.0100
[2025-05-06 17:04:37,093][meta_train][INFO] - Epoch 49/100, iter 7/8, train loss=5.2668, lr=0.0001
[2025-05-06 17:04:42,250][train][INFO] - Epoch 23/100, Val Acc=0.3918, Val Loss=2.2576, lr=0.0100
[2025-05-06 17:04:44,334][train][INFO] - Epoch 23/100, Val Acc=0.6463, Val Loss=1.5775, lr=0.0100
[2025-05-06 17:04:49,557][train][INFO] - Epoch 24/100, Val Acc=0.4254, Val Loss=2.1291, lr=0.0100
[2025-05-06 17:04:52,217][train][INFO] - Epoch 24/100, Val Acc=0.6461, Val Loss=1.5627, lr=0.0100
[2025-05-06 17:04:57,156][train][INFO] - Epoch 25/100, Val Acc=0.4029, Val Loss=2.2842, lr=0.0100
[2025-05-06 17:04:59,117][meta_train][INFO] - Epoch 49/100, iter 8/8, train loss=5.1768, lr=0.0001
[2025-05-06 17:04:59,168][meta_train][INFO] - epoch_49 saved !
[2025-05-06 17:04:59,891][train][INFO] - Epoch 25/100, Val Acc=0.6406, Val Loss=1.6350, lr=0.0100
[2025-05-06 17:05:04,758][train][INFO] - Epoch 26/100, Val Acc=0.4011, Val Loss=2.3025, lr=0.0100
[2025-05-06 17:05:07,937][train][INFO] - Epoch 26/100, Val Acc=0.6498, Val Loss=1.5835, lr=0.0100
[2025-05-06 17:05:12,171][train][INFO] - Epoch 27/100, Val Acc=0.4275, Val Loss=2.1068, lr=0.0100
[2025-05-06 17:05:15,613][train][INFO] - Epoch 27/100, Val Acc=0.6414, Val Loss=1.6178, lr=0.0100
[2025-05-06 17:05:19,806][train][INFO] - Epoch 28/100, Val Acc=0.4357, Val Loss=2.0443, lr=0.0100
[2025-05-06 17:05:21,065][meta_train][INFO] - Epoch 50/100, iter 1/8, train loss=4.6249, lr=0.0001
[2025-05-06 17:05:23,620][train][INFO] - Epoch 28/100, Val Acc=0.6298, Val Loss=1.6971, lr=0.0100
[2025-05-06 17:05:27,619][train][INFO] - Epoch 29/100, Val Acc=0.4318, Val Loss=2.1137, lr=0.0100
[2025-05-06 17:05:31,342][train][INFO] - Epoch 29/100, Val Acc=0.6573, Val Loss=1.5546, lr=0.0100
[2025-05-06 17:05:34,333][train][INFO] - Epoch 30/100, Val Acc=0.4335, Val Loss=2.1285, lr=0.0100
[2025-05-06 17:05:39,043][train][INFO] - Epoch 30/100, Val Acc=0.6564, Val Loss=1.5502, lr=0.0100
[2025-05-06 17:05:42,061][train][INFO] - Epoch 31/100, Val Acc=0.4521, Val Loss=2.0096, lr=0.0100
[2025-05-06 17:05:42,986][meta_train][INFO] - Epoch 50/100, iter 2/8, train loss=4.7147, lr=0.0001
[2025-05-06 17:05:46,604][train][INFO] - Epoch 31/100, Val Acc=0.6329, Val Loss=1.6822, lr=0.0100
[2025-05-06 17:05:49,676][train][INFO] - Epoch 32/100, Val Acc=0.4566, Val Loss=2.0074, lr=0.0100
[2025-05-06 17:05:53,860][train][INFO] - Epoch 32/100, Val Acc=0.6456, Val Loss=1.6019, lr=0.0100
[2025-05-06 17:05:57,594][train][INFO] - Epoch 33/100, Val Acc=0.4569, Val Loss=2.0046, lr=0.0100
[2025-05-06 17:06:01,620][train][INFO] - Epoch 33/100, Val Acc=0.6494, Val Loss=1.5989, lr=0.0100
[2025-05-06 17:06:04,912][meta_train][INFO] - Epoch 50/100, iter 3/8, train loss=4.9178, lr=0.0001
[2025-05-06 17:06:05,690][train][INFO] - Epoch 34/100, Val Acc=0.4372, Val Loss=2.0945, lr=0.0100
[2025-05-06 17:06:08,923][train][INFO] - Epoch 34/100, Val Acc=0.6488, Val Loss=1.6136, lr=0.0100
[2025-05-06 17:06:13,314][train][INFO] - Epoch 35/100, Val Acc=0.4469, Val Loss=2.0831, lr=0.0100
[2025-05-06 17:06:16,952][train][INFO] - Epoch 35/100, Val Acc=0.6478, Val Loss=1.6084, lr=0.0100
[2025-05-06 17:06:21,276][train][INFO] - Epoch 36/100, Val Acc=0.4682, Val Loss=1.9464, lr=0.0100
[2025-05-06 17:06:24,820][train][INFO] - Epoch 36/100, Val Acc=0.6462, Val Loss=1.5963, lr=0.0100
[2025-05-06 17:06:26,946][meta_train][INFO] - Epoch 50/100, iter 4/8, train loss=4.9989, lr=0.0001
[2025-05-06 17:06:28,844][train][INFO] - Epoch 37/100, Val Acc=0.4400, Val Loss=2.1041, lr=0.0100
[2025-05-06 17:06:32,703][train][INFO] - Epoch 37/100, Val Acc=0.6429, Val Loss=1.7038, lr=0.0100
[2025-05-06 17:06:36,818][train][INFO] - Epoch 38/100, Val Acc=0.4791, Val Loss=1.9101, lr=0.0100
[2025-05-06 17:06:40,575][train][INFO] - Epoch 38/100, Val Acc=0.6385, Val Loss=1.6921, lr=0.0100
[2025-05-06 17:06:45,019][train][INFO] - Epoch 39/100, Val Acc=0.4549, Val Loss=2.0390, lr=0.0100
[2025-05-06 17:06:48,571][train][INFO] - Epoch 39/100, Val Acc=0.6485, Val Loss=1.6085, lr=0.0100
[2025-05-06 17:06:50,582][meta_train][INFO] - Epoch 50/100, iter 5/8, train loss=4.7739, lr=0.0001
[2025-05-06 17:06:52,908][train][INFO] - Epoch 40/100, Val Acc=0.4656, Val Loss=1.9566, lr=0.0100
[2025-05-06 17:06:56,672][train][INFO] - Epoch 40/100, Val Acc=0.6343, Val Loss=1.6575, lr=0.0100
[2025-05-06 17:07:01,082][train][INFO] - Epoch 41/100, Val Acc=0.4669, Val Loss=2.0096, lr=0.0100
[2025-05-06 17:07:03,315][train][INFO] - Epoch 41/100, Val Acc=0.6488, Val Loss=1.6604, lr=0.0100
[2025-05-06 17:07:08,653][train][INFO] - Epoch 42/100, Val Acc=0.4783, Val Loss=1.9142, lr=0.0100
[2025-05-06 17:07:11,090][train][INFO] - Epoch 42/100, Val Acc=0.6580, Val Loss=1.5335, lr=0.0100
[2025-05-06 17:07:13,142][meta_train][INFO] - Epoch 50/100, iter 6/8, train loss=5.1465, lr=0.0001
[2025-05-06 17:07:16,298][train][INFO] - Epoch 43/100, Val Acc=0.4743, Val Loss=1.9640, lr=0.0100
[2025-05-06 17:07:18,686][train][INFO] - Epoch 43/100, Val Acc=0.6408, Val Loss=1.6723, lr=0.0100
[2025-05-06 17:07:24,035][train][INFO] - Epoch 44/100, Val Acc=0.4762, Val Loss=1.9218, lr=0.0100
[2025-05-06 17:07:26,451][train][INFO] - Epoch 44/100, Val Acc=0.6461, Val Loss=1.6501, lr=0.0100
[2025-05-06 17:07:31,668][train][INFO] - Epoch 45/100, Val Acc=0.4661, Val Loss=2.0215, lr=0.0100
[2025-05-06 17:07:34,057][train][INFO] - Epoch 45/100, Val Acc=0.6481, Val Loss=1.5905, lr=0.0100
[2025-05-06 17:07:35,199][meta_train][INFO] - Epoch 50/100, iter 7/8, train loss=4.9639, lr=0.0001
[2025-05-06 17:07:39,200][train][INFO] - Epoch 46/100, Val Acc=0.4592, Val Loss=2.0559, lr=0.0100
[2025-05-06 17:07:41,853][train][INFO] - Epoch 46/100, Val Acc=0.6478, Val Loss=1.6626, lr=0.0100
[2025-05-06 17:07:46,407][train][INFO] - Epoch 47/100, Val Acc=0.4802, Val Loss=1.9061, lr=0.0100
[2025-05-06 17:07:49,489][train][INFO] - Epoch 47/100, Val Acc=0.6455, Val Loss=1.6444, lr=0.0100
[2025-05-06 17:07:53,700][train][INFO] - Epoch 48/100, Val Acc=0.4593, Val Loss=2.0191, lr=0.0100
[2025-05-06 17:07:57,073][train][INFO] - Epoch 48/100, Val Acc=0.6560, Val Loss=1.5982, lr=0.0100
[2025-05-06 17:07:57,106][meta_train][INFO] - Epoch 50/100, iter 8/8, train loss=4.8701, lr=0.0001
[2025-05-06 17:07:57,135][meta_train][INFO] - epoch_50 saved !
[2025-05-06 17:08:01,429][train][INFO] - Epoch 49/100, Val Acc=0.4652, Val Loss=1.9579, lr=0.0100
[2025-05-06 17:08:04,956][train][INFO] - Epoch 49/100, Val Acc=0.6565, Val Loss=1.5495, lr=0.0100
[2025-05-06 17:08:09,531][train][INFO] - Epoch 50/100, Val Acc=0.4812, Val Loss=1.9501, lr=0.0100
[2025-05-06 17:08:12,627][train][INFO] - Epoch 50/100, Val Acc=0.6419, Val Loss=1.6648, lr=0.0100
[2025-05-06 17:08:16,729][train][INFO] - Epoch 51/100, Val Acc=0.4759, Val Loss=1.9453, lr=0.0100
[2025-05-06 17:08:19,071][meta_train][INFO] - Epoch 51/100, iter 1/8, train loss=4.8820, lr=0.0001
[2025-05-06 17:08:19,881][train][INFO] - Epoch 51/100, Val Acc=0.6402, Val Loss=1.6608, lr=0.0100
[2025-05-06 17:08:24,383][train][INFO] - Epoch 52/100, Val Acc=0.4583, Val Loss=2.0111, lr=0.0100
[2025-05-06 17:08:26,833][train][INFO] - Epoch 52/100, Val Acc=0.6433, Val Loss=1.6709, lr=0.0100
[2025-05-06 17:08:31,899][train][INFO] - Epoch 53/100, Val Acc=0.4895, Val Loss=1.8743, lr=0.0100
[2025-05-06 17:08:34,408][train][INFO] - Epoch 53/100, Val Acc=0.6525, Val Loss=1.5602, lr=0.0100
[2025-05-06 17:08:39,411][train][INFO] - Epoch 54/100, Val Acc=0.4551, Val Loss=2.0621, lr=0.0100
[2025-05-06 17:08:41,100][meta_train][INFO] - Epoch 51/100, iter 2/8, train loss=4.6262, lr=0.0001
[2025-05-06 17:08:41,928][train][INFO] - Epoch 54/100, Val Acc=0.6440, Val Loss=1.6503, lr=0.0100
[2025-05-06 17:08:46,711][train][INFO] - Epoch 55/100, Val Acc=0.4707, Val Loss=1.9723, lr=0.0100
[2025-05-06 17:08:49,743][train][INFO] - Epoch 55/100, Val Acc=0.6409, Val Loss=1.6875, lr=0.0100
[2025-05-06 17:08:54,006][train][INFO] - Epoch 56/100, Val Acc=0.4667, Val Loss=2.0072, lr=0.0100
[2025-05-06 17:08:57,290][train][INFO] - Epoch 56/100, Val Acc=0.6423, Val Loss=1.6427, lr=0.0100
[2025-05-06 17:09:01,553][train][INFO] - Epoch 57/100, Val Acc=0.4933, Val Loss=1.8801, lr=0.0100
[2025-05-06 17:09:03,360][meta_train][INFO] - Epoch 51/100, iter 3/8, train loss=5.0081, lr=0.0001
[2025-05-06 17:09:04,734][train][INFO] - Epoch 57/100, Val Acc=0.6477, Val Loss=1.6315, lr=0.0100
[2025-05-06 17:09:09,450][train][INFO] - Epoch 58/100, Val Acc=0.5023, Val Loss=1.8285, lr=0.0100
[2025-05-06 17:09:12,548][train][INFO] - Epoch 58/100, Val Acc=0.6444, Val Loss=1.6553, lr=0.0100
[2025-05-06 17:09:17,358][train][INFO] - Epoch 59/100, Val Acc=0.4855, Val Loss=1.9503, lr=0.0100
[2025-05-06 17:09:19,576][train][INFO] - Epoch 59/100, Val Acc=0.6251, Val Loss=1.7558, lr=0.0100
[2025-05-06 17:09:24,811][meta_train][INFO] - Epoch 51/100, iter 4/8, train loss=5.0374, lr=0.0001
[2025-05-06 17:09:24,845][train][INFO] - Epoch 60/100, Val Acc=0.5074, Val Loss=1.8138, lr=0.0100
[2025-05-06 17:09:27,891][train][INFO] - Epoch 60/100, Val Acc=0.6511, Val Loss=1.6685, lr=0.0100
[2025-05-06 17:09:31,871][train][INFO] - Epoch 61/100, Val Acc=0.5696, Val Loss=1.5576, lr=0.0010
[2025-05-06 17:09:35,633][train][INFO] - Epoch 61/100, Val Acc=0.7081, Val Loss=1.3163, lr=0.0010
[2025-05-06 17:09:38,982][train][INFO] - Epoch 62/100, Val Acc=0.5694, Val Loss=1.5569, lr=0.0010
[2025-05-06 17:09:43,330][train][INFO] - Epoch 62/100, Val Acc=0.7116, Val Loss=1.3142, lr=0.0010
[2025-05-06 17:09:46,857][train][INFO] - Epoch 63/100, Val Acc=0.5723, Val Loss=1.5390, lr=0.0010
[2025-05-06 17:09:47,022][meta_train][INFO] - Epoch 51/100, iter 5/8, train loss=4.8820, lr=0.0001
[2025-05-06 17:09:51,101][train][INFO] - Epoch 63/100, Val Acc=0.7130, Val Loss=1.3088, lr=0.0010
[2025-05-06 17:09:54,825][train][INFO] - Epoch 64/100, Val Acc=0.5741, Val Loss=1.5427, lr=0.0010
[2025-05-06 17:09:58,175][train][INFO] - Epoch 64/100, Val Acc=0.7157, Val Loss=1.3135, lr=0.0010
[2025-05-06 17:10:02,157][train][INFO] - Epoch 65/100, Val Acc=0.5742, Val Loss=1.5414, lr=0.0010
[2025-05-06 17:10:05,407][train][INFO] - Epoch 65/100, Val Acc=0.7168, Val Loss=1.3124, lr=0.0010
[2025-05-06 17:10:09,657][train][INFO] - Epoch 66/100, Val Acc=0.5770, Val Loss=1.5385, lr=0.0010
[2025-05-06 17:10:10,521][meta_train][INFO] - Epoch 51/100, iter 6/8, train loss=4.8376, lr=0.0001
[2025-05-06 17:10:13,026][train][INFO] - Epoch 66/100, Val Acc=0.7168, Val Loss=1.3183, lr=0.0010
[2025-05-06 17:10:17,413][train][INFO] - Epoch 67/100, Val Acc=0.5744, Val Loss=1.5409, lr=0.0010
[2025-05-06 17:10:20,771][train][INFO] - Epoch 67/100, Val Acc=0.7160, Val Loss=1.3260, lr=0.0010
[2025-05-06 17:10:25,006][train][INFO] - Epoch 68/100, Val Acc=0.5753, Val Loss=1.5384, lr=0.0010
[2025-05-06 17:10:28,350][train][INFO] - Epoch 68/100, Val Acc=0.7177, Val Loss=1.3250, lr=0.0010
[2025-05-06 17:10:32,378][train][INFO] - Epoch 69/100, Val Acc=0.5748, Val Loss=1.5423, lr=0.0010
[2025-05-06 17:10:32,378][meta_train][INFO] - Epoch 51/100, iter 7/8, train loss=4.6669, lr=0.0001
[2025-05-06 17:10:36,292][train][INFO] - Epoch 69/100, Val Acc=0.7174, Val Loss=1.3257, lr=0.0010
[2025-05-06 17:10:39,535][train][INFO] - Epoch 70/100, Val Acc=0.5725, Val Loss=1.5387, lr=0.0010
[2025-05-06 17:10:43,492][train][INFO] - Epoch 70/100, Val Acc=0.7187, Val Loss=1.3279, lr=0.0010
[2025-05-06 17:10:46,670][train][INFO] - Epoch 71/100, Val Acc=0.5745, Val Loss=1.5416, lr=0.0010
[2025-05-06 17:10:51,369][train][INFO] - Epoch 71/100, Val Acc=0.7201, Val Loss=1.3367, lr=0.0010
[2025-05-06 17:10:53,687][train][INFO] - Epoch 72/100, Val Acc=0.5730, Val Loss=1.5420, lr=0.0010
[2025-05-06 17:10:54,902][meta_train][INFO] - Epoch 51/100, iter 8/8, train loss=5.1520, lr=0.0001
[2025-05-06 17:10:54,930][meta_train][INFO] - epoch_51 saved !
[2025-05-06 17:10:59,339][train][INFO] - Epoch 72/100, Val Acc=0.7181, Val Loss=1.3416, lr=0.0010
[2025-05-06 17:11:01,513][train][INFO] - Epoch 73/100, Val Acc=0.5725, Val Loss=1.5488, lr=0.0010
[2025-05-06 17:11:06,965][train][INFO] - Epoch 73/100, Val Acc=0.7204, Val Loss=1.3381, lr=0.0010
[2025-05-06 17:11:08,530][train][INFO] - Epoch 74/100, Val Acc=0.5779, Val Loss=1.5466, lr=0.0010
[2025-05-06 17:11:14,468][train][INFO] - Epoch 74/100, Val Acc=0.7191, Val Loss=1.3477, lr=0.0010
[2025-05-06 17:11:16,233][train][INFO] - Epoch 75/100, Val Acc=0.5762, Val Loss=1.5461, lr=0.0010
[2025-05-06 17:11:16,923][meta_train][INFO] - Epoch 52/100, iter 1/8, train loss=4.8378, lr=0.0001
[2025-05-06 17:11:21,491][train][INFO] - Epoch 75/100, Val Acc=0.7201, Val Loss=1.3420, lr=0.0010
[2025-05-06 17:11:24,092][train][INFO] - Epoch 76/100, Val Acc=0.5777, Val Loss=1.5389, lr=0.0010
[2025-05-06 17:11:29,495][train][INFO] - Epoch 76/100, Val Acc=0.7219, Val Loss=1.3499, lr=0.0010
[2025-05-06 17:11:32,096][train][INFO] - Epoch 77/100, Val Acc=0.5743, Val Loss=1.5565, lr=0.0010
[2025-05-06 17:11:37,362][train][INFO] - Epoch 77/100, Val Acc=0.7209, Val Loss=1.3539, lr=0.0010
[2025-05-06 17:11:39,342][train][INFO] - Epoch 78/100, Val Acc=0.5767, Val Loss=1.5510, lr=0.0010
[2025-05-06 17:11:40,729][meta_train][INFO] - Epoch 52/100, iter 2/8, train loss=4.7904, lr=0.0001
[2025-05-06 17:11:45,145][train][INFO] - Epoch 78/100, Val Acc=0.7208, Val Loss=1.3463, lr=0.0010
[2025-05-06 17:11:47,396][train][INFO] - Epoch 79/100, Val Acc=0.5767, Val Loss=1.5503, lr=0.0010
[2025-05-06 17:11:52,719][train][INFO] - Epoch 79/100, Val Acc=0.7194, Val Loss=1.3569, lr=0.0010
[2025-05-06 17:11:54,989][train][INFO] - Epoch 80/100, Val Acc=0.5773, Val Loss=1.5517, lr=0.0010
[2025-05-06 17:12:00,741][train][INFO] - Epoch 80/100, Val Acc=0.7227, Val Loss=1.3566, lr=0.0010
[2025-05-06 17:12:02,919][meta_train][INFO] - Epoch 52/100, iter 3/8, train loss=4.8642, lr=0.0001
[2025-05-06 17:12:03,013][train][INFO] - Epoch 81/100, Val Acc=0.5785, Val Loss=1.5575, lr=0.0010
[2025-05-06 17:12:08,516][train][INFO] - Epoch 81/100, Val Acc=0.7197, Val Loss=1.3554, lr=0.0010
[2025-05-06 17:12:10,907][train][INFO] - Epoch 82/100, Val Acc=0.5765, Val Loss=1.5655, lr=0.0010
[2025-05-06 17:12:16,109][train][INFO] - Epoch 82/100, Val Acc=0.7208, Val Loss=1.3570, lr=0.0010
[2025-05-06 17:12:18,086][train][INFO] - Epoch 83/100, Val Acc=0.5745, Val Loss=1.5510, lr=0.0010
[2025-05-06 17:12:24,070][train][INFO] - Epoch 83/100, Val Acc=0.7221, Val Loss=1.3513, lr=0.0010
[2025-05-06 17:12:25,121][meta_train][INFO] - Epoch 52/100, iter 4/8, train loss=4.9314, lr=0.0001
[2025-05-06 17:12:25,505][train][INFO] - Epoch 84/100, Val Acc=0.5743, Val Loss=1.5583, lr=0.0010
[2025-05-06 17:12:31,825][train][INFO] - Epoch 84/100, Val Acc=0.7204, Val Loss=1.3602, lr=0.0010
[2025-05-06 17:12:32,919][train][INFO] - Epoch 85/100, Val Acc=0.5762, Val Loss=1.5498, lr=0.0010
[2025-05-06 17:12:39,550][train][INFO] - Epoch 85/100, Val Acc=0.7203, Val Loss=1.3671, lr=0.0010
[2025-05-06 17:12:40,420][train][INFO] - Epoch 86/100, Val Acc=0.5769, Val Loss=1.5559, lr=0.0010
[2025-05-06 17:12:46,758][train][INFO] - Epoch 86/100, Val Acc=0.7200, Val Loss=1.3669, lr=0.0010
[2025-05-06 17:12:47,078][meta_train][INFO] - Epoch 52/100, iter 5/8, train loss=4.8574, lr=0.0001
[2025-05-06 17:12:47,925][train][INFO] - Epoch 87/100, Val Acc=0.5722, Val Loss=1.5610, lr=0.0010
[2025-05-06 17:12:54,551][train][INFO] - Epoch 87/100, Val Acc=0.7211, Val Loss=1.3629, lr=0.0010
[2025-05-06 17:12:55,544][train][INFO] - Epoch 88/100, Val Acc=0.5756, Val Loss=1.5658, lr=0.0010
[2025-05-06 17:13:02,352][train][INFO] - Epoch 88/100, Val Acc=0.7184, Val Loss=1.3707, lr=0.0010
[2025-05-06 17:13:03,358][train][INFO] - Epoch 89/100, Val Acc=0.5779, Val Loss=1.5676, lr=0.0010
[2025-05-06 17:13:09,458][meta_train][INFO] - Epoch 52/100, iter 6/8, train loss=5.0744, lr=0.0001
[2025-05-06 17:13:10,201][train][INFO] - Epoch 89/100, Val Acc=0.7213, Val Loss=1.3748, lr=0.0010
[2025-05-06 17:13:10,897][train][INFO] - Epoch 90/100, Val Acc=0.5765, Val Loss=1.5649, lr=0.0010
[2025-05-06 17:13:17,180][train][INFO] - Epoch 90/100, Val Acc=0.7203, Val Loss=1.3690, lr=0.0010
[2025-05-06 17:13:18,583][train][INFO] - Epoch 91/100, Val Acc=0.5843, Val Loss=1.5438, lr=0.0001
[2025-05-06 17:13:24,311][train][INFO] - Epoch 91/100, Val Acc=0.7214, Val Loss=1.3670, lr=0.0001
[2025-05-06 17:13:25,824][train][INFO] - Epoch 92/100, Val Acc=0.5819, Val Loss=1.5433, lr=0.0001
[2025-05-06 17:13:31,072][meta_train][INFO] - Epoch 52/100, iter 7/8, train loss=4.6917, lr=0.0001
[2025-05-06 17:13:32,301][train][INFO] - Epoch 92/100, Val Acc=0.7234, Val Loss=1.3647, lr=0.0001
[2025-05-06 17:13:33,373][train][INFO] - Epoch 93/100, Val Acc=0.5814, Val Loss=1.5425, lr=0.0001
[2025-05-06 17:13:40,153][train][INFO] - Epoch 93/100, Val Acc=0.7216, Val Loss=1.3654, lr=0.0001
[2025-05-06 17:13:40,516][train][INFO] - Epoch 94/100, Val Acc=0.5821, Val Loss=1.5367, lr=0.0001
[2025-05-06 17:13:47,945][train][INFO] - Epoch 94/100, Val Acc=0.7242, Val Loss=1.3676, lr=0.0001
[2025-05-06 17:13:47,963][train][INFO] - Epoch 95/100, Val Acc=0.5833, Val Loss=1.5363, lr=0.0001
[2025-05-06 17:13:53,339][meta_train][INFO] - Epoch 52/100, iter 8/8, train loss=4.6207, lr=0.0001
[2025-05-06 17:13:53,372][meta_train][INFO] - epoch_52 saved !
[2025-05-06 17:13:55,727][train][INFO] - Epoch 96/100, Val Acc=0.5819, Val Loss=1.5367, lr=0.0001
[2025-05-06 17:13:55,736][train][INFO] - Epoch 95/100, Val Acc=0.7227, Val Loss=1.3637, lr=0.0001
[2025-05-06 17:14:03,327][train][INFO] - Epoch 97/100, Val Acc=0.5824, Val Loss=1.5372, lr=0.0001
[2025-05-06 17:14:03,338][train][INFO] - Epoch 96/100, Val Acc=0.7221, Val Loss=1.3637, lr=0.0001
[2025-05-06 17:14:11,122][train][INFO] - Epoch 97/100, Val Acc=0.7209, Val Loss=1.3686, lr=0.0001
[2025-05-06 17:14:11,191][train][INFO] - Epoch 98/100, Val Acc=0.5837, Val Loss=1.5356, lr=0.0001
[2025-05-06 17:14:15,787][meta_train][INFO] - Epoch 53/100, iter 1/8, train loss=4.6215, lr=0.0001
[2025-05-06 17:14:19,057][train][INFO] - Epoch 98/100, Val Acc=0.7226, Val Loss=1.3652, lr=0.0001
[2025-05-06 17:14:19,083][train][INFO] - Epoch 99/100, Val Acc=0.5811, Val Loss=1.5367, lr=0.0001
[2025-05-06 17:14:26,610][train][INFO] - Epoch 99/100, Val Acc=0.7228, Val Loss=1.3706, lr=0.0001
[2025-05-06 17:14:26,626][train][INFO] - Epoch 100/100, Val Acc=0.5826, Val Loss=1.5363, lr=0.0001
[2025-05-06 17:14:31,368][train][INFO] - After training : Train Acc=0.6987  Val Acc=0.5843
[2025-05-06 17:14:31,381][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 17:14:33,775][train][INFO] - Epoch 100/100, Val Acc=0.7229, Val Loss=1.3677, lr=0.0001
[2025-05-06 17:14:37,879][meta_train][INFO] - Epoch 53/100, iter 2/8, train loss=4.8508, lr=0.0001
[2025-05-06 17:14:38,749][train][INFO] - After training : Train Acc=0.9974  Val Acc=0.7242
[2025-05-06 17:14:38,762][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 17:14:59,792][meta_train][INFO] - Epoch 53/100, iter 3/8, train loss=4.6889, lr=0.0001
[2025-05-06 17:15:23,783][meta_train][INFO] - Epoch 53/100, iter 4/8, train loss=4.8037, lr=0.0001
[2025-05-06 17:15:33,464][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 17:15:46,327][meta_train][INFO] - Epoch 53/100, iter 5/8, train loss=4.8240, lr=0.0001
[2025-05-06 17:15:49,557][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 17:16:08,310][meta_train][INFO] - Epoch 53/100, iter 6/8, train loss=4.9382, lr=0.0001
[2025-05-06 17:16:31,108][meta_train][INFO] - Epoch 53/100, iter 7/8, train loss=4.8586, lr=0.0001
[2025-05-06 17:16:42,568][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 17:16:43,013][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 17:16:53,592][meta_train][INFO] - Epoch 53/100, iter 8/8, train loss=5.1307, lr=0.0001
[2025-05-06 17:16:53,630][meta_train][INFO] - epoch_53 saved !
[2025-05-06 17:16:59,099][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 17:16:59,556][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 17:17:14,932][meta_train][INFO] - Epoch 54/100, iter 1/8, train loss=4.6796, lr=0.0001
[2025-05-06 17:17:36,052][meta_train][INFO] - Epoch 54/100, iter 2/8, train loss=4.6232, lr=0.0001
[2025-05-06 17:17:57,728][meta_train][INFO] - Epoch 54/100, iter 3/8, train loss=4.8243, lr=0.0001
[2025-05-06 17:18:19,534][meta_train][INFO] - Epoch 54/100, iter 4/8, train loss=5.0625, lr=0.0001
[2025-05-06 17:18:40,754][meta_train][INFO] - Epoch 54/100, iter 5/8, train loss=4.9395, lr=0.0001
[2025-05-06 17:19:02,196][meta_train][INFO] - Epoch 54/100, iter 6/8, train loss=4.8819, lr=0.0001
[2025-05-06 17:19:25,255][meta_train][INFO] - Epoch 54/100, iter 7/8, train loss=4.8000, lr=0.0001
[2025-05-06 17:19:46,112][meta_train][INFO] - Epoch 54/100, iter 8/8, train loss=4.8193, lr=0.0001
[2025-05-06 17:19:46,145][meta_train][INFO] - epoch_54 saved !
[2025-05-06 17:20:07,621][meta_train][INFO] - Epoch 55/100, iter 1/8, train loss=4.8235, lr=0.0001
[2025-05-06 17:20:29,209][meta_train][INFO] - Epoch 55/100, iter 2/8, train loss=4.8185, lr=0.0001
[2025-05-06 17:20:50,213][meta_train][INFO] - Epoch 55/100, iter 3/8, train loss=4.6234, lr=0.0001
[2025-05-06 17:21:11,833][meta_train][INFO] - Epoch 55/100, iter 4/8, train loss=5.1051, lr=0.0001
[2025-05-06 17:21:32,964][meta_train][INFO] - Epoch 55/100, iter 5/8, train loss=4.8686, lr=0.0001
[2025-05-06 17:21:54,148][meta_train][INFO] - Epoch 55/100, iter 6/8, train loss=4.9218, lr=0.0001
[2025-05-06 17:22:14,995][meta_train][INFO] - Epoch 55/100, iter 7/8, train loss=4.6862, lr=0.0001
[2025-05-06 17:22:38,356][meta_train][INFO] - Epoch 55/100, iter 8/8, train loss=4.7662, lr=0.0001
[2025-05-06 17:22:38,384][meta_train][INFO] - epoch_55 saved !
[2025-05-06 17:23:00,976][meta_train][INFO] - Epoch 56/100, iter 1/8, train loss=4.7578, lr=0.0001
[2025-05-06 17:23:21,651][meta_train][INFO] - Epoch 56/100, iter 2/8, train loss=4.6923, lr=0.0001
[2025-05-06 17:23:42,782][meta_train][INFO] - Epoch 56/100, iter 3/8, train loss=4.8904, lr=0.0001
[2025-05-06 17:24:04,295][meta_train][INFO] - Epoch 56/100, iter 4/8, train loss=4.7848, lr=0.0001
[2025-05-06 17:24:25,462][meta_train][INFO] - Epoch 56/100, iter 5/8, train loss=4.6207, lr=0.0001
[2025-05-06 17:24:47,099][meta_train][INFO] - Epoch 56/100, iter 6/8, train loss=4.8498, lr=0.0001
[2025-05-06 17:25:08,574][meta_train][INFO] - Epoch 56/100, iter 7/8, train loss=4.8021, lr=0.0001
[2025-05-06 17:25:30,122][meta_train][INFO] - Epoch 56/100, iter 8/8, train loss=5.0312, lr=0.0001
[2025-05-06 17:25:30,148][meta_train][INFO] - epoch_56 saved !
[2025-05-06 17:25:51,321][meta_train][INFO] - Epoch 57/100, iter 1/8, train loss=4.7831, lr=0.0001
[2025-05-06 17:26:13,137][meta_train][INFO] - Epoch 57/100, iter 2/8, train loss=4.8484, lr=0.0001
[2025-05-06 17:26:33,970][meta_train][INFO] - Epoch 57/100, iter 3/8, train loss=4.6200, lr=0.0001
[2025-05-06 17:26:54,957][meta_train][INFO] - Epoch 57/100, iter 4/8, train loss=4.6868, lr=0.0001
[2025-05-06 17:27:16,276][meta_train][INFO] - Epoch 57/100, iter 5/8, train loss=4.7900, lr=0.0001
[2025-05-06 17:27:37,625][meta_train][INFO] - Epoch 57/100, iter 6/8, train loss=4.9796, lr=0.0001
[2025-05-06 17:27:58,500][meta_train][INFO] - Epoch 57/100, iter 7/8, train loss=4.9009, lr=0.0001
[2025-05-06 17:28:21,700][meta_train][INFO] - Epoch 57/100, iter 8/8, train loss=4.7913, lr=0.0001
[2025-05-06 17:28:21,726][meta_train][INFO] - epoch_57 saved !
[2025-05-06 17:28:42,538][meta_train][INFO] - Epoch 58/100, iter 1/8, train loss=4.6728, lr=0.0001
[2025-05-06 17:28:48,639][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-06 17:28:48,689][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 17:28:48,690][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 17:28:48,690][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 17:28:53,565][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 30

[2025-05-06 17:28:53,645][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 17:28:53,645][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 17:28:53,645][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 17:29:00,813][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 17:29:05,965][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 17:29:08,183][train][INFO] - Epoch 1/100, Val Acc=0.0527, Val Loss=4.0471, lr=0.0100
[2025-05-06 17:29:10,501][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Oneal
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 35

[2025-05-06 17:29:10,569][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 17:29:10,569][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 17:29:10,569][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 17:29:14,047][train][INFO] - Epoch 1/100, Val Acc=0.0405, Val Loss=4.1783, lr=0.0100
[2025-05-06 17:29:16,121][train][INFO] - Epoch 2/100, Val Acc=0.1575, Val Loss=3.4341, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 17:29:21,433][train][INFO] - Epoch 2/100, Val Acc=0.0477, Val Loss=4.0210, lr=0.0100
[2025-05-06 17:29:23,713][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 17:29:23,893][train][INFO] - Epoch 3/100, Val Acc=0.2578, Val Loss=2.8953, lr=0.0100
[2025-05-06 17:29:28,846][train][INFO] - Epoch 3/100, Val Acc=0.1248, Val Loss=3.4397, lr=0.0100
[2025-05-06 17:29:30,895][train][INFO] - Epoch 4/100, Val Acc=0.3567, Val Loss=2.3446, lr=0.0100
[2025-05-06 17:29:31,135][train][INFO] - Epoch 1/100, Val Acc=0.0405, Val Loss=4.1331, lr=0.0100
[2025-05-06 17:29:36,203][train][INFO] - Epoch 4/100, Val Acc=0.1948, Val Loss=3.0787, lr=0.0100
[2025-05-06 17:29:38,421][train][INFO] - Epoch 5/100, Val Acc=0.4064, Val Loss=2.2144, lr=0.0100
[2025-05-06 17:29:38,615][train][INFO] - Epoch 2/100, Val Acc=0.0798, Val Loss=3.8156, lr=0.0100
[2025-05-06 17:29:43,738][train][INFO] - Epoch 5/100, Val Acc=0.2257, Val Loss=3.0619, lr=0.0100
[2025-05-06 17:29:45,395][train][INFO] - Epoch 6/100, Val Acc=0.4341, Val Loss=2.1022, lr=0.0100
[2025-05-06 17:29:46,124][train][INFO] - Epoch 3/100, Val Acc=0.1089, Val Loss=3.5765, lr=0.0100
[2025-05-06 17:29:50,646][train][INFO] - Epoch 6/100, Val Acc=0.2472, Val Loss=2.8372, lr=0.0100
[2025-05-06 17:29:53,091][train][INFO] - Epoch 7/100, Val Acc=0.4833, Val Loss=1.9266, lr=0.0100
[2025-05-06 17:29:53,868][train][INFO] - Epoch 4/100, Val Acc=0.1649, Val Loss=3.3643, lr=0.0100
[2025-05-06 17:29:58,190][train][INFO] - Epoch 7/100, Val Acc=0.3226, Val Loss=2.4961, lr=0.0100
[2025-05-06 17:29:59,959][train][INFO] - Epoch 8/100, Val Acc=0.4807, Val Loss=1.9690, lr=0.0100
[2025-05-06 17:30:01,633][train][INFO] - Epoch 5/100, Val Acc=0.2012, Val Loss=3.0359, lr=0.0100
[2025-05-06 17:30:05,371][train][INFO] - Epoch 8/100, Val Acc=0.3347, Val Loss=2.4860, lr=0.0100
[2025-05-06 17:30:06,780][train][INFO] - Epoch 9/100, Val Acc=0.5091, Val Loss=1.8849, lr=0.0100
[2025-05-06 17:30:08,888][train][INFO] - Epoch 6/100, Val Acc=0.2542, Val Loss=2.7540, lr=0.0100
[2025-05-06 17:30:12,533][train][INFO] - Epoch 9/100, Val Acc=0.3596, Val Loss=2.4299, lr=0.0100
[2025-05-06 17:30:14,132][train][INFO] - Epoch 10/100, Val Acc=0.4968, Val Loss=2.0111, lr=0.0100
[2025-05-06 17:30:16,130][train][INFO] - Epoch 7/100, Val Acc=0.2751, Val Loss=2.6544, lr=0.0100
[2025-05-06 17:30:19,685][train][INFO] - Epoch 10/100, Val Acc=0.3708, Val Loss=2.4871, lr=0.0100
[2025-05-06 17:30:21,651][train][INFO] - Epoch 11/100, Val Acc=0.5458, Val Loss=1.7306, lr=0.0100
[2025-05-06 17:30:23,485][train][INFO] - Epoch 8/100, Val Acc=0.2798, Val Loss=2.7824, lr=0.0100
[2025-05-06 17:30:26,571][train][INFO] - Epoch 11/100, Val Acc=0.3836, Val Loss=2.3439, lr=0.0100
[2025-05-06 17:30:28,635][train][INFO] - Epoch 12/100, Val Acc=0.5366, Val Loss=1.7930, lr=0.0100
[2025-05-06 17:30:31,170][train][INFO] - Epoch 9/100, Val Acc=0.2663, Val Loss=2.8498, lr=0.0100
[2025-05-06 17:30:33,513][train][INFO] - Epoch 12/100, Val Acc=0.4171, Val Loss=2.1571, lr=0.0100
[2025-05-06 17:30:35,951][train][INFO] - Epoch 13/100, Val Acc=0.5439, Val Loss=1.7295, lr=0.0100
[2025-05-06 17:30:38,741][train][INFO] - Epoch 10/100, Val Acc=0.3206, Val Loss=2.5734, lr=0.0100
[2025-05-06 17:30:40,282][train][INFO] - Epoch 13/100, Val Acc=0.4307, Val Loss=2.0983, lr=0.0100
[2025-05-06 17:30:43,700][train][INFO] - Epoch 14/100, Val Acc=0.5762, Val Loss=1.6402, lr=0.0100
[2025-05-06 17:30:46,158][train][INFO] - Epoch 11/100, Val Acc=0.3664, Val Loss=2.3258, lr=0.0100
[2025-05-06 17:30:47,536][train][INFO] - Epoch 14/100, Val Acc=0.4410, Val Loss=2.1212, lr=0.0100
[2025-05-06 17:30:50,820][train][INFO] - Epoch 15/100, Val Acc=0.5730, Val Loss=1.6774, lr=0.0100
[2025-05-06 17:30:53,664][train][INFO] - Epoch 12/100, Val Acc=0.3605, Val Loss=2.3859, lr=0.0100
[2025-05-06 17:30:54,742][train][INFO] - Epoch 15/100, Val Acc=0.4482, Val Loss=2.0822, lr=0.0100
[2025-05-06 17:30:57,992][train][INFO] - Epoch 16/100, Val Acc=0.5414, Val Loss=1.8727, lr=0.0100
[2025-05-06 17:31:00,927][train][INFO] - Epoch 13/100, Val Acc=0.3775, Val Loss=2.3726, lr=0.0100
[2025-05-06 17:31:02,093][train][INFO] - Epoch 16/100, Val Acc=0.4286, Val Loss=2.2831, lr=0.0100
[2025-05-06 17:31:05,245][train][INFO] - Epoch 17/100, Val Acc=0.5925, Val Loss=1.5949, lr=0.0100
[2025-05-06 17:31:08,717][train][INFO] - Epoch 14/100, Val Acc=0.4097, Val Loss=2.2197, lr=0.0100
[2025-05-06 17:31:09,061][train][INFO] - Epoch 17/100, Val Acc=0.4415, Val Loss=2.2133, lr=0.0100
[2025-05-06 17:31:12,545][train][INFO] - Epoch 18/100, Val Acc=0.5446, Val Loss=1.8677, lr=0.0100
[2025-05-06 17:31:16,406][train][INFO] - Epoch 18/100, Val Acc=0.5147, Val Loss=1.8076, lr=0.0100
[2025-05-06 17:31:16,494][train][INFO] - Epoch 15/100, Val Acc=0.4270, Val Loss=2.1528, lr=0.0100
[2025-05-06 17:31:19,551][train][INFO] - Epoch 19/100, Val Acc=0.5934, Val Loss=1.6156, lr=0.0100
[2025-05-06 17:31:23,675][train][INFO] - Epoch 19/100, Val Acc=0.4449, Val Loss=2.2541, lr=0.0100
[2025-05-06 17:31:23,843][train][INFO] - Epoch 16/100, Val Acc=0.4072, Val Loss=2.2096, lr=0.0100
[2025-05-06 17:31:26,618][train][INFO] - Epoch 20/100, Val Acc=0.5690, Val Loss=1.7857, lr=0.0100
[2025-05-06 17:31:30,937][train][INFO] - Epoch 20/100, Val Acc=0.4903, Val Loss=1.9486, lr=0.0100
[2025-05-06 17:31:31,481][train][INFO] - Epoch 17/100, Val Acc=0.4143, Val Loss=2.2224, lr=0.0100
[2025-05-06 17:31:34,222][train][INFO] - Epoch 21/100, Val Acc=0.5986, Val Loss=1.6404, lr=0.0100
[2025-05-06 17:31:38,202][train][INFO] - Epoch 21/100, Val Acc=0.5288, Val Loss=1.7840, lr=0.0100
[2025-05-06 17:31:39,215][train][INFO] - Epoch 18/100, Val Acc=0.4162, Val Loss=2.1665, lr=0.0100
[2025-05-06 17:31:41,241][train][INFO] - Epoch 22/100, Val Acc=0.5898, Val Loss=1.7060, lr=0.0100
[2025-05-06 17:31:44,890][train][INFO] - Epoch 22/100, Val Acc=0.5136, Val Loss=1.8506, lr=0.0100
[2025-05-06 17:31:47,027][train][INFO] - Epoch 19/100, Val Acc=0.4335, Val Loss=2.1106, lr=0.0100
[2025-05-06 17:31:48,182][train][INFO] - Epoch 23/100, Val Acc=0.5724, Val Loss=1.7361, lr=0.0100
[2025-05-06 17:31:52,178][train][INFO] - Epoch 23/100, Val Acc=0.5173, Val Loss=1.8432, lr=0.0100
[2025-05-06 17:31:54,896][train][INFO] - Epoch 20/100, Val Acc=0.4653, Val Loss=1.9665, lr=0.0100
[2025-05-06 17:31:55,245][train][INFO] - Epoch 24/100, Val Acc=0.5969, Val Loss=1.6302, lr=0.0100
[2025-05-06 17:31:59,138][train][INFO] - Epoch 24/100, Val Acc=0.5291, Val Loss=1.8401, lr=0.0100
[2025-05-06 17:32:02,304][train][INFO] - Epoch 21/100, Val Acc=0.4683, Val Loss=1.9809, lr=0.0100
[2025-05-06 17:32:02,409][train][INFO] - Epoch 25/100, Val Acc=0.6027, Val Loss=1.6393, lr=0.0100
[2025-05-06 17:32:06,297][train][INFO] - Epoch 25/100, Val Acc=0.5244, Val Loss=1.8550, lr=0.0100
[2025-05-06 17:32:09,651][train][INFO] - Epoch 26/100, Val Acc=0.6032, Val Loss=1.6518, lr=0.0100
[2025-05-06 17:32:09,754][train][INFO] - Epoch 22/100, Val Acc=0.4627, Val Loss=1.9854, lr=0.0100
[2025-05-06 17:32:13,799][train][INFO] - Epoch 26/100, Val Acc=0.5225, Val Loss=1.9140, lr=0.0100
[2025-05-06 17:32:16,350][train][INFO] - Epoch 27/100, Val Acc=0.6186, Val Loss=1.5657, lr=0.0100
[2025-05-06 17:32:17,441][train][INFO] - Epoch 23/100, Val Acc=0.4716, Val Loss=1.9832, lr=0.0100
[2025-05-06 17:32:20,910][train][INFO] - Epoch 27/100, Val Acc=0.5455, Val Loss=1.7437, lr=0.0100
[2025-05-06 17:32:23,870][train][INFO] - Epoch 28/100, Val Acc=0.5985, Val Loss=1.6753, lr=0.0100
[2025-05-06 17:32:25,158][train][INFO] - Epoch 24/100, Val Acc=0.4752, Val Loss=1.9557, lr=0.0100
[2025-05-06 17:32:28,231][train][INFO] - Epoch 28/100, Val Acc=0.5366, Val Loss=1.7969, lr=0.0100
[2025-05-06 17:32:31,283][train][INFO] - Epoch 29/100, Val Acc=0.6217, Val Loss=1.5252, lr=0.0100
[2025-05-06 17:32:32,722][train][INFO] - Epoch 25/100, Val Acc=0.4867, Val Loss=1.9072, lr=0.0100
[2025-05-06 17:32:35,101][train][INFO] - Epoch 29/100, Val Acc=0.5406, Val Loss=1.7885, lr=0.0100
[2025-05-06 17:32:38,379][train][INFO] - Epoch 30/100, Val Acc=0.6077, Val Loss=1.6367, lr=0.0100
[2025-05-06 17:32:40,107][train][INFO] - Epoch 26/100, Val Acc=0.4768, Val Loss=2.0058, lr=0.0100
[2025-05-06 17:32:42,184][train][INFO] - Epoch 30/100, Val Acc=0.5525, Val Loss=1.7622, lr=0.0100
[2025-05-06 17:32:45,597][train][INFO] - Epoch 31/100, Val Acc=0.6091, Val Loss=1.6752, lr=0.0100
[2025-05-06 17:32:47,771][train][INFO] - Epoch 27/100, Val Acc=0.4910, Val Loss=1.8953, lr=0.0100
[2025-05-06 17:32:49,465][train][INFO] - Epoch 31/100, Val Acc=0.5756, Val Loss=1.6356, lr=0.0100
[2025-05-06 17:32:53,315][train][INFO] - Epoch 32/100, Val Acc=0.6109, Val Loss=1.6628, lr=0.0100
[2025-05-06 17:32:55,222][train][INFO] - Epoch 28/100, Val Acc=0.4918, Val Loss=1.8828, lr=0.0100
[2025-05-06 17:32:57,105][train][INFO] - Epoch 32/100, Val Acc=0.5454, Val Loss=1.8600, lr=0.0100
[2025-05-06 17:33:00,714][train][INFO] - Epoch 33/100, Val Acc=0.6192, Val Loss=1.6314, lr=0.0100
[2025-05-06 17:33:02,818][train][INFO] - Epoch 29/100, Val Acc=0.4835, Val Loss=1.9564, lr=0.0100
[2025-05-06 17:33:04,032][train][INFO] - Epoch 33/100, Val Acc=0.5542, Val Loss=1.7579, lr=0.0100
[2025-05-06 17:33:07,947][train][INFO] - Epoch 34/100, Val Acc=0.6222, Val Loss=1.5898, lr=0.0100
[2025-05-06 17:33:10,037][train][INFO] - Epoch 30/100, Val Acc=0.5070, Val Loss=1.8427, lr=0.0100
[2025-05-06 17:33:10,973][train][INFO] - Epoch 34/100, Val Acc=0.5549, Val Loss=1.7605, lr=0.0100
[2025-05-06 17:33:14,977][train][INFO] - Epoch 35/100, Val Acc=0.6250, Val Loss=1.5746, lr=0.0100
[2025-05-06 17:33:17,449][train][INFO] - Epoch 31/100, Val Acc=0.5163, Val Loss=1.7789, lr=0.0100
[2025-05-06 17:33:17,844][train][INFO] - Epoch 35/100, Val Acc=0.5651, Val Loss=1.7282, lr=0.0100
[2025-05-06 17:33:22,315][train][INFO] - Epoch 36/100, Val Acc=0.6099, Val Loss=1.6486, lr=0.0100
[2025-05-06 17:33:24,927][train][INFO] - Epoch 36/100, Val Acc=0.5630, Val Loss=1.7407, lr=0.0100
[2025-05-06 17:33:25,158][train][INFO] - Epoch 32/100, Val Acc=0.5128, Val Loss=1.8016, lr=0.0100
[2025-05-06 17:33:29,786][train][INFO] - Epoch 37/100, Val Acc=0.6228, Val Loss=1.6104, lr=0.0100
[2025-05-06 17:33:32,226][train][INFO] - Epoch 37/100, Val Acc=0.5675, Val Loss=1.7537, lr=0.0100
[2025-05-06 17:33:32,780][train][INFO] - Epoch 33/100, Val Acc=0.5024, Val Loss=1.8765, lr=0.0100
[2025-05-06 17:33:36,462][train][INFO] - Epoch 38/100, Val Acc=0.5942, Val Loss=1.7795, lr=0.0100
[2025-05-06 17:33:39,550][train][INFO] - Epoch 38/100, Val Acc=0.5795, Val Loss=1.6534, lr=0.0100
[2025-05-06 17:33:39,725][train][INFO] - Epoch 34/100, Val Acc=0.5199, Val Loss=1.8088, lr=0.0100
[2025-05-06 17:33:43,590][train][INFO] - Epoch 39/100, Val Acc=0.6143, Val Loss=1.7129, lr=0.0100
[2025-05-06 17:33:46,533][train][INFO] - Epoch 39/100, Val Acc=0.5724, Val Loss=1.7435, lr=0.0100
[2025-05-06 17:33:47,433][train][INFO] - Epoch 35/100, Val Acc=0.5436, Val Loss=1.7213, lr=0.0100
[2025-05-06 17:33:51,008][train][INFO] - Epoch 40/100, Val Acc=0.6191, Val Loss=1.6378, lr=0.0100
[2025-05-06 17:33:53,364][train][INFO] - Epoch 40/100, Val Acc=0.5512, Val Loss=1.8340, lr=0.0100
[2025-05-06 17:33:54,798][train][INFO] - Epoch 36/100, Val Acc=0.5178, Val Loss=1.8017, lr=0.0100
[2025-05-06 17:33:58,147][train][INFO] - Epoch 41/100, Val Acc=0.6213, Val Loss=1.6553, lr=0.0100
[2025-05-06 17:34:00,499][train][INFO] - Epoch 41/100, Val Acc=0.5715, Val Loss=1.7299, lr=0.0100
[2025-05-06 17:34:01,776][train][INFO] - Epoch 37/100, Val Acc=0.5343, Val Loss=1.7737, lr=0.0100
[2025-05-06 17:34:05,054][train][INFO] - Epoch 42/100, Val Acc=0.6097, Val Loss=1.7391, lr=0.0100
[2025-05-06 17:34:06,818][train][INFO] - Epoch 42/100, Val Acc=0.5617, Val Loss=1.7944, lr=0.0100
[2025-05-06 17:34:08,666][train][INFO] - Epoch 38/100, Val Acc=0.5348, Val Loss=1.7586, lr=0.0100
[2025-05-06 17:34:12,018][train][INFO] - Epoch 43/100, Val Acc=0.6247, Val Loss=1.6372, lr=0.0100
[2025-05-06 17:34:14,210][train][INFO] - Epoch 43/100, Val Acc=0.5958, Val Loss=1.6189, lr=0.0100
[2025-05-06 17:34:16,420][train][INFO] - Epoch 39/100, Val Acc=0.5255, Val Loss=1.7446, lr=0.0100
[2025-05-06 17:34:19,320][train][INFO] - Epoch 44/100, Val Acc=0.6304, Val Loss=1.6029, lr=0.0100
[2025-05-06 17:34:21,031][train][INFO] - Epoch 44/100, Val Acc=0.5884, Val Loss=1.6709, lr=0.0100
[2025-05-06 17:34:23,389][train][INFO] - Epoch 40/100, Val Acc=0.5210, Val Loss=1.8231, lr=0.0100
[2025-05-06 17:34:26,287][train][INFO] - Epoch 45/100, Val Acc=0.6271, Val Loss=1.6426, lr=0.0100
[2025-05-06 17:34:28,146][train][INFO] - Epoch 45/100, Val Acc=0.5688, Val Loss=1.7709, lr=0.0100
[2025-05-06 17:34:30,849][train][INFO] - Epoch 41/100, Val Acc=0.5262, Val Loss=1.8105, lr=0.0100
[2025-05-06 17:34:33,174][train][INFO] - Epoch 46/100, Val Acc=0.6328, Val Loss=1.5949, lr=0.0100
[2025-05-06 17:34:35,243][train][INFO] - Epoch 46/100, Val Acc=0.5755, Val Loss=1.7442, lr=0.0100
[2025-05-06 17:34:38,768][train][INFO] - Epoch 42/100, Val Acc=0.4934, Val Loss=1.9813, lr=0.0100
[2025-05-06 17:34:40,726][train][INFO] - Epoch 47/100, Val Acc=0.6317, Val Loss=1.6198, lr=0.0100
[2025-05-06 17:34:42,973][train][INFO] - Epoch 47/100, Val Acc=0.5585, Val Loss=1.8112, lr=0.0100
[2025-05-06 17:34:46,317][train][INFO] - Epoch 43/100, Val Acc=0.5396, Val Loss=1.7399, lr=0.0100
[2025-05-06 17:34:48,015][train][INFO] - Epoch 48/100, Val Acc=0.6116, Val Loss=1.7213, lr=0.0100
[2025-05-06 17:34:50,207][train][INFO] - Epoch 48/100, Val Acc=0.5860, Val Loss=1.6817, lr=0.0100
[2025-05-06 17:34:53,556][train][INFO] - Epoch 44/100, Val Acc=0.5535, Val Loss=1.6790, lr=0.0100
[2025-05-06 17:34:55,367][train][INFO] - Epoch 49/100, Val Acc=0.6226, Val Loss=1.6977, lr=0.0100
[2025-05-06 17:34:57,608][train][INFO] - Epoch 49/100, Val Acc=0.5863, Val Loss=1.7155, lr=0.0100
[2025-05-06 17:35:00,748][train][INFO] - Epoch 45/100, Val Acc=0.5158, Val Loss=1.8976, lr=0.0100
[2025-05-06 17:35:02,879][train][INFO] - Epoch 50/100, Val Acc=0.6254, Val Loss=1.6612, lr=0.0100
[2025-05-06 17:35:05,009][train][INFO] - Epoch 50/100, Val Acc=0.5853, Val Loss=1.7125, lr=0.0100
[2025-05-06 17:35:08,427][train][INFO] - Epoch 46/100, Val Acc=0.5327, Val Loss=1.8130, lr=0.0100
[2025-05-06 17:35:10,044][train][INFO] - Epoch 51/100, Val Acc=0.6150, Val Loss=1.7125, lr=0.0100
[2025-05-06 17:35:12,098][train][INFO] - Epoch 51/100, Val Acc=0.5956, Val Loss=1.6916, lr=0.0100
[2025-05-06 17:35:15,916][train][INFO] - Epoch 47/100, Val Acc=0.5384, Val Loss=1.7578, lr=0.0100
[2025-05-06 17:35:16,908][train][INFO] - Epoch 52/100, Val Acc=0.6111, Val Loss=1.7924, lr=0.0100
[2025-05-06 17:35:18,659][train][INFO] - Epoch 52/100, Val Acc=0.5740, Val Loss=1.7704, lr=0.0100
[2025-05-06 17:35:23,770][train][INFO] - Epoch 48/100, Val Acc=0.5486, Val Loss=1.7082, lr=0.0100
[2025-05-06 17:35:23,966][train][INFO] - Epoch 53/100, Val Acc=0.6370, Val Loss=1.6356, lr=0.0100
[2025-05-06 17:35:25,919][train][INFO] - Epoch 53/100, Val Acc=0.5940, Val Loss=1.6973, lr=0.0100
[2025-05-06 17:35:31,181][train][INFO] - Epoch 54/100, Val Acc=0.6283, Val Loss=1.6452, lr=0.0100
[2025-05-06 17:35:31,342][train][INFO] - Epoch 49/100, Val Acc=0.5624, Val Loss=1.7051, lr=0.0100
[2025-05-06 17:35:33,166][train][INFO] - Epoch 54/100, Val Acc=0.5714, Val Loss=1.7559, lr=0.0100
[2025-05-06 17:35:38,797][train][INFO] - Epoch 55/100, Val Acc=0.6324, Val Loss=1.6645, lr=0.0100
[2025-05-06 17:35:38,877][train][INFO] - Epoch 50/100, Val Acc=0.5375, Val Loss=1.8098, lr=0.0100
[2025-05-06 17:35:40,560][train][INFO] - Epoch 55/100, Val Acc=0.5778, Val Loss=1.7526, lr=0.0100
[2025-05-06 17:35:46,452][train][INFO] - Epoch 56/100, Val Acc=0.6301, Val Loss=1.6798, lr=0.0100
[2025-05-06 17:35:46,578][train][INFO] - Epoch 51/100, Val Acc=0.5478, Val Loss=1.7649, lr=0.0100
[2025-05-06 17:35:47,848][train][INFO] - Epoch 56/100, Val Acc=0.5718, Val Loss=1.8556, lr=0.0100
[2025-05-06 17:35:53,998][train][INFO] - Epoch 57/100, Val Acc=0.6113, Val Loss=1.7676, lr=0.0100
[2025-05-06 17:35:54,440][train][INFO] - Epoch 52/100, Val Acc=0.5084, Val Loss=1.9679, lr=0.0100
[2025-05-06 17:35:55,313][train][INFO] - Epoch 57/100, Val Acc=0.5802, Val Loss=1.7823, lr=0.0100
[2025-05-06 17:36:00,858][train][INFO] - Epoch 58/100, Val Acc=0.6341, Val Loss=1.6378, lr=0.0100
[2025-05-06 17:36:02,204][train][INFO] - Epoch 53/100, Val Acc=0.5723, Val Loss=1.6338, lr=0.0100
[2025-05-06 17:36:02,365][train][INFO] - Epoch 58/100, Val Acc=0.5897, Val Loss=1.7147, lr=0.0100
[2025-05-06 17:36:08,491][train][INFO] - Epoch 59/100, Val Acc=0.6161, Val Loss=1.7573, lr=0.0100
[2025-05-06 17:36:09,729][train][INFO] - Epoch 59/100, Val Acc=0.5869, Val Loss=1.7844, lr=0.0100
[2025-05-06 17:36:09,805][train][INFO] - Epoch 54/100, Val Acc=0.5392, Val Loss=1.7412, lr=0.0100
[2025-05-06 17:36:15,729][train][INFO] - Epoch 60/100, Val Acc=0.6288, Val Loss=1.6902, lr=0.0100
[2025-05-06 17:36:17,031][train][INFO] - Epoch 60/100, Val Acc=0.5950, Val Loss=1.6572, lr=0.0100
[2025-05-06 17:36:17,576][train][INFO] - Epoch 55/100, Val Acc=0.5609, Val Loss=1.6943, lr=0.0100
[2025-05-06 17:36:22,900][train][INFO] - Epoch 61/100, Val Acc=0.6859, Val Loss=1.3624, lr=0.0010
[2025-05-06 17:36:24,466][train][INFO] - Epoch 61/100, Val Acc=0.6600, Val Loss=1.3755, lr=0.0010
[2025-05-06 17:36:24,955][train][INFO] - Epoch 56/100, Val Acc=0.5533, Val Loss=1.7652, lr=0.0100
[2025-05-06 17:36:29,960][train][INFO] - Epoch 62/100, Val Acc=0.6925, Val Loss=1.3546, lr=0.0010
[2025-05-06 17:36:31,487][train][INFO] - Epoch 62/100, Val Acc=0.6639, Val Loss=1.3731, lr=0.0010
[2025-05-06 17:36:32,610][train][INFO] - Epoch 57/100, Val Acc=0.5509, Val Loss=1.7313, lr=0.0100
[2025-05-06 17:36:37,557][train][INFO] - Epoch 63/100, Val Acc=0.6909, Val Loss=1.3660, lr=0.0010
[2025-05-06 17:36:38,488][train][INFO] - Epoch 63/100, Val Acc=0.6654, Val Loss=1.3775, lr=0.0010
[2025-05-06 17:36:40,379][train][INFO] - Epoch 58/100, Val Acc=0.5641, Val Loss=1.6495, lr=0.0100
[2025-05-06 17:36:44,781][train][INFO] - Epoch 64/100, Val Acc=0.6897, Val Loss=1.3714, lr=0.0010
[2025-05-06 17:36:45,574][train][INFO] - Epoch 64/100, Val Acc=0.6656, Val Loss=1.3806, lr=0.0010
[2025-05-06 17:36:47,660][train][INFO] - Epoch 59/100, Val Acc=0.5448, Val Loss=1.7574, lr=0.0100
[2025-05-06 17:36:51,920][train][INFO] - Epoch 65/100, Val Acc=0.6916, Val Loss=1.3788, lr=0.0010
[2025-05-06 17:36:52,612][train][INFO] - Epoch 65/100, Val Acc=0.6708, Val Loss=1.3764, lr=0.0010
[2025-05-06 17:36:55,073][train][INFO] - Epoch 60/100, Val Acc=0.5507, Val Loss=1.7697, lr=0.0100
[2025-05-06 17:36:59,262][train][INFO] - Epoch 66/100, Val Acc=0.6935, Val Loss=1.3879, lr=0.0010
[2025-05-06 17:36:59,764][train][INFO] - Epoch 66/100, Val Acc=0.6666, Val Loss=1.3951, lr=0.0010
[2025-05-06 17:37:02,202][train][INFO] - Epoch 61/100, Val Acc=0.6259, Val Loss=1.3913, lr=0.0010
[2025-05-06 17:37:06,790][train][INFO] - Epoch 67/100, Val Acc=0.6653, Val Loss=1.4014, lr=0.0010
[2025-05-06 17:37:06,816][train][INFO] - Epoch 67/100, Val Acc=0.6942, Val Loss=1.3978, lr=0.0010
[2025-05-06 17:37:09,472][train][INFO] - Epoch 62/100, Val Acc=0.6289, Val Loss=1.3857, lr=0.0010
[2025-05-06 17:37:14,042][train][INFO] - Epoch 68/100, Val Acc=0.6692, Val Loss=1.4078, lr=0.0010
[2025-05-06 17:37:14,120][train][INFO] - Epoch 68/100, Val Acc=0.6933, Val Loss=1.3994, lr=0.0010
[2025-05-06 17:37:17,055][train][INFO] - Epoch 63/100, Val Acc=0.6295, Val Loss=1.3895, lr=0.0010
[2025-05-06 17:37:20,959][train][INFO] - Epoch 69/100, Val Acc=0.6720, Val Loss=1.4032, lr=0.0010
[2025-05-06 17:37:21,675][train][INFO] - Epoch 69/100, Val Acc=0.6939, Val Loss=1.4037, lr=0.0010
[2025-05-06 17:37:24,537][train][INFO] - Epoch 64/100, Val Acc=0.6293, Val Loss=1.3888, lr=0.0010
[2025-05-06 17:37:28,532][train][INFO] - Epoch 70/100, Val Acc=0.6691, Val Loss=1.4146, lr=0.0010
[2025-05-06 17:37:29,001][train][INFO] - Epoch 70/100, Val Acc=0.6955, Val Loss=1.4121, lr=0.0010
[2025-05-06 17:37:31,839][train][INFO] - Epoch 65/100, Val Acc=0.6330, Val Loss=1.3980, lr=0.0010
[2025-05-06 17:37:35,703][train][INFO] - Epoch 71/100, Val Acc=0.6718, Val Loss=1.4165, lr=0.0010
[2025-05-06 17:37:36,397][train][INFO] - Epoch 71/100, Val Acc=0.6938, Val Loss=1.4271, lr=0.0010
[2025-05-06 17:37:39,310][train][INFO] - Epoch 66/100, Val Acc=0.6310, Val Loss=1.3907, lr=0.0010
[2025-05-06 17:37:43,151][train][INFO] - Epoch 72/100, Val Acc=0.6689, Val Loss=1.4344, lr=0.0010
[2025-05-06 17:37:43,390][train][INFO] - Epoch 72/100, Val Acc=0.6909, Val Loss=1.4338, lr=0.0010
[2025-05-06 17:37:47,060][train][INFO] - Epoch 67/100, Val Acc=0.6277, Val Loss=1.4006, lr=0.0010
[2025-05-06 17:37:50,554][train][INFO] - Epoch 73/100, Val Acc=0.6733, Val Loss=1.4268, lr=0.0010
[2025-05-06 17:37:51,021][train][INFO] - Epoch 73/100, Val Acc=0.6921, Val Loss=1.4332, lr=0.0010
[2025-05-06 17:37:54,836][train][INFO] - Epoch 68/100, Val Acc=0.6310, Val Loss=1.4065, lr=0.0010
[2025-05-06 17:37:57,939][train][INFO] - Epoch 74/100, Val Acc=0.6670, Val Loss=1.4551, lr=0.0010
[2025-05-06 17:37:58,706][train][INFO] - Epoch 74/100, Val Acc=0.6931, Val Loss=1.4411, lr=0.0010
[2025-05-06 17:38:02,775][train][INFO] - Epoch 69/100, Val Acc=0.6299, Val Loss=1.4088, lr=0.0010
[2025-05-06 17:38:04,888][train][INFO] - Epoch 75/100, Val Acc=0.6667, Val Loss=1.4489, lr=0.0010
[2025-05-06 17:38:06,298][train][INFO] - Epoch 75/100, Val Acc=0.6949, Val Loss=1.4409, lr=0.0010
[2025-05-06 17:38:10,922][train][INFO] - Epoch 70/100, Val Acc=0.6329, Val Loss=1.4074, lr=0.0010
[2025-05-06 17:38:12,207][train][INFO] - Epoch 76/100, Val Acc=0.6716, Val Loss=1.4496, lr=0.0010
[2025-05-06 17:38:13,505][train][INFO] - Epoch 76/100, Val Acc=0.6929, Val Loss=1.4422, lr=0.0010
[2025-05-06 17:38:18,526][train][INFO] - Epoch 71/100, Val Acc=0.6327, Val Loss=1.4137, lr=0.0010
[2025-05-06 17:38:19,691][train][INFO] - Epoch 77/100, Val Acc=0.6635, Val Loss=1.4718, lr=0.0010
[2025-05-06 17:38:21,282][train][INFO] - Epoch 77/100, Val Acc=0.6946, Val Loss=1.4524, lr=0.0010
[2025-05-06 17:38:25,820][train][INFO] - Epoch 72/100, Val Acc=0.6365, Val Loss=1.4191, lr=0.0010
[2025-05-06 17:38:27,166][train][INFO] - Epoch 78/100, Val Acc=0.6679, Val Loss=1.4675, lr=0.0010
[2025-05-06 17:38:28,626][train][INFO] - Epoch 78/100, Val Acc=0.6951, Val Loss=1.4561, lr=0.0010
[2025-05-06 17:38:33,613][train][INFO] - Epoch 73/100, Val Acc=0.6306, Val Loss=1.4147, lr=0.0010
[2025-05-06 17:38:34,682][train][INFO] - Epoch 79/100, Val Acc=0.6669, Val Loss=1.4764, lr=0.0010
[2025-05-06 17:38:36,149][train][INFO] - Epoch 79/100, Val Acc=0.6945, Val Loss=1.4581, lr=0.0010
[2025-05-06 17:38:41,587][train][INFO] - Epoch 74/100, Val Acc=0.6346, Val Loss=1.4242, lr=0.0010
[2025-05-06 17:38:41,830][train][INFO] - Epoch 80/100, Val Acc=0.6654, Val Loss=1.4913, lr=0.0010
[2025-05-06 17:38:43,231][train][INFO] - Epoch 80/100, Val Acc=0.6949, Val Loss=1.4647, lr=0.0010
[2025-05-06 17:38:49,005][train][INFO] - Epoch 81/100, Val Acc=0.6683, Val Loss=1.4919, lr=0.0010
[2025-05-06 17:38:49,009][train][INFO] - Epoch 75/100, Val Acc=0.6353, Val Loss=1.4204, lr=0.0010
[2025-05-06 17:38:50,572][train][INFO] - Epoch 81/100, Val Acc=0.6932, Val Loss=1.4660, lr=0.0010
[2025-05-06 17:38:56,518][train][INFO] - Epoch 82/100, Val Acc=0.6683, Val Loss=1.4970, lr=0.0010
[2025-05-06 17:38:56,857][train][INFO] - Epoch 76/100, Val Acc=0.6335, Val Loss=1.4259, lr=0.0010
[2025-05-06 17:38:56,906][train][INFO] - Epoch 82/100, Val Acc=0.6917, Val Loss=1.4797, lr=0.0010
[2025-05-06 17:39:03,267][train][INFO] - Epoch 83/100, Val Acc=0.6677, Val Loss=1.5016, lr=0.0010
[2025-05-06 17:39:04,397][train][INFO] - Epoch 77/100, Val Acc=0.6291, Val Loss=1.4375, lr=0.0010
[2025-05-06 17:39:04,490][train][INFO] - Epoch 83/100, Val Acc=0.6943, Val Loss=1.4833, lr=0.0010
[2025-05-06 17:39:10,360][train][INFO] - Epoch 84/100, Val Acc=0.6679, Val Loss=1.5090, lr=0.0010
[2025-05-06 17:39:11,923][train][INFO] - Epoch 84/100, Val Acc=0.6949, Val Loss=1.4804, lr=0.0010
[2025-05-06 17:39:12,079][train][INFO] - Epoch 78/100, Val Acc=0.6287, Val Loss=1.4396, lr=0.0010
[2025-05-06 17:39:17,610][train][INFO] - Epoch 85/100, Val Acc=0.6659, Val Loss=1.5265, lr=0.0010
[2025-05-06 17:39:19,022][train][INFO] - Epoch 79/100, Val Acc=0.6301, Val Loss=1.4485, lr=0.0010
[2025-05-06 17:39:19,561][train][INFO] - Epoch 85/100, Val Acc=0.6948, Val Loss=1.4905, lr=0.0010
[2025-05-06 17:39:24,267][train][INFO] - Epoch 86/100, Val Acc=0.6662, Val Loss=1.5310, lr=0.0010
[2025-05-06 17:39:26,233][train][INFO] - Epoch 80/100, Val Acc=0.6280, Val Loss=1.4542, lr=0.0010
[2025-05-06 17:39:26,395][train][INFO] - Epoch 86/100, Val Acc=0.6963, Val Loss=1.4830, lr=0.0010
[2025-05-06 17:39:31,214][train][INFO] - Epoch 87/100, Val Acc=0.6678, Val Loss=1.5311, lr=0.0010
[2025-05-06 17:39:33,810][train][INFO] - Epoch 87/100, Val Acc=0.6956, Val Loss=1.4888, lr=0.0010
[2025-05-06 17:39:34,384][train][INFO] - Epoch 81/100, Val Acc=0.6315, Val Loss=1.4563, lr=0.0010
[2025-05-06 17:39:38,041][train][INFO] - Epoch 88/100, Val Acc=0.6619, Val Loss=1.5460, lr=0.0010
[2025-05-06 17:39:40,989][train][INFO] - Epoch 88/100, Val Acc=0.6961, Val Loss=1.4899, lr=0.0010
[2025-05-06 17:39:41,849][train][INFO] - Epoch 82/100, Val Acc=0.6308, Val Loss=1.4526, lr=0.0010
[2025-05-06 17:39:44,762][train][INFO] - Epoch 89/100, Val Acc=0.6675, Val Loss=1.5418, lr=0.0010
[2025-05-06 17:39:48,483][train][INFO] - Epoch 89/100, Val Acc=0.6929, Val Loss=1.5016, lr=0.0010
[2025-05-06 17:39:49,372][train][INFO] - Epoch 83/100, Val Acc=0.6307, Val Loss=1.4598, lr=0.0010
[2025-05-06 17:39:51,796][train][INFO] - Epoch 90/100, Val Acc=0.6641, Val Loss=1.5530, lr=0.0010
[2025-05-06 17:39:55,635][train][INFO] - Epoch 90/100, Val Acc=0.6937, Val Loss=1.5026, lr=0.0010
[2025-05-06 17:39:56,735][train][INFO] - Epoch 84/100, Val Acc=0.6315, Val Loss=1.4697, lr=0.0010
[2025-05-06 17:39:58,905][train][INFO] - Epoch 91/100, Val Acc=0.6660, Val Loss=1.5405, lr=0.0001
[2025-05-06 17:40:02,725][train][INFO] - Epoch 91/100, Val Acc=0.6958, Val Loss=1.4934, lr=0.0001
[2025-05-06 17:40:04,544][train][INFO] - Epoch 85/100, Val Acc=0.6308, Val Loss=1.4798, lr=0.0010
[2025-05-06 17:40:05,967][train][INFO] - Epoch 92/100, Val Acc=0.6663, Val Loss=1.5478, lr=0.0001
[2025-05-06 17:40:09,992][train][INFO] - Epoch 92/100, Val Acc=0.6940, Val Loss=1.4959, lr=0.0001
[2025-05-06 17:40:12,410][train][INFO] - Epoch 86/100, Val Acc=0.6293, Val Loss=1.4737, lr=0.0010
[2025-05-06 17:40:13,403][train][INFO] - Epoch 93/100, Val Acc=0.6687, Val Loss=1.5362, lr=0.0001
[2025-05-06 17:40:17,090][train][INFO] - Epoch 93/100, Val Acc=0.6973, Val Loss=1.4920, lr=0.0001
[2025-05-06 17:40:19,938][train][INFO] - Epoch 87/100, Val Acc=0.6343, Val Loss=1.4775, lr=0.0010
[2025-05-06 17:40:20,363][train][INFO] - Epoch 94/100, Val Acc=0.6688, Val Loss=1.5332, lr=0.0001
[2025-05-06 17:40:24,094][train][INFO] - Epoch 94/100, Val Acc=0.6957, Val Loss=1.4909, lr=0.0001
[2025-05-06 17:40:26,956][train][INFO] - Epoch 88/100, Val Acc=0.6314, Val Loss=1.4858, lr=0.0010
[2025-05-06 17:40:27,640][train][INFO] - Epoch 95/100, Val Acc=0.6689, Val Loss=1.5324, lr=0.0001
[2025-05-06 17:40:31,592][train][INFO] - Epoch 95/100, Val Acc=0.6963, Val Loss=1.4958, lr=0.0001
[2025-05-06 17:40:34,580][train][INFO] - Epoch 89/100, Val Acc=0.6266, Val Loss=1.4981, lr=0.0010
[2025-05-06 17:40:35,235][train][INFO] - Epoch 96/100, Val Acc=0.6687, Val Loss=1.5359, lr=0.0001
[2025-05-06 17:40:38,922][train][INFO] - Epoch 96/100, Val Acc=0.6966, Val Loss=1.4880, lr=0.0001
[2025-05-06 17:40:42,260][train][INFO] - Epoch 97/100, Val Acc=0.6675, Val Loss=1.5394, lr=0.0001
[2025-05-06 17:40:42,415][train][INFO] - Epoch 90/100, Val Acc=0.6292, Val Loss=1.4930, lr=0.0010
[2025-05-06 17:40:46,086][train][INFO] - Epoch 97/100, Val Acc=0.6968, Val Loss=1.4936, lr=0.0001
[2025-05-06 17:40:49,264][train][INFO] - Epoch 98/100, Val Acc=0.6678, Val Loss=1.5379, lr=0.0001
[2025-05-06 17:40:49,639][train][INFO] - Epoch 91/100, Val Acc=0.6311, Val Loss=1.4803, lr=0.0001
[2025-05-06 17:40:53,008][train][INFO] - Epoch 98/100, Val Acc=0.6967, Val Loss=1.4879, lr=0.0001
[2025-05-06 17:40:56,270][train][INFO] - Epoch 99/100, Val Acc=0.6693, Val Loss=1.5393, lr=0.0001
[2025-05-06 17:40:56,952][train][INFO] - Epoch 92/100, Val Acc=0.6324, Val Loss=1.4818, lr=0.0001
[2025-05-06 17:40:59,968][train][INFO] - Epoch 99/100, Val Acc=0.6967, Val Loss=1.4940, lr=0.0001
[2025-05-06 17:41:03,622][train][INFO] - Epoch 100/100, Val Acc=0.6680, Val Loss=1.5430, lr=0.0001
[2025-05-06 17:41:04,366][train][INFO] - Epoch 93/100, Val Acc=0.6321, Val Loss=1.4819, lr=0.0001
[2025-05-06 17:41:07,410][train][INFO] - Epoch 100/100, Val Acc=0.6958, Val Loss=1.4883, lr=0.0001
[2025-05-06 17:41:08,602][train][INFO] - After training : Train Acc=0.9158  Val Acc=0.6733
[2025-05-06 17:41:08,615][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 17:41:11,860][train][INFO] - Epoch 94/100, Val Acc=0.6323, Val Loss=1.4746, lr=0.0001
[2025-05-06 17:41:12,553][train][INFO] - After training : Train Acc=0.9914  Val Acc=0.6973
[2025-05-06 17:41:12,559][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 17:41:19,440][train][INFO] - Epoch 95/100, Val Acc=0.6306, Val Loss=1.4816, lr=0.0001
[2025-05-06 17:41:26,752][train][INFO] - Epoch 96/100, Val Acc=0.6312, Val Loss=1.4703, lr=0.0001
[2025-05-06 17:41:34,409][train][INFO] - Epoch 97/100, Val Acc=0.6326, Val Loss=1.4777, lr=0.0001
[2025-05-06 17:41:41,818][train][INFO] - Epoch 98/100, Val Acc=0.6345, Val Loss=1.4742, lr=0.0001
[2025-05-06 17:41:48,932][train][INFO] - Epoch 99/100, Val Acc=0.6312, Val Loss=1.4818, lr=0.0001
[2025-05-06 17:41:56,311][train][INFO] - Epoch 100/100, Val Acc=0.6319, Val Loss=1.4791, lr=0.0001
[2025-05-06 17:42:01,685][train][INFO] - After training : Train Acc=0.8201  Val Acc=0.6365
[2025-05-06 17:42:01,691][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 17:42:14,602][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 17:42:22,422][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 17:43:31,835][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 17:43:50,253][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 17:43:50,721][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 17:43:51,719][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 17:43:52,247][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 17:44:53,235][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 17:44:53,670][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 18:41:06,994][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-06 18:41:07,080][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 18:41:07,080][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 18:41:07,080][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=100']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 96, in main
    all_files = os.listdir(save_dir)
FileNotFoundError: [Errno 2] No such file or directory: 'save/metanetwork/VGG19_on_CIFAR100/Iris/level_2/'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-06 18:41:30,123][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 2
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-06 18:41:30,172][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 18:41:30,172][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 18:41:30,172][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Error executing job with overrides: ['run=visualize', 'index=70']
Traceback (most recent call last):
  File "/home/liuyewei/metanetwork/meta-pruning/main/main.py", line 96, in main
    all_files = os.listdir(save_dir)
FileNotFoundError: [Errno 2] No such file or directory: 'save/metanetwork/VGG19_on_CIFAR100/Iris/level_2/'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-05-06 18:42:05,001][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-06 18:42:05,084][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 18:42:05,084][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 18:42:05,084][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 18:42:08,967][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-06 18:42:09,035][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 18:42:09,036][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 18:42:09,036][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 18:42:24,878][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 18:42:28,637][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 18:42:33,042][train][INFO] - Epoch 1/300, Val Acc=0.0477, Val Loss=4.2598, lr=0.0100
[2025-05-06 18:42:36,924][train][INFO] - Epoch 1/300, Val Acc=0.0498, Val Loss=4.0701, lr=0.0100
[2025-05-06 18:42:41,584][train][INFO] - Epoch 2/300, Val Acc=0.1800, Val Loss=3.1408, lr=0.0100
[2025-05-06 18:42:44,467][train][INFO] - Epoch 2/300, Val Acc=0.1073, Val Loss=3.7285, lr=0.0100
[2025-05-06 18:42:49,870][train][INFO] - Epoch 3/300, Val Acc=0.2047, Val Loss=3.0136, lr=0.0100
[2025-05-06 18:42:52,118][train][INFO] - Epoch 3/300, Val Acc=0.1012, Val Loss=3.7805, lr=0.0100
[2025-05-06 18:42:57,466][train][INFO] - Epoch 4/300, Val Acc=0.1948, Val Loss=3.0851, lr=0.0100
[2025-05-06 18:43:00,141][train][INFO] - Epoch 4/300, Val Acc=0.2114, Val Loss=3.0320, lr=0.0100
[2025-05-06 18:43:05,669][train][INFO] - Epoch 5/300, Val Acc=0.2555, Val Loss=3.0180, lr=0.0100
[2025-05-06 18:43:07,931][train][INFO] - Epoch 5/300, Val Acc=0.2427, Val Loss=2.9453, lr=0.0100
[2025-05-06 18:43:14,240][train][INFO] - Epoch 6/300, Val Acc=0.3487, Val Loss=2.4645, lr=0.0100
[2025-05-06 18:43:16,010][train][INFO] - Epoch 6/300, Val Acc=0.2416, Val Loss=2.9458, lr=0.0100
[2025-05-06 18:43:21,592][train][INFO] - Epoch 7/300, Val Acc=0.3783, Val Loss=2.2895, lr=0.0100
[2025-05-06 18:43:24,231][train][INFO] - Epoch 7/300, Val Acc=0.2974, Val Loss=2.8628, lr=0.0100
[2025-05-06 18:43:29,682][train][INFO] - Epoch 8/300, Val Acc=0.4061, Val Loss=2.2777, lr=0.0100
[2025-05-06 18:43:32,197][train][INFO] - Epoch 8/300, Val Acc=0.3250, Val Loss=2.6406, lr=0.0100
[2025-05-06 18:43:37,673][train][INFO] - Epoch 9/300, Val Acc=0.4010, Val Loss=2.3423, lr=0.0100
[2025-05-06 18:43:40,121][train][INFO] - Epoch 9/300, Val Acc=0.3207, Val Loss=2.6397, lr=0.0100
[2025-05-06 18:43:45,411][train][INFO] - Epoch 10/300, Val Acc=0.4514, Val Loss=2.0412, lr=0.0100
[2025-05-06 18:43:48,439][train][INFO] - Epoch 10/300, Val Acc=0.3509, Val Loss=2.4300, lr=0.0100
[2025-05-06 18:43:53,314][train][INFO] - Epoch 11/300, Val Acc=0.5048, Val Loss=1.8166, lr=0.0100
[2025-05-06 18:43:56,114][train][INFO] - Epoch 11/300, Val Acc=0.4011, Val Loss=2.2054, lr=0.0100
[2025-05-06 18:44:01,721][train][INFO] - Epoch 12/300, Val Acc=0.4850, Val Loss=1.9557, lr=0.0100
[2025-05-06 18:44:04,672][train][INFO] - Epoch 12/300, Val Acc=0.4183, Val Loss=2.1640, lr=0.0100
[2025-05-06 18:44:09,184][train][INFO] - Epoch 13/300, Val Acc=0.4410, Val Loss=2.2209, lr=0.0100
[2025-05-06 18:44:12,890][train][INFO] - Epoch 13/300, Val Acc=0.4435, Val Loss=2.0170, lr=0.0100
[2025-05-06 18:44:17,351][train][INFO] - Epoch 14/300, Val Acc=0.4867, Val Loss=1.9895, lr=0.0100
[2025-05-06 18:44:21,255][train][INFO] - Epoch 14/300, Val Acc=0.4405, Val Loss=2.0874, lr=0.0100
[2025-05-06 18:44:25,130][train][INFO] - Epoch 15/300, Val Acc=0.5212, Val Loss=1.8461, lr=0.0100
[2025-05-06 18:44:28,719][train][INFO] - Epoch 15/300, Val Acc=0.4195, Val Loss=2.2101, lr=0.0100
[2025-05-06 18:44:33,022][train][INFO] - Epoch 16/300, Val Acc=0.5462, Val Loss=1.6684, lr=0.0100
[2025-05-06 18:44:35,965][train][INFO] - Epoch 16/300, Val Acc=0.4628, Val Loss=1.9817, lr=0.0100
[2025-05-06 18:44:41,358][train][INFO] - Epoch 17/300, Val Acc=0.5245, Val Loss=1.8001, lr=0.0100
[2025-05-06 18:44:44,199][train][INFO] - Epoch 17/300, Val Acc=0.4801, Val Loss=1.8794, lr=0.0100
[2025-05-06 18:44:49,341][train][INFO] - Epoch 18/300, Val Acc=0.5309, Val Loss=1.8349, lr=0.0100
[2025-05-06 18:44:51,597][train][INFO] - Epoch 18/300, Val Acc=0.4345, Val Loss=2.1876, lr=0.0100
[2025-05-06 18:44:57,429][train][INFO] - Epoch 19/300, Val Acc=0.5541, Val Loss=1.6883, lr=0.0100
[2025-05-06 18:44:59,545][train][INFO] - Epoch 19/300, Val Acc=0.4943, Val Loss=1.8217, lr=0.0100
[2025-05-06 18:45:05,866][train][INFO] - Epoch 20/300, Val Acc=0.5786, Val Loss=1.6245, lr=0.0100
[2025-05-06 18:45:07,821][train][INFO] - Epoch 20/300, Val Acc=0.4860, Val Loss=1.8589, lr=0.0100
[2025-05-06 18:45:14,253][train][INFO] - Epoch 21/300, Val Acc=0.5292, Val Loss=1.8784, lr=0.0100
[2025-05-06 18:45:15,711][train][INFO] - Epoch 21/300, Val Acc=0.4424, Val Loss=2.1362, lr=0.0100
[2025-05-06 18:45:22,236][train][INFO] - Epoch 22/300, Val Acc=0.5382, Val Loss=1.8203, lr=0.0100
[2025-05-06 18:45:23,869][train][INFO] - Epoch 22/300, Val Acc=0.4686, Val Loss=2.0200, lr=0.0100
[2025-05-06 18:45:30,587][train][INFO] - Epoch 23/300, Val Acc=0.5682, Val Loss=1.7212, lr=0.0100
[2025-05-06 18:45:32,069][train][INFO] - Epoch 23/300, Val Acc=0.5070, Val Loss=1.7903, lr=0.0100
[2025-05-06 18:45:38,515][train][INFO] - Epoch 24/300, Val Acc=0.5739, Val Loss=1.6791, lr=0.0100
[2025-05-06 18:45:40,281][train][INFO] - Epoch 24/300, Val Acc=0.5075, Val Loss=1.8016, lr=0.0100
[2025-05-06 18:45:46,176][train][INFO] - Epoch 25/300, Val Acc=0.5900, Val Loss=1.5826, lr=0.0100
[2025-05-06 18:45:48,573][train][INFO] - Epoch 25/300, Val Acc=0.5087, Val Loss=1.8099, lr=0.0100
[2025-05-06 18:45:54,452][train][INFO] - Epoch 26/300, Val Acc=0.5526, Val Loss=1.8464, lr=0.0100
[2025-05-06 18:45:56,899][train][INFO] - Epoch 26/300, Val Acc=0.4809, Val Loss=1.9551, lr=0.0100
[2025-05-06 18:46:02,441][train][INFO] - Epoch 27/300, Val Acc=0.6022, Val Loss=1.5530, lr=0.0100
[2025-05-06 18:46:04,481][train][INFO] - Epoch 27/300, Val Acc=0.4908, Val Loss=1.8938, lr=0.0100
[2025-05-06 18:46:09,646][train][INFO] - Epoch 28/300, Val Acc=0.5802, Val Loss=1.6209, lr=0.0100
[2025-05-06 18:46:12,497][train][INFO] - Epoch 28/300, Val Acc=0.4820, Val Loss=1.9695, lr=0.0100
[2025-05-06 18:46:17,813][train][INFO] - Epoch 29/300, Val Acc=0.5965, Val Loss=1.6158, lr=0.0100
[2025-05-06 18:46:20,653][train][INFO] - Epoch 29/300, Val Acc=0.5256, Val Loss=1.7564, lr=0.0100
[2025-05-06 18:46:25,915][train][INFO] - Epoch 30/300, Val Acc=0.6045, Val Loss=1.5908, lr=0.0100
[2025-05-06 18:46:28,858][train][INFO] - Epoch 30/300, Val Acc=0.5313, Val Loss=1.7132, lr=0.0100
[2025-05-06 18:46:34,205][train][INFO] - Epoch 31/300, Val Acc=0.6015, Val Loss=1.6014, lr=0.0100
[2025-05-06 18:46:36,705][train][INFO] - Epoch 31/300, Val Acc=0.5290, Val Loss=1.7829, lr=0.0100
[2025-05-06 18:46:42,517][train][INFO] - Epoch 32/300, Val Acc=0.5894, Val Loss=1.6960, lr=0.0100
[2025-05-06 18:46:44,838][train][INFO] - Epoch 32/300, Val Acc=0.5317, Val Loss=1.7320, lr=0.0100
[2025-05-06 18:46:51,069][train][INFO] - Epoch 33/300, Val Acc=0.5832, Val Loss=1.6813, lr=0.0100
[2025-05-06 18:46:52,908][train][INFO] - Epoch 33/300, Val Acc=0.5049, Val Loss=1.9286, lr=0.0100
[2025-05-06 18:46:59,382][train][INFO] - Epoch 34/300, Val Acc=0.6108, Val Loss=1.5890, lr=0.0100
[2025-05-06 18:47:01,118][train][INFO] - Epoch 34/300, Val Acc=0.4972, Val Loss=1.9323, lr=0.0100
[2025-05-06 18:47:07,249][train][INFO] - Epoch 35/300, Val Acc=0.5902, Val Loss=1.6914, lr=0.0100
[2025-05-06 18:47:08,690][train][INFO] - Epoch 35/300, Val Acc=0.5299, Val Loss=1.7207, lr=0.0100
[2025-05-06 18:47:15,247][train][INFO] - Epoch 36/300, Val Acc=0.5950, Val Loss=1.6372, lr=0.0100
[2025-05-06 18:47:15,913][train][INFO] - Epoch 36/300, Val Acc=0.5112, Val Loss=1.8713, lr=0.0100
[2025-05-06 18:47:23,354][train][INFO] - Epoch 37/300, Val Acc=0.5957, Val Loss=1.6907, lr=0.0100
[2025-05-06 18:47:23,915][train][INFO] - Epoch 37/300, Val Acc=0.5491, Val Loss=1.6927, lr=0.0100
[2025-05-06 18:47:30,689][train][INFO] - Epoch 38/300, Val Acc=0.5994, Val Loss=1.6521, lr=0.0100
[2025-05-06 18:47:32,162][train][INFO] - Epoch 38/300, Val Acc=0.5422, Val Loss=1.6943, lr=0.0100
[2025-05-06 18:47:38,450][train][INFO] - Epoch 39/300, Val Acc=0.6045, Val Loss=1.6506, lr=0.0100
[2025-05-06 18:47:40,087][train][INFO] - Epoch 39/300, Val Acc=0.5596, Val Loss=1.6220, lr=0.0100
[2025-05-06 18:47:46,776][train][INFO] - Epoch 40/300, Val Acc=0.5957, Val Loss=1.6921, lr=0.0100
[2025-05-06 18:47:47,362][train][INFO] - Epoch 40/300, Val Acc=0.5390, Val Loss=1.7392, lr=0.0100
[2025-05-06 18:47:54,438][train][INFO] - Epoch 41/300, Val Acc=0.6126, Val Loss=1.6022, lr=0.0100
[2025-05-06 18:47:55,625][train][INFO] - Epoch 41/300, Val Acc=0.5231, Val Loss=1.8813, lr=0.0100
[2025-05-06 18:48:02,445][train][INFO] - Epoch 42/300, Val Acc=0.6008, Val Loss=1.7293, lr=0.0100
[2025-05-06 18:48:03,018][train][INFO] - Epoch 42/300, Val Acc=0.5333, Val Loss=1.7644, lr=0.0100
[2025-05-06 18:48:10,465][train][INFO] - Epoch 43/300, Val Acc=0.6106, Val Loss=1.6888, lr=0.0100
[2025-05-06 18:48:11,137][train][INFO] - Epoch 43/300, Val Acc=0.5573, Val Loss=1.6679, lr=0.0100
[2025-05-06 18:48:18,874][train][INFO] - Epoch 44/300, Val Acc=0.6022, Val Loss=1.6992, lr=0.0100
[2025-05-06 18:48:19,434][train][INFO] - Epoch 44/300, Val Acc=0.5433, Val Loss=1.7712, lr=0.0100
[2025-05-06 18:48:26,941][train][INFO] - Epoch 45/300, Val Acc=0.5575, Val Loss=1.6770, lr=0.0100
[2025-05-06 18:48:27,205][train][INFO] - Epoch 45/300, Val Acc=0.6069, Val Loss=1.6741, lr=0.0100
[2025-05-06 18:48:35,057][train][INFO] - Epoch 46/300, Val Acc=0.5451, Val Loss=1.7361, lr=0.0100
[2025-05-06 18:48:35,279][train][INFO] - Epoch 46/300, Val Acc=0.6077, Val Loss=1.6555, lr=0.0100
[2025-05-06 18:48:42,882][train][INFO] - Epoch 47/300, Val Acc=0.5551, Val Loss=1.7168, lr=0.0100
[2025-05-06 18:48:43,402][train][INFO] - Epoch 47/300, Val Acc=0.5942, Val Loss=1.7828, lr=0.0100
[2025-05-06 18:48:50,674][train][INFO] - Epoch 48/300, Val Acc=0.5555, Val Loss=1.7282, lr=0.0100
[2025-05-06 18:48:51,531][train][INFO] - Epoch 48/300, Val Acc=0.6006, Val Loss=1.7140, lr=0.0100
[2025-05-06 18:48:59,059][train][INFO] - Epoch 49/300, Val Acc=0.5588, Val Loss=1.6738, lr=0.0100
[2025-05-06 18:48:59,885][train][INFO] - Epoch 49/300, Val Acc=0.6161, Val Loss=1.6509, lr=0.0100
[2025-05-06 18:49:07,013][train][INFO] - Epoch 50/300, Val Acc=0.5569, Val Loss=1.7256, lr=0.0100
[2025-05-06 18:49:08,391][train][INFO] - Epoch 50/300, Val Acc=0.6044, Val Loss=1.7283, lr=0.0100
[2025-05-06 18:49:14,948][train][INFO] - Epoch 51/300, Val Acc=0.5711, Val Loss=1.6467, lr=0.0100
[2025-05-06 18:49:16,588][train][INFO] - Epoch 51/300, Val Acc=0.6041, Val Loss=1.7113, lr=0.0100
[2025-05-06 18:49:23,079][train][INFO] - Epoch 52/300, Val Acc=0.5407, Val Loss=1.8245, lr=0.0100
[2025-05-06 18:49:24,436][train][INFO] - Epoch 52/300, Val Acc=0.6287, Val Loss=1.5932, lr=0.0100
[2025-05-06 18:49:31,112][train][INFO] - Epoch 53/300, Val Acc=0.5788, Val Loss=1.6307, lr=0.0100
[2025-05-06 18:49:33,010][train][INFO] - Epoch 53/300, Val Acc=0.6217, Val Loss=1.6603, lr=0.0100
[2025-05-06 18:49:39,529][train][INFO] - Epoch 54/300, Val Acc=0.5520, Val Loss=1.7428, lr=0.0100
[2025-05-06 18:49:41,536][train][INFO] - Epoch 54/300, Val Acc=0.6270, Val Loss=1.5705, lr=0.0100
[2025-05-06 18:49:47,065][train][INFO] - Epoch 55/300, Val Acc=0.5525, Val Loss=1.7450, lr=0.0100
[2025-05-06 18:49:49,358][train][INFO] - Epoch 55/300, Val Acc=0.6294, Val Loss=1.5980, lr=0.0100
[2025-05-06 18:49:54,481][train][INFO] - Epoch 56/300, Val Acc=0.5839, Val Loss=1.6067, lr=0.0100
[2025-05-06 18:49:57,868][train][INFO] - Epoch 56/300, Val Acc=0.6263, Val Loss=1.6246, lr=0.0100
[2025-05-06 18:50:02,434][train][INFO] - Epoch 57/300, Val Acc=0.5611, Val Loss=1.7065, lr=0.0100
[2025-05-06 18:50:05,869][train][INFO] - Epoch 57/300, Val Acc=0.6276, Val Loss=1.6091, lr=0.0100
[2025-05-06 18:50:09,971][train][INFO] - Epoch 58/300, Val Acc=0.5690, Val Loss=1.6520, lr=0.0100
[2025-05-06 18:50:13,807][train][INFO] - Epoch 58/300, Val Acc=0.6157, Val Loss=1.6608, lr=0.0100
[2025-05-06 18:50:17,866][train][INFO] - Epoch 59/300, Val Acc=0.5442, Val Loss=1.7990, lr=0.0100
[2025-05-06 18:50:21,951][train][INFO] - Epoch 59/300, Val Acc=0.6123, Val Loss=1.6716, lr=0.0100
[2025-05-06 18:50:25,440][train][INFO] - Epoch 60/300, Val Acc=0.5901, Val Loss=1.5750, lr=0.0100
[2025-05-06 18:50:30,240][train][INFO] - Epoch 60/300, Val Acc=0.6115, Val Loss=1.7082, lr=0.0100
[2025-05-06 18:50:32,416][train][INFO] - Epoch 61/300, Val Acc=0.5577, Val Loss=1.7228, lr=0.0100
[2025-05-06 18:50:38,632][train][INFO] - Epoch 61/300, Val Acc=0.6108, Val Loss=1.7583, lr=0.0100
[2025-05-06 18:50:40,931][train][INFO] - Epoch 62/300, Val Acc=0.5877, Val Loss=1.6130, lr=0.0100
[2025-05-06 18:50:46,627][train][INFO] - Epoch 62/300, Val Acc=0.6356, Val Loss=1.6124, lr=0.0100
[2025-05-06 18:50:49,125][train][INFO] - Epoch 63/300, Val Acc=0.5485, Val Loss=1.8167, lr=0.0100
[2025-05-06 18:50:54,681][train][INFO] - Epoch 63/300, Val Acc=0.6120, Val Loss=1.7385, lr=0.0100
[2025-05-06 18:50:56,762][train][INFO] - Epoch 64/300, Val Acc=0.5739, Val Loss=1.6722, lr=0.0100
[2025-05-06 18:51:03,268][train][INFO] - Epoch 64/300, Val Acc=0.6238, Val Loss=1.6561, lr=0.0100
[2025-05-06 18:51:04,316][train][INFO] - Epoch 65/300, Val Acc=0.5870, Val Loss=1.5967, lr=0.0100
[2025-05-06 18:51:11,292][train][INFO] - Epoch 65/300, Val Acc=0.6161, Val Loss=1.6728, lr=0.0100
[2025-05-06 18:51:11,831][train][INFO] - Epoch 66/300, Val Acc=0.5751, Val Loss=1.6556, lr=0.0100
[2025-05-06 18:51:18,669][train][INFO] - Epoch 66/300, Val Acc=0.6154, Val Loss=1.7134, lr=0.0100
[2025-05-06 18:51:19,713][train][INFO] - Epoch 67/300, Val Acc=0.5798, Val Loss=1.6135, lr=0.0100
[2025-05-06 18:51:26,328][train][INFO] - Epoch 67/300, Val Acc=0.6130, Val Loss=1.7646, lr=0.0100
[2025-05-06 18:51:27,933][train][INFO] - Epoch 68/300, Val Acc=0.5718, Val Loss=1.6964, lr=0.0100
[2025-05-06 18:51:34,485][train][INFO] - Epoch 68/300, Val Acc=0.6207, Val Loss=1.6768, lr=0.0100
[2025-05-06 18:51:35,354][train][INFO] - Epoch 69/300, Val Acc=0.5786, Val Loss=1.6676, lr=0.0100
[2025-05-06 18:51:42,095][train][INFO] - Epoch 69/300, Val Acc=0.6240, Val Loss=1.6447, lr=0.0100
[2025-05-06 18:51:43,542][train][INFO] - Epoch 70/300, Val Acc=0.5752, Val Loss=1.6897, lr=0.0100
[2025-05-06 18:51:50,060][train][INFO] - Epoch 70/300, Val Acc=0.6266, Val Loss=1.6447, lr=0.0100
[2025-05-06 18:51:51,714][train][INFO] - Epoch 71/300, Val Acc=0.5885, Val Loss=1.6308, lr=0.0100
[2025-05-06 18:51:58,600][train][INFO] - Epoch 71/300, Val Acc=0.6222, Val Loss=1.6697, lr=0.0100
[2025-05-06 18:51:59,612][train][INFO] - Epoch 72/300, Val Acc=0.5704, Val Loss=1.6931, lr=0.0100
[2025-05-06 18:52:06,971][train][INFO] - Epoch 72/300, Val Acc=0.6120, Val Loss=1.7344, lr=0.0100
[2025-05-06 18:52:07,701][train][INFO] - Epoch 73/300, Val Acc=0.5892, Val Loss=1.6220, lr=0.0100
[2025-05-06 18:52:15,308][train][INFO] - Epoch 73/300, Val Acc=0.6172, Val Loss=1.7438, lr=0.0100
[2025-05-06 18:52:15,562][train][INFO] - Epoch 74/300, Val Acc=0.5923, Val Loss=1.6255, lr=0.0100
[2025-05-06 18:52:23,090][train][INFO] - Epoch 74/300, Val Acc=0.6213, Val Loss=1.7418, lr=0.0100
[2025-05-06 18:52:23,415][train][INFO] - Epoch 75/300, Val Acc=0.5769, Val Loss=1.6795, lr=0.0100
[2025-05-06 18:52:30,974][train][INFO] - Epoch 75/300, Val Acc=0.6213, Val Loss=1.6760, lr=0.0100
[2025-05-06 18:52:31,431][train][INFO] - Epoch 76/300, Val Acc=0.5727, Val Loss=1.7565, lr=0.0100
[2025-05-06 18:52:39,426][train][INFO] - Epoch 76/300, Val Acc=0.6193, Val Loss=1.7378, lr=0.0100
[2025-05-06 18:52:39,474][train][INFO] - Epoch 77/300, Val Acc=0.5796, Val Loss=1.6820, lr=0.0100
[2025-05-06 18:52:47,466][train][INFO] - Epoch 77/300, Val Acc=0.6214, Val Loss=1.7219, lr=0.0100
[2025-05-06 18:52:47,508][train][INFO] - Epoch 78/300, Val Acc=0.5726, Val Loss=1.7394, lr=0.0100
[2025-05-06 18:52:55,641][train][INFO] - Epoch 79/300, Val Acc=0.5754, Val Loss=1.7508, lr=0.0100
[2025-05-06 18:52:56,169][train][INFO] - Epoch 78/300, Val Acc=0.6123, Val Loss=1.7881, lr=0.0100
[2025-05-06 18:53:03,625][train][INFO] - Epoch 80/300, Val Acc=0.5858, Val Loss=1.6833, lr=0.0100
[2025-05-06 18:53:04,159][train][INFO] - Epoch 79/300, Val Acc=0.6211, Val Loss=1.7528, lr=0.0100
[2025-05-06 18:53:11,364][train][INFO] - Epoch 81/300, Val Acc=0.5778, Val Loss=1.7087, lr=0.0100
[2025-05-06 18:53:12,701][train][INFO] - Epoch 80/300, Val Acc=0.6205, Val Loss=1.7111, lr=0.0100
[2025-05-06 18:53:19,281][train][INFO] - Epoch 82/300, Val Acc=0.5472, Val Loss=1.9512, lr=0.0100
[2025-05-06 18:53:21,119][train][INFO] - Epoch 81/300, Val Acc=0.6105, Val Loss=1.7924, lr=0.0100
[2025-05-06 18:53:26,598][train][INFO] - Epoch 83/300, Val Acc=0.5996, Val Loss=1.6041, lr=0.0100
[2025-05-06 18:53:29,050][train][INFO] - Epoch 82/300, Val Acc=0.6186, Val Loss=1.7614, lr=0.0100
[2025-05-06 18:53:34,466][train][INFO] - Epoch 84/300, Val Acc=0.5786, Val Loss=1.7234, lr=0.0100
[2025-05-06 18:53:36,878][train][INFO] - Epoch 83/300, Val Acc=0.6028, Val Loss=1.8526, lr=0.0100
[2025-05-06 18:53:42,175][train][INFO] - Epoch 85/300, Val Acc=0.5763, Val Loss=1.7184, lr=0.0100
[2025-05-06 18:53:44,876][train][INFO] - Epoch 84/300, Val Acc=0.6237, Val Loss=1.6995, lr=0.0100
[2025-05-06 18:53:49,328][train][INFO] - Epoch 86/300, Val Acc=0.5939, Val Loss=1.6662, lr=0.0100
[2025-05-06 18:53:52,921][train][INFO] - Epoch 85/300, Val Acc=0.6105, Val Loss=1.8146, lr=0.0100
[2025-05-06 18:53:56,579][train][INFO] - Epoch 87/300, Val Acc=0.5787, Val Loss=1.7136, lr=0.0100
[2025-05-06 18:54:00,744][train][INFO] - Epoch 86/300, Val Acc=0.6261, Val Loss=1.7051, lr=0.0100
[2025-05-06 18:54:04,617][train][INFO] - Epoch 88/300, Val Acc=0.5769, Val Loss=1.7157, lr=0.0100
[2025-05-06 18:54:08,877][train][INFO] - Epoch 87/300, Val Acc=0.6282, Val Loss=1.6647, lr=0.0100
[2025-05-06 18:54:12,613][train][INFO] - Epoch 89/300, Val Acc=0.5749, Val Loss=1.7565, lr=0.0100
[2025-05-06 18:54:16,562][train][INFO] - Epoch 88/300, Val Acc=0.6211, Val Loss=1.7572, lr=0.0100
[2025-05-06 18:54:20,932][train][INFO] - Epoch 90/300, Val Acc=0.5865, Val Loss=1.6815, lr=0.0100
[2025-05-06 18:54:24,462][train][INFO] - Epoch 89/300, Val Acc=0.6376, Val Loss=1.6533, lr=0.0100
[2025-05-06 18:54:28,564][train][INFO] - Epoch 91/300, Val Acc=0.5897, Val Loss=1.6865, lr=0.0100
[2025-05-06 18:54:31,655][train][INFO] - Epoch 90/300, Val Acc=0.6317, Val Loss=1.6938, lr=0.0100
[2025-05-06 18:54:36,449][train][INFO] - Epoch 92/300, Val Acc=0.5926, Val Loss=1.6540, lr=0.0100
[2025-05-06 18:54:40,164][train][INFO] - Epoch 91/300, Val Acc=0.6231, Val Loss=1.6967, lr=0.0100
[2025-05-06 18:54:44,364][train][INFO] - Epoch 93/300, Val Acc=0.5905, Val Loss=1.6276, lr=0.0100
[2025-05-06 18:54:47,541][train][INFO] - Epoch 92/300, Val Acc=0.6363, Val Loss=1.6961, lr=0.0100
[2025-05-06 18:54:52,299][train][INFO] - Epoch 94/300, Val Acc=0.5911, Val Loss=1.6885, lr=0.0100
[2025-05-06 18:54:55,720][train][INFO] - Epoch 93/300, Val Acc=0.6330, Val Loss=1.7043, lr=0.0100
[2025-05-06 18:55:00,072][train][INFO] - Epoch 95/300, Val Acc=0.5733, Val Loss=1.7624, lr=0.0100
[2025-05-06 18:55:03,878][train][INFO] - Epoch 94/300, Val Acc=0.6306, Val Loss=1.7326, lr=0.0100
[2025-05-06 18:55:08,655][train][INFO] - Epoch 96/300, Val Acc=0.5849, Val Loss=1.6842, lr=0.0100
[2025-05-06 18:55:11,761][train][INFO] - Epoch 95/300, Val Acc=0.6395, Val Loss=1.6464, lr=0.0100
[2025-05-06 18:55:15,987][train][INFO] - Epoch 97/300, Val Acc=0.5983, Val Loss=1.6165, lr=0.0100
[2025-05-06 18:55:19,438][train][INFO] - Epoch 96/300, Val Acc=0.6144, Val Loss=1.7942, lr=0.0100
[2025-05-06 18:55:23,617][train][INFO] - Epoch 98/300, Val Acc=0.5917, Val Loss=1.6895, lr=0.0100
[2025-05-06 18:55:27,223][train][INFO] - Epoch 97/300, Val Acc=0.6261, Val Loss=1.7382, lr=0.0100
[2025-05-06 18:55:31,453][train][INFO] - Epoch 99/300, Val Acc=0.6116, Val Loss=1.6024, lr=0.0100
[2025-05-06 18:55:34,798][train][INFO] - Epoch 98/300, Val Acc=0.6141, Val Loss=1.8326, lr=0.0100
[2025-05-06 18:55:39,336][train][INFO] - Epoch 100/300, Val Acc=0.5900, Val Loss=1.6588, lr=0.0100
[2025-05-06 18:55:42,750][train][INFO] - Epoch 99/300, Val Acc=0.6307, Val Loss=1.6590, lr=0.0100
[2025-05-06 18:55:47,583][train][INFO] - Epoch 101/300, Val Acc=0.6082, Val Loss=1.6001, lr=0.0100
[2025-05-06 18:55:51,035][train][INFO] - Epoch 100/300, Val Acc=0.6414, Val Loss=1.6611, lr=0.0100
[2025-05-06 18:55:55,788][train][INFO] - Epoch 102/300, Val Acc=0.5969, Val Loss=1.6837, lr=0.0100
[2025-05-06 18:55:59,077][train][INFO] - Epoch 101/300, Val Acc=0.6433, Val Loss=1.5969, lr=0.0100
[2025-05-06 18:56:03,498][train][INFO] - Epoch 103/300, Val Acc=0.5938, Val Loss=1.6634, lr=0.0100
[2025-05-06 18:56:06,981][train][INFO] - Epoch 102/300, Val Acc=0.6269, Val Loss=1.7142, lr=0.0100
[2025-05-06 18:56:11,477][train][INFO] - Epoch 104/300, Val Acc=0.5689, Val Loss=1.7915, lr=0.0100
[2025-05-06 18:56:14,897][train][INFO] - Epoch 103/300, Val Acc=0.6085, Val Loss=1.8172, lr=0.0100
[2025-05-06 18:56:18,883][train][INFO] - Epoch 105/300, Val Acc=0.5702, Val Loss=1.7975, lr=0.0100
[2025-05-06 18:56:23,263][train][INFO] - Epoch 104/300, Val Acc=0.6282, Val Loss=1.7554, lr=0.0100
[2025-05-06 18:56:27,268][train][INFO] - Epoch 106/300, Val Acc=0.5950, Val Loss=1.6840, lr=0.0100
[2025-05-06 18:56:31,545][train][INFO] - Epoch 105/300, Val Acc=0.6377, Val Loss=1.6675, lr=0.0100
[2025-05-06 18:56:35,643][train][INFO] - Epoch 107/300, Val Acc=0.5843, Val Loss=1.7290, lr=0.0100
[2025-05-06 18:56:39,039][train][INFO] - Epoch 106/300, Val Acc=0.6491, Val Loss=1.6130, lr=0.0100
[2025-05-06 18:56:43,789][train][INFO] - Epoch 108/300, Val Acc=0.6140, Val Loss=1.6172, lr=0.0100
[2025-05-06 18:56:47,208][train][INFO] - Epoch 107/300, Val Acc=0.6457, Val Loss=1.6338, lr=0.0100
[2025-05-06 18:56:51,398][train][INFO] - Epoch 109/300, Val Acc=0.6008, Val Loss=1.6347, lr=0.0100
[2025-05-06 18:56:55,346][train][INFO] - Epoch 108/300, Val Acc=0.6391, Val Loss=1.6799, lr=0.0100
[2025-05-06 18:56:59,823][train][INFO] - Epoch 110/300, Val Acc=0.5885, Val Loss=1.7128, lr=0.0100
[2025-05-06 18:57:02,691][train][INFO] - Epoch 109/300, Val Acc=0.6409, Val Loss=1.6870, lr=0.0100
[2025-05-06 18:57:07,811][train][INFO] - Epoch 111/300, Val Acc=0.5956, Val Loss=1.6450, lr=0.0100
[2025-05-06 18:57:10,641][train][INFO] - Epoch 110/300, Val Acc=0.6356, Val Loss=1.7233, lr=0.0100
[2025-05-06 18:57:15,620][train][INFO] - Epoch 112/300, Val Acc=0.5886, Val Loss=1.7158, lr=0.0100
[2025-05-06 18:57:18,595][train][INFO] - Epoch 111/300, Val Acc=0.6315, Val Loss=1.7359, lr=0.0100
[2025-05-06 18:57:23,930][train][INFO] - Epoch 113/300, Val Acc=0.5754, Val Loss=1.8186, lr=0.0100
[2025-05-06 18:57:26,918][train][INFO] - Epoch 112/300, Val Acc=0.6241, Val Loss=1.7644, lr=0.0100
[2025-05-06 18:57:32,396][train][INFO] - Epoch 114/300, Val Acc=0.6024, Val Loss=1.6463, lr=0.0100
[2025-05-06 18:57:35,430][train][INFO] - Epoch 113/300, Val Acc=0.6267, Val Loss=1.7318, lr=0.0100
[2025-05-06 18:57:40,100][train][INFO] - Epoch 115/300, Val Acc=0.5706, Val Loss=1.8334, lr=0.0100
[2025-05-06 18:57:43,804][train][INFO] - Epoch 114/300, Val Acc=0.6432, Val Loss=1.6667, lr=0.0100
[2025-05-06 18:57:48,529][train][INFO] - Epoch 116/300, Val Acc=0.6007, Val Loss=1.6487, lr=0.0100
[2025-05-06 18:57:52,164][train][INFO] - Epoch 115/300, Val Acc=0.6319, Val Loss=1.7441, lr=0.0100
[2025-05-06 18:57:56,562][train][INFO] - Epoch 117/300, Val Acc=0.5895, Val Loss=1.7346, lr=0.0100
[2025-05-06 18:58:00,440][train][INFO] - Epoch 116/300, Val Acc=0.6329, Val Loss=1.7273, lr=0.0100
[2025-05-06 18:58:04,598][train][INFO] - Epoch 118/300, Val Acc=0.5950, Val Loss=1.6965, lr=0.0100
[2025-05-06 18:58:08,519][train][INFO] - Epoch 117/300, Val Acc=0.6277, Val Loss=1.7417, lr=0.0100
[2025-05-06 18:58:12,787][train][INFO] - Epoch 119/300, Val Acc=0.5744, Val Loss=1.8363, lr=0.0100
[2025-05-06 18:58:17,035][train][INFO] - Epoch 118/300, Val Acc=0.6321, Val Loss=1.7607, lr=0.0100
[2025-05-06 18:58:20,712][train][INFO] - Epoch 120/300, Val Acc=0.5844, Val Loss=1.7783, lr=0.0100
[2025-05-06 18:58:25,529][train][INFO] - Epoch 119/300, Val Acc=0.6172, Val Loss=1.8245, lr=0.0100
[2025-05-06 18:58:28,886][train][INFO] - Epoch 121/300, Val Acc=0.5914, Val Loss=1.7298, lr=0.0100
[2025-05-06 18:58:33,974][train][INFO] - Epoch 120/300, Val Acc=0.6233, Val Loss=1.7512, lr=0.0100
[2025-05-06 18:58:35,813][train][INFO] - Epoch 122/300, Val Acc=0.5793, Val Loss=1.8672, lr=0.0100
[2025-05-06 18:58:42,515][train][INFO] - Epoch 121/300, Val Acc=0.6262, Val Loss=1.7664, lr=0.0100
[2025-05-06 18:58:43,938][train][INFO] - Epoch 123/300, Val Acc=0.6001, Val Loss=1.6684, lr=0.0100
[2025-05-06 18:58:50,555][train][INFO] - Epoch 122/300, Val Acc=0.6304, Val Loss=1.7189, lr=0.0100
[2025-05-06 18:58:52,476][train][INFO] - Epoch 124/300, Val Acc=0.5978, Val Loss=1.6591, lr=0.0100
[2025-05-06 18:58:58,719][train][INFO] - Epoch 123/300, Val Acc=0.6246, Val Loss=1.7790, lr=0.0100
[2025-05-06 18:59:00,631][train][INFO] - Epoch 125/300, Val Acc=0.5882, Val Loss=1.7702, lr=0.0100
[2025-05-06 18:59:07,074][train][INFO] - Epoch 124/300, Val Acc=0.6401, Val Loss=1.7263, lr=0.0100
[2025-05-06 18:59:08,226][train][INFO] - Epoch 126/300, Val Acc=0.6054, Val Loss=1.6735, lr=0.0100
[2025-05-06 18:59:14,800][train][INFO] - Epoch 125/300, Val Acc=0.6376, Val Loss=1.7150, lr=0.0100
[2025-05-06 18:59:16,310][train][INFO] - Epoch 127/300, Val Acc=0.5924, Val Loss=1.7601, lr=0.0100
[2025-05-06 18:59:22,763][train][INFO] - Epoch 126/300, Val Acc=0.6430, Val Loss=1.7056, lr=0.0100
[2025-05-06 18:59:24,634][train][INFO] - Epoch 128/300, Val Acc=0.5807, Val Loss=1.8132, lr=0.0100
[2025-05-06 18:59:30,849][train][INFO] - Epoch 127/300, Val Acc=0.6328, Val Loss=1.6962, lr=0.0100
[2025-05-06 18:59:32,345][train][INFO] - Epoch 129/300, Val Acc=0.6024, Val Loss=1.6499, lr=0.0100
[2025-05-06 18:59:39,138][train][INFO] - Epoch 128/300, Val Acc=0.6298, Val Loss=1.7898, lr=0.0100
[2025-05-06 18:59:39,950][train][INFO] - Epoch 130/300, Val Acc=0.5984, Val Loss=1.7086, lr=0.0100
[2025-05-06 18:59:47,002][train][INFO] - Epoch 129/300, Val Acc=0.6351, Val Loss=1.7319, lr=0.0100
[2025-05-06 18:59:47,994][train][INFO] - Epoch 131/300, Val Acc=0.6109, Val Loss=1.6114, lr=0.0100
[2025-05-06 18:59:54,560][train][INFO] - Epoch 130/300, Val Acc=0.6355, Val Loss=1.7282, lr=0.0100
[2025-05-06 18:59:55,869][train][INFO] - Epoch 132/300, Val Acc=0.5664, Val Loss=1.9274, lr=0.0100
[2025-05-06 19:00:02,652][train][INFO] - Epoch 131/300, Val Acc=0.6390, Val Loss=1.7386, lr=0.0100
[2025-05-06 19:00:04,184][train][INFO] - Epoch 133/300, Val Acc=0.6177, Val Loss=1.6003, lr=0.0100
[2025-05-06 19:00:10,844][train][INFO] - Epoch 132/300, Val Acc=0.6261, Val Loss=1.8587, lr=0.0100
[2025-05-06 19:00:11,916][train][INFO] - Epoch 134/300, Val Acc=0.6018, Val Loss=1.6474, lr=0.0100
[2025-05-06 19:00:18,586][train][INFO] - Epoch 133/300, Val Acc=0.6238, Val Loss=1.7603, lr=0.0100
[2025-05-06 19:00:20,288][train][INFO] - Epoch 135/300, Val Acc=0.6185, Val Loss=1.5920, lr=0.0100
[2025-05-06 19:00:26,588][train][INFO] - Epoch 134/300, Val Acc=0.6391, Val Loss=1.7053, lr=0.0100
[2025-05-06 19:00:27,702][train][INFO] - Epoch 136/300, Val Acc=0.6039, Val Loss=1.6613, lr=0.0100
[2025-05-06 19:00:34,494][train][INFO] - Epoch 135/300, Val Acc=0.6073, Val Loss=1.8848, lr=0.0100
[2025-05-06 19:00:36,278][train][INFO] - Epoch 137/300, Val Acc=0.5863, Val Loss=1.7519, lr=0.0100
[2025-05-06 19:00:42,103][train][INFO] - Epoch 136/300, Val Acc=0.6373, Val Loss=1.6977, lr=0.0100
[2025-05-06 19:00:43,807][train][INFO] - Epoch 138/300, Val Acc=0.6000, Val Loss=1.6806, lr=0.0100
[2025-05-06 19:00:49,546][train][INFO] - Epoch 137/300, Val Acc=0.6308, Val Loss=1.7730, lr=0.0100
[2025-05-06 19:00:51,443][train][INFO] - Epoch 139/300, Val Acc=0.6106, Val Loss=1.6362, lr=0.0100
[2025-05-06 19:00:57,735][train][INFO] - Epoch 138/300, Val Acc=0.6274, Val Loss=1.7813, lr=0.0100
[2025-05-06 19:00:59,529][train][INFO] - Epoch 140/300, Val Acc=0.6065, Val Loss=1.6712, lr=0.0100
[2025-05-06 19:01:05,698][train][INFO] - Epoch 139/300, Val Acc=0.6216, Val Loss=1.8265, lr=0.0100
[2025-05-06 19:01:07,484][train][INFO] - Epoch 141/300, Val Acc=0.6181, Val Loss=1.5952, lr=0.0100
[2025-05-06 19:01:13,184][train][INFO] - Epoch 140/300, Val Acc=0.6403, Val Loss=1.7137, lr=0.0100
[2025-05-06 19:01:15,398][train][INFO] - Epoch 142/300, Val Acc=0.6017, Val Loss=1.7042, lr=0.0100
[2025-05-06 19:01:21,199][train][INFO] - Epoch 141/300, Val Acc=0.6240, Val Loss=1.7571, lr=0.0100
[2025-05-06 19:01:23,245][train][INFO] - Epoch 143/300, Val Acc=0.6055, Val Loss=1.6879, lr=0.0100
[2025-05-06 19:01:29,700][train][INFO] - Epoch 142/300, Val Acc=0.6312, Val Loss=1.7402, lr=0.0100
[2025-05-06 19:01:30,795][train][INFO] - Epoch 144/300, Val Acc=0.6101, Val Loss=1.6667, lr=0.0100
[2025-05-06 19:01:38,148][train][INFO] - Epoch 143/300, Val Acc=0.6363, Val Loss=1.7472, lr=0.0100
[2025-05-06 19:01:38,899][train][INFO] - Epoch 145/300, Val Acc=0.6065, Val Loss=1.6942, lr=0.0100
[2025-05-06 19:01:45,829][train][INFO] - Epoch 144/300, Val Acc=0.6254, Val Loss=1.7392, lr=0.0100
[2025-05-06 19:01:46,657][train][INFO] - Epoch 146/300, Val Acc=0.6098, Val Loss=1.6507, lr=0.0100
[2025-05-06 19:01:53,423][train][INFO] - Epoch 145/300, Val Acc=0.6376, Val Loss=1.7465, lr=0.0100
[2025-05-06 19:01:54,777][train][INFO] - Epoch 147/300, Val Acc=0.6024, Val Loss=1.6794, lr=0.0100
[2025-05-06 19:02:01,694][train][INFO] - Epoch 146/300, Val Acc=0.6246, Val Loss=1.7858, lr=0.0100
[2025-05-06 19:02:03,366][train][INFO] - Epoch 148/300, Val Acc=0.6043, Val Loss=1.6664, lr=0.0100
[2025-05-06 19:02:09,841][train][INFO] - Epoch 147/300, Val Acc=0.6435, Val Loss=1.6698, lr=0.0100
[2025-05-06 19:02:11,412][train][INFO] - Epoch 149/300, Val Acc=0.6108, Val Loss=1.6242, lr=0.0100
[2025-05-06 19:02:17,617][train][INFO] - Epoch 148/300, Val Acc=0.6261, Val Loss=1.8144, lr=0.0100
[2025-05-06 19:02:19,276][train][INFO] - Epoch 150/300, Val Acc=0.5984, Val Loss=1.7385, lr=0.0100
[2025-05-06 19:02:25,320][train][INFO] - Epoch 149/300, Val Acc=0.6348, Val Loss=1.7758, lr=0.0100
[2025-05-06 19:02:27,444][train][INFO] - Epoch 151/300, Val Acc=0.6666, Val Loss=1.3732, lr=0.0010
[2025-05-06 19:02:33,401][train][INFO] - Epoch 150/300, Val Acc=0.6317, Val Loss=1.7839, lr=0.0100
[2025-05-06 19:02:34,939][train][INFO] - Epoch 152/300, Val Acc=0.6714, Val Loss=1.3833, lr=0.0010
[2025-05-06 19:02:41,467][train][INFO] - Epoch 151/300, Val Acc=0.6934, Val Loss=1.4369, lr=0.0010
[2025-05-06 19:02:42,065][train][INFO] - Epoch 153/300, Val Acc=0.6742, Val Loss=1.3818, lr=0.0010
[2025-05-06 19:02:49,501][train][INFO] - Epoch 152/300, Val Acc=0.6983, Val Loss=1.4338, lr=0.0010
[2025-05-06 19:02:50,030][train][INFO] - Epoch 154/300, Val Acc=0.6737, Val Loss=1.3901, lr=0.0010
[2025-05-06 19:02:57,604][train][INFO] - Epoch 153/300, Val Acc=0.6988, Val Loss=1.4405, lr=0.0010
[2025-05-06 19:02:58,659][train][INFO] - Epoch 155/300, Val Acc=0.6768, Val Loss=1.4050, lr=0.0010
[2025-05-06 19:03:05,719][train][INFO] - Epoch 154/300, Val Acc=0.7004, Val Loss=1.4554, lr=0.0010
[2025-05-06 19:03:06,583][train][INFO] - Epoch 156/300, Val Acc=0.6775, Val Loss=1.4019, lr=0.0010
[2025-05-06 19:03:14,175][train][INFO] - Epoch 155/300, Val Acc=0.7010, Val Loss=1.4647, lr=0.0010
[2025-05-06 19:03:15,061][train][INFO] - Epoch 157/300, Val Acc=0.6765, Val Loss=1.4112, lr=0.0010
[2025-05-06 19:03:22,448][train][INFO] - Epoch 156/300, Val Acc=0.7040, Val Loss=1.4604, lr=0.0010
[2025-05-06 19:03:22,683][train][INFO] - Epoch 158/300, Val Acc=0.6765, Val Loss=1.4175, lr=0.0010
[2025-05-06 19:03:30,504][train][INFO] - Epoch 157/300, Val Acc=0.7039, Val Loss=1.4671, lr=0.0010
[2025-05-06 19:03:30,891][train][INFO] - Epoch 159/300, Val Acc=0.6735, Val Loss=1.4249, lr=0.0010
[2025-05-06 19:03:38,969][train][INFO] - Epoch 158/300, Val Acc=0.7047, Val Loss=1.4755, lr=0.0010
[2025-05-06 19:03:39,105][train][INFO] - Epoch 160/300, Val Acc=0.6768, Val Loss=1.4425, lr=0.0010
[2025-05-06 19:03:45,834][train][INFO] - Epoch 159/300, Val Acc=0.7041, Val Loss=1.4853, lr=0.0010
[2025-05-06 19:03:46,978][train][INFO] - Epoch 161/300, Val Acc=0.6775, Val Loss=1.4419, lr=0.0010
[2025-05-06 19:03:53,891][train][INFO] - Epoch 160/300, Val Acc=0.7030, Val Loss=1.4861, lr=0.0010
[2025-05-06 19:03:55,229][train][INFO] - Epoch 162/300, Val Acc=0.6742, Val Loss=1.4554, lr=0.0010
[2025-05-06 19:04:01,625][train][INFO] - Epoch 161/300, Val Acc=0.7024, Val Loss=1.4984, lr=0.0010
[2025-05-06 19:04:03,503][train][INFO] - Epoch 163/300, Val Acc=0.6760, Val Loss=1.4617, lr=0.0010
[2025-05-06 19:04:09,345][train][INFO] - Epoch 162/300, Val Acc=0.7021, Val Loss=1.4975, lr=0.0010
[2025-05-06 19:04:11,432][train][INFO] - Epoch 164/300, Val Acc=0.6754, Val Loss=1.4698, lr=0.0010
[2025-05-06 19:04:17,062][train][INFO] - Epoch 163/300, Val Acc=0.7041, Val Loss=1.4982, lr=0.0010
[2025-05-06 19:04:19,466][train][INFO] - Epoch 165/300, Val Acc=0.6771, Val Loss=1.4670, lr=0.0010
[2025-05-06 19:04:24,508][train][INFO] - Epoch 164/300, Val Acc=0.7052, Val Loss=1.5106, lr=0.0010
[2025-05-06 19:04:27,749][train][INFO] - Epoch 166/300, Val Acc=0.6747, Val Loss=1.4840, lr=0.0010
[2025-05-06 19:04:32,493][train][INFO] - Epoch 165/300, Val Acc=0.7045, Val Loss=1.5063, lr=0.0010
[2025-05-06 19:04:35,906][train][INFO] - Epoch 167/300, Val Acc=0.6720, Val Loss=1.4894, lr=0.0010
[2025-05-06 19:04:40,999][train][INFO] - Epoch 166/300, Val Acc=0.7051, Val Loss=1.5158, lr=0.0010
[2025-05-06 19:04:42,517][train][INFO] - Epoch 168/300, Val Acc=0.6742, Val Loss=1.4902, lr=0.0010
[2025-05-06 19:04:48,726][train][INFO] - Epoch 167/300, Val Acc=0.7035, Val Loss=1.5169, lr=0.0010
[2025-05-06 19:04:50,720][train][INFO] - Epoch 169/300, Val Acc=0.6743, Val Loss=1.4934, lr=0.0010
[2025-05-06 19:04:56,994][train][INFO] - Epoch 168/300, Val Acc=0.7065, Val Loss=1.5156, lr=0.0010
[2025-05-06 19:04:58,717][train][INFO] - Epoch 170/300, Val Acc=0.6746, Val Loss=1.5138, lr=0.0010
[2025-05-06 19:05:04,830][train][INFO] - Epoch 169/300, Val Acc=0.7044, Val Loss=1.5216, lr=0.0010
[2025-05-06 19:05:06,331][train][INFO] - Epoch 171/300, Val Acc=0.6735, Val Loss=1.5108, lr=0.0010
[2025-05-06 19:05:12,340][train][INFO] - Epoch 170/300, Val Acc=0.7077, Val Loss=1.5247, lr=0.0010
[2025-05-06 19:05:14,321][train][INFO] - Epoch 172/300, Val Acc=0.6752, Val Loss=1.5143, lr=0.0010
[2025-05-06 19:05:20,228][train][INFO] - Epoch 171/300, Val Acc=0.7051, Val Loss=1.5308, lr=0.0010
[2025-05-06 19:05:21,927][train][INFO] - Epoch 173/300, Val Acc=0.6753, Val Loss=1.5241, lr=0.0010
[2025-05-06 19:05:27,811][train][INFO] - Epoch 172/300, Val Acc=0.7065, Val Loss=1.5280, lr=0.0010
[2025-05-06 19:05:29,724][train][INFO] - Epoch 174/300, Val Acc=0.6717, Val Loss=1.5266, lr=0.0010
[2025-05-06 19:05:35,953][train][INFO] - Epoch 173/300, Val Acc=0.7038, Val Loss=1.5288, lr=0.0010
[2025-05-06 19:05:38,002][train][INFO] - Epoch 175/300, Val Acc=0.6750, Val Loss=1.5333, lr=0.0010
[2025-05-06 19:05:44,017][train][INFO] - Epoch 174/300, Val Acc=0.7075, Val Loss=1.5269, lr=0.0010
[2025-05-06 19:05:44,612][train][INFO] - Epoch 176/300, Val Acc=0.6728, Val Loss=1.5367, lr=0.0010
[2025-05-06 19:05:51,929][train][INFO] - Epoch 175/300, Val Acc=0.7104, Val Loss=1.5257, lr=0.0010
[2025-05-06 19:05:52,481][train][INFO] - Epoch 177/300, Val Acc=0.6758, Val Loss=1.5347, lr=0.0010
[2025-05-06 19:06:00,555][train][INFO] - Epoch 176/300, Val Acc=0.7085, Val Loss=1.5307, lr=0.0010
[2025-05-06 19:06:00,657][train][INFO] - Epoch 178/300, Val Acc=0.6712, Val Loss=1.5533, lr=0.0010
[2025-05-06 19:06:08,198][train][INFO] - Epoch 177/300, Val Acc=0.7056, Val Loss=1.5415, lr=0.0010
[2025-05-06 19:06:08,884][train][INFO] - Epoch 179/300, Val Acc=0.6712, Val Loss=1.5431, lr=0.0010
[2025-05-06 19:06:16,004][train][INFO] - Epoch 178/300, Val Acc=0.7049, Val Loss=1.5410, lr=0.0010
[2025-05-06 19:06:16,573][train][INFO] - Epoch 180/300, Val Acc=0.6710, Val Loss=1.5543, lr=0.0010
[2025-05-06 19:06:24,398][train][INFO] - Epoch 179/300, Val Acc=0.7056, Val Loss=1.5467, lr=0.0010
[2025-05-06 19:06:25,084][train][INFO] - Epoch 181/300, Val Acc=0.6706, Val Loss=1.5651, lr=0.0010
[2025-05-06 19:06:32,728][train][INFO] - Epoch 180/300, Val Acc=0.7082, Val Loss=1.5491, lr=0.0010
[2025-05-06 19:06:32,968][train][INFO] - Epoch 182/300, Val Acc=0.6746, Val Loss=1.5722, lr=0.0010
[2025-05-06 19:06:40,679][train][INFO] - Epoch 181/300, Val Acc=0.7065, Val Loss=1.5547, lr=0.0010
[2025-05-06 19:06:41,123][train][INFO] - Epoch 183/300, Val Acc=0.6723, Val Loss=1.5743, lr=0.0010
[2025-05-06 19:06:48,593][train][INFO] - Epoch 182/300, Val Acc=0.7058, Val Loss=1.5469, lr=0.0010
[2025-05-06 19:06:48,986][train][INFO] - Epoch 184/300, Val Acc=0.6738, Val Loss=1.5813, lr=0.0010
[2025-05-06 19:06:56,386][train][INFO] - Epoch 183/300, Val Acc=0.7075, Val Loss=1.5436, lr=0.0010
[2025-05-06 19:06:56,702][train][INFO] - Epoch 185/300, Val Acc=0.6735, Val Loss=1.5880, lr=0.0010
[2025-05-06 19:07:03,671][train][INFO] - Epoch 184/300, Val Acc=0.7071, Val Loss=1.5546, lr=0.0010
[2025-05-06 19:07:03,927][train][INFO] - Epoch 186/300, Val Acc=0.6730, Val Loss=1.5843, lr=0.0010
[2025-05-06 19:07:11,244][train][INFO] - Epoch 187/300, Val Acc=0.6724, Val Loss=1.5851, lr=0.0010
[2025-05-06 19:07:11,401][train][INFO] - Epoch 185/300, Val Acc=0.7054, Val Loss=1.5617, lr=0.0010
[2025-05-06 19:07:19,135][train][INFO] - Epoch 188/300, Val Acc=0.6707, Val Loss=1.5974, lr=0.0010
[2025-05-06 19:07:19,381][train][INFO] - Epoch 186/300, Val Acc=0.7064, Val Loss=1.5571, lr=0.0010
[2025-05-06 19:07:27,329][train][INFO] - Epoch 189/300, Val Acc=0.6702, Val Loss=1.6022, lr=0.0010
[2025-05-06 19:07:27,722][train][INFO] - Epoch 187/300, Val Acc=0.7059, Val Loss=1.5598, lr=0.0010
[2025-05-06 19:07:35,413][train][INFO] - Epoch 190/300, Val Acc=0.6688, Val Loss=1.6164, lr=0.0010
[2025-05-06 19:07:35,942][train][INFO] - Epoch 188/300, Val Acc=0.7043, Val Loss=1.5632, lr=0.0010
[2025-05-06 19:07:43,568][train][INFO] - Epoch 191/300, Val Acc=0.6714, Val Loss=1.6010, lr=0.0010
[2025-05-06 19:07:44,374][train][INFO] - Epoch 189/300, Val Acc=0.7042, Val Loss=1.5581, lr=0.0010
[2025-05-06 19:07:51,742][train][INFO] - Epoch 192/300, Val Acc=0.6726, Val Loss=1.6040, lr=0.0010
[2025-05-06 19:07:52,623][train][INFO] - Epoch 190/300, Val Acc=0.7045, Val Loss=1.5584, lr=0.0010
[2025-05-06 19:07:59,808][train][INFO] - Epoch 193/300, Val Acc=0.6689, Val Loss=1.6224, lr=0.0010
[2025-05-06 19:08:00,094][train][INFO] - Epoch 191/300, Val Acc=0.7029, Val Loss=1.5609, lr=0.0010
[2025-05-06 19:08:07,597][train][INFO] - Epoch 194/300, Val Acc=0.6713, Val Loss=1.6203, lr=0.0010
[2025-05-06 19:08:08,460][train][INFO] - Epoch 192/300, Val Acc=0.7077, Val Loss=1.5635, lr=0.0010
[2025-05-06 19:08:15,783][train][INFO] - Epoch 195/300, Val Acc=0.6701, Val Loss=1.6129, lr=0.0010
[2025-05-06 19:08:16,685][train][INFO] - Epoch 193/300, Val Acc=0.7061, Val Loss=1.5620, lr=0.0010
[2025-05-06 19:08:22,791][train][INFO] - Epoch 196/300, Val Acc=0.6711, Val Loss=1.6322, lr=0.0010
[2025-05-06 19:08:24,507][train][INFO] - Epoch 194/300, Val Acc=0.7052, Val Loss=1.5573, lr=0.0010
[2025-05-06 19:08:30,545][train][INFO] - Epoch 197/300, Val Acc=0.6732, Val Loss=1.6290, lr=0.0010
[2025-05-06 19:08:32,796][train][INFO] - Epoch 195/300, Val Acc=0.7071, Val Loss=1.5627, lr=0.0010
[2025-05-06 19:08:37,956][train][INFO] - Epoch 198/300, Val Acc=0.6689, Val Loss=1.6430, lr=0.0010
[2025-05-06 19:08:41,157][train][INFO] - Epoch 196/300, Val Acc=0.7070, Val Loss=1.5633, lr=0.0010
[2025-05-06 19:08:46,206][train][INFO] - Epoch 199/300, Val Acc=0.6733, Val Loss=1.6335, lr=0.0010
[2025-05-06 19:08:49,453][train][INFO] - Epoch 197/300, Val Acc=0.7053, Val Loss=1.5662, lr=0.0010
[2025-05-06 19:08:54,503][train][INFO] - Epoch 200/300, Val Acc=0.6678, Val Loss=1.6448, lr=0.0010
[2025-05-06 19:08:57,572][train][INFO] - Epoch 198/300, Val Acc=0.7069, Val Loss=1.5649, lr=0.0010
[2025-05-06 19:09:02,944][train][INFO] - Epoch 201/300, Val Acc=0.6701, Val Loss=1.6616, lr=0.0010
[2025-05-06 19:09:05,320][train][INFO] - Epoch 199/300, Val Acc=0.7085, Val Loss=1.5591, lr=0.0010
[2025-05-06 19:09:10,583][train][INFO] - Epoch 202/300, Val Acc=0.6678, Val Loss=1.6557, lr=0.0010
[2025-05-06 19:09:12,551][train][INFO] - Epoch 200/300, Val Acc=0.7082, Val Loss=1.5614, lr=0.0010
[2025-05-06 19:09:18,470][train][INFO] - Epoch 203/300, Val Acc=0.6706, Val Loss=1.6359, lr=0.0010
[2025-05-06 19:09:20,502][train][INFO] - Epoch 201/300, Val Acc=0.7073, Val Loss=1.5665, lr=0.0010
[2025-05-06 19:09:26,277][train][INFO] - Epoch 204/300, Val Acc=0.6686, Val Loss=1.6565, lr=0.0010
[2025-05-06 19:09:27,452][train][INFO] - Epoch 202/300, Val Acc=0.7053, Val Loss=1.5762, lr=0.0010
[2025-05-06 19:09:34,426][train][INFO] - Epoch 205/300, Val Acc=0.6702, Val Loss=1.6474, lr=0.0010
[2025-05-06 19:09:35,446][train][INFO] - Epoch 203/300, Val Acc=0.7072, Val Loss=1.5649, lr=0.0010
[2025-05-06 19:09:41,649][train][INFO] - Epoch 206/300, Val Acc=0.6677, Val Loss=1.6639, lr=0.0010
[2025-05-06 19:09:43,723][train][INFO] - Epoch 204/300, Val Acc=0.7070, Val Loss=1.5657, lr=0.0010
[2025-05-06 19:09:49,840][train][INFO] - Epoch 207/300, Val Acc=0.6703, Val Loss=1.6604, lr=0.0010
[2025-05-06 19:09:51,847][train][INFO] - Epoch 205/300, Val Acc=0.7085, Val Loss=1.5689, lr=0.0010
[2025-05-06 19:09:58,129][train][INFO] - Epoch 208/300, Val Acc=0.6714, Val Loss=1.6560, lr=0.0010
[2025-05-06 19:10:00,178][train][INFO] - Epoch 206/300, Val Acc=0.7064, Val Loss=1.5750, lr=0.0010
[2025-05-06 19:10:06,280][train][INFO] - Epoch 209/300, Val Acc=0.6689, Val Loss=1.6640, lr=0.0010
[2025-05-06 19:10:08,360][train][INFO] - Epoch 207/300, Val Acc=0.7075, Val Loss=1.5729, lr=0.0010
[2025-05-06 19:10:14,559][train][INFO] - Epoch 210/300, Val Acc=0.6703, Val Loss=1.6764, lr=0.0010
[2025-05-06 19:10:16,620][train][INFO] - Epoch 208/300, Val Acc=0.7046, Val Loss=1.5784, lr=0.0010
[2025-05-06 19:10:22,419][train][INFO] - Epoch 211/300, Val Acc=0.6678, Val Loss=1.6724, lr=0.0010
[2025-05-06 19:10:25,184][train][INFO] - Epoch 209/300, Val Acc=0.7073, Val Loss=1.5733, lr=0.0010
[2025-05-06 19:10:30,200][train][INFO] - Epoch 212/300, Val Acc=0.6688, Val Loss=1.6691, lr=0.0010
[2025-05-06 19:10:33,137][train][INFO] - Epoch 210/300, Val Acc=0.7090, Val Loss=1.5746, lr=0.0010
[2025-05-06 19:10:37,871][train][INFO] - Epoch 213/300, Val Acc=0.6723, Val Loss=1.6695, lr=0.0010
[2025-05-06 19:10:41,299][train][INFO] - Epoch 211/300, Val Acc=0.7112, Val Loss=1.5750, lr=0.0010
[2025-05-06 19:10:46,418][train][INFO] - Epoch 214/300, Val Acc=0.6697, Val Loss=1.6840, lr=0.0010
[2025-05-06 19:10:49,836][train][INFO] - Epoch 212/300, Val Acc=0.7083, Val Loss=1.5767, lr=0.0010
[2025-05-06 19:10:54,227][train][INFO] - Epoch 215/300, Val Acc=0.6671, Val Loss=1.7018, lr=0.0010
[2025-05-06 19:10:58,036][train][INFO] - Epoch 213/300, Val Acc=0.7052, Val Loss=1.5785, lr=0.0010
[2025-05-06 19:11:01,783][train][INFO] - Epoch 216/300, Val Acc=0.6699, Val Loss=1.6798, lr=0.0010
[2025-05-06 19:11:06,227][train][INFO] - Epoch 214/300, Val Acc=0.7063, Val Loss=1.5720, lr=0.0010
[2025-05-06 19:11:09,737][train][INFO] - Epoch 217/300, Val Acc=0.6654, Val Loss=1.6889, lr=0.0010
[2025-05-06 19:11:14,193][train][INFO] - Epoch 215/300, Val Acc=0.7087, Val Loss=1.5809, lr=0.0010
[2025-05-06 19:11:17,289][train][INFO] - Epoch 218/300, Val Acc=0.6704, Val Loss=1.6836, lr=0.0010
[2025-05-06 19:11:22,076][train][INFO] - Epoch 216/300, Val Acc=0.7074, Val Loss=1.5772, lr=0.0010
[2025-05-06 19:11:25,844][train][INFO] - Epoch 219/300, Val Acc=0.6673, Val Loss=1.6919, lr=0.0010
[2025-05-06 19:11:30,262][train][INFO] - Epoch 217/300, Val Acc=0.7093, Val Loss=1.5768, lr=0.0010
[2025-05-06 19:11:34,000][train][INFO] - Epoch 220/300, Val Acc=0.6695, Val Loss=1.6962, lr=0.0010
[2025-05-06 19:11:38,473][train][INFO] - Epoch 218/300, Val Acc=0.7083, Val Loss=1.5752, lr=0.0010
[2025-05-06 19:11:42,319][train][INFO] - Epoch 221/300, Val Acc=0.6684, Val Loss=1.6978, lr=0.0010
[2025-05-06 19:11:46,816][train][INFO] - Epoch 219/300, Val Acc=0.7063, Val Loss=1.5803, lr=0.0010
[2025-05-06 19:11:50,473][train][INFO] - Epoch 222/300, Val Acc=0.6676, Val Loss=1.7167, lr=0.0010
[2025-05-06 19:11:55,110][train][INFO] - Epoch 220/300, Val Acc=0.7081, Val Loss=1.5771, lr=0.0010
[2025-05-06 19:11:58,638][train][INFO] - Epoch 223/300, Val Acc=0.6669, Val Loss=1.7054, lr=0.0010
[2025-05-06 19:12:03,275][train][INFO] - Epoch 221/300, Val Acc=0.7057, Val Loss=1.5823, lr=0.0010
[2025-05-06 19:12:06,857][train][INFO] - Epoch 224/300, Val Acc=0.6656, Val Loss=1.7077, lr=0.0010
[2025-05-06 19:12:11,578][train][INFO] - Epoch 222/300, Val Acc=0.7082, Val Loss=1.5812, lr=0.0010
[2025-05-06 19:12:14,782][train][INFO] - Epoch 225/300, Val Acc=0.6657, Val Loss=1.7056, lr=0.0010
[2025-05-06 19:12:19,921][train][INFO] - Epoch 223/300, Val Acc=0.7076, Val Loss=1.5745, lr=0.0010
[2025-05-06 19:12:23,106][train][INFO] - Epoch 226/300, Val Acc=0.6705, Val Loss=1.6983, lr=0.0010
[2025-05-06 19:12:28,119][train][INFO] - Epoch 224/300, Val Acc=0.7074, Val Loss=1.5763, lr=0.0010
[2025-05-06 19:12:30,701][train][INFO] - Epoch 227/300, Val Acc=0.6700, Val Loss=1.7003, lr=0.0010
[2025-05-06 19:12:36,363][train][INFO] - Epoch 225/300, Val Acc=0.7084, Val Loss=1.5729, lr=0.0010
[2025-05-06 19:12:38,797][train][INFO] - Epoch 228/300, Val Acc=0.6683, Val Loss=1.7139, lr=0.0010
[2025-05-06 19:12:44,968][train][INFO] - Epoch 226/300, Val Acc=0.7072, Val Loss=1.5764, lr=0.0010
[2025-05-06 19:12:47,007][train][INFO] - Epoch 229/300, Val Acc=0.6677, Val Loss=1.7166, lr=0.0010
[2025-05-06 19:12:53,174][train][INFO] - Epoch 227/300, Val Acc=0.7085, Val Loss=1.5794, lr=0.0010
[2025-05-06 19:12:55,109][train][INFO] - Epoch 230/300, Val Acc=0.6650, Val Loss=1.7220, lr=0.0010
[2025-05-06 19:13:01,457][train][INFO] - Epoch 228/300, Val Acc=0.7091, Val Loss=1.5722, lr=0.0010
[2025-05-06 19:13:03,006][train][INFO] - Epoch 231/300, Val Acc=0.6639, Val Loss=1.7329, lr=0.0010
[2025-05-06 19:13:09,610][train][INFO] - Epoch 229/300, Val Acc=0.7083, Val Loss=1.5787, lr=0.0010
[2025-05-06 19:13:11,529][train][INFO] - Epoch 232/300, Val Acc=0.6711, Val Loss=1.7091, lr=0.0010
[2025-05-06 19:13:18,062][train][INFO] - Epoch 230/300, Val Acc=0.7072, Val Loss=1.5779, lr=0.0010
[2025-05-06 19:13:19,665][train][INFO] - Epoch 233/300, Val Acc=0.6657, Val Loss=1.7260, lr=0.0010
[2025-05-06 19:13:25,961][train][INFO] - Epoch 231/300, Val Acc=0.7085, Val Loss=1.5817, lr=0.0010
[2025-05-06 19:13:27,653][train][INFO] - Epoch 234/300, Val Acc=0.6679, Val Loss=1.7348, lr=0.0010
[2025-05-06 19:13:34,254][train][INFO] - Epoch 232/300, Val Acc=0.7076, Val Loss=1.5734, lr=0.0010
[2025-05-06 19:13:35,529][train][INFO] - Epoch 235/300, Val Acc=0.6671, Val Loss=1.7212, lr=0.0010
[2025-05-06 19:13:42,260][train][INFO] - Epoch 233/300, Val Acc=0.7076, Val Loss=1.5802, lr=0.0010
[2025-05-06 19:13:44,163][train][INFO] - Epoch 236/300, Val Acc=0.6692, Val Loss=1.7179, lr=0.0010
[2025-05-06 19:13:50,419][train][INFO] - Epoch 234/300, Val Acc=0.7065, Val Loss=1.5812, lr=0.0010
[2025-05-06 19:13:52,046][train][INFO] - Epoch 237/300, Val Acc=0.6676, Val Loss=1.7351, lr=0.0010
[2025-05-06 19:13:58,306][train][INFO] - Epoch 235/300, Val Acc=0.7097, Val Loss=1.5790, lr=0.0010
[2025-05-06 19:13:59,737][train][INFO] - Epoch 238/300, Val Acc=0.6690, Val Loss=1.7285, lr=0.0010
[2025-05-06 19:14:06,143][train][INFO] - Epoch 236/300, Val Acc=0.7097, Val Loss=1.5772, lr=0.0010
[2025-05-06 19:14:07,460][train][INFO] - Epoch 239/300, Val Acc=0.6645, Val Loss=1.7553, lr=0.0010
[2025-05-06 19:14:14,305][train][INFO] - Epoch 237/300, Val Acc=0.7084, Val Loss=1.5851, lr=0.0010
[2025-05-06 19:14:15,269][train][INFO] - Epoch 240/300, Val Acc=0.6639, Val Loss=1.7358, lr=0.0010
[2025-05-06 19:14:22,154][train][INFO] - Epoch 238/300, Val Acc=0.7113, Val Loss=1.5807, lr=0.0010
[2025-05-06 19:14:23,464][train][INFO] - Epoch 241/300, Val Acc=0.6666, Val Loss=1.7305, lr=0.0010
[2025-05-06 19:14:30,451][train][INFO] - Epoch 239/300, Val Acc=0.7081, Val Loss=1.5793, lr=0.0010
[2025-05-06 19:14:31,592][train][INFO] - Epoch 242/300, Val Acc=0.6698, Val Loss=1.7244, lr=0.0010
[2025-05-06 19:14:38,436][train][INFO] - Epoch 240/300, Val Acc=0.7091, Val Loss=1.5888, lr=0.0010
[2025-05-06 19:14:39,875][train][INFO] - Epoch 243/300, Val Acc=0.6713, Val Loss=1.7308, lr=0.0010
[2025-05-06 19:14:45,564][train][INFO] - Epoch 241/300, Val Acc=0.7095, Val Loss=1.5811, lr=0.0010
[2025-05-06 19:14:48,074][train][INFO] - Epoch 244/300, Val Acc=0.6704, Val Loss=1.7287, lr=0.0010
[2025-05-06 19:14:53,632][train][INFO] - Epoch 242/300, Val Acc=0.7091, Val Loss=1.5878, lr=0.0010
[2025-05-06 19:14:56,486][train][INFO] - Epoch 245/300, Val Acc=0.6698, Val Loss=1.7348, lr=0.0010
[2025-05-06 19:15:01,959][train][INFO] - Epoch 243/300, Val Acc=0.7076, Val Loss=1.5846, lr=0.0010
[2025-05-06 19:15:04,879][train][INFO] - Epoch 246/300, Val Acc=0.6695, Val Loss=1.7328, lr=0.0010
[2025-05-06 19:15:09,894][train][INFO] - Epoch 244/300, Val Acc=0.7093, Val Loss=1.5797, lr=0.0010
[2025-05-06 19:15:12,709][train][INFO] - Epoch 247/300, Val Acc=0.6718, Val Loss=1.7360, lr=0.0010
[2025-05-06 19:15:18,142][train][INFO] - Epoch 245/300, Val Acc=0.7089, Val Loss=1.5850, lr=0.0010
[2025-05-06 19:15:20,715][train][INFO] - Epoch 248/300, Val Acc=0.6683, Val Loss=1.7361, lr=0.0010
[2025-05-06 19:15:26,010][train][INFO] - Epoch 246/300, Val Acc=0.7088, Val Loss=1.5865, lr=0.0010
[2025-05-06 19:15:28,358][train][INFO] - Epoch 249/300, Val Acc=0.6702, Val Loss=1.7429, lr=0.0010
[2025-05-06 19:15:33,778][train][INFO] - Epoch 247/300, Val Acc=0.7111, Val Loss=1.5846, lr=0.0010
[2025-05-06 19:15:36,593][train][INFO] - Epoch 250/300, Val Acc=0.6670, Val Loss=1.7404, lr=0.0010
[2025-05-06 19:15:41,711][train][INFO] - Epoch 248/300, Val Acc=0.7074, Val Loss=1.5838, lr=0.0010
[2025-05-06 19:15:44,700][train][INFO] - Epoch 251/300, Val Acc=0.6699, Val Loss=1.7372, lr=0.0001
[2025-05-06 19:15:49,587][train][INFO] - Epoch 249/300, Val Acc=0.7083, Val Loss=1.5888, lr=0.0010
[2025-05-06 19:15:52,383][train][INFO] - Epoch 252/300, Val Acc=0.6710, Val Loss=1.7239, lr=0.0001
[2025-05-06 19:15:57,609][train][INFO] - Epoch 250/300, Val Acc=0.7101, Val Loss=1.5892, lr=0.0010
[2025-05-06 19:16:00,488][train][INFO] - Epoch 253/300, Val Acc=0.6717, Val Loss=1.7234, lr=0.0001
[2025-05-06 19:16:05,798][train][INFO] - Epoch 251/300, Val Acc=0.7110, Val Loss=1.5855, lr=0.0001
[2025-05-06 19:16:08,466][train][INFO] - Epoch 254/300, Val Acc=0.6723, Val Loss=1.7183, lr=0.0001
[2025-05-06 19:16:14,241][train][INFO] - Epoch 252/300, Val Acc=0.7101, Val Loss=1.5859, lr=0.0001
[2025-05-06 19:16:16,572][train][INFO] - Epoch 255/300, Val Acc=0.6721, Val Loss=1.7168, lr=0.0001
[2025-05-06 19:16:22,326][train][INFO] - Epoch 253/300, Val Acc=0.7102, Val Loss=1.5853, lr=0.0001
[2025-05-06 19:16:25,120][train][INFO] - Epoch 256/300, Val Acc=0.6728, Val Loss=1.7231, lr=0.0001
[2025-05-06 19:16:30,802][train][INFO] - Epoch 254/300, Val Acc=0.7110, Val Loss=1.5790, lr=0.0001
[2025-05-06 19:16:33,559][train][INFO] - Epoch 257/300, Val Acc=0.6722, Val Loss=1.7216, lr=0.0001
[2025-05-06 19:16:39,075][train][INFO] - Epoch 255/300, Val Acc=0.7098, Val Loss=1.5874, lr=0.0001
[2025-05-06 19:16:41,616][train][INFO] - Epoch 258/300, Val Acc=0.6751, Val Loss=1.7288, lr=0.0001
[2025-05-06 19:16:47,266][train][INFO] - Epoch 256/300, Val Acc=0.7114, Val Loss=1.5807, lr=0.0001
[2025-05-06 19:16:49,208][train][INFO] - Epoch 259/300, Val Acc=0.6727, Val Loss=1.7238, lr=0.0001
[2025-05-06 19:16:55,090][train][INFO] - Epoch 257/300, Val Acc=0.7119, Val Loss=1.5793, lr=0.0001
[2025-05-06 19:16:57,459][train][INFO] - Epoch 260/300, Val Acc=0.6738, Val Loss=1.7194, lr=0.0001
[2025-05-06 19:17:03,366][train][INFO] - Epoch 258/300, Val Acc=0.7109, Val Loss=1.5808, lr=0.0001
[2025-05-06 19:17:05,625][train][INFO] - Epoch 261/300, Val Acc=0.6721, Val Loss=1.7218, lr=0.0001
[2025-05-06 19:17:12,104][train][INFO] - Epoch 259/300, Val Acc=0.7102, Val Loss=1.5805, lr=0.0001
[2025-05-06 19:17:13,259][train][INFO] - Epoch 262/300, Val Acc=0.6713, Val Loss=1.7288, lr=0.0001
[2025-05-06 19:17:20,381][train][INFO] - Epoch 260/300, Val Acc=0.7125, Val Loss=1.5822, lr=0.0001
[2025-05-06 19:17:21,304][train][INFO] - Epoch 263/300, Val Acc=0.6731, Val Loss=1.7300, lr=0.0001
[2025-05-06 19:17:28,555][train][INFO] - Epoch 261/300, Val Acc=0.7109, Val Loss=1.5852, lr=0.0001
[2025-05-06 19:17:29,517][train][INFO] - Epoch 264/300, Val Acc=0.6732, Val Loss=1.7258, lr=0.0001
[2025-05-06 19:17:37,074][train][INFO] - Epoch 262/300, Val Acc=0.7115, Val Loss=1.5782, lr=0.0001
[2025-05-06 19:17:37,381][train][INFO] - Epoch 265/300, Val Acc=0.6724, Val Loss=1.7264, lr=0.0001
[2025-05-06 19:17:44,653][train][INFO] - Epoch 266/300, Val Acc=0.6745, Val Loss=1.7192, lr=0.0001
[2025-05-06 19:17:45,557][train][INFO] - Epoch 263/300, Val Acc=0.7109, Val Loss=1.5795, lr=0.0001
[2025-05-06 19:17:53,326][train][INFO] - Epoch 267/300, Val Acc=0.6754, Val Loss=1.7258, lr=0.0001
[2025-05-06 19:17:53,617][train][INFO] - Epoch 264/300, Val Acc=0.7091, Val Loss=1.5821, lr=0.0001
[2025-05-06 19:18:00,076][train][INFO] - Epoch 268/300, Val Acc=0.6731, Val Loss=1.7241, lr=0.0001
[2025-05-06 19:18:01,940][train][INFO] - Epoch 265/300, Val Acc=0.7124, Val Loss=1.5795, lr=0.0001
[2025-05-06 19:18:08,277][train][INFO] - Epoch 269/300, Val Acc=0.6718, Val Loss=1.7324, lr=0.0001
[2025-05-06 19:18:09,458][train][INFO] - Epoch 266/300, Val Acc=0.7097, Val Loss=1.5786, lr=0.0001
[2025-05-06 19:18:16,485][train][INFO] - Epoch 270/300, Val Acc=0.6718, Val Loss=1.7271, lr=0.0001
[2025-05-06 19:18:17,716][train][INFO] - Epoch 267/300, Val Acc=0.7102, Val Loss=1.5804, lr=0.0001
[2025-05-06 19:18:24,200][train][INFO] - Epoch 271/300, Val Acc=0.6723, Val Loss=1.7235, lr=0.0001
[2025-05-06 19:18:25,810][train][INFO] - Epoch 268/300, Val Acc=0.7100, Val Loss=1.5831, lr=0.0001
[2025-05-06 19:18:32,048][train][INFO] - Epoch 272/300, Val Acc=0.6724, Val Loss=1.7252, lr=0.0001
[2025-05-06 19:18:33,134][train][INFO] - Epoch 269/300, Val Acc=0.7101, Val Loss=1.5842, lr=0.0001
[2025-05-06 19:18:39,791][train][INFO] - Epoch 273/300, Val Acc=0.6727, Val Loss=1.7294, lr=0.0001
[2025-05-06 19:18:41,149][train][INFO] - Epoch 270/300, Val Acc=0.7121, Val Loss=1.5818, lr=0.0001
[2025-05-06 19:18:47,822][train][INFO] - Epoch 274/300, Val Acc=0.6743, Val Loss=1.7299, lr=0.0001
[2025-05-06 19:18:49,209][train][INFO] - Epoch 271/300, Val Acc=0.7107, Val Loss=1.5807, lr=0.0001
[2025-05-06 19:18:55,761][train][INFO] - Epoch 275/300, Val Acc=0.6734, Val Loss=1.7311, lr=0.0001
[2025-05-06 19:18:57,549][train][INFO] - Epoch 272/300, Val Acc=0.7112, Val Loss=1.5792, lr=0.0001
[2025-05-06 19:19:03,742][train][INFO] - Epoch 276/300, Val Acc=0.6751, Val Loss=1.7237, lr=0.0001
[2025-05-06 19:19:05,016][train][INFO] - Epoch 273/300, Val Acc=0.7113, Val Loss=1.5792, lr=0.0001
[2025-05-06 19:19:11,818][train][INFO] - Epoch 277/300, Val Acc=0.6740, Val Loss=1.7288, lr=0.0001
[2025-05-06 19:19:13,158][train][INFO] - Epoch 274/300, Val Acc=0.7103, Val Loss=1.5798, lr=0.0001
[2025-05-06 19:19:20,015][train][INFO] - Epoch 278/300, Val Acc=0.6751, Val Loss=1.7306, lr=0.0001
[2025-05-06 19:19:20,982][train][INFO] - Epoch 275/300, Val Acc=0.7120, Val Loss=1.5765, lr=0.0001
[2025-05-06 19:19:27,733][train][INFO] - Epoch 279/300, Val Acc=0.6757, Val Loss=1.7258, lr=0.0001
[2025-05-06 19:19:29,266][train][INFO] - Epoch 276/300, Val Acc=0.7102, Val Loss=1.5793, lr=0.0001
[2025-05-06 19:19:35,339][train][INFO] - Epoch 280/300, Val Acc=0.6751, Val Loss=1.7307, lr=0.0001
[2025-05-06 19:19:36,891][train][INFO] - Epoch 277/300, Val Acc=0.7105, Val Loss=1.5820, lr=0.0001
[2025-05-06 19:19:43,074][train][INFO] - Epoch 281/300, Val Acc=0.6748, Val Loss=1.7370, lr=0.0001
[2025-05-06 19:19:44,909][train][INFO] - Epoch 278/300, Val Acc=0.7115, Val Loss=1.5783, lr=0.0001
[2025-05-06 19:19:50,766][train][INFO] - Epoch 282/300, Val Acc=0.6772, Val Loss=1.7288, lr=0.0001
[2025-05-06 19:19:52,793][train][INFO] - Epoch 279/300, Val Acc=0.7102, Val Loss=1.5824, lr=0.0001
[2025-05-06 19:19:58,156][train][INFO] - Epoch 283/300, Val Acc=0.6737, Val Loss=1.7298, lr=0.0001
[2025-05-06 19:20:00,672][train][INFO] - Epoch 280/300, Val Acc=0.7097, Val Loss=1.5815, lr=0.0001
[2025-05-06 19:20:06,050][train][INFO] - Epoch 284/300, Val Acc=0.6736, Val Loss=1.7311, lr=0.0001
[2025-05-06 19:20:09,051][train][INFO] - Epoch 281/300, Val Acc=0.7104, Val Loss=1.5817, lr=0.0001
[2025-05-06 19:20:14,462][train][INFO] - Epoch 285/300, Val Acc=0.6721, Val Loss=1.7302, lr=0.0001
[2025-05-06 19:20:17,339][train][INFO] - Epoch 282/300, Val Acc=0.7116, Val Loss=1.5755, lr=0.0001
[2025-05-06 19:20:22,532][train][INFO] - Epoch 286/300, Val Acc=0.6736, Val Loss=1.7342, lr=0.0001
[2025-05-06 19:20:25,660][train][INFO] - Epoch 283/300, Val Acc=0.7108, Val Loss=1.5752, lr=0.0001
[2025-05-06 19:20:30,652][train][INFO] - Epoch 287/300, Val Acc=0.6752, Val Loss=1.7357, lr=0.0001
[2025-05-06 19:20:33,722][train][INFO] - Epoch 284/300, Val Acc=0.7119, Val Loss=1.5842, lr=0.0001
[2025-05-06 19:20:38,059][train][INFO] - Epoch 288/300, Val Acc=0.6753, Val Loss=1.7399, lr=0.0001
[2025-05-06 19:20:41,981][train][INFO] - Epoch 285/300, Val Acc=0.7111, Val Loss=1.5771, lr=0.0001
[2025-05-06 19:20:46,244][train][INFO] - Epoch 289/300, Val Acc=0.6746, Val Loss=1.7356, lr=0.0001
[2025-05-06 19:20:50,253][train][INFO] - Epoch 286/300, Val Acc=0.7088, Val Loss=1.5801, lr=0.0001
[2025-05-06 19:20:54,578][train][INFO] - Epoch 290/300, Val Acc=0.6755, Val Loss=1.7436, lr=0.0001
[2025-05-06 19:20:58,782][train][INFO] - Epoch 287/300, Val Acc=0.7105, Val Loss=1.5818, lr=0.0001
[2025-05-06 19:21:02,728][train][INFO] - Epoch 291/300, Val Acc=0.6750, Val Loss=1.7380, lr=0.0001
[2025-05-06 19:21:06,765][train][INFO] - Epoch 288/300, Val Acc=0.7114, Val Loss=1.5788, lr=0.0001
[2025-05-06 19:21:10,973][train][INFO] - Epoch 292/300, Val Acc=0.6744, Val Loss=1.7385, lr=0.0001
[2025-05-06 19:21:14,397][train][INFO] - Epoch 289/300, Val Acc=0.7111, Val Loss=1.5768, lr=0.0001
[2025-05-06 19:21:18,106][train][INFO] - Epoch 293/300, Val Acc=0.6735, Val Loss=1.7361, lr=0.0001
[2025-05-06 19:21:22,943][train][INFO] - Epoch 290/300, Val Acc=0.7095, Val Loss=1.5795, lr=0.0001
[2025-05-06 19:21:25,719][train][INFO] - Epoch 294/300, Val Acc=0.6755, Val Loss=1.7452, lr=0.0001
[2025-05-06 19:21:30,651][train][INFO] - Epoch 291/300, Val Acc=0.7105, Val Loss=1.5797, lr=0.0001
[2025-05-06 19:21:33,602][train][INFO] - Epoch 295/300, Val Acc=0.6753, Val Loss=1.7383, lr=0.0001
[2025-05-06 19:21:38,418][train][INFO] - Epoch 292/300, Val Acc=0.7117, Val Loss=1.5762, lr=0.0001
[2025-05-06 19:21:41,489][train][INFO] - Epoch 296/300, Val Acc=0.6743, Val Loss=1.7340, lr=0.0001
[2025-05-06 19:21:46,708][train][INFO] - Epoch 293/300, Val Acc=0.7104, Val Loss=1.5792, lr=0.0001
[2025-05-06 19:21:48,856][train][INFO] - Epoch 297/300, Val Acc=0.6728, Val Loss=1.7435, lr=0.0001
[2025-05-06 19:21:54,618][train][INFO] - Epoch 294/300, Val Acc=0.7113, Val Loss=1.5844, lr=0.0001
[2025-05-06 19:21:56,843][train][INFO] - Epoch 298/300, Val Acc=0.6749, Val Loss=1.7386, lr=0.0001
[2025-05-06 19:22:02,266][train][INFO] - Epoch 295/300, Val Acc=0.7129, Val Loss=1.5768, lr=0.0001
[2025-05-06 19:22:04,676][train][INFO] - Epoch 299/300, Val Acc=0.6739, Val Loss=1.7412, lr=0.0001
[2025-05-06 19:22:10,159][train][INFO] - Epoch 296/300, Val Acc=0.7114, Val Loss=1.5823, lr=0.0001
[2025-05-06 19:22:12,133][train][INFO] - Epoch 300/300, Val Acc=0.6731, Val Loss=1.7365, lr=0.0001
[2025-05-06 19:22:17,249][train][INFO] - After training : Train Acc=0.9456  Val Acc=0.6775
[2025-05-06 19:22:17,255][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 19:22:18,425][train][INFO] - Epoch 297/300, Val Acc=0.7110, Val Loss=1.5777, lr=0.0001
[2025-05-06 19:22:26,290][train][INFO] - Epoch 298/300, Val Acc=0.7108, Val Loss=1.5776, lr=0.0001
[2025-05-06 19:22:34,033][train][INFO] - Epoch 299/300, Val Acc=0.7113, Val Loss=1.5810, lr=0.0001
[2025-05-06 19:22:41,689][train][INFO] - Epoch 300/300, Val Acc=0.7096, Val Loss=1.5803, lr=0.0001
[2025-05-06 19:22:46,959][train][INFO] - After training : Train Acc=0.9996  Val Acc=0.7129
[2025-05-06 19:22:46,970][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 19:23:58,930][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 19:24:32,231][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 19:26:21,661][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 19:26:22,122][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 19:26:59,829][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 19:27:00,231][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 19:48:47,164][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 400
        lr: 0.1
        lr_decay_milestones: 100, 250, 350
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 400
        lr: 0.1
        lr_decay_milestones: 100, 250, 350
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-06 19:48:47,244][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 19:48:47,244][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 19:48:47,244][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 19:48:51,246][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 400
        lr: 0.1
        lr_decay_milestones: 100, 250, 350
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 400
        lr: 0.1
        lr_decay_milestones: 100, 250, 350
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-06 19:48:51,322][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 19:48:51,322][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 19:48:51,322][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 19:49:06,779][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 19:49:10,697][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 19:49:14,728][train][INFO] - Epoch 1/400, Val Acc=0.0307, Val Loss=4.2826, lr=0.1000
[2025-05-06 19:49:18,558][train][INFO] - Epoch 1/400, Val Acc=0.0504, Val Loss=4.1361, lr=0.1000
[2025-05-06 19:49:22,936][train][INFO] - Epoch 2/400, Val Acc=0.0206, Val Loss=4.8229, lr=0.1000
[2025-05-06 19:49:26,750][train][INFO] - Epoch 2/400, Val Acc=0.0592, Val Loss=3.9966, lr=0.1000
[2025-05-06 19:49:31,500][train][INFO] - Epoch 3/400, Val Acc=0.0446, Val Loss=4.1575, lr=0.1000
[2025-05-06 19:49:35,034][train][INFO] - Epoch 3/400, Val Acc=0.0436, Val Loss=4.8956, lr=0.1000
[2025-05-06 19:49:39,569][train][INFO] - Epoch 4/400, Val Acc=0.0581, Val Loss=4.1740, lr=0.1000
[2025-05-06 19:49:43,285][train][INFO] - Epoch 4/400, Val Acc=0.0766, Val Loss=3.8981, lr=0.1000
[2025-05-06 19:49:47,860][train][INFO] - Epoch 5/400, Val Acc=0.0785, Val Loss=3.7707, lr=0.1000
[2025-05-06 19:49:50,407][train][INFO] - Epoch 5/400, Val Acc=0.0448, Val Loss=4.7152, lr=0.1000
[2025-05-06 19:49:56,562][train][INFO] - Epoch 6/400, Val Acc=0.1177, Val Loss=3.6453, lr=0.1000
[2025-05-06 19:49:58,457][train][INFO] - Epoch 6/400, Val Acc=0.0867, Val Loss=3.8529, lr=0.1000
[2025-05-06 19:50:04,338][train][INFO] - Epoch 7/400, Val Acc=0.0895, Val Loss=3.8801, lr=0.1000
[2025-05-06 19:50:06,307][train][INFO] - Epoch 7/400, Val Acc=0.0946, Val Loss=3.9865, lr=0.1000
[2025-05-06 19:50:12,600][train][INFO] - Epoch 8/400, Val Acc=0.1335, Val Loss=3.4357, lr=0.1000
[2025-05-06 19:50:13,697][train][INFO] - Epoch 8/400, Val Acc=0.1395, Val Loss=3.4514, lr=0.1000
[2025-05-06 19:50:20,705][train][INFO] - Epoch 9/400, Val Acc=0.1372, Val Loss=3.5229, lr=0.1000
[2025-05-06 19:50:22,033][train][INFO] - Epoch 9/400, Val Acc=0.1485, Val Loss=3.5630, lr=0.1000
[2025-05-06 19:50:29,357][train][INFO] - Epoch 10/400, Val Acc=0.0862, Val Loss=4.1729, lr=0.1000
[2025-05-06 19:50:30,078][train][INFO] - Epoch 10/400, Val Acc=0.1380, Val Loss=3.5596, lr=0.1000
[2025-05-06 19:50:37,299][train][INFO] - Epoch 11/400, Val Acc=0.2034, Val Loss=3.0658, lr=0.1000
[2025-05-06 19:50:37,506][train][INFO] - Epoch 11/400, Val Acc=0.1134, Val Loss=4.0379, lr=0.1000
[2025-05-06 19:50:45,464][train][INFO] - Epoch 12/400, Val Acc=0.1255, Val Loss=3.9087, lr=0.1000
[2025-05-06 19:50:45,719][train][INFO] - Epoch 12/400, Val Acc=0.1896, Val Loss=3.1248, lr=0.1000
[2025-05-06 19:50:53,369][train][INFO] - Epoch 13/400, Val Acc=0.1230, Val Loss=3.7816, lr=0.1000
[2025-05-06 19:50:53,474][train][INFO] - Epoch 13/400, Val Acc=0.2240, Val Loss=3.1040, lr=0.1000
[2025-05-06 19:51:01,547][train][INFO] - Epoch 14/400, Val Acc=0.2310, Val Loss=2.9844, lr=0.1000
[2025-05-06 19:51:01,874][train][INFO] - Epoch 14/400, Val Acc=0.1712, Val Loss=3.3551, lr=0.1000
[2025-05-06 19:51:09,521][train][INFO] - Epoch 15/400, Val Acc=0.1657, Val Loss=3.6857, lr=0.1000
[2025-05-06 19:51:09,638][train][INFO] - Epoch 15/400, Val Acc=0.1685, Val Loss=3.7140, lr=0.1000
[2025-05-06 19:51:16,882][train][INFO] - Epoch 16/400, Val Acc=0.2006, Val Loss=3.4223, lr=0.1000
[2025-05-06 19:51:17,344][train][INFO] - Epoch 16/400, Val Acc=0.1141, Val Loss=5.1848, lr=0.1000
[2025-05-06 19:51:25,219][train][INFO] - Epoch 17/400, Val Acc=0.0796, Val Loss=4.4871, lr=0.1000
[2025-05-06 19:51:25,245][train][INFO] - Epoch 17/400, Val Acc=0.2383, Val Loss=3.0441, lr=0.1000
[2025-05-06 19:51:32,321][train][INFO] - Epoch 18/400, Val Acc=0.2512, Val Loss=2.9606, lr=0.1000
[2025-05-06 19:51:33,325][train][INFO] - Epoch 18/400, Val Acc=0.1378, Val Loss=3.5853, lr=0.1000
[2025-05-06 19:51:40,640][train][INFO] - Epoch 19/400, Val Acc=0.3059, Val Loss=2.6818, lr=0.1000
[2025-05-06 19:51:42,147][train][INFO] - Epoch 19/400, Val Acc=0.1740, Val Loss=3.3686, lr=0.1000
[2025-05-06 19:51:48,385][train][INFO] - Epoch 20/400, Val Acc=0.3086, Val Loss=2.6877, lr=0.1000
[2025-05-06 19:51:49,604][train][INFO] - Epoch 20/400, Val Acc=0.1945, Val Loss=3.1031, lr=0.1000
[2025-05-06 19:51:56,515][train][INFO] - Epoch 21/400, Val Acc=0.2103, Val Loss=3.1889, lr=0.1000
[2025-05-06 19:51:58,232][train][INFO] - Epoch 21/400, Val Acc=0.2265, Val Loss=2.9929, lr=0.1000
[2025-05-06 19:52:04,749][train][INFO] - Epoch 22/400, Val Acc=0.2657, Val Loss=2.8830, lr=0.1000
[2025-05-06 19:52:06,833][train][INFO] - Epoch 22/400, Val Acc=0.2098, Val Loss=3.1481, lr=0.1000
[2025-05-06 19:52:12,776][train][INFO] - Epoch 23/400, Val Acc=0.2765, Val Loss=2.7497, lr=0.1000
[2025-05-06 19:52:15,252][train][INFO] - Epoch 23/400, Val Acc=0.2255, Val Loss=3.0745, lr=0.1000
[2025-05-06 19:52:20,578][train][INFO] - Epoch 24/400, Val Acc=0.2698, Val Loss=3.1016, lr=0.1000
[2025-05-06 19:52:23,678][train][INFO] - Epoch 24/400, Val Acc=0.2312, Val Loss=2.9697, lr=0.1000
[2025-05-06 19:52:28,034][train][INFO] - Epoch 25/400, Val Acc=0.3201, Val Loss=2.6642, lr=0.1000
[2025-05-06 19:52:32,273][train][INFO] - Epoch 25/400, Val Acc=0.2163, Val Loss=3.0405, lr=0.1000
[2025-05-06 19:52:36,255][train][INFO] - Epoch 26/400, Val Acc=0.3224, Val Loss=2.6959, lr=0.1000
[2025-05-06 19:52:40,505][train][INFO] - Epoch 26/400, Val Acc=0.2236, Val Loss=3.1683, lr=0.1000
[2025-05-06 19:52:44,167][train][INFO] - Epoch 27/400, Val Acc=0.2916, Val Loss=2.9202, lr=0.1000
[2025-05-06 19:52:48,326][train][INFO] - Epoch 27/400, Val Acc=0.2123, Val Loss=3.2221, lr=0.1000
[2025-05-06 19:52:52,303][train][INFO] - Epoch 28/400, Val Acc=0.3384, Val Loss=2.6124, lr=0.1000
[2025-05-06 19:52:56,762][train][INFO] - Epoch 28/400, Val Acc=0.1409, Val Loss=3.7357, lr=0.1000
[2025-05-06 19:53:00,534][train][INFO] - Epoch 29/400, Val Acc=0.2857, Val Loss=3.0237, lr=0.1000
[2025-05-06 19:53:05,533][train][INFO] - Epoch 29/400, Val Acc=0.2284, Val Loss=3.0193, lr=0.1000
[2025-05-06 19:53:08,629][train][INFO] - Epoch 30/400, Val Acc=0.2705, Val Loss=2.8736, lr=0.1000
[2025-05-06 19:53:13,898][train][INFO] - Epoch 30/400, Val Acc=0.1868, Val Loss=3.4767, lr=0.1000
[2025-05-06 19:53:16,617][train][INFO] - Epoch 31/400, Val Acc=0.3199, Val Loss=2.8356, lr=0.1000
[2025-05-06 19:53:21,678][train][INFO] - Epoch 31/400, Val Acc=0.2030, Val Loss=3.2316, lr=0.1000
[2025-05-06 19:53:24,538][train][INFO] - Epoch 32/400, Val Acc=0.3463, Val Loss=2.5269, lr=0.1000
[2025-05-06 19:53:30,110][train][INFO] - Epoch 32/400, Val Acc=0.2115, Val Loss=3.2288, lr=0.1000
[2025-05-06 19:53:32,187][train][INFO] - Epoch 33/400, Val Acc=0.3685, Val Loss=2.5047, lr=0.1000
[2025-05-06 19:53:38,674][train][INFO] - Epoch 33/400, Val Acc=0.2292, Val Loss=2.9801, lr=0.1000
[2025-05-06 19:53:40,376][train][INFO] - Epoch 34/400, Val Acc=0.2343, Val Loss=3.3974, lr=0.1000
[2025-05-06 19:53:45,761][train][INFO] - Epoch 34/400, Val Acc=0.1001, Val Loss=4.4057, lr=0.1000
[2025-05-06 19:53:48,678][train][INFO] - Epoch 35/400, Val Acc=0.3806, Val Loss=2.4177, lr=0.1000
[2025-05-06 19:53:54,348][train][INFO] - Epoch 35/400, Val Acc=0.2300, Val Loss=3.1316, lr=0.1000
[2025-05-06 19:53:56,729][train][INFO] - Epoch 36/400, Val Acc=0.2834, Val Loss=3.2207, lr=0.1000
[2025-05-06 19:54:02,245][train][INFO] - Epoch 36/400, Val Acc=0.2358, Val Loss=2.9414, lr=0.1000
[2025-05-06 19:54:04,338][train][INFO] - Epoch 37/400, Val Acc=0.3812, Val Loss=2.4065, lr=0.1000
[2025-05-06 19:54:10,842][train][INFO] - Epoch 37/400, Val Acc=0.2350, Val Loss=2.9357, lr=0.1000
[2025-05-06 19:54:12,611][train][INFO] - Epoch 38/400, Val Acc=0.3240, Val Loss=2.7433, lr=0.1000
[2025-05-06 19:54:19,199][train][INFO] - Epoch 38/400, Val Acc=0.2288, Val Loss=3.1853, lr=0.1000
[2025-05-06 19:54:20,849][train][INFO] - Epoch 39/400, Val Acc=0.3375, Val Loss=2.8684, lr=0.1000
[2025-05-06 19:54:26,836][train][INFO] - Epoch 39/400, Val Acc=0.1960, Val Loss=3.2292, lr=0.1000
[2025-05-06 19:54:29,157][train][INFO] - Epoch 40/400, Val Acc=0.3322, Val Loss=2.8470, lr=0.1000
[2025-05-06 19:54:35,018][train][INFO] - Epoch 40/400, Val Acc=0.1548, Val Loss=3.8008, lr=0.1000
[2025-05-06 19:54:37,055][train][INFO] - Epoch 41/400, Val Acc=0.3675, Val Loss=2.5622, lr=0.1000
[2025-05-06 19:54:43,204][train][INFO] - Epoch 41/400, Val Acc=0.2466, Val Loss=2.9678, lr=0.1000
[2025-05-06 19:54:44,736][train][INFO] - Epoch 42/400, Val Acc=0.3878, Val Loss=2.4869, lr=0.1000
[2025-05-06 19:54:51,250][train][INFO] - Epoch 42/400, Val Acc=0.1060, Val Loss=4.0904, lr=0.1000
[2025-05-06 19:54:52,973][train][INFO] - Epoch 43/400, Val Acc=0.3778, Val Loss=2.4334, lr=0.1000
[2025-05-06 19:54:58,524][train][INFO] - Epoch 43/400, Val Acc=0.1293, Val Loss=3.6625, lr=0.1000
[2025-05-06 19:55:00,714][train][INFO] - Epoch 44/400, Val Acc=0.2598, Val Loss=3.2114, lr=0.1000
[2025-05-06 19:55:06,652][train][INFO] - Epoch 44/400, Val Acc=0.2571, Val Loss=2.9152, lr=0.1000
[2025-05-06 19:55:08,268][train][INFO] - Epoch 45/400, Val Acc=0.3852, Val Loss=2.4897, lr=0.1000
[2025-05-06 19:55:14,490][train][INFO] - Epoch 45/400, Val Acc=0.1718, Val Loss=3.4335, lr=0.1000
[2025-05-06 19:55:16,090][train][INFO] - Epoch 46/400, Val Acc=0.2824, Val Loss=3.2499, lr=0.1000
[2025-05-06 19:55:22,949][train][INFO] - Epoch 46/400, Val Acc=0.2351, Val Loss=3.2627, lr=0.1000
[2025-05-06 19:55:24,214][train][INFO] - Epoch 47/400, Val Acc=0.4046, Val Loss=2.4461, lr=0.1000
[2025-05-06 19:55:31,678][train][INFO] - Epoch 47/400, Val Acc=0.2253, Val Loss=3.3531, lr=0.1000
[2025-05-06 19:55:32,638][train][INFO] - Epoch 48/400, Val Acc=0.4263, Val Loss=2.2122, lr=0.1000
[2025-05-06 19:55:39,989][train][INFO] - Epoch 48/400, Val Acc=0.2385, Val Loss=3.1108, lr=0.1000
[2025-05-06 19:55:40,556][train][INFO] - Epoch 49/400, Val Acc=0.3977, Val Loss=2.5320, lr=0.1000
[2025-05-06 19:55:48,516][train][INFO] - Epoch 49/400, Val Acc=0.1932, Val Loss=3.5793, lr=0.1000
[2025-05-06 19:55:48,665][train][INFO] - Epoch 50/400, Val Acc=0.3727, Val Loss=2.5007, lr=0.1000
[2025-05-06 19:55:56,264][train][INFO] - Epoch 51/400, Val Acc=0.3285, Val Loss=2.8760, lr=0.1000
[2025-05-06 19:55:56,918][train][INFO] - Epoch 50/400, Val Acc=0.2038, Val Loss=3.2594, lr=0.1000
[2025-05-06 19:56:04,553][train][INFO] - Epoch 52/400, Val Acc=0.3834, Val Loss=2.4808, lr=0.1000
[2025-05-06 19:56:04,923][train][INFO] - Epoch 51/400, Val Acc=0.1660, Val Loss=3.4518, lr=0.1000
[2025-05-06 19:56:12,791][train][INFO] - Epoch 53/400, Val Acc=0.3641, Val Loss=2.6176, lr=0.1000
[2025-05-06 19:56:13,757][train][INFO] - Epoch 52/400, Val Acc=0.2173, Val Loss=3.5319, lr=0.1000
[2025-05-06 19:56:20,991][train][INFO] - Epoch 54/400, Val Acc=0.3398, Val Loss=2.5928, lr=0.1000
[2025-05-06 19:56:21,920][train][INFO] - Epoch 53/400, Val Acc=0.1932, Val Loss=3.5492, lr=0.1000
[2025-05-06 19:56:28,647][train][INFO] - Epoch 55/400, Val Acc=0.4314, Val Loss=2.2769, lr=0.1000
[2025-05-06 19:56:29,739][train][INFO] - Epoch 54/400, Val Acc=0.2441, Val Loss=3.1236, lr=0.1000
[2025-05-06 19:56:36,727][train][INFO] - Epoch 56/400, Val Acc=0.3496, Val Loss=2.5978, lr=0.1000
[2025-05-06 19:56:38,156][train][INFO] - Epoch 55/400, Val Acc=0.2432, Val Loss=3.2067, lr=0.1000
[2025-05-06 19:56:44,727][train][INFO] - Epoch 57/400, Val Acc=0.3841, Val Loss=2.5903, lr=0.1000
[2025-05-06 19:56:46,543][train][INFO] - Epoch 56/400, Val Acc=0.2079, Val Loss=3.7920, lr=0.1000
[2025-05-06 19:56:53,112][train][INFO] - Epoch 58/400, Val Acc=0.4027, Val Loss=2.3633, lr=0.1000
[2025-05-06 19:56:55,001][train][INFO] - Epoch 57/400, Val Acc=0.2681, Val Loss=2.8544, lr=0.1000
[2025-05-06 19:57:00,592][train][INFO] - Epoch 59/400, Val Acc=0.3605, Val Loss=2.6764, lr=0.1000
[2025-05-06 19:57:03,712][train][INFO] - Epoch 58/400, Val Acc=0.2856, Val Loss=2.6735, lr=0.1000
[2025-05-06 19:57:08,749][train][INFO] - Epoch 60/400, Val Acc=0.4214, Val Loss=2.2418, lr=0.1000
[2025-05-06 19:57:11,686][train][INFO] - Epoch 59/400, Val Acc=0.2132, Val Loss=3.3104, lr=0.1000
[2025-05-06 19:57:16,542][train][INFO] - Epoch 61/400, Val Acc=0.3096, Val Loss=2.8356, lr=0.1000
[2025-05-06 19:57:19,877][train][INFO] - Epoch 60/400, Val Acc=0.3020, Val Loss=2.7232, lr=0.1000
[2025-05-06 19:57:24,422][train][INFO] - Epoch 62/400, Val Acc=0.3915, Val Loss=2.4087, lr=0.1000
[2025-05-06 19:57:28,264][train][INFO] - Epoch 61/400, Val Acc=0.2838, Val Loss=2.8321, lr=0.1000
[2025-05-06 19:57:31,915][train][INFO] - Epoch 63/400, Val Acc=0.3109, Val Loss=3.1209, lr=0.1000
[2025-05-06 19:57:35,804][train][INFO] - Epoch 62/400, Val Acc=0.2282, Val Loss=3.0102, lr=0.1000
[2025-05-06 19:57:39,688][train][INFO] - Epoch 64/400, Val Acc=0.4199, Val Loss=2.2736, lr=0.1000
[2025-05-06 19:57:43,943][train][INFO] - Epoch 63/400, Val Acc=0.2055, Val Loss=3.6535, lr=0.1000
[2025-05-06 19:57:47,794][train][INFO] - Epoch 65/400, Val Acc=0.3740, Val Loss=2.5884, lr=0.1000
[2025-05-06 19:57:52,650][train][INFO] - Epoch 64/400, Val Acc=0.1931, Val Loss=3.1301, lr=0.1000
[2025-05-06 19:57:55,453][train][INFO] - Epoch 66/400, Val Acc=0.4101, Val Loss=2.4469, lr=0.1000
[2025-05-06 19:58:01,032][train][INFO] - Epoch 65/400, Val Acc=0.2346, Val Loss=3.0815, lr=0.1000
[2025-05-06 19:58:03,747][train][INFO] - Epoch 67/400, Val Acc=0.3886, Val Loss=2.6742, lr=0.1000
[2025-05-06 19:58:08,809][train][INFO] - Epoch 66/400, Val Acc=0.2159, Val Loss=3.1360, lr=0.1000
[2025-05-06 19:58:11,363][train][INFO] - Epoch 68/400, Val Acc=0.3050, Val Loss=3.2128, lr=0.1000
[2025-05-06 19:58:16,116][train][INFO] - Epoch 67/400, Val Acc=0.2114, Val Loss=3.1797, lr=0.1000
[2025-05-06 19:58:19,221][train][INFO] - Epoch 69/400, Val Acc=0.4109, Val Loss=2.3254, lr=0.1000
[2025-05-06 19:58:24,515][train][INFO] - Epoch 68/400, Val Acc=0.2799, Val Loss=2.7398, lr=0.1000
[2025-05-06 19:58:27,417][train][INFO] - Epoch 70/400, Val Acc=0.4317, Val Loss=2.2606, lr=0.1000
[2025-05-06 19:58:32,695][train][INFO] - Epoch 69/400, Val Acc=0.3011, Val Loss=2.7246, lr=0.1000
[2025-05-06 19:58:35,166][train][INFO] - Epoch 71/400, Val Acc=0.3933, Val Loss=2.4602, lr=0.1000
[2025-05-06 19:58:41,165][train][INFO] - Epoch 70/400, Val Acc=0.2537, Val Loss=2.9534, lr=0.1000
[2025-05-06 19:58:43,270][train][INFO] - Epoch 72/400, Val Acc=0.3493, Val Loss=2.7382, lr=0.1000
[2025-05-06 19:58:48,998][train][INFO] - Epoch 71/400, Val Acc=0.2167, Val Loss=3.4654, lr=0.1000
[2025-05-06 19:58:51,012][train][INFO] - Epoch 73/400, Val Acc=0.4154, Val Loss=2.3872, lr=0.1000
[2025-05-06 19:58:57,353][train][INFO] - Epoch 72/400, Val Acc=0.2791, Val Loss=2.9901, lr=0.1000
[2025-05-06 19:58:59,521][train][INFO] - Epoch 74/400, Val Acc=0.4005, Val Loss=2.4544, lr=0.1000
[2025-05-06 19:59:05,151][train][INFO] - Epoch 73/400, Val Acc=0.2760, Val Loss=2.8640, lr=0.1000
[2025-05-06 19:59:06,738][train][INFO] - Epoch 75/400, Val Acc=0.3667, Val Loss=2.6171, lr=0.1000
[2025-05-06 19:59:13,208][train][INFO] - Epoch 74/400, Val Acc=0.2668, Val Loss=2.9307, lr=0.1000
[2025-05-06 19:59:14,429][train][INFO] - Epoch 76/400, Val Acc=0.2922, Val Loss=3.6949, lr=0.1000
[2025-05-06 19:59:20,486][train][INFO] - Epoch 75/400, Val Acc=0.2868, Val Loss=2.7889, lr=0.1000
[2025-05-06 19:59:22,586][train][INFO] - Epoch 77/400, Val Acc=0.3634, Val Loss=2.6733, lr=0.1000
[2025-05-06 19:59:28,740][train][INFO] - Epoch 76/400, Val Acc=0.2725, Val Loss=2.9555, lr=0.1000
[2025-05-06 19:59:30,719][train][INFO] - Epoch 78/400, Val Acc=0.3912, Val Loss=2.8273, lr=0.1000
[2025-05-06 19:59:37,225][train][INFO] - Epoch 77/400, Val Acc=0.2434, Val Loss=3.2078, lr=0.1000
[2025-05-06 19:59:38,811][train][INFO] - Epoch 79/400, Val Acc=0.4198, Val Loss=2.3242, lr=0.1000
[2025-05-06 19:59:45,493][train][INFO] - Epoch 78/400, Val Acc=0.2784, Val Loss=2.8381, lr=0.1000
[2025-05-06 19:59:47,125][train][INFO] - Epoch 80/400, Val Acc=0.3011, Val Loss=2.9482, lr=0.1000
[2025-05-06 19:59:53,693][train][INFO] - Epoch 79/400, Val Acc=0.2783, Val Loss=2.8888, lr=0.1000
[2025-05-06 19:59:54,688][train][INFO] - Epoch 81/400, Val Acc=0.3816, Val Loss=2.7180, lr=0.1000
[2025-05-06 20:00:02,309][train][INFO] - Epoch 80/400, Val Acc=0.0983, Val Loss=4.2095, lr=0.1000
[2025-05-06 20:00:02,741][train][INFO] - Epoch 82/400, Val Acc=0.3981, Val Loss=2.4730, lr=0.1000
[2025-05-06 20:00:10,810][train][INFO] - Epoch 81/400, Val Acc=0.2592, Val Loss=2.9564, lr=0.1000
[2025-05-06 20:00:11,142][train][INFO] - Epoch 83/400, Val Acc=0.4383, Val Loss=2.2336, lr=0.1000
[2025-05-06 20:00:18,412][train][INFO] - Epoch 82/400, Val Acc=0.1709, Val Loss=4.9448, lr=0.1000
[2025-05-06 20:00:19,448][train][INFO] - Epoch 84/400, Val Acc=0.3878, Val Loss=2.6841, lr=0.1000
[2025-05-06 20:00:26,551][train][INFO] - Epoch 83/400, Val Acc=0.1854, Val Loss=4.2619, lr=0.1000
[2025-05-06 20:00:26,756][train][INFO] - Epoch 85/400, Val Acc=0.4102, Val Loss=2.3572, lr=0.1000
[2025-05-06 20:00:34,341][train][INFO] - Epoch 86/400, Val Acc=0.4300, Val Loss=2.2780, lr=0.1000
[2025-05-06 20:00:34,729][train][INFO] - Epoch 84/400, Val Acc=0.2198, Val Loss=3.1342, lr=0.1000
[2025-05-06 20:00:42,284][train][INFO] - Epoch 87/400, Val Acc=0.2961, Val Loss=3.0262, lr=0.1000
[2025-05-06 20:00:42,307][train][INFO] - Epoch 85/400, Val Acc=0.1717, Val Loss=3.6199, lr=0.1000
[2025-05-06 20:00:50,707][train][INFO] - Epoch 86/400, Val Acc=0.2582, Val Loss=3.3568, lr=0.1000
[2025-05-06 20:00:50,824][train][INFO] - Epoch 88/400, Val Acc=0.3678, Val Loss=2.6742, lr=0.1000
[2025-05-06 20:00:58,700][train][INFO] - Epoch 87/400, Val Acc=0.1673, Val Loss=4.2144, lr=0.1000
[2025-05-06 20:00:59,100][train][INFO] - Epoch 89/400, Val Acc=0.3907, Val Loss=2.4573, lr=0.1000
[2025-05-06 20:01:06,468][train][INFO] - Epoch 90/400, Val Acc=0.4010, Val Loss=2.6575, lr=0.1000
[2025-05-06 20:01:06,853][train][INFO] - Epoch 88/400, Val Acc=0.1059, Val Loss=4.1576, lr=0.1000
[2025-05-06 20:01:14,548][train][INFO] - Epoch 91/400, Val Acc=0.4013, Val Loss=2.4421, lr=0.1000
[2025-05-06 20:01:15,432][train][INFO] - Epoch 89/400, Val Acc=0.2820, Val Loss=2.7838, lr=0.1000
[2025-05-06 20:01:22,617][train][INFO] - Epoch 92/400, Val Acc=0.3093, Val Loss=2.9211, lr=0.1000
[2025-05-06 20:01:23,917][train][INFO] - Epoch 90/400, Val Acc=0.2413, Val Loss=3.1407, lr=0.1000
[2025-05-06 20:01:30,109][train][INFO] - Epoch 93/400, Val Acc=0.3791, Val Loss=2.5309, lr=0.1000
[2025-05-06 20:01:31,551][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 300
        lr: 0.01
        lr_decay_milestones: 150,250
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-05-06 20:01:31,623][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 20:01:31,623][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 20:01:31,623][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 20:01:31,878][train][INFO] - Epoch 91/400, Val Acc=0.1787, Val Loss=3.2879, lr=0.1000
[2025-05-06 20:01:37,943][train][INFO] - Epoch 94/400, Val Acc=0.4098, Val Loss=2.4117, lr=0.1000
[2025-05-06 20:01:40,173][train][INFO] - Epoch 92/400, Val Acc=0.2350, Val Loss=3.1772, lr=0.1000
[2025-05-06 20:01:46,422][train][INFO] - Epoch 95/400, Val Acc=0.3260, Val Loss=2.9676, lr=0.1000
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 20:01:48,762][train][INFO] - Epoch 93/400, Val Acc=0.2213, Val Loss=3.2344, lr=0.1000
[2025-05-06 20:01:51,866][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 20:01:53,857][train][INFO] - Epoch 96/400, Val Acc=0.3500, Val Loss=2.8252, lr=0.1000
[2025-05-06 20:01:56,637][train][INFO] - Epoch 94/400, Val Acc=0.2978, Val Loss=2.6870, lr=0.1000
[2025-05-06 20:01:59,355][train][INFO] - Epoch 1/300, Val Acc=0.0628, Val Loss=3.9465, lr=0.0100
[2025-05-06 20:02:01,101][train][INFO] - Epoch 97/400, Val Acc=0.3341, Val Loss=2.6083, lr=0.1000
[2025-05-06 20:02:04,643][train][INFO] - Epoch 95/400, Val Acc=0.2353, Val Loss=3.4524, lr=0.1000
[2025-05-06 20:02:06,256][train][INFO] - Epoch 2/300, Val Acc=0.2409, Val Loss=2.8412, lr=0.0100
[2025-05-06 20:02:08,215][train][INFO] - Epoch 98/400, Val Acc=0.4338, Val Loss=2.3374, lr=0.1000
[2025-05-06 20:02:12,494][train][INFO] - Epoch 96/400, Val Acc=0.1014, Val Loss=3.9593, lr=0.1000
[2025-05-06 20:02:13,266][train][INFO] - Epoch 3/300, Val Acc=0.3140, Val Loss=2.6228, lr=0.0100
[2025-05-06 20:02:15,778][train][INFO] - Epoch 99/400, Val Acc=0.4077, Val Loss=2.4186, lr=0.1000
[2025-05-06 20:02:20,026][train][INFO] - Epoch 4/300, Val Acc=0.3967, Val Loss=2.2098, lr=0.0100
[2025-05-06 20:02:20,600][train][INFO] - Epoch 97/400, Val Acc=0.2536, Val Loss=3.0536, lr=0.1000
[2025-05-06 20:02:23,490][train][INFO] - Epoch 100/400, Val Acc=0.3955, Val Loss=2.4259, lr=0.1000
[2025-05-06 20:02:27,709][train][INFO] - Epoch 5/300, Val Acc=0.4572, Val Loss=2.0084, lr=0.0100
[2025-05-06 20:02:28,519][train][INFO] - Epoch 98/400, Val Acc=0.2716, Val Loss=3.1272, lr=0.1000
[2025-05-06 20:02:30,766][train][INFO] - Epoch 101/400, Val Acc=0.6220, Val Loss=1.3891, lr=0.0100
[2025-05-06 20:02:35,398][train][INFO] - Epoch 6/300, Val Acc=0.4667, Val Loss=2.0535, lr=0.0100
[2025-05-06 20:02:36,388][train][INFO] - Epoch 99/400, Val Acc=0.3133, Val Loss=2.6383, lr=0.1000
[2025-05-06 20:02:38,265][train][INFO] - Epoch 102/400, Val Acc=0.6315, Val Loss=1.3601, lr=0.0100
[2025-05-06 20:02:42,696][train][INFO] - Epoch 7/300, Val Acc=0.5403, Val Loss=1.7169, lr=0.0100
[2025-05-06 20:02:44,389][train][INFO] - Epoch 100/400, Val Acc=0.2455, Val Loss=3.0578, lr=0.1000
[2025-05-06 20:02:45,586][train][INFO] - Epoch 103/400, Val Acc=0.6356, Val Loss=1.3396, lr=0.0100
[2025-05-06 20:02:49,817][train][INFO] - Epoch 8/300, Val Acc=0.5366, Val Loss=1.7757, lr=0.0100
[2025-05-06 20:02:52,370][train][INFO] - Epoch 101/400, Val Acc=0.4518, Val Loss=1.9797, lr=0.0100
[2025-05-06 20:02:52,921][train][INFO] - Epoch 104/400, Val Acc=0.6349, Val Loss=1.3626, lr=0.0100
[2025-05-06 20:02:57,384][train][INFO] - Epoch 9/300, Val Acc=0.5476, Val Loss=1.7621, lr=0.0100
[2025-05-06 20:02:59,615][train][INFO] - Epoch 105/400, Val Acc=0.6355, Val Loss=1.3700, lr=0.0100
[2025-05-06 20:02:59,771][train][INFO] - Epoch 102/400, Val Acc=0.4726, Val Loss=1.9217, lr=0.0100
[2025-05-06 20:03:04,657][train][INFO] - Epoch 10/300, Val Acc=0.5788, Val Loss=1.6087, lr=0.0100
[2025-05-06 20:03:07,532][train][INFO] - Epoch 106/400, Val Acc=0.6386, Val Loss=1.3769, lr=0.0100
[2025-05-06 20:03:07,619][train][INFO] - Epoch 103/400, Val Acc=0.4831, Val Loss=1.8708, lr=0.0100
[2025-05-06 20:03:12,148][train][INFO] - Epoch 11/300, Val Acc=0.6044, Val Loss=1.4911, lr=0.0100
[2025-05-06 20:03:14,974][train][INFO] - Epoch 107/400, Val Acc=0.6386, Val Loss=1.3909, lr=0.0100
[2025-05-06 20:03:15,860][train][INFO] - Epoch 104/400, Val Acc=0.4795, Val Loss=1.8778, lr=0.0100
[2025-05-06 20:03:19,790][train][INFO] - Epoch 12/300, Val Acc=0.5985, Val Loss=1.5820, lr=0.0100
[2025-05-06 20:03:22,457][train][INFO] - Epoch 108/400, Val Acc=0.6377, Val Loss=1.3883, lr=0.0100
[2025-05-06 20:03:23,596][train][INFO] - Epoch 105/400, Val Acc=0.4830, Val Loss=1.8809, lr=0.0100
[2025-05-06 20:03:27,125][train][INFO] - Epoch 13/300, Val Acc=0.5849, Val Loss=1.6367, lr=0.0100
[2025-05-06 20:03:30,148][train][INFO] - Epoch 109/400, Val Acc=0.6396, Val Loss=1.4103, lr=0.0100
[2025-05-06 20:03:31,640][train][INFO] - Epoch 106/400, Val Acc=0.4827, Val Loss=1.9093, lr=0.0100
[2025-05-06 20:03:34,494][train][INFO] - Epoch 14/300, Val Acc=0.6296, Val Loss=1.4463, lr=0.0100
[2025-05-06 20:03:37,455][train][INFO] - Epoch 110/400, Val Acc=0.6364, Val Loss=1.4111, lr=0.0100
[2025-05-06 20:03:39,153][train][INFO] - Epoch 107/400, Val Acc=0.4939, Val Loss=1.8652, lr=0.0100
[2025-05-06 20:03:41,672][train][INFO] - Epoch 15/300, Val Acc=0.6188, Val Loss=1.5124, lr=0.0100
[2025-05-06 20:03:44,982][train][INFO] - Epoch 111/400, Val Acc=0.6365, Val Loss=1.4220, lr=0.0100
[2025-05-06 20:03:46,901][train][INFO] - Epoch 108/400, Val Acc=0.4867, Val Loss=1.8684, lr=0.0100
[2025-05-06 20:03:48,549][train][INFO] - Epoch 16/300, Val Acc=0.5907, Val Loss=1.6319, lr=0.0100
[2025-05-06 20:03:52,745][train][INFO] - Epoch 112/400, Val Acc=0.6361, Val Loss=1.4238, lr=0.0100
[2025-05-06 20:03:54,846][train][INFO] - Epoch 109/400, Val Acc=0.4926, Val Loss=1.8513, lr=0.0100
[2025-05-06 20:03:56,045][train][INFO] - Epoch 17/300, Val Acc=0.6213, Val Loss=1.4974, lr=0.0100
[2025-05-06 20:03:59,779][train][INFO] - Epoch 113/400, Val Acc=0.6319, Val Loss=1.4609, lr=0.0100
[2025-05-06 20:04:02,751][train][INFO] - Epoch 110/400, Val Acc=0.4833, Val Loss=1.9153, lr=0.0100
[2025-05-06 20:04:03,846][train][INFO] - Epoch 18/300, Val Acc=0.6267, Val Loss=1.4999, lr=0.0100
[2025-05-06 20:04:06,965][train][INFO] - Epoch 114/400, Val Acc=0.6398, Val Loss=1.4793, lr=0.0100
[2025-05-06 20:04:10,372][train][INFO] - Epoch 111/400, Val Acc=0.4443, Val Loss=2.0542, lr=0.0100
[2025-05-06 20:04:11,082][train][INFO] - Epoch 19/300, Val Acc=0.6205, Val Loss=1.5298, lr=0.0100
[2025-05-06 20:04:14,205][train][INFO] - Epoch 115/400, Val Acc=0.6375, Val Loss=1.4617, lr=0.0100
[2025-05-06 20:04:18,423][train][INFO] - Epoch 112/400, Val Acc=0.4858, Val Loss=1.9076, lr=0.0100
[2025-05-06 20:04:18,471][train][INFO] - Epoch 20/300, Val Acc=0.6269, Val Loss=1.5115, lr=0.0100
[2025-05-06 20:04:21,868][train][INFO] - Epoch 116/400, Val Acc=0.6276, Val Loss=1.4862, lr=0.0100
[2025-05-06 20:04:25,737][train][INFO] - Epoch 21/300, Val Acc=0.6204, Val Loss=1.5880, lr=0.0100
[2025-05-06 20:04:26,451][train][INFO] - Epoch 113/400, Val Acc=0.4986, Val Loss=1.8693, lr=0.0100
[2025-05-06 20:04:29,109][train][INFO] - Epoch 117/400, Val Acc=0.6215, Val Loss=1.5434, lr=0.0100
[2025-05-06 20:04:33,103][train][INFO] - Epoch 22/300, Val Acc=0.6353, Val Loss=1.5153, lr=0.0100
[2025-05-06 20:04:34,081][train][INFO] - Epoch 114/400, Val Acc=0.4926, Val Loss=1.8957, lr=0.0100
[2025-05-06 20:04:36,385][train][INFO] - Epoch 118/400, Val Acc=0.6201, Val Loss=1.5775, lr=0.0100
[2025-05-06 20:04:40,032][train][INFO] - Epoch 23/300, Val Acc=0.6271, Val Loss=1.5117, lr=0.0100
[2025-05-06 20:04:42,105][train][INFO] - Epoch 115/400, Val Acc=0.4802, Val Loss=1.9774, lr=0.0100
[2025-05-06 20:04:44,129][train][INFO] - Epoch 119/400, Val Acc=0.6329, Val Loss=1.5098, lr=0.0100
[2025-05-06 20:04:47,079][train][INFO] - Epoch 24/300, Val Acc=0.6289, Val Loss=1.6078, lr=0.0100
[2025-05-06 20:04:50,118][train][INFO] - Epoch 116/400, Val Acc=0.4955, Val Loss=1.9059, lr=0.0100
[2025-05-06 20:04:51,433][train][INFO] - Epoch 120/400, Val Acc=0.6265, Val Loss=1.5291, lr=0.0100
[2025-05-06 20:04:54,506][train][INFO] - Epoch 25/300, Val Acc=0.6409, Val Loss=1.5260, lr=0.0100
[2025-05-06 20:04:58,029][train][INFO] - Epoch 117/400, Val Acc=0.4800, Val Loss=1.9567, lr=0.0100
[2025-05-06 20:04:59,085][train][INFO] - Epoch 121/400, Val Acc=0.6268, Val Loss=1.5507, lr=0.0100
[2025-05-06 20:05:01,759][train][INFO] - Epoch 26/300, Val Acc=0.6063, Val Loss=1.7043, lr=0.0100
[2025-05-06 20:05:06,028][train][INFO] - Epoch 118/400, Val Acc=0.4772, Val Loss=1.9554, lr=0.0100
[2025-05-06 20:05:06,347][train][INFO] - Epoch 122/400, Val Acc=0.6213, Val Loss=1.5776, lr=0.0100
[2025-05-06 20:05:09,000][train][INFO] - Epoch 27/300, Val Acc=0.6130, Val Loss=1.6800, lr=0.0100
[2025-05-06 20:05:14,033][train][INFO] - Epoch 123/400, Val Acc=0.6131, Val Loss=1.5847, lr=0.0100
[2025-05-06 20:05:14,199][train][INFO] - Epoch 119/400, Val Acc=0.4721, Val Loss=1.9883, lr=0.0100
[2025-05-06 20:05:16,088][train][INFO] - Epoch 28/300, Val Acc=0.6445, Val Loss=1.5446, lr=0.0100
[2025-05-06 20:05:21,749][train][INFO] - Epoch 120/400, Val Acc=0.4916, Val Loss=1.8814, lr=0.0100
[2025-05-06 20:05:21,888][train][INFO] - Epoch 124/400, Val Acc=0.6183, Val Loss=1.5982, lr=0.0100
[2025-05-06 20:05:23,191][train][INFO] - Epoch 29/300, Val Acc=0.6401, Val Loss=1.5094, lr=0.0100
[2025-05-06 20:05:29,602][train][INFO] - Epoch 121/400, Val Acc=0.4811, Val Loss=1.9594, lr=0.0100
[2025-05-06 20:05:29,773][train][INFO] - Epoch 125/400, Val Acc=0.6217, Val Loss=1.5825, lr=0.0100
[2025-05-06 20:05:30,667][train][INFO] - Epoch 30/300, Val Acc=0.6545, Val Loss=1.4600, lr=0.0100
[2025-05-06 20:05:37,071][train][INFO] - Epoch 126/400, Val Acc=0.6260, Val Loss=1.5473, lr=0.0100
[2025-05-06 20:05:37,451][train][INFO] - Epoch 122/400, Val Acc=0.4760, Val Loss=2.0219, lr=0.0100
[2025-05-06 20:05:38,106][train][INFO] - Epoch 31/300, Val Acc=0.6496, Val Loss=1.5288, lr=0.0100
[2025-05-06 20:05:44,819][train][INFO] - Epoch 127/400, Val Acc=0.6263, Val Loss=1.5813, lr=0.0100
[2025-05-06 20:05:45,103][train][INFO] - Epoch 123/400, Val Acc=0.4785, Val Loss=1.9911, lr=0.0100
[2025-05-06 20:05:45,527][train][INFO] - Epoch 32/300, Val Acc=0.6515, Val Loss=1.5034, lr=0.0100
[2025-05-06 20:05:52,231][train][INFO] - Epoch 128/400, Val Acc=0.6183, Val Loss=1.5938, lr=0.0100
[2025-05-06 20:05:52,934][train][INFO] - Epoch 124/400, Val Acc=0.4969, Val Loss=1.8869, lr=0.0100
[2025-05-06 20:05:53,454][train][INFO] - Epoch 33/300, Val Acc=0.6498, Val Loss=1.5003, lr=0.0100
[2025-05-06 20:05:59,632][train][INFO] - Epoch 129/400, Val Acc=0.6231, Val Loss=1.5847, lr=0.0100
[2025-05-06 20:06:00,670][train][INFO] - Epoch 125/400, Val Acc=0.4826, Val Loss=1.9878, lr=0.0100
[2025-05-06 20:06:00,883][train][INFO] - Epoch 34/300, Val Acc=0.6590, Val Loss=1.4502, lr=0.0100
[2025-05-06 20:06:07,101][train][INFO] - Epoch 130/400, Val Acc=0.6056, Val Loss=1.7026, lr=0.0100
[2025-05-06 20:06:08,362][train][INFO] - Epoch 35/300, Val Acc=0.6498, Val Loss=1.5339, lr=0.0100
[2025-05-06 20:06:08,543][train][INFO] - Epoch 126/400, Val Acc=0.4805, Val Loss=1.9445, lr=0.0100
[2025-05-06 20:06:14,494][train][INFO] - Epoch 131/400, Val Acc=0.6164, Val Loss=1.5959, lr=0.0100
[2025-05-06 20:06:15,962][train][INFO] - Epoch 36/300, Val Acc=0.6414, Val Loss=1.5838, lr=0.0100
[2025-05-06 20:06:16,497][train][INFO] - Epoch 127/400, Val Acc=0.4763, Val Loss=2.0108, lr=0.0100
[2025-05-06 20:06:22,030][train][INFO] - Epoch 132/400, Val Acc=0.5986, Val Loss=1.7546, lr=0.0100
[2025-05-06 20:06:23,398][train][INFO] - Epoch 37/300, Val Acc=0.6295, Val Loss=1.6534, lr=0.0100
[2025-05-06 20:06:24,002][train][INFO] - Epoch 128/400, Val Acc=0.4852, Val Loss=1.9110, lr=0.0100
[2025-05-06 20:06:29,898][train][INFO] - Epoch 133/400, Val Acc=0.6062, Val Loss=1.6965, lr=0.0100
[2025-05-06 20:06:30,647][train][INFO] - Epoch 38/300, Val Acc=0.6218, Val Loss=1.6983, lr=0.0100
[2025-05-06 20:06:31,794][train][INFO] - Epoch 129/400, Val Acc=0.4782, Val Loss=2.0377, lr=0.0100
[2025-05-06 20:06:37,548][train][INFO] - Epoch 134/400, Val Acc=0.5965, Val Loss=1.7232, lr=0.0100
[2025-05-06 20:06:37,908][train][INFO] - Epoch 39/300, Val Acc=0.6405, Val Loss=1.6089, lr=0.0100
[2025-05-06 20:06:39,845][train][INFO] - Epoch 130/400, Val Acc=0.4796, Val Loss=2.0192, lr=0.0100
[2025-05-06 20:06:44,740][train][INFO] - Epoch 40/300, Val Acc=0.6407, Val Loss=1.5597, lr=0.0100
[2025-05-06 20:06:45,061][train][INFO] - Epoch 135/400, Val Acc=0.6262, Val Loss=1.5436, lr=0.0100
[2025-05-06 20:06:47,684][train][INFO] - Epoch 131/400, Val Acc=0.4665, Val Loss=2.0181, lr=0.0100
[2025-05-06 20:06:52,313][train][INFO] - Epoch 41/300, Val Acc=0.6287, Val Loss=1.6774, lr=0.0100
[2025-05-06 20:06:52,588][train][INFO] - Epoch 136/400, Val Acc=0.6206, Val Loss=1.6147, lr=0.0100
[2025-05-06 20:06:55,172][train][INFO] - Epoch 132/400, Val Acc=0.4572, Val Loss=2.1229, lr=0.0100
[2025-05-06 20:06:59,882][train][INFO] - Epoch 137/400, Val Acc=0.5984, Val Loss=1.7449, lr=0.0100
[2025-05-06 20:07:00,002][train][INFO] - Epoch 42/300, Val Acc=0.6356, Val Loss=1.6461, lr=0.0100
[2025-05-06 20:07:02,976][train][INFO] - Epoch 133/400, Val Acc=0.4935, Val Loss=1.9208, lr=0.0100
[2025-05-06 20:07:07,503][train][INFO] - Epoch 43/300, Val Acc=0.6277, Val Loss=1.6772, lr=0.0100
[2025-05-06 20:07:07,521][train][INFO] - Epoch 138/400, Val Acc=0.6218, Val Loss=1.6401, lr=0.0100
[2025-05-06 20:07:10,546][train][INFO] - Epoch 134/400, Val Acc=0.4495, Val Loss=2.1547, lr=0.0100
[2025-05-06 20:07:14,944][train][INFO] - Epoch 139/400, Val Acc=0.6245, Val Loss=1.5914, lr=0.0100
[2025-05-06 20:07:15,271][train][INFO] - Epoch 44/300, Val Acc=0.6404, Val Loss=1.5988, lr=0.0100
[2025-05-06 20:07:18,705][train][INFO] - Epoch 135/400, Val Acc=0.4763, Val Loss=2.0017, lr=0.0100
[2025-05-06 20:07:22,722][train][INFO] - Epoch 140/400, Val Acc=0.5912, Val Loss=1.8325, lr=0.0100
[2025-05-06 20:07:22,733][train][INFO] - Epoch 45/300, Val Acc=0.6418, Val Loss=1.6109, lr=0.0100
[2025-05-06 20:07:26,895][train][INFO] - Epoch 136/400, Val Acc=0.4711, Val Loss=2.0665, lr=0.0100
[2025-05-06 20:07:30,215][train][INFO] - Epoch 46/300, Val Acc=0.6468, Val Loss=1.5447, lr=0.0100
[2025-05-06 20:07:30,711][train][INFO] - Epoch 141/400, Val Acc=0.6051, Val Loss=1.7120, lr=0.0100
[2025-05-06 20:07:34,384][train][INFO] - Epoch 137/400, Val Acc=0.4805, Val Loss=1.9990, lr=0.0100
[2025-05-06 20:07:37,694][train][INFO] - Epoch 47/300, Val Acc=0.6547, Val Loss=1.5368, lr=0.0100
[2025-05-06 20:07:38,418][train][INFO] - Epoch 142/400, Val Acc=0.6178, Val Loss=1.6502, lr=0.0100
[2025-05-06 20:07:42,250][train][INFO] - Epoch 138/400, Val Acc=0.4804, Val Loss=1.9545, lr=0.0100
[2025-05-06 20:07:45,396][train][INFO] - Epoch 48/300, Val Acc=0.6297, Val Loss=1.6948, lr=0.0100
[2025-05-06 20:07:46,090][train][INFO] - Epoch 143/400, Val Acc=0.5992, Val Loss=1.7945, lr=0.0100
[2025-05-06 20:07:50,100][train][INFO] - Epoch 139/400, Val Acc=0.4836, Val Loss=1.9420, lr=0.0100
[2025-05-06 20:07:52,389][train][INFO] - Epoch 49/300, Val Acc=0.6432, Val Loss=1.6274, lr=0.0100
[2025-05-06 20:07:53,523][train][INFO] - Epoch 144/400, Val Acc=0.6153, Val Loss=1.6983, lr=0.0100
[2025-05-06 20:07:57,801][train][INFO] - Epoch 140/400, Val Acc=0.4805, Val Loss=1.9831, lr=0.0100
[2025-05-06 20:07:59,900][train][INFO] - Epoch 50/300, Val Acc=0.6504, Val Loss=1.5781, lr=0.0100
[2025-05-06 20:08:00,997][train][INFO] - Epoch 145/400, Val Acc=0.6040, Val Loss=1.7318, lr=0.0100
[2025-05-06 20:08:05,492][train][INFO] - Epoch 141/400, Val Acc=0.4759, Val Loss=2.0235, lr=0.0100
[2025-05-06 20:08:07,007][train][INFO] - Epoch 51/300, Val Acc=0.6337, Val Loss=1.6617, lr=0.0100
[2025-05-06 20:08:08,533][train][INFO] - Epoch 146/400, Val Acc=0.6146, Val Loss=1.6778, lr=0.0100
[2025-05-06 20:08:13,080][train][INFO] - Epoch 142/400, Val Acc=0.4434, Val Loss=2.2875, lr=0.0100
[2025-05-06 20:08:14,330][train][INFO] - Epoch 52/300, Val Acc=0.6602, Val Loss=1.5069, lr=0.0100
[2025-05-06 20:08:16,241][train][INFO] - Epoch 147/400, Val Acc=0.6053, Val Loss=1.7755, lr=0.0100
[2025-05-06 20:08:20,819][train][INFO] - Epoch 143/400, Val Acc=0.4435, Val Loss=2.1603, lr=0.0100
[2025-05-06 20:08:21,512][train][INFO] - Epoch 53/300, Val Acc=0.6549, Val Loss=1.5744, lr=0.0100
[2025-05-06 20:08:23,534][train][INFO] - Epoch 148/400, Val Acc=0.6053, Val Loss=1.7570, lr=0.0100
[2025-05-06 20:08:28,285][train][INFO] - Epoch 144/400, Val Acc=0.4783, Val Loss=2.0116, lr=0.0100
[2025-05-06 20:08:28,725][train][INFO] - Epoch 54/300, Val Acc=0.6522, Val Loss=1.5670, lr=0.0100
[2025-05-06 20:08:30,810][train][INFO] - Epoch 149/400, Val Acc=0.6075, Val Loss=1.6803, lr=0.0100
[2025-05-06 20:08:36,019][train][INFO] - Epoch 55/300, Val Acc=0.6612, Val Loss=1.5137, lr=0.0100
[2025-05-06 20:08:36,144][train][INFO] - Epoch 145/400, Val Acc=0.4757, Val Loss=2.0187, lr=0.0100
[2025-05-06 20:08:38,558][train][INFO] - Epoch 150/400, Val Acc=0.6041, Val Loss=1.7378, lr=0.0100
[2025-05-06 20:08:43,377][train][INFO] - Epoch 56/300, Val Acc=0.6555, Val Loss=1.5373, lr=0.0100
[2025-05-06 20:08:43,684][train][INFO] - Epoch 146/400, Val Acc=0.4276, Val Loss=2.1941, lr=0.0100
[2025-05-06 20:08:46,351][train][INFO] - Epoch 151/400, Val Acc=0.5983, Val Loss=1.7741, lr=0.0100
[2025-05-06 20:08:50,539][train][INFO] - Epoch 57/300, Val Acc=0.6415, Val Loss=1.6430, lr=0.0100
[2025-05-06 20:08:51,558][train][INFO] - Epoch 147/400, Val Acc=0.4787, Val Loss=1.9850, lr=0.0100
[2025-05-06 20:08:53,803][train][INFO] - Epoch 152/400, Val Acc=0.6182, Val Loss=1.6448, lr=0.0100
[2025-05-06 20:08:58,226][train][INFO] - Epoch 58/300, Val Acc=0.6531, Val Loss=1.5788, lr=0.0100
[2025-05-06 20:08:59,067][train][INFO] - Epoch 148/400, Val Acc=0.4771, Val Loss=2.0519, lr=0.0100
[2025-05-06 20:09:01,006][train][INFO] - Epoch 153/400, Val Acc=0.6153, Val Loss=1.6606, lr=0.0100
[2025-05-06 20:09:05,689][train][INFO] - Epoch 59/300, Val Acc=0.6416, Val Loss=1.6816, lr=0.0100
[2025-05-06 20:09:06,935][train][INFO] - Epoch 149/400, Val Acc=0.4836, Val Loss=1.9863, lr=0.0100
[2025-05-06 20:09:08,683][train][INFO] - Epoch 154/400, Val Acc=0.5968, Val Loss=1.7982, lr=0.0100
[2025-05-06 20:09:13,269][train][INFO] - Epoch 60/300, Val Acc=0.6599, Val Loss=1.5457, lr=0.0100
[2025-05-06 20:09:15,069][train][INFO] - Epoch 150/400, Val Acc=0.4911, Val Loss=1.9850, lr=0.0100
[2025-05-06 20:09:16,271][train][INFO] - Epoch 155/400, Val Acc=0.6184, Val Loss=1.6333, lr=0.0100
[2025-05-06 20:09:20,107][train][INFO] - Epoch 61/300, Val Acc=0.6599, Val Loss=1.5214, lr=0.0100
[2025-05-06 20:09:23,114][train][INFO] - Epoch 151/400, Val Acc=0.4783, Val Loss=2.0064, lr=0.0100
[2025-05-06 20:09:23,758][train][INFO] - Epoch 156/400, Val Acc=0.5959, Val Loss=1.8075, lr=0.0100
[2025-05-06 20:09:26,843][train][INFO] - Epoch 62/300, Val Acc=0.6598, Val Loss=1.5352, lr=0.0100
[2025-05-06 20:09:30,817][train][INFO] - Epoch 152/400, Val Acc=0.4846, Val Loss=2.0435, lr=0.0100
[2025-05-06 20:09:31,427][train][INFO] - Epoch 157/400, Val Acc=0.5944, Val Loss=1.8141, lr=0.0100
[2025-05-06 20:09:33,956][train][INFO] - Epoch 63/300, Val Acc=0.6534, Val Loss=1.5867, lr=0.0100
[2025-05-06 20:09:38,719][train][INFO] - Epoch 153/400, Val Acc=0.4696, Val Loss=2.0707, lr=0.0100
[2025-05-06 20:09:38,884][train][INFO] - Epoch 158/400, Val Acc=0.6148, Val Loss=1.6848, lr=0.0100
[2025-05-06 20:09:41,561][train][INFO] - Epoch 64/300, Val Acc=0.6566, Val Loss=1.5402, lr=0.0100
[2025-05-06 20:09:46,378][train][INFO] - Epoch 159/400, Val Acc=0.5885, Val Loss=1.8836, lr=0.0100
[2025-05-06 20:09:46,830][train][INFO] - Epoch 154/400, Val Acc=0.4895, Val Loss=1.9667, lr=0.0100
[2025-05-06 20:09:48,576][train][INFO] - Epoch 65/300, Val Acc=0.6497, Val Loss=1.6152, lr=0.0100
[2025-05-06 20:09:53,286][train][INFO] - Epoch 160/400, Val Acc=0.6045, Val Loss=1.6922, lr=0.0100
[2025-05-06 20:09:54,351][train][INFO] - Epoch 155/400, Val Acc=0.4797, Val Loss=2.0579, lr=0.0100
[2025-05-06 20:09:56,085][train][INFO] - Epoch 66/300, Val Acc=0.6601, Val Loss=1.5633, lr=0.0100
[2025-05-06 20:10:00,717][train][INFO] - Epoch 161/400, Val Acc=0.6247, Val Loss=1.6643, lr=0.0100
[2025-05-06 20:10:02,153][train][INFO] - Epoch 156/400, Val Acc=0.4886, Val Loss=1.9823, lr=0.0100
[2025-05-06 20:10:03,366][train][INFO] - Epoch 67/300, Val Acc=0.6453, Val Loss=1.6314, lr=0.0100
[2025-05-06 20:10:08,315][train][INFO] - Epoch 162/400, Val Acc=0.6164, Val Loss=1.7288, lr=0.0100
[2025-05-06 20:10:10,318][train][INFO] - Epoch 157/400, Val Acc=0.4876, Val Loss=2.0487, lr=0.0100
[2025-05-06 20:10:10,847][train][INFO] - Epoch 68/300, Val Acc=0.6444, Val Loss=1.6469, lr=0.0100
[2025-05-06 20:10:15,829][train][INFO] - Epoch 163/400, Val Acc=0.6210, Val Loss=1.6597, lr=0.0100
[2025-05-06 20:10:17,811][train][INFO] - Epoch 69/300, Val Acc=0.6470, Val Loss=1.6043, lr=0.0100
[2025-05-06 20:10:18,008][train][INFO] - Epoch 158/400, Val Acc=0.4851, Val Loss=2.0388, lr=0.0100
[2025-05-06 20:10:23,235][train][INFO] - Epoch 164/400, Val Acc=0.6015, Val Loss=1.8281, lr=0.0100
[2025-05-06 20:10:24,837][train][INFO] - Epoch 70/300, Val Acc=0.6468, Val Loss=1.6642, lr=0.0100
[2025-05-06 20:10:26,214][train][INFO] - Epoch 159/400, Val Acc=0.4872, Val Loss=1.9993, lr=0.0100
[2025-05-06 20:10:30,345][train][INFO] - Epoch 165/400, Val Acc=0.6136, Val Loss=1.6890, lr=0.0100
[2025-05-06 20:10:32,177][train][INFO] - Epoch 71/300, Val Acc=0.6567, Val Loss=1.5896, lr=0.0100
[2025-05-06 20:10:33,760][train][INFO] - Epoch 160/400, Val Acc=0.4746, Val Loss=2.0355, lr=0.0100
[2025-05-06 20:10:37,770][train][INFO] - Epoch 166/400, Val Acc=0.6227, Val Loss=1.6695, lr=0.0100
[2025-05-06 20:10:39,891][train][INFO] - Epoch 72/300, Val Acc=0.6501, Val Loss=1.6522, lr=0.0100
[2025-05-06 20:10:41,690][train][INFO] - Epoch 161/400, Val Acc=0.4919, Val Loss=1.9766, lr=0.0100
[2025-05-06 20:10:45,182][train][INFO] - Epoch 167/400, Val Acc=0.5945, Val Loss=1.8130, lr=0.0100
[2025-05-06 20:10:47,548][train][INFO] - Epoch 73/300, Val Acc=0.6566, Val Loss=1.5818, lr=0.0100
[2025-05-06 20:10:49,859][train][INFO] - Epoch 162/400, Val Acc=0.4360, Val Loss=2.1490, lr=0.0100
[2025-05-06 20:10:52,935][train][INFO] - Epoch 168/400, Val Acc=0.6048, Val Loss=1.8205, lr=0.0100
[2025-05-06 20:10:55,079][train][INFO] - Epoch 74/300, Val Acc=0.6524, Val Loss=1.6052, lr=0.0100
[2025-05-06 20:10:57,556][train][INFO] - Epoch 163/400, Val Acc=0.4528, Val Loss=2.1075, lr=0.0100
[2025-05-06 20:11:00,468][train][INFO] - Epoch 169/400, Val Acc=0.5925, Val Loss=1.8724, lr=0.0100
[2025-05-06 20:11:02,483][train][INFO] - Epoch 75/300, Val Acc=0.6443, Val Loss=1.7276, lr=0.0100
[2025-05-06 20:11:05,871][train][INFO] - Epoch 164/400, Val Acc=0.4843, Val Loss=1.9890, lr=0.0100
[2025-05-06 20:11:08,193][train][INFO] - Epoch 170/400, Val Acc=0.6127, Val Loss=1.7054, lr=0.0100
[2025-05-06 20:11:09,845][train][INFO] - Epoch 76/300, Val Acc=0.6575, Val Loss=1.5741, lr=0.0100
[2025-05-06 20:11:12,931][train][INFO] - Epoch 165/400, Val Acc=0.4655, Val Loss=2.0930, lr=0.0100
[2025-05-06 20:11:15,707][train][INFO] - Epoch 171/400, Val Acc=0.6070, Val Loss=1.7213, lr=0.0100
[2025-05-06 20:11:17,355][train][INFO] - Epoch 77/300, Val Acc=0.6413, Val Loss=1.6958, lr=0.0100
[2025-05-06 20:11:20,804][train][INFO] - Epoch 166/400, Val Acc=0.4895, Val Loss=2.0110, lr=0.0100
[2025-05-06 20:11:23,092][train][INFO] - Epoch 172/400, Val Acc=0.6128, Val Loss=1.7217, lr=0.0100
[2025-05-06 20:11:24,938][train][INFO] - Epoch 78/300, Val Acc=0.6636, Val Loss=1.5352, lr=0.0100
[2025-05-06 20:11:28,619][train][INFO] - Epoch 167/400, Val Acc=0.4849, Val Loss=1.9614, lr=0.0100
[2025-05-06 20:11:30,909][train][INFO] - Epoch 173/400, Val Acc=0.6093, Val Loss=1.7581, lr=0.0100
[2025-05-06 20:11:32,127][train][INFO] - Epoch 79/300, Val Acc=0.6500, Val Loss=1.6616, lr=0.0100
[2025-05-06 20:11:36,465][train][INFO] - Epoch 168/400, Val Acc=0.4837, Val Loss=2.0287, lr=0.0100
[2025-05-06 20:11:38,025][train][INFO] - Epoch 174/400, Val Acc=0.6170, Val Loss=1.6903, lr=0.0100
[2025-05-06 20:11:39,355][train][INFO] - Epoch 80/300, Val Acc=0.6610, Val Loss=1.5942, lr=0.0100
[2025-05-06 20:11:44,028][train][INFO] - Epoch 169/400, Val Acc=0.4925, Val Loss=2.0119, lr=0.0100
[2025-05-06 20:11:45,662][train][INFO] - Epoch 175/400, Val Acc=0.6113, Val Loss=1.7341, lr=0.0100
[2025-05-06 20:11:46,833][train][INFO] - Epoch 81/300, Val Acc=0.6433, Val Loss=1.6803, lr=0.0100
[2025-05-06 20:11:52,052][train][INFO] - Epoch 170/400, Val Acc=0.4910, Val Loss=1.9322, lr=0.0100
[2025-05-06 20:11:52,823][train][INFO] - Epoch 176/400, Val Acc=0.6051, Val Loss=1.8223, lr=0.0100
[2025-05-06 20:11:54,004][train][INFO] - Epoch 82/300, Val Acc=0.6282, Val Loss=1.7748, lr=0.0100
[2025-05-06 20:11:59,433][train][INFO] - Epoch 171/400, Val Acc=0.4823, Val Loss=2.0059, lr=0.0100
[2025-05-06 20:12:00,208][train][INFO] - Epoch 177/400, Val Acc=0.6139, Val Loss=1.7771, lr=0.0100
[2025-05-06 20:12:01,691][train][INFO] - Epoch 83/300, Val Acc=0.6545, Val Loss=1.5859, lr=0.0100
[2025-05-06 20:12:07,301][train][INFO] - Epoch 172/400, Val Acc=0.4867, Val Loss=1.9805, lr=0.0100
[2025-05-06 20:12:07,443][train][INFO] - Epoch 178/400, Val Acc=0.6068, Val Loss=1.7722, lr=0.0100
[2025-05-06 20:12:09,259][train][INFO] - Epoch 84/300, Val Acc=0.6633, Val Loss=1.5852, lr=0.0100
[2025-05-06 20:12:14,728][train][INFO] - Epoch 173/400, Val Acc=0.4796, Val Loss=2.0364, lr=0.0100
[2025-05-06 20:12:15,223][train][INFO] - Epoch 179/400, Val Acc=0.6203, Val Loss=1.6979, lr=0.0100
[2025-05-06 20:12:16,712][train][INFO] - Epoch 85/300, Val Acc=0.6593, Val Loss=1.5997, lr=0.0100
[2025-05-06 20:12:22,604][train][INFO] - Epoch 174/400, Val Acc=0.4936, Val Loss=1.9960, lr=0.0100
[2025-05-06 20:12:22,818][train][INFO] - Epoch 180/400, Val Acc=0.6110, Val Loss=1.7902, lr=0.0100
[2025-05-06 20:12:24,239][train][INFO] - Epoch 86/300, Val Acc=0.6625, Val Loss=1.5435, lr=0.0100
[2025-05-06 20:12:30,018][train][INFO] - Epoch 181/400, Val Acc=0.6014, Val Loss=1.8358, lr=0.0100
[2025-05-06 20:12:30,857][train][INFO] - Epoch 175/400, Val Acc=0.4909, Val Loss=1.9700, lr=0.0100
[2025-05-06 20:12:31,920][train][INFO] - Epoch 87/300, Val Acc=0.6582, Val Loss=1.5903, lr=0.0100
[2025-05-06 20:12:37,586][train][INFO] - Epoch 182/400, Val Acc=0.6127, Val Loss=1.7618, lr=0.0100
[2025-05-06 20:12:39,173][train][INFO] - Epoch 88/300, Val Acc=0.6613, Val Loss=1.5566, lr=0.0100
[2025-05-06 20:12:39,305][train][INFO] - Epoch 176/400, Val Acc=0.4931, Val Loss=1.9976, lr=0.0100
[2025-05-06 20:12:45,235][train][INFO] - Epoch 183/400, Val Acc=0.6219, Val Loss=1.7334, lr=0.0100
[2025-05-06 20:12:46,566][train][INFO] - Epoch 89/300, Val Acc=0.6454, Val Loss=1.6831, lr=0.0100
[2025-05-06 20:12:47,169][train][INFO] - Epoch 177/400, Val Acc=0.4353, Val Loss=2.3821, lr=0.0100
[2025-05-06 20:12:52,511][train][INFO] - Epoch 184/400, Val Acc=0.6238, Val Loss=1.7141, lr=0.0100
[2025-05-06 20:12:54,278][train][INFO] - Epoch 90/300, Val Acc=0.6440, Val Loss=1.6854, lr=0.0100
[2025-05-06 20:12:54,305][train][INFO] - Epoch 178/400, Val Acc=0.4465, Val Loss=2.2529, lr=0.0100
[2025-05-06 20:12:59,952][train][INFO] - Epoch 185/400, Val Acc=0.6170, Val Loss=1.7096, lr=0.0100
[2025-05-06 20:13:01,962][train][INFO] - Epoch 91/300, Val Acc=0.6603, Val Loss=1.5762, lr=0.0100
[2025-05-06 20:13:02,007][train][INFO] - Epoch 179/400, Val Acc=0.4747, Val Loss=2.0886, lr=0.0100
[2025-05-06 20:13:07,335][train][INFO] - Epoch 186/400, Val Acc=0.6208, Val Loss=1.7198, lr=0.0100
[2025-05-06 20:13:09,541][train][INFO] - Epoch 92/300, Val Acc=0.6555, Val Loss=1.6149, lr=0.0100
[2025-05-06 20:13:09,850][train][INFO] - Epoch 180/400, Val Acc=0.4943, Val Loss=1.9681, lr=0.0100
[2025-05-06 20:13:15,223][train][INFO] - Epoch 187/400, Val Acc=0.6229, Val Loss=1.6934, lr=0.0100
[2025-05-06 20:13:16,986][train][INFO] - Epoch 93/300, Val Acc=0.6530, Val Loss=1.6815, lr=0.0100
[2025-05-06 20:13:17,683][train][INFO] - Epoch 181/400, Val Acc=0.4743, Val Loss=2.0787, lr=0.0100
[2025-05-06 20:13:22,521][train][INFO] - Epoch 188/400, Val Acc=0.6211, Val Loss=1.7306, lr=0.0100
[2025-05-06 20:13:24,400][train][INFO] - Epoch 94/300, Val Acc=0.6648, Val Loss=1.5675, lr=0.0100
[2025-05-06 20:13:25,956][train][INFO] - Epoch 182/400, Val Acc=0.4673, Val Loss=2.0905, lr=0.0100
[2025-05-06 20:13:29,776][train][INFO] - Epoch 189/400, Val Acc=0.6107, Val Loss=1.7884, lr=0.0100
[2025-05-06 20:13:31,838][train][INFO] - Epoch 95/300, Val Acc=0.6622, Val Loss=1.5787, lr=0.0100
[2025-05-06 20:13:33,339][train][INFO] - Epoch 183/400, Val Acc=0.4511, Val Loss=2.1105, lr=0.0100
[2025-05-06 20:13:37,582][train][INFO] - Epoch 190/400, Val Acc=0.6069, Val Loss=1.7742, lr=0.0100
[2025-05-06 20:13:39,463][train][INFO] - Epoch 96/300, Val Acc=0.6587, Val Loss=1.6282, lr=0.0100
[2025-05-06 20:13:41,262][train][INFO] - Epoch 184/400, Val Acc=0.4933, Val Loss=1.9808, lr=0.0100
[2025-05-06 20:13:45,129][train][INFO] - Epoch 191/400, Val Acc=0.6141, Val Loss=1.7553, lr=0.0100
[2025-05-06 20:13:46,787][train][INFO] - Epoch 97/300, Val Acc=0.6439, Val Loss=1.7047, lr=0.0100
[2025-05-06 20:13:49,013][train][INFO] - Epoch 185/400, Val Acc=0.4974, Val Loss=1.9337, lr=0.0100
[2025-05-06 20:13:52,886][train][INFO] - Epoch 192/400, Val Acc=0.6153, Val Loss=1.7354, lr=0.0100
[2025-05-06 20:13:54,189][train][INFO] - Epoch 98/300, Val Acc=0.6628, Val Loss=1.6150, lr=0.0100
[2025-05-06 20:13:56,847][train][INFO] - Epoch 186/400, Val Acc=0.4946, Val Loss=1.9701, lr=0.0100
[2025-05-06 20:14:00,232][train][INFO] - Epoch 193/400, Val Acc=0.6129, Val Loss=1.7055, lr=0.0100
[2025-05-06 20:14:01,748][train][INFO] - Epoch 99/300, Val Acc=0.6558, Val Loss=1.6526, lr=0.0100
[2025-05-06 20:14:04,737][train][INFO] - Epoch 187/400, Val Acc=0.4749, Val Loss=2.0819, lr=0.0100
[2025-05-06 20:14:07,620][train][INFO] - Epoch 194/400, Val Acc=0.6024, Val Loss=1.8096, lr=0.0100
[2025-05-06 20:14:09,170][train][INFO] - Epoch 100/300, Val Acc=0.6537, Val Loss=1.6493, lr=0.0100
[2025-05-06 20:14:12,309][train][INFO] - Epoch 188/400, Val Acc=0.4791, Val Loss=2.1031, lr=0.0100
[2025-05-06 20:14:15,150][train][INFO] - Epoch 195/400, Val Acc=0.6134, Val Loss=1.7528, lr=0.0100
[2025-05-06 20:14:16,654][train][INFO] - Epoch 101/300, Val Acc=0.6588, Val Loss=1.6081, lr=0.0100
[2025-05-06 20:14:19,936][train][INFO] - Epoch 189/400, Val Acc=0.5090, Val Loss=1.9253, lr=0.0100
[2025-05-06 20:14:22,629][train][INFO] - Epoch 196/400, Val Acc=0.6238, Val Loss=1.7130, lr=0.0100
[2025-05-06 20:14:24,168][train][INFO] - Epoch 102/300, Val Acc=0.6557, Val Loss=1.6311, lr=0.0100
[2025-05-06 20:14:28,074][train][INFO] - Epoch 190/400, Val Acc=0.4912, Val Loss=2.0120, lr=0.0100
[2025-05-06 20:14:30,462][train][INFO] - Epoch 197/400, Val Acc=0.6185, Val Loss=1.7298, lr=0.0100
[2025-05-06 20:14:31,693][train][INFO] - Epoch 103/300, Val Acc=0.6465, Val Loss=1.6999, lr=0.0100
[2025-05-06 20:14:35,408][train][INFO] - Epoch 191/400, Val Acc=0.5026, Val Loss=1.9078, lr=0.0100
[2025-05-06 20:14:38,022][train][INFO] - Epoch 198/400, Val Acc=0.6055, Val Loss=1.7764, lr=0.0100
[2025-05-06 20:14:39,528][train][INFO] - Epoch 104/300, Val Acc=0.6609, Val Loss=1.6031, lr=0.0100
[2025-05-06 20:14:43,289][train][INFO] - Epoch 192/400, Val Acc=0.4885, Val Loss=2.0220, lr=0.0100
[2025-05-06 20:14:45,468][train][INFO] - Epoch 199/400, Val Acc=0.6296, Val Loss=1.6875, lr=0.0100
[2025-05-06 20:14:47,000][train][INFO] - Epoch 105/300, Val Acc=0.6609, Val Loss=1.6294, lr=0.0100
[2025-05-06 20:14:51,413][train][INFO] - Epoch 193/400, Val Acc=0.4920, Val Loss=2.0043, lr=0.0100
[2025-05-06 20:14:52,976][train][INFO] - Epoch 200/400, Val Acc=0.6141, Val Loss=1.8158, lr=0.0100
[2025-05-06 20:14:54,180][train][INFO] - Epoch 106/300, Val Acc=0.6637, Val Loss=1.5916, lr=0.0100
[2025-05-06 20:14:59,128][train][INFO] - Epoch 194/400, Val Acc=0.4732, Val Loss=2.0832, lr=0.0100
[2025-05-06 20:15:00,561][train][INFO] - Epoch 107/300, Val Acc=0.6628, Val Loss=1.6010, lr=0.0100
[2025-05-06 20:15:00,755][train][INFO] - Epoch 201/400, Val Acc=0.6015, Val Loss=1.8618, lr=0.0100
[2025-05-06 20:15:06,847][train][INFO] - Epoch 195/400, Val Acc=0.4657, Val Loss=2.1125, lr=0.0100
[2025-05-06 20:15:07,824][train][INFO] - Epoch 108/300, Val Acc=0.6561, Val Loss=1.6127, lr=0.0100
[2025-05-06 20:15:08,264][train][INFO] - Epoch 202/400, Val Acc=0.6184, Val Loss=1.7358, lr=0.0100
[2025-05-06 20:15:14,065][train][INFO] - Epoch 196/400, Val Acc=0.4895, Val Loss=1.9851, lr=0.0100
[2025-05-06 20:15:15,736][train][INFO] - Epoch 109/300, Val Acc=0.6449, Val Loss=1.6789, lr=0.0100
[2025-05-06 20:15:15,911][train][INFO] - Epoch 203/400, Val Acc=0.6002, Val Loss=1.8392, lr=0.0100
[2025-05-06 20:15:21,597][train][INFO] - Epoch 197/400, Val Acc=0.4619, Val Loss=2.0724, lr=0.0100
[2025-05-06 20:15:23,446][train][INFO] - Epoch 110/300, Val Acc=0.6650, Val Loss=1.5976, lr=0.0100
[2025-05-06 20:15:23,528][train][INFO] - Epoch 204/400, Val Acc=0.6116, Val Loss=1.7490, lr=0.0100
[2025-05-06 20:15:29,562][train][INFO] - Epoch 198/400, Val Acc=0.4605, Val Loss=2.1967, lr=0.0100
[2025-05-06 20:15:31,146][train][INFO] - Epoch 205/400, Val Acc=0.6061, Val Loss=1.8142, lr=0.0100
[2025-05-06 20:15:31,211][train][INFO] - Epoch 111/300, Val Acc=0.6586, Val Loss=1.6322, lr=0.0100
[2025-05-06 20:15:37,390][train][INFO] - Epoch 199/400, Val Acc=0.5013, Val Loss=1.9420, lr=0.0100
[2025-05-06 20:15:38,266][train][INFO] - Epoch 206/400, Val Acc=0.6190, Val Loss=1.7220, lr=0.0100
[2025-05-06 20:15:38,632][train][INFO] - Epoch 112/300, Val Acc=0.6457, Val Loss=1.6602, lr=0.0100
[2025-05-06 20:15:44,972][train][INFO] - Epoch 200/400, Val Acc=0.4808, Val Loss=2.0208, lr=0.0100
[2025-05-06 20:15:45,949][train][INFO] - Epoch 207/400, Val Acc=0.6142, Val Loss=1.7672, lr=0.0100
[2025-05-06 20:15:46,043][train][INFO] - Epoch 113/300, Val Acc=0.6458, Val Loss=1.7022, lr=0.0100
[2025-05-06 20:15:52,974][train][INFO] - Epoch 201/400, Val Acc=0.4914, Val Loss=1.9907, lr=0.0100
[2025-05-06 20:15:53,523][train][INFO] - Epoch 208/400, Val Acc=0.6087, Val Loss=1.8271, lr=0.0100
[2025-05-06 20:15:53,729][train][INFO] - Epoch 114/300, Val Acc=0.6482, Val Loss=1.6808, lr=0.0100
[2025-05-06 20:16:00,781][train][INFO] - Epoch 202/400, Val Acc=0.5118, Val Loss=1.9169, lr=0.0100
[2025-05-06 20:16:01,219][train][INFO] - Epoch 115/300, Val Acc=0.6405, Val Loss=1.6807, lr=0.0100
[2025-05-06 20:16:01,324][train][INFO] - Epoch 209/400, Val Acc=0.6126, Val Loss=1.8164, lr=0.0100
[2025-05-06 20:16:08,354][train][INFO] - Epoch 116/300, Val Acc=0.6383, Val Loss=1.7243, lr=0.0100
[2025-05-06 20:16:08,422][train][INFO] - Epoch 203/400, Val Acc=0.5012, Val Loss=1.9512, lr=0.0100
[2025-05-06 20:16:09,120][train][INFO] - Epoch 210/400, Val Acc=0.6230, Val Loss=1.7362, lr=0.0100
[2025-05-06 20:16:15,735][train][INFO] - Epoch 204/400, Val Acc=0.4702, Val Loss=2.0834, lr=0.0100
[2025-05-06 20:16:15,787][train][INFO] - Epoch 117/300, Val Acc=0.6383, Val Loss=1.7397, lr=0.0100
[2025-05-06 20:16:16,660][train][INFO] - Epoch 211/400, Val Acc=0.5990, Val Loss=1.8708, lr=0.0100
[2025-05-06 20:16:23,319][train][INFO] - Epoch 118/300, Val Acc=0.6685, Val Loss=1.5693, lr=0.0100
[2025-05-06 20:16:23,662][train][INFO] - Epoch 205/400, Val Acc=0.4327, Val Loss=2.2415, lr=0.0100
[2025-05-06 20:16:24,306][train][INFO] - Epoch 212/400, Val Acc=0.6193, Val Loss=1.7499, lr=0.0100
[2025-05-06 20:16:30,891][train][INFO] - Epoch 119/300, Val Acc=0.6566, Val Loss=1.6360, lr=0.0100
[2025-05-06 20:16:31,543][train][INFO] - Epoch 206/400, Val Acc=0.4930, Val Loss=2.0003, lr=0.0100
[2025-05-06 20:16:32,050][train][INFO] - Epoch 213/400, Val Acc=0.6072, Val Loss=1.8671, lr=0.0100
[2025-05-06 20:16:38,429][train][INFO] - Epoch 120/300, Val Acc=0.6570, Val Loss=1.6145, lr=0.0100
[2025-05-06 20:16:39,354][train][INFO] - Epoch 207/400, Val Acc=0.4952, Val Loss=1.9327, lr=0.0100
[2025-05-06 20:16:39,605][train][INFO] - Epoch 214/400, Val Acc=0.6113, Val Loss=1.8464, lr=0.0100
[2025-05-06 20:16:46,036][train][INFO] - Epoch 121/300, Val Acc=0.6427, Val Loss=1.6861, lr=0.0100
[2025-05-06 20:16:46,397][train][INFO] - Epoch 215/400, Val Acc=0.6220, Val Loss=1.7825, lr=0.0100
[2025-05-06 20:16:47,259][train][INFO] - Epoch 208/400, Val Acc=0.4924, Val Loss=1.9683, lr=0.0100
[2025-05-06 20:16:53,590][train][INFO] - Epoch 216/400, Val Acc=0.6254, Val Loss=1.7109, lr=0.0100
[2025-05-06 20:16:53,696][train][INFO] - Epoch 122/300, Val Acc=0.6335, Val Loss=1.7626, lr=0.0100
[2025-05-06 20:16:55,539][train][INFO] - Epoch 209/400, Val Acc=0.5048, Val Loss=1.9386, lr=0.0100
[2025-05-06 20:17:00,710][train][INFO] - Epoch 217/400, Val Acc=0.6031, Val Loss=1.9076, lr=0.0100
[2025-05-06 20:17:00,786][train][INFO] - Epoch 123/300, Val Acc=0.6626, Val Loss=1.6132, lr=0.0100
[2025-05-06 20:17:03,597][train][INFO] - Epoch 210/400, Val Acc=0.4869, Val Loss=2.0299, lr=0.0100
[2025-05-06 20:17:07,933][train][INFO] - Epoch 218/400, Val Acc=0.6177, Val Loss=1.8146, lr=0.0100
[2025-05-06 20:17:08,296][train][INFO] - Epoch 124/300, Val Acc=0.6640, Val Loss=1.5588, lr=0.0100
[2025-05-06 20:17:11,307][train][INFO] - Epoch 211/400, Val Acc=0.5068, Val Loss=1.8927, lr=0.0100
[2025-05-06 20:17:15,431][train][INFO] - Epoch 219/400, Val Acc=0.6074, Val Loss=1.7910, lr=0.0100
[2025-05-06 20:17:15,779][train][INFO] - Epoch 125/300, Val Acc=0.6599, Val Loss=1.5761, lr=0.0100
[2025-05-06 20:17:18,614][train][INFO] - Epoch 212/400, Val Acc=0.4827, Val Loss=2.0233, lr=0.0100
[2025-05-06 20:17:22,302][train][INFO] - Epoch 220/400, Val Acc=0.6109, Val Loss=1.8365, lr=0.0100
[2025-05-06 20:17:23,179][train][INFO] - Epoch 126/300, Val Acc=0.6564, Val Loss=1.6598, lr=0.0100
[2025-05-06 20:17:26,500][train][INFO] - Epoch 213/400, Val Acc=0.5034, Val Loss=1.9546, lr=0.0100
[2025-05-06 20:17:29,734][train][INFO] - Epoch 221/400, Val Acc=0.6036, Val Loss=1.8663, lr=0.0100
[2025-05-06 20:17:30,710][train][INFO] - Epoch 127/300, Val Acc=0.6471, Val Loss=1.7112, lr=0.0100
[2025-05-06 20:17:34,322][train][INFO] - Epoch 214/400, Val Acc=0.4837, Val Loss=2.0181, lr=0.0100
[2025-05-06 20:17:37,273][train][INFO] - Epoch 222/400, Val Acc=0.6033, Val Loss=1.8824, lr=0.0100
[2025-05-06 20:17:38,097][train][INFO] - Epoch 128/300, Val Acc=0.6585, Val Loss=1.6426, lr=0.0100
[2025-05-06 20:17:41,921][train][INFO] - Epoch 215/400, Val Acc=0.4819, Val Loss=2.0264, lr=0.0100
[2025-05-06 20:17:44,302][train][INFO] - Epoch 223/400, Val Acc=0.6250, Val Loss=1.7291, lr=0.0100
[2025-05-06 20:17:45,396][train][INFO] - Epoch 129/300, Val Acc=0.6471, Val Loss=1.6719, lr=0.0100
[2025-05-06 20:17:49,716][train][INFO] - Epoch 216/400, Val Acc=0.4725, Val Loss=2.0653, lr=0.0100
[2025-05-06 20:17:51,841][train][INFO] - Epoch 224/400, Val Acc=0.5973, Val Loss=1.8876, lr=0.0100
[2025-05-06 20:17:52,886][train][INFO] - Epoch 130/300, Val Acc=0.6511, Val Loss=1.6632, lr=0.0100
[2025-05-06 20:17:57,678][train][INFO] - Epoch 217/400, Val Acc=0.5099, Val Loss=1.9042, lr=0.0100
[2025-05-06 20:17:59,320][train][INFO] - Epoch 225/400, Val Acc=0.6158, Val Loss=1.7472, lr=0.0100
[2025-05-06 20:17:59,739][train][INFO] - Epoch 131/300, Val Acc=0.6599, Val Loss=1.6201, lr=0.0100
[2025-05-06 20:18:05,647][train][INFO] - Epoch 218/400, Val Acc=0.5117, Val Loss=1.9308, lr=0.0100
[2025-05-06 20:18:06,825][train][INFO] - Epoch 132/300, Val Acc=0.6457, Val Loss=1.6803, lr=0.0100
[2025-05-06 20:18:07,397][train][INFO] - Epoch 226/400, Val Acc=0.6250, Val Loss=1.6822, lr=0.0100
[2025-05-06 20:18:13,821][train][INFO] - Epoch 219/400, Val Acc=0.4577, Val Loss=2.1233, lr=0.0100
[2025-05-06 20:18:13,970][train][INFO] - Epoch 133/300, Val Acc=0.6568, Val Loss=1.6257, lr=0.0100
[2025-05-06 20:18:14,588][train][INFO] - Epoch 227/400, Val Acc=0.6197, Val Loss=1.7612, lr=0.0100
[2025-05-06 20:18:21,102][train][INFO] - Epoch 134/300, Val Acc=0.6589, Val Loss=1.5884, lr=0.0100
[2025-05-06 20:18:22,075][train][INFO] - Epoch 228/400, Val Acc=0.6095, Val Loss=1.8156, lr=0.0100
[2025-05-06 20:18:22,107][train][INFO] - Epoch 220/400, Val Acc=0.4913, Val Loss=1.9734, lr=0.0100
[2025-05-06 20:18:28,794][train][INFO] - Epoch 135/300, Val Acc=0.6393, Val Loss=1.7041, lr=0.0100
[2025-05-06 20:18:29,620][train][INFO] - Epoch 229/400, Val Acc=0.6180, Val Loss=1.7993, lr=0.0100
[2025-05-06 20:18:30,114][train][INFO] - Epoch 221/400, Val Acc=0.5006, Val Loss=1.9189, lr=0.0100
[2025-05-06 20:18:36,305][train][INFO] - Epoch 136/300, Val Acc=0.6500, Val Loss=1.6842, lr=0.0100
[2025-05-06 20:18:37,085][train][INFO] - Epoch 230/400, Val Acc=0.6212, Val Loss=1.7196, lr=0.0100
[2025-05-06 20:18:37,767][train][INFO] - Epoch 222/400, Val Acc=0.4752, Val Loss=2.0961, lr=0.0100
[2025-05-06 20:18:43,820][train][INFO] - Epoch 137/300, Val Acc=0.6436, Val Loss=1.7096, lr=0.0100
[2025-05-06 20:18:44,590][train][INFO] - Epoch 231/400, Val Acc=0.6285, Val Loss=1.7026, lr=0.0100
[2025-05-06 20:18:45,373][train][INFO] - Epoch 223/400, Val Acc=0.4910, Val Loss=1.9992, lr=0.0100
[2025-05-06 20:18:51,591][train][INFO] - Epoch 138/300, Val Acc=0.6578, Val Loss=1.6090, lr=0.0100
[2025-05-06 20:18:52,079][train][INFO] - Epoch 224/400, Val Acc=0.5033, Val Loss=1.9188, lr=0.0100
[2025-05-06 20:18:52,281][train][INFO] - Epoch 232/400, Val Acc=0.6232, Val Loss=1.6816, lr=0.0100
[2025-05-06 20:18:58,924][train][INFO] - Epoch 139/300, Val Acc=0.6660, Val Loss=1.5826, lr=0.0100
[2025-05-06 20:18:59,694][train][INFO] - Epoch 233/400, Val Acc=0.6015, Val Loss=1.9011, lr=0.0100
[2025-05-06 20:18:59,857][train][INFO] - Epoch 225/400, Val Acc=0.4994, Val Loss=1.9611, lr=0.0100
[2025-05-06 20:19:06,523][train][INFO] - Epoch 140/300, Val Acc=0.6566, Val Loss=1.6285, lr=0.0100
[2025-05-06 20:19:07,587][train][INFO] - Epoch 234/400, Val Acc=0.6193, Val Loss=1.7599, lr=0.0100
[2025-05-06 20:19:07,899][train][INFO] - Epoch 226/400, Val Acc=0.4983, Val Loss=1.9710, lr=0.0100
[2025-05-06 20:19:13,740][train][INFO] - Epoch 141/300, Val Acc=0.6558, Val Loss=1.6897, lr=0.0100
[2025-05-06 20:19:15,306][train][INFO] - Epoch 235/400, Val Acc=0.6315, Val Loss=1.6744, lr=0.0100
[2025-05-06 20:19:15,701][train][INFO] - Epoch 227/400, Val Acc=0.4496, Val Loss=2.1199, lr=0.0100
[2025-05-06 20:19:20,727][train][INFO] - Epoch 142/300, Val Acc=0.6363, Val Loss=1.7743, lr=0.0100
[2025-05-06 20:19:22,211][train][INFO] - Epoch 236/400, Val Acc=0.6104, Val Loss=1.8682, lr=0.0100
[2025-05-06 20:19:23,600][train][INFO] - Epoch 228/400, Val Acc=0.4852, Val Loss=2.0721, lr=0.0100
[2025-05-06 20:19:27,792][train][INFO] - Epoch 143/300, Val Acc=0.6530, Val Loss=1.6639, lr=0.0100
[2025-05-06 20:19:29,971][train][INFO] - Epoch 237/400, Val Acc=0.6096, Val Loss=1.8886, lr=0.0100
[2025-05-06 20:19:31,423][train][INFO] - Epoch 229/400, Val Acc=0.5049, Val Loss=2.0056, lr=0.0100
[2025-05-06 20:19:35,085][train][INFO] - Epoch 144/300, Val Acc=0.6532, Val Loss=1.6399, lr=0.0100
[2025-05-06 20:19:37,150][train][INFO] - Epoch 238/400, Val Acc=0.6084, Val Loss=1.8417, lr=0.0100
[2025-05-06 20:19:39,276][train][INFO] - Epoch 230/400, Val Acc=0.4804, Val Loss=2.0704, lr=0.0100
[2025-05-06 20:19:42,094][train][INFO] - Epoch 145/300, Val Acc=0.6551, Val Loss=1.6385, lr=0.0100
[2025-05-06 20:19:44,518][train][INFO] - Epoch 239/400, Val Acc=0.6309, Val Loss=1.6893, lr=0.0100
[2025-05-06 20:19:46,845][train][INFO] - Epoch 231/400, Val Acc=0.4863, Val Loss=2.0247, lr=0.0100
[2025-05-06 20:19:49,820][train][INFO] - Epoch 146/300, Val Acc=0.6506, Val Loss=1.6836, lr=0.0100
[2025-05-06 20:19:51,892][train][INFO] - Epoch 240/400, Val Acc=0.6164, Val Loss=1.7981, lr=0.0100
[2025-05-06 20:19:54,647][train][INFO] - Epoch 232/400, Val Acc=0.4841, Val Loss=2.0177, lr=0.0100
[2025-05-06 20:19:57,423][train][INFO] - Epoch 147/300, Val Acc=0.6391, Val Loss=1.7590, lr=0.0100
[2025-05-06 20:19:58,929][train][INFO] - Epoch 241/400, Val Acc=0.6104, Val Loss=1.8513, lr=0.0100
[2025-05-06 20:20:02,118][train][INFO] - Epoch 233/400, Val Acc=0.4988, Val Loss=1.9411, lr=0.0100
[2025-05-06 20:20:04,398][train][INFO] - Epoch 148/300, Val Acc=0.6514, Val Loss=1.6614, lr=0.0100
[2025-05-06 20:20:06,558][train][INFO] - Epoch 242/400, Val Acc=0.6247, Val Loss=1.7485, lr=0.0100
[2025-05-06 20:20:09,759][train][INFO] - Epoch 234/400, Val Acc=0.5094, Val Loss=1.8747, lr=0.0100
[2025-05-06 20:20:11,680][train][INFO] - Epoch 149/300, Val Acc=0.6574, Val Loss=1.6399, lr=0.0100
[2025-05-06 20:20:14,113][train][INFO] - Epoch 243/400, Val Acc=0.6253, Val Loss=1.7266, lr=0.0100
[2025-05-06 20:20:17,665][train][INFO] - Epoch 235/400, Val Acc=0.4829, Val Loss=2.1118, lr=0.0100
[2025-05-06 20:20:19,165][train][INFO] - Epoch 150/300, Val Acc=0.6511, Val Loss=1.6849, lr=0.0100
[2025-05-06 20:20:21,583][train][INFO] - Epoch 244/400, Val Acc=0.6198, Val Loss=1.7807, lr=0.0100
[2025-05-06 20:20:25,425][train][INFO] - Epoch 236/400, Val Acc=0.4904, Val Loss=2.0312, lr=0.0100
[2025-05-06 20:20:26,577][train][INFO] - Epoch 151/300, Val Acc=0.7119, Val Loss=1.3398, lr=0.0010
[2025-05-06 20:20:29,053][train][INFO] - Epoch 245/400, Val Acc=0.6136, Val Loss=1.8476, lr=0.0100
[2025-05-06 20:20:33,232][train][INFO] - Epoch 152/300, Val Acc=0.7184, Val Loss=1.3360, lr=0.0010
[2025-05-06 20:20:33,342][train][INFO] - Epoch 237/400, Val Acc=0.5019, Val Loss=1.9976, lr=0.0100
[2025-05-06 20:20:36,775][train][INFO] - Epoch 246/400, Val Acc=0.6203, Val Loss=1.7914, lr=0.0100
[2025-05-06 20:20:40,514][train][INFO] - Epoch 153/300, Val Acc=0.7207, Val Loss=1.3309, lr=0.0010
[2025-05-06 20:20:40,930][train][INFO] - Epoch 238/400, Val Acc=0.4937, Val Loss=1.9638, lr=0.0100
[2025-05-06 20:20:44,095][train][INFO] - Epoch 247/400, Val Acc=0.6169, Val Loss=1.8120, lr=0.0100
[2025-05-06 20:20:47,891][train][INFO] - Epoch 154/300, Val Acc=0.7223, Val Loss=1.3378, lr=0.0010
[2025-05-06 20:20:48,593][train][INFO] - Epoch 239/400, Val Acc=0.4855, Val Loss=2.0273, lr=0.0100
[2025-05-06 20:20:51,673][train][INFO] - Epoch 248/400, Val Acc=0.6155, Val Loss=1.7819, lr=0.0100
[2025-05-06 20:20:55,347][train][INFO] - Epoch 155/300, Val Acc=0.7226, Val Loss=1.3380, lr=0.0010
[2025-05-06 20:20:56,155][train][INFO] - Epoch 240/400, Val Acc=0.5009, Val Loss=1.9539, lr=0.0100
[2025-05-06 20:20:59,304][train][INFO] - Epoch 249/400, Val Acc=0.6217, Val Loss=1.7590, lr=0.0100
[2025-05-06 20:21:02,948][train][INFO] - Epoch 156/300, Val Acc=0.7279, Val Loss=1.3411, lr=0.0010
[2025-05-06 20:21:03,921][train][INFO] - Epoch 241/400, Val Acc=0.4975, Val Loss=1.9719, lr=0.0100
[2025-05-06 20:21:07,122][train][INFO] - Epoch 250/400, Val Acc=0.6135, Val Loss=1.8150, lr=0.0100
[2025-05-06 20:21:10,463][train][INFO] - Epoch 157/300, Val Acc=0.7266, Val Loss=1.3451, lr=0.0010
[2025-05-06 20:21:11,858][train][INFO] - Epoch 242/400, Val Acc=0.5004, Val Loss=1.9558, lr=0.0100
[2025-05-06 20:21:14,632][train][INFO] - Epoch 251/400, Val Acc=0.6717, Val Loss=1.4961, lr=0.0010
[2025-05-06 20:21:18,034][train][INFO] - Epoch 158/300, Val Acc=0.7247, Val Loss=1.3521, lr=0.0010
[2025-05-06 20:21:19,673][train][INFO] - Epoch 243/400, Val Acc=0.5027, Val Loss=1.9342, lr=0.0100
[2025-05-06 20:21:22,294][train][INFO] - Epoch 252/400, Val Acc=0.6757, Val Loss=1.4927, lr=0.0010
[2025-05-06 20:21:25,345][train][INFO] - Epoch 159/300, Val Acc=0.7275, Val Loss=1.3552, lr=0.0010
[2025-05-06 20:21:27,080][train][INFO] - Epoch 244/400, Val Acc=0.5097, Val Loss=1.9002, lr=0.0100
[2025-05-06 20:21:29,434][train][INFO] - Epoch 253/400, Val Acc=0.6761, Val Loss=1.5008, lr=0.0010
[2025-05-06 20:21:32,707][train][INFO] - Epoch 160/300, Val Acc=0.7267, Val Loss=1.3630, lr=0.0010
[2025-05-06 20:21:35,037][train][INFO] - Epoch 245/400, Val Acc=0.4754, Val Loss=2.1134, lr=0.0100
[2025-05-06 20:21:36,911][train][INFO] - Epoch 254/400, Val Acc=0.6776, Val Loss=1.5123, lr=0.0010
[2025-05-06 20:21:40,426][train][INFO] - Epoch 161/300, Val Acc=0.7281, Val Loss=1.3567, lr=0.0010
[2025-05-06 20:21:43,182][train][INFO] - Epoch 246/400, Val Acc=0.5064, Val Loss=1.8968, lr=0.0100
[2025-05-06 20:21:44,408][train][INFO] - Epoch 255/400, Val Acc=0.6775, Val Loss=1.5259, lr=0.0010
[2025-05-06 20:21:47,904][train][INFO] - Epoch 162/300, Val Acc=0.7282, Val Loss=1.3518, lr=0.0010
[2025-05-06 20:21:50,902][train][INFO] - Epoch 247/400, Val Acc=0.4975, Val Loss=1.9528, lr=0.0100
[2025-05-06 20:21:51,899][train][INFO] - Epoch 256/400, Val Acc=0.6803, Val Loss=1.5365, lr=0.0010
[2025-05-06 20:21:55,567][train][INFO] - Epoch 163/300, Val Acc=0.7272, Val Loss=1.3615, lr=0.0010
[2025-05-06 20:21:58,570][train][INFO] - Epoch 248/400, Val Acc=0.4791, Val Loss=2.0702, lr=0.0100
[2025-05-06 20:21:59,335][train][INFO] - Epoch 257/400, Val Acc=0.6777, Val Loss=1.5483, lr=0.0010
[2025-05-06 20:22:02,449][train][INFO] - Epoch 164/300, Val Acc=0.7269, Val Loss=1.3618, lr=0.0010
[2025-05-06 20:22:06,375][train][INFO] - Epoch 249/400, Val Acc=0.4930, Val Loss=2.0471, lr=0.0100
[2025-05-06 20:22:06,553][train][INFO] - Epoch 258/400, Val Acc=0.6793, Val Loss=1.5566, lr=0.0010
[2025-05-06 20:22:09,796][train][INFO] - Epoch 165/300, Val Acc=0.7292, Val Loss=1.3575, lr=0.0010
[2025-05-06 20:22:13,622][train][INFO] - Epoch 259/400, Val Acc=0.6826, Val Loss=1.5604, lr=0.0010
[2025-05-06 20:22:13,988][train][INFO] - Epoch 250/400, Val Acc=0.4982, Val Loss=1.9903, lr=0.0100
[2025-05-06 20:22:17,459][train][INFO] - Epoch 166/300, Val Acc=0.7297, Val Loss=1.3647, lr=0.0010
[2025-05-06 20:22:21,263][train][INFO] - Epoch 260/400, Val Acc=0.6800, Val Loss=1.5668, lr=0.0010
[2025-05-06 20:22:22,038][train][INFO] - Epoch 251/400, Val Acc=0.5634, Val Loss=1.6725, lr=0.0010
[2025-05-06 20:22:24,615][train][INFO] - Epoch 167/300, Val Acc=0.7286, Val Loss=1.3702, lr=0.0010
[2025-05-06 20:22:28,935][train][INFO] - Epoch 261/400, Val Acc=0.6770, Val Loss=1.5820, lr=0.0010
[2025-05-06 20:22:30,029][train][INFO] - Epoch 252/400, Val Acc=0.5679, Val Loss=1.6695, lr=0.0010
[2025-05-06 20:22:31,592][train][INFO] - Epoch 168/300, Val Acc=0.7278, Val Loss=1.3721, lr=0.0010
[2025-05-06 20:22:36,773][train][INFO] - Epoch 262/400, Val Acc=0.6773, Val Loss=1.5892, lr=0.0010
[2025-05-06 20:22:38,031][train][INFO] - Epoch 253/400, Val Acc=0.5700, Val Loss=1.6661, lr=0.0010
[2025-05-06 20:22:38,345][train][INFO] - Epoch 169/300, Val Acc=0.7314, Val Loss=1.3760, lr=0.0010
[2025-05-06 20:22:44,245][train][INFO] - Epoch 263/400, Val Acc=0.6803, Val Loss=1.5947, lr=0.0010
[2025-05-06 20:22:45,582][train][INFO] - Epoch 170/300, Val Acc=0.7288, Val Loss=1.3818, lr=0.0010
[2025-05-06 20:22:45,961][train][INFO] - Epoch 254/400, Val Acc=0.5718, Val Loss=1.6769, lr=0.0010
[2025-05-06 20:22:51,472][train][INFO] - Epoch 264/400, Val Acc=0.6814, Val Loss=1.5921, lr=0.0010
[2025-05-06 20:22:52,865][train][INFO] - Epoch 171/300, Val Acc=0.7275, Val Loss=1.3785, lr=0.0010
[2025-05-06 20:22:53,489][train][INFO] - Epoch 255/400, Val Acc=0.5725, Val Loss=1.6724, lr=0.0010
[2025-05-06 20:22:58,937][train][INFO] - Epoch 265/400, Val Acc=0.6816, Val Loss=1.5968, lr=0.0010
[2025-05-06 20:22:59,986][train][INFO] - Epoch 172/300, Val Acc=0.7288, Val Loss=1.3803, lr=0.0010
[2025-05-06 20:23:00,894][train][INFO] - Epoch 256/400, Val Acc=0.5726, Val Loss=1.6730, lr=0.0010
[2025-05-06 20:23:06,642][train][INFO] - Epoch 266/400, Val Acc=0.6800, Val Loss=1.6117, lr=0.0010
[2025-05-06 20:23:07,638][train][INFO] - Epoch 173/300, Val Acc=0.7283, Val Loss=1.3817, lr=0.0010
[2025-05-06 20:23:09,203][train][INFO] - Epoch 257/400, Val Acc=0.5765, Val Loss=1.6615, lr=0.0010
[2025-05-06 20:23:14,064][train][INFO] - Epoch 267/400, Val Acc=0.6819, Val Loss=1.6148, lr=0.0010
[2025-05-06 20:23:15,503][train][INFO] - Epoch 174/300, Val Acc=0.7283, Val Loss=1.3834, lr=0.0010
[2025-05-06 20:23:17,023][train][INFO] - Epoch 258/400, Val Acc=0.5709, Val Loss=1.6699, lr=0.0010
[2025-05-06 20:23:21,578][train][INFO] - Epoch 268/400, Val Acc=0.6805, Val Loss=1.6271, lr=0.0010
[2025-05-06 20:23:23,281][train][INFO] - Epoch 175/300, Val Acc=0.7306, Val Loss=1.3855, lr=0.0010
[2025-05-06 20:23:24,562][train][INFO] - Epoch 259/400, Val Acc=0.5745, Val Loss=1.6647, lr=0.0010
[2025-05-06 20:23:29,669][train][INFO] - Epoch 269/400, Val Acc=0.6799, Val Loss=1.6356, lr=0.0010
[2025-05-06 20:23:30,917][train][INFO] - Epoch 176/300, Val Acc=0.7276, Val Loss=1.3811, lr=0.0010
[2025-05-06 20:23:32,214][train][INFO] - Epoch 260/400, Val Acc=0.5726, Val Loss=1.6715, lr=0.0010
[2025-05-06 20:23:37,395][train][INFO] - Epoch 270/400, Val Acc=0.6790, Val Loss=1.6416, lr=0.0010
[2025-05-06 20:23:38,498][train][INFO] - Epoch 177/300, Val Acc=0.7303, Val Loss=1.3851, lr=0.0010
[2025-05-06 20:23:40,462][train][INFO] - Epoch 261/400, Val Acc=0.5783, Val Loss=1.6675, lr=0.0010
[2025-05-06 20:23:45,064][train][INFO] - Epoch 271/400, Val Acc=0.6808, Val Loss=1.6395, lr=0.0010
[2025-05-06 20:23:45,662][train][INFO] - Epoch 178/300, Val Acc=0.7301, Val Loss=1.3803, lr=0.0010
[2025-05-06 20:23:48,589][train][INFO] - Epoch 262/400, Val Acc=0.5757, Val Loss=1.6762, lr=0.0010
[2025-05-06 20:23:52,692][train][INFO] - Epoch 272/400, Val Acc=0.6814, Val Loss=1.6508, lr=0.0010
[2025-05-06 20:23:53,165][train][INFO] - Epoch 179/300, Val Acc=0.7328, Val Loss=1.3856, lr=0.0010
[2025-05-06 20:23:56,562][train][INFO] - Epoch 263/400, Val Acc=0.5753, Val Loss=1.6789, lr=0.0010
[2025-05-06 20:24:00,347][train][INFO] - Epoch 273/400, Val Acc=0.6823, Val Loss=1.6480, lr=0.0010
[2025-05-06 20:24:00,682][train][INFO] - Epoch 180/300, Val Acc=0.7309, Val Loss=1.3935, lr=0.0010
[2025-05-06 20:24:03,983][train][INFO] - Epoch 264/400, Val Acc=0.5757, Val Loss=1.6860, lr=0.0010
[2025-05-06 20:24:07,652][train][INFO] - Epoch 181/300, Val Acc=0.7298, Val Loss=1.3928, lr=0.0010
[2025-05-06 20:24:07,967][train][INFO] - Epoch 274/400, Val Acc=0.6826, Val Loss=1.6472, lr=0.0010
[2025-05-06 20:24:11,953][train][INFO] - Epoch 265/400, Val Acc=0.5720, Val Loss=1.6844, lr=0.0010
[2025-05-06 20:24:14,695][train][INFO] - Epoch 182/300, Val Acc=0.7324, Val Loss=1.3866, lr=0.0010
[2025-05-06 20:24:15,178][train][INFO] - Epoch 275/400, Val Acc=0.6830, Val Loss=1.6505, lr=0.0010
[2025-05-06 20:24:20,045][train][INFO] - Epoch 266/400, Val Acc=0.5765, Val Loss=1.6800, lr=0.0010
[2025-05-06 20:24:22,321][train][INFO] - Epoch 183/300, Val Acc=0.7328, Val Loss=1.3849, lr=0.0010
[2025-05-06 20:24:22,375][train][INFO] - Epoch 276/400, Val Acc=0.6804, Val Loss=1.6547, lr=0.0010
[2025-05-06 20:24:28,048][train][INFO] - Epoch 267/400, Val Acc=0.5757, Val Loss=1.6961, lr=0.0010
[2025-05-06 20:24:29,752][train][INFO] - Epoch 184/300, Val Acc=0.7315, Val Loss=1.3860, lr=0.0010
[2025-05-06 20:24:29,926][train][INFO] - Epoch 277/400, Val Acc=0.6813, Val Loss=1.6705, lr=0.0010
[2025-05-06 20:24:36,004][train][INFO] - Epoch 268/400, Val Acc=0.5755, Val Loss=1.6931, lr=0.0010
[2025-05-06 20:24:37,522][train][INFO] - Epoch 185/300, Val Acc=0.7315, Val Loss=1.3849, lr=0.0010
[2025-05-06 20:24:37,870][train][INFO] - Epoch 278/400, Val Acc=0.6773, Val Loss=1.6783, lr=0.0010
[2025-05-06 20:24:43,582][train][INFO] - Epoch 269/400, Val Acc=0.5736, Val Loss=1.6966, lr=0.0010
[2025-05-06 20:24:45,108][train][INFO] - Epoch 186/300, Val Acc=0.7291, Val Loss=1.3858, lr=0.0010
[2025-05-06 20:24:45,457][train][INFO] - Epoch 279/400, Val Acc=0.6791, Val Loss=1.6732, lr=0.0010
[2025-05-06 20:24:51,291][train][INFO] - Epoch 270/400, Val Acc=0.5783, Val Loss=1.6878, lr=0.0010
[2025-05-06 20:24:52,348][train][INFO] - Epoch 187/300, Val Acc=0.7308, Val Loss=1.3884, lr=0.0010
[2025-05-06 20:24:52,742][train][INFO] - Epoch 280/400, Val Acc=0.6811, Val Loss=1.6705, lr=0.0010
[2025-05-06 20:24:59,514][train][INFO] - Epoch 271/400, Val Acc=0.5783, Val Loss=1.6869, lr=0.0010
[2025-05-06 20:24:59,700][train][INFO] - Epoch 188/300, Val Acc=0.7313, Val Loss=1.3968, lr=0.0010
[2025-05-06 20:25:00,121][train][INFO] - Epoch 281/400, Val Acc=0.6812, Val Loss=1.6774, lr=0.0010
[2025-05-06 20:25:07,000][train][INFO] - Epoch 189/300, Val Acc=0.7302, Val Loss=1.3972, lr=0.0010
[2025-05-06 20:25:07,352][train][INFO] - Epoch 272/400, Val Acc=0.5731, Val Loss=1.6984, lr=0.0010
[2025-05-06 20:25:07,609][train][INFO] - Epoch 282/400, Val Acc=0.6807, Val Loss=1.6846, lr=0.0010
[2025-05-06 20:25:14,442][train][INFO] - Epoch 190/300, Val Acc=0.7321, Val Loss=1.3917, lr=0.0010
[2025-05-06 20:25:15,163][train][INFO] - Epoch 283/400, Val Acc=0.6790, Val Loss=1.6888, lr=0.0010
[2025-05-06 20:25:15,382][train][INFO] - Epoch 273/400, Val Acc=0.5779, Val Loss=1.6955, lr=0.0010
[2025-05-06 20:25:21,553][train][INFO] - Epoch 191/300, Val Acc=0.7301, Val Loss=1.3951, lr=0.0010
[2025-05-06 20:25:22,689][train][INFO] - Epoch 284/400, Val Acc=0.6807, Val Loss=1.6889, lr=0.0010
[2025-05-06 20:25:22,875][train][INFO] - Epoch 274/400, Val Acc=0.5778, Val Loss=1.6964, lr=0.0010
[2025-05-06 20:25:29,097][train][INFO] - Epoch 192/300, Val Acc=0.7329, Val Loss=1.3909, lr=0.0010
[2025-05-06 20:25:30,090][train][INFO] - Epoch 285/400, Val Acc=0.6802, Val Loss=1.6983, lr=0.0010
[2025-05-06 20:25:30,563][train][INFO] - Epoch 275/400, Val Acc=0.5771, Val Loss=1.6898, lr=0.0010
[2025-05-06 20:25:36,325][train][INFO] - Epoch 193/300, Val Acc=0.7290, Val Loss=1.3901, lr=0.0010
[2025-05-06 20:25:37,374][train][INFO] - Epoch 286/400, Val Acc=0.6792, Val Loss=1.7020, lr=0.0010
[2025-05-06 20:25:38,259][train][INFO] - Epoch 276/400, Val Acc=0.5762, Val Loss=1.6987, lr=0.0010
[2025-05-06 20:25:44,015][train][INFO] - Epoch 194/300, Val Acc=0.7305, Val Loss=1.3866, lr=0.0010
[2025-05-06 20:25:45,084][train][INFO] - Epoch 287/400, Val Acc=0.6807, Val Loss=1.6942, lr=0.0010
[2025-05-06 20:25:46,324][train][INFO] - Epoch 277/400, Val Acc=0.5785, Val Loss=1.7050, lr=0.0010
[2025-05-06 20:25:51,201][train][INFO] - Epoch 195/300, Val Acc=0.7314, Val Loss=1.3911, lr=0.0010
[2025-05-06 20:25:52,335][train][INFO] - Epoch 288/400, Val Acc=0.6820, Val Loss=1.6964, lr=0.0010
[2025-05-06 20:25:54,051][train][INFO] - Epoch 278/400, Val Acc=0.5756, Val Loss=1.7007, lr=0.0010
[2025-05-06 20:25:58,514][train][INFO] - Epoch 196/300, Val Acc=0.7295, Val Loss=1.3944, lr=0.0010
[2025-05-06 20:25:59,537][train][INFO] - Epoch 289/400, Val Acc=0.6794, Val Loss=1.7049, lr=0.0010
[2025-05-06 20:26:01,978][train][INFO] - Epoch 279/400, Val Acc=0.5759, Val Loss=1.7052, lr=0.0010
[2025-05-06 20:26:06,068][train][INFO] - Epoch 197/300, Val Acc=0.7297, Val Loss=1.3962, lr=0.0010
[2025-05-06 20:26:06,867][train][INFO] - Epoch 290/400, Val Acc=0.6777, Val Loss=1.7049, lr=0.0010
[2025-05-06 20:26:09,796][train][INFO] - Epoch 280/400, Val Acc=0.5730, Val Loss=1.7044, lr=0.0010
[2025-05-06 20:26:12,921][train][INFO] - Epoch 198/300, Val Acc=0.7308, Val Loss=1.3953, lr=0.0010
[2025-05-06 20:26:14,428][train][INFO] - Epoch 291/400, Val Acc=0.6797, Val Loss=1.7120, lr=0.0010
[2025-05-06 20:26:17,506][train][INFO] - Epoch 281/400, Val Acc=0.5755, Val Loss=1.7063, lr=0.0010
[2025-05-06 20:26:20,361][train][INFO] - Epoch 199/300, Val Acc=0.7311, Val Loss=1.4001, lr=0.0010
[2025-05-06 20:26:27,233][train][INFO] - Epoch 200/300, Val Acc=0.7327, Val Loss=1.3979, lr=0.0010
[2025-05-06 20:26:35,267][train][INFO] - Epoch 201/300, Val Acc=0.7301, Val Loss=1.3920, lr=0.0010
[2025-05-06 20:26:42,600][train][INFO] - Epoch 202/300, Val Acc=0.7301, Val Loss=1.3948, lr=0.0010
[2025-05-06 20:26:50,265][train][INFO] - Epoch 203/300, Val Acc=0.7316, Val Loss=1.3909, lr=0.0010
[2025-05-06 20:26:57,600][train][INFO] - Epoch 204/300, Val Acc=0.7296, Val Loss=1.3995, lr=0.0010
[2025-05-06 20:27:04,140][train][INFO] - Epoch 205/300, Val Acc=0.7310, Val Loss=1.4010, lr=0.0010
[2025-05-06 20:27:11,416][train][INFO] - Epoch 206/300, Val Acc=0.7309, Val Loss=1.4052, lr=0.0010
[2025-05-06 20:27:18,317][train][INFO] - Epoch 207/300, Val Acc=0.7305, Val Loss=1.4005, lr=0.0010
[2025-05-06 20:27:25,312][train][INFO] - Epoch 208/300, Val Acc=0.7294, Val Loss=1.4016, lr=0.0010
[2025-05-06 20:27:32,540][train][INFO] - Epoch 209/300, Val Acc=0.7304, Val Loss=1.4009, lr=0.0010
[2025-05-06 20:27:39,318][train][INFO] - Epoch 210/300, Val Acc=0.7287, Val Loss=1.3952, lr=0.0010
[2025-05-06 20:27:46,332][train][INFO] - Epoch 211/300, Val Acc=0.7321, Val Loss=1.3969, lr=0.0010
[2025-05-06 20:27:53,450][train][INFO] - Epoch 212/300, Val Acc=0.7284, Val Loss=1.3978, lr=0.0010
[2025-05-06 20:28:00,264][train][INFO] - Epoch 213/300, Val Acc=0.7302, Val Loss=1.3973, lr=0.0010
[2025-05-06 20:28:07,248][train][INFO] - Epoch 214/300, Val Acc=0.7295, Val Loss=1.3996, lr=0.0010
[2025-05-06 20:28:14,495][train][INFO] - Epoch 215/300, Val Acc=0.7294, Val Loss=1.3992, lr=0.0010
[2025-05-06 20:28:21,651][train][INFO] - Epoch 216/300, Val Acc=0.7318, Val Loss=1.3983, lr=0.0010
[2025-05-06 20:28:24,984][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 1000
        lr: 0.01
        lr_decay_milestones: 600, 900
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 1000
        lr: 0.01
        lr_decay_milestones: 600, 900
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 70

[2025-05-06 20:28:25,077][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 20:28:25,078][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 20:28:25,078][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 20:28:28,949][train][INFO] - Epoch 217/300, Val Acc=0.7306, Val Loss=1.3980, lr=0.0010
[2025-05-06 20:28:29,339][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 3.0
    - 4.5
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 1000
        lr: 0.01
        lr_decay_milestones: 600, 900
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 1000
        lr: 0.01
        lr_decay_milestones: 600, 900
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 100

[2025-05-06 20:28:29,391][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 20:28:29,391][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 20:28:29,391][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 20:28:37,273][train][INFO] - Epoch 218/300, Val Acc=0.7306, Val Loss=1.3956, lr=0.0010
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 20:28:45,026][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 20:28:45,609][train][INFO] - Epoch 219/300, Val Acc=0.7303, Val Loss=1.3924, lr=0.0010
[2025-05-06 20:28:49,351][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 20:28:52,670][train][INFO] - Epoch 1/1000, Val Acc=0.0477, Val Loss=4.2598, lr=0.0100
[2025-05-06 20:28:52,693][train][INFO] - Epoch 220/300, Val Acc=0.7299, Val Loss=1.3958, lr=0.0010
[2025-05-06 20:28:57,206][train][INFO] - Epoch 1/1000, Val Acc=0.0498, Val Loss=4.0701, lr=0.0100
[2025-05-06 20:29:00,400][train][INFO] - Epoch 221/300, Val Acc=0.7308, Val Loss=1.3962, lr=0.0010
[2025-05-06 20:29:00,677][train][INFO] - Epoch 2/1000, Val Acc=0.1800, Val Loss=3.1408, lr=0.0100
[2025-05-06 20:29:04,983][train][INFO] - Epoch 2/1000, Val Acc=0.1073, Val Loss=3.7285, lr=0.0100
[2025-05-06 20:29:07,841][train][INFO] - Epoch 222/300, Val Acc=0.7323, Val Loss=1.3944, lr=0.0010
[2025-05-06 20:29:08,268][train][INFO] - Epoch 3/1000, Val Acc=0.2047, Val Loss=3.0136, lr=0.0100
[2025-05-06 20:29:12,555][train][INFO] - Epoch 3/1000, Val Acc=0.1012, Val Loss=3.7805, lr=0.0100
[2025-05-06 20:29:15,517][train][INFO] - Epoch 223/300, Val Acc=0.7310, Val Loss=1.3947, lr=0.0010
[2025-05-06 20:29:16,427][train][INFO] - Epoch 4/1000, Val Acc=0.1948, Val Loss=3.0851, lr=0.0100
[2025-05-06 20:29:20,408][train][INFO] - Epoch 4/1000, Val Acc=0.2114, Val Loss=3.0320, lr=0.0100
[2025-05-06 20:29:22,584][train][INFO] - Epoch 224/300, Val Acc=0.7319, Val Loss=1.3894, lr=0.0010
[2025-05-06 20:29:24,043][train][INFO] - Epoch 5/1000, Val Acc=0.2555, Val Loss=3.0180, lr=0.0100
[2025-05-06 20:29:28,107][train][INFO] - Epoch 5/1000, Val Acc=0.2427, Val Loss=2.9453, lr=0.0100
[2025-05-06 20:29:29,870][train][INFO] - Epoch 225/300, Val Acc=0.7304, Val Loss=1.3989, lr=0.0010
[2025-05-06 20:29:31,368][train][INFO] - Epoch 6/1000, Val Acc=0.3487, Val Loss=2.4645, lr=0.0100
[2025-05-06 20:29:35,708][train][INFO] - Epoch 6/1000, Val Acc=0.2416, Val Loss=2.9458, lr=0.0100
[2025-05-06 20:29:37,280][train][INFO] - Epoch 226/300, Val Acc=0.7329, Val Loss=1.3888, lr=0.0010
[2025-05-06 20:29:38,895][train][INFO] - Epoch 7/1000, Val Acc=0.3783, Val Loss=2.2895, lr=0.0100
[2025-05-06 20:29:43,181][train][INFO] - Epoch 7/1000, Val Acc=0.2974, Val Loss=2.8628, lr=0.0100
[2025-05-06 20:29:44,718][train][INFO] - Epoch 227/300, Val Acc=0.7308, Val Loss=1.3970, lr=0.0010
[2025-05-06 20:29:46,182][train][INFO] - Epoch 8/1000, Val Acc=0.4061, Val Loss=2.2777, lr=0.0100
[2025-05-06 20:29:50,563][train][INFO] - Epoch 8/1000, Val Acc=0.3250, Val Loss=2.6406, lr=0.0100
[2025-05-06 20:29:52,453][train][INFO] - Epoch 228/300, Val Acc=0.7273, Val Loss=1.3966, lr=0.0010
[2025-05-06 20:29:53,470][train][INFO] - Epoch 9/1000, Val Acc=0.4010, Val Loss=2.3423, lr=0.0100
[2025-05-06 20:29:57,631][train][INFO] - Epoch 9/1000, Val Acc=0.3207, Val Loss=2.6397, lr=0.0100
[2025-05-06 20:30:00,026][train][INFO] - Epoch 229/300, Val Acc=0.7293, Val Loss=1.3998, lr=0.0010
[2025-05-06 20:30:01,268][train][INFO] - Epoch 10/1000, Val Acc=0.4514, Val Loss=2.0412, lr=0.0100
[2025-05-06 20:30:04,910][train][INFO] - Epoch 10/1000, Val Acc=0.3509, Val Loss=2.4300, lr=0.0100
[2025-05-06 20:30:07,509][train][INFO] - Epoch 230/300, Val Acc=0.7296, Val Loss=1.3990, lr=0.0010
[2025-05-06 20:30:08,990][train][INFO] - Epoch 11/1000, Val Acc=0.5048, Val Loss=1.8166, lr=0.0100
[2025-05-06 20:30:12,361][train][INFO] - Epoch 11/1000, Val Acc=0.4011, Val Loss=2.2054, lr=0.0100
[2025-05-06 20:30:14,890][train][INFO] - Epoch 231/300, Val Acc=0.7305, Val Loss=1.3933, lr=0.0010
[2025-05-06 20:30:16,744][train][INFO] - Epoch 12/1000, Val Acc=0.4850, Val Loss=1.9557, lr=0.0100
[2025-05-06 20:30:19,460][train][INFO] - Epoch 12/1000, Val Acc=0.4183, Val Loss=2.1640, lr=0.0100
[2025-05-06 20:30:22,370][train][INFO] - Epoch 232/300, Val Acc=0.7300, Val Loss=1.3963, lr=0.0010
[2025-05-06 20:30:24,464][train][INFO] - Epoch 13/1000, Val Acc=0.4410, Val Loss=2.2209, lr=0.0100
[2025-05-06 20:30:26,937][train][INFO] - Epoch 13/1000, Val Acc=0.4435, Val Loss=2.0170, lr=0.0100
[2025-05-06 20:30:29,657][train][INFO] - Epoch 233/300, Val Acc=0.7308, Val Loss=1.4026, lr=0.0010
[2025-05-06 20:30:31,855][train][INFO] - Epoch 14/1000, Val Acc=0.4867, Val Loss=1.9895, lr=0.0100
[2025-05-06 20:30:34,370][train][INFO] - Epoch 14/1000, Val Acc=0.4405, Val Loss=2.0874, lr=0.0100
[2025-05-06 20:30:36,772][train][INFO] - Epoch 234/300, Val Acc=0.7330, Val Loss=1.3959, lr=0.0010
[2025-05-06 20:30:39,323][train][INFO] - Epoch 15/1000, Val Acc=0.5212, Val Loss=1.8461, lr=0.0100
[2025-05-06 20:30:41,900][train][INFO] - Epoch 15/1000, Val Acc=0.4195, Val Loss=2.2101, lr=0.0100
[2025-05-06 20:30:44,162][train][INFO] - Epoch 235/300, Val Acc=0.7327, Val Loss=1.3972, lr=0.0010
[2025-05-06 20:30:47,000][train][INFO] - Epoch 16/1000, Val Acc=0.5462, Val Loss=1.6684, lr=0.0100
[2025-05-06 20:30:49,847][train][INFO] - Epoch 16/1000, Val Acc=0.4628, Val Loss=1.9817, lr=0.0100
[2025-05-06 20:30:51,673][train][INFO] - Epoch 236/300, Val Acc=0.7317, Val Loss=1.3984, lr=0.0010
[2025-05-06 20:30:54,690][train][INFO] - Epoch 17/1000, Val Acc=0.5245, Val Loss=1.8001, lr=0.0100
[2025-05-06 20:30:57,144][train][INFO] - Epoch 17/1000, Val Acc=0.4801, Val Loss=1.8794, lr=0.0100
[2025-05-06 20:30:59,073][train][INFO] - Epoch 237/300, Val Acc=0.7328, Val Loss=1.4014, lr=0.0010
[2025-05-06 20:31:02,235][train][INFO] - Epoch 18/1000, Val Acc=0.5309, Val Loss=1.8349, lr=0.0100
[2025-05-06 20:31:04,388][train][INFO] - Epoch 18/1000, Val Acc=0.4345, Val Loss=2.1876, lr=0.0100
[2025-05-06 20:31:06,231][train][INFO] - Epoch 238/300, Val Acc=0.7295, Val Loss=1.3970, lr=0.0010
[2025-05-06 20:31:10,089][train][INFO] - Epoch 19/1000, Val Acc=0.5541, Val Loss=1.6883, lr=0.0100
[2025-05-06 20:31:11,875][train][INFO] - Epoch 19/1000, Val Acc=0.4943, Val Loss=1.8217, lr=0.0100
[2025-05-06 20:31:13,705][train][INFO] - Epoch 239/300, Val Acc=0.7298, Val Loss=1.3984, lr=0.0010
[2025-05-06 20:31:17,817][train][INFO] - Epoch 20/1000, Val Acc=0.5786, Val Loss=1.6245, lr=0.0100
[2025-05-06 20:31:18,911][train][INFO] - Epoch 20/1000, Val Acc=0.4860, Val Loss=1.8589, lr=0.0100
[2025-05-06 20:31:20,813][train][INFO] - Epoch 240/300, Val Acc=0.7289, Val Loss=1.3987, lr=0.0010
[2025-05-06 20:31:25,139][train][INFO] - Epoch 21/1000, Val Acc=0.5292, Val Loss=1.8784, lr=0.0100
[2025-05-06 20:31:26,260][train][INFO] - Epoch 21/1000, Val Acc=0.4424, Val Loss=2.1362, lr=0.0100
[2025-05-06 20:31:27,687][train][INFO] - Epoch 241/300, Val Acc=0.7314, Val Loss=1.3991, lr=0.0010
[2025-05-06 20:31:32,627][train][INFO] - Epoch 22/1000, Val Acc=0.5382, Val Loss=1.8203, lr=0.0100
[2025-05-06 20:31:34,106][train][INFO] - Epoch 22/1000, Val Acc=0.4686, Val Loss=2.0200, lr=0.0100
[2025-05-06 20:31:34,534][train][INFO] - Epoch 242/300, Val Acc=0.7296, Val Loss=1.4024, lr=0.0010
[2025-05-06 20:31:40,610][train][INFO] - Epoch 23/1000, Val Acc=0.5682, Val Loss=1.7212, lr=0.0100
[2025-05-06 20:31:41,157][train][INFO] - Epoch 23/1000, Val Acc=0.5070, Val Loss=1.7903, lr=0.0100
[2025-05-06 20:31:42,172][train][INFO] - Epoch 243/300, Val Acc=0.7283, Val Loss=1.4042, lr=0.0010
[2025-05-06 20:31:48,165][train][INFO] - Epoch 24/1000, Val Acc=0.5739, Val Loss=1.6791, lr=0.0100
[2025-05-06 20:31:49,167][train][INFO] - Epoch 24/1000, Val Acc=0.5075, Val Loss=1.8016, lr=0.0100
[2025-05-06 20:31:49,175][train][INFO] - Epoch 244/300, Val Acc=0.7313, Val Loss=1.3956, lr=0.0010
[2025-05-06 20:31:55,345][train][INFO] - Epoch 25/1000, Val Acc=0.5900, Val Loss=1.5826, lr=0.0100
[2025-05-06 20:31:56,413][train][INFO] - Epoch 25/1000, Val Acc=0.5087, Val Loss=1.8099, lr=0.0100
[2025-05-06 20:31:56,837][train][INFO] - Epoch 245/300, Val Acc=0.7309, Val Loss=1.4014, lr=0.0010
[2025-05-06 20:32:02,547][train][INFO] - Epoch 26/1000, Val Acc=0.5526, Val Loss=1.8464, lr=0.0100
[2025-05-06 20:32:03,842][train][INFO] - Epoch 246/300, Val Acc=0.7303, Val Loss=1.3960, lr=0.0010
[2025-05-06 20:32:03,883][train][INFO] - Epoch 26/1000, Val Acc=0.4809, Val Loss=1.9551, lr=0.0100
[2025-05-06 20:32:10,060][train][INFO] - Epoch 27/1000, Val Acc=0.6022, Val Loss=1.5530, lr=0.0100
[2025-05-06 20:32:11,310][train][INFO] - Epoch 247/300, Val Acc=0.7316, Val Loss=1.3996, lr=0.0010
[2025-05-06 20:32:11,632][train][INFO] - Epoch 27/1000, Val Acc=0.4908, Val Loss=1.8938, lr=0.0100
[2025-05-06 20:32:17,229][train][INFO] - Epoch 28/1000, Val Acc=0.5802, Val Loss=1.6209, lr=0.0100
[2025-05-06 20:32:18,893][train][INFO] - Epoch 248/300, Val Acc=0.7312, Val Loss=1.3959, lr=0.0010
[2025-05-06 20:32:19,535][train][INFO] - Epoch 28/1000, Val Acc=0.4820, Val Loss=1.9695, lr=0.0100
[2025-05-06 20:32:24,999][train][INFO] - Epoch 29/1000, Val Acc=0.5965, Val Loss=1.6158, lr=0.0100
[2025-05-06 20:32:26,452][train][INFO] - Epoch 249/300, Val Acc=0.7316, Val Loss=1.4010, lr=0.0010
[2025-05-06 20:32:27,314][train][INFO] - Epoch 29/1000, Val Acc=0.5256, Val Loss=1.7564, lr=0.0100
[2025-05-06 20:32:32,686][train][INFO] - Epoch 30/1000, Val Acc=0.6045, Val Loss=1.5908, lr=0.0100
[2025-05-06 20:32:33,691][train][INFO] - Epoch 250/300, Val Acc=0.7324, Val Loss=1.4024, lr=0.0010
[2025-05-06 20:32:34,978][train][INFO] - Epoch 30/1000, Val Acc=0.5313, Val Loss=1.7132, lr=0.0100
[2025-05-06 20:32:39,832][train][INFO] - Epoch 31/1000, Val Acc=0.6015, Val Loss=1.6014, lr=0.0100
[2025-05-06 20:32:41,122][train][INFO] - Epoch 251/300, Val Acc=0.7328, Val Loss=1.4021, lr=0.0001
[2025-05-06 20:32:42,409][train][INFO] - Epoch 31/1000, Val Acc=0.5290, Val Loss=1.7829, lr=0.0100
[2025-05-06 20:32:47,493][train][INFO] - Epoch 32/1000, Val Acc=0.5894, Val Loss=1.6960, lr=0.0100
[2025-05-06 20:32:48,574][train][INFO] - Epoch 252/300, Val Acc=0.7331, Val Loss=1.4019, lr=0.0001
[2025-05-06 20:32:50,449][train][INFO] - Epoch 32/1000, Val Acc=0.5317, Val Loss=1.7320, lr=0.0100
[2025-05-06 20:32:55,216][train][INFO] - Epoch 33/1000, Val Acc=0.5832, Val Loss=1.6813, lr=0.0100
[2025-05-06 20:32:56,188][train][INFO] - Epoch 253/300, Val Acc=0.7315, Val Loss=1.4025, lr=0.0001
[2025-05-06 20:32:58,040][train][INFO] - Epoch 33/1000, Val Acc=0.5049, Val Loss=1.9286, lr=0.0100
[2025-05-06 20:33:03,270][train][INFO] - Epoch 34/1000, Val Acc=0.6108, Val Loss=1.5890, lr=0.0100
[2025-05-06 20:33:03,721][train][INFO] - Epoch 254/300, Val Acc=0.7328, Val Loss=1.3967, lr=0.0001
[2025-05-06 20:33:05,794][train][INFO] - Epoch 34/1000, Val Acc=0.4972, Val Loss=1.9323, lr=0.0100
[2025-05-06 20:33:10,972][train][INFO] - Epoch 35/1000, Val Acc=0.5902, Val Loss=1.6914, lr=0.0100
[2025-05-06 20:33:11,202][train][INFO] - Epoch 255/300, Val Acc=0.7325, Val Loss=1.3981, lr=0.0001
[2025-05-06 20:33:13,541][train][INFO] - Epoch 35/1000, Val Acc=0.5299, Val Loss=1.7207, lr=0.0100
[2025-05-06 20:33:18,725][train][INFO] - Epoch 256/300, Val Acc=0.7330, Val Loss=1.3970, lr=0.0001
[2025-05-06 20:33:18,967][train][INFO] - Epoch 36/1000, Val Acc=0.5950, Val Loss=1.6372, lr=0.0100
[2025-05-06 20:33:20,797][train][INFO] - Epoch 36/1000, Val Acc=0.5112, Val Loss=1.8713, lr=0.0100
[2025-05-06 20:33:25,790][train][INFO] - Epoch 37/1000, Val Acc=0.5957, Val Loss=1.6907, lr=0.0100
[2025-05-06 20:33:26,599][train][INFO] - Epoch 257/300, Val Acc=0.7327, Val Loss=1.3960, lr=0.0001
[2025-05-06 20:33:28,625][train][INFO] - Epoch 37/1000, Val Acc=0.5491, Val Loss=1.6927, lr=0.0100
[2025-05-06 20:33:33,321][train][INFO] - Epoch 38/1000, Val Acc=0.5994, Val Loss=1.6521, lr=0.0100
[2025-05-06 20:33:34,016][train][INFO] - Epoch 258/300, Val Acc=0.7318, Val Loss=1.3959, lr=0.0001
[2025-05-06 20:33:36,215][train][INFO] - Epoch 38/1000, Val Acc=0.5422, Val Loss=1.6943, lr=0.0100
[2025-05-06 20:33:40,902][train][INFO] - Epoch 39/1000, Val Acc=0.6045, Val Loss=1.6506, lr=0.0100
[2025-05-06 20:33:41,508][train][INFO] - Epoch 259/300, Val Acc=0.7325, Val Loss=1.3995, lr=0.0001
[2025-05-06 20:33:43,534][train][INFO] - Epoch 39/1000, Val Acc=0.5596, Val Loss=1.6220, lr=0.0100
[2025-05-06 20:33:48,600][train][INFO] - Epoch 40/1000, Val Acc=0.5957, Val Loss=1.6921, lr=0.0100
[2025-05-06 20:33:49,219][train][INFO] - Epoch 260/300, Val Acc=0.7339, Val Loss=1.3946, lr=0.0001
[2025-05-06 20:33:51,128][train][INFO] - Epoch 40/1000, Val Acc=0.5390, Val Loss=1.7392, lr=0.0100
[2025-05-06 20:33:56,130][train][INFO] - Epoch 41/1000, Val Acc=0.6126, Val Loss=1.6022, lr=0.0100
[2025-05-06 20:33:56,723][train][INFO] - Epoch 261/300, Val Acc=0.7328, Val Loss=1.3962, lr=0.0001
[2025-05-06 20:33:58,392][train][INFO] - Epoch 41/1000, Val Acc=0.5231, Val Loss=1.8813, lr=0.0100
[2025-05-06 20:34:03,797][train][INFO] - Epoch 42/1000, Val Acc=0.6008, Val Loss=1.7293, lr=0.0100
[2025-05-06 20:34:04,040][train][INFO] - Epoch 262/300, Val Acc=0.7335, Val Loss=1.3998, lr=0.0001
[2025-05-06 20:34:05,780][train][INFO] - Epoch 42/1000, Val Acc=0.5333, Val Loss=1.7644, lr=0.0100
[2025-05-06 20:34:11,327][train][INFO] - Epoch 263/300, Val Acc=0.7326, Val Loss=1.3985, lr=0.0001
[2025-05-06 20:34:11,678][train][INFO] - Epoch 43/1000, Val Acc=0.6106, Val Loss=1.6888, lr=0.0100
[2025-05-06 20:34:13,351][train][INFO] - Epoch 43/1000, Val Acc=0.5573, Val Loss=1.6679, lr=0.0100
[2025-05-06 20:34:18,391][train][INFO] - Epoch 264/300, Val Acc=0.7342, Val Loss=1.3992, lr=0.0001
[2025-05-06 20:34:19,392][train][INFO] - Epoch 44/1000, Val Acc=0.6022, Val Loss=1.6992, lr=0.0100
[2025-05-06 20:34:20,358][train][INFO] - Epoch 44/1000, Val Acc=0.5433, Val Loss=1.7712, lr=0.0100
[2025-05-06 20:34:25,845][train][INFO] - Epoch 265/300, Val Acc=0.7335, Val Loss=1.3920, lr=0.0001
[2025-05-06 20:34:27,239][train][INFO] - Epoch 45/1000, Val Acc=0.6069, Val Loss=1.6741, lr=0.0100
[2025-05-06 20:34:27,612][train][INFO] - Epoch 45/1000, Val Acc=0.5575, Val Loss=1.6770, lr=0.0100
[2025-05-06 20:34:32,935][train][INFO] - Epoch 266/300, Val Acc=0.7329, Val Loss=1.3948, lr=0.0001
[2025-05-06 20:34:34,839][train][INFO] - Epoch 46/1000, Val Acc=0.6077, Val Loss=1.6555, lr=0.0100
[2025-05-06 20:34:35,180][train][INFO] - Epoch 46/1000, Val Acc=0.5451, Val Loss=1.7361, lr=0.0100
[2025-05-06 20:34:40,358][train][INFO] - Epoch 267/300, Val Acc=0.7336, Val Loss=1.3920, lr=0.0001
[2025-05-06 20:34:42,109][train][INFO] - Epoch 47/1000, Val Acc=0.5551, Val Loss=1.7168, lr=0.0100
[2025-05-06 20:34:42,588][train][INFO] - Epoch 47/1000, Val Acc=0.5942, Val Loss=1.7828, lr=0.0100
[2025-05-06 20:34:48,144][train][INFO] - Epoch 268/300, Val Acc=0.7323, Val Loss=1.3986, lr=0.0001
[2025-05-06 20:34:49,644][train][INFO] - Epoch 48/1000, Val Acc=0.5555, Val Loss=1.7282, lr=0.0100
[2025-05-06 20:34:50,202][train][INFO] - Epoch 48/1000, Val Acc=0.6006, Val Loss=1.7140, lr=0.0100
[2025-05-06 20:34:54,949][train][INFO] - Epoch 269/300, Val Acc=0.7320, Val Loss=1.3966, lr=0.0001
[2025-05-06 20:34:57,565][train][INFO] - Epoch 49/1000, Val Acc=0.5588, Val Loss=1.6738, lr=0.0100
[2025-05-06 20:34:57,957][train][INFO] - Epoch 49/1000, Val Acc=0.6161, Val Loss=1.6509, lr=0.0100
[2025-05-06 20:35:02,422][train][INFO] - Epoch 270/300, Val Acc=0.7320, Val Loss=1.3902, lr=0.0001
[2025-05-06 20:35:05,035][train][INFO] - Epoch 50/1000, Val Acc=0.5569, Val Loss=1.7256, lr=0.0100
[2025-05-06 20:35:05,609][train][INFO] - Epoch 50/1000, Val Acc=0.6044, Val Loss=1.7283, lr=0.0100
[2025-05-06 20:35:09,687][train][INFO] - Epoch 271/300, Val Acc=0.7326, Val Loss=1.3971, lr=0.0001
[2025-05-06 20:35:12,370][train][INFO] - Epoch 51/1000, Val Acc=0.5711, Val Loss=1.6467, lr=0.0100
[2025-05-06 20:35:13,068][train][INFO] - Epoch 51/1000, Val Acc=0.6041, Val Loss=1.7113, lr=0.0100
[2025-05-06 20:35:17,279][train][INFO] - Epoch 272/300, Val Acc=0.7329, Val Loss=1.3963, lr=0.0001
[2025-05-06 20:35:19,685][train][INFO] - Epoch 52/1000, Val Acc=0.5407, Val Loss=1.8245, lr=0.0100
[2025-05-06 20:35:20,366][train][INFO] - Epoch 52/1000, Val Acc=0.6287, Val Loss=1.5932, lr=0.0100
[2025-05-06 20:35:24,459][train][INFO] - Epoch 273/300, Val Acc=0.7327, Val Loss=1.3962, lr=0.0001
[2025-05-06 20:35:27,538][train][INFO] - Epoch 53/1000, Val Acc=0.5788, Val Loss=1.6307, lr=0.0100
[2025-05-06 20:35:28,237][train][INFO] - Epoch 53/1000, Val Acc=0.6217, Val Loss=1.6603, lr=0.0100
[2025-05-06 20:35:31,751][train][INFO] - Epoch 274/300, Val Acc=0.7340, Val Loss=1.3968, lr=0.0001
[2025-05-06 20:35:35,266][train][INFO] - Epoch 54/1000, Val Acc=0.5520, Val Loss=1.7428, lr=0.0100
[2025-05-06 20:35:36,191][train][INFO] - Epoch 54/1000, Val Acc=0.6270, Val Loss=1.5705, lr=0.0100
[2025-05-06 20:35:39,290][train][INFO] - Epoch 275/300, Val Acc=0.7338, Val Loss=1.3909, lr=0.0001
[2025-05-06 20:35:42,595][train][INFO] - Epoch 55/1000, Val Acc=0.5525, Val Loss=1.7450, lr=0.0100
[2025-05-06 20:35:43,880][train][INFO] - Epoch 55/1000, Val Acc=0.6294, Val Loss=1.5980, lr=0.0100
[2025-05-06 20:35:46,319][train][INFO] - Epoch 276/300, Val Acc=0.7328, Val Loss=1.3925, lr=0.0001
[2025-05-06 20:35:49,940][train][INFO] - Epoch 56/1000, Val Acc=0.5839, Val Loss=1.6067, lr=0.0100
[2025-05-06 20:35:51,730][train][INFO] - Epoch 56/1000, Val Acc=0.6263, Val Loss=1.6246, lr=0.0100
[2025-05-06 20:35:53,934][train][INFO] - Epoch 277/300, Val Acc=0.7322, Val Loss=1.3985, lr=0.0001
[2025-05-06 20:35:57,625][train][INFO] - Epoch 57/1000, Val Acc=0.5611, Val Loss=1.7065, lr=0.0100
[2025-05-06 20:35:58,858][train][INFO] - Epoch 57/1000, Val Acc=0.6276, Val Loss=1.6091, lr=0.0100
[2025-05-06 20:36:01,472][train][INFO] - Epoch 278/300, Val Acc=0.7329, Val Loss=1.3932, lr=0.0001
[2025-05-06 20:36:05,380][train][INFO] - Epoch 58/1000, Val Acc=0.5690, Val Loss=1.6520, lr=0.0100
[2025-05-06 20:36:06,354][train][INFO] - Epoch 58/1000, Val Acc=0.6157, Val Loss=1.6608, lr=0.0100
[2025-05-06 20:36:08,687][train][INFO] - Epoch 279/300, Val Acc=0.7331, Val Loss=1.3944, lr=0.0001
[2025-05-06 20:36:12,736][train][INFO] - Epoch 59/1000, Val Acc=0.5442, Val Loss=1.7990, lr=0.0100
[2025-05-06 20:36:14,026][train][INFO] - Epoch 59/1000, Val Acc=0.6123, Val Loss=1.6716, lr=0.0100
[2025-05-06 20:36:15,658][train][INFO] - Epoch 280/300, Val Acc=0.7340, Val Loss=1.3956, lr=0.0001
[2025-05-06 20:36:20,409][train][INFO] - Epoch 60/1000, Val Acc=0.5901, Val Loss=1.5750, lr=0.0100
[2025-05-06 20:36:21,644][train][INFO] - Epoch 60/1000, Val Acc=0.6115, Val Loss=1.7082, lr=0.0100
[2025-05-06 20:36:23,091][train][INFO] - Epoch 281/300, Val Acc=0.7328, Val Loss=1.3966, lr=0.0001
[2025-05-06 20:36:27,172][train][INFO] - Epoch 61/1000, Val Acc=0.5577, Val Loss=1.7228, lr=0.0100
[2025-05-06 20:36:29,610][train][INFO] - Epoch 61/1000, Val Acc=0.6108, Val Loss=1.7583, lr=0.0100
[2025-05-06 20:36:30,502][train][INFO] - Epoch 282/300, Val Acc=0.7329, Val Loss=1.3915, lr=0.0001
[2025-05-06 20:36:34,648][train][INFO] - Epoch 62/1000, Val Acc=0.5877, Val Loss=1.6130, lr=0.0100
[2025-05-06 20:36:36,800][train][INFO] - Epoch 62/1000, Val Acc=0.6356, Val Loss=1.6124, lr=0.0100
[2025-05-06 20:36:37,856][train][INFO] - Epoch 283/300, Val Acc=0.7349, Val Loss=1.3959, lr=0.0001
[2025-05-06 20:36:42,172][train][INFO] - Epoch 63/1000, Val Acc=0.5485, Val Loss=1.8167, lr=0.0100
[2025-05-06 20:36:44,508][train][INFO] - Epoch 63/1000, Val Acc=0.6120, Val Loss=1.7385, lr=0.0100
[2025-05-06 20:36:45,244][train][INFO] - Epoch 284/300, Val Acc=0.7346, Val Loss=1.3965, lr=0.0001
[2025-05-06 20:36:49,660][train][INFO] - Epoch 64/1000, Val Acc=0.5739, Val Loss=1.6722, lr=0.0100
[2025-05-06 20:36:52,349][train][INFO] - Epoch 64/1000, Val Acc=0.6238, Val Loss=1.6561, lr=0.0100
[2025-05-06 20:36:52,718][train][INFO] - Epoch 285/300, Val Acc=0.7338, Val Loss=1.3923, lr=0.0001
[2025-05-06 20:36:56,963][train][INFO] - Epoch 65/1000, Val Acc=0.5870, Val Loss=1.5967, lr=0.0100
[2025-05-06 20:37:00,136][train][INFO] - Epoch 65/1000, Val Acc=0.6161, Val Loss=1.6728, lr=0.0100
[2025-05-06 20:37:00,264][train][INFO] - Epoch 286/300, Val Acc=0.7339, Val Loss=1.3929, lr=0.0001
[2025-05-06 20:37:04,675][train][INFO] - Epoch 66/1000, Val Acc=0.5751, Val Loss=1.6556, lr=0.0100
[2025-05-06 20:37:07,548][train][INFO] - Epoch 287/300, Val Acc=0.7329, Val Loss=1.3948, lr=0.0001
[2025-05-06 20:37:08,022][train][INFO] - Epoch 66/1000, Val Acc=0.6154, Val Loss=1.7134, lr=0.0100
[2025-05-06 20:37:12,308][train][INFO] - Epoch 67/1000, Val Acc=0.5798, Val Loss=1.6135, lr=0.0100
[2025-05-06 20:37:15,139][train][INFO] - Epoch 288/300, Val Acc=0.7341, Val Loss=1.3931, lr=0.0001
[2025-05-06 20:37:15,576][train][INFO] - Epoch 67/1000, Val Acc=0.6130, Val Loss=1.7646, lr=0.0100
[2025-05-06 20:37:19,193][train][INFO] - Epoch 68/1000, Val Acc=0.5718, Val Loss=1.6964, lr=0.0100
[2025-05-06 20:37:22,634][train][INFO] - Epoch 289/300, Val Acc=0.7347, Val Loss=1.3878, lr=0.0001
[2025-05-06 20:37:23,127][train][INFO] - Epoch 68/1000, Val Acc=0.6207, Val Loss=1.6768, lr=0.0100
[2025-05-06 20:37:26,846][train][INFO] - Epoch 69/1000, Val Acc=0.5786, Val Loss=1.6676, lr=0.0100
[2025-05-06 20:37:30,086][train][INFO] - Epoch 69/1000, Val Acc=0.6240, Val Loss=1.6447, lr=0.0100
[2025-05-06 20:37:30,404][train][INFO] - Epoch 290/300, Val Acc=0.7328, Val Loss=1.3975, lr=0.0001
[2025-05-06 20:37:34,865][train][INFO] - Epoch 70/1000, Val Acc=0.5752, Val Loss=1.6897, lr=0.0100
[2025-05-06 20:37:37,438][train][INFO] - Epoch 291/300, Val Acc=0.7346, Val Loss=1.3941, lr=0.0001
[2025-05-06 20:37:37,582][train][INFO] - Epoch 70/1000, Val Acc=0.6266, Val Loss=1.6447, lr=0.0100
[2025-05-06 20:37:42,272][train][INFO] - Epoch 71/1000, Val Acc=0.5885, Val Loss=1.6308, lr=0.0100
[2025-05-06 20:37:44,761][train][INFO] - Epoch 292/300, Val Acc=0.7327, Val Loss=1.3937, lr=0.0001
[2025-05-06 20:37:45,445][train][INFO] - Epoch 71/1000, Val Acc=0.6222, Val Loss=1.6697, lr=0.0100
[2025-05-06 20:37:49,523][train][INFO] - Epoch 72/1000, Val Acc=0.5704, Val Loss=1.6931, lr=0.0100
[2025-05-06 20:37:52,627][train][INFO] - Epoch 293/300, Val Acc=0.7338, Val Loss=1.3982, lr=0.0001
[2025-05-06 20:37:53,128][train][INFO] - Epoch 72/1000, Val Acc=0.6120, Val Loss=1.7344, lr=0.0100
[2025-05-06 20:37:56,966][train][INFO] - Epoch 73/1000, Val Acc=0.5892, Val Loss=1.6220, lr=0.0100
[2025-05-06 20:37:59,810][train][INFO] - Epoch 294/300, Val Acc=0.7312, Val Loss=1.3988, lr=0.0001
[2025-05-06 20:38:01,094][train][INFO] - Epoch 73/1000, Val Acc=0.6172, Val Loss=1.7438, lr=0.0100
[2025-05-06 20:38:04,992][train][INFO] - Epoch 74/1000, Val Acc=0.5923, Val Loss=1.6255, lr=0.0100
[2025-05-06 20:38:07,438][train][INFO] - Epoch 295/300, Val Acc=0.7345, Val Loss=1.3925, lr=0.0001
[2025-05-06 20:38:08,549][train][INFO] - Epoch 74/1000, Val Acc=0.6213, Val Loss=1.7418, lr=0.0100
[2025-05-06 20:38:12,465][train][INFO] - Epoch 75/1000, Val Acc=0.5769, Val Loss=1.6795, lr=0.0100
[2025-05-06 20:38:14,977][train][INFO] - Epoch 296/300, Val Acc=0.7316, Val Loss=1.3953, lr=0.0001
[2025-05-06 20:38:16,662][train][INFO] - Epoch 75/1000, Val Acc=0.6213, Val Loss=1.6760, lr=0.0100
[2025-05-06 20:38:19,745][train][INFO] - Epoch 76/1000, Val Acc=0.5727, Val Loss=1.7565, lr=0.0100
[2025-05-06 20:38:22,529][train][INFO] - Epoch 297/300, Val Acc=0.7336, Val Loss=1.3943, lr=0.0001
[2025-05-06 20:38:24,437][train][INFO] - Epoch 76/1000, Val Acc=0.6193, Val Loss=1.7378, lr=0.0100
[2025-05-06 20:38:27,680][train][INFO] - Epoch 77/1000, Val Acc=0.5796, Val Loss=1.6820, lr=0.0100
[2025-05-06 20:38:29,814][train][INFO] - Epoch 298/300, Val Acc=0.7332, Val Loss=1.3945, lr=0.0001
[2025-05-06 20:38:31,705][train][INFO] - Epoch 77/1000, Val Acc=0.6214, Val Loss=1.7219, lr=0.0100
[2025-05-06 20:38:35,321][train][INFO] - Epoch 78/1000, Val Acc=0.5726, Val Loss=1.7394, lr=0.0100
[2025-05-06 20:38:37,529][train][INFO] - Epoch 299/300, Val Acc=0.7326, Val Loss=1.3958, lr=0.0001
[2025-05-06 20:38:39,684][train][INFO] - Epoch 78/1000, Val Acc=0.6123, Val Loss=1.7881, lr=0.0100
[2025-05-06 20:38:42,732][train][INFO] - Epoch 79/1000, Val Acc=0.5754, Val Loss=1.7508, lr=0.0100
[2025-05-06 20:38:45,046][train][INFO] - Epoch 300/300, Val Acc=0.7344, Val Loss=1.3979, lr=0.0001
[2025-05-06 20:38:47,159][train][INFO] - Epoch 79/1000, Val Acc=0.6211, Val Loss=1.7528, lr=0.0100
[2025-05-06 20:38:49,953][train][INFO] - After training : Train Acc=0.9998  Val Acc=0.7349
[2025-05-06 20:38:49,958][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 20:38:50,229][train][INFO] - Epoch 80/1000, Val Acc=0.5858, Val Loss=1.6833, lr=0.0100
[2025-05-06 20:38:54,979][train][INFO] - Epoch 80/1000, Val Acc=0.6205, Val Loss=1.7111, lr=0.0100
[2025-05-06 20:38:58,222][train][INFO] - Epoch 81/1000, Val Acc=0.5778, Val Loss=1.7087, lr=0.0100
[2025-05-06 20:39:02,813][train][INFO] - Epoch 81/1000, Val Acc=0.6105, Val Loss=1.7924, lr=0.0100
[2025-05-06 20:39:05,753][train][INFO] - Epoch 82/1000, Val Acc=0.5472, Val Loss=1.9512, lr=0.0100
[2025-05-06 20:39:10,704][train][INFO] - Epoch 82/1000, Val Acc=0.6186, Val Loss=1.7614, lr=0.0100
[2025-05-06 20:39:13,357][train][INFO] - Epoch 83/1000, Val Acc=0.5996, Val Loss=1.6041, lr=0.0100
[2025-05-06 20:39:18,404][train][INFO] - Epoch 83/1000, Val Acc=0.6028, Val Loss=1.8526, lr=0.0100
[2025-05-06 20:39:20,881][train][INFO] - Epoch 84/1000, Val Acc=0.5786, Val Loss=1.7234, lr=0.0100
[2025-05-06 20:39:25,928][train][INFO] - Epoch 84/1000, Val Acc=0.6237, Val Loss=1.6995, lr=0.0100
[2025-05-06 20:39:28,452][train][INFO] - Epoch 85/1000, Val Acc=0.5763, Val Loss=1.7184, lr=0.0100
[2025-05-06 20:39:33,777][train][INFO] - Epoch 85/1000, Val Acc=0.6105, Val Loss=1.8146, lr=0.0100
[2025-05-06 20:39:35,617][train][INFO] - Epoch 86/1000, Val Acc=0.5939, Val Loss=1.6662, lr=0.0100
[2025-05-06 20:39:41,507][train][INFO] - Epoch 86/1000, Val Acc=0.6261, Val Loss=1.7051, lr=0.0100
[2025-05-06 20:39:42,939][train][INFO] - Epoch 87/1000, Val Acc=0.5787, Val Loss=1.7136, lr=0.0100
[2025-05-06 20:39:49,321][train][INFO] - Epoch 87/1000, Val Acc=0.6282, Val Loss=1.6647, lr=0.0100
[2025-05-06 20:39:50,691][train][INFO] - Epoch 88/1000, Val Acc=0.5769, Val Loss=1.7157, lr=0.0100
[2025-05-06 20:39:57,152][train][INFO] - Epoch 88/1000, Val Acc=0.6211, Val Loss=1.7572, lr=0.0100
[2025-05-06 20:39:58,428][train][INFO] - Epoch 89/1000, Val Acc=0.5749, Val Loss=1.7565, lr=0.0100
[2025-05-06 20:40:04,835][train][INFO] - Epoch 89/1000, Val Acc=0.6376, Val Loss=1.6533, lr=0.0100
[2025-05-06 20:40:06,226][train][INFO] - Epoch 90/1000, Val Acc=0.5865, Val Loss=1.6815, lr=0.0100
[2025-05-06 20:40:12,182][train][INFO] - Epoch 90/1000, Val Acc=0.6317, Val Loss=1.6938, lr=0.0100
[2025-05-06 20:40:14,092][train][INFO] - Epoch 91/1000, Val Acc=0.5897, Val Loss=1.6865, lr=0.0100
[2025-05-06 20:40:19,776][train][INFO] - Epoch 91/1000, Val Acc=0.6231, Val Loss=1.6967, lr=0.0100
[2025-05-06 20:40:21,645][train][INFO] - Epoch 92/1000, Val Acc=0.5926, Val Loss=1.6540, lr=0.0100
[2025-05-06 20:40:22,001][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 20:40:27,291][train][INFO] - Epoch 92/1000, Val Acc=0.6363, Val Loss=1.6961, lr=0.0100
[2025-05-06 20:40:29,294][train][INFO] - Epoch 93/1000, Val Acc=0.5905, Val Loss=1.6276, lr=0.0100
[2025-05-06 20:40:35,046][train][INFO] - Epoch 93/1000, Val Acc=0.6330, Val Loss=1.7043, lr=0.0100
[2025-05-06 20:40:36,686][train][INFO] - Epoch 94/1000, Val Acc=0.5911, Val Loss=1.6885, lr=0.0100
[2025-05-06 20:40:42,390][train][INFO] - Epoch 94/1000, Val Acc=0.6306, Val Loss=1.7326, lr=0.0100
[2025-05-06 20:40:44,275][train][INFO] - Epoch 95/1000, Val Acc=0.5733, Val Loss=1.7624, lr=0.0100
[2025-05-06 20:40:50,354][train][INFO] - Epoch 95/1000, Val Acc=0.6395, Val Loss=1.6464, lr=0.0100
[2025-05-06 20:40:51,733][train][INFO] - Epoch 96/1000, Val Acc=0.5849, Val Loss=1.6842, lr=0.0100
[2025-05-06 20:40:58,168][train][INFO] - Epoch 96/1000, Val Acc=0.6144, Val Loss=1.7942, lr=0.0100
[2025-05-06 20:40:59,091][train][INFO] - Epoch 97/1000, Val Acc=0.5983, Val Loss=1.6165, lr=0.0100
[2025-05-06 20:41:05,885][train][INFO] - Epoch 97/1000, Val Acc=0.6261, Val Loss=1.7382, lr=0.0100
[2025-05-06 20:41:06,786][train][INFO] - Epoch 98/1000, Val Acc=0.5917, Val Loss=1.6895, lr=0.0100
[2025-05-06 20:41:13,681][train][INFO] - Epoch 98/1000, Val Acc=0.6141, Val Loss=1.8326, lr=0.0100
[2025-05-06 20:41:14,583][train][INFO] - Epoch 99/1000, Val Acc=0.6116, Val Loss=1.6024, lr=0.0100
[2025-05-06 20:41:21,242][train][INFO] - Epoch 99/1000, Val Acc=0.6307, Val Loss=1.6590, lr=0.0100
[2025-05-06 20:41:22,268][train][INFO] - Epoch 100/1000, Val Acc=0.5900, Val Loss=1.6588, lr=0.0100
[2025-05-06 20:41:28,882][train][INFO] - Epoch 100/1000, Val Acc=0.6414, Val Loss=1.6611, lr=0.0100
[2025-05-06 20:41:29,991][train][INFO] - Epoch 101/1000, Val Acc=0.6082, Val Loss=1.6001, lr=0.0100
[2025-05-06 20:41:36,797][train][INFO] - Epoch 101/1000, Val Acc=0.6433, Val Loss=1.5969, lr=0.0100
[2025-05-06 20:41:37,189][train][INFO] - Epoch 102/1000, Val Acc=0.5969, Val Loss=1.6837, lr=0.0100
[2025-05-06 20:41:44,584][train][INFO] - Epoch 102/1000, Val Acc=0.6269, Val Loss=1.7142, lr=0.0100
[2025-05-06 20:41:45,284][train][INFO] - Epoch 103/1000, Val Acc=0.5938, Val Loss=1.6634, lr=0.0100
[2025-05-06 20:41:52,336][train][INFO] - Epoch 103/1000, Val Acc=0.6085, Val Loss=1.8172, lr=0.0100
[2025-05-06 20:41:52,993][train][INFO] - Epoch 104/1000, Val Acc=0.5689, Val Loss=1.7915, lr=0.0100
[2025-05-06 20:41:59,626][train][INFO] - Epoch 104/1000, Val Acc=0.6282, Val Loss=1.7554, lr=0.0100
[2025-05-06 20:42:00,406][train][INFO] - Epoch 105/1000, Val Acc=0.5702, Val Loss=1.7975, lr=0.0100
[2025-05-06 20:42:07,501][train][INFO] - Epoch 105/1000, Val Acc=0.6377, Val Loss=1.6675, lr=0.0100
[2025-05-06 20:42:08,159][train][INFO] - Epoch 106/1000, Val Acc=0.5950, Val Loss=1.6840, lr=0.0100
[2025-05-06 20:42:15,040][train][INFO] - Epoch 106/1000, Val Acc=0.6491, Val Loss=1.6130, lr=0.0100
[2025-05-06 20:42:15,844][train][INFO] - Epoch 107/1000, Val Acc=0.5843, Val Loss=1.7290, lr=0.0100
[2025-05-06 20:42:22,701][train][INFO] - Epoch 107/1000, Val Acc=0.6457, Val Loss=1.6338, lr=0.0100
[2025-05-06 20:42:23,419][train][INFO] - Epoch 108/1000, Val Acc=0.6140, Val Loss=1.6172, lr=0.0100
[2025-05-06 20:42:29,262][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 20:42:29,784][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 20:42:30,344][train][INFO] - Epoch 108/1000, Val Acc=0.6391, Val Loss=1.6799, lr=0.0100
[2025-05-06 20:42:31,117][train][INFO] - Epoch 109/1000, Val Acc=0.6008, Val Loss=1.6347, lr=0.0100
[2025-05-06 20:42:38,282][train][INFO] - Epoch 109/1000, Val Acc=0.6409, Val Loss=1.6870, lr=0.0100
[2025-05-06 20:42:38,839][train][INFO] - Epoch 110/1000, Val Acc=0.5885, Val Loss=1.7128, lr=0.0100
[2025-05-06 20:42:46,261][train][INFO] - Epoch 110/1000, Val Acc=0.6356, Val Loss=1.7233, lr=0.0100
[2025-05-06 20:42:47,002][train][INFO] - Epoch 111/1000, Val Acc=0.5956, Val Loss=1.6450, lr=0.0100
[2025-05-06 20:42:54,440][train][INFO] - Epoch 111/1000, Val Acc=0.6315, Val Loss=1.7359, lr=0.0100
[2025-05-06 20:42:55,109][train][INFO] - Epoch 112/1000, Val Acc=0.5886, Val Loss=1.7158, lr=0.0100
[2025-05-06 20:43:02,910][train][INFO] - Epoch 112/1000, Val Acc=0.6241, Val Loss=1.7644, lr=0.0100
[2025-05-06 20:43:03,116][train][INFO] - Epoch 113/1000, Val Acc=0.5754, Val Loss=1.8186, lr=0.0100
[2025-05-06 20:43:10,729][train][INFO] - Epoch 113/1000, Val Acc=0.6267, Val Loss=1.7318, lr=0.0100
[2025-05-06 20:43:11,650][train][INFO] - Epoch 114/1000, Val Acc=0.6024, Val Loss=1.6463, lr=0.0100
[2025-05-06 20:43:18,793][train][INFO] - Epoch 114/1000, Val Acc=0.6432, Val Loss=1.6667, lr=0.0100
[2025-05-06 20:43:19,826][train][INFO] - Epoch 115/1000, Val Acc=0.5706, Val Loss=1.8334, lr=0.0100
[2025-05-06 20:43:26,414][train][INFO] - Epoch 115/1000, Val Acc=0.6319, Val Loss=1.7441, lr=0.0100
[2025-05-06 20:43:27,881][train][INFO] - Epoch 116/1000, Val Acc=0.6007, Val Loss=1.6487, lr=0.0100
[2025-05-06 20:43:34,608][train][INFO] - Epoch 116/1000, Val Acc=0.6329, Val Loss=1.7273, lr=0.0100
[2025-05-06 20:43:36,222][train][INFO] - Epoch 117/1000, Val Acc=0.5895, Val Loss=1.7346, lr=0.0100
[2025-05-06 20:43:42,607][train][INFO] - Epoch 117/1000, Val Acc=0.6277, Val Loss=1.7417, lr=0.0100
[2025-05-06 20:43:44,004][train][INFO] - Epoch 118/1000, Val Acc=0.5950, Val Loss=1.6965, lr=0.0100
[2025-05-06 20:43:51,063][train][INFO] - Epoch 118/1000, Val Acc=0.6321, Val Loss=1.7607, lr=0.0100
[2025-05-06 20:43:52,186][train][INFO] - Epoch 119/1000, Val Acc=0.5744, Val Loss=1.8363, lr=0.0100
[2025-05-06 20:43:58,351][train][INFO] - Epoch 119/1000, Val Acc=0.6172, Val Loss=1.8245, lr=0.0100
[2025-05-06 20:44:00,395][train][INFO] - Epoch 120/1000, Val Acc=0.5844, Val Loss=1.7783, lr=0.0100
[2025-05-06 20:44:06,443][train][INFO] - Epoch 120/1000, Val Acc=0.6233, Val Loss=1.7512, lr=0.0100
[2025-05-06 20:44:08,308][train][INFO] - Epoch 121/1000, Val Acc=0.5914, Val Loss=1.7298, lr=0.0100
[2025-05-06 20:44:13,573][train][INFO] - Epoch 121/1000, Val Acc=0.6262, Val Loss=1.7664, lr=0.0100
[2025-05-06 20:44:15,948][train][INFO] - Epoch 122/1000, Val Acc=0.5793, Val Loss=1.8672, lr=0.0100
[2025-05-06 20:44:21,068][train][INFO] - Epoch 122/1000, Val Acc=0.6304, Val Loss=1.7189, lr=0.0100
[2025-05-06 20:44:24,187][train][INFO] - Epoch 123/1000, Val Acc=0.6001, Val Loss=1.6684, lr=0.0100
[2025-05-06 20:44:29,137][train][INFO] - Epoch 123/1000, Val Acc=0.6246, Val Loss=1.7790, lr=0.0100
[2025-05-06 20:44:32,413][train][INFO] - Epoch 124/1000, Val Acc=0.5978, Val Loss=1.6591, lr=0.0100
[2025-05-06 20:44:36,865][train][INFO] - Epoch 124/1000, Val Acc=0.6401, Val Loss=1.7263, lr=0.0100
[2025-05-06 20:44:40,472][train][INFO] - Epoch 125/1000, Val Acc=0.5882, Val Loss=1.7702, lr=0.0100
[2025-05-06 20:44:44,880][train][INFO] - Epoch 125/1000, Val Acc=0.6376, Val Loss=1.7150, lr=0.0100
[2025-05-06 20:44:47,408][train][INFO] - Epoch 126/1000, Val Acc=0.6054, Val Loss=1.6735, lr=0.0100
[2025-05-06 20:44:52,444][train][INFO] - Epoch 126/1000, Val Acc=0.6430, Val Loss=1.7056, lr=0.0100
[2025-05-06 20:44:55,196][train][INFO] - Epoch 127/1000, Val Acc=0.5924, Val Loss=1.7601, lr=0.0100
[2025-05-06 20:45:00,229][train][INFO] - Epoch 127/1000, Val Acc=0.6328, Val Loss=1.6962, lr=0.0100
[2025-05-06 20:45:02,939][train][INFO] - Epoch 128/1000, Val Acc=0.5807, Val Loss=1.8132, lr=0.0100
[2025-05-06 20:45:08,717][train][INFO] - Epoch 128/1000, Val Acc=0.6298, Val Loss=1.7898, lr=0.0100
[2025-05-06 20:45:11,178][train][INFO] - Epoch 129/1000, Val Acc=0.6024, Val Loss=1.6499, lr=0.0100
[2025-05-06 20:45:17,000][train][INFO] - Epoch 129/1000, Val Acc=0.6351, Val Loss=1.7319, lr=0.0100
[2025-05-06 20:45:19,160][train][INFO] - Epoch 130/1000, Val Acc=0.5984, Val Loss=1.7086, lr=0.0100
[2025-05-06 20:45:24,837][train][INFO] - Epoch 130/1000, Val Acc=0.6355, Val Loss=1.7282, lr=0.0100
[2025-05-06 20:45:27,223][train][INFO] - Epoch 131/1000, Val Acc=0.6109, Val Loss=1.6114, lr=0.0100
[2025-05-06 20:45:33,215][train][INFO] - Epoch 131/1000, Val Acc=0.6390, Val Loss=1.7386, lr=0.0100
[2025-05-06 20:45:35,271][train][INFO] - Epoch 132/1000, Val Acc=0.5664, Val Loss=1.9274, lr=0.0100
[2025-05-06 20:45:41,320][train][INFO] - Epoch 132/1000, Val Acc=0.6261, Val Loss=1.8587, lr=0.0100
[2025-05-06 20:45:43,055][train][INFO] - Epoch 133/1000, Val Acc=0.6177, Val Loss=1.6003, lr=0.0100
[2025-05-06 20:45:49,845][train][INFO] - Epoch 133/1000, Val Acc=0.6238, Val Loss=1.7603, lr=0.0100
[2025-05-06 20:45:51,479][train][INFO] - Epoch 134/1000, Val Acc=0.6018, Val Loss=1.6474, lr=0.0100
[2025-05-06 20:45:57,760][train][INFO] - Epoch 134/1000, Val Acc=0.6391, Val Loss=1.7053, lr=0.0100
[2025-05-06 20:45:59,054][train][INFO] - Epoch 135/1000, Val Acc=0.6185, Val Loss=1.5920, lr=0.0100
[2025-05-06 20:46:05,853][train][INFO] - Epoch 135/1000, Val Acc=0.6073, Val Loss=1.8848, lr=0.0100
[2025-05-06 20:46:06,803][train][INFO] - Epoch 136/1000, Val Acc=0.6039, Val Loss=1.6613, lr=0.0100
[2025-05-06 20:46:13,912][train][INFO] - Epoch 136/1000, Val Acc=0.6373, Val Loss=1.6977, lr=0.0100
[2025-05-06 20:46:14,844][train][INFO] - Epoch 137/1000, Val Acc=0.5863, Val Loss=1.7519, lr=0.0100
[2025-05-06 20:46:22,262][train][INFO] - Epoch 137/1000, Val Acc=0.6308, Val Loss=1.7730, lr=0.0100
[2025-05-06 20:46:23,112][train][INFO] - Epoch 138/1000, Val Acc=0.6000, Val Loss=1.6806, lr=0.0100
[2025-05-06 20:46:29,621][train][INFO] - Epoch 138/1000, Val Acc=0.6274, Val Loss=1.7813, lr=0.0100
[2025-05-06 20:46:31,019][train][INFO] - Epoch 139/1000, Val Acc=0.6106, Val Loss=1.6362, lr=0.0100
[2025-05-06 20:46:37,406][train][INFO] - Epoch 139/1000, Val Acc=0.6216, Val Loss=1.8265, lr=0.0100
[2025-05-06 20:46:38,499][train][INFO] - Epoch 140/1000, Val Acc=0.6065, Val Loss=1.6712, lr=0.0100
[2025-05-06 20:46:44,946][train][INFO] - Epoch 140/1000, Val Acc=0.6403, Val Loss=1.7137, lr=0.0100
[2025-05-06 20:46:45,834][train][INFO] - Epoch 141/1000, Val Acc=0.6181, Val Loss=1.5952, lr=0.0100
[2025-05-06 20:46:53,292][train][INFO] - Epoch 141/1000, Val Acc=0.6240, Val Loss=1.7571, lr=0.0100
[2025-05-06 20:46:53,632][train][INFO] - Epoch 142/1000, Val Acc=0.6017, Val Loss=1.7042, lr=0.0100
[2025-05-06 20:47:01,025][train][INFO] - Epoch 142/1000, Val Acc=0.6312, Val Loss=1.7402, lr=0.0100
[2025-05-06 20:47:01,899][train][INFO] - Epoch 143/1000, Val Acc=0.6055, Val Loss=1.6879, lr=0.0100
[2025-05-06 20:47:09,473][train][INFO] - Epoch 143/1000, Val Acc=0.6363, Val Loss=1.7472, lr=0.0100
[2025-05-06 20:47:09,666][train][INFO] - Epoch 144/1000, Val Acc=0.6101, Val Loss=1.6667, lr=0.0100
[2025-05-06 20:47:17,936][train][INFO] - Epoch 144/1000, Val Acc=0.6254, Val Loss=1.7392, lr=0.0100
[2025-05-06 20:47:18,014][train][INFO] - Epoch 145/1000, Val Acc=0.6065, Val Loss=1.6942, lr=0.0100
[2025-05-06 20:47:25,573][train][INFO] - Epoch 146/1000, Val Acc=0.6098, Val Loss=1.6507, lr=0.0100
[2025-05-06 20:47:26,603][train][INFO] - Epoch 145/1000, Val Acc=0.6376, Val Loss=1.7465, lr=0.0100
[2025-05-06 20:47:33,182][train][INFO] - Epoch 147/1000, Val Acc=0.6024, Val Loss=1.6794, lr=0.0100
[2025-05-06 20:47:34,583][train][INFO] - Epoch 146/1000, Val Acc=0.6246, Val Loss=1.7858, lr=0.0100
[2025-05-06 20:47:41,449][train][INFO] - Epoch 148/1000, Val Acc=0.6043, Val Loss=1.6664, lr=0.0100
[2025-05-06 20:47:42,806][train][INFO] - Epoch 147/1000, Val Acc=0.6435, Val Loss=1.6698, lr=0.0100
[2025-05-06 20:47:49,508][train][INFO] - Epoch 149/1000, Val Acc=0.6108, Val Loss=1.6242, lr=0.0100
[2025-05-06 20:47:51,051][train][INFO] - Epoch 148/1000, Val Acc=0.6261, Val Loss=1.8144, lr=0.0100
[2025-05-06 20:47:57,682][train][INFO] - Epoch 150/1000, Val Acc=0.5984, Val Loss=1.7385, lr=0.0100
[2025-05-06 20:47:58,520][train][INFO] - Epoch 149/1000, Val Acc=0.6348, Val Loss=1.7758, lr=0.0100
[2025-05-06 20:48:06,046][train][INFO] - Epoch 151/1000, Val Acc=0.5988, Val Loss=1.7267, lr=0.0100
[2025-05-06 20:48:06,339][train][INFO] - Epoch 150/1000, Val Acc=0.6317, Val Loss=1.7839, lr=0.0100
[2025-05-06 20:48:13,060][train][INFO] - Epoch 152/1000, Val Acc=0.6177, Val Loss=1.6278, lr=0.0100
[2025-05-06 20:48:13,812][train][INFO] - Epoch 151/1000, Val Acc=0.6371, Val Loss=1.7359, lr=0.0100
[2025-05-06 20:48:21,434][train][INFO] - Epoch 153/1000, Val Acc=0.6033, Val Loss=1.7054, lr=0.0100
[2025-05-06 20:48:22,184][train][INFO] - Epoch 152/1000, Val Acc=0.6252, Val Loss=1.8014, lr=0.0100
[2025-05-06 20:48:29,112][train][INFO] - Epoch 154/1000, Val Acc=0.6043, Val Loss=1.6956, lr=0.0100
[2025-05-06 20:48:30,845][train][INFO] - Epoch 153/1000, Val Acc=0.6419, Val Loss=1.6842, lr=0.0100
[2025-05-06 20:48:36,855][train][INFO] - Epoch 155/1000, Val Acc=0.6066, Val Loss=1.6732, lr=0.0100
[2025-05-06 20:48:39,204][train][INFO] - Epoch 154/1000, Val Acc=0.6299, Val Loss=1.7562, lr=0.0100
[2025-05-06 20:48:44,717][train][INFO] - Epoch 156/1000, Val Acc=0.6026, Val Loss=1.6674, lr=0.0100
[2025-05-06 20:48:46,921][train][INFO] - Epoch 155/1000, Val Acc=0.6388, Val Loss=1.7181, lr=0.0100
[2025-05-06 20:48:52,892][train][INFO] - Epoch 157/1000, Val Acc=0.6161, Val Loss=1.6528, lr=0.0100
[2025-05-06 20:48:54,497][train][INFO] - Epoch 156/1000, Val Acc=0.6353, Val Loss=1.7694, lr=0.0100
[2025-05-06 20:49:00,942][train][INFO] - Epoch 158/1000, Val Acc=0.5956, Val Loss=1.7697, lr=0.0100
[2025-05-06 20:49:02,419][train][INFO] - Epoch 157/1000, Val Acc=0.6391, Val Loss=1.7231, lr=0.0100
[2025-05-06 20:49:08,789][train][INFO] - Epoch 159/1000, Val Acc=0.6076, Val Loss=1.6801, lr=0.0100
[2025-05-06 20:49:10,374][train][INFO] - Epoch 158/1000, Val Acc=0.6378, Val Loss=1.7119, lr=0.0100
[2025-05-06 20:49:17,010][train][INFO] - Epoch 160/1000, Val Acc=0.6020, Val Loss=1.7009, lr=0.0100
[2025-05-06 20:49:18,134][train][INFO] - Epoch 159/1000, Val Acc=0.6390, Val Loss=1.6934, lr=0.0100
[2025-05-06 20:49:24,941][train][INFO] - Epoch 161/1000, Val Acc=0.5951, Val Loss=1.7064, lr=0.0100
[2025-05-06 20:49:25,741][train][INFO] - Epoch 160/1000, Val Acc=0.6390, Val Loss=1.7237, lr=0.0100
[2025-05-06 20:49:33,154][train][INFO] - Epoch 162/1000, Val Acc=0.5926, Val Loss=1.7904, lr=0.0100
[2025-05-06 20:49:33,949][train][INFO] - Epoch 161/1000, Val Acc=0.6265, Val Loss=1.7636, lr=0.0100
[2025-05-06 20:49:41,558][train][INFO] - Epoch 163/1000, Val Acc=0.6013, Val Loss=1.7135, lr=0.0100
[2025-05-06 20:49:41,626][train][INFO] - Epoch 162/1000, Val Acc=0.6482, Val Loss=1.6754, lr=0.0100
[2025-05-06 20:49:50,027][train][INFO] - Epoch 163/1000, Val Acc=0.6454, Val Loss=1.6651, lr=0.0100
[2025-05-06 20:49:50,074][train][INFO] - Epoch 164/1000, Val Acc=0.6080, Val Loss=1.6736, lr=0.0100
[2025-05-06 20:49:58,090][train][INFO] - Epoch 165/1000, Val Acc=0.6147, Val Loss=1.6381, lr=0.0100
[2025-05-06 20:49:58,577][train][INFO] - Epoch 164/1000, Val Acc=0.6244, Val Loss=1.7802, lr=0.0100
[2025-05-06 20:50:05,566][train][INFO] - Epoch 166/1000, Val Acc=0.6070, Val Loss=1.6850, lr=0.0100
[2025-05-06 20:50:07,199][train][INFO] - Epoch 165/1000, Val Acc=0.6263, Val Loss=1.8306, lr=0.0100
[2025-05-06 20:50:13,554][train][INFO] - Epoch 167/1000, Val Acc=0.6087, Val Loss=1.6498, lr=0.0100
[2025-05-06 20:50:15,533][train][INFO] - Epoch 166/1000, Val Acc=0.6246, Val Loss=1.8554, lr=0.0100
[2025-05-06 20:50:21,831][train][INFO] - Epoch 168/1000, Val Acc=0.5957, Val Loss=1.7690, lr=0.0100
[2025-05-06 20:50:23,655][train][INFO] - Epoch 167/1000, Val Acc=0.6167, Val Loss=1.8767, lr=0.0100
[2025-05-06 20:50:30,179][train][INFO] - Epoch 169/1000, Val Acc=0.5885, Val Loss=1.8086, lr=0.0100
[2025-05-06 20:50:30,433][train][INFO] - Epoch 168/1000, Val Acc=0.6470, Val Loss=1.6758, lr=0.0100
[2025-05-06 20:50:38,523][train][INFO] - Epoch 170/1000, Val Acc=0.6088, Val Loss=1.6901, lr=0.0100
[2025-05-06 20:50:38,716][train][INFO] - Epoch 169/1000, Val Acc=0.6225, Val Loss=1.8326, lr=0.0100
[2025-05-06 20:50:46,757][train][INFO] - Epoch 171/1000, Val Acc=0.5969, Val Loss=1.7636, lr=0.0100
[2025-05-06 20:50:47,361][train][INFO] - Epoch 170/1000, Val Acc=0.6204, Val Loss=1.8291, lr=0.0100
[2025-05-06 20:50:55,116][train][INFO] - Epoch 171/1000, Val Acc=0.6515, Val Loss=1.6524, lr=0.0100
[2025-05-06 20:50:55,207][train][INFO] - Epoch 172/1000, Val Acc=0.6005, Val Loss=1.7534, lr=0.0100
[2025-05-06 20:51:02,736][train][INFO] - Epoch 173/1000, Val Acc=0.6057, Val Loss=1.7714, lr=0.0100
[2025-05-06 20:51:03,614][train][INFO] - Epoch 172/1000, Val Acc=0.6316, Val Loss=1.7704, lr=0.0100
[2025-05-06 20:51:10,881][train][INFO] - Epoch 174/1000, Val Acc=0.6158, Val Loss=1.6519, lr=0.0100
[2025-05-06 20:51:12,096][train][INFO] - Epoch 173/1000, Val Acc=0.6459, Val Loss=1.6854, lr=0.0100
[2025-05-06 20:51:19,023][train][INFO] - Epoch 175/1000, Val Acc=0.6090, Val Loss=1.6885, lr=0.0100
[2025-05-06 20:51:20,122][train][INFO] - Epoch 174/1000, Val Acc=0.6438, Val Loss=1.7156, lr=0.0100
[2025-05-06 20:51:26,098][train][INFO] - Epoch 176/1000, Val Acc=0.6092, Val Loss=1.6883, lr=0.0100
[2025-05-06 20:51:28,188][train][INFO] - Epoch 175/1000, Val Acc=0.6266, Val Loss=1.8349, lr=0.0100
[2025-05-06 20:51:34,531][train][INFO] - Epoch 177/1000, Val Acc=0.6198, Val Loss=1.6565, lr=0.0100
[2025-05-06 20:51:36,586][train][INFO] - Epoch 176/1000, Val Acc=0.6388, Val Loss=1.7629, lr=0.0100
[2025-05-06 20:51:42,806][train][INFO] - Epoch 178/1000, Val Acc=0.6075, Val Loss=1.7528, lr=0.0100
[2025-05-06 20:51:44,703][train][INFO] - Epoch 177/1000, Val Acc=0.6444, Val Loss=1.6655, lr=0.0100
[2025-05-06 20:51:50,751][train][INFO] - Epoch 179/1000, Val Acc=0.6211, Val Loss=1.6661, lr=0.0100
[2025-05-06 20:51:53,074][train][INFO] - Epoch 178/1000, Val Acc=0.6354, Val Loss=1.7466, lr=0.0100
[2025-05-06 20:51:58,565][train][INFO] - Epoch 180/1000, Val Acc=0.6047, Val Loss=1.7316, lr=0.0100
[2025-05-06 20:52:01,348][train][INFO] - Epoch 179/1000, Val Acc=0.6348, Val Loss=1.7854, lr=0.0100
[2025-05-06 20:52:06,891][train][INFO] - Epoch 181/1000, Val Acc=0.6166, Val Loss=1.6713, lr=0.0100
[2025-05-06 20:52:09,463][train][INFO] - Epoch 180/1000, Val Acc=0.6344, Val Loss=1.7088, lr=0.0100
[2025-05-06 20:52:15,132][train][INFO] - Epoch 182/1000, Val Acc=0.6100, Val Loss=1.6881, lr=0.0100
[2025-05-06 20:52:17,959][train][INFO] - Epoch 181/1000, Val Acc=0.6471, Val Loss=1.7270, lr=0.0100
[2025-05-06 20:52:23,205][train][INFO] - Epoch 183/1000, Val Acc=0.6082, Val Loss=1.6677, lr=0.0100
[2025-05-06 20:52:26,164][train][INFO] - Epoch 182/1000, Val Acc=0.6426, Val Loss=1.7100, lr=0.0100
[2025-05-06 20:52:31,370][train][INFO] - Epoch 184/1000, Val Acc=0.6118, Val Loss=1.6807, lr=0.0100
[2025-05-06 20:52:34,652][train][INFO] - Epoch 183/1000, Val Acc=0.6514, Val Loss=1.6770, lr=0.0100
[2025-05-06 20:52:39,221][train][INFO] - Epoch 185/1000, Val Acc=0.6017, Val Loss=1.7533, lr=0.0100
[2025-05-06 20:52:43,229][train][INFO] - Epoch 184/1000, Val Acc=0.6470, Val Loss=1.7182, lr=0.0100
[2025-05-06 20:52:46,550][train][INFO] - Epoch 186/1000, Val Acc=0.6229, Val Loss=1.6186, lr=0.0100
[2025-05-06 20:52:51,077][train][INFO] - Epoch 185/1000, Val Acc=0.6525, Val Loss=1.6740, lr=0.0100
[2025-05-06 20:52:54,453][train][INFO] - Epoch 187/1000, Val Acc=0.6076, Val Loss=1.7169, lr=0.0100
[2025-05-06 20:52:58,186][train][INFO] - Epoch 186/1000, Val Acc=0.6353, Val Loss=1.7556, lr=0.0100
[2025-05-06 20:53:02,423][train][INFO] - Epoch 188/1000, Val Acc=0.5997, Val Loss=1.8289, lr=0.0100
[2025-05-06 20:53:06,689][train][INFO] - Epoch 187/1000, Val Acc=0.6303, Val Loss=1.8041, lr=0.0100
[2025-05-06 20:53:10,771][train][INFO] - Epoch 189/1000, Val Acc=0.6149, Val Loss=1.6784, lr=0.0100
[2025-05-06 20:53:15,110][train][INFO] - Epoch 188/1000, Val Acc=0.6497, Val Loss=1.6779, lr=0.0100
[2025-05-06 20:53:18,551][train][INFO] - Epoch 190/1000, Val Acc=0.6115, Val Loss=1.6795, lr=0.0100
[2025-05-06 20:53:23,532][train][INFO] - Epoch 189/1000, Val Acc=0.6271, Val Loss=1.7832, lr=0.0100
[2025-05-06 20:53:26,141][train][INFO] - Epoch 191/1000, Val Acc=0.6308, Val Loss=1.6181, lr=0.0100
[2025-05-06 20:53:31,844][train][INFO] - Epoch 190/1000, Val Acc=0.6440, Val Loss=1.7364, lr=0.0100
[2025-05-06 20:53:33,955][train][INFO] - Epoch 192/1000, Val Acc=0.6031, Val Loss=1.7628, lr=0.0100
[2025-05-06 20:53:39,195][train][INFO] - Epoch 191/1000, Val Acc=0.6444, Val Loss=1.6956, lr=0.0100
[2025-05-06 20:53:42,412][train][INFO] - Epoch 193/1000, Val Acc=0.6159, Val Loss=1.6917, lr=0.0100
[2025-05-06 20:53:47,503][train][INFO] - Epoch 192/1000, Val Acc=0.6438, Val Loss=1.6741, lr=0.0100
[2025-05-06 20:53:49,727][train][INFO] - Epoch 194/1000, Val Acc=0.6076, Val Loss=1.7105, lr=0.0100
[2025-05-06 20:53:55,191][train][INFO] - Epoch 193/1000, Val Acc=0.6414, Val Loss=1.6965, lr=0.0100
[2025-05-06 20:53:57,880][train][INFO] - Epoch 195/1000, Val Acc=0.5996, Val Loss=1.7734, lr=0.0100
[2025-05-06 20:54:03,496][train][INFO] - Epoch 194/1000, Val Acc=0.6373, Val Loss=1.7446, lr=0.0100
[2025-05-06 20:54:06,180][train][INFO] - Epoch 196/1000, Val Acc=0.6107, Val Loss=1.6889, lr=0.0100
[2025-05-06 20:54:11,166][train][INFO] - Epoch 195/1000, Val Acc=0.6290, Val Loss=1.7930, lr=0.0100
[2025-05-06 20:54:14,662][train][INFO] - Epoch 197/1000, Val Acc=0.6069, Val Loss=1.7151, lr=0.0100
[2025-05-06 20:54:19,941][train][INFO] - Epoch 196/1000, Val Acc=0.6433, Val Loss=1.7033, lr=0.0100
[2025-05-06 20:54:22,741][train][INFO] - Epoch 198/1000, Val Acc=0.6020, Val Loss=1.6906, lr=0.0100
[2025-05-06 20:54:27,855][train][INFO] - Epoch 197/1000, Val Acc=0.6424, Val Loss=1.7037, lr=0.0100
[2025-05-06 20:54:30,344][train][INFO] - Epoch 199/1000, Val Acc=0.5943, Val Loss=1.8445, lr=0.0100
[2025-05-06 20:54:36,210][train][INFO] - Epoch 198/1000, Val Acc=0.6507, Val Loss=1.6985, lr=0.0100
[2025-05-06 20:54:38,049][train][INFO] - Epoch 200/1000, Val Acc=0.6117, Val Loss=1.6934, lr=0.0100
[2025-05-06 20:54:44,806][train][INFO] - Epoch 199/1000, Val Acc=0.6504, Val Loss=1.6836, lr=0.0100
[2025-05-06 20:54:45,279][train][INFO] - Epoch 201/1000, Val Acc=0.6095, Val Loss=1.7025, lr=0.0100
[2025-05-06 20:54:53,413][train][INFO] - Epoch 200/1000, Val Acc=0.6456, Val Loss=1.7438, lr=0.0100
[2025-05-06 20:54:53,578][train][INFO] - Epoch 202/1000, Val Acc=0.6129, Val Loss=1.6951, lr=0.0100
[2025-05-06 20:55:00,697][train][INFO] - Epoch 203/1000, Val Acc=0.5956, Val Loss=1.8208, lr=0.0100
[2025-05-06 20:55:01,710][train][INFO] - Epoch 201/1000, Val Acc=0.6404, Val Loss=1.7278, lr=0.0100
[2025-05-06 20:55:08,671][train][INFO] - Epoch 204/1000, Val Acc=0.6112, Val Loss=1.7466, lr=0.0100
[2025-05-06 20:55:10,113][train][INFO] - Epoch 202/1000, Val Acc=0.6448, Val Loss=1.7153, lr=0.0100
[2025-05-06 20:55:16,810][train][INFO] - Epoch 205/1000, Val Acc=0.6147, Val Loss=1.7001, lr=0.0100
[2025-05-06 20:55:18,295][train][INFO] - Epoch 203/1000, Val Acc=0.6513, Val Loss=1.6635, lr=0.0100
[2025-05-06 20:55:24,883][train][INFO] - Epoch 206/1000, Val Acc=0.6129, Val Loss=1.6947, lr=0.0100
[2025-05-06 20:55:26,754][train][INFO] - Epoch 204/1000, Val Acc=0.6407, Val Loss=1.7144, lr=0.0100
[2025-05-06 20:55:33,300][train][INFO] - Epoch 207/1000, Val Acc=0.6192, Val Loss=1.6842, lr=0.0100
[2025-05-06 20:55:35,420][train][INFO] - Epoch 205/1000, Val Acc=0.6375, Val Loss=1.7795, lr=0.0100
[2025-05-06 20:55:41,533][train][INFO] - Epoch 208/1000, Val Acc=0.6165, Val Loss=1.6822, lr=0.0100
[2025-05-06 20:55:43,397][train][INFO] - Epoch 206/1000, Val Acc=0.6517, Val Loss=1.6579, lr=0.0100
[2025-05-06 20:55:49,901][train][INFO] - Epoch 209/1000, Val Acc=0.6040, Val Loss=1.7709, lr=0.0100
[2025-05-06 20:55:51,430][train][INFO] - Epoch 207/1000, Val Acc=0.6425, Val Loss=1.7143, lr=0.0100
[2025-05-06 20:55:57,738][train][INFO] - Epoch 210/1000, Val Acc=0.6051, Val Loss=1.7065, lr=0.0100
[2025-05-06 20:55:59,698][train][INFO] - Epoch 208/1000, Val Acc=0.6511, Val Loss=1.6606, lr=0.0100
[2025-05-06 20:56:06,117][train][INFO] - Epoch 211/1000, Val Acc=0.6042, Val Loss=1.7468, lr=0.0100
[2025-05-06 20:56:08,075][train][INFO] - Epoch 209/1000, Val Acc=0.6457, Val Loss=1.6957, lr=0.0100
[2025-05-06 20:56:13,906][train][INFO] - Epoch 212/1000, Val Acc=0.6142, Val Loss=1.7212, lr=0.0100
[2025-05-06 20:56:16,616][train][INFO] - Epoch 210/1000, Val Acc=0.6461, Val Loss=1.7090, lr=0.0100
[2025-05-06 20:56:21,153][train][INFO] - Epoch 213/1000, Val Acc=0.6185, Val Loss=1.6690, lr=0.0100
[2025-05-06 20:56:25,137][train][INFO] - Epoch 211/1000, Val Acc=0.6206, Val Loss=1.8895, lr=0.0100
[2025-05-06 20:56:28,633][train][INFO] - Epoch 214/1000, Val Acc=0.6134, Val Loss=1.7211, lr=0.0100
[2025-05-06 20:56:33,403][train][INFO] - Epoch 212/1000, Val Acc=0.6375, Val Loss=1.7554, lr=0.0100
[2025-05-06 20:56:36,765][train][INFO] - Epoch 215/1000, Val Acc=0.6164, Val Loss=1.7041, lr=0.0100
[2025-05-06 20:56:41,589][train][INFO] - Epoch 213/1000, Val Acc=0.6447, Val Loss=1.6932, lr=0.0100
[2025-05-06 20:56:43,392][train][INFO] - Epoch 216/1000, Val Acc=0.6074, Val Loss=1.7751, lr=0.0100
[2025-05-06 20:56:49,495][train][INFO] - Epoch 214/1000, Val Acc=0.6306, Val Loss=1.8019, lr=0.0100
[2025-05-06 20:56:50,455][train][INFO] - Epoch 217/1000, Val Acc=0.6130, Val Loss=1.7545, lr=0.0100
[2025-05-06 20:56:58,241][train][INFO] - Epoch 215/1000, Val Acc=0.6333, Val Loss=1.7193, lr=0.0100
[2025-05-06 20:56:58,861][train][INFO] - Epoch 218/1000, Val Acc=0.6301, Val Loss=1.6240, lr=0.0100
[2025-05-06 20:57:06,041][train][INFO] - Epoch 216/1000, Val Acc=0.6380, Val Loss=1.7383, lr=0.0100
[2025-05-06 20:57:07,289][train][INFO] - Epoch 219/1000, Val Acc=0.6208, Val Loss=1.6876, lr=0.0100
[2025-05-06 20:57:13,187][train][INFO] - Epoch 217/1000, Val Acc=0.6215, Val Loss=1.8550, lr=0.0100
[2025-05-06 20:57:14,566][train][INFO] - Epoch 220/1000, Val Acc=0.6238, Val Loss=1.6678, lr=0.0100
[2025-05-06 20:57:21,541][train][INFO] - Epoch 218/1000, Val Acc=0.6359, Val Loss=1.7350, lr=0.0100
[2025-05-06 20:57:22,158][train][INFO] - Epoch 221/1000, Val Acc=0.6139, Val Loss=1.7216, lr=0.0100
[2025-05-06 20:57:30,048][train][INFO] - Epoch 219/1000, Val Acc=0.6242, Val Loss=1.8672, lr=0.0100
[2025-05-06 20:57:30,487][train][INFO] - Epoch 222/1000, Val Acc=0.6301, Val Loss=1.6175, lr=0.0100
[2025-05-06 20:57:38,504][train][INFO] - Epoch 220/1000, Val Acc=0.6429, Val Loss=1.7198, lr=0.0100
[2025-05-06 20:57:38,522][train][INFO] - Epoch 223/1000, Val Acc=0.6053, Val Loss=1.7552, lr=0.0100
[2025-05-06 20:57:46,292][train][INFO] - Epoch 221/1000, Val Acc=0.6383, Val Loss=1.7604, lr=0.0100
[2025-05-06 20:57:46,634][train][INFO] - Epoch 224/1000, Val Acc=0.6034, Val Loss=1.8041, lr=0.0100
[2025-05-06 20:57:54,518][train][INFO] - Epoch 225/1000, Val Acc=0.6328, Val Loss=1.6022, lr=0.0100
[2025-05-06 20:57:54,556][train][INFO] - Epoch 222/1000, Val Acc=0.6380, Val Loss=1.7418, lr=0.0100
[2025-05-06 20:58:02,633][train][INFO] - Epoch 223/1000, Val Acc=0.6371, Val Loss=1.6940, lr=0.0100
[2025-05-06 20:58:03,014][train][INFO] - Epoch 226/1000, Val Acc=0.5964, Val Loss=1.8452, lr=0.0100
[2025-05-06 20:58:10,096][train][INFO] - Epoch 224/1000, Val Acc=0.6290, Val Loss=1.7868, lr=0.0100
[2025-05-06 20:58:11,019][train][INFO] - Epoch 227/1000, Val Acc=0.6271, Val Loss=1.6373, lr=0.0100
[2025-05-06 20:58:17,605][train][INFO] - Epoch 225/1000, Val Acc=0.6353, Val Loss=1.7604, lr=0.0100
[2025-05-06 20:58:19,123][train][INFO] - Epoch 228/1000, Val Acc=0.6282, Val Loss=1.6309, lr=0.0100
[2025-05-06 20:58:25,829][train][INFO] - Epoch 226/1000, Val Acc=0.6439, Val Loss=1.6910, lr=0.0100
[2025-05-06 20:58:27,426][train][INFO] - Epoch 229/1000, Val Acc=0.6214, Val Loss=1.7019, lr=0.0100
[2025-05-06 20:58:33,850][train][INFO] - Epoch 227/1000, Val Acc=0.6422, Val Loss=1.7203, lr=0.0100
[2025-05-06 20:58:35,357][train][INFO] - Epoch 230/1000, Val Acc=0.6153, Val Loss=1.7235, lr=0.0100
[2025-05-06 20:58:41,796][train][INFO] - Epoch 228/1000, Val Acc=0.6393, Val Loss=1.7561, lr=0.0100
[2025-05-06 20:58:43,638][train][INFO] - Epoch 231/1000, Val Acc=0.6189, Val Loss=1.6906, lr=0.0100
[2025-05-06 20:58:50,367][train][INFO] - Epoch 229/1000, Val Acc=0.6411, Val Loss=1.7370, lr=0.0100
[2025-05-06 20:58:51,363][train][INFO] - Epoch 232/1000, Val Acc=0.6061, Val Loss=1.7312, lr=0.0100
[2025-05-06 20:58:58,487][train][INFO] - Epoch 230/1000, Val Acc=0.6407, Val Loss=1.6886, lr=0.0100
[2025-05-06 20:58:59,368][train][INFO] - Epoch 233/1000, Val Acc=0.6222, Val Loss=1.6475, lr=0.0100
[2025-05-06 20:59:06,653][train][INFO] - Epoch 231/1000, Val Acc=0.6399, Val Loss=1.7458, lr=0.0100
[2025-05-06 20:59:06,832][train][INFO] - Epoch 234/1000, Val Acc=0.6247, Val Loss=1.6814, lr=0.0100
[2025-05-06 20:59:15,012][train][INFO] - Epoch 235/1000, Val Acc=0.6121, Val Loss=1.7562, lr=0.0100
[2025-05-06 20:59:15,151][train][INFO] - Epoch 232/1000, Val Acc=0.6451, Val Loss=1.7061, lr=0.0100
[2025-05-06 20:59:23,058][train][INFO] - Epoch 236/1000, Val Acc=0.6084, Val Loss=1.7347, lr=0.0100
[2025-05-06 20:59:23,647][train][INFO] - Epoch 233/1000, Val Acc=0.6471, Val Loss=1.7121, lr=0.0100
[2025-05-06 20:59:31,257][train][INFO] - Epoch 237/1000, Val Acc=0.6212, Val Loss=1.6723, lr=0.0100
[2025-05-06 20:59:31,988][train][INFO] - Epoch 234/1000, Val Acc=0.6368, Val Loss=1.7465, lr=0.0100
[2025-05-06 20:59:39,474][train][INFO] - Epoch 238/1000, Val Acc=0.6071, Val Loss=1.7741, lr=0.0100
[2025-05-06 20:59:39,784][train][INFO] - Epoch 235/1000, Val Acc=0.6352, Val Loss=1.7352, lr=0.0100
[2025-05-06 20:59:47,773][train][INFO] - Epoch 239/1000, Val Acc=0.6269, Val Loss=1.6762, lr=0.0100
[2025-05-06 20:59:47,884][train][INFO] - Epoch 236/1000, Val Acc=0.6334, Val Loss=1.7821, lr=0.0100
[2025-05-06 20:59:55,522][train][INFO] - Epoch 240/1000, Val Acc=0.6280, Val Loss=1.6290, lr=0.0100
[2025-05-06 20:59:55,782][train][INFO] - Epoch 237/1000, Val Acc=0.6431, Val Loss=1.7228, lr=0.0100
[2025-05-06 21:00:03,779][train][INFO] - Epoch 241/1000, Val Acc=0.5904, Val Loss=1.8572, lr=0.0100
[2025-05-06 21:00:03,847][train][INFO] - Epoch 238/1000, Val Acc=0.6377, Val Loss=1.7466, lr=0.0100
[2025-05-06 21:00:11,389][train][INFO] - Epoch 242/1000, Val Acc=0.6136, Val Loss=1.6984, lr=0.0100
[2025-05-06 21:00:11,878][train][INFO] - Epoch 239/1000, Val Acc=0.6326, Val Loss=1.8324, lr=0.0100
[2025-05-06 21:00:19,521][train][INFO] - Epoch 243/1000, Val Acc=0.6282, Val Loss=1.6642, lr=0.0100
[2025-05-06 21:00:19,870][train][INFO] - Epoch 240/1000, Val Acc=0.6348, Val Loss=1.8058, lr=0.0100
[2025-05-06 21:00:27,285][train][INFO] - Epoch 244/1000, Val Acc=0.6258, Val Loss=1.6508, lr=0.0100
[2025-05-06 21:00:27,402][train][INFO] - Epoch 241/1000, Val Acc=0.6271, Val Loss=1.8305, lr=0.0100
[2025-05-06 21:00:34,947][train][INFO] - Epoch 245/1000, Val Acc=0.6126, Val Loss=1.7362, lr=0.0100
[2025-05-06 21:00:35,242][train][INFO] - Epoch 242/1000, Val Acc=0.6327, Val Loss=1.7451, lr=0.0100
[2025-05-06 21:00:42,628][train][INFO] - Epoch 246/1000, Val Acc=0.6077, Val Loss=1.7621, lr=0.0100
[2025-05-06 21:00:43,384][train][INFO] - Epoch 243/1000, Val Acc=0.6315, Val Loss=1.7815, lr=0.0100
[2025-05-06 21:00:51,223][train][INFO] - Epoch 247/1000, Val Acc=0.6182, Val Loss=1.7179, lr=0.0100
[2025-05-06 21:00:51,785][train][INFO] - Epoch 244/1000, Val Acc=0.6442, Val Loss=1.7473, lr=0.0100
[2025-05-06 21:00:59,031][train][INFO] - Epoch 248/1000, Val Acc=0.6320, Val Loss=1.6406, lr=0.0100
[2025-05-06 21:00:59,715][train][INFO] - Epoch 245/1000, Val Acc=0.6403, Val Loss=1.7198, lr=0.0100
[2025-05-06 21:01:06,794][train][INFO] - Epoch 249/1000, Val Acc=0.6146, Val Loss=1.7380, lr=0.0100
[2025-05-06 21:01:07,538][train][INFO] - Epoch 246/1000, Val Acc=0.6255, Val Loss=1.8414, lr=0.0100
[2025-05-06 21:01:15,270][train][INFO] - Epoch 250/1000, Val Acc=0.6115, Val Loss=1.7590, lr=0.0100
[2025-05-06 21:01:15,826][train][INFO] - Epoch 247/1000, Val Acc=0.6324, Val Loss=1.7821, lr=0.0100
[2025-05-06 21:01:23,573][train][INFO] - Epoch 251/1000, Val Acc=0.6164, Val Loss=1.7170, lr=0.0100
[2025-05-06 21:01:23,815][train][INFO] - Epoch 248/1000, Val Acc=0.6343, Val Loss=1.7907, lr=0.0100
[2025-05-06 21:01:30,369][train][INFO] - Epoch 252/1000, Val Acc=0.6205, Val Loss=1.7329, lr=0.0100
[2025-05-06 21:01:32,046][train][INFO] - Epoch 249/1000, Val Acc=0.6363, Val Loss=1.7711, lr=0.0100
[2025-05-06 21:01:38,057][train][INFO] - Epoch 253/1000, Val Acc=0.6312, Val Loss=1.6257, lr=0.0100
[2025-05-06 21:01:40,423][train][INFO] - Epoch 250/1000, Val Acc=0.6388, Val Loss=1.7551, lr=0.0100
[2025-05-06 21:01:46,053][train][INFO] - Epoch 254/1000, Val Acc=0.6347, Val Loss=1.6273, lr=0.0100
[2025-05-06 21:01:48,058][train][INFO] - Epoch 251/1000, Val Acc=0.6441, Val Loss=1.7500, lr=0.0100
[2025-05-06 21:01:54,292][train][INFO] - Epoch 255/1000, Val Acc=0.6191, Val Loss=1.7469, lr=0.0100
[2025-05-06 21:01:56,198][train][INFO] - Epoch 252/1000, Val Acc=0.6417, Val Loss=1.7171, lr=0.0100
[2025-05-06 21:02:02,417][train][INFO] - Epoch 256/1000, Val Acc=0.6145, Val Loss=1.7645, lr=0.0100
[2025-05-06 21:02:04,184][train][INFO] - Epoch 253/1000, Val Acc=0.6400, Val Loss=1.7336, lr=0.0100
[2025-05-06 21:02:10,745][train][INFO] - Epoch 257/1000, Val Acc=0.6191, Val Loss=1.6839, lr=0.0100
[2025-05-06 21:02:11,963][train][INFO] - Epoch 254/1000, Val Acc=0.6318, Val Loss=1.7981, lr=0.0100
[2025-05-06 21:02:18,945][train][INFO] - Epoch 258/1000, Val Acc=0.6188, Val Loss=1.7273, lr=0.0100
[2025-05-06 21:02:20,066][train][INFO] - Epoch 255/1000, Val Acc=0.6464, Val Loss=1.7013, lr=0.0100
[2025-05-06 21:02:27,438][train][INFO] - Epoch 259/1000, Val Acc=0.6110, Val Loss=1.7984, lr=0.0100
[2025-05-06 21:02:27,537][train][INFO] - Epoch 256/1000, Val Acc=0.6518, Val Loss=1.6768, lr=0.0100
[2025-05-06 21:02:35,331][train][INFO] - Epoch 260/1000, Val Acc=0.6097, Val Loss=1.7319, lr=0.0100
[2025-05-06 21:02:35,779][train][INFO] - Epoch 257/1000, Val Acc=0.6432, Val Loss=1.7219, lr=0.0100
[2025-05-06 21:02:43,284][train][INFO] - Epoch 258/1000, Val Acc=0.6250, Val Loss=1.8568, lr=0.0100
[2025-05-06 21:02:43,708][train][INFO] - Epoch 261/1000, Val Acc=0.6174, Val Loss=1.7112, lr=0.0100
[2025-05-06 21:02:50,416][train][INFO] - Epoch 259/1000, Val Acc=0.6476, Val Loss=1.7085, lr=0.0100
[2025-05-06 21:02:51,913][train][INFO] - Epoch 262/1000, Val Acc=0.6185, Val Loss=1.7184, lr=0.0100
[2025-05-06 21:02:58,996][train][INFO] - Epoch 260/1000, Val Acc=0.6468, Val Loss=1.7059, lr=0.0100
[2025-05-06 21:03:00,099][train][INFO] - Epoch 263/1000, Val Acc=0.6131, Val Loss=1.7326, lr=0.0100
[2025-05-06 21:03:07,197][train][INFO] - Epoch 261/1000, Val Acc=0.6447, Val Loss=1.7125, lr=0.0100
[2025-05-06 21:03:08,500][train][INFO] - Epoch 264/1000, Val Acc=0.6197, Val Loss=1.6786, lr=0.0100
[2025-05-06 21:03:15,432][train][INFO] - Epoch 262/1000, Val Acc=0.6298, Val Loss=1.7791, lr=0.0100
[2025-05-06 21:03:16,970][train][INFO] - Epoch 265/1000, Val Acc=0.6202, Val Loss=1.7122, lr=0.0100
[2025-05-06 21:03:23,850][train][INFO] - Epoch 263/1000, Val Acc=0.6435, Val Loss=1.7302, lr=0.0100
[2025-05-06 21:03:24,522][train][INFO] - Epoch 266/1000, Val Acc=0.6192, Val Loss=1.7104, lr=0.0100
[2025-05-06 21:03:31,825][train][INFO] - Epoch 264/1000, Val Acc=0.6430, Val Loss=1.7202, lr=0.0100
[2025-05-06 21:03:32,779][train][INFO] - Epoch 267/1000, Val Acc=0.6241, Val Loss=1.6745, lr=0.0100
[2025-05-06 21:03:39,921][train][INFO] - Epoch 265/1000, Val Acc=0.6414, Val Loss=1.7471, lr=0.0100
[2025-05-06 21:03:41,062][train][INFO] - Epoch 268/1000, Val Acc=0.6267, Val Loss=1.6600, lr=0.0100
[2025-05-06 21:03:47,932][train][INFO] - Epoch 266/1000, Val Acc=0.6464, Val Loss=1.6918, lr=0.0100
[2025-05-06 21:03:49,139][train][INFO] - Epoch 269/1000, Val Acc=0.6200, Val Loss=1.7198, lr=0.0100
[2025-05-06 21:03:56,098][train][INFO] - Epoch 267/1000, Val Acc=0.6421, Val Loss=1.7076, lr=0.0100
[2025-05-06 21:03:57,621][train][INFO] - Epoch 270/1000, Val Acc=0.6257, Val Loss=1.6868, lr=0.0100
[2025-05-06 21:04:04,222][train][INFO] - Epoch 268/1000, Val Acc=0.6218, Val Loss=1.8392, lr=0.0100
[2025-05-06 21:04:05,928][train][INFO] - Epoch 271/1000, Val Acc=0.6180, Val Loss=1.7319, lr=0.0100
[2025-05-06 21:04:12,468][train][INFO] - Epoch 269/1000, Val Acc=0.6371, Val Loss=1.7964, lr=0.0100
[2025-05-06 21:04:14,086][train][INFO] - Epoch 272/1000, Val Acc=0.6320, Val Loss=1.6339, lr=0.0100
[2025-05-06 21:04:20,856][train][INFO] - Epoch 270/1000, Val Acc=0.6424, Val Loss=1.7497, lr=0.0100
[2025-05-06 21:04:22,173][train][INFO] - Epoch 273/1000, Val Acc=0.6320, Val Loss=1.6674, lr=0.0100
[2025-05-06 21:04:29,110][train][INFO] - Epoch 271/1000, Val Acc=0.6546, Val Loss=1.6315, lr=0.0100
[2025-05-06 21:04:29,525][train][INFO] - Epoch 274/1000, Val Acc=0.6183, Val Loss=1.7224, lr=0.0100
[2025-05-06 21:04:37,598][train][INFO] - Epoch 272/1000, Val Acc=0.6267, Val Loss=1.8374, lr=0.0100
[2025-05-06 21:04:37,736][train][INFO] - Epoch 275/1000, Val Acc=0.6185, Val Loss=1.7167, lr=0.0100
[2025-05-06 21:04:45,479][train][INFO] - Epoch 273/1000, Val Acc=0.6422, Val Loss=1.7451, lr=0.0100
[2025-05-06 21:04:46,162][train][INFO] - Epoch 276/1000, Val Acc=0.6253, Val Loss=1.6446, lr=0.0100
[2025-05-06 21:04:53,856][train][INFO] - Epoch 274/1000, Val Acc=0.6156, Val Loss=1.9243, lr=0.0100
[2025-05-06 21:04:54,388][train][INFO] - Epoch 277/1000, Val Acc=0.6267, Val Loss=1.6535, lr=0.0100
[2025-05-06 21:05:01,217][train][INFO] - Epoch 275/1000, Val Acc=0.6249, Val Loss=1.8580, lr=0.0100
[2025-05-06 21:05:02,390][train][INFO] - Epoch 278/1000, Val Acc=0.6246, Val Loss=1.6533, lr=0.0100
[2025-05-06 21:05:09,427][train][INFO] - Epoch 276/1000, Val Acc=0.6378, Val Loss=1.7500, lr=0.0100
[2025-05-06 21:05:10,656][train][INFO] - Epoch 279/1000, Val Acc=0.6196, Val Loss=1.7308, lr=0.0100
[2025-05-06 21:05:17,869][train][INFO] - Epoch 277/1000, Val Acc=0.6291, Val Loss=1.8038, lr=0.0100
[2025-05-06 21:05:18,226][train][INFO] - Epoch 280/1000, Val Acc=0.6211, Val Loss=1.6922, lr=0.0100
[2025-05-06 21:05:25,784][train][INFO] - Epoch 278/1000, Val Acc=0.6416, Val Loss=1.7589, lr=0.0100
[2025-05-06 21:05:26,410][train][INFO] - Epoch 281/1000, Val Acc=0.6226, Val Loss=1.7117, lr=0.0100
[2025-05-06 21:05:33,896][train][INFO] - Epoch 279/1000, Val Acc=0.6352, Val Loss=1.7567, lr=0.0100
[2025-05-06 21:05:34,754][train][INFO] - Epoch 282/1000, Val Acc=0.6337, Val Loss=1.6498, lr=0.0100
[2025-05-06 21:05:42,053][train][INFO] - Epoch 280/1000, Val Acc=0.6405, Val Loss=1.7712, lr=0.0100
[2025-05-06 21:05:43,130][train][INFO] - Epoch 283/1000, Val Acc=0.6188, Val Loss=1.7016, lr=0.0100
[2025-05-06 21:05:50,771][train][INFO] - Epoch 281/1000, Val Acc=0.6567, Val Loss=1.6526, lr=0.0100
[2025-05-06 21:05:51,435][train][INFO] - Epoch 284/1000, Val Acc=0.6245, Val Loss=1.6785, lr=0.0100
[2025-05-06 21:05:58,858][train][INFO] - Epoch 282/1000, Val Acc=0.6423, Val Loss=1.7247, lr=0.0100
[2025-05-06 21:05:59,884][train][INFO] - Epoch 285/1000, Val Acc=0.6134, Val Loss=1.7099, lr=0.0100
[2025-05-06 21:06:07,119][train][INFO] - Epoch 283/1000, Val Acc=0.6482, Val Loss=1.6819, lr=0.0100
[2025-05-06 21:06:07,311][train][INFO] - Epoch 286/1000, Val Acc=0.6201, Val Loss=1.7457, lr=0.0100
[2025-05-06 21:06:15,138][train][INFO] - Epoch 287/1000, Val Acc=0.6206, Val Loss=1.6921, lr=0.0100
[2025-05-06 21:06:15,507][train][INFO] - Epoch 284/1000, Val Acc=0.6444, Val Loss=1.7162, lr=0.0100
[2025-05-06 21:06:24,145][train][INFO] - Epoch 285/1000, Val Acc=0.6221, Val Loss=1.8526, lr=0.0100
[2025-05-06 21:06:24,212][train][INFO] - Epoch 288/1000, Val Acc=0.6296, Val Loss=1.6355, lr=0.0100
[2025-05-06 21:06:33,471][train][INFO] - Epoch 289/1000, Val Acc=0.6181, Val Loss=1.7932, lr=0.0100
[2025-05-06 21:06:33,532][train][INFO] - Epoch 286/1000, Val Acc=0.6307, Val Loss=1.8045, lr=0.0100
[2025-05-06 21:06:41,244][train][INFO] - Epoch 287/1000, Val Acc=0.6459, Val Loss=1.6875, lr=0.0100
[2025-05-06 21:06:41,311][train][INFO] - Epoch 290/1000, Val Acc=0.6360, Val Loss=1.6202, lr=0.0100
[2025-05-06 21:06:49,408][train][INFO] - Epoch 288/1000, Val Acc=0.6486, Val Loss=1.6946, lr=0.0100
[2025-05-06 21:06:49,754][train][INFO] - Epoch 291/1000, Val Acc=0.6141, Val Loss=1.7165, lr=0.0100
[2025-05-06 21:06:57,038][train][INFO] - Epoch 289/1000, Val Acc=0.6378, Val Loss=1.7747, lr=0.0100
[2025-05-06 21:06:58,014][train][INFO] - Epoch 292/1000, Val Acc=0.6295, Val Loss=1.6268, lr=0.0100
[2025-05-06 21:07:05,632][train][INFO] - Epoch 290/1000, Val Acc=0.6433, Val Loss=1.7264, lr=0.0100
[2025-05-06 21:07:06,588][train][INFO] - Epoch 293/1000, Val Acc=0.6320, Val Loss=1.6479, lr=0.0100
[2025-05-06 21:07:13,925][train][INFO] - Epoch 291/1000, Val Acc=0.6437, Val Loss=1.7185, lr=0.0100
[2025-05-06 21:07:14,622][train][INFO] - Epoch 294/1000, Val Acc=0.6186, Val Loss=1.7581, lr=0.0100
[2025-05-06 21:07:21,908][train][INFO] - Epoch 295/1000, Val Acc=0.6094, Val Loss=1.7847, lr=0.0100
[2025-05-06 21:07:21,965][train][INFO] - Epoch 292/1000, Val Acc=0.6517, Val Loss=1.6739, lr=0.0100
[2025-05-06 21:07:30,255][train][INFO] - Epoch 296/1000, Val Acc=0.6259, Val Loss=1.7044, lr=0.0100
[2025-05-06 21:07:30,334][train][INFO] - Epoch 293/1000, Val Acc=0.6384, Val Loss=1.7625, lr=0.0100
[2025-05-06 21:07:38,575][train][INFO] - Epoch 297/1000, Val Acc=0.6445, Val Loss=1.6081, lr=0.0100
[2025-05-06 21:07:38,685][train][INFO] - Epoch 294/1000, Val Acc=0.6383, Val Loss=1.7780, lr=0.0100
[2025-05-06 21:07:46,784][train][INFO] - Epoch 298/1000, Val Acc=0.6111, Val Loss=1.7678, lr=0.0100
[2025-05-06 21:07:47,110][train][INFO] - Epoch 295/1000, Val Acc=0.6396, Val Loss=1.7817, lr=0.0100
[2025-05-06 21:07:54,332][train][INFO] - Epoch 299/1000, Val Acc=0.6215, Val Loss=1.6918, lr=0.0100
[2025-05-06 21:07:55,319][train][INFO] - Epoch 296/1000, Val Acc=0.6408, Val Loss=1.7559, lr=0.0100
[2025-05-06 21:08:02,162][train][INFO] - Epoch 300/1000, Val Acc=0.6172, Val Loss=1.7490, lr=0.0100
[2025-05-06 21:08:03,246][train][INFO] - Epoch 297/1000, Val Acc=0.6463, Val Loss=1.7101, lr=0.0100
[2025-05-06 21:08:09,943][train][INFO] - Epoch 301/1000, Val Acc=0.6295, Val Loss=1.6945, lr=0.0100
[2025-05-06 21:08:11,046][train][INFO] - Epoch 298/1000, Val Acc=0.6270, Val Loss=1.8030, lr=0.0100
[2025-05-06 21:08:18,258][train][INFO] - Epoch 302/1000, Val Acc=0.6258, Val Loss=1.6573, lr=0.0100
[2025-05-06 21:08:19,335][train][INFO] - Epoch 299/1000, Val Acc=0.6328, Val Loss=1.7751, lr=0.0100
[2025-05-06 21:08:26,269][train][INFO] - Epoch 303/1000, Val Acc=0.6239, Val Loss=1.7064, lr=0.0100
[2025-05-06 21:08:27,919][train][INFO] - Epoch 300/1000, Val Acc=0.6450, Val Loss=1.7315, lr=0.0100
[2025-05-06 21:08:34,205][train][INFO] - Epoch 304/1000, Val Acc=0.6056, Val Loss=1.7819, lr=0.0100
[2025-05-06 21:08:36,023][train][INFO] - Epoch 301/1000, Val Acc=0.6348, Val Loss=1.8275, lr=0.0100
[2025-05-06 21:08:42,593][train][INFO] - Epoch 305/1000, Val Acc=0.6135, Val Loss=1.7546, lr=0.0100
[2025-05-06 21:08:44,107][train][INFO] - Epoch 302/1000, Val Acc=0.6449, Val Loss=1.7112, lr=0.0100
[2025-05-06 21:08:50,452][train][INFO] - Epoch 306/1000, Val Acc=0.6317, Val Loss=1.6709, lr=0.0100
[2025-05-06 21:08:52,318][train][INFO] - Epoch 303/1000, Val Acc=0.6465, Val Loss=1.7202, lr=0.0100
[2025-05-06 21:08:58,907][train][INFO] - Epoch 307/1000, Val Acc=0.6248, Val Loss=1.7255, lr=0.0100
[2025-05-06 21:09:00,780][train][INFO] - Epoch 304/1000, Val Acc=0.6482, Val Loss=1.7052, lr=0.0100
[2025-05-06 21:09:06,990][train][INFO] - Epoch 308/1000, Val Acc=0.6337, Val Loss=1.6776, lr=0.0100
[2025-05-06 21:09:08,096][train][INFO] - Epoch 305/1000, Val Acc=0.6394, Val Loss=1.7648, lr=0.0100
[2025-05-06 21:09:15,273][train][INFO] - Epoch 309/1000, Val Acc=0.6140, Val Loss=1.7566, lr=0.0100
[2025-05-06 21:09:16,468][train][INFO] - Epoch 306/1000, Val Acc=0.6484, Val Loss=1.6976, lr=0.0100
[2025-05-06 21:09:23,332][train][INFO] - Epoch 310/1000, Val Acc=0.6173, Val Loss=1.7059, lr=0.0100
[2025-05-06 21:09:24,058][train][INFO] - Epoch 307/1000, Val Acc=0.6448, Val Loss=1.7017, lr=0.0100
[2025-05-06 21:09:30,870][train][INFO] - Epoch 311/1000, Val Acc=0.6261, Val Loss=1.6940, lr=0.0100
[2025-05-06 21:09:32,288][train][INFO] - Epoch 308/1000, Val Acc=0.6526, Val Loss=1.6854, lr=0.0100
[2025-05-06 21:09:38,540][train][INFO] - Epoch 312/1000, Val Acc=0.6180, Val Loss=1.6936, lr=0.0100
[2025-05-06 21:09:40,634][train][INFO] - Epoch 309/1000, Val Acc=0.6362, Val Loss=1.7963, lr=0.0100
[2025-05-06 21:09:46,752][train][INFO] - Epoch 313/1000, Val Acc=0.6144, Val Loss=1.7667, lr=0.0100
[2025-05-06 21:09:49,423][train][INFO] - Epoch 310/1000, Val Acc=0.6375, Val Loss=1.7764, lr=0.0100
[2025-05-06 21:09:54,304][train][INFO] - Epoch 314/1000, Val Acc=0.6196, Val Loss=1.7028, lr=0.0100
[2025-05-06 21:09:58,176][train][INFO] - Epoch 311/1000, Val Acc=0.6508, Val Loss=1.7267, lr=0.0100
[2025-05-06 21:10:01,770][train][INFO] - Epoch 315/1000, Val Acc=0.6144, Val Loss=1.7590, lr=0.0100
[2025-05-06 21:10:06,703][train][INFO] - Epoch 312/1000, Val Acc=0.6265, Val Loss=1.8596, lr=0.0100
[2025-05-06 21:10:09,513][train][INFO] - Epoch 316/1000, Val Acc=0.6223, Val Loss=1.7111, lr=0.0100
[2025-05-06 21:10:14,396][train][INFO] - Epoch 313/1000, Val Acc=0.6388, Val Loss=1.7799, lr=0.0100
[2025-05-06 21:10:17,746][train][INFO] - Epoch 317/1000, Val Acc=0.6218, Val Loss=1.6818, lr=0.0100
[2025-05-06 21:10:22,095][train][INFO] - Epoch 314/1000, Val Acc=0.6476, Val Loss=1.7431, lr=0.0100
[2025-05-06 21:10:25,271][train][INFO] - Epoch 318/1000, Val Acc=0.6204, Val Loss=1.7242, lr=0.0100
[2025-05-06 21:10:30,026][train][INFO] - Epoch 315/1000, Val Acc=0.6443, Val Loss=1.7231, lr=0.0100
[2025-05-06 21:10:33,560][train][INFO] - Epoch 319/1000, Val Acc=0.6309, Val Loss=1.6226, lr=0.0100
[2025-05-06 21:10:37,948][train][INFO] - Epoch 316/1000, Val Acc=0.6349, Val Loss=1.7805, lr=0.0100
[2025-05-06 21:10:42,086][train][INFO] - Epoch 320/1000, Val Acc=0.6161, Val Loss=1.7748, lr=0.0100
[2025-05-06 21:10:46,496][train][INFO] - Epoch 317/1000, Val Acc=0.6477, Val Loss=1.7168, lr=0.0100
[2025-05-06 21:10:50,509][train][INFO] - Epoch 321/1000, Val Acc=0.6338, Val Loss=1.6513, lr=0.0100
[2025-05-06 21:10:54,185][train][INFO] - Epoch 318/1000, Val Acc=0.6414, Val Loss=1.7867, lr=0.0100
[2025-05-06 21:10:58,701][train][INFO] - Epoch 322/1000, Val Acc=0.6169, Val Loss=1.7636, lr=0.0100
[2025-05-06 21:11:02,506][train][INFO] - Epoch 319/1000, Val Acc=0.6362, Val Loss=1.7282, lr=0.0100
[2025-05-06 21:11:05,849][train][INFO] - Epoch 323/1000, Val Acc=0.6168, Val Loss=1.7267, lr=0.0100
[2025-05-06 21:11:10,507][train][INFO] - Epoch 320/1000, Val Acc=0.6344, Val Loss=1.7786, lr=0.0100
[2025-05-06 21:11:14,323][train][INFO] - Epoch 324/1000, Val Acc=0.6202, Val Loss=1.7370, lr=0.0100
[2025-05-06 21:11:18,735][train][INFO] - Epoch 321/1000, Val Acc=0.6437, Val Loss=1.7196, lr=0.0100
[2025-05-06 21:11:22,701][train][INFO] - Epoch 325/1000, Val Acc=0.6266, Val Loss=1.6687, lr=0.0100
[2025-05-06 21:11:26,578][train][INFO] - Epoch 322/1000, Val Acc=0.6395, Val Loss=1.7838, lr=0.0100
[2025-05-06 21:11:31,039][train][INFO] - Epoch 326/1000, Val Acc=0.6346, Val Loss=1.6037, lr=0.0100
[2025-05-06 21:11:34,782][train][INFO] - Epoch 323/1000, Val Acc=0.6478, Val Loss=1.7047, lr=0.0100
[2025-05-06 21:11:39,176][train][INFO] - Epoch 327/1000, Val Acc=0.6217, Val Loss=1.7163, lr=0.0100
[2025-05-06 21:11:43,416][train][INFO] - Epoch 324/1000, Val Acc=0.6438, Val Loss=1.7460, lr=0.0100
[2025-05-06 21:11:47,256][train][INFO] - Epoch 328/1000, Val Acc=0.6266, Val Loss=1.6550, lr=0.0100
[2025-05-06 21:11:51,555][train][INFO] - Epoch 325/1000, Val Acc=0.6323, Val Loss=1.8181, lr=0.0100
[2025-05-06 21:11:55,641][train][INFO] - Epoch 329/1000, Val Acc=0.6235, Val Loss=1.6717, lr=0.0100
[2025-05-06 21:11:59,827][train][INFO] - Epoch 326/1000, Val Acc=0.6477, Val Loss=1.7105, lr=0.0100
[2025-05-06 21:12:03,138][train][INFO] - Epoch 330/1000, Val Acc=0.6265, Val Loss=1.6901, lr=0.0100
[2025-05-06 21:12:07,927][train][INFO] - Epoch 327/1000, Val Acc=0.6430, Val Loss=1.7313, lr=0.0100
[2025-05-06 21:12:11,303][train][INFO] - Epoch 331/1000, Val Acc=0.6204, Val Loss=1.6844, lr=0.0100
[2025-05-06 21:12:16,126][train][INFO] - Epoch 328/1000, Val Acc=0.6519, Val Loss=1.6847, lr=0.0100
[2025-05-06 21:12:19,357][train][INFO] - Epoch 332/1000, Val Acc=0.6162, Val Loss=1.7424, lr=0.0100
[2025-05-06 21:12:24,491][train][INFO] - Epoch 329/1000, Val Acc=0.6453, Val Loss=1.7241, lr=0.0100
[2025-05-06 21:12:27,160][train][INFO] - Epoch 333/1000, Val Acc=0.6281, Val Loss=1.6569, lr=0.0100
[2025-05-06 21:12:33,023][train][INFO] - Epoch 330/1000, Val Acc=0.6301, Val Loss=1.8202, lr=0.0100
[2025-05-06 21:12:35,231][train][INFO] - Epoch 334/1000, Val Acc=0.6047, Val Loss=1.7885, lr=0.0100
[2025-05-06 21:12:41,349][train][INFO] - Epoch 331/1000, Val Acc=0.6478, Val Loss=1.7193, lr=0.0100
[2025-05-06 21:12:43,039][train][INFO] - Epoch 335/1000, Val Acc=0.6185, Val Loss=1.7291, lr=0.0100
[2025-05-06 21:12:49,286][train][INFO] - Epoch 332/1000, Val Acc=0.6421, Val Loss=1.7888, lr=0.0100
[2025-05-06 21:12:51,012][train][INFO] - Epoch 336/1000, Val Acc=0.6277, Val Loss=1.6968, lr=0.0100
[2025-05-06 21:12:57,847][train][INFO] - Epoch 333/1000, Val Acc=0.6338, Val Loss=1.7670, lr=0.0100
[2025-05-06 21:12:58,490][train][INFO] - Epoch 337/1000, Val Acc=0.6221, Val Loss=1.6813, lr=0.0100
[2025-05-06 21:13:06,216][train][INFO] - Epoch 334/1000, Val Acc=0.6434, Val Loss=1.7419, lr=0.0100
[2025-05-06 21:13:06,754][train][INFO] - Epoch 338/1000, Val Acc=0.6198, Val Loss=1.7352, lr=0.0100
[2025-05-06 21:13:14,691][train][INFO] - Epoch 335/1000, Val Acc=0.6544, Val Loss=1.6827, lr=0.0100
[2025-05-06 21:13:14,886][train][INFO] - Epoch 339/1000, Val Acc=0.6147, Val Loss=1.7830, lr=0.0100
[2025-05-06 21:13:23,139][train][INFO] - Epoch 336/1000, Val Acc=0.6475, Val Loss=1.7078, lr=0.0100
[2025-05-06 21:13:23,162][train][INFO] - Epoch 340/1000, Val Acc=0.6129, Val Loss=1.7426, lr=0.0100
[2025-05-06 21:13:30,958][train][INFO] - Epoch 337/1000, Val Acc=0.6446, Val Loss=1.7251, lr=0.0100
[2025-05-06 21:13:31,192][train][INFO] - Epoch 341/1000, Val Acc=0.6303, Val Loss=1.6149, lr=0.0100
[2025-05-06 21:13:39,260][train][INFO] - Epoch 342/1000, Val Acc=0.6174, Val Loss=1.7401, lr=0.0100
[2025-05-06 21:13:39,586][train][INFO] - Epoch 338/1000, Val Acc=0.6376, Val Loss=1.7631, lr=0.0100
[2025-05-06 21:13:47,747][train][INFO] - Epoch 343/1000, Val Acc=0.6274, Val Loss=1.7076, lr=0.0100
[2025-05-06 21:13:48,478][train][INFO] - Epoch 339/1000, Val Acc=0.6441, Val Loss=1.7162, lr=0.0100
[2025-05-06 21:13:56,018][train][INFO] - Epoch 340/1000, Val Acc=0.6402, Val Loss=1.7332, lr=0.0100
[2025-05-06 21:13:56,401][train][INFO] - Epoch 344/1000, Val Acc=0.6306, Val Loss=1.6446, lr=0.0100
[2025-05-06 21:14:03,350][train][INFO] - Epoch 341/1000, Val Acc=0.6288, Val Loss=1.8291, lr=0.0100
[2025-05-06 21:14:04,819][train][INFO] - Epoch 345/1000, Val Acc=0.6196, Val Loss=1.7123, lr=0.0100
[2025-05-06 21:14:11,531][train][INFO] - Epoch 342/1000, Val Acc=0.6471, Val Loss=1.7228, lr=0.0100
[2025-05-06 21:14:12,829][train][INFO] - Epoch 346/1000, Val Acc=0.6284, Val Loss=1.6823, lr=0.0100
[2025-05-06 21:14:19,637][train][INFO] - Epoch 343/1000, Val Acc=0.6450, Val Loss=1.7500, lr=0.0100
[2025-05-06 21:14:21,031][train][INFO] - Epoch 347/1000, Val Acc=0.6225, Val Loss=1.6841, lr=0.0100
[2025-05-06 21:14:27,824][train][INFO] - Epoch 344/1000, Val Acc=0.6505, Val Loss=1.6891, lr=0.0100
[2025-05-06 21:14:28,858][train][INFO] - Epoch 348/1000, Val Acc=0.6222, Val Loss=1.7154, lr=0.0100
[2025-05-06 21:14:36,148][train][INFO] - Epoch 345/1000, Val Acc=0.6466, Val Loss=1.7115, lr=0.0100
[2025-05-06 21:14:36,935][train][INFO] - Epoch 349/1000, Val Acc=0.6332, Val Loss=1.6340, lr=0.0100
[2025-05-06 21:14:44,358][train][INFO] - Epoch 346/1000, Val Acc=0.6415, Val Loss=1.7731, lr=0.0100
[2025-05-06 21:14:45,337][train][INFO] - Epoch 350/1000, Val Acc=0.6229, Val Loss=1.6746, lr=0.0100
[2025-05-06 21:14:53,354][train][INFO] - Epoch 347/1000, Val Acc=0.6423, Val Loss=1.7812, lr=0.0100
[2025-05-06 21:14:54,025][train][INFO] - Epoch 351/1000, Val Acc=0.6276, Val Loss=1.6825, lr=0.0100
[2025-05-06 21:15:01,472][train][INFO] - Epoch 348/1000, Val Acc=0.6422, Val Loss=1.7390, lr=0.0100
[2025-05-06 21:15:02,323][train][INFO] - Epoch 352/1000, Val Acc=0.6244, Val Loss=1.7206, lr=0.0100
[2025-05-06 21:15:09,055][train][INFO] - Epoch 349/1000, Val Acc=0.6336, Val Loss=1.7855, lr=0.0100
[2025-05-06 21:15:10,492][train][INFO] - Epoch 353/1000, Val Acc=0.6267, Val Loss=1.7288, lr=0.0100
[2025-05-06 21:15:16,801][train][INFO] - Epoch 350/1000, Val Acc=0.6405, Val Loss=1.7554, lr=0.0100
[2025-05-06 21:15:18,515][train][INFO] - Epoch 354/1000, Val Acc=0.6230, Val Loss=1.7158, lr=0.0100
[2025-05-06 21:15:25,642][train][INFO] - Epoch 351/1000, Val Acc=0.6445, Val Loss=1.7412, lr=0.0100
[2025-05-06 21:15:26,206][train][INFO] - Epoch 355/1000, Val Acc=0.6237, Val Loss=1.6799, lr=0.0100
[2025-05-06 21:15:33,768][train][INFO] - Epoch 352/1000, Val Acc=0.6271, Val Loss=1.8807, lr=0.0100
[2025-05-06 21:15:34,534][train][INFO] - Epoch 356/1000, Val Acc=0.6181, Val Loss=1.7719, lr=0.0100
[2025-05-06 21:15:42,462][train][INFO] - Epoch 353/1000, Val Acc=0.6360, Val Loss=1.7568, lr=0.0100
[2025-05-06 21:15:42,789][train][INFO] - Epoch 357/1000, Val Acc=0.6249, Val Loss=1.6656, lr=0.0100
[2025-05-06 21:15:50,551][train][INFO] - Epoch 358/1000, Val Acc=0.6232, Val Loss=1.7364, lr=0.0100
[2025-05-06 21:15:50,720][train][INFO] - Epoch 354/1000, Val Acc=0.6474, Val Loss=1.7225, lr=0.0100
[2025-05-06 21:15:58,177][train][INFO] - Epoch 355/1000, Val Acc=0.6461, Val Loss=1.7024, lr=0.0100
[2025-05-06 21:15:58,433][train][INFO] - Epoch 359/1000, Val Acc=0.6264, Val Loss=1.7008, lr=0.0100
[2025-05-06 21:16:06,394][train][INFO] - Epoch 356/1000, Val Acc=0.6533, Val Loss=1.6941, lr=0.0100
[2025-05-06 21:16:06,451][train][INFO] - Epoch 360/1000, Val Acc=0.6216, Val Loss=1.7190, lr=0.0100
[2025-05-06 21:16:14,581][train][INFO] - Epoch 361/1000, Val Acc=0.6212, Val Loss=1.7331, lr=0.0100
[2025-05-06 21:16:14,788][train][INFO] - Epoch 357/1000, Val Acc=0.6459, Val Loss=1.7247, lr=0.0100
[2025-05-06 21:16:23,306][train][INFO] - Epoch 362/1000, Val Acc=0.6169, Val Loss=1.7586, lr=0.0100
[2025-05-06 21:16:23,564][train][INFO] - Epoch 358/1000, Val Acc=0.6299, Val Loss=1.8590, lr=0.0100
[2025-05-06 21:16:31,722][train][INFO] - Epoch 363/1000, Val Acc=0.6277, Val Loss=1.6639, lr=0.0100
[2025-05-06 21:16:32,118][train][INFO] - Epoch 359/1000, Val Acc=0.6508, Val Loss=1.7029, lr=0.0100
[2025-05-06 21:16:39,749][train][INFO] - Epoch 360/1000, Val Acc=0.6417, Val Loss=1.7695, lr=0.0100
[2025-05-06 21:16:40,120][train][INFO] - Epoch 364/1000, Val Acc=0.6337, Val Loss=1.6254, lr=0.0100
[2025-05-06 21:16:47,565][train][INFO] - Epoch 361/1000, Val Acc=0.6429, Val Loss=1.7775, lr=0.0100
[2025-05-06 21:16:48,467][train][INFO] - Epoch 365/1000, Val Acc=0.6346, Val Loss=1.6578, lr=0.0100
[2025-05-06 21:16:56,006][train][INFO] - Epoch 362/1000, Val Acc=0.6443, Val Loss=1.7495, lr=0.0100
[2025-05-06 21:16:56,770][train][INFO] - Epoch 366/1000, Val Acc=0.6259, Val Loss=1.6649, lr=0.0100
[2025-05-06 21:17:04,274][train][INFO] - Epoch 363/1000, Val Acc=0.6457, Val Loss=1.6949, lr=0.0100
[2025-05-06 21:17:05,138][train][INFO] - Epoch 367/1000, Val Acc=0.6285, Val Loss=1.6817, lr=0.0100
[2025-05-06 21:17:12,292][train][INFO] - Epoch 368/1000, Val Acc=0.6314, Val Loss=1.6358, lr=0.0100
[2025-05-06 21:17:12,832][train][INFO] - Epoch 364/1000, Val Acc=0.6449, Val Loss=1.7234, lr=0.0100
[2025-05-06 21:17:20,135][train][INFO] - Epoch 369/1000, Val Acc=0.6139, Val Loss=1.7927, lr=0.0100
[2025-05-06 21:17:20,974][train][INFO] - Epoch 365/1000, Val Acc=0.6544, Val Loss=1.6615, lr=0.0100
[2025-05-06 21:17:28,013][train][INFO] - Epoch 370/1000, Val Acc=0.6200, Val Loss=1.7167, lr=0.0100
[2025-05-06 21:17:28,406][train][INFO] - Epoch 366/1000, Val Acc=0.6393, Val Loss=1.7655, lr=0.0100
[2025-05-06 21:17:36,096][train][INFO] - Epoch 371/1000, Val Acc=0.6300, Val Loss=1.6347, lr=0.0100
[2025-05-06 21:17:36,836][train][INFO] - Epoch 367/1000, Val Acc=0.6402, Val Loss=1.7564, lr=0.0100
[2025-05-06 21:17:44,790][train][INFO] - Epoch 372/1000, Val Acc=0.6364, Val Loss=1.6565, lr=0.0100
[2025-05-06 21:17:45,041][train][INFO] - Epoch 368/1000, Val Acc=0.6263, Val Loss=1.8432, lr=0.0100
[2025-05-06 21:17:52,151][train][INFO] - Epoch 373/1000, Val Acc=0.6261, Val Loss=1.6875, lr=0.0100
[2025-05-06 21:17:53,453][train][INFO] - Epoch 369/1000, Val Acc=0.6368, Val Loss=1.7601, lr=0.0100
[2025-05-06 21:17:59,076][train][INFO] - Epoch 374/1000, Val Acc=0.6235, Val Loss=1.6890, lr=0.0100
[2025-05-06 21:18:01,758][train][INFO] - Epoch 370/1000, Val Acc=0.6422, Val Loss=1.7418, lr=0.0100
[2025-05-06 21:18:07,290][train][INFO] - Epoch 375/1000, Val Acc=0.6168, Val Loss=1.7438, lr=0.0100
[2025-05-06 21:18:09,680][train][INFO] - Epoch 371/1000, Val Acc=0.6474, Val Loss=1.7168, lr=0.0100
[2025-05-06 21:18:15,308][train][INFO] - Epoch 376/1000, Val Acc=0.6244, Val Loss=1.7081, lr=0.0100
[2025-05-06 21:18:17,987][train][INFO] - Epoch 372/1000, Val Acc=0.6390, Val Loss=1.7875, lr=0.0100
[2025-05-06 21:18:23,570][train][INFO] - Epoch 377/1000, Val Acc=0.6326, Val Loss=1.6599, lr=0.0100
[2025-05-06 21:18:26,366][train][INFO] - Epoch 373/1000, Val Acc=0.6315, Val Loss=1.7799, lr=0.0100
[2025-05-06 21:18:31,817][train][INFO] - Epoch 378/1000, Val Acc=0.6253, Val Loss=1.7140, lr=0.0100
[2025-05-06 21:18:34,325][train][INFO] - Epoch 374/1000, Val Acc=0.6449, Val Loss=1.7431, lr=0.0100
[2025-05-06 21:18:40,054][train][INFO] - Epoch 379/1000, Val Acc=0.6293, Val Loss=1.6826, lr=0.0100
[2025-05-06 21:18:42,544][train][INFO] - Epoch 375/1000, Val Acc=0.6414, Val Loss=1.7872, lr=0.0100
[2025-05-06 21:18:48,405][train][INFO] - Epoch 380/1000, Val Acc=0.6337, Val Loss=1.6407, lr=0.0100
[2025-05-06 21:18:51,160][train][INFO] - Epoch 376/1000, Val Acc=0.6360, Val Loss=1.7650, lr=0.0100
[2025-05-06 21:18:56,019][train][INFO] - Epoch 381/1000, Val Acc=0.6306, Val Loss=1.6516, lr=0.0100
[2025-05-06 21:18:59,388][train][INFO] - Epoch 377/1000, Val Acc=0.6449, Val Loss=1.7206, lr=0.0100
[2025-05-06 21:19:04,038][train][INFO] - Epoch 382/1000, Val Acc=0.6174, Val Loss=1.7449, lr=0.0100
[2025-05-06 21:19:07,856][train][INFO] - Epoch 378/1000, Val Acc=0.6241, Val Loss=1.8534, lr=0.0100
[2025-05-06 21:19:12,096][train][INFO] - Epoch 383/1000, Val Acc=0.6062, Val Loss=1.7924, lr=0.0100
[2025-05-06 21:19:15,441][train][INFO] - Epoch 379/1000, Val Acc=0.6459, Val Loss=1.7160, lr=0.0100
[2025-05-06 21:19:20,237][train][INFO] - Epoch 384/1000, Val Acc=0.6152, Val Loss=1.7324, lr=0.0100
[2025-05-06 21:19:23,677][train][INFO] - Epoch 380/1000, Val Acc=0.6489, Val Loss=1.7170, lr=0.0100
[2025-05-06 21:19:28,060][train][INFO] - Epoch 385/1000, Val Acc=0.6321, Val Loss=1.6556, lr=0.0100
[2025-05-06 21:19:31,545][train][INFO] - Epoch 381/1000, Val Acc=0.6372, Val Loss=1.7730, lr=0.0100
[2025-05-06 21:19:36,048][train][INFO] - Epoch 386/1000, Val Acc=0.6335, Val Loss=1.6495, lr=0.0100
[2025-05-06 21:19:40,025][train][INFO] - Epoch 382/1000, Val Acc=0.6533, Val Loss=1.6905, lr=0.0100
[2025-05-06 21:19:43,877][train][INFO] - Epoch 387/1000, Val Acc=0.6151, Val Loss=1.7430, lr=0.0100
[2025-05-06 21:19:47,838][train][INFO] - Epoch 383/1000, Val Acc=0.6516, Val Loss=1.6632, lr=0.0100
[2025-05-06 21:19:51,815][train][INFO] - Epoch 388/1000, Val Acc=0.6361, Val Loss=1.6586, lr=0.0100
[2025-05-06 21:19:55,789][train][INFO] - Epoch 384/1000, Val Acc=0.6501, Val Loss=1.7454, lr=0.0100
[2025-05-06 21:20:00,384][train][INFO] - Epoch 389/1000, Val Acc=0.6288, Val Loss=1.6994, lr=0.0100
[2025-05-06 21:20:03,485][train][INFO] - Epoch 385/1000, Val Acc=0.6318, Val Loss=1.7850, lr=0.0100
[2025-05-06 21:20:08,274][train][INFO] - Epoch 390/1000, Val Acc=0.6328, Val Loss=1.6789, lr=0.0100
[2025-05-06 21:20:10,760][train][INFO] - Epoch 386/1000, Val Acc=0.6439, Val Loss=1.7682, lr=0.0100
[2025-05-06 21:20:16,356][train][INFO] - Epoch 391/1000, Val Acc=0.6225, Val Loss=1.7275, lr=0.0100
[2025-05-06 21:20:18,941][train][INFO] - Epoch 387/1000, Val Acc=0.6368, Val Loss=1.8057, lr=0.0100
[2025-05-06 21:20:24,586][train][INFO] - Epoch 392/1000, Val Acc=0.6125, Val Loss=1.7773, lr=0.0100
[2025-05-06 21:20:26,630][train][INFO] - Epoch 388/1000, Val Acc=0.6442, Val Loss=1.7179, lr=0.0100
[2025-05-06 21:20:32,243][train][INFO] - Epoch 393/1000, Val Acc=0.6154, Val Loss=1.7595, lr=0.0100
[2025-05-06 21:20:35,095][train][INFO] - Epoch 389/1000, Val Acc=0.6320, Val Loss=1.8529, lr=0.0100
[2025-05-06 21:20:39,870][train][INFO] - Epoch 394/1000, Val Acc=0.6032, Val Loss=1.7765, lr=0.0100
[2025-05-06 21:20:43,517][train][INFO] - Epoch 390/1000, Val Acc=0.6269, Val Loss=1.8861, lr=0.0100
[2025-05-06 21:20:47,616][train][INFO] - Epoch 395/1000, Val Acc=0.6295, Val Loss=1.6819, lr=0.0100
[2025-05-06 21:20:51,708][train][INFO] - Epoch 391/1000, Val Acc=0.6501, Val Loss=1.6941, lr=0.0100
[2025-05-06 21:20:55,295][train][INFO] - Epoch 396/1000, Val Acc=0.6130, Val Loss=1.7244, lr=0.0100
[2025-05-06 21:20:59,803][train][INFO] - Epoch 392/1000, Val Acc=0.6550, Val Loss=1.6627, lr=0.0100
[2025-05-06 21:21:02,388][train][INFO] - Epoch 397/1000, Val Acc=0.6164, Val Loss=1.7496, lr=0.0100
[2025-05-06 21:21:08,374][train][INFO] - Epoch 393/1000, Val Acc=0.6499, Val Loss=1.7170, lr=0.0100
[2025-05-06 21:21:10,085][train][INFO] - Epoch 398/1000, Val Acc=0.6292, Val Loss=1.7121, lr=0.0100
[2025-05-06 21:21:16,427][train][INFO] - Epoch 394/1000, Val Acc=0.6474, Val Loss=1.7174, lr=0.0100
[2025-05-06 21:21:18,349][train][INFO] - Epoch 399/1000, Val Acc=0.6290, Val Loss=1.7302, lr=0.0100
[2025-05-06 21:21:23,991][train][INFO] - Epoch 395/1000, Val Acc=0.6450, Val Loss=1.7187, lr=0.0100
[2025-05-06 21:21:26,042][train][INFO] - Epoch 400/1000, Val Acc=0.6064, Val Loss=1.8011, lr=0.0100
[2025-05-06 21:21:32,388][train][INFO] - Epoch 396/1000, Val Acc=0.6478, Val Loss=1.6957, lr=0.0100
[2025-05-06 21:21:34,270][train][INFO] - Epoch 401/1000, Val Acc=0.6351, Val Loss=1.6723, lr=0.0100
[2025-05-06 21:21:40,747][train][INFO] - Epoch 397/1000, Val Acc=0.6473, Val Loss=1.7140, lr=0.0100
[2025-05-06 21:21:41,810][train][INFO] - Epoch 402/1000, Val Acc=0.6087, Val Loss=1.8179, lr=0.0100
[2025-05-06 21:21:49,049][train][INFO] - Epoch 398/1000, Val Acc=0.6449, Val Loss=1.7258, lr=0.0100
[2025-05-06 21:21:50,046][train][INFO] - Epoch 403/1000, Val Acc=0.6187, Val Loss=1.7382, lr=0.0100
[2025-05-06 21:21:56,320][train][INFO] - Epoch 399/1000, Val Acc=0.6448, Val Loss=1.7048, lr=0.0100
[2025-05-06 21:21:58,428][train][INFO] - Epoch 404/1000, Val Acc=0.6228, Val Loss=1.7151, lr=0.0100
[2025-05-06 21:22:04,353][train][INFO] - Epoch 400/1000, Val Acc=0.6414, Val Loss=1.7193, lr=0.0100
[2025-05-06 21:22:06,470][train][INFO] - Epoch 405/1000, Val Acc=0.6379, Val Loss=1.6398, lr=0.0100
[2025-05-06 21:22:12,650][train][INFO] - Epoch 401/1000, Val Acc=0.6461, Val Loss=1.7657, lr=0.0100
[2025-05-06 21:22:14,593][train][INFO] - Epoch 406/1000, Val Acc=0.6290, Val Loss=1.7069, lr=0.0100
[2025-05-06 21:22:20,901][train][INFO] - Epoch 402/1000, Val Acc=0.6338, Val Loss=1.8082, lr=0.0100
[2025-05-06 21:22:23,082][train][INFO] - Epoch 407/1000, Val Acc=0.6245, Val Loss=1.7084, lr=0.0100
[2025-05-06 21:22:29,680][train][INFO] - Epoch 403/1000, Val Acc=0.6460, Val Loss=1.7089, lr=0.0100
[2025-05-06 21:22:31,476][train][INFO] - Epoch 408/1000, Val Acc=0.6226, Val Loss=1.7210, lr=0.0100
[2025-05-06 21:22:37,558][train][INFO] - Epoch 404/1000, Val Acc=0.6499, Val Loss=1.7043, lr=0.0100
[2025-05-06 21:22:39,974][train][INFO] - Epoch 409/1000, Val Acc=0.6205, Val Loss=1.7584, lr=0.0100
[2025-05-06 21:22:46,064][train][INFO] - Epoch 405/1000, Val Acc=0.6314, Val Loss=1.8481, lr=0.0100
[2025-05-06 21:22:48,138][train][INFO] - Epoch 410/1000, Val Acc=0.6285, Val Loss=1.6748, lr=0.0100
[2025-05-06 21:22:54,453][train][INFO] - Epoch 406/1000, Val Acc=0.6392, Val Loss=1.7590, lr=0.0100
[2025-05-06 21:22:56,495][train][INFO] - Epoch 411/1000, Val Acc=0.6248, Val Loss=1.6888, lr=0.0100
[2025-05-06 21:23:02,803][train][INFO] - Epoch 407/1000, Val Acc=0.6343, Val Loss=1.8132, lr=0.0100
[2025-05-06 21:23:04,753][train][INFO] - Epoch 412/1000, Val Acc=0.6252, Val Loss=1.7328, lr=0.0100
[2025-05-06 21:23:10,913][train][INFO] - Epoch 408/1000, Val Acc=0.6369, Val Loss=1.8086, lr=0.0100
[2025-05-06 21:23:12,737][train][INFO] - Epoch 413/1000, Val Acc=0.6287, Val Loss=1.7047, lr=0.0100
[2025-05-06 21:23:18,251][train][INFO] - Epoch 409/1000, Val Acc=0.6438, Val Loss=1.7266, lr=0.0100
[2025-05-06 21:23:19,873][train][INFO] - Epoch 414/1000, Val Acc=0.6161, Val Loss=1.7771, lr=0.0100
[2025-05-06 21:23:26,511][train][INFO] - Epoch 410/1000, Val Acc=0.6429, Val Loss=1.7505, lr=0.0100
[2025-05-06 21:23:28,184][train][INFO] - Epoch 415/1000, Val Acc=0.6373, Val Loss=1.6379, lr=0.0100
[2025-05-06 21:23:34,432][train][INFO] - Epoch 411/1000, Val Acc=0.6465, Val Loss=1.7264, lr=0.0100
[2025-05-06 21:23:35,610][train][INFO] - Epoch 416/1000, Val Acc=0.6283, Val Loss=1.6790, lr=0.0100
[2025-05-06 21:23:42,363][train][INFO] - Epoch 412/1000, Val Acc=0.6337, Val Loss=1.7941, lr=0.0100
[2025-05-06 21:23:42,824][train][INFO] - Epoch 417/1000, Val Acc=0.6193, Val Loss=1.7239, lr=0.0100
[2025-05-06 21:23:51,001][train][INFO] - Epoch 413/1000, Val Acc=0.6423, Val Loss=1.7437, lr=0.0100
[2025-05-06 21:23:51,129][train][INFO] - Epoch 418/1000, Val Acc=0.6271, Val Loss=1.6906, lr=0.0100
[2025-05-06 21:23:59,189][train][INFO] - Epoch 414/1000, Val Acc=0.6362, Val Loss=1.7559, lr=0.0100
[2025-05-06 21:23:59,619][train][INFO] - Epoch 419/1000, Val Acc=0.6353, Val Loss=1.6612, lr=0.0100
[2025-05-06 21:24:06,807][train][INFO] - Epoch 415/1000, Val Acc=0.6508, Val Loss=1.6801, lr=0.0100
[2025-05-06 21:24:08,003][train][INFO] - Epoch 420/1000, Val Acc=0.6359, Val Loss=1.6569, lr=0.0100
[2025-05-06 21:24:15,140][train][INFO] - Epoch 416/1000, Val Acc=0.6438, Val Loss=1.7706, lr=0.0100
[2025-05-06 21:24:16,140][train][INFO] - Epoch 421/1000, Val Acc=0.6245, Val Loss=1.7095, lr=0.0100
[2025-05-06 21:24:23,460][train][INFO] - Epoch 417/1000, Val Acc=0.6358, Val Loss=1.8004, lr=0.0100
[2025-05-06 21:24:24,902][train][INFO] - Epoch 422/1000, Val Acc=0.6279, Val Loss=1.6862, lr=0.0100
[2025-05-06 21:24:31,989][train][INFO] - Epoch 418/1000, Val Acc=0.6344, Val Loss=1.7517, lr=0.0100
[2025-05-06 21:24:33,075][train][INFO] - Epoch 423/1000, Val Acc=0.6206, Val Loss=1.7541, lr=0.0100
[2025-05-06 21:24:40,390][train][INFO] - Epoch 419/1000, Val Acc=0.6355, Val Loss=1.7952, lr=0.0100
[2025-05-06 21:24:41,120][train][INFO] - Epoch 424/1000, Val Acc=0.6281, Val Loss=1.7215, lr=0.0100
[2025-05-06 21:24:48,189][train][INFO] - Epoch 420/1000, Val Acc=0.6498, Val Loss=1.7127, lr=0.0100
[2025-05-06 21:24:49,480][train][INFO] - Epoch 425/1000, Val Acc=0.6369, Val Loss=1.6700, lr=0.0100
[2025-05-06 21:24:56,253][train][INFO] - Epoch 421/1000, Val Acc=0.6505, Val Loss=1.7230, lr=0.0100
[2025-05-06 21:24:58,047][train][INFO] - Epoch 426/1000, Val Acc=0.6286, Val Loss=1.6960, lr=0.0100
[2025-05-06 21:25:04,535][train][INFO] - Epoch 422/1000, Val Acc=0.6412, Val Loss=1.7485, lr=0.0100
[2025-05-06 21:25:06,383][train][INFO] - Epoch 427/1000, Val Acc=0.6306, Val Loss=1.6389, lr=0.0100
[2025-05-06 21:25:12,463][train][INFO] - Epoch 423/1000, Val Acc=0.6507, Val Loss=1.6611, lr=0.0100
[2025-05-06 21:25:14,445][train][INFO] - Epoch 428/1000, Val Acc=0.6245, Val Loss=1.7330, lr=0.0100
[2025-05-06 21:25:20,892][train][INFO] - Epoch 424/1000, Val Acc=0.6384, Val Loss=1.7606, lr=0.0100
[2025-05-06 21:25:22,556][train][INFO] - Epoch 429/1000, Val Acc=0.6265, Val Loss=1.7479, lr=0.0100
[2025-05-06 21:25:29,168][train][INFO] - Epoch 425/1000, Val Acc=0.6338, Val Loss=1.7659, lr=0.0100
[2025-05-06 21:25:30,562][train][INFO] - Epoch 430/1000, Val Acc=0.6292, Val Loss=1.7022, lr=0.0100
[2025-05-06 21:25:36,436][train][INFO] - Epoch 426/1000, Val Acc=0.6482, Val Loss=1.7133, lr=0.0100
[2025-05-06 21:25:38,431][train][INFO] - Epoch 431/1000, Val Acc=0.6087, Val Loss=1.8132, lr=0.0100
[2025-05-06 21:25:44,816][train][INFO] - Epoch 427/1000, Val Acc=0.6428, Val Loss=1.7144, lr=0.0100
[2025-05-06 21:25:46,193][train][INFO] - Epoch 432/1000, Val Acc=0.6222, Val Loss=1.7572, lr=0.0100
[2025-05-06 21:25:52,969][train][INFO] - Epoch 428/1000, Val Acc=0.6468, Val Loss=1.7320, lr=0.0100
[2025-05-06 21:25:54,435][train][INFO] - Epoch 433/1000, Val Acc=0.6389, Val Loss=1.6441, lr=0.0100
[2025-05-06 21:26:01,245][train][INFO] - Epoch 429/1000, Val Acc=0.6529, Val Loss=1.6487, lr=0.0100
[2025-05-06 21:26:01,298][train][INFO] - Epoch 434/1000, Val Acc=0.6281, Val Loss=1.6921, lr=0.0100
[2025-05-06 21:26:09,277][train][INFO] - Epoch 430/1000, Val Acc=0.6305, Val Loss=1.8027, lr=0.0100
[2025-05-06 21:26:09,697][train][INFO] - Epoch 435/1000, Val Acc=0.6214, Val Loss=1.7126, lr=0.0100
[2025-05-06 21:26:17,046][train][INFO] - Epoch 431/1000, Val Acc=0.6373, Val Loss=1.7547, lr=0.0100
[2025-05-06 21:26:17,740][train][INFO] - Epoch 436/1000, Val Acc=0.6125, Val Loss=1.7686, lr=0.0100
[2025-05-06 21:26:25,449][train][INFO] - Epoch 432/1000, Val Acc=0.6435, Val Loss=1.7139, lr=0.0100
[2025-05-06 21:26:25,732][train][INFO] - Epoch 437/1000, Val Acc=0.6322, Val Loss=1.6490, lr=0.0100
[2025-05-06 21:26:33,469][train][INFO] - Epoch 433/1000, Val Acc=0.6531, Val Loss=1.6817, lr=0.0100
[2025-05-06 21:26:33,722][train][INFO] - Epoch 438/1000, Val Acc=0.6210, Val Loss=1.7236, lr=0.0100
[2025-05-06 21:26:41,720][train][INFO] - Epoch 439/1000, Val Acc=0.6215, Val Loss=1.7063, lr=0.0100
[2025-05-06 21:26:42,155][train][INFO] - Epoch 434/1000, Val Acc=0.6414, Val Loss=1.7383, lr=0.0100
[2025-05-06 21:26:50,245][train][INFO] - Epoch 440/1000, Val Acc=0.6340, Val Loss=1.6888, lr=0.0100
[2025-05-06 21:26:50,560][train][INFO] - Epoch 435/1000, Val Acc=0.6352, Val Loss=1.8181, lr=0.0100
[2025-05-06 21:26:58,435][train][INFO] - Epoch 441/1000, Val Acc=0.6225, Val Loss=1.7496, lr=0.0100
[2025-05-06 21:26:58,709][train][INFO] - Epoch 436/1000, Val Acc=0.6311, Val Loss=1.8008, lr=0.0100
[2025-05-06 21:27:06,739][train][INFO] - Epoch 442/1000, Val Acc=0.6376, Val Loss=1.6516, lr=0.0100
[2025-05-06 21:27:06,956][train][INFO] - Epoch 437/1000, Val Acc=0.6525, Val Loss=1.7259, lr=0.0100
[2025-05-06 21:27:14,813][train][INFO] - Epoch 443/1000, Val Acc=0.6271, Val Loss=1.6940, lr=0.0100
[2025-05-06 21:27:14,881][train][INFO] - Epoch 438/1000, Val Acc=0.6293, Val Loss=1.8378, lr=0.0100
[2025-05-06 21:27:22,688][train][INFO] - Epoch 444/1000, Val Acc=0.6220, Val Loss=1.7289, lr=0.0100
[2025-05-06 21:27:22,751][train][INFO] - Epoch 439/1000, Val Acc=0.6595, Val Loss=1.6336, lr=0.0100
[2025-05-06 21:27:30,646][train][INFO] - Epoch 440/1000, Val Acc=0.6439, Val Loss=1.7392, lr=0.0100
[2025-05-06 21:27:31,000][train][INFO] - Epoch 445/1000, Val Acc=0.6195, Val Loss=1.7584, lr=0.0100
[2025-05-06 21:27:39,144][train][INFO] - Epoch 441/1000, Val Acc=0.6226, Val Loss=1.8940, lr=0.0100
[2025-05-06 21:27:39,198][train][INFO] - Epoch 446/1000, Val Acc=0.6098, Val Loss=1.7846, lr=0.0100
[2025-05-06 21:27:47,311][train][INFO] - Epoch 447/1000, Val Acc=0.6315, Val Loss=1.7194, lr=0.0100
[2025-05-06 21:27:47,609][train][INFO] - Epoch 442/1000, Val Acc=0.6313, Val Loss=1.7742, lr=0.0100
[2025-05-06 21:27:55,414][train][INFO] - Epoch 448/1000, Val Acc=0.6251, Val Loss=1.6925, lr=0.0100
[2025-05-06 21:27:56,007][train][INFO] - Epoch 443/1000, Val Acc=0.6484, Val Loss=1.6765, lr=0.0100
[2025-05-06 21:28:03,135][train][INFO] - Epoch 449/1000, Val Acc=0.6261, Val Loss=1.7404, lr=0.0100
[2025-05-06 21:28:04,230][train][INFO] - Epoch 444/1000, Val Acc=0.6428, Val Loss=1.7304, lr=0.0100
[2025-05-06 21:28:10,792][train][INFO] - Epoch 450/1000, Val Acc=0.6324, Val Loss=1.6982, lr=0.0100
[2025-05-06 21:28:12,077][train][INFO] - Epoch 445/1000, Val Acc=0.6282, Val Loss=1.8827, lr=0.0100
[2025-05-06 21:28:18,726][train][INFO] - Epoch 451/1000, Val Acc=0.6336, Val Loss=1.6925, lr=0.0100
[2025-05-06 21:28:20,656][train][INFO] - Epoch 446/1000, Val Acc=0.6421, Val Loss=1.7669, lr=0.0100
[2025-05-06 21:28:26,579][train][INFO] - Epoch 452/1000, Val Acc=0.6275, Val Loss=1.6889, lr=0.0100
[2025-05-06 21:28:28,724][train][INFO] - Epoch 447/1000, Val Acc=0.6461, Val Loss=1.7181, lr=0.0100
[2025-05-06 21:28:34,530][train][INFO] - Epoch 453/1000, Val Acc=0.6296, Val Loss=1.6994, lr=0.0100
[2025-05-06 21:28:37,072][train][INFO] - Epoch 448/1000, Val Acc=0.6553, Val Loss=1.6381, lr=0.0100
[2025-05-06 21:28:42,836][train][INFO] - Epoch 454/1000, Val Acc=0.6140, Val Loss=1.8022, lr=0.0100
[2025-05-06 21:28:45,677][train][INFO] - Epoch 449/1000, Val Acc=0.6465, Val Loss=1.7275, lr=0.0100
[2025-05-06 21:28:51,203][train][INFO] - Epoch 455/1000, Val Acc=0.6407, Val Loss=1.6533, lr=0.0100
[2025-05-06 21:28:53,844][train][INFO] - Epoch 450/1000, Val Acc=0.6457, Val Loss=1.7298, lr=0.0100
[2025-05-06 21:28:59,649][train][INFO] - Epoch 456/1000, Val Acc=0.6021, Val Loss=1.9144, lr=0.0100
[2025-05-06 21:29:02,500][train][INFO] - Epoch 451/1000, Val Acc=0.6279, Val Loss=1.8649, lr=0.0100
[2025-05-06 21:29:07,031][train][INFO] - Epoch 457/1000, Val Acc=0.6192, Val Loss=1.7787, lr=0.0100
[2025-05-06 21:29:11,075][train][INFO] - Epoch 452/1000, Val Acc=0.6361, Val Loss=1.7772, lr=0.0100
[2025-05-06 21:29:14,682][train][INFO] - Epoch 458/1000, Val Acc=0.6204, Val Loss=1.7479, lr=0.0100
[2025-05-06 21:29:19,532][train][INFO] - Epoch 453/1000, Val Acc=0.6420, Val Loss=1.7305, lr=0.0100
[2025-05-06 21:29:22,743][train][INFO] - Epoch 459/1000, Val Acc=0.6340, Val Loss=1.6591, lr=0.0100
[2025-05-06 21:29:26,739][train][INFO] - Epoch 454/1000, Val Acc=0.6522, Val Loss=1.7103, lr=0.0100
[2025-05-06 21:29:30,596][train][INFO] - Epoch 460/1000, Val Acc=0.6171, Val Loss=1.7726, lr=0.0100
[2025-05-06 21:29:35,073][train][INFO] - Epoch 455/1000, Val Acc=0.6464, Val Loss=1.7502, lr=0.0100
[2025-05-06 21:29:38,241][train][INFO] - Epoch 461/1000, Val Acc=0.6351, Val Loss=1.6486, lr=0.0100
[2025-05-06 21:29:44,045][train][INFO] - Epoch 456/1000, Val Acc=0.6530, Val Loss=1.6887, lr=0.0100
[2025-05-06 21:29:47,681][train][INFO] - Epoch 462/1000, Val Acc=0.6293, Val Loss=1.6885, lr=0.0100
[2025-05-06 21:29:52,933][train][INFO] - Epoch 457/1000, Val Acc=0.6440, Val Loss=1.7825, lr=0.0100
[2025-05-06 21:29:55,982][train][INFO] - Epoch 463/1000, Val Acc=0.6333, Val Loss=1.6869, lr=0.0100
[2025-05-06 21:30:01,073][train][INFO] - Epoch 458/1000, Val Acc=0.6367, Val Loss=1.7611, lr=0.0100
[2025-05-06 21:30:03,975][train][INFO] - Epoch 464/1000, Val Acc=0.6342, Val Loss=1.7332, lr=0.0100
[2025-05-06 21:30:09,446][train][INFO] - Epoch 459/1000, Val Acc=0.6522, Val Loss=1.7049, lr=0.0100
[2025-05-06 21:30:12,261][train][INFO] - Epoch 465/1000, Val Acc=0.6331, Val Loss=1.6848, lr=0.0100
[2025-05-06 21:30:17,478][train][INFO] - Epoch 460/1000, Val Acc=0.6388, Val Loss=1.7349, lr=0.0100
[2025-05-06 21:30:20,626][train][INFO] - Epoch 466/1000, Val Acc=0.6393, Val Loss=1.6464, lr=0.0100
[2025-05-06 21:30:25,387][train][INFO] - Epoch 461/1000, Val Acc=0.6457, Val Loss=1.7456, lr=0.0100
[2025-05-06 21:30:28,803][train][INFO] - Epoch 467/1000, Val Acc=0.6355, Val Loss=1.6391, lr=0.0100
[2025-05-06 21:30:33,584][train][INFO] - Epoch 462/1000, Val Acc=0.6495, Val Loss=1.7150, lr=0.0100
[2025-05-06 21:30:37,298][train][INFO] - Epoch 468/1000, Val Acc=0.6312, Val Loss=1.6801, lr=0.0100
[2025-05-06 21:30:42,076][train][INFO] - Epoch 463/1000, Val Acc=0.6521, Val Loss=1.7293, lr=0.0100
[2025-05-06 21:30:45,643][train][INFO] - Epoch 469/1000, Val Acc=0.6343, Val Loss=1.6584, lr=0.0100
[2025-05-06 21:30:49,632][train][INFO] - Epoch 464/1000, Val Acc=0.6327, Val Loss=1.8275, lr=0.0100
[2025-05-06 21:30:54,192][train][INFO] - Epoch 470/1000, Val Acc=0.6339, Val Loss=1.6793, lr=0.0100
[2025-05-06 21:30:57,816][train][INFO] - Epoch 465/1000, Val Acc=0.6457, Val Loss=1.7080, lr=0.0100
[2025-05-06 21:31:02,485][train][INFO] - Epoch 471/1000, Val Acc=0.6220, Val Loss=1.7910, lr=0.0100
[2025-05-06 21:31:06,470][train][INFO] - Epoch 466/1000, Val Acc=0.6520, Val Loss=1.7327, lr=0.0100
[2025-05-06 21:31:09,817][train][INFO] - Epoch 472/1000, Val Acc=0.6316, Val Loss=1.6862, lr=0.0100
[2025-05-06 21:31:13,938][train][INFO] - Epoch 467/1000, Val Acc=0.6277, Val Loss=1.8513, lr=0.0100
[2025-05-06 21:31:17,781][train][INFO] - Epoch 473/1000, Val Acc=0.6374, Val Loss=1.6534, lr=0.0100
[2025-05-06 21:31:21,871][train][INFO] - Epoch 468/1000, Val Acc=0.6502, Val Loss=1.6947, lr=0.0100
[2025-05-06 21:31:25,027][train][INFO] - Epoch 474/1000, Val Acc=0.6162, Val Loss=1.7989, lr=0.0100
[2025-05-06 21:31:28,967][train][INFO] - Epoch 469/1000, Val Acc=0.6438, Val Loss=1.7597, lr=0.0100
[2025-05-06 21:31:32,619][train][INFO] - Epoch 475/1000, Val Acc=0.6191, Val Loss=1.7430, lr=0.0100
[2025-05-06 21:31:37,212][train][INFO] - Epoch 470/1000, Val Acc=0.6518, Val Loss=1.7419, lr=0.0100
[2025-05-06 21:31:40,103][train][INFO] - Epoch 476/1000, Val Acc=0.6228, Val Loss=1.7164, lr=0.0100
[2025-05-06 21:31:45,202][train][INFO] - Epoch 471/1000, Val Acc=0.6497, Val Loss=1.7311, lr=0.0100
[2025-05-06 21:31:47,552][train][INFO] - Epoch 477/1000, Val Acc=0.6272, Val Loss=1.7166, lr=0.0100
[2025-05-06 21:31:53,491][train][INFO] - Epoch 472/1000, Val Acc=0.6393, Val Loss=1.7377, lr=0.0100
[2025-05-06 21:31:55,803][train][INFO] - Epoch 478/1000, Val Acc=0.6240, Val Loss=1.7763, lr=0.0100
[2025-05-06 21:32:02,209][train][INFO] - Epoch 473/1000, Val Acc=0.6439, Val Loss=1.7622, lr=0.0100
[2025-05-06 21:32:02,960][train][INFO] - Epoch 479/1000, Val Acc=0.6359, Val Loss=1.6660, lr=0.0100
[2025-05-06 21:32:09,136][train][INFO] - Epoch 474/1000, Val Acc=0.6476, Val Loss=1.7099, lr=0.0100
[2025-05-06 21:32:11,050][train][INFO] - Epoch 480/1000, Val Acc=0.6322, Val Loss=1.7181, lr=0.0100
[2025-05-06 21:32:17,118][train][INFO] - Epoch 475/1000, Val Acc=0.6488, Val Loss=1.7166, lr=0.0100
[2025-05-06 21:32:19,050][train][INFO] - Epoch 481/1000, Val Acc=0.6352, Val Loss=1.6544, lr=0.0100
[2025-05-06 21:32:24,950][train][INFO] - Epoch 476/1000, Val Acc=0.6337, Val Loss=1.7940, lr=0.0100
[2025-05-06 21:32:27,224][train][INFO] - Epoch 482/1000, Val Acc=0.6102, Val Loss=1.8111, lr=0.0100
[2025-05-06 21:32:33,060][train][INFO] - Epoch 477/1000, Val Acc=0.6424, Val Loss=1.7445, lr=0.0100
[2025-05-06 21:32:35,092][train][INFO] - Epoch 483/1000, Val Acc=0.6390, Val Loss=1.6205, lr=0.0100
[2025-05-06 21:32:40,394][train][INFO] - Epoch 478/1000, Val Acc=0.6486, Val Loss=1.7022, lr=0.0100
[2025-05-06 21:32:42,865][train][INFO] - Epoch 484/1000, Val Acc=0.6307, Val Loss=1.6857, lr=0.0100
[2025-05-06 21:32:48,188][train][INFO] - Epoch 479/1000, Val Acc=0.6485, Val Loss=1.6995, lr=0.0100
[2025-05-06 21:32:50,181][train][INFO] - Epoch 485/1000, Val Acc=0.6298, Val Loss=1.6822, lr=0.0100
[2025-05-06 21:32:56,575][train][INFO] - Epoch 480/1000, Val Acc=0.6356, Val Loss=1.7759, lr=0.0100
[2025-05-06 21:32:58,012][train][INFO] - Epoch 486/1000, Val Acc=0.6339, Val Loss=1.6652, lr=0.0100
[2025-05-06 21:33:04,808][train][INFO] - Epoch 481/1000, Val Acc=0.6319, Val Loss=1.7899, lr=0.0100
[2025-05-06 21:33:05,814][train][INFO] - Epoch 487/1000, Val Acc=0.6231, Val Loss=1.7203, lr=0.0100
[2025-05-06 21:33:12,893][train][INFO] - Epoch 482/1000, Val Acc=0.6450, Val Loss=1.7355, lr=0.0100
[2025-05-06 21:33:13,993][train][INFO] - Epoch 488/1000, Val Acc=0.6116, Val Loss=1.7932, lr=0.0100
[2025-05-06 21:33:21,338][train][INFO] - Epoch 483/1000, Val Acc=0.6458, Val Loss=1.7150, lr=0.0100
[2025-05-06 21:33:21,948][train][INFO] - Epoch 489/1000, Val Acc=0.6315, Val Loss=1.7106, lr=0.0100
[2025-05-06 21:33:29,878][train][INFO] - Epoch 484/1000, Val Acc=0.6460, Val Loss=1.7251, lr=0.0100
[2025-05-06 21:33:30,003][train][INFO] - Epoch 490/1000, Val Acc=0.6174, Val Loss=1.7702, lr=0.0100
[2025-05-06 21:33:37,089][train][INFO] - Epoch 485/1000, Val Acc=0.6383, Val Loss=1.7638, lr=0.0100
[2025-05-06 21:33:38,213][train][INFO] - Epoch 491/1000, Val Acc=0.6337, Val Loss=1.7275, lr=0.0100
[2025-05-06 21:33:45,621][train][INFO] - Epoch 486/1000, Val Acc=0.6449, Val Loss=1.7392, lr=0.0100
[2025-05-06 21:33:46,643][train][INFO] - Epoch 492/1000, Val Acc=0.6349, Val Loss=1.6857, lr=0.0100
[2025-05-06 21:33:53,723][train][INFO] - Epoch 493/1000, Val Acc=0.6309, Val Loss=1.6649, lr=0.0100
[2025-05-06 21:33:53,731][train][INFO] - Epoch 487/1000, Val Acc=0.6394, Val Loss=1.7625, lr=0.0100
[2025-05-06 21:34:01,353][train][INFO] - Epoch 494/1000, Val Acc=0.6295, Val Loss=1.7074, lr=0.0100
[2025-05-06 21:34:01,522][train][INFO] - Epoch 488/1000, Val Acc=0.6450, Val Loss=1.7323, lr=0.0100
[2025-05-06 21:34:09,640][train][INFO] - Epoch 489/1000, Val Acc=0.6395, Val Loss=1.7409, lr=0.0100
[2025-05-06 21:34:09,880][train][INFO] - Epoch 495/1000, Val Acc=0.6308, Val Loss=1.6729, lr=0.0100
[2025-05-06 21:34:18,293][train][INFO] - Epoch 490/1000, Val Acc=0.6461, Val Loss=1.6948, lr=0.0100
[2025-05-06 21:34:18,405][train][INFO] - Epoch 496/1000, Val Acc=0.6341, Val Loss=1.6719, lr=0.0100
[2025-05-06 21:34:26,369][train][INFO] - Epoch 491/1000, Val Acc=0.6395, Val Loss=1.7831, lr=0.0100
[2025-05-06 21:34:26,422][train][INFO] - Epoch 497/1000, Val Acc=0.6208, Val Loss=1.7551, lr=0.0100
[2025-05-06 21:34:34,255][train][INFO] - Epoch 492/1000, Val Acc=0.6428, Val Loss=1.7370, lr=0.0100
[2025-05-06 21:34:34,460][train][INFO] - Epoch 498/1000, Val Acc=0.6349, Val Loss=1.6543, lr=0.0100
[2025-05-06 21:34:42,153][train][INFO] - Epoch 493/1000, Val Acc=0.6506, Val Loss=1.6918, lr=0.0100
[2025-05-06 21:34:42,798][train][INFO] - Epoch 499/1000, Val Acc=0.6336, Val Loss=1.7265, lr=0.0100
[2025-05-06 21:34:50,383][train][INFO] - Epoch 494/1000, Val Acc=0.6276, Val Loss=1.8486, lr=0.0100
[2025-05-06 21:34:51,271][train][INFO] - Epoch 500/1000, Val Acc=0.6222, Val Loss=1.7350, lr=0.0100
[2025-05-06 21:34:58,632][train][INFO] - Epoch 501/1000, Val Acc=0.6271, Val Loss=1.7153, lr=0.0100
[2025-05-06 21:34:58,751][train][INFO] - Epoch 495/1000, Val Acc=0.6405, Val Loss=1.7572, lr=0.0100
[2025-05-06 21:35:06,819][train][INFO] - Epoch 502/1000, Val Acc=0.6421, Val Loss=1.6639, lr=0.0100
[2025-05-06 21:35:06,896][train][INFO] - Epoch 496/1000, Val Acc=0.6395, Val Loss=1.7621, lr=0.0100
[2025-05-06 21:35:14,884][train][INFO] - Epoch 503/1000, Val Acc=0.6306, Val Loss=1.6604, lr=0.0100
[2025-05-06 21:35:15,092][train][INFO] - Epoch 497/1000, Val Acc=0.6454, Val Loss=1.7496, lr=0.0100
[2025-05-06 21:35:22,935][train][INFO] - Epoch 504/1000, Val Acc=0.6419, Val Loss=1.6554, lr=0.0100
[2025-05-06 21:35:23,519][train][INFO] - Epoch 498/1000, Val Acc=0.6278, Val Loss=1.8316, lr=0.0100
[2025-05-06 21:35:30,945][train][INFO] - Epoch 505/1000, Val Acc=0.6194, Val Loss=1.7760, lr=0.0100
[2025-05-06 21:35:32,084][train][INFO] - Epoch 499/1000, Val Acc=0.6473, Val Loss=1.7178, lr=0.0100
[2025-05-06 21:35:39,313][train][INFO] - Epoch 506/1000, Val Acc=0.6311, Val Loss=1.6904, lr=0.0100
[2025-05-06 21:35:40,525][train][INFO] - Epoch 500/1000, Val Acc=0.6409, Val Loss=1.7301, lr=0.0100
[2025-05-06 21:35:48,200][train][INFO] - Epoch 507/1000, Val Acc=0.6380, Val Loss=1.6573, lr=0.0100
[2025-05-06 21:35:50,037][train][INFO] - Epoch 501/1000, Val Acc=0.6453, Val Loss=1.7465, lr=0.0100
[2025-05-06 21:35:57,150][train][INFO] - Epoch 508/1000, Val Acc=0.6194, Val Loss=1.7945, lr=0.0100
[2025-05-06 21:35:58,560][train][INFO] - Epoch 502/1000, Val Acc=0.6485, Val Loss=1.7550, lr=0.0100
[2025-05-06 21:36:05,170][train][INFO] - Epoch 509/1000, Val Acc=0.6167, Val Loss=1.8196, lr=0.0100
[2025-05-06 21:36:06,554][train][INFO] - Epoch 503/1000, Val Acc=0.6476, Val Loss=1.7212, lr=0.0100
[2025-05-06 21:36:12,734][train][INFO] - Epoch 510/1000, Val Acc=0.6343, Val Loss=1.6589, lr=0.0100
[2025-05-06 21:36:14,704][train][INFO] - Epoch 504/1000, Val Acc=0.6504, Val Loss=1.7110, lr=0.0100
[2025-05-06 21:36:20,783][train][INFO] - Epoch 511/1000, Val Acc=0.6223, Val Loss=1.7853, lr=0.0100
[2025-05-06 21:36:23,265][train][INFO] - Epoch 505/1000, Val Acc=0.6392, Val Loss=1.7930, lr=0.0100
[2025-05-06 21:36:28,988][train][INFO] - Epoch 512/1000, Val Acc=0.6270, Val Loss=1.7425, lr=0.0100
[2025-05-06 21:36:31,125][train][INFO] - Epoch 506/1000, Val Acc=0.6439, Val Loss=1.7463, lr=0.0100
[2025-05-06 21:36:37,055][train][INFO] - Epoch 513/1000, Val Acc=0.6255, Val Loss=1.7371, lr=0.0100
[2025-05-06 21:36:38,909][train][INFO] - Epoch 507/1000, Val Acc=0.6399, Val Loss=1.7748, lr=0.0100
[2025-05-06 21:36:45,351][train][INFO] - Epoch 514/1000, Val Acc=0.6286, Val Loss=1.6871, lr=0.0100
[2025-05-06 21:36:47,276][train][INFO] - Epoch 508/1000, Val Acc=0.6393, Val Loss=1.7552, lr=0.0100
[2025-05-06 21:36:53,936][train][INFO] - Epoch 515/1000, Val Acc=0.6267, Val Loss=1.7213, lr=0.0100
[2025-05-06 21:36:55,685][train][INFO] - Epoch 509/1000, Val Acc=0.6421, Val Loss=1.7458, lr=0.0100
[2025-05-06 21:37:02,565][train][INFO] - Epoch 516/1000, Val Acc=0.6381, Val Loss=1.6705, lr=0.0100
[2025-05-06 21:37:03,573][train][INFO] - Epoch 510/1000, Val Acc=0.6455, Val Loss=1.7152, lr=0.0100
[2025-05-06 21:37:11,138][train][INFO] - Epoch 517/1000, Val Acc=0.6238, Val Loss=1.7528, lr=0.0100
[2025-05-06 21:37:12,121][train][INFO] - Epoch 511/1000, Val Acc=0.6375, Val Loss=1.8041, lr=0.0100
[2025-05-06 21:37:19,577][train][INFO] - Epoch 518/1000, Val Acc=0.6191, Val Loss=1.7383, lr=0.0100
[2025-05-06 21:37:20,206][train][INFO] - Epoch 512/1000, Val Acc=0.6279, Val Loss=1.8554, lr=0.0100
[2025-05-06 21:37:27,181][train][INFO] - Epoch 513/1000, Val Acc=0.6490, Val Loss=1.7247, lr=0.0100
[2025-05-06 21:37:27,572][train][INFO] - Epoch 519/1000, Val Acc=0.6390, Val Loss=1.6374, lr=0.0100
[2025-05-06 21:37:34,861][train][INFO] - Epoch 514/1000, Val Acc=0.6286, Val Loss=1.8511, lr=0.0100
[2025-05-06 21:37:35,503][train][INFO] - Epoch 520/1000, Val Acc=0.6376, Val Loss=1.6635, lr=0.0100
[2025-05-06 21:37:42,843][train][INFO] - Epoch 515/1000, Val Acc=0.6520, Val Loss=1.6654, lr=0.0100
[2025-05-06 21:37:43,169][train][INFO] - Epoch 521/1000, Val Acc=0.6446, Val Loss=1.5985, lr=0.0100
[2025-05-06 21:37:50,244][train][INFO] - Epoch 522/1000, Val Acc=0.6132, Val Loss=1.7983, lr=0.0100
[2025-05-06 21:37:50,869][train][INFO] - Epoch 516/1000, Val Acc=0.6464, Val Loss=1.7677, lr=0.0100
[2025-05-06 21:37:58,308][train][INFO] - Epoch 523/1000, Val Acc=0.6215, Val Loss=1.7603, lr=0.0100
[2025-05-06 21:37:58,988][train][INFO] - Epoch 517/1000, Val Acc=0.6398, Val Loss=1.7792, lr=0.0100
[2025-05-06 21:38:06,263][train][INFO] - Epoch 524/1000, Val Acc=0.6146, Val Loss=1.8459, lr=0.0100
[2025-05-06 21:38:06,466][train][INFO] - Epoch 518/1000, Val Acc=0.6328, Val Loss=1.8167, lr=0.0100
[2025-05-06 21:38:13,740][train][INFO] - Epoch 519/1000, Val Acc=0.6436, Val Loss=1.7599, lr=0.0100
[2025-05-06 21:38:14,703][train][INFO] - Epoch 525/1000, Val Acc=0.6151, Val Loss=1.7756, lr=0.0100
[2025-05-06 21:38:21,969][train][INFO] - Epoch 520/1000, Val Acc=0.6469, Val Loss=1.6901, lr=0.0100
[2025-05-06 21:38:23,133][train][INFO] - Epoch 526/1000, Val Acc=0.6272, Val Loss=1.7350, lr=0.0100
[2025-05-06 21:38:29,397][train][INFO] - Epoch 521/1000, Val Acc=0.6267, Val Loss=1.8728, lr=0.0100
[2025-05-06 21:38:31,454][train][INFO] - Epoch 527/1000, Val Acc=0.6002, Val Loss=1.9280, lr=0.0100
[2025-05-06 21:38:37,451][train][INFO] - Epoch 522/1000, Val Acc=0.6411, Val Loss=1.7794, lr=0.0100
[2025-05-06 21:38:39,055][train][INFO] - Epoch 528/1000, Val Acc=0.6221, Val Loss=1.7215, lr=0.0100
[2025-05-06 21:38:44,739][train][INFO] - Epoch 523/1000, Val Acc=0.6353, Val Loss=1.8151, lr=0.0100
[2025-05-06 21:38:46,981][train][INFO] - Epoch 529/1000, Val Acc=0.6168, Val Loss=1.7640, lr=0.0100
[2025-05-06 21:38:52,672][train][INFO] - Epoch 524/1000, Val Acc=0.6540, Val Loss=1.6968, lr=0.0100
[2025-05-06 21:38:54,730][train][INFO] - Epoch 530/1000, Val Acc=0.6102, Val Loss=1.8457, lr=0.0100
[2025-05-06 21:39:01,169][train][INFO] - Epoch 525/1000, Val Acc=0.6434, Val Loss=1.7454, lr=0.0100
[2025-05-06 21:39:02,741][train][INFO] - Epoch 531/1000, Val Acc=0.6224, Val Loss=1.7230, lr=0.0100
[2025-05-06 21:39:09,484][train][INFO] - Epoch 526/1000, Val Acc=0.6355, Val Loss=1.7782, lr=0.0100
[2025-05-06 21:39:10,608][train][INFO] - Epoch 532/1000, Val Acc=0.6372, Val Loss=1.6671, lr=0.0100
[2025-05-06 21:39:17,638][train][INFO] - Epoch 527/1000, Val Acc=0.6447, Val Loss=1.7334, lr=0.0100
[2025-05-06 21:39:18,353][train][INFO] - Epoch 533/1000, Val Acc=0.6303, Val Loss=1.7091, lr=0.0100
[2025-05-06 21:39:25,876][train][INFO] - Epoch 528/1000, Val Acc=0.6430, Val Loss=1.7350, lr=0.0100
[2025-05-06 21:39:26,438][train][INFO] - Epoch 534/1000, Val Acc=0.6265, Val Loss=1.7019, lr=0.0100
[2025-05-06 21:39:33,977][train][INFO] - Epoch 529/1000, Val Acc=0.6401, Val Loss=1.7783, lr=0.0100
[2025-05-06 21:39:34,458][train][INFO] - Epoch 535/1000, Val Acc=0.6275, Val Loss=1.7240, lr=0.0100
[2025-05-06 21:39:41,858][train][INFO] - Epoch 530/1000, Val Acc=0.6314, Val Loss=1.8766, lr=0.0100
[2025-05-06 21:39:42,521][train][INFO] - Epoch 536/1000, Val Acc=0.6333, Val Loss=1.6736, lr=0.0100
[2025-05-06 21:39:49,930][train][INFO] - Epoch 537/1000, Val Acc=0.6258, Val Loss=1.7651, lr=0.0100
[2025-05-06 21:39:50,105][train][INFO] - Epoch 531/1000, Val Acc=0.6344, Val Loss=1.8451, lr=0.0100
[2025-05-06 21:39:58,341][train][INFO] - Epoch 538/1000, Val Acc=0.6104, Val Loss=1.8174, lr=0.0100
[2025-05-06 21:39:58,402][train][INFO] - Epoch 532/1000, Val Acc=0.6304, Val Loss=1.8407, lr=0.0100
[2025-05-06 21:40:06,049][train][INFO] - Epoch 539/1000, Val Acc=0.6340, Val Loss=1.6641, lr=0.0100
[2025-05-06 21:40:06,456][train][INFO] - Epoch 533/1000, Val Acc=0.6493, Val Loss=1.6951, lr=0.0100
[2025-05-06 21:40:14,240][train][INFO] - Epoch 540/1000, Val Acc=0.6334, Val Loss=1.6793, lr=0.0100
[2025-05-06 21:40:15,141][train][INFO] - Epoch 534/1000, Val Acc=0.6367, Val Loss=1.8182, lr=0.0100
[2025-05-06 21:40:22,608][train][INFO] - Epoch 541/1000, Val Acc=0.6232, Val Loss=1.7549, lr=0.0100
[2025-05-06 21:40:22,711][train][INFO] - Epoch 535/1000, Val Acc=0.6438, Val Loss=1.7973, lr=0.0100
[2025-05-06 21:40:30,356][train][INFO] - Epoch 542/1000, Val Acc=0.6323, Val Loss=1.7206, lr=0.0100
[2025-05-06 21:40:30,924][train][INFO] - Epoch 536/1000, Val Acc=0.6452, Val Loss=1.7513, lr=0.0100
[2025-05-06 21:40:37,873][train][INFO] - Epoch 543/1000, Val Acc=0.6353, Val Loss=1.6675, lr=0.0100
[2025-05-06 21:40:38,967][train][INFO] - Epoch 537/1000, Val Acc=0.6416, Val Loss=1.7753, lr=0.0100
[2025-05-06 21:40:46,001][train][INFO] - Epoch 544/1000, Val Acc=0.6278, Val Loss=1.6905, lr=0.0100
[2025-05-06 21:40:46,387][train][INFO] - Epoch 538/1000, Val Acc=0.6267, Val Loss=1.8600, lr=0.0100
[2025-05-06 21:40:54,176][train][INFO] - Epoch 545/1000, Val Acc=0.6185, Val Loss=1.7867, lr=0.0100
[2025-05-06 21:40:54,653][train][INFO] - Epoch 539/1000, Val Acc=0.6498, Val Loss=1.7105, lr=0.0100
[2025-05-06 21:41:02,031][train][INFO] - Epoch 540/1000, Val Acc=0.6500, Val Loss=1.7206, lr=0.0100
[2025-05-06 21:41:02,462][train][INFO] - Epoch 546/1000, Val Acc=0.6309, Val Loss=1.7484, lr=0.0100
[2025-05-06 21:41:10,383][train][INFO] - Epoch 541/1000, Val Acc=0.6442, Val Loss=1.7172, lr=0.0100
[2025-05-06 21:41:10,740][train][INFO] - Epoch 547/1000, Val Acc=0.6366, Val Loss=1.6622, lr=0.0100
[2025-05-06 21:41:18,578][train][INFO] - Epoch 542/1000, Val Acc=0.6468, Val Loss=1.7305, lr=0.0100
[2025-05-06 21:41:18,797][train][INFO] - Epoch 548/1000, Val Acc=0.6317, Val Loss=1.7024, lr=0.0100
[2025-05-06 21:41:26,218][train][INFO] - Epoch 549/1000, Val Acc=0.6299, Val Loss=1.7060, lr=0.0100
[2025-05-06 21:41:26,763][train][INFO] - Epoch 543/1000, Val Acc=0.6355, Val Loss=1.7909, lr=0.0100
[2025-05-06 21:41:34,526][train][INFO] - Epoch 550/1000, Val Acc=0.6339, Val Loss=1.6635, lr=0.0100
[2025-05-06 21:41:34,997][train][INFO] - Epoch 544/1000, Val Acc=0.6328, Val Loss=1.8140, lr=0.0100
[2025-05-06 21:41:42,882][train][INFO] - Epoch 545/1000, Val Acc=0.6534, Val Loss=1.6985, lr=0.0100
[2025-05-06 21:41:43,001][train][INFO] - Epoch 551/1000, Val Acc=0.6323, Val Loss=1.7050, lr=0.0100
[2025-05-06 21:41:51,584][train][INFO] - Epoch 552/1000, Val Acc=0.5993, Val Loss=1.9088, lr=0.0100
[2025-05-06 21:41:51,678][train][INFO] - Epoch 546/1000, Val Acc=0.6483, Val Loss=1.7299, lr=0.0100
[2025-05-06 21:41:59,670][train][INFO] - Epoch 553/1000, Val Acc=0.6193, Val Loss=1.7897, lr=0.0100
[2025-05-06 21:42:00,415][train][INFO] - Epoch 547/1000, Val Acc=0.6472, Val Loss=1.7409, lr=0.0100
[2025-05-06 21:42:07,739][train][INFO] - Epoch 554/1000, Val Acc=0.6328, Val Loss=1.6864, lr=0.0100
[2025-05-06 21:42:08,044][train][INFO] - Epoch 548/1000, Val Acc=0.6298, Val Loss=1.8523, lr=0.0100
[2025-05-06 21:42:15,456][train][INFO] - Epoch 555/1000, Val Acc=0.6323, Val Loss=1.7214, lr=0.0100
[2025-05-06 21:42:16,452][train][INFO] - Epoch 549/1000, Val Acc=0.6419, Val Loss=1.7268, lr=0.0100
[2025-05-06 21:42:23,595][train][INFO] - Epoch 556/1000, Val Acc=0.6369, Val Loss=1.6786, lr=0.0100
[2025-05-06 21:42:23,991][train][INFO] - Epoch 550/1000, Val Acc=0.6347, Val Loss=1.8153, lr=0.0100
[2025-05-06 21:42:32,189][train][INFO] - Epoch 557/1000, Val Acc=0.6234, Val Loss=1.7837, lr=0.0100
[2025-05-06 21:42:32,279][train][INFO] - Epoch 551/1000, Val Acc=0.6516, Val Loss=1.7058, lr=0.0100
[2025-05-06 21:42:39,735][train][INFO] - Epoch 558/1000, Val Acc=0.6286, Val Loss=1.7054, lr=0.0100
[2025-05-06 21:42:40,421][train][INFO] - Epoch 552/1000, Val Acc=0.6432, Val Loss=1.7473, lr=0.0100
[2025-05-06 21:42:48,162][train][INFO] - Epoch 559/1000, Val Acc=0.6303, Val Loss=1.7370, lr=0.0100
[2025-05-06 21:42:48,813][train][INFO] - Epoch 553/1000, Val Acc=0.6408, Val Loss=1.7402, lr=0.0100
[2025-05-06 21:42:56,115][train][INFO] - Epoch 560/1000, Val Acc=0.6079, Val Loss=1.8280, lr=0.0100
[2025-05-06 21:42:56,986][train][INFO] - Epoch 554/1000, Val Acc=0.6475, Val Loss=1.6822, lr=0.0100
[2025-05-06 21:43:04,180][train][INFO] - Epoch 561/1000, Val Acc=0.6315, Val Loss=1.6771, lr=0.0100
[2025-05-06 21:43:05,408][train][INFO] - Epoch 555/1000, Val Acc=0.6443, Val Loss=1.7106, lr=0.0100
[2025-05-06 21:43:11,731][train][INFO] - Epoch 562/1000, Val Acc=0.6026, Val Loss=1.8301, lr=0.0100
[2025-05-06 21:43:13,294][train][INFO] - Epoch 556/1000, Val Acc=0.6393, Val Loss=1.7754, lr=0.0100
[2025-05-06 21:43:19,819][train][INFO] - Epoch 563/1000, Val Acc=0.6116, Val Loss=1.8518, lr=0.0100
[2025-05-06 21:43:21,786][train][INFO] - Epoch 557/1000, Val Acc=0.6356, Val Loss=1.7954, lr=0.0100
[2025-05-06 21:43:28,425][train][INFO] - Epoch 564/1000, Val Acc=0.6317, Val Loss=1.7219, lr=0.0100
[2025-05-06 21:43:29,644][train][INFO] - Epoch 558/1000, Val Acc=0.6321, Val Loss=1.8327, lr=0.0100
[2025-05-06 21:43:35,457][train][INFO] - Epoch 565/1000, Val Acc=0.6326, Val Loss=1.7039, lr=0.0100
[2025-05-06 21:43:37,995][train][INFO] - Epoch 559/1000, Val Acc=0.6524, Val Loss=1.7214, lr=0.0100
[2025-05-06 21:43:43,345][train][INFO] - Epoch 566/1000, Val Acc=0.6373, Val Loss=1.6532, lr=0.0100
[2025-05-06 21:43:45,683][train][INFO] - Epoch 560/1000, Val Acc=0.6326, Val Loss=1.8395, lr=0.0100
[2025-05-06 21:43:51,264][train][INFO] - Epoch 567/1000, Val Acc=0.6179, Val Loss=1.7877, lr=0.0100
[2025-05-06 21:43:54,160][train][INFO] - Epoch 561/1000, Val Acc=0.6508, Val Loss=1.6921, lr=0.0100
[2025-05-06 21:43:59,116][train][INFO] - Epoch 568/1000, Val Acc=0.6211, Val Loss=1.7867, lr=0.0100
[2025-05-06 21:44:02,067][train][INFO] - Epoch 562/1000, Val Acc=0.6466, Val Loss=1.7630, lr=0.0100
[2025-05-06 21:44:07,170][train][INFO] - Epoch 569/1000, Val Acc=0.6354, Val Loss=1.7051, lr=0.0100
[2025-05-06 21:44:09,903][train][INFO] - Epoch 563/1000, Val Acc=0.6480, Val Loss=1.6956, lr=0.0100
[2025-05-06 21:44:15,633][train][INFO] - Epoch 570/1000, Val Acc=0.6317, Val Loss=1.6334, lr=0.0100
[2025-05-06 21:44:18,509][train][INFO] - Epoch 564/1000, Val Acc=0.6527, Val Loss=1.7071, lr=0.0100
[2025-05-06 21:44:24,006][train][INFO] - Epoch 571/1000, Val Acc=0.6228, Val Loss=1.7360, lr=0.0100
[2025-05-06 21:44:26,388][train][INFO] - Epoch 565/1000, Val Acc=0.6420, Val Loss=1.7965, lr=0.0100
[2025-05-06 21:44:32,391][train][INFO] - Epoch 572/1000, Val Acc=0.6129, Val Loss=1.7911, lr=0.0100
[2025-05-06 21:44:34,745][train][INFO] - Epoch 566/1000, Val Acc=0.6269, Val Loss=1.8554, lr=0.0100
[2025-05-06 21:44:40,529][train][INFO] - Epoch 573/1000, Val Acc=0.6306, Val Loss=1.6475, lr=0.0100
[2025-05-06 21:44:42,504][train][INFO] - Epoch 567/1000, Val Acc=0.6516, Val Loss=1.6973, lr=0.0100
[2025-05-06 21:44:48,231][train][INFO] - Epoch 574/1000, Val Acc=0.6362, Val Loss=1.6652, lr=0.0100
[2025-05-06 21:44:50,801][train][INFO] - Epoch 568/1000, Val Acc=0.6201, Val Loss=1.8877, lr=0.0100
[2025-05-06 21:44:56,036][train][INFO] - Epoch 575/1000, Val Acc=0.6459, Val Loss=1.6240, lr=0.0100
[2025-05-06 21:44:58,745][train][INFO] - Epoch 569/1000, Val Acc=0.6446, Val Loss=1.7731, lr=0.0100
[2025-05-06 21:45:04,030][train][INFO] - Epoch 576/1000, Val Acc=0.6339, Val Loss=1.6961, lr=0.0100
[2025-05-06 21:45:07,113][train][INFO] - Epoch 570/1000, Val Acc=0.6550, Val Loss=1.6858, lr=0.0100
[2025-05-06 21:45:11,911][train][INFO] - Epoch 577/1000, Val Acc=0.6331, Val Loss=1.6868, lr=0.0100
[2025-05-06 21:45:15,226][train][INFO] - Epoch 571/1000, Val Acc=0.6436, Val Loss=1.7768, lr=0.0100
[2025-05-06 21:45:19,365][train][INFO] - Epoch 578/1000, Val Acc=0.6316, Val Loss=1.6865, lr=0.0100
[2025-05-06 21:45:23,495][train][INFO] - Epoch 572/1000, Val Acc=0.6480, Val Loss=1.7415, lr=0.0100
[2025-05-06 21:45:27,151][train][INFO] - Epoch 579/1000, Val Acc=0.6215, Val Loss=1.7722, lr=0.0100
[2025-05-06 21:45:31,415][train][INFO] - Epoch 573/1000, Val Acc=0.6454, Val Loss=1.7882, lr=0.0100
[2025-05-06 21:45:34,306][train][INFO] - Epoch 580/1000, Val Acc=0.6351, Val Loss=1.6875, lr=0.0100
[2025-05-06 21:45:39,675][train][INFO] - Epoch 574/1000, Val Acc=0.6516, Val Loss=1.7062, lr=0.0100
[2025-05-06 21:45:42,436][train][INFO] - Epoch 581/1000, Val Acc=0.6281, Val Loss=1.7224, lr=0.0100
[2025-05-06 21:45:47,993][train][INFO] - Epoch 575/1000, Val Acc=0.6431, Val Loss=1.7452, lr=0.0100
[2025-05-06 21:45:50,276][train][INFO] - Epoch 582/1000, Val Acc=0.6311, Val Loss=1.7125, lr=0.0100
[2025-05-06 21:45:55,927][train][INFO] - Epoch 576/1000, Val Acc=0.6416, Val Loss=1.7522, lr=0.0100
[2025-05-06 21:45:58,402][train][INFO] - Epoch 583/1000, Val Acc=0.6353, Val Loss=1.6597, lr=0.0100
[2025-05-06 21:46:04,382][train][INFO] - Epoch 577/1000, Val Acc=0.6310, Val Loss=1.8532, lr=0.0100
[2025-05-06 21:46:05,846][train][INFO] - Epoch 584/1000, Val Acc=0.6341, Val Loss=1.6990, lr=0.0100
[2025-05-06 21:46:12,460][train][INFO] - Epoch 578/1000, Val Acc=0.6491, Val Loss=1.7040, lr=0.0100
[2025-05-06 21:46:13,937][train][INFO] - Epoch 585/1000, Val Acc=0.6207, Val Loss=1.8068, lr=0.0100
[2025-05-06 21:46:21,116][train][INFO] - Epoch 579/1000, Val Acc=0.6331, Val Loss=1.7769, lr=0.0100
[2025-05-06 21:46:21,894][train][INFO] - Epoch 586/1000, Val Acc=0.6399, Val Loss=1.6713, lr=0.0100
[2025-05-06 21:46:29,429][train][INFO] - Epoch 580/1000, Val Acc=0.6404, Val Loss=1.7796, lr=0.0100
[2025-05-06 21:46:30,115][train][INFO] - Epoch 587/1000, Val Acc=0.6352, Val Loss=1.6862, lr=0.0100
[2025-05-06 21:46:37,696][train][INFO] - Epoch 581/1000, Val Acc=0.6332, Val Loss=1.7974, lr=0.0100
[2025-05-06 21:46:38,505][train][INFO] - Epoch 588/1000, Val Acc=0.6146, Val Loss=1.7855, lr=0.0100
[2025-05-06 21:46:46,060][train][INFO] - Epoch 582/1000, Val Acc=0.6521, Val Loss=1.7379, lr=0.0100
[2025-05-06 21:46:46,521][train][INFO] - Epoch 589/1000, Val Acc=0.6156, Val Loss=1.7681, lr=0.0100
[2025-05-06 21:46:54,047][train][INFO] - Epoch 590/1000, Val Acc=0.6288, Val Loss=1.7278, lr=0.0100
[2025-05-06 21:46:54,302][train][INFO] - Epoch 583/1000, Val Acc=0.6377, Val Loss=1.8391, lr=0.0100
[2025-05-06 21:47:01,966][train][INFO] - Epoch 584/1000, Val Acc=0.6560, Val Loss=1.6786, lr=0.0100
[2025-05-06 21:47:02,052][train][INFO] - Epoch 591/1000, Val Acc=0.6329, Val Loss=1.7148, lr=0.0100
[2025-05-06 21:47:10,127][train][INFO] - Epoch 592/1000, Val Acc=0.6338, Val Loss=1.7328, lr=0.0100
[2025-05-06 21:47:10,356][train][INFO] - Epoch 585/1000, Val Acc=0.6388, Val Loss=1.7881, lr=0.0100
[2025-05-06 21:47:18,227][train][INFO] - Epoch 586/1000, Val Acc=0.6340, Val Loss=1.8490, lr=0.0100
[2025-05-06 21:47:18,502][train][INFO] - Epoch 593/1000, Val Acc=0.6225, Val Loss=1.7516, lr=0.0100
[2025-05-06 21:47:26,239][train][INFO] - Epoch 587/1000, Val Acc=0.6520, Val Loss=1.6735, lr=0.0100
[2025-05-06 21:47:26,748][train][INFO] - Epoch 594/1000, Val Acc=0.6274, Val Loss=1.6973, lr=0.0100
[2025-05-06 21:47:34,584][train][INFO] - Epoch 588/1000, Val Acc=0.6442, Val Loss=1.7271, lr=0.0100
[2025-05-06 21:47:35,180][train][INFO] - Epoch 595/1000, Val Acc=0.6318, Val Loss=1.6961, lr=0.0100
[2025-05-06 21:47:42,649][train][INFO] - Epoch 589/1000, Val Acc=0.6421, Val Loss=1.7672, lr=0.0100
[2025-05-06 21:47:43,189][train][INFO] - Epoch 596/1000, Val Acc=0.6321, Val Loss=1.6552, lr=0.0100
[2025-05-06 21:47:50,208][train][INFO] - Epoch 590/1000, Val Acc=0.6526, Val Loss=1.7016, lr=0.0100
[2025-05-06 21:47:51,471][train][INFO] - Epoch 597/1000, Val Acc=0.6235, Val Loss=1.7601, lr=0.0100
[2025-05-06 21:47:58,347][train][INFO] - Epoch 591/1000, Val Acc=0.6527, Val Loss=1.7253, lr=0.0100
[2025-05-06 21:47:59,443][train][INFO] - Epoch 598/1000, Val Acc=0.6268, Val Loss=1.7366, lr=0.0100
[2025-05-06 21:48:06,847][train][INFO] - Epoch 592/1000, Val Acc=0.6411, Val Loss=1.7385, lr=0.0100
[2025-05-06 21:48:07,418][train][INFO] - Epoch 599/1000, Val Acc=0.6289, Val Loss=1.7423, lr=0.0100
[2025-05-06 21:48:14,564][train][INFO] - Epoch 600/1000, Val Acc=0.6312, Val Loss=1.7125, lr=0.0100
[2025-05-06 21:48:15,610][train][INFO] - Epoch 593/1000, Val Acc=0.6445, Val Loss=1.7694, lr=0.0100
[2025-05-06 21:48:22,401][train][INFO] - Epoch 601/1000, Val Acc=0.6880, Val Loss=1.4272, lr=0.0010
[2025-05-06 21:48:23,864][train][INFO] - Epoch 594/1000, Val Acc=0.6383, Val Loss=1.7793, lr=0.0100
[2025-05-06 21:48:30,618][train][INFO] - Epoch 602/1000, Val Acc=0.6920, Val Loss=1.4366, lr=0.0010
[2025-05-06 21:48:32,061][train][INFO] - Epoch 595/1000, Val Acc=0.6407, Val Loss=1.7896, lr=0.0100
[2025-05-06 21:48:38,705][train][INFO] - Epoch 603/1000, Val Acc=0.6943, Val Loss=1.4463, lr=0.0010
[2025-05-06 21:48:40,167][train][INFO] - Epoch 596/1000, Val Acc=0.6336, Val Loss=1.8142, lr=0.0100
[2025-05-06 21:48:47,052][train][INFO] - Epoch 604/1000, Val Acc=0.6957, Val Loss=1.4562, lr=0.0010
[2025-05-06 21:48:48,816][train][INFO] - Epoch 597/1000, Val Acc=0.6465, Val Loss=1.7602, lr=0.0100
[2025-05-06 21:48:55,094][train][INFO] - Epoch 605/1000, Val Acc=0.6980, Val Loss=1.4598, lr=0.0010
[2025-05-06 21:48:56,764][train][INFO] - Epoch 598/1000, Val Acc=0.6511, Val Loss=1.7064, lr=0.0100
[2025-05-06 21:49:03,229][train][INFO] - Epoch 606/1000, Val Acc=0.6952, Val Loss=1.4734, lr=0.0010
[2025-05-06 21:49:04,693][train][INFO] - Epoch 599/1000, Val Acc=0.6333, Val Loss=1.8038, lr=0.0100
[2025-05-06 21:49:11,749][train][INFO] - Epoch 607/1000, Val Acc=0.6955, Val Loss=1.4784, lr=0.0010
[2025-05-06 21:49:12,034][train][INFO] - Epoch 600/1000, Val Acc=0.6487, Val Loss=1.7234, lr=0.0100
[2025-05-06 21:49:19,966][train][INFO] - Epoch 601/1000, Val Acc=0.6982, Val Loss=1.4628, lr=0.0010
[2025-05-06 21:49:20,343][train][INFO] - Epoch 608/1000, Val Acc=0.6962, Val Loss=1.4825, lr=0.0010
[2025-05-06 21:49:27,521][train][INFO] - Epoch 602/1000, Val Acc=0.7038, Val Loss=1.4592, lr=0.0010
[2025-05-06 21:49:28,794][train][INFO] - Epoch 609/1000, Val Acc=0.6980, Val Loss=1.4954, lr=0.0010
[2025-05-06 21:49:35,299][train][INFO] - Epoch 603/1000, Val Acc=0.7064, Val Loss=1.4602, lr=0.0010
[2025-05-06 21:49:36,523][train][INFO] - Epoch 610/1000, Val Acc=0.6976, Val Loss=1.4949, lr=0.0010
[2025-05-06 21:49:43,062][train][INFO] - Epoch 604/1000, Val Acc=0.7071, Val Loss=1.4709, lr=0.0010
[2025-05-06 21:49:43,970][train][INFO] - Epoch 611/1000, Val Acc=0.6970, Val Loss=1.5044, lr=0.0010
[2025-05-06 21:49:52,224][train][INFO] - Epoch 605/1000, Val Acc=0.7060, Val Loss=1.4717, lr=0.0010
[2025-05-06 21:49:53,671][train][INFO] - Epoch 612/1000, Val Acc=0.6974, Val Loss=1.5036, lr=0.0010
[2025-05-06 21:50:00,977][train][INFO] - Epoch 606/1000, Val Acc=0.7088, Val Loss=1.4737, lr=0.0010
[2025-05-06 21:50:02,104][train][INFO] - Epoch 613/1000, Val Acc=0.6984, Val Loss=1.5118, lr=0.0010
[2025-05-06 21:50:09,326][train][INFO] - Epoch 607/1000, Val Acc=0.7125, Val Loss=1.4832, lr=0.0010
[2025-05-06 21:50:10,172][train][INFO] - Epoch 614/1000, Val Acc=0.6974, Val Loss=1.5172, lr=0.0010
[2025-05-06 21:50:17,873][train][INFO] - Epoch 608/1000, Val Acc=0.7091, Val Loss=1.4892, lr=0.0010
[2025-05-06 21:50:18,538][train][INFO] - Epoch 615/1000, Val Acc=0.6981, Val Loss=1.5192, lr=0.0010
[2025-05-06 21:50:26,257][train][INFO] - Epoch 616/1000, Val Acc=0.6981, Val Loss=1.5179, lr=0.0010
[2025-05-06 21:50:26,287][train][INFO] - Epoch 609/1000, Val Acc=0.7093, Val Loss=1.4880, lr=0.0010
[2025-05-06 21:50:34,851][train][INFO] - Epoch 610/1000, Val Acc=0.7101, Val Loss=1.4968, lr=0.0010
[2025-05-06 21:50:34,898][train][INFO] - Epoch 617/1000, Val Acc=0.6955, Val Loss=1.5269, lr=0.0010
[2025-05-06 21:50:42,917][train][INFO] - Epoch 611/1000, Val Acc=0.7107, Val Loss=1.4975, lr=0.0010
[2025-05-06 21:50:43,012][train][INFO] - Epoch 618/1000, Val Acc=0.6980, Val Loss=1.5346, lr=0.0010
[2025-05-06 21:50:51,214][train][INFO] - Epoch 612/1000, Val Acc=0.7105, Val Loss=1.5015, lr=0.0010
[2025-05-06 21:50:51,270][train][INFO] - Epoch 619/1000, Val Acc=0.6997, Val Loss=1.5317, lr=0.0010
[2025-05-06 21:50:59,149][train][INFO] - Epoch 613/1000, Val Acc=0.7112, Val Loss=1.5023, lr=0.0010
[2025-05-06 21:50:59,326][train][INFO] - Epoch 620/1000, Val Acc=0.7002, Val Loss=1.5313, lr=0.0010
[2025-05-06 21:51:07,074][train][INFO] - Epoch 614/1000, Val Acc=0.7105, Val Loss=1.5077, lr=0.0010
[2025-05-06 21:51:07,582][train][INFO] - Epoch 621/1000, Val Acc=0.6983, Val Loss=1.5402, lr=0.0010
[2025-05-06 21:51:15,406][train][INFO] - Epoch 615/1000, Val Acc=0.7097, Val Loss=1.5107, lr=0.0010
[2025-05-06 21:51:15,755][train][INFO] - Epoch 622/1000, Val Acc=0.6983, Val Loss=1.5415, lr=0.0010
[2025-05-06 21:51:23,281][train][INFO] - Epoch 616/1000, Val Acc=0.7113, Val Loss=1.5066, lr=0.0010
[2025-05-06 21:51:23,465][train][INFO] - Epoch 623/1000, Val Acc=0.7016, Val Loss=1.5460, lr=0.0010
[2025-05-06 21:51:31,207][train][INFO] - Epoch 617/1000, Val Acc=0.7125, Val Loss=1.5117, lr=0.0010
[2025-05-06 21:51:31,471][train][INFO] - Epoch 624/1000, Val Acc=0.6994, Val Loss=1.5523, lr=0.0010
[2025-05-06 21:51:39,631][train][INFO] - Epoch 625/1000, Val Acc=0.6995, Val Loss=1.5544, lr=0.0010
[2025-05-06 21:51:39,721][train][INFO] - Epoch 618/1000, Val Acc=0.7118, Val Loss=1.5141, lr=0.0010
[2025-05-06 21:51:47,603][train][INFO] - Epoch 626/1000, Val Acc=0.6995, Val Loss=1.5544, lr=0.0010
[2025-05-06 21:51:47,819][train][INFO] - Epoch 619/1000, Val Acc=0.7118, Val Loss=1.5116, lr=0.0010
[2025-05-06 21:51:55,760][train][INFO] - Epoch 627/1000, Val Acc=0.6980, Val Loss=1.5620, lr=0.0010
[2025-05-06 21:51:56,123][train][INFO] - Epoch 620/1000, Val Acc=0.7131, Val Loss=1.5152, lr=0.0010
[2025-05-06 21:52:03,549][train][INFO] - Epoch 628/1000, Val Acc=0.6985, Val Loss=1.5636, lr=0.0010
[2025-05-06 21:52:04,711][train][INFO] - Epoch 621/1000, Val Acc=0.7158, Val Loss=1.5087, lr=0.0010
[2025-05-06 21:52:11,327][train][INFO] - Epoch 629/1000, Val Acc=0.6995, Val Loss=1.5611, lr=0.0010
[2025-05-06 21:52:13,209][train][INFO] - Epoch 622/1000, Val Acc=0.7130, Val Loss=1.5115, lr=0.0010
[2025-05-06 21:52:19,359][train][INFO] - Epoch 630/1000, Val Acc=0.6984, Val Loss=1.5608, lr=0.0010
[2025-05-06 21:52:21,856][train][INFO] - Epoch 623/1000, Val Acc=0.7115, Val Loss=1.5148, lr=0.0010
[2025-05-06 21:52:27,848][train][INFO] - Epoch 631/1000, Val Acc=0.6994, Val Loss=1.5684, lr=0.0010
[2025-05-06 21:52:30,398][train][INFO] - Epoch 624/1000, Val Acc=0.7122, Val Loss=1.5126, lr=0.0010
[2025-05-06 21:52:35,980][train][INFO] - Epoch 632/1000, Val Acc=0.6991, Val Loss=1.5646, lr=0.0010
[2025-05-06 21:52:38,589][train][INFO] - Epoch 625/1000, Val Acc=0.7110, Val Loss=1.5164, lr=0.0010
[2025-05-06 21:52:44,507][train][INFO] - Epoch 633/1000, Val Acc=0.7000, Val Loss=1.5661, lr=0.0010
[2025-05-06 21:52:46,748][train][INFO] - Epoch 626/1000, Val Acc=0.7123, Val Loss=1.5203, lr=0.0010
[2025-05-06 21:52:52,416][train][INFO] - Epoch 634/1000, Val Acc=0.7006, Val Loss=1.5716, lr=0.0010
[2025-05-06 21:52:54,983][train][INFO] - Epoch 627/1000, Val Acc=0.7130, Val Loss=1.5186, lr=0.0010
[2025-05-06 21:53:00,324][train][INFO] - Epoch 635/1000, Val Acc=0.6998, Val Loss=1.5725, lr=0.0010
[2025-05-06 21:53:03,356][train][INFO] - Epoch 628/1000, Val Acc=0.7132, Val Loss=1.5265, lr=0.0010
[2025-05-06 21:53:08,618][train][INFO] - Epoch 636/1000, Val Acc=0.6981, Val Loss=1.5878, lr=0.0010
[2025-05-06 21:53:11,052][train][INFO] - Epoch 629/1000, Val Acc=0.7144, Val Loss=1.5274, lr=0.0010
[2025-05-06 21:53:15,910][train][INFO] - Epoch 637/1000, Val Acc=0.6966, Val Loss=1.5766, lr=0.0010
[2025-05-06 21:53:19,102][train][INFO] - Epoch 630/1000, Val Acc=0.7143, Val Loss=1.5275, lr=0.0010
[2025-05-06 21:53:24,079][train][INFO] - Epoch 638/1000, Val Acc=0.6970, Val Loss=1.5864, lr=0.0010
[2025-05-06 21:53:26,856][train][INFO] - Epoch 631/1000, Val Acc=0.7161, Val Loss=1.5243, lr=0.0010
[2025-05-06 21:53:32,445][train][INFO] - Epoch 639/1000, Val Acc=0.6981, Val Loss=1.5854, lr=0.0010
[2025-05-06 21:53:34,933][train][INFO] - Epoch 632/1000, Val Acc=0.7128, Val Loss=1.5246, lr=0.0010
[2025-05-06 21:53:40,490][train][INFO] - Epoch 640/1000, Val Acc=0.6979, Val Loss=1.5908, lr=0.0010
[2025-05-06 21:53:42,950][train][INFO] - Epoch 633/1000, Val Acc=0.7150, Val Loss=1.5230, lr=0.0010
[2025-05-06 21:53:48,759][train][INFO] - Epoch 641/1000, Val Acc=0.6996, Val Loss=1.5894, lr=0.0010
[2025-05-06 21:53:50,987][train][INFO] - Epoch 634/1000, Val Acc=0.7137, Val Loss=1.5287, lr=0.0010
[2025-05-06 21:53:56,616][train][INFO] - Epoch 642/1000, Val Acc=0.6971, Val Loss=1.5858, lr=0.0010
[2025-05-06 21:53:59,472][train][INFO] - Epoch 635/1000, Val Acc=0.7137, Val Loss=1.5256, lr=0.0010
[2025-05-06 21:54:04,879][train][INFO] - Epoch 643/1000, Val Acc=0.6966, Val Loss=1.5832, lr=0.0010
[2025-05-06 21:54:07,873][train][INFO] - Epoch 636/1000, Val Acc=0.7137, Val Loss=1.5303, lr=0.0010
[2025-05-06 21:54:12,935][train][INFO] - Epoch 644/1000, Val Acc=0.6977, Val Loss=1.5910, lr=0.0010
[2025-05-06 21:54:16,216][train][INFO] - Epoch 637/1000, Val Acc=0.7128, Val Loss=1.5308, lr=0.0010
[2025-05-06 21:54:21,172][train][INFO] - Epoch 645/1000, Val Acc=0.7001, Val Loss=1.5906, lr=0.0010
[2025-05-06 21:54:24,784][train][INFO] - Epoch 638/1000, Val Acc=0.7132, Val Loss=1.5323, lr=0.0010
[2025-05-06 21:54:28,776][train][INFO] - Epoch 646/1000, Val Acc=0.6993, Val Loss=1.5881, lr=0.0010
[2025-05-06 21:54:32,608][train][INFO] - Epoch 639/1000, Val Acc=0.7166, Val Loss=1.5235, lr=0.0010
[2025-05-06 21:54:35,457][train][INFO] - Epoch 647/1000, Val Acc=0.6968, Val Loss=1.5949, lr=0.0010
[2025-05-06 21:54:40,481][train][INFO] - Epoch 640/1000, Val Acc=0.7145, Val Loss=1.5275, lr=0.0010
[2025-05-06 21:54:43,653][train][INFO] - Epoch 648/1000, Val Acc=0.6979, Val Loss=1.5971, lr=0.0010
[2025-05-06 21:54:48,760][train][INFO] - Epoch 641/1000, Val Acc=0.7141, Val Loss=1.5325, lr=0.0010
[2025-05-06 21:54:52,195][train][INFO] - Epoch 649/1000, Val Acc=0.6968, Val Loss=1.5926, lr=0.0010
[2025-05-06 21:54:57,002][train][INFO] - Epoch 642/1000, Val Acc=0.7155, Val Loss=1.5329, lr=0.0010
[2025-05-06 21:55:00,248][train][INFO] - Epoch 650/1000, Val Acc=0.6969, Val Loss=1.5958, lr=0.0010
[2025-05-06 21:55:05,272][train][INFO] - Epoch 643/1000, Val Acc=0.7153, Val Loss=1.5319, lr=0.0010
[2025-05-06 21:55:08,411][train][INFO] - Epoch 651/1000, Val Acc=0.6959, Val Loss=1.5954, lr=0.0010
[2025-05-06 21:55:13,243][train][INFO] - Epoch 644/1000, Val Acc=0.7163, Val Loss=1.5326, lr=0.0010
[2025-05-06 21:55:16,849][train][INFO] - Epoch 652/1000, Val Acc=0.6978, Val Loss=1.5962, lr=0.0010
[2025-05-06 21:55:21,266][train][INFO] - Epoch 645/1000, Val Acc=0.7176, Val Loss=1.5260, lr=0.0010
[2025-05-06 21:55:24,762][train][INFO] - Epoch 653/1000, Val Acc=0.6983, Val Loss=1.5925, lr=0.0010
[2025-05-06 21:55:29,903][train][INFO] - Epoch 646/1000, Val Acc=0.7157, Val Loss=1.5314, lr=0.0010
[2025-05-06 21:55:32,796][train][INFO] - Epoch 654/1000, Val Acc=0.6979, Val Loss=1.6003, lr=0.0010
[2025-05-06 21:55:37,910][train][INFO] - Epoch 647/1000, Val Acc=0.7146, Val Loss=1.5311, lr=0.0010
[2025-05-06 21:55:40,282][train][INFO] - Epoch 655/1000, Val Acc=0.6969, Val Loss=1.5976, lr=0.0010
[2025-05-06 21:55:45,274][train][INFO] - Epoch 648/1000, Val Acc=0.7167, Val Loss=1.5246, lr=0.0010
[2025-05-06 21:55:48,550][train][INFO] - Epoch 656/1000, Val Acc=0.7005, Val Loss=1.5917, lr=0.0010
[2025-05-06 21:55:52,925][train][INFO] - Epoch 649/1000, Val Acc=0.7174, Val Loss=1.5252, lr=0.0010
[2025-05-06 21:55:56,691][train][INFO] - Epoch 657/1000, Val Acc=0.6983, Val Loss=1.6033, lr=0.0010
[2025-05-06 21:56:01,466][train][INFO] - Epoch 650/1000, Val Acc=0.7165, Val Loss=1.5303, lr=0.0010
[2025-05-06 21:56:04,593][train][INFO] - Epoch 658/1000, Val Acc=0.6993, Val Loss=1.6066, lr=0.0010
[2025-05-06 21:56:09,441][train][INFO] - Epoch 651/1000, Val Acc=0.7150, Val Loss=1.5314, lr=0.0010
[2025-05-06 21:56:12,484][train][INFO] - Epoch 659/1000, Val Acc=0.6989, Val Loss=1.5987, lr=0.0010
[2025-05-06 21:56:17,420][train][INFO] - Epoch 652/1000, Val Acc=0.7168, Val Loss=1.5278, lr=0.0010
[2025-05-06 21:56:20,608][train][INFO] - Epoch 660/1000, Val Acc=0.6982, Val Loss=1.6118, lr=0.0010
[2025-05-06 21:56:25,940][train][INFO] - Epoch 653/1000, Val Acc=0.7169, Val Loss=1.5329, lr=0.0010
[2025-05-06 21:56:28,108][train][INFO] - Epoch 661/1000, Val Acc=0.6985, Val Loss=1.5995, lr=0.0010
[2025-05-06 21:56:33,779][train][INFO] - Epoch 654/1000, Val Acc=0.7143, Val Loss=1.5363, lr=0.0010
[2025-05-06 21:56:36,510][train][INFO] - Epoch 662/1000, Val Acc=0.6995, Val Loss=1.5926, lr=0.0010
[2025-05-06 21:56:41,781][train][INFO] - Epoch 655/1000, Val Acc=0.7164, Val Loss=1.5284, lr=0.0010
[2025-05-06 21:56:44,296][train][INFO] - Epoch 663/1000, Val Acc=0.6990, Val Loss=1.5934, lr=0.0010
[2025-05-06 21:56:50,181][train][INFO] - Epoch 656/1000, Val Acc=0.7161, Val Loss=1.5330, lr=0.0010
[2025-05-06 21:56:52,574][train][INFO] - Epoch 664/1000, Val Acc=0.6978, Val Loss=1.6028, lr=0.0010
[2025-05-06 21:56:58,172][train][INFO] - Epoch 657/1000, Val Acc=0.7168, Val Loss=1.5324, lr=0.0010
[2025-05-06 21:57:00,570][train][INFO] - Epoch 665/1000, Val Acc=0.6995, Val Loss=1.6032, lr=0.0010
[2025-05-06 21:57:06,220][train][INFO] - Epoch 658/1000, Val Acc=0.7159, Val Loss=1.5337, lr=0.0010
[2025-05-06 21:57:09,144][train][INFO] - Epoch 666/1000, Val Acc=0.6969, Val Loss=1.5960, lr=0.0010
[2025-05-06 21:57:14,543][train][INFO] - Epoch 659/1000, Val Acc=0.7160, Val Loss=1.5285, lr=0.0010
[2025-05-06 21:57:17,195][train][INFO] - Epoch 667/1000, Val Acc=0.6980, Val Loss=1.6040, lr=0.0010
[2025-05-06 21:57:21,945][train][INFO] - Epoch 660/1000, Val Acc=0.7172, Val Loss=1.5383, lr=0.0010
[2025-05-06 21:57:24,782][train][INFO] - Epoch 668/1000, Val Acc=0.6982, Val Loss=1.6010, lr=0.0010
[2025-05-06 21:57:30,017][train][INFO] - Epoch 661/1000, Val Acc=0.7146, Val Loss=1.5388, lr=0.0010
[2025-05-06 21:57:33,087][train][INFO] - Epoch 669/1000, Val Acc=0.7005, Val Loss=1.5988, lr=0.0010
[2025-05-06 21:57:38,481][train][INFO] - Epoch 662/1000, Val Acc=0.7153, Val Loss=1.5293, lr=0.0010
[2025-05-06 21:57:41,314][train][INFO] - Epoch 670/1000, Val Acc=0.6986, Val Loss=1.6053, lr=0.0010
[2025-05-06 21:57:47,037][train][INFO] - Epoch 663/1000, Val Acc=0.7163, Val Loss=1.5331, lr=0.0010
[2025-05-06 21:57:49,904][train][INFO] - Epoch 671/1000, Val Acc=0.6984, Val Loss=1.6049, lr=0.0010
[2025-05-06 21:57:54,889][train][INFO] - Epoch 664/1000, Val Acc=0.7148, Val Loss=1.5327, lr=0.0010
[2025-05-06 21:57:57,903][train][INFO] - Epoch 672/1000, Val Acc=0.6995, Val Loss=1.6058, lr=0.0010
[2025-05-06 21:58:02,920][train][INFO] - Epoch 665/1000, Val Acc=0.7152, Val Loss=1.5373, lr=0.0010
[2025-05-06 21:58:05,399][train][INFO] - Epoch 673/1000, Val Acc=0.7004, Val Loss=1.6064, lr=0.0010
[2025-05-06 21:58:10,966][train][INFO] - Epoch 666/1000, Val Acc=0.7171, Val Loss=1.5380, lr=0.0010
[2025-05-06 21:58:13,149][train][INFO] - Epoch 674/1000, Val Acc=0.6968, Val Loss=1.6126, lr=0.0010
[2025-05-06 21:58:19,082][train][INFO] - Epoch 667/1000, Val Acc=0.7177, Val Loss=1.5308, lr=0.0010
[2025-05-06 21:58:21,612][train][INFO] - Epoch 675/1000, Val Acc=0.7011, Val Loss=1.6137, lr=0.0010
[2025-05-06 21:58:26,481][train][INFO] - Epoch 668/1000, Val Acc=0.7173, Val Loss=1.5296, lr=0.0010
[2025-05-06 21:58:29,895][train][INFO] - Epoch 676/1000, Val Acc=0.7024, Val Loss=1.6052, lr=0.0010
[2025-05-06 21:58:34,519][train][INFO] - Epoch 669/1000, Val Acc=0.7184, Val Loss=1.5259, lr=0.0010
[2025-05-06 21:58:38,246][train][INFO] - Epoch 677/1000, Val Acc=0.7016, Val Loss=1.6180, lr=0.0010
[2025-05-06 21:58:42,797][train][INFO] - Epoch 670/1000, Val Acc=0.7195, Val Loss=1.5279, lr=0.0010
[2025-05-06 21:58:46,248][train][INFO] - Epoch 678/1000, Val Acc=0.7021, Val Loss=1.6098, lr=0.0010
[2025-05-06 21:58:50,385][train][INFO] - Epoch 671/1000, Val Acc=0.7171, Val Loss=1.5349, lr=0.0010
[2025-05-06 21:58:54,606][train][INFO] - Epoch 679/1000, Val Acc=0.6995, Val Loss=1.6156, lr=0.0010
[2025-05-06 21:58:58,462][train][INFO] - Epoch 672/1000, Val Acc=0.7200, Val Loss=1.5329, lr=0.0010
[2025-05-06 21:59:02,924][train][INFO] - Epoch 680/1000, Val Acc=0.7004, Val Loss=1.6093, lr=0.0010
[2025-05-06 21:59:06,882][train][INFO] - Epoch 673/1000, Val Acc=0.7175, Val Loss=1.5327, lr=0.0010
[2025-05-06 21:59:11,147][train][INFO] - Epoch 681/1000, Val Acc=0.6995, Val Loss=1.6242, lr=0.0010
[2025-05-06 21:59:15,077][train][INFO] - Epoch 674/1000, Val Acc=0.7153, Val Loss=1.5398, lr=0.0010
[2025-05-06 21:59:19,204][train][INFO] - Epoch 682/1000, Val Acc=0.7018, Val Loss=1.6126, lr=0.0010
[2025-05-06 21:59:22,943][train][INFO] - Epoch 675/1000, Val Acc=0.7203, Val Loss=1.5303, lr=0.0010
[2025-05-06 21:59:27,910][train][INFO] - Epoch 683/1000, Val Acc=0.6987, Val Loss=1.6259, lr=0.0010
[2025-05-06 21:59:30,924][train][INFO] - Epoch 676/1000, Val Acc=0.7159, Val Loss=1.5350, lr=0.0010
[2025-05-06 21:59:36,235][train][INFO] - Epoch 684/1000, Val Acc=0.7008, Val Loss=1.6216, lr=0.0010
[2025-05-06 21:59:39,219][train][INFO] - Epoch 677/1000, Val Acc=0.7178, Val Loss=1.5338, lr=0.0010
[2025-05-06 21:59:44,271][train][INFO] - Epoch 685/1000, Val Acc=0.6995, Val Loss=1.6171, lr=0.0010
[2025-05-06 21:59:47,002][train][INFO] - Epoch 678/1000, Val Acc=0.7177, Val Loss=1.5325, lr=0.0010
[2025-05-06 21:59:52,499][train][INFO] - Epoch 686/1000, Val Acc=0.7023, Val Loss=1.6138, lr=0.0010
[2025-05-06 21:59:54,851][train][INFO] - Epoch 679/1000, Val Acc=0.7183, Val Loss=1.5368, lr=0.0010
[2025-05-06 22:00:00,188][train][INFO] - Epoch 687/1000, Val Acc=0.7013, Val Loss=1.5995, lr=0.0010
[2025-05-06 22:00:02,921][train][INFO] - Epoch 680/1000, Val Acc=0.7177, Val Loss=1.5324, lr=0.0010
[2025-05-06 22:00:07,552][train][INFO] - Epoch 688/1000, Val Acc=0.7023, Val Loss=1.6129, lr=0.0010
[2025-05-06 22:00:11,236][train][INFO] - Epoch 681/1000, Val Acc=0.7168, Val Loss=1.5430, lr=0.0010
[2025-05-06 22:00:15,080][train][INFO] - Epoch 689/1000, Val Acc=0.7011, Val Loss=1.6209, lr=0.0010
[2025-05-06 22:00:19,050][train][INFO] - Epoch 682/1000, Val Acc=0.7166, Val Loss=1.5387, lr=0.0010
[2025-05-06 22:00:23,445][train][INFO] - Epoch 690/1000, Val Acc=0.6994, Val Loss=1.6183, lr=0.0010
[2025-05-06 22:00:27,192][train][INFO] - Epoch 683/1000, Val Acc=0.7156, Val Loss=1.5407, lr=0.0010
[2025-05-06 22:00:30,752][train][INFO] - Epoch 691/1000, Val Acc=0.7009, Val Loss=1.6203, lr=0.0010
[2025-05-06 22:00:35,444][train][INFO] - Epoch 684/1000, Val Acc=0.7174, Val Loss=1.5416, lr=0.0010
[2025-05-06 22:00:39,245][train][INFO] - Epoch 692/1000, Val Acc=0.7007, Val Loss=1.6131, lr=0.0010
[2025-05-06 22:00:43,775][train][INFO] - Epoch 685/1000, Val Acc=0.7171, Val Loss=1.5385, lr=0.0010
[2025-05-06 22:00:47,764][train][INFO] - Epoch 693/1000, Val Acc=0.7016, Val Loss=1.6129, lr=0.0010
[2025-05-06 22:00:51,722][train][INFO] - Epoch 686/1000, Val Acc=0.7185, Val Loss=1.5351, lr=0.0010
[2025-05-06 22:00:55,678][train][INFO] - Epoch 694/1000, Val Acc=0.7022, Val Loss=1.6250, lr=0.0010
[2025-05-06 22:00:59,626][train][INFO] - Epoch 687/1000, Val Acc=0.7169, Val Loss=1.5370, lr=0.0010
[2025-05-06 22:01:03,938][train][INFO] - Epoch 695/1000, Val Acc=0.6983, Val Loss=1.6329, lr=0.0010
[2025-05-06 22:01:07,608][train][INFO] - Epoch 688/1000, Val Acc=0.7189, Val Loss=1.5333, lr=0.0010
[2025-05-06 22:01:12,040][train][INFO] - Epoch 696/1000, Val Acc=0.6999, Val Loss=1.6264, lr=0.0010
[2025-05-06 22:01:15,744][train][INFO] - Epoch 689/1000, Val Acc=0.7193, Val Loss=1.5407, lr=0.0010
[2025-05-06 22:01:19,755][train][INFO] - Epoch 697/1000, Val Acc=0.7002, Val Loss=1.6229, lr=0.0010
[2025-05-06 22:01:23,942][train][INFO] - Epoch 690/1000, Val Acc=0.7172, Val Loss=1.5383, lr=0.0010
[2025-05-06 22:01:27,318][train][INFO] - Epoch 698/1000, Val Acc=0.7001, Val Loss=1.6149, lr=0.0010
[2025-05-06 22:01:32,282][train][INFO] - Epoch 691/1000, Val Acc=0.7176, Val Loss=1.5340, lr=0.0010
[2025-05-06 22:01:35,091][train][INFO] - Epoch 699/1000, Val Acc=0.6980, Val Loss=1.6232, lr=0.0010
[2025-05-06 22:01:40,442][train][INFO] - Epoch 692/1000, Val Acc=0.7180, Val Loss=1.5323, lr=0.0010
[2025-05-06 22:01:42,843][train][INFO] - Epoch 700/1000, Val Acc=0.6983, Val Loss=1.6294, lr=0.0010
[2025-05-06 22:01:48,491][train][INFO] - Epoch 693/1000, Val Acc=0.7179, Val Loss=1.5380, lr=0.0010
[2025-05-06 22:01:50,616][train][INFO] - Epoch 701/1000, Val Acc=0.6981, Val Loss=1.6346, lr=0.0010
[2025-05-06 22:01:56,389][train][INFO] - Epoch 694/1000, Val Acc=0.7193, Val Loss=1.5347, lr=0.0010
[2025-05-06 22:01:58,014][train][INFO] - Epoch 702/1000, Val Acc=0.7012, Val Loss=1.6270, lr=0.0010
[2025-05-06 22:02:04,177][train][INFO] - Epoch 695/1000, Val Acc=0.7174, Val Loss=1.5382, lr=0.0010
[2025-05-06 22:02:05,999][train][INFO] - Epoch 703/1000, Val Acc=0.7003, Val Loss=1.6362, lr=0.0010
[2025-05-06 22:02:12,161][train][INFO] - Epoch 696/1000, Val Acc=0.7176, Val Loss=1.5375, lr=0.0010
[2025-05-06 22:02:13,875][train][INFO] - Epoch 704/1000, Val Acc=0.7010, Val Loss=1.6368, lr=0.0010
[2025-05-06 22:02:19,837][train][INFO] - Epoch 697/1000, Val Acc=0.7172, Val Loss=1.5397, lr=0.0010
[2025-05-06 22:02:21,902][train][INFO] - Epoch 705/1000, Val Acc=0.7007, Val Loss=1.6402, lr=0.0010
[2025-05-06 22:02:27,310][train][INFO] - Epoch 698/1000, Val Acc=0.7182, Val Loss=1.5263, lr=0.0010
[2025-05-06 22:02:29,582][train][INFO] - Epoch 706/1000, Val Acc=0.6983, Val Loss=1.6355, lr=0.0010
[2025-05-06 22:02:35,222][train][INFO] - Epoch 699/1000, Val Acc=0.7182, Val Loss=1.5289, lr=0.0010
[2025-05-06 22:02:37,621][train][INFO] - Epoch 707/1000, Val Acc=0.6999, Val Loss=1.6316, lr=0.0010
[2025-05-06 22:02:43,760][train][INFO] - Epoch 700/1000, Val Acc=0.7192, Val Loss=1.5351, lr=0.0010
[2025-05-06 22:02:45,871][train][INFO] - Epoch 708/1000, Val Acc=0.7009, Val Loss=1.6333, lr=0.0010
[2025-05-06 22:02:51,489][train][INFO] - Epoch 701/1000, Val Acc=0.7182, Val Loss=1.5384, lr=0.0010
[2025-05-06 22:02:53,854][train][INFO] - Epoch 709/1000, Val Acc=0.6997, Val Loss=1.6334, lr=0.0010
[2025-05-06 22:02:59,733][train][INFO] - Epoch 702/1000, Val Acc=0.7195, Val Loss=1.5330, lr=0.0010
[2025-05-06 22:03:01,787][train][INFO] - Epoch 710/1000, Val Acc=0.6996, Val Loss=1.6310, lr=0.0010
[2025-05-06 22:03:07,327][train][INFO] - Epoch 703/1000, Val Acc=0.7185, Val Loss=1.5335, lr=0.0010
[2025-05-06 22:03:10,252][train][INFO] - Epoch 711/1000, Val Acc=0.7020, Val Loss=1.6253, lr=0.0010
[2025-05-06 22:03:15,509][train][INFO] - Epoch 704/1000, Val Acc=0.7174, Val Loss=1.5305, lr=0.0010
[2025-05-06 22:03:18,244][train][INFO] - Epoch 712/1000, Val Acc=0.7001, Val Loss=1.6409, lr=0.0010
[2025-05-06 22:03:22,631][train][INFO] - Epoch 705/1000, Val Acc=0.7188, Val Loss=1.5299, lr=0.0010
[2025-05-06 22:03:25,639][train][INFO] - Epoch 713/1000, Val Acc=0.6993, Val Loss=1.6397, lr=0.0010
[2025-05-06 22:03:31,057][train][INFO] - Epoch 706/1000, Val Acc=0.7175, Val Loss=1.5370, lr=0.0010
[2025-05-06 22:03:33,467][train][INFO] - Epoch 714/1000, Val Acc=0.7021, Val Loss=1.6344, lr=0.0010
[2025-05-06 22:03:38,685][train][INFO] - Epoch 707/1000, Val Acc=0.7191, Val Loss=1.5369, lr=0.0010
[2025-05-06 22:03:40,870][train][INFO] - Epoch 715/1000, Val Acc=0.6989, Val Loss=1.6313, lr=0.0010
[2025-05-06 22:03:47,086][train][INFO] - Epoch 708/1000, Val Acc=0.7185, Val Loss=1.5438, lr=0.0010
[2025-05-06 22:03:48,216][train][INFO] - Epoch 716/1000, Val Acc=0.7003, Val Loss=1.6294, lr=0.0010
[2025-05-06 22:03:55,161][train][INFO] - Epoch 709/1000, Val Acc=0.7217, Val Loss=1.5336, lr=0.0010
[2025-05-06 22:03:56,448][train][INFO] - Epoch 717/1000, Val Acc=0.7000, Val Loss=1.6389, lr=0.0010
[2025-05-06 22:04:03,761][train][INFO] - Epoch 710/1000, Val Acc=0.7178, Val Loss=1.5444, lr=0.0010
[2025-05-06 22:04:04,947][train][INFO] - Epoch 718/1000, Val Acc=0.6996, Val Loss=1.6442, lr=0.0010
[2025-05-06 22:04:12,127][train][INFO] - Epoch 711/1000, Val Acc=0.7223, Val Loss=1.5308, lr=0.0010
[2025-05-06 22:04:12,172][train][INFO] - Epoch 719/1000, Val Acc=0.6986, Val Loss=1.6333, lr=0.0010
[2025-05-06 22:04:19,585][train][INFO] - Epoch 720/1000, Val Acc=0.6995, Val Loss=1.6327, lr=0.0010
[2025-05-06 22:04:20,306][train][INFO] - Epoch 712/1000, Val Acc=0.7189, Val Loss=1.5476, lr=0.0010
[2025-05-06 22:04:27,579][train][INFO] - Epoch 721/1000, Val Acc=0.7001, Val Loss=1.6313, lr=0.0010
[2025-05-06 22:04:28,524][train][INFO] - Epoch 713/1000, Val Acc=0.7190, Val Loss=1.5384, lr=0.0010
[2025-05-06 22:04:36,060][train][INFO] - Epoch 722/1000, Val Acc=0.6992, Val Loss=1.6409, lr=0.0010
[2025-05-06 22:04:36,646][train][INFO] - Epoch 714/1000, Val Acc=0.7181, Val Loss=1.5369, lr=0.0010
[2025-05-06 22:04:44,396][train][INFO] - Epoch 715/1000, Val Acc=0.7187, Val Loss=1.5374, lr=0.0010
[2025-05-06 22:04:44,517][train][INFO] - Epoch 723/1000, Val Acc=0.6989, Val Loss=1.6374, lr=0.0010
[2025-05-06 22:04:51,992][train][INFO] - Epoch 716/1000, Val Acc=0.7184, Val Loss=1.5340, lr=0.0010
[2025-05-06 22:04:52,214][train][INFO] - Epoch 724/1000, Val Acc=0.6989, Val Loss=1.6458, lr=0.0010
[2025-05-06 22:05:00,187][train][INFO] - Epoch 717/1000, Val Acc=0.7200, Val Loss=1.5304, lr=0.0010
[2025-05-06 22:05:00,954][train][INFO] - Epoch 725/1000, Val Acc=0.6993, Val Loss=1.6420, lr=0.0010
[2025-05-06 22:05:07,901][train][INFO] - Epoch 718/1000, Val Acc=0.7207, Val Loss=1.5302, lr=0.0010
[2025-05-06 22:05:08,561][train][INFO] - Epoch 726/1000, Val Acc=0.6984, Val Loss=1.6512, lr=0.0010
[2025-05-06 22:05:15,803][train][INFO] - Epoch 719/1000, Val Acc=0.7202, Val Loss=1.5308, lr=0.0010
[2025-05-06 22:05:16,962][train][INFO] - Epoch 727/1000, Val Acc=0.6981, Val Loss=1.6428, lr=0.0010
[2025-05-06 22:05:23,517][train][INFO] - Epoch 720/1000, Val Acc=0.7195, Val Loss=1.5262, lr=0.0010
[2025-05-06 22:05:25,107][train][INFO] - Epoch 728/1000, Val Acc=0.7015, Val Loss=1.6441, lr=0.0010
[2025-05-06 22:05:31,535][train][INFO] - Epoch 721/1000, Val Acc=0.7184, Val Loss=1.5401, lr=0.0010
[2025-05-06 22:05:33,093][train][INFO] - Epoch 729/1000, Val Acc=0.6995, Val Loss=1.6381, lr=0.0010
[2025-05-06 22:05:39,714][train][INFO] - Epoch 722/1000, Val Acc=0.7202, Val Loss=1.5315, lr=0.0010
[2025-05-06 22:05:41,317][train][INFO] - Epoch 730/1000, Val Acc=0.6984, Val Loss=1.6464, lr=0.0010
[2025-05-06 22:05:47,208][train][INFO] - Epoch 723/1000, Val Acc=0.7190, Val Loss=1.5376, lr=0.0010
[2025-05-06 22:05:49,238][train][INFO] - Epoch 731/1000, Val Acc=0.7009, Val Loss=1.6395, lr=0.0010
[2025-05-06 22:05:54,907][train][INFO] - Epoch 724/1000, Val Acc=0.7196, Val Loss=1.5324, lr=0.0010
[2025-05-06 22:05:57,389][train][INFO] - Epoch 732/1000, Val Acc=0.7002, Val Loss=1.6388, lr=0.0010
[2025-05-06 22:06:03,171][train][INFO] - Epoch 725/1000, Val Acc=0.7172, Val Loss=1.5444, lr=0.0010
[2025-05-06 22:06:05,132][train][INFO] - Epoch 733/1000, Val Acc=0.6985, Val Loss=1.6461, lr=0.0010
[2025-05-06 22:06:11,339][train][INFO] - Epoch 726/1000, Val Acc=0.7197, Val Loss=1.5456, lr=0.0010
[2025-05-06 22:06:13,043][train][INFO] - Epoch 734/1000, Val Acc=0.6970, Val Loss=1.6431, lr=0.0010
[2025-05-06 22:06:17,965][train][INFO] - Epoch 727/1000, Val Acc=0.7200, Val Loss=1.5337, lr=0.0010
[2025-05-06 22:06:20,814][train][INFO] - Epoch 735/1000, Val Acc=0.7000, Val Loss=1.6559, lr=0.0010
[2025-05-06 22:06:26,191][train][INFO] - Epoch 728/1000, Val Acc=0.7213, Val Loss=1.5306, lr=0.0010
[2025-05-06 22:06:28,910][train][INFO] - Epoch 736/1000, Val Acc=0.6994, Val Loss=1.6510, lr=0.0010
[2025-05-06 22:06:34,498][train][INFO] - Epoch 729/1000, Val Acc=0.7194, Val Loss=1.5370, lr=0.0010
[2025-05-06 22:06:37,169][train][INFO] - Epoch 737/1000, Val Acc=0.6988, Val Loss=1.6367, lr=0.0010
[2025-05-06 22:06:42,828][train][INFO] - Epoch 730/1000, Val Acc=0.7177, Val Loss=1.5418, lr=0.0010
[2025-05-06 22:06:44,452][train][INFO] - Epoch 738/1000, Val Acc=0.6979, Val Loss=1.6491, lr=0.0010
[2025-05-06 22:06:51,020][train][INFO] - Epoch 731/1000, Val Acc=0.7188, Val Loss=1.5399, lr=0.0010
[2025-05-06 22:06:52,898][train][INFO] - Epoch 739/1000, Val Acc=0.6968, Val Loss=1.6497, lr=0.0010
[2025-05-06 22:06:59,046][train][INFO] - Epoch 732/1000, Val Acc=0.7219, Val Loss=1.5369, lr=0.0010
[2025-05-06 22:07:00,682][train][INFO] - Epoch 740/1000, Val Acc=0.6998, Val Loss=1.6535, lr=0.0010
[2025-05-06 22:07:06,388][train][INFO] - Epoch 733/1000, Val Acc=0.7192, Val Loss=1.5335, lr=0.0010
[2025-05-06 22:07:08,896][train][INFO] - Epoch 741/1000, Val Acc=0.7007, Val Loss=1.6440, lr=0.0010
[2025-05-06 22:07:14,728][train][INFO] - Epoch 734/1000, Val Acc=0.7200, Val Loss=1.5340, lr=0.0010
[2025-05-06 22:07:17,271][train][INFO] - Epoch 742/1000, Val Acc=0.6990, Val Loss=1.6529, lr=0.0010
[2025-05-06 22:07:22,904][train][INFO] - Epoch 735/1000, Val Acc=0.7218, Val Loss=1.5360, lr=0.0010
[2025-05-06 22:07:25,053][train][INFO] - Epoch 743/1000, Val Acc=0.7039, Val Loss=1.6381, lr=0.0010
[2025-05-06 22:07:31,532][train][INFO] - Epoch 736/1000, Val Acc=0.7209, Val Loss=1.5327, lr=0.0010
[2025-05-06 22:07:33,378][train][INFO] - Epoch 744/1000, Val Acc=0.7026, Val Loss=1.6414, lr=0.0010
[2025-05-06 22:07:39,903][train][INFO] - Epoch 737/1000, Val Acc=0.7208, Val Loss=1.5390, lr=0.0010
[2025-05-06 22:07:41,326][train][INFO] - Epoch 745/1000, Val Acc=0.6995, Val Loss=1.6560, lr=0.0010
[2025-05-06 22:07:47,412][train][INFO] - Epoch 738/1000, Val Acc=0.7194, Val Loss=1.5354, lr=0.0010
[2025-05-06 22:07:49,309][train][INFO] - Epoch 746/1000, Val Acc=0.7004, Val Loss=1.6621, lr=0.0010
[2025-05-06 22:07:55,357][train][INFO] - Epoch 739/1000, Val Acc=0.7186, Val Loss=1.5408, lr=0.0010
[2025-05-06 22:07:57,073][train][INFO] - Epoch 747/1000, Val Acc=0.7024, Val Loss=1.6512, lr=0.0010
[2025-05-06 22:08:03,475][train][INFO] - Epoch 740/1000, Val Acc=0.7199, Val Loss=1.5392, lr=0.0010
[2025-05-06 22:08:05,199][train][INFO] - Epoch 748/1000, Val Acc=0.7001, Val Loss=1.6481, lr=0.0010
[2025-05-06 22:08:11,334][train][INFO] - Epoch 741/1000, Val Acc=0.7207, Val Loss=1.5347, lr=0.0010
[2025-05-06 22:08:13,093][train][INFO] - Epoch 749/1000, Val Acc=0.7001, Val Loss=1.6573, lr=0.0010
[2025-05-06 22:08:19,494][train][INFO] - Epoch 742/1000, Val Acc=0.7203, Val Loss=1.5368, lr=0.0010
[2025-05-06 22:08:21,030][train][INFO] - Epoch 750/1000, Val Acc=0.6996, Val Loss=1.6585, lr=0.0010
[2025-05-06 22:08:27,498][train][INFO] - Epoch 743/1000, Val Acc=0.7182, Val Loss=1.5363, lr=0.0010
[2025-05-06 22:08:29,124][train][INFO] - Epoch 751/1000, Val Acc=0.6997, Val Loss=1.6643, lr=0.0010
[2025-05-06 22:08:35,786][train][INFO] - Epoch 744/1000, Val Acc=0.7210, Val Loss=1.5258, lr=0.0010
[2025-05-06 22:08:36,951][train][INFO] - Epoch 752/1000, Val Acc=0.7038, Val Loss=1.6431, lr=0.0010
[2025-05-06 22:08:43,350][train][INFO] - Epoch 745/1000, Val Acc=0.7195, Val Loss=1.5331, lr=0.0010
[2025-05-06 22:08:44,603][train][INFO] - Epoch 753/1000, Val Acc=0.7013, Val Loss=1.6503, lr=0.0010
[2025-05-06 22:08:51,304][train][INFO] - Epoch 746/1000, Val Acc=0.7225, Val Loss=1.5315, lr=0.0010
[2025-05-06 22:08:52,590][train][INFO] - Epoch 754/1000, Val Acc=0.7014, Val Loss=1.6632, lr=0.0010
[2025-05-06 22:08:59,621][train][INFO] - Epoch 747/1000, Val Acc=0.7218, Val Loss=1.5344, lr=0.0010
[2025-05-06 22:09:00,864][train][INFO] - Epoch 755/1000, Val Acc=0.7022, Val Loss=1.6601, lr=0.0010
[2025-05-06 22:09:07,836][train][INFO] - Epoch 748/1000, Val Acc=0.7202, Val Loss=1.5393, lr=0.0010
[2025-05-06 22:09:08,745][train][INFO] - Epoch 756/1000, Val Acc=0.7019, Val Loss=1.6531, lr=0.0010
[2025-05-06 22:09:15,567][train][INFO] - Epoch 749/1000, Val Acc=0.7191, Val Loss=1.5403, lr=0.0010
[2025-05-06 22:09:16,339][train][INFO] - Epoch 757/1000, Val Acc=0.6988, Val Loss=1.6515, lr=0.0010
[2025-05-06 22:09:23,912][train][INFO] - Epoch 750/1000, Val Acc=0.7222, Val Loss=1.5313, lr=0.0010
[2025-05-06 22:09:24,287][train][INFO] - Epoch 758/1000, Val Acc=0.6999, Val Loss=1.6590, lr=0.0010
[2025-05-06 22:09:31,680][train][INFO] - Epoch 759/1000, Val Acc=0.7033, Val Loss=1.6503, lr=0.0010
[2025-05-06 22:09:31,808][train][INFO] - Epoch 751/1000, Val Acc=0.7213, Val Loss=1.5365, lr=0.0010
[2025-05-06 22:09:39,909][train][INFO] - Epoch 760/1000, Val Acc=0.7019, Val Loss=1.6542, lr=0.0010
[2025-05-06 22:09:40,018][train][INFO] - Epoch 752/1000, Val Acc=0.7213, Val Loss=1.5256, lr=0.0010
[2025-05-06 22:09:47,895][train][INFO] - Epoch 761/1000, Val Acc=0.7004, Val Loss=1.6669, lr=0.0010
[2025-05-06 22:09:48,576][train][INFO] - Epoch 753/1000, Val Acc=0.7202, Val Loss=1.5377, lr=0.0010
[2025-05-06 22:09:55,611][train][INFO] - Epoch 762/1000, Val Acc=0.7003, Val Loss=1.6526, lr=0.0010
[2025-05-06 22:09:56,748][train][INFO] - Epoch 754/1000, Val Acc=0.7182, Val Loss=1.5495, lr=0.0010
[2025-05-06 22:10:03,856][train][INFO] - Epoch 763/1000, Val Acc=0.6998, Val Loss=1.6501, lr=0.0010
[2025-05-06 22:10:04,767][train][INFO] - Epoch 755/1000, Val Acc=0.7192, Val Loss=1.5460, lr=0.0010
[2025-05-06 22:10:12,035][train][INFO] - Epoch 764/1000, Val Acc=0.6999, Val Loss=1.6705, lr=0.0010
[2025-05-06 22:10:13,014][train][INFO] - Epoch 756/1000, Val Acc=0.7177, Val Loss=1.5490, lr=0.0010
[2025-05-06 22:10:20,455][train][INFO] - Epoch 765/1000, Val Acc=0.7000, Val Loss=1.6628, lr=0.0010
[2025-05-06 22:10:20,845][train][INFO] - Epoch 757/1000, Val Acc=0.7172, Val Loss=1.5501, lr=0.0010
[2025-05-06 22:10:28,301][train][INFO] - Epoch 766/1000, Val Acc=0.7006, Val Loss=1.6588, lr=0.0010
[2025-05-06 22:10:28,670][train][INFO] - Epoch 758/1000, Val Acc=0.7186, Val Loss=1.5467, lr=0.0010
[2025-05-06 22:10:36,361][train][INFO] - Epoch 759/1000, Val Acc=0.7189, Val Loss=1.5542, lr=0.0010
[2025-05-06 22:10:36,402][train][INFO] - Epoch 767/1000, Val Acc=0.7011, Val Loss=1.6574, lr=0.0010
[2025-05-06 22:10:44,647][train][INFO] - Epoch 768/1000, Val Acc=0.6973, Val Loss=1.6753, lr=0.0010
[2025-05-06 22:10:44,651][train][INFO] - Epoch 760/1000, Val Acc=0.7207, Val Loss=1.5450, lr=0.0010
[2025-05-06 22:10:52,963][train][INFO] - Epoch 761/1000, Val Acc=0.7180, Val Loss=1.5583, lr=0.0010
[2025-05-06 22:10:53,069][train][INFO] - Epoch 769/1000, Val Acc=0.6992, Val Loss=1.6666, lr=0.0010
[2025-05-06 22:11:00,584][train][INFO] - Epoch 762/1000, Val Acc=0.7200, Val Loss=1.5557, lr=0.0010
[2025-05-06 22:11:01,082][train][INFO] - Epoch 770/1000, Val Acc=0.6991, Val Loss=1.6691, lr=0.0010
[2025-05-06 22:11:09,061][train][INFO] - Epoch 763/1000, Val Acc=0.7207, Val Loss=1.5451, lr=0.0010
[2025-05-06 22:11:09,176][train][INFO] - Epoch 771/1000, Val Acc=0.7008, Val Loss=1.6695, lr=0.0010
[2025-05-06 22:11:16,282][train][INFO] - Epoch 764/1000, Val Acc=0.7193, Val Loss=1.5499, lr=0.0010
[2025-05-06 22:11:17,502][train][INFO] - Epoch 772/1000, Val Acc=0.7001, Val Loss=1.6661, lr=0.0010
[2025-05-06 22:11:24,396][train][INFO] - Epoch 765/1000, Val Acc=0.7208, Val Loss=1.5381, lr=0.0010
[2025-05-06 22:11:25,668][train][INFO] - Epoch 773/1000, Val Acc=0.7003, Val Loss=1.6682, lr=0.0010
[2025-05-06 22:11:32,555][train][INFO] - Epoch 766/1000, Val Acc=0.7203, Val Loss=1.5506, lr=0.0010
[2025-05-06 22:11:33,649][train][INFO] - Epoch 774/1000, Val Acc=0.6991, Val Loss=1.6717, lr=0.0010
[2025-05-06 22:11:40,219][train][INFO] - Epoch 767/1000, Val Acc=0.7210, Val Loss=1.5516, lr=0.0010
[2025-05-06 22:11:41,679][train][INFO] - Epoch 775/1000, Val Acc=0.7003, Val Loss=1.6789, lr=0.0010
[2025-05-06 22:11:48,364][train][INFO] - Epoch 768/1000, Val Acc=0.7191, Val Loss=1.5511, lr=0.0010
[2025-05-06 22:11:49,758][train][INFO] - Epoch 776/1000, Val Acc=0.7002, Val Loss=1.6746, lr=0.0010
[2025-05-06 22:11:56,708][train][INFO] - Epoch 769/1000, Val Acc=0.7204, Val Loss=1.5489, lr=0.0010
[2025-05-06 22:11:57,504][train][INFO] - Epoch 777/1000, Val Acc=0.6988, Val Loss=1.6767, lr=0.0010
[2025-05-06 22:12:05,458][train][INFO] - Epoch 770/1000, Val Acc=0.7192, Val Loss=1.5546, lr=0.0010
[2025-05-06 22:12:05,631][train][INFO] - Epoch 778/1000, Val Acc=0.7017, Val Loss=1.6687, lr=0.0010
[2025-05-06 22:12:13,283][train][INFO] - Epoch 771/1000, Val Acc=0.7197, Val Loss=1.5457, lr=0.0010
[2025-05-06 22:12:14,220][train][INFO] - Epoch 779/1000, Val Acc=0.7023, Val Loss=1.6740, lr=0.0010
[2025-05-06 22:12:21,126][train][INFO] - Epoch 772/1000, Val Acc=0.7222, Val Loss=1.5476, lr=0.0010
[2025-05-06 22:12:21,873][train][INFO] - Epoch 780/1000, Val Acc=0.6996, Val Loss=1.6799, lr=0.0010
[2025-05-06 22:12:28,904][train][INFO] - Epoch 773/1000, Val Acc=0.7197, Val Loss=1.5498, lr=0.0010
[2025-05-06 22:12:30,021][train][INFO] - Epoch 781/1000, Val Acc=0.7023, Val Loss=1.6825, lr=0.0010
[2025-05-06 22:12:37,083][train][INFO] - Epoch 774/1000, Val Acc=0.7208, Val Loss=1.5537, lr=0.0010
[2025-05-06 22:12:37,995][train][INFO] - Epoch 782/1000, Val Acc=0.6994, Val Loss=1.6899, lr=0.0010
[2025-05-06 22:12:45,471][train][INFO] - Epoch 775/1000, Val Acc=0.7202, Val Loss=1.5496, lr=0.0010
[2025-05-06 22:12:46,212][train][INFO] - Epoch 783/1000, Val Acc=0.6992, Val Loss=1.6824, lr=0.0010
[2025-05-06 22:12:53,870][train][INFO] - Epoch 776/1000, Val Acc=0.7212, Val Loss=1.5457, lr=0.0010
[2025-05-06 22:12:54,121][train][INFO] - Epoch 784/1000, Val Acc=0.7020, Val Loss=1.6847, lr=0.0010
[2025-05-06 22:13:01,671][train][INFO] - Epoch 777/1000, Val Acc=0.7219, Val Loss=1.5478, lr=0.0010
[2025-05-06 22:13:02,040][train][INFO] - Epoch 785/1000, Val Acc=0.6991, Val Loss=1.6940, lr=0.0010
[2025-05-06 22:13:09,982][train][INFO] - Epoch 778/1000, Val Acc=0.7192, Val Loss=1.5624, lr=0.0010
[2025-05-06 22:13:10,051][train][INFO] - Epoch 786/1000, Val Acc=0.7008, Val Loss=1.6826, lr=0.0010
[2025-05-06 22:13:18,219][train][INFO] - Epoch 787/1000, Val Acc=0.7014, Val Loss=1.6684, lr=0.0010
[2025-05-06 22:13:18,268][train][INFO] - Epoch 779/1000, Val Acc=0.7219, Val Loss=1.5595, lr=0.0010
[2025-05-06 22:13:26,156][train][INFO] - Epoch 780/1000, Val Acc=0.7202, Val Loss=1.5524, lr=0.0010
[2025-05-06 22:13:26,453][train][INFO] - Epoch 788/1000, Val Acc=0.6977, Val Loss=1.6842, lr=0.0010
[2025-05-06 22:13:33,867][train][INFO] - Epoch 789/1000, Val Acc=0.6994, Val Loss=1.6785, lr=0.0010
[2025-05-06 22:13:34,294][train][INFO] - Epoch 781/1000, Val Acc=0.7220, Val Loss=1.5527, lr=0.0010
[2025-05-06 22:13:41,601][train][INFO] - Epoch 790/1000, Val Acc=0.7023, Val Loss=1.6662, lr=0.0010
[2025-05-06 22:13:42,467][train][INFO] - Epoch 782/1000, Val Acc=0.7218, Val Loss=1.5476, lr=0.0010
[2025-05-06 22:13:49,389][train][INFO] - Epoch 791/1000, Val Acc=0.7003, Val Loss=1.6813, lr=0.0010
[2025-05-06 22:13:50,960][train][INFO] - Epoch 783/1000, Val Acc=0.7208, Val Loss=1.5521, lr=0.0010
[2025-05-06 22:13:56,783][train][INFO] - Epoch 792/1000, Val Acc=0.6993, Val Loss=1.6889, lr=0.0010
[2025-05-06 22:13:57,630][train][INFO] - Epoch 784/1000, Val Acc=0.7189, Val Loss=1.5591, lr=0.0010
[2025-05-06 22:14:04,905][train][INFO] - Epoch 793/1000, Val Acc=0.6995, Val Loss=1.6694, lr=0.0010
[2025-05-06 22:14:05,739][train][INFO] - Epoch 785/1000, Val Acc=0.7184, Val Loss=1.5617, lr=0.0010
[2025-05-06 22:14:12,596][train][INFO] - Epoch 794/1000, Val Acc=0.6997, Val Loss=1.6765, lr=0.0010
[2025-05-06 22:14:13,402][train][INFO] - Epoch 786/1000, Val Acc=0.7209, Val Loss=1.5566, lr=0.0010
[2025-05-06 22:14:20,944][train][INFO] - Epoch 787/1000, Val Acc=0.7202, Val Loss=1.5512, lr=0.0010
[2025-05-06 22:14:20,956][train][INFO] - Epoch 795/1000, Val Acc=0.6963, Val Loss=1.6920, lr=0.0010
[2025-05-06 22:14:28,998][train][INFO] - Epoch 788/1000, Val Acc=0.7218, Val Loss=1.5585, lr=0.0010
[2025-05-06 22:14:29,132][train][INFO] - Epoch 796/1000, Val Acc=0.6995, Val Loss=1.6795, lr=0.0010
[2025-05-06 22:14:36,829][train][INFO] - Epoch 789/1000, Val Acc=0.7208, Val Loss=1.5608, lr=0.0010
[2025-05-06 22:14:37,026][train][INFO] - Epoch 797/1000, Val Acc=0.6970, Val Loss=1.7012, lr=0.0010
[2025-05-06 22:14:44,389][train][INFO] - Epoch 798/1000, Val Acc=0.6959, Val Loss=1.6996, lr=0.0010
[2025-05-06 22:14:45,387][train][INFO] - Epoch 790/1000, Val Acc=0.7197, Val Loss=1.5644, lr=0.0010
[2025-05-06 22:14:52,546][train][INFO] - Epoch 799/1000, Val Acc=0.6991, Val Loss=1.6929, lr=0.0010
[2025-05-06 22:14:53,626][train][INFO] - Epoch 791/1000, Val Acc=0.7204, Val Loss=1.5604, lr=0.0010
[2025-05-06 22:15:00,927][train][INFO] - Epoch 800/1000, Val Acc=0.7009, Val Loss=1.6840, lr=0.0010
[2025-05-06 22:15:01,936][train][INFO] - Epoch 792/1000, Val Acc=0.7189, Val Loss=1.5703, lr=0.0010
[2025-05-06 22:15:08,917][train][INFO] - Epoch 801/1000, Val Acc=0.6982, Val Loss=1.6784, lr=0.0010
[2025-05-06 22:15:10,059][train][INFO] - Epoch 793/1000, Val Acc=0.7195, Val Loss=1.5604, lr=0.0010
[2025-05-06 22:15:17,547][train][INFO] - Epoch 802/1000, Val Acc=0.6992, Val Loss=1.7080, lr=0.0010
[2025-05-06 22:15:18,138][train][INFO] - Epoch 794/1000, Val Acc=0.7190, Val Loss=1.5624, lr=0.0010
[2025-05-06 22:15:25,375][train][INFO] - Epoch 803/1000, Val Acc=0.6975, Val Loss=1.6915, lr=0.0010
[2025-05-06 22:15:26,350][train][INFO] - Epoch 795/1000, Val Acc=0.7197, Val Loss=1.5654, lr=0.0010
[2025-05-06 22:15:33,289][train][INFO] - Epoch 804/1000, Val Acc=0.6984, Val Loss=1.6963, lr=0.0010
[2025-05-06 22:15:33,912][train][INFO] - Epoch 796/1000, Val Acc=0.7193, Val Loss=1.5727, lr=0.0010
[2025-05-06 22:15:40,771][train][INFO] - Epoch 805/1000, Val Acc=0.6964, Val Loss=1.6959, lr=0.0010
[2025-05-06 22:15:42,381][train][INFO] - Epoch 797/1000, Val Acc=0.7190, Val Loss=1.5703, lr=0.0010
[2025-05-06 22:15:48,773][train][INFO] - Epoch 806/1000, Val Acc=0.6952, Val Loss=1.7013, lr=0.0010
[2025-05-06 22:15:51,084][train][INFO] - Epoch 798/1000, Val Acc=0.7188, Val Loss=1.5684, lr=0.0010
[2025-05-06 22:15:56,811][train][INFO] - Epoch 807/1000, Val Acc=0.6974, Val Loss=1.6900, lr=0.0010
[2025-05-06 22:15:59,100][train][INFO] - Epoch 799/1000, Val Acc=0.7175, Val Loss=1.5805, lr=0.0010
[2025-05-06 22:16:04,757][train][INFO] - Epoch 808/1000, Val Acc=0.6976, Val Loss=1.6983, lr=0.0010
[2025-05-06 22:16:07,596][train][INFO] - Epoch 800/1000, Val Acc=0.7164, Val Loss=1.5763, lr=0.0010
[2025-05-06 22:16:11,981][train][INFO] - Epoch 809/1000, Val Acc=0.6938, Val Loss=1.7192, lr=0.0010
[2025-05-06 22:16:15,949][train][INFO] - Epoch 801/1000, Val Acc=0.7191, Val Loss=1.5747, lr=0.0010
[2025-05-06 22:16:20,003][train][INFO] - Epoch 810/1000, Val Acc=0.6955, Val Loss=1.7139, lr=0.0010
[2025-05-06 22:16:24,219][train][INFO] - Epoch 802/1000, Val Acc=0.7192, Val Loss=1.5811, lr=0.0010
[2025-05-06 22:16:28,035][train][INFO] - Epoch 811/1000, Val Acc=0.6969, Val Loss=1.7139, lr=0.0010
[2025-05-06 22:16:32,837][train][INFO] - Epoch 803/1000, Val Acc=0.7205, Val Loss=1.5665, lr=0.0010
[2025-05-06 22:16:35,523][train][INFO] - Epoch 812/1000, Val Acc=0.6971, Val Loss=1.7185, lr=0.0010
[2025-05-06 22:16:41,301][train][INFO] - Epoch 804/1000, Val Acc=0.7188, Val Loss=1.5643, lr=0.0010
[2025-05-06 22:16:43,652][train][INFO] - Epoch 813/1000, Val Acc=0.6961, Val Loss=1.7074, lr=0.0010
[2025-05-06 22:16:49,480][train][INFO] - Epoch 805/1000, Val Acc=0.7196, Val Loss=1.5683, lr=0.0010
[2025-05-06 22:16:51,519][train][INFO] - Epoch 814/1000, Val Acc=0.6944, Val Loss=1.7012, lr=0.0010
[2025-05-06 22:16:57,298][train][INFO] - Epoch 806/1000, Val Acc=0.7212, Val Loss=1.5626, lr=0.0010
[2025-05-06 22:16:58,669][train][INFO] - Epoch 815/1000, Val Acc=0.6945, Val Loss=1.7076, lr=0.0010
[2025-05-06 22:17:05,794][train][INFO] - Epoch 807/1000, Val Acc=0.7172, Val Loss=1.5681, lr=0.0010
[2025-05-06 22:17:06,660][train][INFO] - Epoch 816/1000, Val Acc=0.6940, Val Loss=1.7141, lr=0.0010
[2025-05-06 22:17:13,637][train][INFO] - Epoch 808/1000, Val Acc=0.7189, Val Loss=1.5691, lr=0.0010
[2025-05-06 22:17:14,651][train][INFO] - Epoch 817/1000, Val Acc=0.6945, Val Loss=1.7257, lr=0.0010
[2025-05-06 22:17:21,706][train][INFO] - Epoch 809/1000, Val Acc=0.7218, Val Loss=1.5660, lr=0.0010
[2025-05-06 22:17:22,960][train][INFO] - Epoch 818/1000, Val Acc=0.6957, Val Loss=1.7029, lr=0.0010
[2025-05-06 22:17:29,659][train][INFO] - Epoch 810/1000, Val Acc=0.7190, Val Loss=1.5683, lr=0.0010
[2025-05-06 22:17:31,293][train][INFO] - Epoch 819/1000, Val Acc=0.6931, Val Loss=1.7069, lr=0.0010
[2025-05-06 22:17:37,533][train][INFO] - Epoch 811/1000, Val Acc=0.7212, Val Loss=1.5578, lr=0.0010
[2025-05-06 22:17:39,369][train][INFO] - Epoch 820/1000, Val Acc=0.6954, Val Loss=1.7097, lr=0.0010
[2025-05-06 22:17:45,503][train][INFO] - Epoch 812/1000, Val Acc=0.7186, Val Loss=1.5722, lr=0.0010
[2025-05-06 22:17:47,099][train][INFO] - Epoch 821/1000, Val Acc=0.6945, Val Loss=1.7265, lr=0.0010
[2025-05-06 22:17:53,235][train][INFO] - Epoch 813/1000, Val Acc=0.7201, Val Loss=1.5691, lr=0.0010
[2025-05-06 22:17:54,283][train][INFO] - Epoch 822/1000, Val Acc=0.6966, Val Loss=1.7247, lr=0.0010
[2025-05-06 22:18:01,560][train][INFO] - Epoch 814/1000, Val Acc=0.7193, Val Loss=1.5709, lr=0.0010
[2025-05-06 22:18:02,053][train][INFO] - Epoch 823/1000, Val Acc=0.6948, Val Loss=1.7250, lr=0.0010
[2025-05-06 22:18:09,286][train][INFO] - Epoch 815/1000, Val Acc=0.7184, Val Loss=1.5643, lr=0.0010
[2025-05-06 22:18:10,515][train][INFO] - Epoch 824/1000, Val Acc=0.6949, Val Loss=1.7260, lr=0.0010
[2025-05-06 22:18:17,004][train][INFO] - Epoch 816/1000, Val Acc=0.7187, Val Loss=1.5670, lr=0.0010
[2025-05-06 22:18:18,011][train][INFO] - Epoch 825/1000, Val Acc=0.6957, Val Loss=1.7325, lr=0.0010
[2025-05-06 22:18:25,305][train][INFO] - Epoch 826/1000, Val Acc=0.6920, Val Loss=1.7362, lr=0.0010
[2025-05-06 22:18:25,516][train][INFO] - Epoch 817/1000, Val Acc=0.7178, Val Loss=1.5719, lr=0.0010
[2025-05-06 22:18:33,318][train][INFO] - Epoch 818/1000, Val Acc=0.7184, Val Loss=1.5814, lr=0.0010
[2025-05-06 22:18:33,516][train][INFO] - Epoch 827/1000, Val Acc=0.6948, Val Loss=1.7363, lr=0.0010
[2025-05-06 22:18:41,597][train][INFO] - Epoch 828/1000, Val Acc=0.6957, Val Loss=1.7530, lr=0.0010
[2025-05-06 22:18:41,653][train][INFO] - Epoch 819/1000, Val Acc=0.7157, Val Loss=1.5917, lr=0.0010
[2025-05-06 22:18:49,190][train][INFO] - Epoch 820/1000, Val Acc=0.7154, Val Loss=1.5961, lr=0.0010
[2025-05-06 22:18:49,891][train][INFO] - Epoch 829/1000, Val Acc=0.6938, Val Loss=1.7739, lr=0.0010
[2025-05-06 22:18:57,071][train][INFO] - Epoch 821/1000, Val Acc=0.7174, Val Loss=1.5902, lr=0.0010
[2025-05-06 22:18:58,149][train][INFO] - Epoch 830/1000, Val Acc=0.6948, Val Loss=1.7469, lr=0.0010
[2025-05-06 22:19:04,368][train][INFO] - Epoch 822/1000, Val Acc=0.7154, Val Loss=1.5939, lr=0.0010
[2025-05-06 22:19:06,429][train][INFO] - Epoch 831/1000, Val Acc=0.6914, Val Loss=1.7452, lr=0.0010
[2025-05-06 22:19:11,888][train][INFO] - Epoch 823/1000, Val Acc=0.7179, Val Loss=1.5800, lr=0.0010
[2025-05-06 22:19:14,665][train][INFO] - Epoch 832/1000, Val Acc=0.6921, Val Loss=1.7565, lr=0.0010
[2025-05-06 22:19:19,785][train][INFO] - Epoch 824/1000, Val Acc=0.7169, Val Loss=1.5875, lr=0.0010
[2025-05-06 22:19:23,008][train][INFO] - Epoch 833/1000, Val Acc=0.6939, Val Loss=1.7336, lr=0.0010
[2025-05-06 22:19:27,910][train][INFO] - Epoch 825/1000, Val Acc=0.7187, Val Loss=1.5759, lr=0.0010
[2025-05-06 22:19:30,779][train][INFO] - Epoch 834/1000, Val Acc=0.6930, Val Loss=1.7422, lr=0.0010
[2025-05-06 22:19:35,581][train][INFO] - Epoch 826/1000, Val Acc=0.7157, Val Loss=1.5851, lr=0.0010
[2025-05-06 22:19:38,846][train][INFO] - Epoch 835/1000, Val Acc=0.6926, Val Loss=1.7383, lr=0.0010
[2025-05-06 22:19:43,013][train][INFO] - Epoch 827/1000, Val Acc=0.7163, Val Loss=1.5882, lr=0.0010
[2025-05-06 22:19:46,804][train][INFO] - Epoch 836/1000, Val Acc=0.6904, Val Loss=1.7388, lr=0.0010
[2025-05-06 22:19:51,263][train][INFO] - Epoch 828/1000, Val Acc=0.7188, Val Loss=1.5800, lr=0.0010
[2025-05-06 22:19:54,884][train][INFO] - Epoch 837/1000, Val Acc=0.6938, Val Loss=1.7513, lr=0.0010
[2025-05-06 22:19:59,314][train][INFO] - Epoch 829/1000, Val Acc=0.7214, Val Loss=1.5756, lr=0.0010
[2025-05-06 22:20:02,785][train][INFO] - Epoch 838/1000, Val Acc=0.6956, Val Loss=1.7337, lr=0.0010
[2025-05-06 22:20:07,618][train][INFO] - Epoch 830/1000, Val Acc=0.7191, Val Loss=1.5810, lr=0.0010
[2025-05-06 22:20:10,721][train][INFO] - Epoch 839/1000, Val Acc=0.6931, Val Loss=1.7325, lr=0.0010
[2025-05-06 22:20:15,557][train][INFO] - Epoch 831/1000, Val Acc=0.7174, Val Loss=1.5872, lr=0.0010
[2025-05-06 22:20:18,896][train][INFO] - Epoch 840/1000, Val Acc=0.6941, Val Loss=1.7249, lr=0.0010
[2025-05-06 22:20:23,408][train][INFO] - Epoch 832/1000, Val Acc=0.7191, Val Loss=1.5850, lr=0.0010
[2025-05-06 22:20:26,411][train][INFO] - Epoch 841/1000, Val Acc=0.6925, Val Loss=1.7314, lr=0.0010
[2025-05-06 22:20:31,396][train][INFO] - Epoch 833/1000, Val Acc=0.7181, Val Loss=1.5789, lr=0.0010
[2025-05-06 22:20:34,352][train][INFO] - Epoch 842/1000, Val Acc=0.6936, Val Loss=1.7273, lr=0.0010
[2025-05-06 22:20:39,937][train][INFO] - Epoch 834/1000, Val Acc=0.7174, Val Loss=1.5843, lr=0.0010
[2025-05-06 22:20:42,747][train][INFO] - Epoch 843/1000, Val Acc=0.6927, Val Loss=1.7429, lr=0.0010
[2025-05-06 22:20:47,848][train][INFO] - Epoch 835/1000, Val Acc=0.7172, Val Loss=1.5850, lr=0.0010
[2025-05-06 22:20:51,039][train][INFO] - Epoch 844/1000, Val Acc=0.6931, Val Loss=1.7521, lr=0.0010
[2025-05-06 22:20:56,023][train][INFO] - Epoch 836/1000, Val Acc=0.7181, Val Loss=1.5877, lr=0.0010
[2025-05-06 22:20:59,057][train][INFO] - Epoch 845/1000, Val Acc=0.6942, Val Loss=1.7466, lr=0.0010
[2025-05-06 22:21:03,843][train][INFO] - Epoch 837/1000, Val Acc=0.7183, Val Loss=1.5887, lr=0.0010
[2025-05-06 22:21:07,171][train][INFO] - Epoch 846/1000, Val Acc=0.6929, Val Loss=1.7437, lr=0.0010
[2025-05-06 22:21:11,696][train][INFO] - Epoch 838/1000, Val Acc=0.7184, Val Loss=1.5869, lr=0.0010
[2025-05-06 22:21:14,421][train][INFO] - Epoch 847/1000, Val Acc=0.6944, Val Loss=1.7435, lr=0.0010
[2025-05-06 22:21:19,779][train][INFO] - Epoch 839/1000, Val Acc=0.7186, Val Loss=1.5794, lr=0.0010
[2025-05-06 22:21:21,327][train][INFO] - Epoch 848/1000, Val Acc=0.6939, Val Loss=1.7364, lr=0.0010
[2025-05-06 22:21:27,718][train][INFO] - Epoch 840/1000, Val Acc=0.7204, Val Loss=1.5899, lr=0.0010
[2025-05-06 22:21:29,049][train][INFO] - Epoch 849/1000, Val Acc=0.6946, Val Loss=1.7277, lr=0.0010
[2025-05-06 22:21:35,650][train][INFO] - Epoch 841/1000, Val Acc=0.7187, Val Loss=1.5901, lr=0.0010
[2025-05-06 22:21:37,176][train][INFO] - Epoch 850/1000, Val Acc=0.6927, Val Loss=1.7454, lr=0.0010
[2025-05-06 22:21:43,737][train][INFO] - Epoch 842/1000, Val Acc=0.7189, Val Loss=1.5836, lr=0.0010
[2025-05-06 22:21:44,907][train][INFO] - Epoch 851/1000, Val Acc=0.6937, Val Loss=1.7584, lr=0.0010
[2025-05-06 22:21:51,565][train][INFO] - Epoch 852/1000, Val Acc=0.6957, Val Loss=1.7334, lr=0.0010
[2025-05-06 22:21:51,626][train][INFO] - Epoch 843/1000, Val Acc=0.7173, Val Loss=1.5886, lr=0.0010
[2025-05-06 22:21:59,250][train][INFO] - Epoch 853/1000, Val Acc=0.6909, Val Loss=1.7600, lr=0.0010
[2025-05-06 22:22:00,042][train][INFO] - Epoch 844/1000, Val Acc=0.7158, Val Loss=1.5953, lr=0.0010
[2025-05-06 22:22:07,556][train][INFO] - Epoch 854/1000, Val Acc=0.6908, Val Loss=1.7475, lr=0.0010
[2025-05-06 22:22:08,095][train][INFO] - Epoch 845/1000, Val Acc=0.7174, Val Loss=1.5944, lr=0.0010
[2025-05-06 22:22:15,029][train][INFO] - Epoch 855/1000, Val Acc=0.6926, Val Loss=1.7493, lr=0.0010
[2025-05-06 22:22:16,339][train][INFO] - Epoch 846/1000, Val Acc=0.7191, Val Loss=1.5885, lr=0.0010
[2025-05-06 22:22:23,500][train][INFO] - Epoch 856/1000, Val Acc=0.6921, Val Loss=1.7524, lr=0.0010
[2025-05-06 22:22:24,594][train][INFO] - Epoch 847/1000, Val Acc=0.7200, Val Loss=1.5869, lr=0.0010
[2025-05-06 22:22:31,321][train][INFO] - Epoch 857/1000, Val Acc=0.6881, Val Loss=1.7824, lr=0.0010
[2025-05-06 22:22:32,447][train][INFO] - Epoch 848/1000, Val Acc=0.7199, Val Loss=1.5796, lr=0.0010
[2025-05-06 22:22:38,559][train][INFO] - Epoch 858/1000, Val Acc=0.6930, Val Loss=1.7636, lr=0.0010
[2025-05-06 22:22:40,412][train][INFO] - Epoch 849/1000, Val Acc=0.7212, Val Loss=1.5859, lr=0.0010
[2025-05-06 22:22:46,631][train][INFO] - Epoch 859/1000, Val Acc=0.6949, Val Loss=1.7419, lr=0.0010
[2025-05-06 22:22:48,871][train][INFO] - Epoch 850/1000, Val Acc=0.7184, Val Loss=1.5846, lr=0.0010
[2025-05-06 22:22:54,653][train][INFO] - Epoch 860/1000, Val Acc=0.6939, Val Loss=1.7374, lr=0.0010
[2025-05-06 22:22:57,412][train][INFO] - Epoch 851/1000, Val Acc=0.7176, Val Loss=1.6024, lr=0.0010
[2025-05-06 22:23:02,620][train][INFO] - Epoch 861/1000, Val Acc=0.6900, Val Loss=1.7508, lr=0.0010
[2025-05-06 22:23:06,025][train][INFO] - Epoch 852/1000, Val Acc=0.7186, Val Loss=1.5930, lr=0.0010
[2025-05-06 22:23:11,078][train][INFO] - Epoch 862/1000, Val Acc=0.6895, Val Loss=1.7398, lr=0.0010
[2025-05-06 22:23:14,112][train][INFO] - Epoch 853/1000, Val Acc=0.7187, Val Loss=1.5874, lr=0.0010
[2025-05-06 22:23:19,134][train][INFO] - Epoch 863/1000, Val Acc=0.6882, Val Loss=1.7669, lr=0.0010
[2025-05-06 22:23:21,867][train][INFO] - Epoch 854/1000, Val Acc=0.7191, Val Loss=1.5842, lr=0.0010
[2025-05-06 22:23:27,355][train][INFO] - Epoch 864/1000, Val Acc=0.6899, Val Loss=1.7558, lr=0.0010
[2025-05-06 22:23:30,225][train][INFO] - Epoch 855/1000, Val Acc=0.7186, Val Loss=1.6014, lr=0.0010
[2025-05-06 22:23:35,502][train][INFO] - Epoch 865/1000, Val Acc=0.6899, Val Loss=1.7534, lr=0.0010
[2025-05-06 22:23:37,930][train][INFO] - Epoch 856/1000, Val Acc=0.7205, Val Loss=1.5996, lr=0.0010
[2025-05-06 22:23:43,820][train][INFO] - Epoch 866/1000, Val Acc=0.6919, Val Loss=1.7425, lr=0.0010
[2025-05-06 22:23:46,347][train][INFO] - Epoch 857/1000, Val Acc=0.7189, Val Loss=1.6001, lr=0.0010
[2025-05-06 22:23:51,470][train][INFO] - Epoch 867/1000, Val Acc=0.6923, Val Loss=1.7470, lr=0.0010
[2025-05-06 22:23:54,578][train][INFO] - Epoch 858/1000, Val Acc=0.7175, Val Loss=1.5902, lr=0.0010
[2025-05-06 22:23:59,497][train][INFO] - Epoch 868/1000, Val Acc=0.6902, Val Loss=1.7667, lr=0.0010
[2025-05-06 22:24:02,704][train][INFO] - Epoch 859/1000, Val Acc=0.7206, Val Loss=1.5890, lr=0.0010
[2025-05-06 22:24:07,129][train][INFO] - Epoch 869/1000, Val Acc=0.6876, Val Loss=1.7713, lr=0.0010
[2025-05-06 22:24:10,652][train][INFO] - Epoch 860/1000, Val Acc=0.7200, Val Loss=1.5969, lr=0.0010
[2025-05-06 22:24:15,086][train][INFO] - Epoch 870/1000, Val Acc=0.6885, Val Loss=1.7611, lr=0.0010
[2025-05-06 22:24:18,559][train][INFO] - Epoch 861/1000, Val Acc=0.7169, Val Loss=1.6029, lr=0.0010
[2025-05-06 22:24:23,421][train][INFO] - Epoch 871/1000, Val Acc=0.6895, Val Loss=1.7529, lr=0.0010
[2025-05-06 22:24:26,778][train][INFO] - Epoch 862/1000, Val Acc=0.7191, Val Loss=1.5913, lr=0.0010
[2025-05-06 22:24:31,308][train][INFO] - Epoch 872/1000, Val Acc=0.6897, Val Loss=1.7646, lr=0.0010
[2025-05-06 22:24:34,494][train][INFO] - Epoch 863/1000, Val Acc=0.7189, Val Loss=1.5972, lr=0.0010
[2025-05-06 22:24:38,391][train][INFO] - Epoch 873/1000, Val Acc=0.6858, Val Loss=1.7585, lr=0.0010
[2025-05-06 22:24:42,664][train][INFO] - Epoch 864/1000, Val Acc=0.7181, Val Loss=1.6033, lr=0.0010
[2025-05-06 22:24:45,828][train][INFO] - Epoch 874/1000, Val Acc=0.6862, Val Loss=1.7779, lr=0.0010
[2025-05-06 22:24:50,776][train][INFO] - Epoch 865/1000, Val Acc=0.7154, Val Loss=1.6079, lr=0.0010
[2025-05-06 22:24:53,677][train][INFO] - Epoch 875/1000, Val Acc=0.6929, Val Loss=1.7501, lr=0.0010
[2025-05-06 22:24:59,072][train][INFO] - Epoch 866/1000, Val Acc=0.7195, Val Loss=1.5976, lr=0.0010
[2025-05-06 22:25:01,882][train][INFO] - Epoch 876/1000, Val Acc=0.6869, Val Loss=1.7786, lr=0.0010
[2025-05-06 22:25:07,044][train][INFO] - Epoch 867/1000, Val Acc=0.7162, Val Loss=1.6143, lr=0.0010
[2025-05-06 22:25:09,365][train][INFO] - Epoch 877/1000, Val Acc=0.6923, Val Loss=1.7593, lr=0.0010
[2025-05-06 22:25:15,452][train][INFO] - Epoch 868/1000, Val Acc=0.7177, Val Loss=1.6060, lr=0.0010
[2025-05-06 22:25:17,434][train][INFO] - Epoch 878/1000, Val Acc=0.6912, Val Loss=1.7727, lr=0.0010
[2025-05-06 22:25:23,266][train][INFO] - Epoch 869/1000, Val Acc=0.7179, Val Loss=1.6091, lr=0.0010
[2025-05-06 22:25:25,632][train][INFO] - Epoch 879/1000, Val Acc=0.6889, Val Loss=1.7600, lr=0.0010
[2025-05-06 22:25:31,533][train][INFO] - Epoch 870/1000, Val Acc=0.7168, Val Loss=1.6108, lr=0.0010
[2025-05-06 22:25:33,655][train][INFO] - Epoch 880/1000, Val Acc=0.6891, Val Loss=1.7615, lr=0.0010
[2025-05-06 22:25:39,841][train][INFO] - Epoch 871/1000, Val Acc=0.7178, Val Loss=1.6071, lr=0.0010
[2025-05-06 22:25:41,681][train][INFO] - Epoch 881/1000, Val Acc=0.6901, Val Loss=1.7684, lr=0.0010
[2025-05-06 22:25:47,909][train][INFO] - Epoch 872/1000, Val Acc=0.7150, Val Loss=1.6172, lr=0.0010
[2025-05-06 22:25:48,927][train][INFO] - Epoch 882/1000, Val Acc=0.6844, Val Loss=1.7854, lr=0.0010
[2025-05-06 22:25:55,801][train][INFO] - Epoch 873/1000, Val Acc=0.7144, Val Loss=1.6203, lr=0.0010
[2025-05-06 22:25:57,380][train][INFO] - Epoch 883/1000, Val Acc=0.6860, Val Loss=1.7492, lr=0.0010
[2025-05-06 22:26:03,586][train][INFO] - Epoch 874/1000, Val Acc=0.7169, Val Loss=1.6101, lr=0.0010
[2025-05-06 22:26:04,623][train][INFO] - Epoch 884/1000, Val Acc=0.6886, Val Loss=1.7491, lr=0.0010
[2025-05-06 22:26:10,627][train][INFO] - Epoch 875/1000, Val Acc=0.7175, Val Loss=1.6156, lr=0.0010
[2025-05-06 22:26:13,129][train][INFO] - Epoch 885/1000, Val Acc=0.6871, Val Loss=1.7699, lr=0.0010
[2025-05-06 22:26:18,706][train][INFO] - Epoch 876/1000, Val Acc=0.7158, Val Loss=1.6161, lr=0.0010
[2025-05-06 22:26:21,404][train][INFO] - Epoch 886/1000, Val Acc=0.6905, Val Loss=1.7724, lr=0.0010
[2025-05-06 22:26:27,192][train][INFO] - Epoch 877/1000, Val Acc=0.7169, Val Loss=1.6240, lr=0.0010
[2025-05-06 22:26:29,608][train][INFO] - Epoch 887/1000, Val Acc=0.6865, Val Loss=1.7713, lr=0.0010
[2025-05-06 22:26:35,135][train][INFO] - Epoch 878/1000, Val Acc=0.7158, Val Loss=1.6219, lr=0.0010
[2025-05-06 22:26:37,360][train][INFO] - Epoch 888/1000, Val Acc=0.6863, Val Loss=1.7955, lr=0.0010
[2025-05-06 22:26:42,802][train][INFO] - Epoch 879/1000, Val Acc=0.7164, Val Loss=1.6260, lr=0.0010
[2025-05-06 22:26:45,687][train][INFO] - Epoch 889/1000, Val Acc=0.6889, Val Loss=1.7652, lr=0.0010
[2025-05-06 22:26:50,297][train][INFO] - Epoch 880/1000, Val Acc=0.7152, Val Loss=1.6278, lr=0.0010
[2025-05-06 22:26:53,796][train][INFO] - Epoch 890/1000, Val Acc=0.6877, Val Loss=1.7812, lr=0.0010
[2025-05-06 22:26:58,326][train][INFO] - Epoch 881/1000, Val Acc=0.7156, Val Loss=1.6223, lr=0.0010
[2025-05-06 22:27:02,039][train][INFO] - Epoch 891/1000, Val Acc=0.6866, Val Loss=1.7785, lr=0.0010
[2025-05-06 22:27:06,238][train][INFO] - Epoch 882/1000, Val Acc=0.7166, Val Loss=1.6247, lr=0.0010
[2025-05-06 22:27:09,784][train][INFO] - Epoch 892/1000, Val Acc=0.6819, Val Loss=1.7972, lr=0.0010
[2025-05-06 22:27:14,795][train][INFO] - Epoch 883/1000, Val Acc=0.7154, Val Loss=1.6260, lr=0.0010
[2025-05-06 22:27:17,959][train][INFO] - Epoch 893/1000, Val Acc=0.6890, Val Loss=1.7742, lr=0.0010
[2025-05-06 22:27:22,948][train][INFO] - Epoch 884/1000, Val Acc=0.7148, Val Loss=1.6459, lr=0.0010
[2025-05-06 22:27:25,410][train][INFO] - Epoch 894/1000, Val Acc=0.6838, Val Loss=1.7919, lr=0.0010
[2025-05-06 22:27:31,419][train][INFO] - Epoch 885/1000, Val Acc=0.7134, Val Loss=1.6437, lr=0.0010
[2025-05-06 22:27:33,264][train][INFO] - Epoch 895/1000, Val Acc=0.6902, Val Loss=1.7658, lr=0.0010
[2025-05-06 22:27:39,337][train][INFO] - Epoch 886/1000, Val Acc=0.7172, Val Loss=1.6293, lr=0.0010
[2025-05-06 22:27:41,675][train][INFO] - Epoch 896/1000, Val Acc=0.6845, Val Loss=1.7809, lr=0.0010
[2025-05-06 22:27:47,371][train][INFO] - Epoch 887/1000, Val Acc=0.7164, Val Loss=1.6271, lr=0.0010
[2025-05-06 22:27:49,707][train][INFO] - Epoch 897/1000, Val Acc=0.6859, Val Loss=1.7835, lr=0.0010
[2025-05-06 22:27:55,248][train][INFO] - Epoch 888/1000, Val Acc=0.7166, Val Loss=1.6199, lr=0.0010
[2025-05-06 22:27:57,451][train][INFO] - Epoch 898/1000, Val Acc=0.6907, Val Loss=1.7791, lr=0.0010
[2025-05-06 22:28:03,804][train][INFO] - Epoch 889/1000, Val Acc=0.7175, Val Loss=1.6187, lr=0.0010
[2025-05-06 22:28:05,113][train][INFO] - Epoch 899/1000, Val Acc=0.6872, Val Loss=1.7910, lr=0.0010
[2025-05-06 22:28:11,987][train][INFO] - Epoch 890/1000, Val Acc=0.7165, Val Loss=1.6352, lr=0.0010
[2025-05-06 22:28:13,352][train][INFO] - Epoch 900/1000, Val Acc=0.6884, Val Loss=1.7531, lr=0.0010
[2025-05-06 22:28:20,056][train][INFO] - Epoch 891/1000, Val Acc=0.7170, Val Loss=1.6180, lr=0.0010
[2025-05-06 22:28:21,533][train][INFO] - Epoch 901/1000, Val Acc=0.6926, Val Loss=1.7313, lr=0.0001
[2025-05-06 22:28:27,941][train][INFO] - Epoch 892/1000, Val Acc=0.7159, Val Loss=1.6310, lr=0.0010
[2025-05-06 22:28:29,127][train][INFO] - Epoch 902/1000, Val Acc=0.6935, Val Loss=1.7392, lr=0.0001
[2025-05-06 22:28:36,105][train][INFO] - Epoch 893/1000, Val Acc=0.7143, Val Loss=1.6345, lr=0.0010
[2025-05-06 22:28:37,475][train][INFO] - Epoch 903/1000, Val Acc=0.6943, Val Loss=1.7293, lr=0.0001
[2025-05-06 22:28:44,022][train][INFO] - Epoch 894/1000, Val Acc=0.7152, Val Loss=1.6342, lr=0.0010
[2025-05-06 22:28:45,468][train][INFO] - Epoch 904/1000, Val Acc=0.6943, Val Loss=1.7273, lr=0.0001
[2025-05-06 22:28:52,215][train][INFO] - Epoch 895/1000, Val Acc=0.7153, Val Loss=1.6383, lr=0.0010
[2025-05-06 22:28:53,908][train][INFO] - Epoch 905/1000, Val Acc=0.6955, Val Loss=1.7257, lr=0.0001
[2025-05-06 22:29:00,085][train][INFO] - Epoch 896/1000, Val Acc=0.7161, Val Loss=1.6334, lr=0.0010
[2025-05-06 22:29:01,810][train][INFO] - Epoch 906/1000, Val Acc=0.6958, Val Loss=1.7255, lr=0.0001
[2025-05-06 22:29:08,350][train][INFO] - Epoch 897/1000, Val Acc=0.7145, Val Loss=1.6370, lr=0.0010
[2025-05-06 22:29:09,981][train][INFO] - Epoch 907/1000, Val Acc=0.6978, Val Loss=1.7264, lr=0.0001
[2025-05-06 22:29:16,334][train][INFO] - Epoch 898/1000, Val Acc=0.7121, Val Loss=1.6574, lr=0.0010
[2025-05-06 22:29:17,977][train][INFO] - Epoch 908/1000, Val Acc=0.6980, Val Loss=1.7204, lr=0.0001
[2025-05-06 22:29:24,194][train][INFO] - Epoch 899/1000, Val Acc=0.7154, Val Loss=1.6381, lr=0.0010
[2025-05-06 22:29:26,081][train][INFO] - Epoch 909/1000, Val Acc=0.6981, Val Loss=1.7239, lr=0.0001
[2025-05-06 22:29:32,568][train][INFO] - Epoch 900/1000, Val Acc=0.7148, Val Loss=1.6425, lr=0.0010
[2025-05-06 22:29:34,592][train][INFO] - Epoch 910/1000, Val Acc=0.6971, Val Loss=1.7238, lr=0.0001
[2025-05-06 22:29:40,492][train][INFO] - Epoch 901/1000, Val Acc=0.7135, Val Loss=1.6356, lr=0.0001
[2025-05-06 22:29:42,029][train][INFO] - Epoch 911/1000, Val Acc=0.6998, Val Loss=1.7223, lr=0.0001
[2025-05-06 22:29:48,365][train][INFO] - Epoch 902/1000, Val Acc=0.7152, Val Loss=1.6349, lr=0.0001
[2025-05-06 22:29:49,997][train][INFO] - Epoch 912/1000, Val Acc=0.6978, Val Loss=1.7287, lr=0.0001
[2025-05-06 22:29:56,762][train][INFO] - Epoch 903/1000, Val Acc=0.7165, Val Loss=1.6302, lr=0.0001
[2025-05-06 22:29:58,156][train][INFO] - Epoch 913/1000, Val Acc=0.6969, Val Loss=1.7305, lr=0.0001
[2025-05-06 22:30:04,577][train][INFO] - Epoch 904/1000, Val Acc=0.7161, Val Loss=1.6351, lr=0.0001
[2025-05-06 22:30:06,471][train][INFO] - Epoch 914/1000, Val Acc=0.6968, Val Loss=1.7246, lr=0.0001
[2025-05-06 22:30:12,535][train][INFO] - Epoch 905/1000, Val Acc=0.7169, Val Loss=1.6275, lr=0.0001
[2025-05-06 22:30:13,558][train][INFO] - Epoch 915/1000, Val Acc=0.6975, Val Loss=1.7279, lr=0.0001
[2025-05-06 22:30:20,298][train][INFO] - Epoch 906/1000, Val Acc=0.7162, Val Loss=1.6328, lr=0.0001
[2025-05-06 22:30:21,599][train][INFO] - Epoch 916/1000, Val Acc=0.6995, Val Loss=1.7280, lr=0.0001
[2025-05-06 22:30:28,280][train][INFO] - Epoch 907/1000, Val Acc=0.7169, Val Loss=1.6268, lr=0.0001
[2025-05-06 22:30:29,331][train][INFO] - Epoch 917/1000, Val Acc=0.6979, Val Loss=1.7299, lr=0.0001
[2025-05-06 22:30:36,557][train][INFO] - Epoch 918/1000, Val Acc=0.6983, Val Loss=1.7319, lr=0.0001
[2025-05-06 22:30:36,581][train][INFO] - Epoch 908/1000, Val Acc=0.7180, Val Loss=1.6274, lr=0.0001
[2025-05-06 22:30:44,445][train][INFO] - Epoch 919/1000, Val Acc=0.6992, Val Loss=1.7325, lr=0.0001
[2025-05-06 22:30:44,501][train][INFO] - Epoch 909/1000, Val Acc=0.7179, Val Loss=1.6282, lr=0.0001
[2025-05-06 22:30:51,658][train][INFO] - Epoch 910/1000, Val Acc=0.7173, Val Loss=1.6280, lr=0.0001
[2025-05-06 22:30:52,934][train][INFO] - Epoch 920/1000, Val Acc=0.6985, Val Loss=1.7352, lr=0.0001
[2025-05-06 22:30:59,895][train][INFO] - Epoch 911/1000, Val Acc=0.7161, Val Loss=1.6299, lr=0.0001
[2025-05-06 22:31:01,019][train][INFO] - Epoch 921/1000, Val Acc=0.6983, Val Loss=1.7355, lr=0.0001
[2025-05-06 22:31:08,274][train][INFO] - Epoch 912/1000, Val Acc=0.7175, Val Loss=1.6229, lr=0.0001
[2025-05-06 22:31:09,210][train][INFO] - Epoch 922/1000, Val Acc=0.6994, Val Loss=1.7313, lr=0.0001
[2025-05-06 22:31:16,590][train][INFO] - Epoch 913/1000, Val Acc=0.7178, Val Loss=1.6278, lr=0.0001
[2025-05-06 22:31:17,044][train][INFO] - Epoch 923/1000, Val Acc=0.6981, Val Loss=1.7401, lr=0.0001
[2025-05-06 22:31:24,851][train][INFO] - Epoch 914/1000, Val Acc=0.7187, Val Loss=1.6154, lr=0.0001
[2025-05-06 22:31:24,883][train][INFO] - Epoch 924/1000, Val Acc=0.7005, Val Loss=1.7328, lr=0.0001
[2025-05-06 22:31:31,855][train][INFO] - Epoch 925/1000, Val Acc=0.7008, Val Loss=1.7293, lr=0.0001
[2025-05-06 22:31:33,276][train][INFO] - Epoch 915/1000, Val Acc=0.7180, Val Loss=1.6269, lr=0.0001
[2025-05-06 22:31:39,674][train][INFO] - Epoch 926/1000, Val Acc=0.7001, Val Loss=1.7296, lr=0.0001
[2025-05-06 22:31:41,104][train][INFO] - Epoch 916/1000, Val Acc=0.7182, Val Loss=1.6209, lr=0.0001
[2025-05-06 22:31:47,942][train][INFO] - Epoch 927/1000, Val Acc=0.7007, Val Loss=1.7196, lr=0.0001
[2025-05-06 22:31:49,489][train][INFO] - Epoch 917/1000, Val Acc=0.7174, Val Loss=1.6223, lr=0.0001
[2025-05-06 22:31:55,602][train][INFO] - Epoch 928/1000, Val Acc=0.7004, Val Loss=1.7359, lr=0.0001
[2025-05-06 22:31:57,426][train][INFO] - Epoch 918/1000, Val Acc=0.7192, Val Loss=1.6191, lr=0.0001
[2025-05-06 22:32:03,527][train][INFO] - Epoch 929/1000, Val Acc=0.6999, Val Loss=1.7316, lr=0.0001
[2025-05-06 22:32:05,612][train][INFO] - Epoch 919/1000, Val Acc=0.7176, Val Loss=1.6231, lr=0.0001
[2025-05-06 22:32:11,196][train][INFO] - Epoch 930/1000, Val Acc=0.7003, Val Loss=1.7325, lr=0.0001
[2025-05-06 22:32:12,787][train][INFO] - Epoch 920/1000, Val Acc=0.7185, Val Loss=1.6165, lr=0.0001
[2025-05-06 22:32:19,314][train][INFO] - Epoch 931/1000, Val Acc=0.7002, Val Loss=1.7268, lr=0.0001
[2025-05-06 22:32:21,353][train][INFO] - Epoch 921/1000, Val Acc=0.7183, Val Loss=1.6152, lr=0.0001
[2025-05-06 22:32:27,052][train][INFO] - Epoch 932/1000, Val Acc=0.7013, Val Loss=1.7310, lr=0.0001
[2025-05-06 22:32:29,295][train][INFO] - Epoch 922/1000, Val Acc=0.7183, Val Loss=1.6197, lr=0.0001
[2025-05-06 22:32:34,615][train][INFO] - Epoch 933/1000, Val Acc=0.7003, Val Loss=1.7322, lr=0.0001
[2025-05-06 22:32:36,660][train][INFO] - Epoch 923/1000, Val Acc=0.7188, Val Loss=1.6235, lr=0.0001
[2025-05-06 22:32:42,731][train][INFO] - Epoch 934/1000, Val Acc=0.7019, Val Loss=1.7301, lr=0.0001
[2025-05-06 22:32:44,587][train][INFO] - Epoch 924/1000, Val Acc=0.7183, Val Loss=1.6238, lr=0.0001
[2025-05-06 22:32:50,052][train][INFO] - Epoch 935/1000, Val Acc=0.7006, Val Loss=1.7345, lr=0.0001
[2025-05-06 22:32:52,728][train][INFO] - Epoch 925/1000, Val Acc=0.7178, Val Loss=1.6206, lr=0.0001
[2025-05-06 22:32:58,239][train][INFO] - Epoch 936/1000, Val Acc=0.6991, Val Loss=1.7339, lr=0.0001
[2025-05-06 22:33:00,899][train][INFO] - Epoch 926/1000, Val Acc=0.7173, Val Loss=1.6206, lr=0.0001
[2025-05-06 22:33:06,296][train][INFO] - Epoch 937/1000, Val Acc=0.6991, Val Loss=1.7365, lr=0.0001
[2025-05-06 22:33:08,587][train][INFO] - Epoch 927/1000, Val Acc=0.7187, Val Loss=1.6177, lr=0.0001
[2025-05-06 22:33:14,478][train][INFO] - Epoch 938/1000, Val Acc=0.6997, Val Loss=1.7440, lr=0.0001
[2025-05-06 22:33:16,227][train][INFO] - Epoch 928/1000, Val Acc=0.7180, Val Loss=1.6143, lr=0.0001
[2025-05-06 22:33:21,922][train][INFO] - Epoch 939/1000, Val Acc=0.7009, Val Loss=1.7319, lr=0.0001
[2025-05-06 22:33:24,196][train][INFO] - Epoch 929/1000, Val Acc=0.7163, Val Loss=1.6242, lr=0.0001
[2025-05-06 22:33:29,719][train][INFO] - Epoch 940/1000, Val Acc=0.7007, Val Loss=1.7225, lr=0.0001
[2025-05-06 22:33:32,251][train][INFO] - Epoch 930/1000, Val Acc=0.7169, Val Loss=1.6188, lr=0.0001
[2025-05-06 22:33:37,678][train][INFO] - Epoch 941/1000, Val Acc=0.6997, Val Loss=1.7319, lr=0.0001
[2025-05-06 22:33:40,335][train][INFO] - Epoch 931/1000, Val Acc=0.7191, Val Loss=1.6230, lr=0.0001
[2025-05-06 22:33:45,548][train][INFO] - Epoch 942/1000, Val Acc=0.7008, Val Loss=1.7324, lr=0.0001
[2025-05-06 22:33:48,929][train][INFO] - Epoch 932/1000, Val Acc=0.7163, Val Loss=1.6225, lr=0.0001
[2025-05-06 22:33:53,314][train][INFO] - Epoch 943/1000, Val Acc=0.7019, Val Loss=1.7367, lr=0.0001
[2025-05-06 22:33:57,084][train][INFO] - Epoch 933/1000, Val Acc=0.7181, Val Loss=1.6249, lr=0.0001
[2025-05-06 22:34:00,341][train][INFO] - Epoch 944/1000, Val Acc=0.7005, Val Loss=1.7396, lr=0.0001
[2025-05-06 22:34:05,364][train][INFO] - Epoch 934/1000, Val Acc=0.7154, Val Loss=1.6221, lr=0.0001
[2025-05-06 22:34:08,374][train][INFO] - Epoch 945/1000, Val Acc=0.7010, Val Loss=1.7408, lr=0.0001
[2025-05-06 22:34:13,103][train][INFO] - Epoch 935/1000, Val Acc=0.7164, Val Loss=1.6261, lr=0.0001
[2025-05-06 22:34:15,984][train][INFO] - Epoch 946/1000, Val Acc=0.7005, Val Loss=1.7421, lr=0.0001
[2025-05-06 22:34:21,620][train][INFO] - Epoch 936/1000, Val Acc=0.7181, Val Loss=1.6166, lr=0.0001
[2025-05-06 22:34:23,514][train][INFO] - Epoch 947/1000, Val Acc=0.6997, Val Loss=1.7355, lr=0.0001
[2025-05-06 22:34:29,917][train][INFO] - Epoch 937/1000, Val Acc=0.7184, Val Loss=1.6222, lr=0.0001
[2025-05-06 22:34:31,794][train][INFO] - Epoch 948/1000, Val Acc=0.6993, Val Loss=1.7364, lr=0.0001
[2025-05-06 22:34:37,981][train][INFO] - Epoch 938/1000, Val Acc=0.7168, Val Loss=1.6233, lr=0.0001
[2025-05-06 22:34:40,089][train][INFO] - Epoch 949/1000, Val Acc=0.7021, Val Loss=1.7370, lr=0.0001
[2025-05-06 22:34:45,839][train][INFO] - Epoch 939/1000, Val Acc=0.7182, Val Loss=1.6223, lr=0.0001
[2025-05-06 22:34:48,587][train][INFO] - Epoch 950/1000, Val Acc=0.7005, Val Loss=1.7408, lr=0.0001
[2025-05-06 22:34:53,655][train][INFO] - Epoch 940/1000, Val Acc=0.7171, Val Loss=1.6185, lr=0.0001
[2025-05-06 22:34:56,607][train][INFO] - Epoch 951/1000, Val Acc=0.7016, Val Loss=1.7423, lr=0.0001
[2025-05-06 22:35:01,686][train][INFO] - Epoch 941/1000, Val Acc=0.7179, Val Loss=1.6195, lr=0.0001
[2025-05-06 22:35:04,764][train][INFO] - Epoch 952/1000, Val Acc=0.7014, Val Loss=1.7371, lr=0.0001
[2025-05-06 22:35:10,046][train][INFO] - Epoch 942/1000, Val Acc=0.7174, Val Loss=1.6195, lr=0.0001
[2025-05-06 22:35:12,817][train][INFO] - Epoch 953/1000, Val Acc=0.7011, Val Loss=1.7343, lr=0.0001
[2025-05-06 22:35:18,463][train][INFO] - Epoch 943/1000, Val Acc=0.7166, Val Loss=1.6218, lr=0.0001
[2025-05-06 22:35:20,643][train][INFO] - Epoch 954/1000, Val Acc=0.7017, Val Loss=1.7353, lr=0.0001
[2025-05-06 22:35:26,574][train][INFO] - Epoch 944/1000, Val Acc=0.7155, Val Loss=1.6230, lr=0.0001
[2025-05-06 22:35:28,660][train][INFO] - Epoch 955/1000, Val Acc=0.6995, Val Loss=1.7430, lr=0.0001
[2025-05-06 22:35:34,002][train][INFO] - Epoch 945/1000, Val Acc=0.7177, Val Loss=1.6203, lr=0.0001
[2025-05-06 22:35:36,293][train][INFO] - Epoch 956/1000, Val Acc=0.6998, Val Loss=1.7427, lr=0.0001
[2025-05-06 22:35:42,507][train][INFO] - Epoch 946/1000, Val Acc=0.7196, Val Loss=1.6224, lr=0.0001
[2025-05-06 22:35:43,813][train][INFO] - Epoch 957/1000, Val Acc=0.7010, Val Loss=1.7380, lr=0.0001
[2025-05-06 22:35:50,737][train][INFO] - Epoch 958/1000, Val Acc=0.7005, Val Loss=1.7438, lr=0.0001
[2025-05-06 22:35:50,865][train][INFO] - Epoch 947/1000, Val Acc=0.7183, Val Loss=1.6226, lr=0.0001
[2025-05-06 22:35:59,241][train][INFO] - Epoch 959/1000, Val Acc=0.7001, Val Loss=1.7561, lr=0.0001
[2025-05-06 22:35:59,333][train][INFO] - Epoch 948/1000, Val Acc=0.7186, Val Loss=1.6222, lr=0.0001
[2025-05-06 22:36:07,528][train][INFO] - Epoch 949/1000, Val Acc=0.7176, Val Loss=1.6180, lr=0.0001
[2025-05-06 22:36:07,546][train][INFO] - Epoch 960/1000, Val Acc=0.7005, Val Loss=1.7392, lr=0.0001
[2025-05-06 22:36:15,530][train][INFO] - Epoch 950/1000, Val Acc=0.7180, Val Loss=1.6205, lr=0.0001
[2025-05-06 22:36:16,069][train][INFO] - Epoch 961/1000, Val Acc=0.7008, Val Loss=1.7421, lr=0.0001
[2025-05-06 22:36:23,843][train][INFO] - Epoch 951/1000, Val Acc=0.7183, Val Loss=1.6210, lr=0.0001
[2025-05-06 22:36:24,562][train][INFO] - Epoch 962/1000, Val Acc=0.7009, Val Loss=1.7406, lr=0.0001
[2025-05-06 22:36:31,648][train][INFO] - Epoch 952/1000, Val Acc=0.7177, Val Loss=1.6218, lr=0.0001
[2025-05-06 22:36:32,616][train][INFO] - Epoch 963/1000, Val Acc=0.6995, Val Loss=1.7475, lr=0.0001
[2025-05-06 22:36:39,839][train][INFO] - Epoch 953/1000, Val Acc=0.7186, Val Loss=1.6179, lr=0.0001
[2025-05-06 22:36:40,761][train][INFO] - Epoch 964/1000, Val Acc=0.6993, Val Loss=1.7505, lr=0.0001
[2025-05-06 22:36:48,311][train][INFO] - Epoch 954/1000, Val Acc=0.7180, Val Loss=1.6167, lr=0.0001
[2025-05-06 22:36:49,420][train][INFO] - Epoch 965/1000, Val Acc=0.7006, Val Loss=1.7429, lr=0.0001
[2025-05-06 22:36:56,606][train][INFO] - Epoch 955/1000, Val Acc=0.7166, Val Loss=1.6206, lr=0.0001
[2025-05-06 22:36:57,466][train][INFO] - Epoch 966/1000, Val Acc=0.7011, Val Loss=1.7391, lr=0.0001
[2025-05-06 22:37:04,491][train][INFO] - Epoch 956/1000, Val Acc=0.7179, Val Loss=1.6170, lr=0.0001
[2025-05-06 22:37:04,631][train][INFO] - Epoch 967/1000, Val Acc=0.7022, Val Loss=1.7419, lr=0.0001
[2025-05-06 22:37:12,255][train][INFO] - Epoch 968/1000, Val Acc=0.7006, Val Loss=1.7447, lr=0.0001
[2025-05-06 22:37:12,965][train][INFO] - Epoch 957/1000, Val Acc=0.7177, Val Loss=1.6177, lr=0.0001
[2025-05-06 22:37:20,242][train][INFO] - Epoch 969/1000, Val Acc=0.7011, Val Loss=1.7449, lr=0.0001
[2025-05-06 22:37:20,963][train][INFO] - Epoch 958/1000, Val Acc=0.7170, Val Loss=1.6214, lr=0.0001
[2025-05-06 22:37:28,214][train][INFO] - Epoch 970/1000, Val Acc=0.7004, Val Loss=1.7417, lr=0.0001
[2025-05-06 22:37:29,556][train][INFO] - Epoch 959/1000, Val Acc=0.7186, Val Loss=1.6231, lr=0.0001
[2025-05-06 22:37:35,541][train][INFO] - Epoch 971/1000, Val Acc=0.7007, Val Loss=1.7406, lr=0.0001
[2025-05-06 22:37:37,631][train][INFO] - Epoch 960/1000, Val Acc=0.7184, Val Loss=1.6166, lr=0.0001
[2025-05-06 22:37:43,034][train][INFO] - Epoch 972/1000, Val Acc=0.7026, Val Loss=1.7425, lr=0.0001
[2025-05-06 22:37:46,025][train][INFO] - Epoch 961/1000, Val Acc=0.7172, Val Loss=1.6134, lr=0.0001
[2025-05-06 22:37:51,249][train][INFO] - Epoch 973/1000, Val Acc=0.6995, Val Loss=1.7418, lr=0.0001
[2025-05-06 22:37:53,637][train][INFO] - Epoch 962/1000, Val Acc=0.7191, Val Loss=1.6167, lr=0.0001
[2025-05-06 22:37:59,271][train][INFO] - Epoch 974/1000, Val Acc=0.7018, Val Loss=1.7465, lr=0.0001
[2025-05-06 22:38:01,939][train][INFO] - Epoch 963/1000, Val Acc=0.7176, Val Loss=1.6225, lr=0.0001
[2025-05-06 22:38:06,951][train][INFO] - Epoch 975/1000, Val Acc=0.7006, Val Loss=1.7385, lr=0.0001
[2025-05-06 22:38:10,566][train][INFO] - Epoch 964/1000, Val Acc=0.7174, Val Loss=1.6220, lr=0.0001
[2025-05-06 22:38:14,461][train][INFO] - Epoch 976/1000, Val Acc=0.7001, Val Loss=1.7352, lr=0.0001
[2025-05-06 22:38:18,714][train][INFO] - Epoch 965/1000, Val Acc=0.7172, Val Loss=1.6224, lr=0.0001
[2025-05-06 22:38:22,140][train][INFO] - Epoch 977/1000, Val Acc=0.7018, Val Loss=1.7428, lr=0.0001
[2025-05-06 22:38:26,761][train][INFO] - Epoch 966/1000, Val Acc=0.7177, Val Loss=1.6160, lr=0.0001
[2025-05-06 22:38:29,977][train][INFO] - Epoch 978/1000, Val Acc=0.7002, Val Loss=1.7440, lr=0.0001
[2025-05-06 22:38:35,004][train][INFO] - Epoch 967/1000, Val Acc=0.7180, Val Loss=1.6166, lr=0.0001
[2025-05-06 22:38:37,491][train][INFO] - Epoch 979/1000, Val Acc=0.7015, Val Loss=1.7414, lr=0.0001
[2025-05-06 22:38:43,034][train][INFO] - Epoch 968/1000, Val Acc=0.7185, Val Loss=1.6193, lr=0.0001
[2025-05-06 22:38:45,633][train][INFO] - Epoch 980/1000, Val Acc=0.7019, Val Loss=1.7396, lr=0.0001
[2025-05-06 22:38:51,573][train][INFO] - Epoch 969/1000, Val Acc=0.7184, Val Loss=1.6172, lr=0.0001
[2025-05-06 22:38:53,653][train][INFO] - Epoch 981/1000, Val Acc=0.7017, Val Loss=1.7444, lr=0.0001
[2025-05-06 22:39:00,083][train][INFO] - Epoch 970/1000, Val Acc=0.7179, Val Loss=1.6207, lr=0.0001
[2025-05-06 22:39:01,374][train][INFO] - Epoch 982/1000, Val Acc=0.7002, Val Loss=1.7432, lr=0.0001
[2025-05-06 22:39:08,516][train][INFO] - Epoch 971/1000, Val Acc=0.7171, Val Loss=1.6135, lr=0.0001
[2025-05-06 22:39:08,569][train][INFO] - Epoch 983/1000, Val Acc=0.7018, Val Loss=1.7492, lr=0.0001
[2025-05-06 22:39:16,354][train][INFO] - Epoch 984/1000, Val Acc=0.7033, Val Loss=1.7428, lr=0.0001
[2025-05-06 22:39:16,516][train][INFO] - Epoch 972/1000, Val Acc=0.7170, Val Loss=1.6186, lr=0.0001
[2025-05-06 22:39:24,111][train][INFO] - Epoch 985/1000, Val Acc=0.7006, Val Loss=1.7352, lr=0.0001
[2025-05-06 22:39:25,069][train][INFO] - Epoch 973/1000, Val Acc=0.7177, Val Loss=1.6205, lr=0.0001
[2025-05-06 22:39:31,354][train][INFO] - Epoch 986/1000, Val Acc=0.7008, Val Loss=1.7444, lr=0.0001
[2025-05-06 22:39:33,276][train][INFO] - Epoch 974/1000, Val Acc=0.7174, Val Loss=1.6191, lr=0.0001
[2025-05-06 22:39:39,494][train][INFO] - Epoch 987/1000, Val Acc=0.7000, Val Loss=1.7488, lr=0.0001
[2025-05-06 22:39:41,402][train][INFO] - Epoch 975/1000, Val Acc=0.7171, Val Loss=1.6200, lr=0.0001
[2025-05-06 22:39:47,627][train][INFO] - Epoch 988/1000, Val Acc=0.7015, Val Loss=1.7493, lr=0.0001
[2025-05-06 22:39:49,549][train][INFO] - Epoch 976/1000, Val Acc=0.7169, Val Loss=1.6213, lr=0.0001
[2025-05-06 22:39:55,280][train][INFO] - Epoch 989/1000, Val Acc=0.7017, Val Loss=1.7476, lr=0.0001
[2025-05-06 22:39:57,427][train][INFO] - Epoch 977/1000, Val Acc=0.7169, Val Loss=1.6243, lr=0.0001
[2025-05-06 22:40:03,475][train][INFO] - Epoch 990/1000, Val Acc=0.7008, Val Loss=1.7429, lr=0.0001
[2025-05-06 22:40:05,827][train][INFO] - Epoch 978/1000, Val Acc=0.7174, Val Loss=1.6216, lr=0.0001
[2025-05-06 22:40:11,985][train][INFO] - Epoch 991/1000, Val Acc=0.7021, Val Loss=1.7488, lr=0.0001
[2025-05-06 22:40:14,276][train][INFO] - Epoch 979/1000, Val Acc=0.7182, Val Loss=1.6253, lr=0.0001
[2025-05-06 22:40:19,938][train][INFO] - Epoch 992/1000, Val Acc=0.7015, Val Loss=1.7494, lr=0.0001
[2025-05-06 22:40:21,883][train][INFO] - Epoch 980/1000, Val Acc=0.7195, Val Loss=1.6193, lr=0.0001
[2025-05-06 22:40:27,774][train][INFO] - Epoch 993/1000, Val Acc=0.7005, Val Loss=1.7385, lr=0.0001
[2025-05-06 22:40:29,812][train][INFO] - Epoch 981/1000, Val Acc=0.7182, Val Loss=1.6186, lr=0.0001
[2025-05-06 22:40:36,016][train][INFO] - Epoch 994/1000, Val Acc=0.6997, Val Loss=1.7516, lr=0.0001
[2025-05-06 22:40:37,677][train][INFO] - Epoch 982/1000, Val Acc=0.7171, Val Loss=1.6215, lr=0.0001
[2025-05-06 22:40:44,139][train][INFO] - Epoch 995/1000, Val Acc=0.7010, Val Loss=1.7443, lr=0.0001
[2025-05-06 22:40:45,237][train][INFO] - Epoch 983/1000, Val Acc=0.7191, Val Loss=1.6240, lr=0.0001
[2025-05-06 22:40:52,105][train][INFO] - Epoch 996/1000, Val Acc=0.6994, Val Loss=1.7513, lr=0.0001
[2025-05-06 22:40:52,854][train][INFO] - Epoch 984/1000, Val Acc=0.7169, Val Loss=1.6225, lr=0.0001
[2025-05-06 22:41:00,265][train][INFO] - Epoch 997/1000, Val Acc=0.7016, Val Loss=1.7448, lr=0.0001
[2025-05-06 22:41:01,495][train][INFO] - Epoch 985/1000, Val Acc=0.7180, Val Loss=1.6204, lr=0.0001
[2025-05-06 22:41:08,388][train][INFO] - Epoch 998/1000, Val Acc=0.7000, Val Loss=1.7488, lr=0.0001
[2025-05-06 22:41:09,545][train][INFO] - Epoch 986/1000, Val Acc=0.7171, Val Loss=1.6189, lr=0.0001
[2025-05-06 22:41:16,694][train][INFO] - Epoch 999/1000, Val Acc=0.6997, Val Loss=1.7426, lr=0.0001
[2025-05-06 22:41:18,160][train][INFO] - Epoch 987/1000, Val Acc=0.7176, Val Loss=1.6188, lr=0.0001
[2025-05-06 22:41:24,831][train][INFO] - Epoch 1000/1000, Val Acc=0.7009, Val Loss=1.7496, lr=0.0001
[2025-05-06 22:41:26,408][train][INFO] - Epoch 988/1000, Val Acc=0.7179, Val Loss=1.6214, lr=0.0001
[2025-05-06 22:41:29,966][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7039
[2025-05-06 22:41:29,975][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 22:41:33,838][train][INFO] - Epoch 989/1000, Val Acc=0.7189, Val Loss=1.6190, lr=0.0001
[2025-05-06 22:41:41,887][train][INFO] - Epoch 990/1000, Val Acc=0.7184, Val Loss=1.6177, lr=0.0001
[2025-05-06 22:41:49,836][train][INFO] - Epoch 991/1000, Val Acc=0.7185, Val Loss=1.6244, lr=0.0001
[2025-05-06 22:41:58,100][train][INFO] - Epoch 992/1000, Val Acc=0.7178, Val Loss=1.6198, lr=0.0001
[2025-05-06 22:42:06,007][train][INFO] - Epoch 993/1000, Val Acc=0.7179, Val Loss=1.6169, lr=0.0001
[2025-05-06 22:42:14,332][train][INFO] - Epoch 994/1000, Val Acc=0.7176, Val Loss=1.6243, lr=0.0001
[2025-05-06 22:42:22,483][train][INFO] - Epoch 995/1000, Val Acc=0.7164, Val Loss=1.6197, lr=0.0001
[2025-05-06 22:42:30,002][train][INFO] - Epoch 996/1000, Val Acc=0.7188, Val Loss=1.6229, lr=0.0001
[2025-05-06 22:42:38,513][train][INFO] - Epoch 997/1000, Val Acc=0.7163, Val Loss=1.6244, lr=0.0001
[2025-05-06 22:42:46,165][train][INFO] - Epoch 998/1000, Val Acc=0.7183, Val Loss=1.6209, lr=0.0001
[2025-05-06 22:42:53,939][train][INFO] - Epoch 999/1000, Val Acc=0.7184, Val Loss=1.6164, lr=0.0001
[2025-05-06 22:43:01,906][train][INFO] - Epoch 1000/1000, Val Acc=0.7170, Val Loss=1.6178, lr=0.0001
[2025-05-06 22:43:07,156][train][INFO] - After training : Train Acc=0.9998  Val Acc=0.7225
[2025-05-06 22:43:07,168][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-06 22:43:09,827][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 22:44:53,647][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-06 22:45:32,795][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 22:45:33,258][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-06 22:47:22,371][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-06 22:47:22,819][Visualize acc speed up curve][INFO] - End visualizing
Traceback (most recent call last):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 105, in run
    cfg = self.compose_config(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 594, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 142, in load_configuration
    return self._load_configuration_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 253, in _load_configuration_impl
    defaults_list = create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 745, in create_defaults_list
    defaults, tree = _create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 715, in _create_defaults_list
    defaults_tree = _create_defaults_tree(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 356, in _create_defaults_tree
    ret = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 457, in _create_defaults_tree_impl
    return _expand_virtual_root(repo, root, overrides, skip_missing)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 280, in _expand_virtual_root
    subtree = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 573, in _create_defaults_tree_impl
    add_child(children, new_root)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 520, in add_child
    subtree_ = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 466, in _create_defaults_tree_impl
    update_package_header(repo=repo, node=parent)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 262, in update_package_header
    loaded = repo.load_config(config_path=node.get_config_path())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 348, in load_config
    ret = self.delegate.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 91, in load_config
    ret = source.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/core_plugins/file_config_source.py", line 31, in load_config
    cfg = OmegaConf.load(f)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/omegaconf.py", line 192, in load
    obj = yaml.load(file_, Loader=get_yaml_loader())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 51, in get_single_data
    return self.construct_document(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 60, in construct_document
    for dummy in generator:
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 413, in construct_yaml_map
    value = self.construct_mapping(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/_utils.py", line 144, in construct_mapping
    raise yaml.constructor.ConstructorError(
yaml.constructor.ConstructorError: while constructing a mapping
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 101, column 5
found duplicate key after_pruning
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 125, column 5
Traceback (most recent call last):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 105, in run
    cfg = self.compose_config(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 594, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 142, in load_configuration
    return self._load_configuration_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 253, in _load_configuration_impl
    defaults_list = create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 745, in create_defaults_list
    defaults, tree = _create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 715, in _create_defaults_list
    defaults_tree = _create_defaults_tree(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 356, in _create_defaults_tree
    ret = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 457, in _create_defaults_tree_impl
    return _expand_virtual_root(repo, root, overrides, skip_missing)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 280, in _expand_virtual_root
    subtree = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 573, in _create_defaults_tree_impl
    add_child(children, new_root)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 520, in add_child
    subtree_ = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 466, in _create_defaults_tree_impl
    update_package_header(repo=repo, node=parent)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 262, in update_package_header
    loaded = repo.load_config(config_path=node.get_config_path())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 348, in load_config
    ret = self.delegate.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 91, in load_config
    ret = source.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/core_plugins/file_config_source.py", line 31, in load_config
    cfg = OmegaConf.load(f)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/omegaconf.py", line 192, in load
    obj = yaml.load(file_, Loader=get_yaml_loader())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 51, in get_single_data
    return self.construct_document(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 60, in construct_document
    for dummy in generator:
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 413, in construct_yaml_map
    value = self.construct_mapping(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/_utils.py", line 144, in construct_mapping
    raise yaml.constructor.ConstructorError(
yaml.constructor.ConstructorError: while constructing a mapping
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 101, column 5
found duplicate key after_pruning
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 125, column 5
Traceback (most recent call last):
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 105, in run
    cfg = self.compose_config(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 594, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 142, in load_configuration
    return self._load_configuration_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_loader_impl.py", line 253, in _load_configuration_impl
    defaults_list = create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 745, in create_defaults_list
    defaults, tree = _create_defaults_list(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 715, in _create_defaults_list
    defaults_tree = _create_defaults_tree(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 356, in _create_defaults_tree
    ret = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 457, in _create_defaults_tree_impl
    return _expand_virtual_root(repo, root, overrides, skip_missing)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 280, in _expand_virtual_root
    subtree = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 573, in _create_defaults_tree_impl
    add_child(children, new_root)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 520, in add_child
    subtree_ = _create_defaults_tree_impl(
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 466, in _create_defaults_tree_impl
    update_package_header(repo=repo, node=parent)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/defaults_list.py", line 262, in update_package_header
    loaded = repo.load_config(config_path=node.get_config_path())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 348, in load_config
    ret = self.delegate.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/config_repository.py", line 91, in load_config
    ret = source.load_config(config_path=config_path)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/hydra/_internal/core_plugins/file_config_source.py", line 31, in load_config
    cfg = OmegaConf.load(f)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/omegaconf.py", line 192, in load
    obj = yaml.load(file_, Loader=get_yaml_loader())
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 51, in get_single_data
    return self.construct_document(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 60, in construct_document
    for dummy in generator:
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/yaml/constructor.py", line 413, in construct_yaml_map
    value = self.construct_mapping(node)
  File "/home/liuyewei/miniconda3/envs/meta-pruning/lib/python3.9/site-packages/omegaconf/_utils.py", line 144, in construct_mapping
    raise yaml.constructor.ConstructorError(
yaml.constructor.ConstructorError: while constructing a mapping
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 101, column 5
found duplicate key after_pruning
  in "/home/liuyewei/metanetwork/meta-pruning/main/configs/task/VGG19_on_CIFAR100.yaml", line 125, column 5
[2025-05-06 23:53:31,413][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 27

[2025-05-06 23:53:31,498][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:53:31,498][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:53:31,498][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 23:53:32,916][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-06 23:53:32,967][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:53:32,967][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:53:32,967][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 23:53:35,261][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Iris
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 23

[2025-05-06 23:53:35,334][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:53:35,334][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:53:35,334][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 23:53:51,370][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 23:53:52,816][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 23:53:55,067][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 23:53:59,601][train][INFO] - Epoch 1/100, Val Acc=0.1728, Val Loss=3.1893, lr=0.0100
[2025-05-06 23:54:00,411][train][INFO] - Epoch 1/100, Val Acc=0.1088, Val Loss=3.6238, lr=0.0100
[2025-05-06 23:54:03,173][train][INFO] - Epoch 1/100, Val Acc=0.1735, Val Loss=3.1780, lr=0.0100
[2025-05-06 23:54:07,354][train][INFO] - Epoch 2/100, Val Acc=0.3918, Val Loss=2.3392, lr=0.0100
[2025-05-06 23:54:08,443][train][INFO] - Epoch 2/100, Val Acc=0.3762, Val Loss=2.2426, lr=0.0100
[2025-05-06 23:54:22,410][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 23

[2025-05-06 23:54:22,460][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:54:22,460][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:54:22,460][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 23:54:26,599][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 25

[2025-05-06 23:54:26,650][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:54:26,650][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:54:26,650][get_dataset_model_loader][INFO] - ==================================================
[2025-05-06 23:54:29,213][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 27

[2025-05-06 23:54:29,264][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-06 23:54:29,264][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-06 23:54:29,264][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 23:54:42,018][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-06 23:54:46,629][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 23:54:49,208][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-06 23:54:50,524][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6078, lr=0.0100
[2025-05-06 23:54:54,496][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6078, lr=0.0100
[2025-05-06 23:54:57,104][train][INFO] - Epoch 1/100, Val Acc=0.0100, Val Loss=4.6078, lr=0.0100
[2025-05-06 23:54:58,435][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6076, lr=0.0100
[2025-05-06 23:55:01,412][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6076, lr=0.0100
[2025-05-06 23:55:04,399][train][INFO] - Epoch 2/100, Val Acc=0.0100, Val Loss=4.6076, lr=0.0100
[2025-05-06 23:55:05,874][train][INFO] - Epoch 3/100, Val Acc=0.0300, Val Loss=4.4138, lr=0.0100
[2025-05-06 23:55:08,687][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:11,963][train][INFO] - Epoch 3/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:13,522][train][INFO] - Epoch 4/100, Val Acc=0.0189, Val Loss=5.8169, lr=0.0100
[2025-05-06 23:55:16,443][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:19,515][train][INFO] - Epoch 4/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:21,522][train][INFO] - Epoch 5/100, Val Acc=0.0460, Val Loss=4.4704, lr=0.0100
[2025-05-06 23:55:23,509][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-06 23:55:26,603][train][INFO] - Epoch 5/100, Val Acc=0.0100, Val Loss=4.6070, lr=0.0100
[2025-05-06 23:55:29,056][train][INFO] - Epoch 6/100, Val Acc=0.0453, Val Loss=6.1438, lr=0.0100
[2025-05-06 23:55:31,185][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:34,196][train][INFO] - Epoch 6/100, Val Acc=0.0100, Val Loss=4.6073, lr=0.0100
[2025-05-06 23:55:36,489][train][INFO] - Epoch 7/100, Val Acc=0.0906, Val Loss=3.8345, lr=0.0100
[2025-05-06 23:55:38,869][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-06 23:55:41,784][train][INFO] - Epoch 7/100, Val Acc=0.0100, Val Loss=4.6066, lr=0.0100
[2025-05-06 23:55:44,282][train][INFO] - Epoch 8/100, Val Acc=0.0687, Val Loss=4.0724, lr=0.0100
[2025-05-06 23:55:46,473][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-06 23:55:49,215][train][INFO] - Epoch 8/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-06 23:55:51,907][train][INFO] - Epoch 9/100, Val Acc=0.1212, Val Loss=3.6766, lr=0.0100
[2025-05-06 23:55:54,474][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-06 23:55:56,489][train][INFO] - Epoch 9/100, Val Acc=0.0100, Val Loss=4.6065, lr=0.0100
[2025-05-06 23:55:59,727][train][INFO] - Epoch 10/100, Val Acc=0.1425, Val Loss=3.3777, lr=0.0100
[2025-05-06 23:56:02,295][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-06 23:56:03,973][train][INFO] - Epoch 10/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-06 23:56:07,336][train][INFO] - Epoch 11/100, Val Acc=0.1214, Val Loss=3.5744, lr=0.0100
[2025-05-06 23:56:10,248][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-06 23:56:11,579][train][INFO] - Epoch 11/100, Val Acc=0.0100, Val Loss=4.6061, lr=0.0100
[2025-05-06 23:56:14,787][train][INFO] - Epoch 12/100, Val Acc=0.1494, Val Loss=3.3390, lr=0.0100
[2025-05-06 23:56:17,893][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-06 23:56:19,368][train][INFO] - Epoch 12/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-06 23:56:22,525][train][INFO] - Epoch 13/100, Val Acc=0.1761, Val Loss=3.2013, lr=0.0100
[2025-05-06 23:56:25,776][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-06 23:56:27,218][train][INFO] - Epoch 13/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-06 23:56:30,201][train][INFO] - Epoch 14/100, Val Acc=0.1942, Val Loss=3.1089, lr=0.0100
[2025-05-06 23:56:33,346][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6059, lr=0.0100
[2025-05-06 23:56:35,083][train][INFO] - Epoch 14/100, Val Acc=0.0100, Val Loss=4.6059, lr=0.0100
[2025-05-06 23:56:38,085][train][INFO] - Epoch 15/100, Val Acc=0.1165, Val Loss=3.9671, lr=0.0100
[2025-05-06 23:56:41,185][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-06 23:56:43,027][train][INFO] - Epoch 15/100, Val Acc=0.0100, Val Loss=4.6060, lr=0.0100
[2025-05-06 23:56:45,504][train][INFO] - Epoch 16/100, Val Acc=0.1741, Val Loss=3.2488, lr=0.0100
[2025-05-06 23:56:48,920][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-06 23:56:50,334][train][INFO] - Epoch 16/100, Val Acc=0.0100, Val Loss=4.6058, lr=0.0100
[2025-05-06 23:56:53,370][train][INFO] - Epoch 17/100, Val Acc=0.1015, Val Loss=4.2260, lr=0.0100
[2025-05-06 23:56:56,752][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-06 23:56:57,529][train][INFO] - Epoch 17/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-06 23:57:00,742][train][INFO] - Epoch 18/100, Val Acc=0.1722, Val Loss=3.2525, lr=0.0100
[2025-05-06 23:57:04,393][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-06 23:57:05,486][train][INFO] - Epoch 18/100, Val Acc=0.0100, Val Loss=4.6056, lr=0.0100
[2025-05-06 23:57:08,648][train][INFO] - Epoch 19/100, Val Acc=0.2108, Val Loss=2.9886, lr=0.0100
[2025-05-06 23:57:12,332][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-06 23:57:13,182][train][INFO] - Epoch 19/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-06 23:57:16,787][train][INFO] - Epoch 20/100, Val Acc=0.1630, Val Loss=3.3470, lr=0.0100
[2025-05-06 23:57:20,397][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-06 23:57:20,456][train][INFO] - Epoch 20/100, Val Acc=0.0100, Val Loss=4.6055, lr=0.0100
[2025-05-06 23:57:24,391][train][INFO] - Epoch 21/100, Val Acc=0.1788, Val Loss=3.3365, lr=0.0100
[2025-05-06 23:57:28,072][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:28,492][train][INFO] - Epoch 21/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:32,064][train][INFO] - Epoch 22/100, Val Acc=0.1562, Val Loss=3.4496, lr=0.0100
[2025-05-06 23:57:35,485][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:36,253][train][INFO] - Epoch 22/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:39,633][train][INFO] - Epoch 23/100, Val Acc=0.1549, Val Loss=3.4232, lr=0.0100
[2025-05-06 23:57:43,580][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:43,684][train][INFO] - Epoch 23/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:47,415][train][INFO] - Epoch 24/100, Val Acc=0.2000, Val Loss=3.1630, lr=0.0100
[2025-05-06 23:57:51,258][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:57:51,394][train][INFO] - Epoch 24/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:57:54,784][train][INFO] - Epoch 25/100, Val Acc=0.2424, Val Loss=2.7895, lr=0.0100
[2025-05-06 23:57:58,547][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:57:59,003][train][INFO] - Epoch 25/100, Val Acc=0.0100, Val Loss=4.6054, lr=0.0100
[2025-05-06 23:58:02,438][train][INFO] - Epoch 26/100, Val Acc=0.2216, Val Loss=3.0762, lr=0.0100
[2025-05-06 23:58:06,677][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:06,814][train][INFO] - Epoch 26/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:10,238][train][INFO] - Epoch 27/100, Val Acc=0.1708, Val Loss=3.4479, lr=0.0100
[2025-05-06 23:58:14,199][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:14,821][train][INFO] - Epoch 27/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:17,887][train][INFO] - Epoch 28/100, Val Acc=0.2561, Val Loss=2.7502, lr=0.0100
[2025-05-06 23:58:21,985][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:22,621][train][INFO] - Epoch 28/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:25,386][train][INFO] - Epoch 29/100, Val Acc=0.2419, Val Loss=2.8554, lr=0.0100
[2025-05-06 23:58:29,613][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:30,612][train][INFO] - Epoch 29/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:33,397][train][INFO] - Epoch 30/100, Val Acc=0.2102, Val Loss=3.1089, lr=0.0100
[2025-05-06 23:58:37,437][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:38,277][train][INFO] - Epoch 30/100, Val Acc=0.0100, Val Loss=4.6053, lr=0.0100
[2025-05-06 23:58:41,761][train][INFO] - Epoch 31/100, Val Acc=0.2432, Val Loss=2.8648, lr=0.0100
[2025-05-06 23:58:45,033][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:46,034][train][INFO] - Epoch 31/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:49,966][train][INFO] - Epoch 32/100, Val Acc=0.2522, Val Loss=2.8323, lr=0.0100
[2025-05-06 23:58:52,617][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:53,657][train][INFO] - Epoch 32/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:58:58,092][train][INFO] - Epoch 33/100, Val Acc=0.2195, Val Loss=3.0507, lr=0.0100
[2025-05-06 23:58:59,916][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:01,548][train][INFO] - Epoch 33/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:05,939][train][INFO] - Epoch 34/100, Val Acc=0.2558, Val Loss=2.7618, lr=0.0100
[2025-05-06 23:59:07,692][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:09,274][train][INFO] - Epoch 34/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:13,890][train][INFO] - Epoch 35/100, Val Acc=0.2446, Val Loss=2.8742, lr=0.0100
[2025-05-06 23:59:15,196][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:16,983][train][INFO] - Epoch 35/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:22,104][train][INFO] - Epoch 36/100, Val Acc=0.2295, Val Loss=3.0298, lr=0.0100
[2025-05-06 23:59:22,588][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:24,554][train][INFO] - Epoch 36/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:30,282][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:30,424][train][INFO] - Epoch 37/100, Val Acc=0.2389, Val Loss=2.9309, lr=0.0100
[2025-05-06 23:59:32,510][train][INFO] - Epoch 37/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:38,056][train][INFO] - Epoch 38/100, Val Acc=0.2179, Val Loss=3.1274, lr=0.0100
[2025-05-06 23:59:38,301][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:39,984][train][INFO] - Epoch 38/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:45,629][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:45,741][train][INFO] - Epoch 39/100, Val Acc=0.2436, Val Loss=2.9161, lr=0.0100
[2025-05-06 23:59:47,292][train][INFO] - Epoch 39/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:53,249][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-06 23:59:53,403][train][INFO] - Epoch 40/100, Val Acc=0.2764, Val Loss=2.7217, lr=0.0100
[2025-05-06 23:59:54,703][train][INFO] - Epoch 40/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:01,345][train][INFO] - Epoch 41/100, Val Acc=0.2511, Val Loss=2.8344, lr=0.0100
[2025-05-07 00:00:01,695][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:02,311][train][INFO] - Epoch 41/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:09,148][train][INFO] - Epoch 42/100, Val Acc=0.1951, Val Loss=3.3177, lr=0.0100
[2025-05-07 00:00:09,374][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:09,512][train][INFO] - Epoch 42/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:16,584][train][INFO] - Epoch 43/100, Val Acc=0.2255, Val Loss=3.1839, lr=0.0100
[2025-05-07 00:00:16,907][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:17,220][train][INFO] - Epoch 43/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:24,643][train][INFO] - Epoch 44/100, Val Acc=0.2236, Val Loss=3.1106, lr=0.0100
[2025-05-07 00:00:24,799][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:24,839][train][INFO] - Epoch 44/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:32,756][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:32,884][train][INFO] - Epoch 45/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:33,009][train][INFO] - Epoch 45/100, Val Acc=0.2548, Val Loss=2.9017, lr=0.0100
[2025-05-07 00:00:40,500][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:40,806][train][INFO] - Epoch 46/100, Val Acc=0.2546, Val Loss=2.9013, lr=0.0100
[2025-05-07 00:00:40,877][train][INFO] - Epoch 46/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:47,776][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:48,302][train][INFO] - Epoch 47/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:48,416][train][INFO] - Epoch 47/100, Val Acc=0.2873, Val Loss=2.6866, lr=0.0100
[2025-05-07 00:00:55,600][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:56,101][train][INFO] - Epoch 48/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:00:56,494][train][INFO] - Epoch 48/100, Val Acc=0.2871, Val Loss=2.7151, lr=0.0100
[2025-05-07 00:01:03,219][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:03,465][train][INFO] - Epoch 49/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:03,850][train][INFO] - Epoch 49/100, Val Acc=0.2862, Val Loss=2.6997, lr=0.0100
[2025-05-07 00:01:11,180][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:11,295][train][INFO] - Epoch 50/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:12,065][train][INFO] - Epoch 50/100, Val Acc=0.2479, Val Loss=2.9204, lr=0.0100
[2025-05-07 00:01:18,700][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:18,906][train][INFO] - Epoch 51/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:20,098][train][INFO] - Epoch 51/100, Val Acc=0.2001, Val Loss=3.3079, lr=0.0100
[2025-05-07 00:01:26,728][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:26,981][train][INFO] - Epoch 52/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:28,046][train][INFO] - Epoch 52/100, Val Acc=0.1773, Val Loss=3.6261, lr=0.0100
[2025-05-07 00:01:34,496][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:34,616][train][INFO] - Epoch 53/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:36,066][train][INFO] - Epoch 53/100, Val Acc=0.2581, Val Loss=2.8671, lr=0.0100
[2025-05-07 00:01:42,192][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:42,474][train][INFO] - Epoch 54/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:44,271][train][INFO] - Epoch 54/100, Val Acc=0.1793, Val Loss=3.7238, lr=0.0100
[2025-05-07 00:01:49,630][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:50,192][train][INFO] - Epoch 55/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:52,028][train][INFO] - Epoch 55/100, Val Acc=0.2746, Val Loss=2.8196, lr=0.0100
[2025-05-07 00:01:57,352][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:57,707][train][INFO] - Epoch 56/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:01:59,816][train][INFO] - Epoch 56/100, Val Acc=0.2825, Val Loss=2.7304, lr=0.0100
[2025-05-07 00:02:04,873][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:04,926][train][INFO] - Epoch 57/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:07,240][train][INFO] - Epoch 57/100, Val Acc=0.2509, Val Loss=2.9567, lr=0.0100
[2025-05-07 00:02:12,353][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:12,538][train][INFO] - Epoch 58/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:14,898][train][INFO] - Epoch 58/100, Val Acc=0.3006, Val Loss=2.6406, lr=0.0100
[2025-05-07 00:02:19,917][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:20,271][train][INFO] - Epoch 59/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:22,359][train][INFO] - Epoch 59/100, Val Acc=0.2956, Val Loss=2.6790, lr=0.0100
[2025-05-07 00:02:27,482][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:28,258][train][INFO] - Epoch 60/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0100
[2025-05-07 00:02:30,156][train][INFO] - Epoch 60/100, Val Acc=0.2710, Val Loss=2.9345, lr=0.0100
[2025-05-07 00:02:35,620][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:35,719][train][INFO] - Epoch 61/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:38,166][train][INFO] - Epoch 61/100, Val Acc=0.3715, Val Loss=2.3067, lr=0.0010
[2025-05-07 00:02:42,850][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:43,602][train][INFO] - Epoch 62/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:45,895][train][INFO] - Epoch 62/100, Val Acc=0.3718, Val Loss=2.3056, lr=0.0010
[2025-05-07 00:02:50,167][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:51,477][train][INFO] - Epoch 63/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:52,783][train][INFO] - Epoch 63/100, Val Acc=0.3737, Val Loss=2.3009, lr=0.0010
[2025-05-07 00:02:57,806][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:02:59,579][train][INFO] - Epoch 64/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:00,399][train][INFO] - Epoch 64/100, Val Acc=0.3712, Val Loss=2.3061, lr=0.0010
[2025-05-07 00:03:05,139][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:07,214][train][INFO] - Epoch 65/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:08,445][train][INFO] - Epoch 65/100, Val Acc=0.3797, Val Loss=2.2815, lr=0.0010
[2025-05-07 00:03:12,120][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:14,778][train][INFO] - Epoch 66/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:16,054][train][INFO] - Epoch 66/100, Val Acc=0.3754, Val Loss=2.2911, lr=0.0010
[2025-05-07 00:03:19,919][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:22,563][train][INFO] - Epoch 67/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:23,708][train][INFO] - Epoch 67/100, Val Acc=0.3761, Val Loss=2.2666, lr=0.0010
[2025-05-07 00:03:27,569][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:30,286][train][INFO] - Epoch 68/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:31,707][train][INFO] - Epoch 68/100, Val Acc=0.3808, Val Loss=2.2774, lr=0.0010
[2025-05-07 00:03:35,232][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:37,686][train][INFO] - Epoch 69/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:39,804][train][INFO] - Epoch 69/100, Val Acc=0.3812, Val Loss=2.2676, lr=0.0010
[2025-05-07 00:03:42,428][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:45,605][train][INFO] - Epoch 70/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:47,650][train][INFO] - Epoch 70/100, Val Acc=0.3823, Val Loss=2.2577, lr=0.0010
[2025-05-07 00:03:50,313][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:53,498][train][INFO] - Epoch 71/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:03:55,685][train][INFO] - Epoch 71/100, Val Acc=0.3751, Val Loss=2.2737, lr=0.0010
[2025-05-07 00:03:57,980][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:01,591][train][INFO] - Epoch 72/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:03,425][train][INFO] - Epoch 72/100, Val Acc=0.3794, Val Loss=2.2787, lr=0.0010
[2025-05-07 00:04:06,011][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:09,216][train][INFO] - Epoch 73/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:11,356][train][INFO] - Epoch 73/100, Val Acc=0.3804, Val Loss=2.2659, lr=0.0010
[2025-05-07 00:04:13,709][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:16,676][train][INFO] - Epoch 74/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:19,019][train][INFO] - Epoch 74/100, Val Acc=0.3850, Val Loss=2.2650, lr=0.0010
[2025-05-07 00:04:21,137][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:24,667][train][INFO] - Epoch 75/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:26,718][train][INFO] - Epoch 75/100, Val Acc=0.3806, Val Loss=2.2617, lr=0.0010
[2025-05-07 00:04:28,817][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:32,576][train][INFO] - Epoch 76/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:34,364][train][INFO] - Epoch 76/100, Val Acc=0.3849, Val Loss=2.2709, lr=0.0010
[2025-05-07 00:04:36,477][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:39,979][train][INFO] - Epoch 77/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:41,787][train][INFO] - Epoch 77/100, Val Acc=0.3822, Val Loss=2.2644, lr=0.0010
[2025-05-07 00:04:43,984][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:47,657][train][INFO] - Epoch 78/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:49,470][train][INFO] - Epoch 78/100, Val Acc=0.3804, Val Loss=2.2746, lr=0.0010
[2025-05-07 00:04:51,237][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:55,677][train][INFO] - Epoch 79/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:04:57,673][train][INFO] - Epoch 79/100, Val Acc=0.3769, Val Loss=2.2911, lr=0.0010
[2025-05-07 00:04:58,418][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:03,130][train][INFO] - Epoch 80/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:05,764][train][INFO] - Epoch 80/100, Val Acc=0.3835, Val Loss=2.2743, lr=0.0010
[2025-05-07 00:05:05,951][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:11,141][train][INFO] - Epoch 81/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:13,327][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:13,475][train][INFO] - Epoch 81/100, Val Acc=0.3811, Val Loss=2.2634, lr=0.0010
[2025-05-07 00:05:19,119][train][INFO] - Epoch 82/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:21,114][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:21,420][train][INFO] - Epoch 82/100, Val Acc=0.3791, Val Loss=2.2776, lr=0.0010
[2025-05-07 00:05:26,733][train][INFO] - Epoch 83/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:28,838][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:29,095][train][INFO] - Epoch 83/100, Val Acc=0.3865, Val Loss=2.2600, lr=0.0010
[2025-05-07 00:05:34,447][train][INFO] - Epoch 84/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:36,158][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:37,346][train][INFO] - Epoch 84/100, Val Acc=0.3812, Val Loss=2.2937, lr=0.0010
[2025-05-07 00:05:42,387][train][INFO] - Epoch 85/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:43,528][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:45,099][train][INFO] - Epoch 85/100, Val Acc=0.3838, Val Loss=2.2665, lr=0.0010
[2025-05-07 00:05:49,836][train][INFO] - Epoch 86/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:50,641][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:53,071][train][INFO] - Epoch 86/100, Val Acc=0.3789, Val Loss=2.2819, lr=0.0010
[2025-05-07 00:05:57,523][train][INFO] - Epoch 87/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:05:58,293][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:06:00,760][train][INFO] - Epoch 87/100, Val Acc=0.3838, Val Loss=2.2768, lr=0.0010
[2025-05-07 00:06:05,177][train][INFO] - Epoch 88/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:06:05,927][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:06:08,857][train][INFO] - Epoch 88/100, Val Acc=0.3856, Val Loss=2.2762, lr=0.0010
[2025-05-07 00:06:12,967][train][INFO] - Epoch 89/100, Val Acc=0.0100, Val Loss=4.6052, lr=0.0010
[2025-05-07 00:07:28,760][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-07 00:07:28,810][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-07 00:07:28,810][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-07 00:07:28,810][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-07 00:07:48,139][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-07 00:07:55,927][train][INFO] - Epoch 1/2000, Val Acc=0.0100, Val Loss=4.6114, lr=0.0100
[2025-05-07 00:08:03,894][train][INFO] - Epoch 2/2000, Val Acc=0.0083, Val Loss=4.6816, lr=0.0100
[2025-05-07 00:08:06,946][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 9.0
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 21

[2025-05-07 00:08:07,011][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-07 00:08:07,011][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-07 00:08:07,011][get_dataset_model_loader][INFO] - ==================================================
[2025-05-07 00:08:11,405][train][INFO] - Epoch 3/2000, Val Acc=0.0347, Val Loss=4.5056, lr=0.0100
[2025-05-07 00:08:19,792][train][INFO] - Epoch 4/2000, Val Acc=0.0909, Val Loss=3.6941, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-07 00:08:26,982][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-07 00:08:28,283][train][INFO] - Epoch 5/2000, Val Acc=0.1538, Val Loss=3.3655, lr=0.0100
[2025-05-07 00:08:35,127][train][INFO] - Epoch 1/2000, Val Acc=0.0123, Val Loss=4.8749, lr=0.0100
[2025-05-07 00:08:36,177][train][INFO] - Epoch 6/2000, Val Acc=0.1839, Val Loss=3.2121, lr=0.0100
[2025-05-07 00:08:43,463][train][INFO] - Epoch 7/2000, Val Acc=0.1721, Val Loss=3.3469, lr=0.0100
[2025-05-07 00:08:43,542][train][INFO] - Epoch 2/2000, Val Acc=0.0129, Val Loss=5.1165, lr=0.0100
[2025-05-07 00:08:51,808][train][INFO] - Epoch 8/2000, Val Acc=0.2367, Val Loss=2.9546, lr=0.0100
[2025-05-07 00:08:51,864][train][INFO] - Epoch 3/2000, Val Acc=0.0307, Val Loss=4.3389, lr=0.0100
[2025-05-07 00:08:52,490][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '5'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 32
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '2':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 12
      hiddim: 96
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 8.95
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 2000
        lr: 0.01
        lr_decay_milestones: 1850, 1950
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Harry
level: 0
run: pruning_one_step
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-05-07 00:08:52,545][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-05-07 00:08:52,545][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-05-07 00:08:52,545][get_dataset_model_loader][INFO] - ==================================================
[2025-05-07 00:08:59,591][train][INFO] - Epoch 4/2000, Val Acc=0.1006, Val Loss=3.5952, lr=0.0100
[2025-05-07 00:09:00,763][train][INFO] - Epoch 9/2000, Val Acc=0.2380, Val Loss=2.9688, lr=0.0100
[2025-05-07 00:09:07,783][train][INFO] - Epoch 5/2000, Val Acc=0.0959, Val Loss=3.8115, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-05-07 00:09:08,796][train][INFO] - Epoch 10/2000, Val Acc=0.2335, Val Loss=2.9973, lr=0.0100
[2025-05-07 00:09:13,225][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-07 00:09:15,599][train][INFO] - Epoch 6/2000, Val Acc=0.1489, Val Loss=3.4241, lr=0.0100
[2025-05-07 00:09:16,429][train][INFO] - Epoch 11/2000, Val Acc=0.3091, Val Loss=2.5310, lr=0.0100
[2025-05-07 00:09:20,801][train][INFO] - Epoch 1/2000, Val Acc=0.0100, Val Loss=4.6114, lr=0.0100
[2025-05-07 00:09:23,547][train][INFO] - Epoch 7/2000, Val Acc=0.1325, Val Loss=3.3739, lr=0.0100
[2025-05-07 00:09:24,505][train][INFO] - Epoch 12/2000, Val Acc=0.2669, Val Loss=2.8693, lr=0.0100
[2025-05-07 00:09:28,254][train][INFO] - Epoch 2/2000, Val Acc=0.0083, Val Loss=4.6816, lr=0.0100
[2025-05-07 00:09:31,368][train][INFO] - Epoch 8/2000, Val Acc=0.1683, Val Loss=3.2739, lr=0.0100
[2025-05-07 00:09:32,344][train][INFO] - Epoch 13/2000, Val Acc=0.3443, Val Loss=2.4074, lr=0.0100
[2025-05-07 00:09:35,878][train][INFO] - Epoch 3/2000, Val Acc=0.0347, Val Loss=4.5056, lr=0.0100
[2025-05-07 00:09:39,035][train][INFO] - Epoch 9/2000, Val Acc=0.2110, Val Loss=2.9570, lr=0.0100
[2025-05-07 00:09:40,210][train][INFO] - Epoch 14/2000, Val Acc=0.3454, Val Loss=2.4001, lr=0.0100
[2025-05-07 00:09:43,314][train][INFO] - Epoch 4/2000, Val Acc=0.0909, Val Loss=3.6941, lr=0.0100
[2025-05-07 00:09:46,907][train][INFO] - Epoch 10/2000, Val Acc=0.1890, Val Loss=3.1693, lr=0.0100
[2025-05-07 00:09:48,073][train][INFO] - Epoch 15/2000, Val Acc=0.2666, Val Loss=3.0072, lr=0.0100
[2025-05-07 00:09:50,755][train][INFO] - Epoch 5/2000, Val Acc=0.1538, Val Loss=3.3655, lr=0.0100
[2025-05-07 00:09:54,705][train][INFO] - Epoch 11/2000, Val Acc=0.2088, Val Loss=3.0746, lr=0.0100
[2025-05-07 00:09:55,881][train][INFO] - Epoch 16/2000, Val Acc=0.3399, Val Loss=2.5008, lr=0.0100
[2025-05-07 00:09:58,212][train][INFO] - Epoch 6/2000, Val Acc=0.1839, Val Loss=3.2121, lr=0.0100
[2025-05-07 00:10:02,608][train][INFO] - Epoch 12/2000, Val Acc=0.1955, Val Loss=3.0959, lr=0.0100
[2025-05-07 00:10:03,214][train][INFO] - Epoch 17/2000, Val Acc=0.3537, Val Loss=2.4310, lr=0.0100
[2025-05-07 00:10:05,917][train][INFO] - Epoch 7/2000, Val Acc=0.1721, Val Loss=3.3469, lr=0.0100
[2025-05-07 00:10:10,214][train][INFO] - Epoch 13/2000, Val Acc=0.1874, Val Loss=3.2019, lr=0.0100
[2025-05-07 00:10:10,944][train][INFO] - Epoch 18/2000, Val Acc=0.3419, Val Loss=2.5220, lr=0.0100
[2025-05-07 00:10:13,574][train][INFO] - Epoch 8/2000, Val Acc=0.2367, Val Loss=2.9546, lr=0.0100
[2025-05-07 00:10:17,577][train][INFO] - Epoch 14/2000, Val Acc=0.1777, Val Loss=3.2603, lr=0.0100
[2025-05-07 00:10:18,489][train][INFO] - Epoch 19/2000, Val Acc=0.3757, Val Loss=2.3394, lr=0.0100
[2025-05-07 00:10:21,299][train][INFO] - Epoch 9/2000, Val Acc=0.2380, Val Loss=2.9688, lr=0.0100
[2025-05-07 00:10:24,889][train][INFO] - Epoch 15/2000, Val Acc=0.2371, Val Loss=2.9150, lr=0.0100
[2025-05-07 00:10:26,219][train][INFO] - Epoch 20/2000, Val Acc=0.4116, Val Loss=2.1341, lr=0.0100
[2025-05-07 00:10:28,951][train][INFO] - Epoch 10/2000, Val Acc=0.2335, Val Loss=2.9973, lr=0.0100
[2025-05-07 00:10:32,559][train][INFO] - Epoch 16/2000, Val Acc=0.2109, Val Loss=3.1933, lr=0.0100
[2025-05-07 00:10:33,960][train][INFO] - Epoch 21/2000, Val Acc=0.4161, Val Loss=2.1494, lr=0.0100
[2025-05-07 00:10:36,162][train][INFO] - Epoch 11/2000, Val Acc=0.3091, Val Loss=2.5310, lr=0.0100
[2025-05-07 00:10:39,967][train][INFO] - Epoch 17/2000, Val Acc=0.2236, Val Loss=3.1627, lr=0.0100
[2025-05-07 00:10:41,606][train][INFO] - Epoch 22/2000, Val Acc=0.3860, Val Loss=2.2593, lr=0.0100
[2025-05-07 00:10:43,561][train][INFO] - Epoch 12/2000, Val Acc=0.2669, Val Loss=2.8693, lr=0.0100
[2025-05-07 00:10:47,385][train][INFO] - Epoch 18/2000, Val Acc=0.2420, Val Loss=2.8621, lr=0.0100
[2025-05-07 00:10:49,424][train][INFO] - Epoch 23/2000, Val Acc=0.4250, Val Loss=2.1168, lr=0.0100
[2025-05-07 00:10:51,399][train][INFO] - Epoch 13/2000, Val Acc=0.3443, Val Loss=2.4074, lr=0.0100
[2025-05-07 00:10:55,350][train][INFO] - Epoch 19/2000, Val Acc=0.2436, Val Loss=2.9562, lr=0.0100
[2025-05-07 00:10:57,092][train][INFO] - Epoch 24/2000, Val Acc=0.4479, Val Loss=2.0023, lr=0.0100
[2025-05-07 00:10:59,046][train][INFO] - Epoch 14/2000, Val Acc=0.3454, Val Loss=2.4001, lr=0.0100
[2025-05-07 00:11:02,707][train][INFO] - Epoch 20/2000, Val Acc=0.2509, Val Loss=2.8723, lr=0.0100
[2025-05-07 00:11:04,938][train][INFO] - Epoch 25/2000, Val Acc=0.4573, Val Loss=1.9823, lr=0.0100
[2025-05-07 00:11:06,643][train][INFO] - Epoch 15/2000, Val Acc=0.2666, Val Loss=3.0072, lr=0.0100
[2025-05-07 00:11:10,491][train][INFO] - Epoch 21/2000, Val Acc=0.2904, Val Loss=2.6250, lr=0.0100
[2025-05-07 00:11:12,583][train][INFO] - Epoch 26/2000, Val Acc=0.4316, Val Loss=2.1276, lr=0.0100
[2025-05-07 00:11:14,406][train][INFO] - Epoch 16/2000, Val Acc=0.3399, Val Loss=2.5008, lr=0.0100
[2025-05-07 00:11:17,691][train][INFO] - Epoch 22/2000, Val Acc=0.2915, Val Loss=2.7497, lr=0.0100
[2025-05-07 00:11:20,289][train][INFO] - Epoch 27/2000, Val Acc=0.4108, Val Loss=2.2066, lr=0.0100
[2025-05-07 00:11:21,922][train][INFO] - Epoch 17/2000, Val Acc=0.3537, Val Loss=2.4310, lr=0.0100
[2025-05-07 00:11:25,629][train][INFO] - Epoch 23/2000, Val Acc=0.2556, Val Loss=2.8101, lr=0.0100
[2025-05-07 00:11:28,055][train][INFO] - Epoch 28/2000, Val Acc=0.4160, Val Loss=2.2133, lr=0.0100
[2025-05-07 00:11:29,537][train][INFO] - Epoch 18/2000, Val Acc=0.3419, Val Loss=2.5220, lr=0.0100
[2025-05-07 00:11:33,472][train][INFO] - Epoch 24/2000, Val Acc=0.3050, Val Loss=2.6192, lr=0.0100
[2025-05-07 00:11:35,796][train][INFO] - Epoch 29/2000, Val Acc=0.4561, Val Loss=2.0136, lr=0.0100
[2025-05-07 00:11:36,781][train][INFO] - Epoch 19/2000, Val Acc=0.3757, Val Loss=2.3394, lr=0.0100
[2025-05-07 00:11:41,195][train][INFO] - Epoch 25/2000, Val Acc=0.3235, Val Loss=2.5711, lr=0.0100
[2025-05-07 00:11:43,994][train][INFO] - Epoch 30/2000, Val Acc=0.4730, Val Loss=1.9318, lr=0.0100
[2025-05-07 00:11:44,321][train][INFO] - Epoch 20/2000, Val Acc=0.4116, Val Loss=2.1341, lr=0.0100
[2025-05-07 00:11:49,102][train][INFO] - Epoch 26/2000, Val Acc=0.2867, Val Loss=2.7265, lr=0.0100
[2025-05-07 00:11:51,710][train][INFO] - Epoch 31/2000, Val Acc=0.4696, Val Loss=1.9640, lr=0.0100
[2025-05-07 00:11:51,834][train][INFO] - Epoch 21/2000, Val Acc=0.4161, Val Loss=2.1494, lr=0.0100
[2025-05-07 00:11:56,890][train][INFO] - Epoch 27/2000, Val Acc=0.3027, Val Loss=2.6649, lr=0.0100
[2025-05-07 00:11:59,745][train][INFO] - Epoch 22/2000, Val Acc=0.3860, Val Loss=2.2593, lr=0.0100
[2025-05-07 00:11:59,908][train][INFO] - Epoch 32/2000, Val Acc=0.4584, Val Loss=1.9701, lr=0.0100
[2025-05-07 00:12:04,703][train][INFO] - Epoch 28/2000, Val Acc=0.2885, Val Loss=2.9256, lr=0.0100
[2025-05-07 00:12:07,283][train][INFO] - Epoch 23/2000, Val Acc=0.4250, Val Loss=2.1168, lr=0.0100
[2025-05-07 00:12:07,761][train][INFO] - Epoch 33/2000, Val Acc=0.4362, Val Loss=2.1575, lr=0.0100
[2025-05-07 00:12:12,372][train][INFO] - Epoch 29/2000, Val Acc=0.3125, Val Loss=2.6606, lr=0.0100
[2025-05-07 00:12:14,504][train][INFO] - Epoch 24/2000, Val Acc=0.4479, Val Loss=2.0023, lr=0.0100
[2025-05-07 00:12:15,733][train][INFO] - Epoch 34/2000, Val Acc=0.4595, Val Loss=1.9880, lr=0.0100
[2025-05-07 00:12:20,263][train][INFO] - Epoch 30/2000, Val Acc=0.3589, Val Loss=2.4285, lr=0.0100
[2025-05-07 00:12:22,265][train][INFO] - Epoch 25/2000, Val Acc=0.4573, Val Loss=1.9823, lr=0.0100
[2025-05-07 00:12:23,597][train][INFO] - Epoch 35/2000, Val Acc=0.4626, Val Loss=2.0220, lr=0.0100
[2025-05-07 00:12:27,703][train][INFO] - Epoch 31/2000, Val Acc=0.3556, Val Loss=2.4285, lr=0.0100
[2025-05-07 00:12:30,072][train][INFO] - Epoch 26/2000, Val Acc=0.4316, Val Loss=2.1276, lr=0.0100
[2025-05-07 00:12:31,597][train][INFO] - Epoch 36/2000, Val Acc=0.4735, Val Loss=2.0218, lr=0.0100
[2025-05-07 00:12:35,455][train][INFO] - Epoch 32/2000, Val Acc=0.3698, Val Loss=2.3286, lr=0.0100
[2025-05-07 00:12:37,572][train][INFO] - Epoch 27/2000, Val Acc=0.4108, Val Loss=2.2066, lr=0.0100
[2025-05-07 00:12:39,633][train][INFO] - Epoch 37/2000, Val Acc=0.5081, Val Loss=1.8295, lr=0.0100
[2025-05-07 00:12:43,508][train][INFO] - Epoch 33/2000, Val Acc=0.3342, Val Loss=2.5192, lr=0.0100
[2025-05-07 00:12:45,050][train][INFO] - Epoch 28/2000, Val Acc=0.4160, Val Loss=2.2133, lr=0.0100
[2025-05-07 00:12:47,613][train][INFO] - Epoch 38/2000, Val Acc=0.4977, Val Loss=1.8533, lr=0.0100
[2025-05-07 00:12:51,201][train][INFO] - Epoch 34/2000, Val Acc=0.3195, Val Loss=2.7038, lr=0.0100
[2025-05-07 00:12:52,908][train][INFO] - Epoch 29/2000, Val Acc=0.4561, Val Loss=2.0136, lr=0.0100
[2025-05-07 00:12:55,374][train][INFO] - Epoch 39/2000, Val Acc=0.4727, Val Loss=1.9816, lr=0.0100
[2025-05-07 00:12:58,858][train][INFO] - Epoch 35/2000, Val Acc=0.3896, Val Loss=2.2404, lr=0.0100
[2025-05-07 00:13:00,364][train][INFO] - Epoch 30/2000, Val Acc=0.4730, Val Loss=1.9318, lr=0.0100
[2025-05-07 00:13:03,580][train][INFO] - Epoch 40/2000, Val Acc=0.4728, Val Loss=1.9976, lr=0.0100
[2025-05-07 00:13:06,251][train][INFO] - Epoch 36/2000, Val Acc=0.3699, Val Loss=2.3715, lr=0.0100
[2025-05-07 00:13:07,816][train][INFO] - Epoch 31/2000, Val Acc=0.4696, Val Loss=1.9640, lr=0.0100
[2025-05-07 00:13:11,396][train][INFO] - Epoch 41/2000, Val Acc=0.4957, Val Loss=1.8969, lr=0.0100
[2025-05-07 00:13:13,687][train][INFO] - Epoch 37/2000, Val Acc=0.3607, Val Loss=2.3459, lr=0.0100
[2025-05-07 00:13:15,268][train][INFO] - Epoch 32/2000, Val Acc=0.4584, Val Loss=1.9701, lr=0.0100
[2025-05-07 00:13:19,439][train][INFO] - Epoch 42/2000, Val Acc=0.5027, Val Loss=1.8587, lr=0.0100
[2025-05-07 00:13:21,344][train][INFO] - Epoch 38/2000, Val Acc=0.3993, Val Loss=2.1864, lr=0.0100
[2025-05-07 00:13:22,757][train][INFO] - Epoch 33/2000, Val Acc=0.4362, Val Loss=2.1575, lr=0.0100
[2025-05-07 00:13:27,488][train][INFO] - Epoch 43/2000, Val Acc=0.5207, Val Loss=1.8040, lr=0.0100
[2025-05-07 00:13:28,601][train][INFO] - Epoch 39/2000, Val Acc=0.3978, Val Loss=2.2549, lr=0.0100
[2025-05-07 00:13:30,291][train][INFO] - Epoch 34/2000, Val Acc=0.4595, Val Loss=1.9880, lr=0.0100
[2025-05-07 00:13:35,189][train][INFO] - Epoch 44/2000, Val Acc=0.5109, Val Loss=1.8133, lr=0.0100
[2025-05-07 00:13:36,032][train][INFO] - Epoch 40/2000, Val Acc=0.4173, Val Loss=2.1641, lr=0.0100
[2025-05-07 00:13:37,924][train][INFO] - Epoch 35/2000, Val Acc=0.4626, Val Loss=2.0220, lr=0.0100
[2025-05-07 00:13:42,969][train][INFO] - Epoch 45/2000, Val Acc=0.5089, Val Loss=1.8242, lr=0.0100
[2025-05-07 00:13:43,326][train][INFO] - Epoch 41/2000, Val Acc=0.4213, Val Loss=2.1585, lr=0.0100
[2025-05-07 00:13:45,917][train][INFO] - Epoch 36/2000, Val Acc=0.4735, Val Loss=2.0218, lr=0.0100
[2025-05-07 00:13:50,744][train][INFO] - Epoch 46/2000, Val Acc=0.5104, Val Loss=1.8402, lr=0.0100
[2025-05-07 00:13:51,302][train][INFO] - Epoch 42/2000, Val Acc=0.3872, Val Loss=2.3011, lr=0.0100
[2025-05-07 00:13:53,513][train][INFO] - Epoch 37/2000, Val Acc=0.5081, Val Loss=1.8295, lr=0.0100
[2025-05-07 00:13:58,626][train][INFO] - Epoch 47/2000, Val Acc=0.5216, Val Loss=1.7895, lr=0.0100
[2025-05-07 00:13:59,220][train][INFO] - Epoch 43/2000, Val Acc=0.3993, Val Loss=2.2861, lr=0.0100
[2025-05-07 00:14:01,006][train][INFO] - Epoch 38/2000, Val Acc=0.4977, Val Loss=1.8533, lr=0.0100
[2025-05-07 00:14:06,354][train][INFO] - Epoch 48/2000, Val Acc=0.5184, Val Loss=1.8127, lr=0.0100
[2025-05-07 00:14:06,964][train][INFO] - Epoch 44/2000, Val Acc=0.3619, Val Loss=2.4200, lr=0.0100
[2025-05-07 00:14:08,793][train][INFO] - Epoch 39/2000, Val Acc=0.4727, Val Loss=1.9816, lr=0.0100
[2025-05-07 00:14:14,139][train][INFO] - Epoch 49/2000, Val Acc=0.5162, Val Loss=1.8359, lr=0.0100
[2025-05-07 00:14:14,551][train][INFO] - Epoch 45/2000, Val Acc=0.4358, Val Loss=2.0790, lr=0.0100
[2025-05-07 00:14:16,462][train][INFO] - Epoch 40/2000, Val Acc=0.4728, Val Loss=1.9976, lr=0.0100
[2025-05-07 00:14:22,032][train][INFO] - Epoch 50/2000, Val Acc=0.5123, Val Loss=1.8540, lr=0.0100
[2025-05-07 00:14:22,087][train][INFO] - Epoch 46/2000, Val Acc=0.4331, Val Loss=2.1076, lr=0.0100
[2025-05-07 00:14:23,807][train][INFO] - Epoch 41/2000, Val Acc=0.4957, Val Loss=1.8969, lr=0.0100
[2025-05-07 00:14:29,229][train][INFO] - Epoch 51/2000, Val Acc=0.5112, Val Loss=1.8444, lr=0.0100
[2025-05-07 00:14:30,010][train][INFO] - Epoch 47/2000, Val Acc=0.3998, Val Loss=2.3389, lr=0.0100
[2025-05-07 00:14:30,887][train][INFO] - Epoch 42/2000, Val Acc=0.5027, Val Loss=1.8587, lr=0.0100
[2025-05-07 00:14:37,109][train][INFO] - Epoch 52/2000, Val Acc=0.4748, Val Loss=2.0892, lr=0.0100
[2025-05-07 00:14:38,282][train][INFO] - Epoch 48/2000, Val Acc=0.4195, Val Loss=2.2255, lr=0.0100
[2025-05-07 00:14:38,601][train][INFO] - Epoch 43/2000, Val Acc=0.5207, Val Loss=1.8040, lr=0.0100
[2025-05-07 00:14:44,558][train][INFO] - Epoch 53/2000, Val Acc=0.5040, Val Loss=1.9552, lr=0.0100
[2025-05-07 00:14:46,012][train][INFO] - Epoch 44/2000, Val Acc=0.5109, Val Loss=1.8133, lr=0.0100
[2025-05-07 00:14:46,019][train][INFO] - Epoch 49/2000, Val Acc=0.4079, Val Loss=2.2692, lr=0.0100
[2025-05-07 00:14:52,167][train][INFO] - Epoch 54/2000, Val Acc=0.5304, Val Loss=1.7693, lr=0.0100
[2025-05-07 00:14:53,449][train][INFO] - Epoch 45/2000, Val Acc=0.5089, Val Loss=1.8242, lr=0.0100
[2025-05-07 00:14:53,852][train][INFO] - Epoch 50/2000, Val Acc=0.4468, Val Loss=2.0698, lr=0.0100
[2025-05-07 00:15:00,237][train][INFO] - Epoch 55/2000, Val Acc=0.4946, Val Loss=1.9258, lr=0.0100
[2025-05-07 00:15:01,207][train][INFO] - Epoch 46/2000, Val Acc=0.5104, Val Loss=1.8402, lr=0.0100
[2025-05-07 00:15:01,413][train][INFO] - Epoch 51/2000, Val Acc=0.4574, Val Loss=2.0229, lr=0.0100
[2025-05-07 00:15:08,379][train][INFO] - Epoch 56/2000, Val Acc=0.5227, Val Loss=1.8318, lr=0.0100
[2025-05-07 00:15:09,220][train][INFO] - Epoch 52/2000, Val Acc=0.4190, Val Loss=2.1963, lr=0.0100
[2025-05-07 00:15:09,561][train][INFO] - Epoch 47/2000, Val Acc=0.5216, Val Loss=1.7895, lr=0.0100
[2025-05-07 00:15:15,604][train][INFO] - Epoch 57/2000, Val Acc=0.5483, Val Loss=1.6845, lr=0.0100
[2025-05-07 00:15:16,778][train][INFO] - Epoch 53/2000, Val Acc=0.4502, Val Loss=2.0421, lr=0.0100
[2025-05-07 00:15:17,346][train][INFO] - Epoch 48/2000, Val Acc=0.5184, Val Loss=1.8127, lr=0.0100
[2025-05-07 00:15:23,523][train][INFO] - Epoch 58/2000, Val Acc=0.5310, Val Loss=1.7666, lr=0.0100
[2025-05-07 00:15:24,365][train][INFO] - Epoch 54/2000, Val Acc=0.4324, Val Loss=2.2140, lr=0.0100
[2025-05-07 00:15:25,016][train][INFO] - Epoch 49/2000, Val Acc=0.5162, Val Loss=1.8359, lr=0.0100
[2025-05-07 00:15:31,338][train][INFO] - Epoch 59/2000, Val Acc=0.5432, Val Loss=1.6975, lr=0.0100
[2025-05-07 00:15:32,116][train][INFO] - Epoch 55/2000, Val Acc=0.4519, Val Loss=2.0715, lr=0.0100
[2025-05-07 00:15:32,429][train][INFO] - Epoch 50/2000, Val Acc=0.5123, Val Loss=1.8540, lr=0.0100
[2025-05-07 00:15:38,807][train][INFO] - Epoch 60/2000, Val Acc=0.5255, Val Loss=1.8257, lr=0.0100
[2025-05-07 00:15:39,767][train][INFO] - Epoch 56/2000, Val Acc=0.4504, Val Loss=2.0832, lr=0.0100
[2025-05-07 00:15:39,871][train][INFO] - Epoch 51/2000, Val Acc=0.5112, Val Loss=1.8444, lr=0.0100
[2025-05-07 00:15:46,655][train][INFO] - Epoch 61/2000, Val Acc=0.5370, Val Loss=1.7684, lr=0.0100
[2025-05-07 00:15:47,267][train][INFO] - Epoch 57/2000, Val Acc=0.4612, Val Loss=2.0290, lr=0.0100
[2025-05-07 00:15:47,294][train][INFO] - Epoch 52/2000, Val Acc=0.4748, Val Loss=2.0892, lr=0.0100
[2025-05-07 00:15:54,549][train][INFO] - Epoch 62/2000, Val Acc=0.5484, Val Loss=1.7137, lr=0.0100
[2025-05-07 00:15:54,836][train][INFO] - Epoch 53/2000, Val Acc=0.5040, Val Loss=1.9552, lr=0.0100
[2025-05-07 00:15:54,876][train][INFO] - Epoch 58/2000, Val Acc=0.4532, Val Loss=2.0416, lr=0.0100
[2025-05-07 00:16:02,609][train][INFO] - Epoch 54/2000, Val Acc=0.5304, Val Loss=1.7693, lr=0.0100
[2025-05-07 00:16:02,767][train][INFO] - Epoch 59/2000, Val Acc=0.4499, Val Loss=2.0907, lr=0.0100
[2025-05-07 00:16:02,809][train][INFO] - Epoch 63/2000, Val Acc=0.5138, Val Loss=1.9043, lr=0.0100
[2025-05-07 00:16:10,246][train][INFO] - Epoch 55/2000, Val Acc=0.4946, Val Loss=1.9258, lr=0.0100
[2025-05-07 00:16:10,388][train][INFO] - Epoch 60/2000, Val Acc=0.4852, Val Loss=1.9174, lr=0.0100
[2025-05-07 00:16:10,762][train][INFO] - Epoch 64/2000, Val Acc=0.5206, Val Loss=1.8605, lr=0.0100
[2025-05-07 00:16:18,103][train][INFO] - Epoch 56/2000, Val Acc=0.5227, Val Loss=1.8318, lr=0.0100
[2025-05-07 00:16:18,274][train][INFO] - Epoch 61/2000, Val Acc=0.4817, Val Loss=1.9548, lr=0.0100
[2025-05-07 00:16:18,699][train][INFO] - Epoch 65/2000, Val Acc=0.5397, Val Loss=1.7639, lr=0.0100
[2025-05-07 00:16:25,614][train][INFO] - Epoch 57/2000, Val Acc=0.5483, Val Loss=1.6845, lr=0.0100
[2025-05-07 00:16:26,289][train][INFO] - Epoch 62/2000, Val Acc=0.4951, Val Loss=1.8690, lr=0.0100
[2025-05-07 00:16:26,378][train][INFO] - Epoch 66/2000, Val Acc=0.5289, Val Loss=1.8242, lr=0.0100
[2025-05-07 00:16:32,882][train][INFO] - Epoch 58/2000, Val Acc=0.5310, Val Loss=1.7666, lr=0.0100
[2025-05-07 00:16:33,836][train][INFO] - Epoch 63/2000, Val Acc=0.4847, Val Loss=1.9472, lr=0.0100
[2025-05-07 00:16:34,092][train][INFO] - Epoch 67/2000, Val Acc=0.5436, Val Loss=1.7413, lr=0.0100
[2025-05-07 00:16:40,733][train][INFO] - Epoch 59/2000, Val Acc=0.5432, Val Loss=1.6975, lr=0.0100
[2025-05-07 00:16:41,596][train][INFO] - Epoch 68/2000, Val Acc=0.5407, Val Loss=1.8012, lr=0.0100
[2025-05-07 00:16:41,652][train][INFO] - Epoch 64/2000, Val Acc=0.4675, Val Loss=2.0202, lr=0.0100
[2025-05-07 00:16:47,609][train][INFO] - Epoch 60/2000, Val Acc=0.5255, Val Loss=1.8257, lr=0.0100
[2025-05-07 00:16:48,804][train][INFO] - Epoch 65/2000, Val Acc=0.4851, Val Loss=1.9091, lr=0.0100
[2025-05-07 00:16:49,554][train][INFO] - Epoch 69/2000, Val Acc=0.5292, Val Loss=1.8061, lr=0.0100
[2025-05-07 00:16:55,071][train][INFO] - Epoch 61/2000, Val Acc=0.5370, Val Loss=1.7684, lr=0.0100
[2025-05-07 00:16:56,293][train][INFO] - Epoch 66/2000, Val Acc=0.4618, Val Loss=2.0335, lr=0.0100
[2025-05-07 00:16:57,516][train][INFO] - Epoch 70/2000, Val Acc=0.5447, Val Loss=1.7558, lr=0.0100
[2025-05-07 00:17:02,419][train][INFO] - Epoch 62/2000, Val Acc=0.5484, Val Loss=1.7137, lr=0.0100
[2025-05-07 00:17:03,842][train][INFO] - Epoch 67/2000, Val Acc=0.4906, Val Loss=1.8814, lr=0.0100
[2025-05-07 00:17:04,939][train][INFO] - Epoch 71/2000, Val Acc=0.5423, Val Loss=1.7597, lr=0.0100
[2025-05-07 00:17:09,902][train][INFO] - Epoch 63/2000, Val Acc=0.5138, Val Loss=1.9043, lr=0.0100
[2025-05-07 00:17:11,943][train][INFO] - Epoch 68/2000, Val Acc=0.4604, Val Loss=2.0673, lr=0.0100
[2025-05-07 00:17:12,792][train][INFO] - Epoch 72/2000, Val Acc=0.5411, Val Loss=1.7384, lr=0.0100
[2025-05-07 00:17:17,695][train][INFO] - Epoch 64/2000, Val Acc=0.5206, Val Loss=1.8605, lr=0.0100
[2025-05-07 00:17:19,223][train][INFO] - Epoch 69/2000, Val Acc=0.4841, Val Loss=1.9530, lr=0.0100
[2025-05-07 00:17:20,474][train][INFO] - Epoch 73/2000, Val Acc=0.5347, Val Loss=1.8039, lr=0.0100
[2025-05-07 00:17:25,191][train][INFO] - Epoch 65/2000, Val Acc=0.5397, Val Loss=1.7639, lr=0.0100
[2025-05-07 00:17:27,009][train][INFO] - Epoch 70/2000, Val Acc=0.4703, Val Loss=2.0000, lr=0.0100
[2025-05-07 00:17:28,448][train][INFO] - Epoch 74/2000, Val Acc=0.5588, Val Loss=1.6659, lr=0.0100
[2025-05-07 00:17:32,700][train][INFO] - Epoch 66/2000, Val Acc=0.5289, Val Loss=1.8242, lr=0.0100
[2025-05-07 00:17:35,033][train][INFO] - Epoch 71/2000, Val Acc=0.4920, Val Loss=1.9027, lr=0.0100
[2025-05-07 00:17:36,381][train][INFO] - Epoch 75/2000, Val Acc=0.5485, Val Loss=1.7181, lr=0.0100
[2025-05-07 00:17:40,190][train][INFO] - Epoch 67/2000, Val Acc=0.5436, Val Loss=1.7413, lr=0.0100
[2025-05-07 00:17:42,729][train][INFO] - Epoch 72/2000, Val Acc=0.5043, Val Loss=1.8364, lr=0.0100
[2025-05-07 00:17:43,975][train][INFO] - Epoch 76/2000, Val Acc=0.5494, Val Loss=1.7429, lr=0.0100
[2025-05-07 00:17:47,311][train][INFO] - Epoch 68/2000, Val Acc=0.5407, Val Loss=1.8012, lr=0.0100
[2025-05-07 00:17:50,959][train][INFO] - Epoch 73/2000, Val Acc=0.5180, Val Loss=1.7701, lr=0.0100
[2025-05-07 00:17:51,577][train][INFO] - Epoch 77/2000, Val Acc=0.5505, Val Loss=1.7615, lr=0.0100
[2025-05-07 00:17:54,618][train][INFO] - Epoch 69/2000, Val Acc=0.5292, Val Loss=1.8061, lr=0.0100
[2025-05-07 00:17:58,792][train][INFO] - Epoch 74/2000, Val Acc=0.5119, Val Loss=1.8150, lr=0.0100
[2025-05-07 00:17:59,094][train][INFO] - Epoch 78/2000, Val Acc=0.5644, Val Loss=1.6764, lr=0.0100
[2025-05-07 00:18:02,524][train][INFO] - Epoch 70/2000, Val Acc=0.5447, Val Loss=1.7558, lr=0.0100
[2025-05-07 00:18:06,006][train][INFO] - Epoch 75/2000, Val Acc=0.4922, Val Loss=1.9066, lr=0.0100
[2025-05-07 00:18:07,105][train][INFO] - Epoch 79/2000, Val Acc=0.5554, Val Loss=1.7095, lr=0.0100
[2025-05-07 00:18:10,328][train][INFO] - Epoch 71/2000, Val Acc=0.5423, Val Loss=1.7597, lr=0.0100
[2025-05-07 00:18:14,016][train][INFO] - Epoch 76/2000, Val Acc=0.4977, Val Loss=1.8507, lr=0.0100
[2025-05-07 00:18:15,369][train][INFO] - Epoch 80/2000, Val Acc=0.5494, Val Loss=1.7721, lr=0.0100
[2025-05-07 00:18:17,535][train][INFO] - Epoch 72/2000, Val Acc=0.5411, Val Loss=1.7384, lr=0.0100
[2025-05-07 00:18:21,886][train][INFO] - Epoch 77/2000, Val Acc=0.4741, Val Loss=2.0085, lr=0.0100
[2025-05-07 00:18:23,527][train][INFO] - Epoch 81/2000, Val Acc=0.5584, Val Loss=1.6949, lr=0.0100
[2025-05-07 00:18:24,992][train][INFO] - Epoch 73/2000, Val Acc=0.5347, Val Loss=1.8039, lr=0.0100
[2025-05-07 00:18:29,689][train][INFO] - Epoch 78/2000, Val Acc=0.5043, Val Loss=1.8025, lr=0.0100
[2025-05-07 00:18:31,357][train][INFO] - Epoch 82/2000, Val Acc=0.5579, Val Loss=1.7501, lr=0.0100
[2025-05-07 00:18:32,967][train][INFO] - Epoch 74/2000, Val Acc=0.5588, Val Loss=1.6659, lr=0.0100
[2025-05-07 00:18:37,221][train][INFO] - Epoch 79/2000, Val Acc=0.5084, Val Loss=1.8115, lr=0.0100
[2025-05-07 00:18:39,078][train][INFO] - Epoch 83/2000, Val Acc=0.5630, Val Loss=1.6769, lr=0.0100
[2025-05-07 00:18:40,471][train][INFO] - Epoch 75/2000, Val Acc=0.5485, Val Loss=1.7181, lr=0.0100
[2025-05-07 00:18:45,449][train][INFO] - Epoch 80/2000, Val Acc=0.4953, Val Loss=1.8749, lr=0.0100
[2025-05-07 00:18:47,122][train][INFO] - Epoch 84/2000, Val Acc=0.5478, Val Loss=1.7673, lr=0.0100
[2025-05-07 00:18:48,128][train][INFO] - Epoch 76/2000, Val Acc=0.5494, Val Loss=1.7429, lr=0.0100
[2025-05-07 00:18:52,448][train][INFO] - Epoch 81/2000, Val Acc=0.4922, Val Loss=1.9319, lr=0.0100
[2025-05-07 00:18:54,704][train][INFO] - Epoch 85/2000, Val Acc=0.5555, Val Loss=1.7396, lr=0.0100
[2025-05-07 00:18:55,622][train][INFO] - Epoch 77/2000, Val Acc=0.5505, Val Loss=1.7615, lr=0.0100
[2025-05-07 00:18:59,818][train][INFO] - Epoch 82/2000, Val Acc=0.4765, Val Loss=1.9813, lr=0.0100
[2025-05-07 00:19:02,333][train][INFO] - Epoch 86/2000, Val Acc=0.5642, Val Loss=1.7035, lr=0.0100
[2025-05-07 00:19:03,258][train][INFO] - Epoch 78/2000, Val Acc=0.5644, Val Loss=1.6764, lr=0.0100
[2025-05-07 00:19:07,781][train][INFO] - Epoch 83/2000, Val Acc=0.5042, Val Loss=1.8481, lr=0.0100
[2025-05-07 00:19:10,515][train][INFO] - Epoch 87/2000, Val Acc=0.5700, Val Loss=1.6445, lr=0.0100
[2025-05-07 00:19:11,092][train][INFO] - Epoch 79/2000, Val Acc=0.5554, Val Loss=1.7095, lr=0.0100
[2025-05-07 00:19:15,535][train][INFO] - Epoch 84/2000, Val Acc=0.4697, Val Loss=2.0555, lr=0.0100
[2025-05-07 00:19:18,417][train][INFO] - Epoch 88/2000, Val Acc=0.5511, Val Loss=1.7451, lr=0.0100
[2025-05-07 00:19:18,859][train][INFO] - Epoch 80/2000, Val Acc=0.5494, Val Loss=1.7721, lr=0.0100
[2025-05-07 00:19:22,743][train][INFO] - Epoch 85/2000, Val Acc=0.5033, Val Loss=1.8740, lr=0.0100
[2025-05-07 00:19:26,343][train][INFO] - Epoch 89/2000, Val Acc=0.5591, Val Loss=1.7089, lr=0.0100
[2025-05-07 00:19:26,537][train][INFO] - Epoch 81/2000, Val Acc=0.5584, Val Loss=1.6949, lr=0.0100
[2025-05-07 00:19:30,381][train][INFO] - Epoch 86/2000, Val Acc=0.5240, Val Loss=1.7878, lr=0.0100
[2025-05-07 00:19:33,770][train][INFO] - Epoch 82/2000, Val Acc=0.5579, Val Loss=1.7501, lr=0.0100
[2025-05-07 00:19:33,854][train][INFO] - Epoch 90/2000, Val Acc=0.5446, Val Loss=1.8036, lr=0.0100
[2025-05-07 00:19:37,945][train][INFO] - Epoch 87/2000, Val Acc=0.5076, Val Loss=1.8427, lr=0.0100
[2025-05-07 00:19:41,328][train][INFO] - Epoch 91/2000, Val Acc=0.5608, Val Loss=1.7395, lr=0.0100
[2025-05-07 00:19:41,463][train][INFO] - Epoch 83/2000, Val Acc=0.5630, Val Loss=1.6769, lr=0.0100
[2025-05-07 00:19:45,692][train][INFO] - Epoch 88/2000, Val Acc=0.5122, Val Loss=1.8085, lr=0.0100
[2025-05-07 00:19:49,203][train][INFO] - Epoch 84/2000, Val Acc=0.5478, Val Loss=1.7673, lr=0.0100
[2025-05-07 00:19:49,222][train][INFO] - Epoch 92/2000, Val Acc=0.5667, Val Loss=1.7199, lr=0.0100
[2025-05-07 00:19:53,252][train][INFO] - Epoch 89/2000, Val Acc=0.4785, Val Loss=1.9734, lr=0.0100
[2025-05-07 00:19:57,019][train][INFO] - Epoch 85/2000, Val Acc=0.5555, Val Loss=1.7396, lr=0.0100
[2025-05-07 00:19:57,237][train][INFO] - Epoch 93/2000, Val Acc=0.5705, Val Loss=1.6832, lr=0.0100
[2025-05-07 00:20:01,037][train][INFO] - Epoch 90/2000, Val Acc=0.5100, Val Loss=1.8395, lr=0.0100
[2025-05-07 00:20:04,665][train][INFO] - Epoch 86/2000, Val Acc=0.5642, Val Loss=1.7035, lr=0.0100
[2025-05-07 00:20:05,464][train][INFO] - Epoch 94/2000, Val Acc=0.5523, Val Loss=1.7805, lr=0.0100
[2025-05-07 00:20:08,424][train][INFO] - Epoch 91/2000, Val Acc=0.5114, Val Loss=1.8073, lr=0.0100
[2025-05-07 00:20:12,677][train][INFO] - Epoch 87/2000, Val Acc=0.5700, Val Loss=1.6445, lr=0.0100
[2025-05-07 00:20:12,898][train][INFO] - Epoch 95/2000, Val Acc=0.5816, Val Loss=1.6066, lr=0.0100
[2025-05-07 00:20:15,903][train][INFO] - Epoch 92/2000, Val Acc=0.5200, Val Loss=1.8167, lr=0.0100
[2025-05-07 00:20:20,579][train][INFO] - Epoch 88/2000, Val Acc=0.5511, Val Loss=1.7451, lr=0.0100
[2025-05-07 00:20:20,864][train][INFO] - Epoch 96/2000, Val Acc=0.5553, Val Loss=1.7286, lr=0.0100
[2025-05-07 00:20:23,455][train][INFO] - Epoch 93/2000, Val Acc=0.5092, Val Loss=1.8775, lr=0.0100
[2025-05-07 00:20:28,126][train][INFO] - Epoch 89/2000, Val Acc=0.5591, Val Loss=1.7089, lr=0.0100
[2025-05-07 00:20:28,438][train][INFO] - Epoch 97/2000, Val Acc=0.5355, Val Loss=1.8121, lr=0.0100
[2025-05-07 00:20:30,932][train][INFO] - Epoch 94/2000, Val Acc=0.5028, Val Loss=1.8438, lr=0.0100
[2025-05-07 00:20:35,527][train][INFO] - Epoch 90/2000, Val Acc=0.5446, Val Loss=1.8036, lr=0.0100
[2025-05-07 00:20:36,809][train][INFO] - Epoch 98/2000, Val Acc=0.5731, Val Loss=1.6512, lr=0.0100
[2025-05-07 00:20:38,578][train][INFO] - Epoch 95/2000, Val Acc=0.5231, Val Loss=1.8083, lr=0.0100
[2025-05-07 00:20:42,823][train][INFO] - Epoch 91/2000, Val Acc=0.5608, Val Loss=1.7395, lr=0.0100
[2025-05-07 00:20:44,490][train][INFO] - Epoch 99/2000, Val Acc=0.5532, Val Loss=1.7873, lr=0.0100
[2025-05-07 00:20:46,064][train][INFO] - Epoch 96/2000, Val Acc=0.5012, Val Loss=1.9046, lr=0.0100
[2025-05-07 00:20:50,267][train][INFO] - Epoch 92/2000, Val Acc=0.5667, Val Loss=1.7199, lr=0.0100
[2025-05-07 00:20:52,159][train][INFO] - Epoch 100/2000, Val Acc=0.5644, Val Loss=1.7555, lr=0.0100
[2025-05-07 00:20:53,391][train][INFO] - Epoch 97/2000, Val Acc=0.4889, Val Loss=1.9578, lr=0.0100
[2025-05-07 00:20:58,147][train][INFO] - Epoch 93/2000, Val Acc=0.5705, Val Loss=1.6832, lr=0.0100
[2025-05-07 00:21:00,205][train][INFO] - Epoch 101/2000, Val Acc=0.5729, Val Loss=1.6719, lr=0.0100
[2025-05-07 00:21:01,266][train][INFO] - Epoch 98/2000, Val Acc=0.5172, Val Loss=1.8085, lr=0.0100
[2025-05-07 00:21:05,071][train][INFO] - Epoch 94/2000, Val Acc=0.5523, Val Loss=1.7805, lr=0.0100
[2025-05-07 00:21:07,689][train][INFO] - Epoch 102/2000, Val Acc=0.5718, Val Loss=1.6451, lr=0.0100
[2025-05-07 00:21:08,999][train][INFO] - Epoch 99/2000, Val Acc=0.5287, Val Loss=1.7599, lr=0.0100
[2025-05-07 00:21:12,048][train][INFO] - Epoch 95/2000, Val Acc=0.5816, Val Loss=1.6066, lr=0.0100
[2025-05-07 00:21:14,987][train][INFO] - Epoch 103/2000, Val Acc=0.5497, Val Loss=1.8341, lr=0.0100
[2025-05-07 00:21:16,324][train][INFO] - Epoch 100/2000, Val Acc=0.5425, Val Loss=1.7336, lr=0.0100
[2025-05-07 00:21:19,065][train][INFO] - Epoch 96/2000, Val Acc=0.5553, Val Loss=1.7286, lr=0.0100
[2025-05-07 00:21:22,697][train][INFO] - Epoch 104/2000, Val Acc=0.5559, Val Loss=1.7912, lr=0.0100
[2025-05-07 00:21:24,043][train][INFO] - Epoch 101/2000, Val Acc=0.5082, Val Loss=1.9101, lr=0.0100
[2025-05-07 00:21:26,577][train][INFO] - Epoch 97/2000, Val Acc=0.5355, Val Loss=1.8121, lr=0.0100
[2025-05-07 00:21:30,505][train][INFO] - Epoch 105/2000, Val Acc=0.5433, Val Loss=1.8582, lr=0.0100
[2025-05-07 00:21:31,648][train][INFO] - Epoch 102/2000, Val Acc=0.5224, Val Loss=1.7819, lr=0.0100
[2025-05-07 00:21:34,331][train][INFO] - Epoch 98/2000, Val Acc=0.5731, Val Loss=1.6512, lr=0.0100
[2025-05-07 00:21:38,669][train][INFO] - Epoch 106/2000, Val Acc=0.5529, Val Loss=1.8171, lr=0.0100
[2025-05-07 00:21:39,456][train][INFO] - Epoch 103/2000, Val Acc=0.4926, Val Loss=1.9345, lr=0.0100
[2025-05-07 00:21:42,214][train][INFO] - Epoch 99/2000, Val Acc=0.5532, Val Loss=1.7873, lr=0.0100
[2025-05-07 00:21:46,626][train][INFO] - Epoch 107/2000, Val Acc=0.5697, Val Loss=1.7040, lr=0.0100
[2025-05-07 00:21:47,309][train][INFO] - Epoch 104/2000, Val Acc=0.4982, Val Loss=1.9280, lr=0.0100
[2025-05-07 00:21:50,307][train][INFO] - Epoch 100/2000, Val Acc=0.5644, Val Loss=1.7555, lr=0.0100
[2025-05-07 00:21:54,828][train][INFO] - Epoch 108/2000, Val Acc=0.5511, Val Loss=1.7933, lr=0.0100
[2025-05-07 00:21:55,087][train][INFO] - Epoch 105/2000, Val Acc=0.5047, Val Loss=1.9162, lr=0.0100
[2025-05-07 00:21:58,052][train][INFO] - Epoch 101/2000, Val Acc=0.5729, Val Loss=1.6719, lr=0.0100
[2025-05-07 00:22:02,663][train][INFO] - Epoch 109/2000, Val Acc=0.5889, Val Loss=1.6157, lr=0.0100
[2025-05-07 00:22:03,165][train][INFO] - Epoch 106/2000, Val Acc=0.5218, Val Loss=1.7847, lr=0.0100
[2025-05-07 00:22:05,858][train][INFO] - Epoch 102/2000, Val Acc=0.5718, Val Loss=1.6451, lr=0.0100
[2025-05-07 00:22:10,078][train][INFO] - Epoch 110/2000, Val Acc=0.5722, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:22:10,376][train][INFO] - Epoch 107/2000, Val Acc=0.5298, Val Loss=1.7856, lr=0.0100
[2025-05-07 00:22:13,674][train][INFO] - Epoch 103/2000, Val Acc=0.5497, Val Loss=1.8341, lr=0.0100
[2025-05-07 00:22:17,575][train][INFO] - Epoch 111/2000, Val Acc=0.5638, Val Loss=1.7267, lr=0.0100
[2025-05-07 00:22:17,793][train][INFO] - Epoch 108/2000, Val Acc=0.5118, Val Loss=1.9184, lr=0.0100
[2025-05-07 00:22:21,105][train][INFO] - Epoch 104/2000, Val Acc=0.5559, Val Loss=1.7912, lr=0.0100
[2025-05-07 00:22:25,472][train][INFO] - Epoch 112/2000, Val Acc=0.5715, Val Loss=1.6969, lr=0.0100
[2025-05-07 00:22:25,783][train][INFO] - Epoch 109/2000, Val Acc=0.5349, Val Loss=1.7524, lr=0.0100
[2025-05-07 00:22:28,789][train][INFO] - Epoch 105/2000, Val Acc=0.5433, Val Loss=1.8582, lr=0.0100
[2025-05-07 00:22:33,286][train][INFO] - Epoch 113/2000, Val Acc=0.5492, Val Loss=1.8090, lr=0.0100
[2025-05-07 00:22:33,500][train][INFO] - Epoch 110/2000, Val Acc=0.5247, Val Loss=1.7823, lr=0.0100
[2025-05-07 00:22:35,877][train][INFO] - Epoch 106/2000, Val Acc=0.5529, Val Loss=1.8171, lr=0.0100
[2025-05-07 00:22:41,452][train][INFO] - Epoch 114/2000, Val Acc=0.5788, Val Loss=1.6517, lr=0.0100
[2025-05-07 00:22:41,500][train][INFO] - Epoch 111/2000, Val Acc=0.5147, Val Loss=1.8618, lr=0.0100
[2025-05-07 00:22:43,550][train][INFO] - Epoch 107/2000, Val Acc=0.5697, Val Loss=1.7040, lr=0.0100
[2025-05-07 00:22:48,912][train][INFO] - Epoch 112/2000, Val Acc=0.5277, Val Loss=1.7669, lr=0.0100
[2025-05-07 00:22:49,246][train][INFO] - Epoch 115/2000, Val Acc=0.5315, Val Loss=2.0013, lr=0.0100
[2025-05-07 00:22:51,206][train][INFO] - Epoch 108/2000, Val Acc=0.5511, Val Loss=1.7933, lr=0.0100
[2025-05-07 00:22:56,753][train][INFO] - Epoch 116/2000, Val Acc=0.5789, Val Loss=1.6890, lr=0.0100
[2025-05-07 00:22:56,890][train][INFO] - Epoch 113/2000, Val Acc=0.5124, Val Loss=1.8903, lr=0.0100
[2025-05-07 00:22:59,031][train][INFO] - Epoch 109/2000, Val Acc=0.5889, Val Loss=1.6157, lr=0.0100
[2025-05-07 00:23:04,272][train][INFO] - Epoch 117/2000, Val Acc=0.5556, Val Loss=1.7749, lr=0.0100
[2025-05-07 00:23:04,424][train][INFO] - Epoch 114/2000, Val Acc=0.5437, Val Loss=1.7241, lr=0.0100
[2025-05-07 00:23:06,362][train][INFO] - Epoch 110/2000, Val Acc=0.5722, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:23:12,370][train][INFO] - Epoch 115/2000, Val Acc=0.5212, Val Loss=1.8286, lr=0.0100
[2025-05-07 00:23:12,538][train][INFO] - Epoch 118/2000, Val Acc=0.5685, Val Loss=1.6885, lr=0.0100
[2025-05-07 00:23:13,778][train][INFO] - Epoch 111/2000, Val Acc=0.5638, Val Loss=1.7267, lr=0.0100
[2025-05-07 00:23:20,114][train][INFO] - Epoch 116/2000, Val Acc=0.5319, Val Loss=1.7969, lr=0.0100
[2025-05-07 00:23:20,819][train][INFO] - Epoch 119/2000, Val Acc=0.5685, Val Loss=1.7046, lr=0.0100
[2025-05-07 00:23:21,545][train][INFO] - Epoch 112/2000, Val Acc=0.5715, Val Loss=1.6969, lr=0.0100
[2025-05-07 00:23:27,522][train][INFO] - Epoch 117/2000, Val Acc=0.4826, Val Loss=2.0501, lr=0.0100
[2025-05-07 00:23:28,528][train][INFO] - Epoch 120/2000, Val Acc=0.5727, Val Loss=1.6830, lr=0.0100
[2025-05-07 00:23:29,240][train][INFO] - Epoch 113/2000, Val Acc=0.5492, Val Loss=1.8090, lr=0.0100
[2025-05-07 00:23:34,957][train][INFO] - Epoch 118/2000, Val Acc=0.5087, Val Loss=1.9278, lr=0.0100
[2025-05-07 00:23:36,513][train][INFO] - Epoch 121/2000, Val Acc=0.5772, Val Loss=1.6937, lr=0.0100
[2025-05-07 00:23:36,761][train][INFO] - Epoch 114/2000, Val Acc=0.5788, Val Loss=1.6517, lr=0.0100
[2025-05-07 00:23:42,521][train][INFO] - Epoch 119/2000, Val Acc=0.5359, Val Loss=1.7309, lr=0.0100
[2025-05-07 00:23:43,614][train][INFO] - Epoch 115/2000, Val Acc=0.5315, Val Loss=2.0013, lr=0.0100
[2025-05-07 00:23:44,254][train][INFO] - Epoch 122/2000, Val Acc=0.5760, Val Loss=1.7129, lr=0.0100
[2025-05-07 00:23:50,129][train][INFO] - Epoch 120/2000, Val Acc=0.5186, Val Loss=1.8616, lr=0.0100
[2025-05-07 00:23:50,928][train][INFO] - Epoch 116/2000, Val Acc=0.5789, Val Loss=1.6890, lr=0.0100
[2025-05-07 00:23:52,465][train][INFO] - Epoch 123/2000, Val Acc=0.5561, Val Loss=1.8245, lr=0.0100
[2025-05-07 00:23:57,751][train][INFO] - Epoch 121/2000, Val Acc=0.5336, Val Loss=1.7683, lr=0.0100
[2025-05-07 00:23:58,067][train][INFO] - Epoch 117/2000, Val Acc=0.5556, Val Loss=1.7749, lr=0.0100
[2025-05-07 00:24:00,580][train][INFO] - Epoch 124/2000, Val Acc=0.5806, Val Loss=1.6674, lr=0.0100
[2025-05-07 00:24:04,925][train][INFO] - Epoch 122/2000, Val Acc=0.5425, Val Loss=1.7437, lr=0.0100
[2025-05-07 00:24:05,401][train][INFO] - Epoch 118/2000, Val Acc=0.5685, Val Loss=1.6885, lr=0.0100
[2025-05-07 00:24:08,774][train][INFO] - Epoch 125/2000, Val Acc=0.5767, Val Loss=1.6772, lr=0.0100
[2025-05-07 00:24:12,502][train][INFO] - Epoch 123/2000, Val Acc=0.5344, Val Loss=1.7430, lr=0.0100
[2025-05-07 00:24:12,920][train][INFO] - Epoch 119/2000, Val Acc=0.5685, Val Loss=1.7046, lr=0.0100
[2025-05-07 00:24:16,688][train][INFO] - Epoch 126/2000, Val Acc=0.5801, Val Loss=1.6702, lr=0.0100
[2025-05-07 00:24:19,534][train][INFO] - Epoch 124/2000, Val Acc=0.5455, Val Loss=1.6892, lr=0.0100
[2025-05-07 00:24:20,575][train][INFO] - Epoch 120/2000, Val Acc=0.5727, Val Loss=1.6830, lr=0.0100
[2025-05-07 00:24:24,181][train][INFO] - Epoch 127/2000, Val Acc=0.5693, Val Loss=1.7105, lr=0.0100
[2025-05-07 00:24:27,254][train][INFO] - Epoch 125/2000, Val Acc=0.5278, Val Loss=1.8202, lr=0.0100
[2025-05-07 00:24:27,856][train][INFO] - Epoch 121/2000, Val Acc=0.5772, Val Loss=1.6937, lr=0.0100
[2025-05-07 00:24:32,893][train][INFO] - Epoch 128/2000, Val Acc=0.5971, Val Loss=1.5847, lr=0.0100
[2025-05-07 00:24:35,058][train][INFO] - Epoch 126/2000, Val Acc=0.5472, Val Loss=1.7135, lr=0.0100
[2025-05-07 00:24:35,316][train][INFO] - Epoch 122/2000, Val Acc=0.5760, Val Loss=1.7129, lr=0.0100
[2025-05-07 00:24:41,221][train][INFO] - Epoch 129/2000, Val Acc=0.5693, Val Loss=1.7586, lr=0.0100
[2025-05-07 00:24:42,816][train][INFO] - Epoch 123/2000, Val Acc=0.5561, Val Loss=1.8245, lr=0.0100
[2025-05-07 00:24:42,926][train][INFO] - Epoch 127/2000, Val Acc=0.5342, Val Loss=1.8158, lr=0.0100
[2025-05-07 00:24:48,876][train][INFO] - Epoch 130/2000, Val Acc=0.5642, Val Loss=1.7329, lr=0.0100
[2025-05-07 00:24:49,766][train][INFO] - Epoch 124/2000, Val Acc=0.5806, Val Loss=1.6674, lr=0.0100
[2025-05-07 00:24:50,516][train][INFO] - Epoch 128/2000, Val Acc=0.5455, Val Loss=1.6891, lr=0.0100
[2025-05-07 00:24:56,470][train][INFO] - Epoch 125/2000, Val Acc=0.5767, Val Loss=1.6772, lr=0.0100
[2025-05-07 00:24:56,799][train][INFO] - Epoch 131/2000, Val Acc=0.5888, Val Loss=1.5982, lr=0.0100
[2025-05-07 00:24:58,424][train][INFO] - Epoch 129/2000, Val Acc=0.5266, Val Loss=1.8375, lr=0.0100
[2025-05-07 00:25:04,392][train][INFO] - Epoch 126/2000, Val Acc=0.5801, Val Loss=1.6702, lr=0.0100
[2025-05-07 00:25:04,799][train][INFO] - Epoch 132/2000, Val Acc=0.5704, Val Loss=1.7548, lr=0.0100
[2025-05-07 00:25:06,297][train][INFO] - Epoch 130/2000, Val Acc=0.5478, Val Loss=1.7236, lr=0.0100
[2025-05-07 00:25:11,972][train][INFO] - Epoch 127/2000, Val Acc=0.5693, Val Loss=1.7105, lr=0.0100
[2025-05-07 00:25:12,757][train][INFO] - Epoch 133/2000, Val Acc=0.5833, Val Loss=1.6911, lr=0.0100
[2025-05-07 00:25:13,713][train][INFO] - Epoch 131/2000, Val Acc=0.5390, Val Loss=1.7225, lr=0.0100
[2025-05-07 00:25:19,238][train][INFO] - Epoch 128/2000, Val Acc=0.5971, Val Loss=1.5847, lr=0.0100
[2025-05-07 00:25:20,820][train][INFO] - Epoch 134/2000, Val Acc=0.5920, Val Loss=1.6267, lr=0.0100
[2025-05-07 00:25:21,436][train][INFO] - Epoch 132/2000, Val Acc=0.5077, Val Loss=1.9948, lr=0.0100
[2025-05-07 00:25:27,030][train][INFO] - Epoch 129/2000, Val Acc=0.5693, Val Loss=1.7586, lr=0.0100
[2025-05-07 00:25:28,393][train][INFO] - Epoch 135/2000, Val Acc=0.5849, Val Loss=1.6750, lr=0.0100
[2025-05-07 00:25:29,281][train][INFO] - Epoch 133/2000, Val Acc=0.5444, Val Loss=1.7514, lr=0.0100
[2025-05-07 00:25:35,083][train][INFO] - Epoch 130/2000, Val Acc=0.5642, Val Loss=1.7329, lr=0.0100
[2025-05-07 00:25:36,054][train][INFO] - Epoch 136/2000, Val Acc=0.5678, Val Loss=1.8239, lr=0.0100
[2025-05-07 00:25:37,369][train][INFO] - Epoch 134/2000, Val Acc=0.5583, Val Loss=1.6682, lr=0.0100
[2025-05-07 00:25:43,090][train][INFO] - Epoch 131/2000, Val Acc=0.5888, Val Loss=1.5982, lr=0.0100
[2025-05-07 00:25:43,306][train][INFO] - Epoch 137/2000, Val Acc=0.5813, Val Loss=1.7123, lr=0.0100
[2025-05-07 00:25:45,009][train][INFO] - Epoch 135/2000, Val Acc=0.5236, Val Loss=1.8376, lr=0.0100
[2025-05-07 00:25:50,738][train][INFO] - Epoch 132/2000, Val Acc=0.5704, Val Loss=1.7548, lr=0.0100
[2025-05-07 00:25:51,140][train][INFO] - Epoch 138/2000, Val Acc=0.5813, Val Loss=1.6763, lr=0.0100
[2025-05-07 00:25:52,757][train][INFO] - Epoch 136/2000, Val Acc=0.5539, Val Loss=1.7011, lr=0.0100
[2025-05-07 00:25:58,559][train][INFO] - Epoch 133/2000, Val Acc=0.5833, Val Loss=1.6911, lr=0.0100
[2025-05-07 00:25:59,314][train][INFO] - Epoch 139/2000, Val Acc=0.5754, Val Loss=1.7068, lr=0.0100
[2025-05-07 00:25:59,904][train][INFO] - Epoch 137/2000, Val Acc=0.5368, Val Loss=1.7464, lr=0.0100
[2025-05-07 00:26:06,641][train][INFO] - Epoch 134/2000, Val Acc=0.5920, Val Loss=1.6267, lr=0.0100
[2025-05-07 00:26:07,295][train][INFO] - Epoch 140/2000, Val Acc=0.5585, Val Loss=1.7590, lr=0.0100
[2025-05-07 00:26:07,523][train][INFO] - Epoch 138/2000, Val Acc=0.5423, Val Loss=1.7404, lr=0.0100
[2025-05-07 00:26:14,119][train][INFO] - Epoch 135/2000, Val Acc=0.5849, Val Loss=1.6750, lr=0.0100
[2025-05-07 00:26:14,123][train][INFO] - Epoch 141/2000, Val Acc=0.5705, Val Loss=1.7103, lr=0.0100
[2025-05-07 00:26:15,330][train][INFO] - Epoch 139/2000, Val Acc=0.5467, Val Loss=1.7288, lr=0.0100
[2025-05-07 00:26:21,693][train][INFO] - Epoch 136/2000, Val Acc=0.5678, Val Loss=1.8239, lr=0.0100
[2025-05-07 00:26:22,151][train][INFO] - Epoch 142/2000, Val Acc=0.5881, Val Loss=1.6804, lr=0.0100
[2025-05-07 00:26:23,066][train][INFO] - Epoch 140/2000, Val Acc=0.5439, Val Loss=1.7588, lr=0.0100
[2025-05-07 00:26:29,434][train][INFO] - Epoch 143/2000, Val Acc=0.5722, Val Loss=1.6955, lr=0.0100
[2025-05-07 00:26:29,551][train][INFO] - Epoch 137/2000, Val Acc=0.5813, Val Loss=1.7123, lr=0.0100
[2025-05-07 00:26:30,423][train][INFO] - Epoch 141/2000, Val Acc=0.5499, Val Loss=1.7492, lr=0.0100
[2025-05-07 00:26:37,005][train][INFO] - Epoch 138/2000, Val Acc=0.5813, Val Loss=1.6763, lr=0.0100
[2025-05-07 00:26:37,641][train][INFO] - Epoch 144/2000, Val Acc=0.5641, Val Loss=1.8134, lr=0.0100
[2025-05-07 00:26:37,832][train][INFO] - Epoch 142/2000, Val Acc=0.5496, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:26:44,952][train][INFO] - Epoch 139/2000, Val Acc=0.5754, Val Loss=1.7068, lr=0.0100
[2025-05-07 00:26:45,240][train][INFO] - Epoch 143/2000, Val Acc=0.5423, Val Loss=1.7607, lr=0.0100
[2025-05-07 00:26:45,275][train][INFO] - Epoch 145/2000, Val Acc=0.5672, Val Loss=1.8049, lr=0.0100
[2025-05-07 00:26:52,614][train][INFO] - Epoch 140/2000, Val Acc=0.5585, Val Loss=1.7590, lr=0.0100
[2025-05-07 00:26:52,915][train][INFO] - Epoch 146/2000, Val Acc=0.5939, Val Loss=1.6280, lr=0.0100
[2025-05-07 00:26:53,454][train][INFO] - Epoch 144/2000, Val Acc=0.5472, Val Loss=1.7176, lr=0.0100
[2025-05-07 00:27:00,263][train][INFO] - Epoch 141/2000, Val Acc=0.5705, Val Loss=1.7103, lr=0.0100
[2025-05-07 00:27:00,610][train][INFO] - Epoch 147/2000, Val Acc=0.5844, Val Loss=1.6407, lr=0.0100
[2025-05-07 00:27:00,660][train][INFO] - Epoch 145/2000, Val Acc=0.5463, Val Loss=1.7642, lr=0.0100
[2025-05-07 00:27:07,833][train][INFO] - Epoch 142/2000, Val Acc=0.5881, Val Loss=1.6804, lr=0.0100
[2025-05-07 00:27:08,116][train][INFO] - Epoch 148/2000, Val Acc=0.5806, Val Loss=1.7284, lr=0.0100
[2025-05-07 00:27:08,204][train][INFO] - Epoch 146/2000, Val Acc=0.5394, Val Loss=1.7556, lr=0.0100
[2025-05-07 00:27:15,459][train][INFO] - Epoch 143/2000, Val Acc=0.5722, Val Loss=1.6955, lr=0.0100
[2025-05-07 00:27:16,055][train][INFO] - Epoch 147/2000, Val Acc=0.5501, Val Loss=1.7020, lr=0.0100
[2025-05-07 00:27:16,152][train][INFO] - Epoch 149/2000, Val Acc=0.5753, Val Loss=1.7136, lr=0.0100
[2025-05-07 00:27:22,770][train][INFO] - Epoch 144/2000, Val Acc=0.5641, Val Loss=1.8134, lr=0.0100
[2025-05-07 00:27:23,415][train][INFO] - Epoch 148/2000, Val Acc=0.5433, Val Loss=1.7485, lr=0.0100
[2025-05-07 00:27:24,196][train][INFO] - Epoch 150/2000, Val Acc=0.5683, Val Loss=1.7549, lr=0.0100
[2025-05-07 00:27:30,013][train][INFO] - Epoch 145/2000, Val Acc=0.5672, Val Loss=1.8049, lr=0.0100
[2025-05-07 00:27:31,144][train][INFO] - Epoch 149/2000, Val Acc=0.5251, Val Loss=1.8429, lr=0.0100
[2025-05-07 00:27:32,122][train][INFO] - Epoch 151/2000, Val Acc=0.5719, Val Loss=1.7402, lr=0.0100
[2025-05-07 00:27:37,898][train][INFO] - Epoch 146/2000, Val Acc=0.5939, Val Loss=1.6280, lr=0.0100
[2025-05-07 00:27:38,853][train][INFO] - Epoch 150/2000, Val Acc=0.5478, Val Loss=1.7353, lr=0.0100
[2025-05-07 00:27:40,089][train][INFO] - Epoch 152/2000, Val Acc=0.5986, Val Loss=1.5955, lr=0.0100
[2025-05-07 00:27:45,860][train][INFO] - Epoch 147/2000, Val Acc=0.5844, Val Loss=1.6407, lr=0.0100
[2025-05-07 00:27:46,573][train][INFO] - Epoch 151/2000, Val Acc=0.5376, Val Loss=1.7420, lr=0.0100
[2025-05-07 00:27:47,994][train][INFO] - Epoch 153/2000, Val Acc=0.5779, Val Loss=1.7350, lr=0.0100
[2025-05-07 00:27:53,506][train][INFO] - Epoch 148/2000, Val Acc=0.5806, Val Loss=1.7284, lr=0.0100
[2025-05-07 00:27:54,605][train][INFO] - Epoch 152/2000, Val Acc=0.5479, Val Loss=1.7527, lr=0.0100
[2025-05-07 00:27:55,796][train][INFO] - Epoch 154/2000, Val Acc=0.5781, Val Loss=1.7134, lr=0.0100
[2025-05-07 00:28:01,139][train][INFO] - Epoch 149/2000, Val Acc=0.5753, Val Loss=1.7136, lr=0.0100
[2025-05-07 00:28:02,329][train][INFO] - Epoch 153/2000, Val Acc=0.5608, Val Loss=1.6428, lr=0.0100
[2025-05-07 00:28:03,824][train][INFO] - Epoch 155/2000, Val Acc=0.5618, Val Loss=1.8122, lr=0.0100
[2025-05-07 00:28:08,695][train][INFO] - Epoch 150/2000, Val Acc=0.5683, Val Loss=1.7549, lr=0.0100
[2025-05-07 00:28:09,915][train][INFO] - Epoch 154/2000, Val Acc=0.5202, Val Loss=1.9258, lr=0.0100
[2025-05-07 00:28:11,247][train][INFO] - Epoch 156/2000, Val Acc=0.5821, Val Loss=1.7146, lr=0.0100
[2025-05-07 00:28:16,513][train][INFO] - Epoch 151/2000, Val Acc=0.5719, Val Loss=1.7402, lr=0.0100
[2025-05-07 00:28:17,398][train][INFO] - Epoch 155/2000, Val Acc=0.5428, Val Loss=1.7418, lr=0.0100
[2025-05-07 00:28:19,362][train][INFO] - Epoch 157/2000, Val Acc=0.5774, Val Loss=1.7146, lr=0.0100
[2025-05-07 00:28:24,222][train][INFO] - Epoch 152/2000, Val Acc=0.5986, Val Loss=1.5955, lr=0.0100
[2025-05-07 00:28:24,825][train][INFO] - Epoch 156/2000, Val Acc=0.5243, Val Loss=1.9046, lr=0.0100
[2025-05-07 00:28:27,306][train][INFO] - Epoch 158/2000, Val Acc=0.5859, Val Loss=1.6929, lr=0.0100
[2025-05-07 00:28:31,985][train][INFO] - Epoch 153/2000, Val Acc=0.5779, Val Loss=1.7350, lr=0.0100
[2025-05-07 00:28:32,278][train][INFO] - Epoch 157/2000, Val Acc=0.5604, Val Loss=1.6319, lr=0.0100
[2025-05-07 00:28:35,315][train][INFO] - Epoch 159/2000, Val Acc=0.5760, Val Loss=1.7617, lr=0.0100
[2025-05-07 00:28:39,710][train][INFO] - Epoch 154/2000, Val Acc=0.5781, Val Loss=1.7134, lr=0.0100
[2025-05-07 00:28:39,935][train][INFO] - Epoch 158/2000, Val Acc=0.5602, Val Loss=1.6728, lr=0.0100
[2025-05-07 00:28:42,978][train][INFO] - Epoch 160/2000, Val Acc=0.5796, Val Loss=1.6824, lr=0.0100
[2025-05-07 00:28:47,534][train][INFO] - Epoch 155/2000, Val Acc=0.5618, Val Loss=1.8122, lr=0.0100
[2025-05-07 00:28:47,699][train][INFO] - Epoch 159/2000, Val Acc=0.5336, Val Loss=1.8369, lr=0.0100
[2025-05-07 00:28:50,623][train][INFO] - Epoch 161/2000, Val Acc=0.5749, Val Loss=1.7797, lr=0.0100
[2025-05-07 00:28:54,977][train][INFO] - Epoch 156/2000, Val Acc=0.5821, Val Loss=1.7146, lr=0.0100
[2025-05-07 00:28:55,614][train][INFO] - Epoch 160/2000, Val Acc=0.5529, Val Loss=1.6946, lr=0.0100
[2025-05-07 00:28:58,402][train][INFO] - Epoch 162/2000, Val Acc=0.5876, Val Loss=1.6939, lr=0.0100
[2025-05-07 00:29:02,277][train][INFO] - Epoch 157/2000, Val Acc=0.5774, Val Loss=1.7146, lr=0.0100
[2025-05-07 00:29:03,429][train][INFO] - Epoch 161/2000, Val Acc=0.5639, Val Loss=1.6545, lr=0.0100
[2025-05-07 00:29:05,874][train][INFO] - Epoch 163/2000, Val Acc=0.5831, Val Loss=1.6790, lr=0.0100
[2025-05-07 00:29:09,694][train][INFO] - Epoch 158/2000, Val Acc=0.5859, Val Loss=1.6929, lr=0.0100
[2025-05-07 00:29:11,010][train][INFO] - Epoch 162/2000, Val Acc=0.5655, Val Loss=1.6597, lr=0.0100
[2025-05-07 00:29:13,635][train][INFO] - Epoch 164/2000, Val Acc=0.5655, Val Loss=1.7630, lr=0.0100
[2025-05-07 00:29:17,285][train][INFO] - Epoch 159/2000, Val Acc=0.5760, Val Loss=1.7617, lr=0.0100
[2025-05-07 00:29:18,112][train][INFO] - Epoch 163/2000, Val Acc=0.5564, Val Loss=1.6935, lr=0.0100
[2025-05-07 00:29:20,954][train][INFO] - Epoch 165/2000, Val Acc=0.5928, Val Loss=1.6678, lr=0.0100
[2025-05-07 00:29:25,016][train][INFO] - Epoch 160/2000, Val Acc=0.5796, Val Loss=1.6824, lr=0.0100
[2025-05-07 00:29:25,459][train][INFO] - Epoch 164/2000, Val Acc=0.5498, Val Loss=1.7212, lr=0.0100
[2025-05-07 00:29:28,711][train][INFO] - Epoch 166/2000, Val Acc=0.5840, Val Loss=1.7074, lr=0.0100
[2025-05-07 00:29:32,385][train][INFO] - Epoch 161/2000, Val Acc=0.5749, Val Loss=1.7797, lr=0.0100
[2025-05-07 00:29:33,130][train][INFO] - Epoch 165/2000, Val Acc=0.5591, Val Loss=1.7072, lr=0.0100
[2025-05-07 00:29:36,492][train][INFO] - Epoch 167/2000, Val Acc=0.5856, Val Loss=1.6994, lr=0.0100
[2025-05-07 00:29:40,159][train][INFO] - Epoch 162/2000, Val Acc=0.5876, Val Loss=1.6939, lr=0.0100
[2025-05-07 00:29:41,255][train][INFO] - Epoch 166/2000, Val Acc=0.5499, Val Loss=1.7226, lr=0.0100
[2025-05-07 00:29:43,908][train][INFO] - Epoch 168/2000, Val Acc=0.5818, Val Loss=1.6987, lr=0.0100
[2025-05-07 00:29:47,309][train][INFO] - Epoch 163/2000, Val Acc=0.5831, Val Loss=1.6790, lr=0.0100
[2025-05-07 00:29:49,113][train][INFO] - Epoch 167/2000, Val Acc=0.5484, Val Loss=1.7816, lr=0.0100
[2025-05-07 00:29:52,078][train][INFO] - Epoch 169/2000, Val Acc=0.5771, Val Loss=1.7894, lr=0.0100
[2025-05-07 00:29:55,107][train][INFO] - Epoch 164/2000, Val Acc=0.5655, Val Loss=1.7630, lr=0.0100
[2025-05-07 00:29:56,870][train][INFO] - Epoch 168/2000, Val Acc=0.5143, Val Loss=1.9653, lr=0.0100
[2025-05-07 00:29:59,793][train][INFO] - Epoch 170/2000, Val Acc=0.5893, Val Loss=1.6844, lr=0.0100
[2025-05-07 00:30:02,942][train][INFO] - Epoch 165/2000, Val Acc=0.5928, Val Loss=1.6678, lr=0.0100
[2025-05-07 00:30:04,888][train][INFO] - Epoch 169/2000, Val Acc=0.5543, Val Loss=1.7039, lr=0.0100
[2025-05-07 00:30:07,628][train][INFO] - Epoch 171/2000, Val Acc=0.5917, Val Loss=1.7119, lr=0.0100
[2025-05-07 00:30:10,869][train][INFO] - Epoch 166/2000, Val Acc=0.5840, Val Loss=1.7074, lr=0.0100
[2025-05-07 00:30:12,558][train][INFO] - Epoch 170/2000, Val Acc=0.5510, Val Loss=1.7033, lr=0.0100
[2025-05-07 00:30:15,612][train][INFO] - Epoch 172/2000, Val Acc=0.6002, Val Loss=1.6242, lr=0.0100
[2025-05-07 00:30:18,048][train][INFO] - Epoch 167/2000, Val Acc=0.5856, Val Loss=1.6994, lr=0.0100
[2025-05-07 00:30:20,035][train][INFO] - Epoch 171/2000, Val Acc=0.5467, Val Loss=1.7282, lr=0.0100
[2025-05-07 00:30:22,788][train][INFO] - Epoch 173/2000, Val Acc=0.5949, Val Loss=1.6785, lr=0.0100
[2025-05-07 00:30:25,952][train][INFO] - Epoch 168/2000, Val Acc=0.5818, Val Loss=1.6987, lr=0.0100
[2025-05-07 00:30:28,109][train][INFO] - Epoch 172/2000, Val Acc=0.5588, Val Loss=1.6982, lr=0.0100
[2025-05-07 00:30:30,778][train][INFO] - Epoch 174/2000, Val Acc=0.5977, Val Loss=1.6200, lr=0.0100
[2025-05-07 00:30:33,500][train][INFO] - Epoch 169/2000, Val Acc=0.5771, Val Loss=1.7894, lr=0.0100
[2025-05-07 00:30:35,691][train][INFO] - Epoch 173/2000, Val Acc=0.5474, Val Loss=1.7529, lr=0.0100
[2025-05-07 00:30:38,717][train][INFO] - Epoch 175/2000, Val Acc=0.5878, Val Loss=1.7075, lr=0.0100
[2025-05-07 00:30:41,108][train][INFO] - Epoch 170/2000, Val Acc=0.5893, Val Loss=1.6844, lr=0.0100
[2025-05-07 00:30:42,956][train][INFO] - Epoch 174/2000, Val Acc=0.5545, Val Loss=1.7198, lr=0.0100
[2025-05-07 00:30:46,557][train][INFO] - Epoch 176/2000, Val Acc=0.6044, Val Loss=1.6302, lr=0.0100
[2025-05-07 00:30:48,773][train][INFO] - Epoch 171/2000, Val Acc=0.5917, Val Loss=1.7119, lr=0.0100
[2025-05-07 00:30:51,054][train][INFO] - Epoch 175/2000, Val Acc=0.5433, Val Loss=1.7722, lr=0.0100
[2025-05-07 00:30:54,118][train][INFO] - Epoch 177/2000, Val Acc=0.5753, Val Loss=1.7671, lr=0.0100
[2025-05-07 00:30:56,476][train][INFO] - Epoch 172/2000, Val Acc=0.6002, Val Loss=1.6242, lr=0.0100
[2025-05-07 00:30:58,633][train][INFO] - Epoch 176/2000, Val Acc=0.5450, Val Loss=1.8163, lr=0.0100
[2025-05-07 00:31:02,181][train][INFO] - Epoch 178/2000, Val Acc=0.5955, Val Loss=1.6476, lr=0.0100
[2025-05-07 00:31:03,819][train][INFO] - Epoch 173/2000, Val Acc=0.5949, Val Loss=1.6785, lr=0.0100
[2025-05-07 00:31:06,244][train][INFO] - Epoch 177/2000, Val Acc=0.5507, Val Loss=1.7646, lr=0.0100
[2025-05-07 00:31:10,112][train][INFO] - Epoch 179/2000, Val Acc=0.5881, Val Loss=1.6708, lr=0.0100
[2025-05-07 00:31:11,293][train][INFO] - Epoch 174/2000, Val Acc=0.5977, Val Loss=1.6200, lr=0.0100
[2025-05-07 00:31:13,566][train][INFO] - Epoch 178/2000, Val Acc=0.5595, Val Loss=1.7271, lr=0.0100
[2025-05-07 00:31:17,836][train][INFO] - Epoch 180/2000, Val Acc=0.5785, Val Loss=1.7247, lr=0.0100
[2025-05-07 00:31:19,265][train][INFO] - Epoch 175/2000, Val Acc=0.5878, Val Loss=1.7075, lr=0.0100
[2025-05-07 00:31:21,552][train][INFO] - Epoch 179/2000, Val Acc=0.5569, Val Loss=1.7150, lr=0.0100
[2025-05-07 00:31:25,589][train][INFO] - Epoch 181/2000, Val Acc=0.6004, Val Loss=1.6493, lr=0.0100
[2025-05-07 00:31:26,899][train][INFO] - Epoch 176/2000, Val Acc=0.6044, Val Loss=1.6302, lr=0.0100
[2025-05-07 00:31:29,400][train][INFO] - Epoch 180/2000, Val Acc=0.5590, Val Loss=1.6816, lr=0.0100
[2025-05-07 00:31:33,344][train][INFO] - Epoch 182/2000, Val Acc=0.6064, Val Loss=1.5737, lr=0.0100
[2025-05-07 00:31:34,167][train][INFO] - Epoch 177/2000, Val Acc=0.5753, Val Loss=1.7671, lr=0.0100
[2025-05-07 00:31:37,291][train][INFO] - Epoch 181/2000, Val Acc=0.5497, Val Loss=1.7861, lr=0.0100
[2025-05-07 00:31:41,306][train][INFO] - Epoch 183/2000, Val Acc=0.5812, Val Loss=1.7237, lr=0.0100
[2025-05-07 00:31:42,060][train][INFO] - Epoch 178/2000, Val Acc=0.5955, Val Loss=1.6476, lr=0.0100
[2025-05-07 00:31:44,804][train][INFO] - Epoch 182/2000, Val Acc=0.5563, Val Loss=1.7084, lr=0.0100
[2025-05-07 00:31:49,612][train][INFO] - Epoch 184/2000, Val Acc=0.5756, Val Loss=1.7898, lr=0.0100
[2025-05-07 00:31:49,825][train][INFO] - Epoch 179/2000, Val Acc=0.5881, Val Loss=1.6708, lr=0.0100
[2025-05-07 00:31:52,242][train][INFO] - Epoch 183/2000, Val Acc=0.5499, Val Loss=1.7279, lr=0.0100
[2025-05-07 00:31:57,531][train][INFO] - Epoch 180/2000, Val Acc=0.5785, Val Loss=1.7247, lr=0.0100
[2025-05-07 00:31:57,638][train][INFO] - Epoch 185/2000, Val Acc=0.5890, Val Loss=1.6941, lr=0.0100
[2025-05-07 00:32:00,066][train][INFO] - Epoch 184/2000, Val Acc=0.5391, Val Loss=1.7930, lr=0.0100
[2025-05-07 00:32:04,980][train][INFO] - Epoch 181/2000, Val Acc=0.6004, Val Loss=1.6493, lr=0.0100
[2025-05-07 00:32:05,446][train][INFO] - Epoch 186/2000, Val Acc=0.5882, Val Loss=1.7105, lr=0.0100
[2025-05-07 00:32:07,770][train][INFO] - Epoch 185/2000, Val Acc=0.5573, Val Loss=1.7018, lr=0.0100
[2025-05-07 00:32:12,635][train][INFO] - Epoch 182/2000, Val Acc=0.6064, Val Loss=1.5737, lr=0.0100
[2025-05-07 00:32:13,291][train][INFO] - Epoch 187/2000, Val Acc=0.5803, Val Loss=1.7462, lr=0.0100
[2025-05-07 00:32:14,910][train][INFO] - Epoch 186/2000, Val Acc=0.5432, Val Loss=1.7435, lr=0.0100
[2025-05-07 00:32:20,468][train][INFO] - Epoch 183/2000, Val Acc=0.5812, Val Loss=1.7237, lr=0.0100
[2025-05-07 00:32:20,934][train][INFO] - Epoch 188/2000, Val Acc=0.5965, Val Loss=1.6532, lr=0.0100
[2025-05-07 00:32:22,295][train][INFO] - Epoch 187/2000, Val Acc=0.5608, Val Loss=1.6706, lr=0.0100
[2025-05-07 00:32:27,602][train][INFO] - Epoch 184/2000, Val Acc=0.5756, Val Loss=1.7898, lr=0.0100
[2025-05-07 00:32:28,674][train][INFO] - Epoch 189/2000, Val Acc=0.6022, Val Loss=1.6301, lr=0.0100
[2025-05-07 00:32:29,956][train][INFO] - Epoch 188/2000, Val Acc=0.5633, Val Loss=1.6739, lr=0.0100
[2025-05-07 00:32:35,632][train][INFO] - Epoch 185/2000, Val Acc=0.5890, Val Loss=1.6941, lr=0.0100
[2025-05-07 00:32:36,755][train][INFO] - Epoch 190/2000, Val Acc=0.5860, Val Loss=1.7124, lr=0.0100
[2025-05-07 00:32:37,780][train][INFO] - Epoch 189/2000, Val Acc=0.5663, Val Loss=1.6866, lr=0.0100
[2025-05-07 00:32:43,295][train][INFO] - Epoch 186/2000, Val Acc=0.5882, Val Loss=1.7105, lr=0.0100
[2025-05-07 00:32:44,626][train][INFO] - Epoch 191/2000, Val Acc=0.5864, Val Loss=1.6944, lr=0.0100
[2025-05-07 00:32:45,636][train][INFO] - Epoch 190/2000, Val Acc=0.5527, Val Loss=1.7688, lr=0.0100
[2025-05-07 00:32:50,588][train][INFO] - Epoch 187/2000, Val Acc=0.5803, Val Loss=1.7462, lr=0.0100
[2025-05-07 00:32:52,407][train][INFO] - Epoch 192/2000, Val Acc=0.5949, Val Loss=1.6718, lr=0.0100
[2025-05-07 00:32:53,201][train][INFO] - Epoch 191/2000, Val Acc=0.5546, Val Loss=1.7603, lr=0.0100
[2025-05-07 00:32:58,186][train][INFO] - Epoch 188/2000, Val Acc=0.5965, Val Loss=1.6532, lr=0.0100
[2025-05-07 00:32:59,808][train][INFO] - Epoch 193/2000, Val Acc=0.5800, Val Loss=1.7337, lr=0.0100
[2025-05-07 00:33:01,159][train][INFO] - Epoch 192/2000, Val Acc=0.5660, Val Loss=1.6906, lr=0.0100
[2025-05-07 00:33:05,745][train][INFO] - Epoch 189/2000, Val Acc=0.6022, Val Loss=1.6301, lr=0.0100
[2025-05-07 00:33:07,193][train][INFO] - Epoch 194/2000, Val Acc=0.5829, Val Loss=1.7870, lr=0.0100
[2025-05-07 00:33:09,194][train][INFO] - Epoch 193/2000, Val Acc=0.5557, Val Loss=1.7227, lr=0.0100
[2025-05-07 00:33:13,381][train][INFO] - Epoch 190/2000, Val Acc=0.5860, Val Loss=1.7124, lr=0.0100
[2025-05-07 00:33:15,305][train][INFO] - Epoch 195/2000, Val Acc=0.5834, Val Loss=1.7608, lr=0.0100
[2025-05-07 00:33:17,196][train][INFO] - Epoch 194/2000, Val Acc=0.5451, Val Loss=1.8100, lr=0.0100
[2025-05-07 00:33:21,154][train][INFO] - Epoch 191/2000, Val Acc=0.5864, Val Loss=1.6944, lr=0.0100
[2025-05-07 00:33:23,050][train][INFO] - Epoch 196/2000, Val Acc=0.5806, Val Loss=1.7555, lr=0.0100
[2025-05-07 00:33:24,334][train][INFO] - Epoch 195/2000, Val Acc=0.5508, Val Loss=1.7626, lr=0.0100
[2025-05-07 00:33:29,099][train][INFO] - Epoch 192/2000, Val Acc=0.5949, Val Loss=1.6718, lr=0.0100
[2025-05-07 00:33:30,763][train][INFO] - Epoch 197/2000, Val Acc=0.5963, Val Loss=1.7063, lr=0.0100
[2025-05-07 00:33:31,906][train][INFO] - Epoch 196/2000, Val Acc=0.5854, Val Loss=1.5953, lr=0.0100
[2025-05-07 00:33:36,998][train][INFO] - Epoch 193/2000, Val Acc=0.5800, Val Loss=1.7337, lr=0.0100
[2025-05-07 00:33:38,656][train][INFO] - Epoch 198/2000, Val Acc=0.5952, Val Loss=1.6743, lr=0.0100
[2025-05-07 00:33:39,308][train][INFO] - Epoch 197/2000, Val Acc=0.5327, Val Loss=1.8455, lr=0.0100
[2025-05-07 00:33:44,616][train][INFO] - Epoch 194/2000, Val Acc=0.5829, Val Loss=1.7870, lr=0.0100
[2025-05-07 00:33:46,512][train][INFO] - Epoch 199/2000, Val Acc=0.5801, Val Loss=1.8152, lr=0.0100
[2025-05-07 00:33:47,186][train][INFO] - Epoch 198/2000, Val Acc=0.5485, Val Loss=1.7349, lr=0.0100
[2025-05-07 00:33:51,906][train][INFO] - Epoch 195/2000, Val Acc=0.5834, Val Loss=1.7608, lr=0.0100
[2025-05-07 00:33:53,832][train][INFO] - Epoch 200/2000, Val Acc=0.5917, Val Loss=1.7271, lr=0.0100
[2025-05-07 00:33:54,674][train][INFO] - Epoch 199/2000, Val Acc=0.5558, Val Loss=1.7272, lr=0.0100
[2025-05-07 00:33:59,574][train][INFO] - Epoch 196/2000, Val Acc=0.5806, Val Loss=1.7555, lr=0.0100
[2025-05-07 00:34:01,641][train][INFO] - Epoch 201/2000, Val Acc=0.5835, Val Loss=1.7460, lr=0.0100
[2025-05-07 00:34:01,951][train][INFO] - Epoch 200/2000, Val Acc=0.5588, Val Loss=1.7409, lr=0.0100
[2025-05-07 00:34:07,624][train][INFO] - Epoch 197/2000, Val Acc=0.5963, Val Loss=1.7063, lr=0.0100
[2025-05-07 00:34:09,554][train][INFO] - Epoch 202/2000, Val Acc=0.5993, Val Loss=1.6595, lr=0.0100
[2025-05-07 00:34:09,617][train][INFO] - Epoch 201/2000, Val Acc=0.5665, Val Loss=1.6680, lr=0.0100
[2025-05-07 00:34:14,975][train][INFO] - Epoch 198/2000, Val Acc=0.5952, Val Loss=1.6743, lr=0.0100
[2025-05-07 00:34:17,459][train][INFO] - Epoch 202/2000, Val Acc=0.5531, Val Loss=1.7750, lr=0.0100
[2025-05-07 00:34:17,583][train][INFO] - Epoch 203/2000, Val Acc=0.5895, Val Loss=1.7272, lr=0.0100
[2025-05-07 00:34:22,497][train][INFO] - Epoch 199/2000, Val Acc=0.5801, Val Loss=1.8152, lr=0.0100
[2025-05-07 00:34:25,350][train][INFO] - Epoch 203/2000, Val Acc=0.5367, Val Loss=1.8547, lr=0.0100
[2025-05-07 00:34:25,733][train][INFO] - Epoch 204/2000, Val Acc=0.5980, Val Loss=1.6450, lr=0.0100
[2025-05-07 00:34:30,187][train][INFO] - Epoch 200/2000, Val Acc=0.5917, Val Loss=1.7271, lr=0.0100
[2025-05-07 00:34:32,967][train][INFO] - Epoch 204/2000, Val Acc=0.5485, Val Loss=1.8036, lr=0.0100
[2025-05-07 00:34:33,366][train][INFO] - Epoch 205/2000, Val Acc=0.5869, Val Loss=1.7053, lr=0.0100
[2025-05-07 00:34:37,714][train][INFO] - Epoch 201/2000, Val Acc=0.5835, Val Loss=1.7460, lr=0.0100
[2025-05-07 00:34:40,574][train][INFO] - Epoch 205/2000, Val Acc=0.5757, Val Loss=1.6391, lr=0.0100
[2025-05-07 00:34:41,130][train][INFO] - Epoch 206/2000, Val Acc=0.5866, Val Loss=1.7019, lr=0.0100
[2025-05-07 00:34:45,180][train][INFO] - Epoch 202/2000, Val Acc=0.5993, Val Loss=1.6595, lr=0.0100
[2025-05-07 00:34:48,228][train][INFO] - Epoch 206/2000, Val Acc=0.5494, Val Loss=1.7334, lr=0.0100
[2025-05-07 00:34:48,986][train][INFO] - Epoch 207/2000, Val Acc=0.5767, Val Loss=1.8426, lr=0.0100
[2025-05-07 00:34:52,672][train][INFO] - Epoch 203/2000, Val Acc=0.5895, Val Loss=1.7272, lr=0.0100
[2025-05-07 00:34:55,491][train][INFO] - Epoch 207/2000, Val Acc=0.5605, Val Loss=1.7072, lr=0.0100
[2025-05-07 00:34:56,872][train][INFO] - Epoch 208/2000, Val Acc=0.5931, Val Loss=1.6797, lr=0.0100
[2025-05-07 00:35:00,398][train][INFO] - Epoch 204/2000, Val Acc=0.5980, Val Loss=1.6450, lr=0.0100
[2025-05-07 00:35:03,051][train][INFO] - Epoch 208/2000, Val Acc=0.5610, Val Loss=1.7191, lr=0.0100
[2025-05-07 00:35:04,795][train][INFO] - Epoch 209/2000, Val Acc=0.6000, Val Loss=1.6522, lr=0.0100
[2025-05-07 00:35:08,099][train][INFO] - Epoch 205/2000, Val Acc=0.5869, Val Loss=1.7053, lr=0.0100
[2025-05-07 00:35:10,734][train][INFO] - Epoch 209/2000, Val Acc=0.5650, Val Loss=1.7081, lr=0.0100
[2025-05-07 00:35:12,721][train][INFO] - Epoch 210/2000, Val Acc=0.5764, Val Loss=1.8207, lr=0.0100
[2025-05-07 00:35:16,023][train][INFO] - Epoch 206/2000, Val Acc=0.5866, Val Loss=1.7019, lr=0.0100
[2025-05-07 00:35:18,507][train][INFO] - Epoch 210/2000, Val Acc=0.5589, Val Loss=1.7909, lr=0.0100
[2025-05-07 00:35:19,955][train][INFO] - Epoch 211/2000, Val Acc=0.5984, Val Loss=1.6699, lr=0.0100
[2025-05-07 00:35:23,807][train][INFO] - Epoch 207/2000, Val Acc=0.5767, Val Loss=1.8426, lr=0.0100
[2025-05-07 00:35:26,297][train][INFO] - Epoch 211/2000, Val Acc=0.5693, Val Loss=1.6562, lr=0.0100
[2025-05-07 00:35:27,573][train][INFO] - Epoch 212/2000, Val Acc=0.5849, Val Loss=1.7546, lr=0.0100
[2025-05-07 00:35:31,784][train][INFO] - Epoch 208/2000, Val Acc=0.5931, Val Loss=1.6797, lr=0.0100
[2025-05-07 00:35:33,877][train][INFO] - Epoch 212/2000, Val Acc=0.5691, Val Loss=1.6355, lr=0.0100
[2025-05-07 00:35:35,653][train][INFO] - Epoch 213/2000, Val Acc=0.5986, Val Loss=1.6548, lr=0.0100
[2025-05-07 00:35:38,978][train][INFO] - Epoch 209/2000, Val Acc=0.6000, Val Loss=1.6522, lr=0.0100
[2025-05-07 00:35:41,836][train][INFO] - Epoch 213/2000, Val Acc=0.5326, Val Loss=1.8563, lr=0.0100
[2025-05-07 00:35:43,625][train][INFO] - Epoch 214/2000, Val Acc=0.5974, Val Loss=1.6715, lr=0.0100
[2025-05-07 00:35:46,750][train][INFO] - Epoch 210/2000, Val Acc=0.5764, Val Loss=1.8207, lr=0.0100
[2025-05-07 00:35:49,560][train][INFO] - Epoch 214/2000, Val Acc=0.5733, Val Loss=1.6359, lr=0.0100
[2025-05-07 00:35:51,589][train][INFO] - Epoch 215/2000, Val Acc=0.5933, Val Loss=1.7128, lr=0.0100
[2025-05-07 00:35:54,408][train][INFO] - Epoch 211/2000, Val Acc=0.5984, Val Loss=1.6699, lr=0.0100
[2025-05-07 00:35:57,423][train][INFO] - Epoch 215/2000, Val Acc=0.5507, Val Loss=1.7909, lr=0.0100
[2025-05-07 00:35:59,491][train][INFO] - Epoch 216/2000, Val Acc=0.5958, Val Loss=1.6623, lr=0.0100
[2025-05-07 00:36:01,946][train][INFO] - Epoch 212/2000, Val Acc=0.5849, Val Loss=1.7546, lr=0.0100
[2025-05-07 00:36:04,320][train][INFO] - Epoch 216/2000, Val Acc=0.5466, Val Loss=1.7660, lr=0.0100
[2025-05-07 00:36:07,135][train][INFO] - Epoch 217/2000, Val Acc=0.5909, Val Loss=1.7292, lr=0.0100
[2025-05-07 00:36:09,752][train][INFO] - Epoch 213/2000, Val Acc=0.5986, Val Loss=1.6548, lr=0.0100
[2025-05-07 00:36:12,210][train][INFO] - Epoch 217/2000, Val Acc=0.5452, Val Loss=1.7671, lr=0.0100
[2025-05-07 00:36:14,831][train][INFO] - Epoch 218/2000, Val Acc=0.5954, Val Loss=1.6798, lr=0.0100
[2025-05-07 00:36:17,430][train][INFO] - Epoch 214/2000, Val Acc=0.5974, Val Loss=1.6715, lr=0.0100
[2025-05-07 00:36:19,762][train][INFO] - Epoch 218/2000, Val Acc=0.5620, Val Loss=1.7199, lr=0.0100
[2025-05-07 00:36:22,713][train][INFO] - Epoch 219/2000, Val Acc=0.5982, Val Loss=1.6864, lr=0.0100
[2025-05-07 00:36:24,859][train][INFO] - Epoch 215/2000, Val Acc=0.5933, Val Loss=1.7128, lr=0.0100
[2025-05-07 00:36:27,157][train][INFO] - Epoch 219/2000, Val Acc=0.5662, Val Loss=1.7020, lr=0.0100
[2025-05-07 00:36:30,385][train][INFO] - Epoch 220/2000, Val Acc=0.6024, Val Loss=1.6697, lr=0.0100
[2025-05-07 00:36:32,883][train][INFO] - Epoch 216/2000, Val Acc=0.5958, Val Loss=1.6623, lr=0.0100
[2025-05-07 00:36:35,172][train][INFO] - Epoch 220/2000, Val Acc=0.5620, Val Loss=1.6933, lr=0.0100
[2025-05-07 00:36:38,381][train][INFO] - Epoch 221/2000, Val Acc=0.5879, Val Loss=1.7178, lr=0.0100
[2025-05-07 00:36:40,288][train][INFO] - Epoch 217/2000, Val Acc=0.5909, Val Loss=1.7292, lr=0.0100
[2025-05-07 00:36:42,620][train][INFO] - Epoch 221/2000, Val Acc=0.5680, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:36:46,413][train][INFO] - Epoch 222/2000, Val Acc=0.6027, Val Loss=1.6606, lr=0.0100
[2025-05-07 00:36:47,831][train][INFO] - Epoch 218/2000, Val Acc=0.5954, Val Loss=1.6798, lr=0.0100
[2025-05-07 00:36:50,469][train][INFO] - Epoch 222/2000, Val Acc=0.5455, Val Loss=1.8053, lr=0.0100
[2025-05-07 00:36:54,348][train][INFO] - Epoch 223/2000, Val Acc=0.5794, Val Loss=1.8120, lr=0.0100
[2025-05-07 00:36:55,457][train][INFO] - Epoch 219/2000, Val Acc=0.5982, Val Loss=1.6864, lr=0.0100
[2025-05-07 00:36:57,839][train][INFO] - Epoch 223/2000, Val Acc=0.5667, Val Loss=1.6963, lr=0.0100
[2025-05-07 00:37:02,202][train][INFO] - Epoch 224/2000, Val Acc=0.6022, Val Loss=1.6550, lr=0.0100
[2025-05-07 00:37:03,052][train][INFO] - Epoch 220/2000, Val Acc=0.6024, Val Loss=1.6697, lr=0.0100
[2025-05-07 00:37:05,395][train][INFO] - Epoch 224/2000, Val Acc=0.5637, Val Loss=1.6900, lr=0.0100
[2025-05-07 00:37:09,624][train][INFO] - Epoch 225/2000, Val Acc=0.6019, Val Loss=1.6462, lr=0.0100
[2025-05-07 00:37:10,625][train][INFO] - Epoch 221/2000, Val Acc=0.5879, Val Loss=1.7178, lr=0.0100
[2025-05-07 00:37:13,071][train][INFO] - Epoch 225/2000, Val Acc=0.5569, Val Loss=1.7451, lr=0.0100
[2025-05-07 00:37:17,546][train][INFO] - Epoch 226/2000, Val Acc=0.6018, Val Loss=1.6582, lr=0.0100
[2025-05-07 00:37:17,969][train][INFO] - Epoch 222/2000, Val Acc=0.6027, Val Loss=1.6606, lr=0.0100
[2025-05-07 00:37:20,868][train][INFO] - Epoch 226/2000, Val Acc=0.5730, Val Loss=1.6192, lr=0.0100
[2025-05-07 00:37:25,135][train][INFO] - Epoch 227/2000, Val Acc=0.5908, Val Loss=1.7467, lr=0.0100
[2025-05-07 00:37:25,694][train][INFO] - Epoch 223/2000, Val Acc=0.5794, Val Loss=1.8120, lr=0.0100
[2025-05-07 00:37:28,745][train][INFO] - Epoch 227/2000, Val Acc=0.5633, Val Loss=1.7271, lr=0.0100
[2025-05-07 00:37:32,816][train][INFO] - Epoch 228/2000, Val Acc=0.5883, Val Loss=1.7390, lr=0.0100
[2025-05-07 00:37:33,460][train][INFO] - Epoch 224/2000, Val Acc=0.6022, Val Loss=1.6550, lr=0.0100
[2025-05-07 00:37:36,298][train][INFO] - Epoch 228/2000, Val Acc=0.5780, Val Loss=1.6584, lr=0.0100
[2025-05-07 00:37:40,378][train][INFO] - Epoch 229/2000, Val Acc=0.5745, Val Loss=1.8469, lr=0.0100
[2025-05-07 00:37:40,824][train][INFO] - Epoch 225/2000, Val Acc=0.6019, Val Loss=1.6462, lr=0.0100
[2025-05-07 00:37:43,835][train][INFO] - Epoch 229/2000, Val Acc=0.5517, Val Loss=1.7684, lr=0.0100
[2025-05-07 00:37:48,166][train][INFO] - Epoch 226/2000, Val Acc=0.6018, Val Loss=1.6582, lr=0.0100
[2025-05-07 00:37:48,386][train][INFO] - Epoch 230/2000, Val Acc=0.5923, Val Loss=1.7250, lr=0.0100
[2025-05-07 00:37:51,510][train][INFO] - Epoch 230/2000, Val Acc=0.5696, Val Loss=1.6831, lr=0.0100
[2025-05-07 00:37:55,713][train][INFO] - Epoch 227/2000, Val Acc=0.5908, Val Loss=1.7467, lr=0.0100
[2025-05-07 00:37:56,344][train][INFO] - Epoch 231/2000, Val Acc=0.5792, Val Loss=1.8277, lr=0.0100
[2025-05-07 00:37:58,857][train][INFO] - Epoch 231/2000, Val Acc=0.5741, Val Loss=1.6487, lr=0.0100
[2025-05-07 00:38:03,162][train][INFO] - Epoch 228/2000, Val Acc=0.5883, Val Loss=1.7390, lr=0.0100
[2025-05-07 00:38:04,675][train][INFO] - Epoch 232/2000, Val Acc=0.5960, Val Loss=1.6668, lr=0.0100
[2025-05-07 00:38:06,747][train][INFO] - Epoch 232/2000, Val Acc=0.5783, Val Loss=1.6558, lr=0.0100
[2025-05-07 00:38:10,841][train][INFO] - Epoch 229/2000, Val Acc=0.5745, Val Loss=1.8469, lr=0.0100
[2025-05-07 00:38:12,444][train][INFO] - Epoch 233/2000, Val Acc=0.5842, Val Loss=1.7584, lr=0.0100
[2025-05-07 00:38:14,876][train][INFO] - Epoch 233/2000, Val Acc=0.5575, Val Loss=1.7744, lr=0.0100
[2025-05-07 00:38:18,670][train][INFO] - Epoch 230/2000, Val Acc=0.5923, Val Loss=1.7250, lr=0.0100
[2025-05-07 00:38:20,095][train][INFO] - Epoch 234/2000, Val Acc=0.5926, Val Loss=1.7645, lr=0.0100
[2025-05-07 00:38:22,690][train][INFO] - Epoch 234/2000, Val Acc=0.5686, Val Loss=1.6478, lr=0.0100
[2025-05-07 00:38:26,660][train][INFO] - Epoch 231/2000, Val Acc=0.5792, Val Loss=1.8277, lr=0.0100
[2025-05-07 00:38:27,417][train][INFO] - Epoch 235/2000, Val Acc=0.5943, Val Loss=1.6694, lr=0.0100
[2025-05-07 00:38:30,144][train][INFO] - Epoch 235/2000, Val Acc=0.5577, Val Loss=1.7430, lr=0.0100
[2025-05-07 00:38:34,378][train][INFO] - Epoch 232/2000, Val Acc=0.5960, Val Loss=1.6668, lr=0.0100
[2025-05-07 00:38:35,302][train][INFO] - Epoch 236/2000, Val Acc=0.5864, Val Loss=1.7451, lr=0.0100
[2025-05-07 00:38:37,663][train][INFO] - Epoch 236/2000, Val Acc=0.5778, Val Loss=1.6408, lr=0.0100
[2025-05-07 00:38:41,949][train][INFO] - Epoch 233/2000, Val Acc=0.5842, Val Loss=1.7584, lr=0.0100
[2025-05-07 00:38:43,442][train][INFO] - Epoch 237/2000, Val Acc=0.5968, Val Loss=1.7070, lr=0.0100
[2025-05-07 00:38:45,418][train][INFO] - Epoch 237/2000, Val Acc=0.5807, Val Loss=1.6313, lr=0.0100
[2025-05-07 00:38:48,651][train][INFO] - Epoch 234/2000, Val Acc=0.5926, Val Loss=1.7645, lr=0.0100
[2025-05-07 00:38:51,324][train][INFO] - Epoch 238/2000, Val Acc=0.5851, Val Loss=1.7069, lr=0.0100
[2025-05-07 00:38:52,859][train][INFO] - Epoch 238/2000, Val Acc=0.5733, Val Loss=1.6575, lr=0.0100
[2025-05-07 00:38:56,326][train][INFO] - Epoch 235/2000, Val Acc=0.5943, Val Loss=1.6694, lr=0.0100
[2025-05-07 00:38:59,350][train][INFO] - Epoch 239/2000, Val Acc=0.5996, Val Loss=1.6745, lr=0.0100
[2025-05-07 00:39:00,505][train][INFO] - Epoch 239/2000, Val Acc=0.5839, Val Loss=1.6049, lr=0.0100
[2025-05-07 00:39:03,844][train][INFO] - Epoch 236/2000, Val Acc=0.5864, Val Loss=1.7451, lr=0.0100
[2025-05-07 00:39:07,031][train][INFO] - Epoch 240/2000, Val Acc=0.5980, Val Loss=1.6965, lr=0.0100
[2025-05-07 00:39:08,195][train][INFO] - Epoch 240/2000, Val Acc=0.5517, Val Loss=1.7541, lr=0.0100
[2025-05-07 00:39:11,021][train][INFO] - Epoch 237/2000, Val Acc=0.5968, Val Loss=1.7070, lr=0.0100
[2025-05-07 00:39:15,259][train][INFO] - Epoch 241/2000, Val Acc=0.5882, Val Loss=1.7603, lr=0.0100
[2025-05-07 00:39:15,728][train][INFO] - Epoch 241/2000, Val Acc=0.5486, Val Loss=1.8246, lr=0.0100
[2025-05-07 00:39:18,615][train][INFO] - Epoch 238/2000, Val Acc=0.5851, Val Loss=1.7069, lr=0.0100
[2025-05-07 00:39:23,245][train][INFO] - Epoch 242/2000, Val Acc=0.5854, Val Loss=1.7851, lr=0.0100
[2025-05-07 00:39:23,419][train][INFO] - Epoch 242/2000, Val Acc=0.5724, Val Loss=1.6860, lr=0.0100
[2025-05-07 00:39:26,115][train][INFO] - Epoch 239/2000, Val Acc=0.5996, Val Loss=1.6745, lr=0.0100
[2025-05-07 00:39:31,127][train][INFO] - Epoch 243/2000, Val Acc=0.5737, Val Loss=1.6472, lr=0.0100
[2025-05-07 00:39:31,153][train][INFO] - Epoch 243/2000, Val Acc=0.5867, Val Loss=1.7797, lr=0.0100
[2025-05-07 00:39:33,655][train][INFO] - Epoch 240/2000, Val Acc=0.5980, Val Loss=1.6965, lr=0.0100
[2025-05-07 00:39:38,505][train][INFO] - Epoch 244/2000, Val Acc=0.5973, Val Loss=1.6878, lr=0.0100
[2025-05-07 00:39:39,098][train][INFO] - Epoch 244/2000, Val Acc=0.5739, Val Loss=1.6657, lr=0.0100
[2025-05-07 00:39:40,996][train][INFO] - Epoch 241/2000, Val Acc=0.5882, Val Loss=1.7603, lr=0.0100
[2025-05-07 00:39:46,400][train][INFO] - Epoch 245/2000, Val Acc=0.6037, Val Loss=1.6523, lr=0.0100
[2025-05-07 00:39:46,686][train][INFO] - Epoch 245/2000, Val Acc=0.5516, Val Loss=1.7856, lr=0.0100
[2025-05-07 00:39:48,547][train][INFO] - Epoch 242/2000, Val Acc=0.5854, Val Loss=1.7851, lr=0.0100
[2025-05-07 00:39:54,370][train][INFO] - Epoch 246/2000, Val Acc=0.5966, Val Loss=1.7228, lr=0.0100
[2025-05-07 00:39:54,510][train][INFO] - Epoch 246/2000, Val Acc=0.5664, Val Loss=1.7339, lr=0.0100
[2025-05-07 00:39:56,018][train][INFO] - Epoch 243/2000, Val Acc=0.5867, Val Loss=1.7797, lr=0.0100
[2025-05-07 00:40:01,803][train][INFO] - Epoch 247/2000, Val Acc=0.5512, Val Loss=1.7806, lr=0.0100
[2025-05-07 00:40:02,267][train][INFO] - Epoch 247/2000, Val Acc=0.5945, Val Loss=1.7472, lr=0.0100
[2025-05-07 00:40:03,488][train][INFO] - Epoch 244/2000, Val Acc=0.5973, Val Loss=1.6878, lr=0.0100
[2025-05-07 00:40:09,778][train][INFO] - Epoch 248/2000, Val Acc=0.5453, Val Loss=1.7959, lr=0.0100
[2025-05-07 00:40:09,790][train][INFO] - Epoch 248/2000, Val Acc=0.6056, Val Loss=1.6322, lr=0.0100
[2025-05-07 00:40:09,889][train][INFO] - Epoch 245/2000, Val Acc=0.6037, Val Loss=1.6523, lr=0.0100
[2025-05-07 00:40:16,638][train][INFO] - Epoch 246/2000, Val Acc=0.5966, Val Loss=1.7228, lr=0.0100
[2025-05-07 00:40:17,554][train][INFO] - Epoch 249/2000, Val Acc=0.5664, Val Loss=1.6720, lr=0.0100
[2025-05-07 00:40:17,640][train][INFO] - Epoch 249/2000, Val Acc=0.5965, Val Loss=1.6616, lr=0.0100
[2025-05-07 00:40:24,544][train][INFO] - Epoch 247/2000, Val Acc=0.5945, Val Loss=1.7472, lr=0.0100
[2025-05-07 00:40:24,661][train][INFO] - Epoch 250/2000, Val Acc=0.5592, Val Loss=1.7518, lr=0.0100
[2025-05-07 00:40:25,258][train][INFO] - Epoch 250/2000, Val Acc=0.5865, Val Loss=1.7567, lr=0.0100
[2025-05-07 00:40:32,139][train][INFO] - Epoch 251/2000, Val Acc=0.5896, Val Loss=1.5939, lr=0.0100
[2025-05-07 00:40:32,338][train][INFO] - Epoch 248/2000, Val Acc=0.6056, Val Loss=1.6322, lr=0.0100
[2025-05-07 00:40:32,660][train][INFO] - Epoch 251/2000, Val Acc=0.5930, Val Loss=1.7251, lr=0.0100
[2025-05-07 00:40:39,872][train][INFO] - Epoch 252/2000, Val Acc=0.5697, Val Loss=1.6686, lr=0.0100
[2025-05-07 00:40:39,979][train][INFO] - Epoch 249/2000, Val Acc=0.5965, Val Loss=1.6616, lr=0.0100
[2025-05-07 00:40:40,758][train][INFO] - Epoch 252/2000, Val Acc=0.5789, Val Loss=1.7884, lr=0.0100
[2025-05-07 00:40:47,522][train][INFO] - Epoch 250/2000, Val Acc=0.5865, Val Loss=1.7567, lr=0.0100
[2025-05-07 00:40:47,564][train][INFO] - Epoch 253/2000, Val Acc=0.5774, Val Loss=1.6537, lr=0.0100
[2025-05-07 00:40:49,044][train][INFO] - Epoch 253/2000, Val Acc=0.5919, Val Loss=1.7470, lr=0.0100
[2025-05-07 00:40:55,016][train][INFO] - Epoch 251/2000, Val Acc=0.5930, Val Loss=1.7251, lr=0.0100
[2025-05-07 00:40:55,296][train][INFO] - Epoch 254/2000, Val Acc=0.5682, Val Loss=1.6914, lr=0.0100
[2025-05-07 00:40:57,036][train][INFO] - Epoch 254/2000, Val Acc=0.6018, Val Loss=1.6766, lr=0.0100
[2025-05-07 00:41:02,868][train][INFO] - Epoch 252/2000, Val Acc=0.5789, Val Loss=1.7884, lr=0.0100
[2025-05-07 00:41:03,272][train][INFO] - Epoch 255/2000, Val Acc=0.5612, Val Loss=1.7638, lr=0.0100
[2025-05-07 00:41:04,671][train][INFO] - Epoch 255/2000, Val Acc=0.5927, Val Loss=1.7366, lr=0.0100
[2025-05-07 00:41:10,656][train][INFO] - Epoch 253/2000, Val Acc=0.5919, Val Loss=1.7470, lr=0.0100
[2025-05-07 00:41:11,312][train][INFO] - Epoch 256/2000, Val Acc=0.5522, Val Loss=1.7927, lr=0.0100
[2025-05-07 00:41:12,391][train][INFO] - Epoch 256/2000, Val Acc=0.6067, Val Loss=1.6565, lr=0.0100
[2025-05-07 00:41:18,222][train][INFO] - Epoch 254/2000, Val Acc=0.6018, Val Loss=1.6766, lr=0.0100
[2025-05-07 00:41:19,016][train][INFO] - Epoch 257/2000, Val Acc=0.5923, Val Loss=1.6336, lr=0.0100
[2025-05-07 00:41:20,194][train][INFO] - Epoch 257/2000, Val Acc=0.6087, Val Loss=1.6342, lr=0.0100
[2025-05-07 00:41:26,163][train][INFO] - Epoch 255/2000, Val Acc=0.5927, Val Loss=1.7366, lr=0.0100
[2025-05-07 00:41:26,863][train][INFO] - Epoch 258/2000, Val Acc=0.5753, Val Loss=1.6516, lr=0.0100
[2025-05-07 00:41:27,545][train][INFO] - Epoch 258/2000, Val Acc=0.6075, Val Loss=1.6420, lr=0.0100
[2025-05-07 00:41:33,640][train][INFO] - Epoch 256/2000, Val Acc=0.6067, Val Loss=1.6565, lr=0.0100
[2025-05-07 00:41:34,740][train][INFO] - Epoch 259/2000, Val Acc=0.5543, Val Loss=1.7342, lr=0.0100
[2025-05-07 00:41:35,540][train][INFO] - Epoch 259/2000, Val Acc=0.5913, Val Loss=1.7515, lr=0.0100
[2025-05-07 00:41:41,163][train][INFO] - Epoch 257/2000, Val Acc=0.6087, Val Loss=1.6342, lr=0.0100
[2025-05-07 00:41:42,338][train][INFO] - Epoch 260/2000, Val Acc=0.5713, Val Loss=1.6650, lr=0.0100
[2025-05-07 00:41:43,544][train][INFO] - Epoch 260/2000, Val Acc=0.5971, Val Loss=1.6569, lr=0.0100
[2025-05-07 00:41:48,880][train][INFO] - Epoch 258/2000, Val Acc=0.6075, Val Loss=1.6420, lr=0.0100
[2025-05-07 00:41:49,507][train][INFO] - Epoch 261/2000, Val Acc=0.5611, Val Loss=1.7120, lr=0.0100
[2025-05-07 00:41:51,322][train][INFO] - Epoch 261/2000, Val Acc=0.5887, Val Loss=1.7695, lr=0.0100
[2025-05-07 00:41:56,577][train][INFO] - Epoch 259/2000, Val Acc=0.5913, Val Loss=1.7515, lr=0.0100
[2025-05-07 00:41:57,147][train][INFO] - Epoch 262/2000, Val Acc=0.5646, Val Loss=1.7653, lr=0.0100
[2025-05-07 00:41:58,923][train][INFO] - Epoch 262/2000, Val Acc=0.6019, Val Loss=1.6772, lr=0.0100
[2025-05-07 00:42:04,182][train][INFO] - Epoch 260/2000, Val Acc=0.5971, Val Loss=1.6569, lr=0.0100
[2025-05-07 00:42:05,015][train][INFO] - Epoch 263/2000, Val Acc=0.5693, Val Loss=1.6757, lr=0.0100
[2025-05-07 00:42:07,203][train][INFO] - Epoch 263/2000, Val Acc=0.6054, Val Loss=1.6736, lr=0.0100
[2025-05-07 00:42:12,276][train][INFO] - Epoch 261/2000, Val Acc=0.5887, Val Loss=1.7695, lr=0.0100
[2025-05-07 00:42:12,389][train][INFO] - Epoch 264/2000, Val Acc=0.5511, Val Loss=1.7509, lr=0.0100
[2025-05-07 00:42:15,029][train][INFO] - Epoch 264/2000, Val Acc=0.6062, Val Loss=1.6745, lr=0.0100
[2025-05-07 00:42:19,514][train][INFO] - Epoch 265/2000, Val Acc=0.5782, Val Loss=1.6546, lr=0.0100
[2025-05-07 00:42:20,008][train][INFO] - Epoch 262/2000, Val Acc=0.6019, Val Loss=1.6772, lr=0.0100
[2025-05-07 00:42:22,565][train][INFO] - Epoch 265/2000, Val Acc=0.5951, Val Loss=1.6897, lr=0.0100
[2025-05-07 00:42:26,847][train][INFO] - Epoch 266/2000, Val Acc=0.5813, Val Loss=1.6382, lr=0.0100
[2025-05-07 00:42:27,291][train][INFO] - Epoch 263/2000, Val Acc=0.6054, Val Loss=1.6736, lr=0.0100
[2025-05-07 00:42:30,364][train][INFO] - Epoch 266/2000, Val Acc=0.5889, Val Loss=1.7432, lr=0.0100
[2025-05-07 00:42:34,161][train][INFO] - Epoch 267/2000, Val Acc=0.5716, Val Loss=1.6761, lr=0.0100
[2025-05-07 00:42:34,908][train][INFO] - Epoch 264/2000, Val Acc=0.6062, Val Loss=1.6745, lr=0.0100
[2025-05-07 00:42:38,511][train][INFO] - Epoch 267/2000, Val Acc=0.5984, Val Loss=1.7131, lr=0.0100
[2025-05-07 00:42:42,024][train][INFO] - Epoch 268/2000, Val Acc=0.5630, Val Loss=1.7442, lr=0.0100
[2025-05-07 00:42:42,478][train][INFO] - Epoch 265/2000, Val Acc=0.5951, Val Loss=1.6897, lr=0.0100
[2025-05-07 00:42:46,115][train][INFO] - Epoch 268/2000, Val Acc=0.5819, Val Loss=1.7863, lr=0.0100
[2025-05-07 00:42:49,645][train][INFO] - Epoch 269/2000, Val Acc=0.5663, Val Loss=1.7285, lr=0.0100
[2025-05-07 00:42:50,145][train][INFO] - Epoch 266/2000, Val Acc=0.5889, Val Loss=1.7432, lr=0.0100
[2025-05-07 00:42:53,830][train][INFO] - Epoch 269/2000, Val Acc=0.5857, Val Loss=1.7992, lr=0.0100
[2025-05-07 00:42:57,365][train][INFO] - Epoch 270/2000, Val Acc=0.5741, Val Loss=1.6871, lr=0.0100
[2025-05-07 00:42:57,469][train][INFO] - Epoch 267/2000, Val Acc=0.5984, Val Loss=1.7131, lr=0.0100
[2025-05-07 00:43:01,111][train][INFO] - Epoch 270/2000, Val Acc=0.5889, Val Loss=1.7627, lr=0.0100
[2025-05-07 00:43:04,899][train][INFO] - Epoch 271/2000, Val Acc=0.5713, Val Loss=1.7315, lr=0.0100
[2025-05-07 00:43:05,241][train][INFO] - Epoch 268/2000, Val Acc=0.5819, Val Loss=1.7863, lr=0.0100
[2025-05-07 00:43:09,156][train][INFO] - Epoch 271/2000, Val Acc=0.5891, Val Loss=1.7319, lr=0.0100
[2025-05-07 00:43:12,584][train][INFO] - Epoch 269/2000, Val Acc=0.5857, Val Loss=1.7992, lr=0.0100
[2025-05-07 00:43:12,586][train][INFO] - Epoch 272/2000, Val Acc=0.5862, Val Loss=1.6020, lr=0.0100
[2025-05-07 00:43:17,103][train][INFO] - Epoch 272/2000, Val Acc=0.5977, Val Loss=1.7220, lr=0.0100
[2025-05-07 00:43:20,365][train][INFO] - Epoch 270/2000, Val Acc=0.5889, Val Loss=1.7627, lr=0.0100
[2025-05-07 00:43:20,689][train][INFO] - Epoch 273/2000, Val Acc=0.5786, Val Loss=1.6771, lr=0.0100
[2025-05-07 00:43:24,666][train][INFO] - Epoch 273/2000, Val Acc=0.6069, Val Loss=1.6489, lr=0.0100
[2025-05-07 00:43:27,187][train][INFO] - Epoch 271/2000, Val Acc=0.5891, Val Loss=1.7319, lr=0.0100
[2025-05-07 00:43:27,919][train][INFO] - Epoch 274/2000, Val Acc=0.5625, Val Loss=1.7500, lr=0.0100
[2025-05-07 00:43:32,167][train][INFO] - Epoch 274/2000, Val Acc=0.6073, Val Loss=1.6800, lr=0.0100
[2025-05-07 00:43:34,918][train][INFO] - Epoch 272/2000, Val Acc=0.5977, Val Loss=1.7220, lr=0.0100
[2025-05-07 00:43:35,023][train][INFO] - Epoch 275/2000, Val Acc=0.5694, Val Loss=1.7088, lr=0.0100
[2025-05-07 00:43:39,780][train][INFO] - Epoch 275/2000, Val Acc=0.5933, Val Loss=1.6910, lr=0.0100
[2025-05-07 00:43:42,263][train][INFO] - Epoch 276/2000, Val Acc=0.5740, Val Loss=1.6971, lr=0.0100
[2025-05-07 00:43:42,398][train][INFO] - Epoch 273/2000, Val Acc=0.6069, Val Loss=1.6489, lr=0.0100
[2025-05-07 00:43:47,099][train][INFO] - Epoch 276/2000, Val Acc=0.6065, Val Loss=1.6521, lr=0.0100
[2025-05-07 00:43:49,763][train][INFO] - Epoch 274/2000, Val Acc=0.6073, Val Loss=1.6800, lr=0.0100
[2025-05-07 00:43:49,853][train][INFO] - Epoch 277/2000, Val Acc=0.5349, Val Loss=1.8422, lr=0.0100
[2025-05-07 00:43:54,952][train][INFO] - Epoch 277/2000, Val Acc=0.5893, Val Loss=1.7358, lr=0.0100
[2025-05-07 00:43:57,505][train][INFO] - Epoch 275/2000, Val Acc=0.5933, Val Loss=1.6910, lr=0.0100
[2025-05-07 00:43:57,802][train][INFO] - Epoch 278/2000, Val Acc=0.5754, Val Loss=1.7050, lr=0.0100
[2025-05-07 00:44:02,636][train][INFO] - Epoch 278/2000, Val Acc=0.5951, Val Loss=1.7000, lr=0.0100
[2025-05-07 00:44:04,525][train][INFO] - Epoch 276/2000, Val Acc=0.6065, Val Loss=1.6521, lr=0.0100
[2025-05-07 00:44:05,455][train][INFO] - Epoch 279/2000, Val Acc=0.5329, Val Loss=1.8905, lr=0.0100
[2025-05-07 00:44:10,761][train][INFO] - Epoch 279/2000, Val Acc=0.5779, Val Loss=1.8426, lr=0.0100
[2025-05-07 00:44:11,709][train][INFO] - Epoch 277/2000, Val Acc=0.5893, Val Loss=1.7358, lr=0.0100
[2025-05-07 00:44:12,546][train][INFO] - Epoch 280/2000, Val Acc=0.5698, Val Loss=1.7274, lr=0.0100
[2025-05-07 00:44:17,771][train][INFO] - Epoch 280/2000, Val Acc=0.6089, Val Loss=1.6721, lr=0.0100
[2025-05-07 00:44:19,507][train][INFO] - Epoch 278/2000, Val Acc=0.5951, Val Loss=1.7000, lr=0.0100
[2025-05-07 00:44:20,185][train][INFO] - Epoch 281/2000, Val Acc=0.5754, Val Loss=1.6622, lr=0.0100
[2025-05-07 00:44:25,153][train][INFO] - Epoch 281/2000, Val Acc=0.6077, Val Loss=1.6701, lr=0.0100
[2025-05-07 00:44:27,115][train][INFO] - Epoch 279/2000, Val Acc=0.5779, Val Loss=1.8426, lr=0.0100
[2025-05-07 00:44:27,728][train][INFO] - Epoch 282/2000, Val Acc=0.5686, Val Loss=1.6942, lr=0.0100
[2025-05-07 00:44:33,104][train][INFO] - Epoch 282/2000, Val Acc=0.5985, Val Loss=1.7008, lr=0.0100
[2025-05-07 00:44:34,728][train][INFO] - Epoch 280/2000, Val Acc=0.6089, Val Loss=1.6721, lr=0.0100
[2025-05-07 00:44:35,507][train][INFO] - Epoch 283/2000, Val Acc=0.5705, Val Loss=1.7031, lr=0.0100
[2025-05-07 00:44:40,825][train][INFO] - Epoch 283/2000, Val Acc=0.5952, Val Loss=1.7230, lr=0.0100
[2025-05-07 00:44:42,477][train][INFO] - Epoch 281/2000, Val Acc=0.6077, Val Loss=1.6701, lr=0.0100
[2025-05-07 00:44:42,809][train][INFO] - Epoch 284/2000, Val Acc=0.5689, Val Loss=1.6824, lr=0.0100
[2025-05-07 00:44:48,885][train][INFO] - Epoch 284/2000, Val Acc=0.6001, Val Loss=1.6873, lr=0.0100
[2025-05-07 00:44:49,433][train][INFO] - Epoch 282/2000, Val Acc=0.5985, Val Loss=1.7008, lr=0.0100
[2025-05-07 00:44:50,661][train][INFO] - Epoch 285/2000, Val Acc=0.5853, Val Loss=1.6352, lr=0.0100
[2025-05-07 00:44:56,650][train][INFO] - Epoch 285/2000, Val Acc=0.5835, Val Loss=1.8095, lr=0.0100
[2025-05-07 00:44:57,413][train][INFO] - Epoch 283/2000, Val Acc=0.5952, Val Loss=1.7230, lr=0.0100
[2025-05-07 00:44:58,175][train][INFO] - Epoch 286/2000, Val Acc=0.5667, Val Loss=1.6954, lr=0.0100
[2025-05-07 00:45:04,555][train][INFO] - Epoch 286/2000, Val Acc=0.6042, Val Loss=1.7035, lr=0.0100
[2025-05-07 00:45:04,972][train][INFO] - Epoch 284/2000, Val Acc=0.6001, Val Loss=1.6873, lr=0.0100
[2025-05-07 00:45:06,128][train][INFO] - Epoch 287/2000, Val Acc=0.5629, Val Loss=1.7377, lr=0.0100
[2025-05-07 00:45:12,453][train][INFO] - Epoch 285/2000, Val Acc=0.5835, Val Loss=1.8095, lr=0.0100
[2025-05-07 00:45:12,636][train][INFO] - Epoch 287/2000, Val Acc=0.6008, Val Loss=1.7031, lr=0.0100
[2025-05-07 00:45:13,889][train][INFO] - Epoch 288/2000, Val Acc=0.5763, Val Loss=1.6640, lr=0.0100
[2025-05-07 00:45:20,303][train][INFO] - Epoch 286/2000, Val Acc=0.6042, Val Loss=1.7035, lr=0.0100
[2025-05-07 00:45:20,450][train][INFO] - Epoch 288/2000, Val Acc=0.6028, Val Loss=1.7118, lr=0.0100
[2025-05-07 00:45:21,902][train][INFO] - Epoch 289/2000, Val Acc=0.5751, Val Loss=1.6805, lr=0.0100
[2025-05-07 00:45:27,668][train][INFO] - Epoch 287/2000, Val Acc=0.6008, Val Loss=1.7031, lr=0.0100
[2025-05-07 00:45:28,178][train][INFO] - Epoch 289/2000, Val Acc=0.6014, Val Loss=1.7214, lr=0.0100
[2025-05-07 00:45:29,305][train][INFO] - Epoch 290/2000, Val Acc=0.5757, Val Loss=1.6764, lr=0.0100
[2025-05-07 00:45:35,420][train][INFO] - Epoch 288/2000, Val Acc=0.6028, Val Loss=1.7118, lr=0.0100
[2025-05-07 00:45:35,722][train][INFO] - Epoch 290/2000, Val Acc=0.6104, Val Loss=1.6298, lr=0.0100
[2025-05-07 00:45:36,996][train][INFO] - Epoch 291/2000, Val Acc=0.5761, Val Loss=1.6794, lr=0.0100
[2025-05-07 00:45:43,094][train][INFO] - Epoch 289/2000, Val Acc=0.6014, Val Loss=1.7214, lr=0.0100
[2025-05-07 00:45:43,218][train][INFO] - Epoch 291/2000, Val Acc=0.6041, Val Loss=1.6700, lr=0.0100
[2025-05-07 00:45:44,709][train][INFO] - Epoch 292/2000, Val Acc=0.5619, Val Loss=1.7700, lr=0.0100
[2025-05-07 00:45:50,688][train][INFO] - Epoch 290/2000, Val Acc=0.6104, Val Loss=1.6298, lr=0.0100
[2025-05-07 00:45:51,357][train][INFO] - Epoch 292/2000, Val Acc=0.5661, Val Loss=1.9843, lr=0.0100
[2025-05-07 00:45:52,158][train][INFO] - Epoch 293/2000, Val Acc=0.5663, Val Loss=1.6945, lr=0.0100
[2025-05-07 00:45:58,435][train][INFO] - Epoch 291/2000, Val Acc=0.6041, Val Loss=1.6700, lr=0.0100
[2025-05-07 00:45:59,307][train][INFO] - Epoch 293/2000, Val Acc=0.5993, Val Loss=1.7268, lr=0.0100
[2025-05-07 00:45:59,543][train][INFO] - Epoch 294/2000, Val Acc=0.5723, Val Loss=1.6495, lr=0.0100
[2025-05-07 00:46:05,700][train][INFO] - Epoch 292/2000, Val Acc=0.5661, Val Loss=1.9843, lr=0.0100
[2025-05-07 00:46:06,411][train][INFO] - Epoch 294/2000, Val Acc=0.5994, Val Loss=1.6847, lr=0.0100
[2025-05-07 00:46:07,218][train][INFO] - Epoch 295/2000, Val Acc=0.5676, Val Loss=1.7390, lr=0.0100
[2025-05-07 00:46:13,086][train][INFO] - Epoch 293/2000, Val Acc=0.5993, Val Loss=1.7268, lr=0.0100
[2025-05-07 00:46:14,144][train][INFO] - Epoch 295/2000, Val Acc=0.5915, Val Loss=1.7900, lr=0.0100
[2025-05-07 00:46:14,839][train][INFO] - Epoch 296/2000, Val Acc=0.5764, Val Loss=1.6916, lr=0.0100
[2025-05-07 00:46:20,862][train][INFO] - Epoch 294/2000, Val Acc=0.5994, Val Loss=1.6847, lr=0.0100
[2025-05-07 00:46:21,805][train][INFO] - Epoch 296/2000, Val Acc=0.6211, Val Loss=1.6371, lr=0.0100
[2025-05-07 00:46:22,507][train][INFO] - Epoch 297/2000, Val Acc=0.5790, Val Loss=1.6657, lr=0.0100
[2025-05-07 00:46:28,369][train][INFO] - Epoch 295/2000, Val Acc=0.5915, Val Loss=1.7900, lr=0.0100
[2025-05-07 00:46:29,799][train][INFO] - Epoch 297/2000, Val Acc=0.5935, Val Loss=1.7445, lr=0.0100
[2025-05-07 00:46:30,415][train][INFO] - Epoch 298/2000, Val Acc=0.5685, Val Loss=1.7309, lr=0.0100
[2025-05-07 00:46:36,230][train][INFO] - Epoch 296/2000, Val Acc=0.6211, Val Loss=1.6371, lr=0.0100
[2025-05-07 00:46:37,808][train][INFO] - Epoch 298/2000, Val Acc=0.6062, Val Loss=1.6366, lr=0.0100
[2025-05-07 00:46:38,040][train][INFO] - Epoch 299/2000, Val Acc=0.5669, Val Loss=1.7015, lr=0.0100
[2025-05-07 00:46:43,686][train][INFO] - Epoch 297/2000, Val Acc=0.5935, Val Loss=1.7445, lr=0.0100
[2025-05-07 00:46:44,818][train][INFO] - Epoch 299/2000, Val Acc=0.5917, Val Loss=1.7554, lr=0.0100
[2025-05-07 00:46:45,783][train][INFO] - Epoch 300/2000, Val Acc=0.5687, Val Loss=1.6984, lr=0.0100
[2025-05-07 00:46:51,536][train][INFO] - Epoch 298/2000, Val Acc=0.6062, Val Loss=1.6366, lr=0.0100
[2025-05-07 00:46:52,309][train][INFO] - Epoch 300/2000, Val Acc=0.5970, Val Loss=1.7247, lr=0.0100
[2025-05-07 00:46:53,525][train][INFO] - Epoch 301/2000, Val Acc=0.5636, Val Loss=1.7586, lr=0.0100
[2025-05-07 00:46:59,226][train][INFO] - Epoch 299/2000, Val Acc=0.5917, Val Loss=1.7554, lr=0.0100
[2025-05-07 00:47:00,436][train][INFO] - Epoch 301/2000, Val Acc=0.6007, Val Loss=1.7681, lr=0.0100
[2025-05-07 00:47:01,599][train][INFO] - Epoch 302/2000, Val Acc=0.5614, Val Loss=1.7562, lr=0.0100
[2025-05-07 00:47:06,511][train][INFO] - Epoch 300/2000, Val Acc=0.5970, Val Loss=1.7247, lr=0.0100
[2025-05-07 00:47:08,234][train][INFO] - Epoch 302/2000, Val Acc=0.5769, Val Loss=1.8320, lr=0.0100
[2025-05-07 00:47:09,572][train][INFO] - Epoch 303/2000, Val Acc=0.5528, Val Loss=1.8453, lr=0.0100
[2025-05-07 00:47:14,092][train][INFO] - Epoch 301/2000, Val Acc=0.6007, Val Loss=1.7681, lr=0.0100
[2025-05-07 00:47:15,697][train][INFO] - Epoch 303/2000, Val Acc=0.6064, Val Loss=1.6773, lr=0.0100
[2025-05-07 00:47:17,146][train][INFO] - Epoch 304/2000, Val Acc=0.5761, Val Loss=1.6748, lr=0.0100
[2025-05-07 00:47:21,611][train][INFO] - Epoch 302/2000, Val Acc=0.5769, Val Loss=1.8320, lr=0.0100
[2025-05-07 00:47:23,197][train][INFO] - Epoch 304/2000, Val Acc=0.5729, Val Loss=1.9026, lr=0.0100
[2025-05-07 00:47:24,807][train][INFO] - Epoch 305/2000, Val Acc=0.5847, Val Loss=1.6045, lr=0.0100
[2025-05-07 00:47:28,919][train][INFO] - Epoch 303/2000, Val Acc=0.6064, Val Loss=1.6773, lr=0.0100
[2025-05-07 00:47:31,168][train][INFO] - Epoch 305/2000, Val Acc=0.6146, Val Loss=1.6414, lr=0.0100
[2025-05-07 00:47:32,611][train][INFO] - Epoch 306/2000, Val Acc=0.5690, Val Loss=1.6627, lr=0.0100
[2025-05-07 00:47:36,091][train][INFO] - Epoch 304/2000, Val Acc=0.5729, Val Loss=1.9026, lr=0.0100
[2025-05-07 00:47:38,849][train][INFO] - Epoch 306/2000, Val Acc=0.5926, Val Loss=1.7736, lr=0.0100
[2025-05-07 00:47:40,147][train][INFO] - Epoch 307/2000, Val Acc=0.5751, Val Loss=1.6727, lr=0.0100
[2025-05-07 00:47:43,490][train][INFO] - Epoch 305/2000, Val Acc=0.6146, Val Loss=1.6414, lr=0.0100
[2025-05-07 00:47:46,915][train][INFO] - Epoch 307/2000, Val Acc=0.6035, Val Loss=1.6911, lr=0.0100
[2025-05-07 00:47:47,982][train][INFO] - Epoch 308/2000, Val Acc=0.5696, Val Loss=1.7071, lr=0.0100
[2025-05-07 00:47:50,989][train][INFO] - Epoch 306/2000, Val Acc=0.5926, Val Loss=1.7736, lr=0.0100
[2025-05-07 00:47:54,923][train][INFO] - Epoch 308/2000, Val Acc=0.6051, Val Loss=1.6841, lr=0.0100
[2025-05-07 00:47:55,458][train][INFO] - Epoch 309/2000, Val Acc=0.5729, Val Loss=1.6348, lr=0.0100
[2025-05-07 00:47:58,448][train][INFO] - Epoch 307/2000, Val Acc=0.6035, Val Loss=1.6911, lr=0.0100
[2025-05-07 00:48:02,673][train][INFO] - Epoch 309/2000, Val Acc=0.6049, Val Loss=1.6766, lr=0.0100
[2025-05-07 00:48:03,354][train][INFO] - Epoch 310/2000, Val Acc=0.5248, Val Loss=1.9561, lr=0.0100
[2025-05-07 00:48:06,025][train][INFO] - Epoch 308/2000, Val Acc=0.6051, Val Loss=1.6841, lr=0.0100
[2025-05-07 00:48:10,530][train][INFO] - Epoch 310/2000, Val Acc=0.6046, Val Loss=1.7104, lr=0.0100
[2025-05-07 00:48:10,571][train][INFO] - Epoch 311/2000, Val Acc=0.5663, Val Loss=1.7488, lr=0.0100
[2025-05-07 00:48:13,574][train][INFO] - Epoch 309/2000, Val Acc=0.6049, Val Loss=1.6766, lr=0.0100
[2025-05-07 00:48:17,860][train][INFO] - Epoch 311/2000, Val Acc=0.6160, Val Loss=1.6070, lr=0.0100
[2025-05-07 00:48:18,083][train][INFO] - Epoch 312/2000, Val Acc=0.5753, Val Loss=1.6936, lr=0.0100
[2025-05-07 00:48:21,063][train][INFO] - Epoch 310/2000, Val Acc=0.6046, Val Loss=1.7104, lr=0.0100
[2025-05-07 00:48:25,266][train][INFO] - Epoch 312/2000, Val Acc=0.5761, Val Loss=1.9022, lr=0.0100
[2025-05-07 00:48:25,444][train][INFO] - Epoch 313/2000, Val Acc=0.5462, Val Loss=1.8626, lr=0.0100
[2025-05-07 00:48:28,835][train][INFO] - Epoch 311/2000, Val Acc=0.6160, Val Loss=1.6070, lr=0.0100
[2025-05-07 00:48:33,253][train][INFO] - Epoch 313/2000, Val Acc=0.5905, Val Loss=1.7650, lr=0.0100
[2025-05-07 00:48:33,319][train][INFO] - Epoch 314/2000, Val Acc=0.5772, Val Loss=1.6866, lr=0.0100
[2025-05-07 00:48:36,081][train][INFO] - Epoch 312/2000, Val Acc=0.5761, Val Loss=1.9022, lr=0.0100
[2025-05-07 00:48:39,949][train][INFO] - Epoch 314/2000, Val Acc=0.6116, Val Loss=1.6509, lr=0.0100
[2025-05-07 00:48:40,758][train][INFO] - Epoch 315/2000, Val Acc=0.5637, Val Loss=1.7082, lr=0.0100
[2025-05-07 00:48:43,703][train][INFO] - Epoch 313/2000, Val Acc=0.5905, Val Loss=1.7650, lr=0.0100
[2025-05-07 00:48:47,044][train][INFO] - Epoch 315/2000, Val Acc=0.5920, Val Loss=1.7413, lr=0.0100
[2025-05-07 00:48:48,467][train][INFO] - Epoch 316/2000, Val Acc=0.5756, Val Loss=1.6707, lr=0.0100
[2025-05-07 00:48:51,356][train][INFO] - Epoch 314/2000, Val Acc=0.6116, Val Loss=1.6509, lr=0.0100
[2025-05-07 00:48:54,839][train][INFO] - Epoch 316/2000, Val Acc=0.5832, Val Loss=1.8000, lr=0.0100
[2025-05-07 00:48:55,888][train][INFO] - Epoch 317/2000, Val Acc=0.5579, Val Loss=1.7732, lr=0.0100
[2025-05-07 00:48:58,957][train][INFO] - Epoch 315/2000, Val Acc=0.5920, Val Loss=1.7413, lr=0.0100
[2025-05-07 00:49:02,780][train][INFO] - Epoch 317/2000, Val Acc=0.6095, Val Loss=1.6838, lr=0.0100
[2025-05-07 00:49:03,591][train][INFO] - Epoch 318/2000, Val Acc=0.5719, Val Loss=1.7059, lr=0.0100
[2025-05-07 00:49:06,094][train][INFO] - Epoch 316/2000, Val Acc=0.5832, Val Loss=1.8000, lr=0.0100
[2025-05-07 00:49:10,546][train][INFO] - Epoch 318/2000, Val Acc=0.5968, Val Loss=1.7517, lr=0.0100
[2025-05-07 00:49:11,263][train][INFO] - Epoch 319/2000, Val Acc=0.5807, Val Loss=1.6258, lr=0.0100
[2025-05-07 00:49:13,987][train][INFO] - Epoch 317/2000, Val Acc=0.6095, Val Loss=1.6838, lr=0.0100
[2025-05-07 00:49:18,598][train][INFO] - Epoch 319/2000, Val Acc=0.5938, Val Loss=1.7533, lr=0.0100
[2025-05-07 00:49:18,693][train][INFO] - Epoch 320/2000, Val Acc=0.5872, Val Loss=1.5975, lr=0.0100
[2025-05-07 00:49:21,661][train][INFO] - Epoch 318/2000, Val Acc=0.5968, Val Loss=1.7517, lr=0.0100
[2025-05-07 00:49:26,613][train][INFO] - Epoch 320/2000, Val Acc=0.6032, Val Loss=1.7086, lr=0.0100
[2025-05-07 00:49:26,686][train][INFO] - Epoch 321/2000, Val Acc=0.5722, Val Loss=1.7185, lr=0.0100
[2025-05-07 00:49:29,290][train][INFO] - Epoch 319/2000, Val Acc=0.5938, Val Loss=1.7533, lr=0.0100
[2025-05-07 00:49:34,378][train][INFO] - Epoch 322/2000, Val Acc=0.5608, Val Loss=1.7491, lr=0.0100
[2025-05-07 00:49:34,460][train][INFO] - Epoch 321/2000, Val Acc=0.6035, Val Loss=1.6947, lr=0.0100
[2025-05-07 00:49:36,849][train][INFO] - Epoch 320/2000, Val Acc=0.6032, Val Loss=1.7086, lr=0.0100
[2025-05-07 00:49:42,358][train][INFO] - Epoch 323/2000, Val Acc=0.5648, Val Loss=1.7398, lr=0.0100
[2025-05-07 00:49:42,459][train][INFO] - Epoch 322/2000, Val Acc=0.5950, Val Loss=1.7678, lr=0.0100
[2025-05-07 00:49:43,973][train][INFO] - Epoch 321/2000, Val Acc=0.6035, Val Loss=1.6947, lr=0.0100
[2025-05-07 00:49:49,862][train][INFO] - Epoch 323/2000, Val Acc=0.6002, Val Loss=1.6958, lr=0.0100
[2025-05-07 00:49:50,416][train][INFO] - Epoch 324/2000, Val Acc=0.5665, Val Loss=1.7129, lr=0.0100
[2025-05-07 00:49:51,135][train][INFO] - Epoch 322/2000, Val Acc=0.5950, Val Loss=1.7678, lr=0.0100
[2025-05-07 00:49:57,742][train][INFO] - Epoch 324/2000, Val Acc=0.6042, Val Loss=1.7040, lr=0.0100
[2025-05-07 00:49:57,971][train][INFO] - Epoch 325/2000, Val Acc=0.5668, Val Loss=1.7260, lr=0.0100
[2025-05-07 00:49:58,510][train][INFO] - Epoch 323/2000, Val Acc=0.6002, Val Loss=1.6958, lr=0.0100
[2025-05-07 00:50:05,058][train][INFO] - Epoch 325/2000, Val Acc=0.6103, Val Loss=1.6675, lr=0.0100
[2025-05-07 00:50:05,968][train][INFO] - Epoch 326/2000, Val Acc=0.5776, Val Loss=1.6456, lr=0.0100
[2025-05-07 00:50:06,619][train][INFO] - Epoch 324/2000, Val Acc=0.6042, Val Loss=1.7040, lr=0.0100
[2025-05-07 00:50:13,052][train][INFO] - Epoch 327/2000, Val Acc=0.5706, Val Loss=1.7378, lr=0.0100
[2025-05-07 00:50:13,178][train][INFO] - Epoch 326/2000, Val Acc=0.5947, Val Loss=1.7450, lr=0.0100
[2025-05-07 00:50:14,141][train][INFO] - Epoch 325/2000, Val Acc=0.6103, Val Loss=1.6675, lr=0.0100
[2025-05-07 00:50:20,600][train][INFO] - Epoch 328/2000, Val Acc=0.5866, Val Loss=1.6235, lr=0.0100
[2025-05-07 00:50:20,643][train][INFO] - Epoch 327/2000, Val Acc=0.6032, Val Loss=1.7356, lr=0.0100
[2025-05-07 00:50:21,674][train][INFO] - Epoch 326/2000, Val Acc=0.5947, Val Loss=1.7450, lr=0.0100
[2025-05-07 00:50:28,417][train][INFO] - Epoch 328/2000, Val Acc=0.6143, Val Loss=1.6498, lr=0.0100
[2025-05-07 00:50:28,445][train][INFO] - Epoch 329/2000, Val Acc=0.5654, Val Loss=1.7893, lr=0.0100
[2025-05-07 00:50:29,584][train][INFO] - Epoch 327/2000, Val Acc=0.6032, Val Loss=1.7356, lr=0.0100
[2025-05-07 00:50:35,947][train][INFO] - Epoch 330/2000, Val Acc=0.5579, Val Loss=1.7574, lr=0.0100
[2025-05-07 00:50:36,540][train][INFO] - Epoch 329/2000, Val Acc=0.6072, Val Loss=1.6773, lr=0.0100
[2025-05-07 00:50:37,206][train][INFO] - Epoch 328/2000, Val Acc=0.6143, Val Loss=1.6498, lr=0.0100
[2025-05-07 00:50:43,673][train][INFO] - Epoch 331/2000, Val Acc=0.5735, Val Loss=1.6874, lr=0.0100
[2025-05-07 00:50:43,732][train][INFO] - Epoch 329/2000, Val Acc=0.6072, Val Loss=1.6773, lr=0.0100
[2025-05-07 00:50:44,883][train][INFO] - Epoch 330/2000, Val Acc=0.5822, Val Loss=1.8177, lr=0.0100
[2025-05-07 00:50:50,904][train][INFO] - Epoch 330/2000, Val Acc=0.5822, Val Loss=1.8177, lr=0.0100
[2025-05-07 00:50:51,714][train][INFO] - Epoch 332/2000, Val Acc=0.5694, Val Loss=1.7015, lr=0.0100
[2025-05-07 00:50:53,046][train][INFO] - Epoch 331/2000, Val Acc=0.6045, Val Loss=1.7274, lr=0.0100
[2025-05-07 00:50:58,506][train][INFO] - Epoch 331/2000, Val Acc=0.6045, Val Loss=1.7274, lr=0.0100
[2025-05-07 00:50:59,684][train][INFO] - Epoch 333/2000, Val Acc=0.5498, Val Loss=1.7818, lr=0.0100
[2025-05-07 00:51:00,647][train][INFO] - Epoch 332/2000, Val Acc=0.6091, Val Loss=1.7031, lr=0.0100
[2025-05-07 00:51:06,376][train][INFO] - Epoch 332/2000, Val Acc=0.6091, Val Loss=1.7031, lr=0.0100
[2025-05-07 00:51:07,252][train][INFO] - Epoch 334/2000, Val Acc=0.5781, Val Loss=1.6833, lr=0.0100
[2025-05-07 00:51:08,116][train][INFO] - Epoch 333/2000, Val Acc=0.5946, Val Loss=1.7723, lr=0.0100
[2025-05-07 00:51:14,027][train][INFO] - Epoch 333/2000, Val Acc=0.5946, Val Loss=1.7723, lr=0.0100
[2025-05-07 00:51:15,034][train][INFO] - Epoch 335/2000, Val Acc=0.5886, Val Loss=1.6120, lr=0.0100
[2025-05-07 00:51:15,751][train][INFO] - Epoch 334/2000, Val Acc=0.6065, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:51:21,867][train][INFO] - Epoch 334/2000, Val Acc=0.6065, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:51:22,551][train][INFO] - Epoch 336/2000, Val Acc=0.5648, Val Loss=1.7356, lr=0.0100
[2025-05-07 00:51:23,273][train][INFO] - Epoch 335/2000, Val Acc=0.6081, Val Loss=1.6798, lr=0.0100
[2025-05-07 00:51:28,798][train][INFO] - Epoch 335/2000, Val Acc=0.6081, Val Loss=1.6798, lr=0.0100
[2025-05-07 00:51:29,977][train][INFO] - Epoch 337/2000, Val Acc=0.5814, Val Loss=1.6265, lr=0.0100
[2025-05-07 00:51:31,334][train][INFO] - Epoch 336/2000, Val Acc=0.6113, Val Loss=1.6687, lr=0.0100
[2025-05-07 00:51:35,915][train][INFO] - Epoch 336/2000, Val Acc=0.6113, Val Loss=1.6687, lr=0.0100
[2025-05-07 00:51:37,966][train][INFO] - Epoch 338/2000, Val Acc=0.5754, Val Loss=1.6911, lr=0.0100
[2025-05-07 00:51:39,636][train][INFO] - Epoch 337/2000, Val Acc=0.6041, Val Loss=1.7241, lr=0.0100
[2025-05-07 00:51:43,430][train][INFO] - Epoch 337/2000, Val Acc=0.6041, Val Loss=1.7241, lr=0.0100
[2025-05-07 00:51:46,000][train][INFO] - Epoch 339/2000, Val Acc=0.5639, Val Loss=1.7804, lr=0.0100
[2025-05-07 00:51:47,775][train][INFO] - Epoch 338/2000, Val Acc=0.5861, Val Loss=1.7756, lr=0.0100
[2025-05-07 00:51:51,126][train][INFO] - Epoch 338/2000, Val Acc=0.5861, Val Loss=1.7756, lr=0.0100
[2025-05-07 00:51:53,421][train][INFO] - Epoch 340/2000, Val Acc=0.5874, Val Loss=1.6329, lr=0.0100
[2025-05-07 00:51:55,673][train][INFO] - Epoch 339/2000, Val Acc=0.5917, Val Loss=1.7699, lr=0.0100
[2025-05-07 00:51:58,705][train][INFO] - Epoch 339/2000, Val Acc=0.5917, Val Loss=1.7699, lr=0.0100
[2025-05-07 00:52:00,862][train][INFO] - Epoch 341/2000, Val Acc=0.5575, Val Loss=1.8185, lr=0.0100
[2025-05-07 00:52:03,944][train][INFO] - Epoch 340/2000, Val Acc=0.5989, Val Loss=1.7343, lr=0.0100
[2025-05-07 00:52:06,074][train][INFO] - Epoch 340/2000, Val Acc=0.5989, Val Loss=1.7343, lr=0.0100
[2025-05-07 00:52:08,374][train][INFO] - Epoch 342/2000, Val Acc=0.5722, Val Loss=1.7167, lr=0.0100
[2025-05-07 00:52:11,679][train][INFO] - Epoch 341/2000, Val Acc=0.6117, Val Loss=1.6593, lr=0.0100
[2025-05-07 00:52:13,196][train][INFO] - Epoch 341/2000, Val Acc=0.6117, Val Loss=1.6593, lr=0.0100
[2025-05-07 00:52:15,839][train][INFO] - Epoch 343/2000, Val Acc=0.5903, Val Loss=1.5910, lr=0.0100
[2025-05-07 00:52:19,613][train][INFO] - Epoch 342/2000, Val Acc=0.5987, Val Loss=1.7267, lr=0.0100
[2025-05-07 00:52:20,349][train][INFO] - Epoch 342/2000, Val Acc=0.5987, Val Loss=1.7267, lr=0.0100
[2025-05-07 00:52:23,568][train][INFO] - Epoch 344/2000, Val Acc=0.5726, Val Loss=1.6787, lr=0.0100
[2025-05-07 00:52:26,934][train][INFO] - Epoch 343/2000, Val Acc=0.6087, Val Loss=1.6803, lr=0.0100
[2025-05-07 00:52:28,295][train][INFO] - Epoch 343/2000, Val Acc=0.6087, Val Loss=1.6803, lr=0.0100
[2025-05-07 00:52:31,543][train][INFO] - Epoch 345/2000, Val Acc=0.5698, Val Loss=1.7564, lr=0.0100
[2025-05-07 00:52:34,489][train][INFO] - Epoch 344/2000, Val Acc=0.6037, Val Loss=1.7135, lr=0.0100
[2025-05-07 00:52:35,881][train][INFO] - Epoch 344/2000, Val Acc=0.6037, Val Loss=1.7135, lr=0.0100
[2025-05-07 00:52:38,896][train][INFO] - Epoch 346/2000, Val Acc=0.5538, Val Loss=1.7962, lr=0.0100
[2025-05-07 00:52:42,204][train][INFO] - Epoch 345/2000, Val Acc=0.5871, Val Loss=1.8050, lr=0.0100
[2025-05-07 00:52:43,323][train][INFO] - Epoch 345/2000, Val Acc=0.5871, Val Loss=1.8050, lr=0.0100
[2025-05-07 00:52:46,878][train][INFO] - Epoch 347/2000, Val Acc=0.5923, Val Loss=1.6004, lr=0.0100
[2025-05-07 00:52:49,783][train][INFO] - Epoch 346/2000, Val Acc=0.5898, Val Loss=1.8045, lr=0.0100
[2025-05-07 00:52:50,703][train][INFO] - Epoch 346/2000, Val Acc=0.5898, Val Loss=1.8045, lr=0.0100
[2025-05-07 00:52:54,298][train][INFO] - Epoch 348/2000, Val Acc=0.5747, Val Loss=1.6864, lr=0.0100
[2025-05-07 00:52:57,788][train][INFO] - Epoch 347/2000, Val Acc=0.5996, Val Loss=1.7630, lr=0.0100
[2025-05-07 00:52:58,262][train][INFO] - Epoch 347/2000, Val Acc=0.5996, Val Loss=1.7630, lr=0.0100
[2025-05-07 00:53:01,776][train][INFO] - Epoch 349/2000, Val Acc=0.5869, Val Loss=1.6603, lr=0.0100
[2025-05-07 00:53:05,635][train][INFO] - Epoch 348/2000, Val Acc=0.6102, Val Loss=1.6792, lr=0.0100
[2025-05-07 00:53:05,678][train][INFO] - Epoch 348/2000, Val Acc=0.6102, Val Loss=1.6792, lr=0.0100
[2025-05-07 00:53:09,617][train][INFO] - Epoch 350/2000, Val Acc=0.5450, Val Loss=1.8634, lr=0.0100
[2025-05-07 00:53:13,597][train][INFO] - Epoch 349/2000, Val Acc=0.5954, Val Loss=1.7713, lr=0.0100
[2025-05-07 00:53:13,865][train][INFO] - Epoch 349/2000, Val Acc=0.5954, Val Loss=1.7713, lr=0.0100
[2025-05-07 00:53:16,899][train][INFO] - Epoch 351/2000, Val Acc=0.5711, Val Loss=1.7032, lr=0.0100
[2025-05-07 00:53:21,651][train][INFO] - Epoch 350/2000, Val Acc=0.6070, Val Loss=1.6760, lr=0.0100
[2025-05-07 00:53:21,657][train][INFO] - Epoch 350/2000, Val Acc=0.6070, Val Loss=1.6760, lr=0.0100
[2025-05-07 00:53:24,537][train][INFO] - Epoch 352/2000, Val Acc=0.5684, Val Loss=1.7215, lr=0.0100
[2025-05-07 00:53:29,059][train][INFO] - Epoch 351/2000, Val Acc=0.5954, Val Loss=1.7581, lr=0.0100
[2025-05-07 00:53:29,392][train][INFO] - Epoch 351/2000, Val Acc=0.5954, Val Loss=1.7581, lr=0.0100
[2025-05-07 00:53:32,152][train][INFO] - Epoch 353/2000, Val Acc=0.5552, Val Loss=1.7951, lr=0.0100
[2025-05-07 00:53:36,313][train][INFO] - Epoch 352/2000, Val Acc=0.6130, Val Loss=1.6801, lr=0.0100
[2025-05-07 00:53:36,895][train][INFO] - Epoch 352/2000, Val Acc=0.6130, Val Loss=1.6801, lr=0.0100
[2025-05-07 00:53:40,091][train][INFO] - Epoch 354/2000, Val Acc=0.5828, Val Loss=1.6477, lr=0.0100
[2025-05-07 00:53:43,338][train][INFO] - Epoch 353/2000, Val Acc=0.5858, Val Loss=1.8522, lr=0.0100
[2025-05-07 00:53:44,369][train][INFO] - Epoch 353/2000, Val Acc=0.5858, Val Loss=1.8522, lr=0.0100
[2025-05-07 00:53:48,004][train][INFO] - Epoch 355/2000, Val Acc=0.5981, Val Loss=1.5762, lr=0.0100
[2025-05-07 00:53:50,705][train][INFO] - Epoch 354/2000, Val Acc=0.6013, Val Loss=1.7488, lr=0.0100
[2025-05-07 00:53:51,596][train][INFO] - Epoch 354/2000, Val Acc=0.6013, Val Loss=1.7488, lr=0.0100
[2025-05-07 00:53:55,777][train][INFO] - Epoch 356/2000, Val Acc=0.5757, Val Loss=1.6970, lr=0.0100
[2025-05-07 00:53:58,429][train][INFO] - Epoch 355/2000, Val Acc=0.5892, Val Loss=1.8039, lr=0.0100
[2025-05-07 00:53:59,216][train][INFO] - Epoch 355/2000, Val Acc=0.5892, Val Loss=1.8039, lr=0.0100
[2025-05-07 00:54:03,293][train][INFO] - Epoch 357/2000, Val Acc=0.5769, Val Loss=1.7000, lr=0.0100
[2025-05-07 00:54:06,085][train][INFO] - Epoch 356/2000, Val Acc=0.5869, Val Loss=1.8285, lr=0.0100
[2025-05-07 00:54:07,273][train][INFO] - Epoch 356/2000, Val Acc=0.5869, Val Loss=1.8285, lr=0.0100
[2025-05-07 00:54:11,001][train][INFO] - Epoch 358/2000, Val Acc=0.5691, Val Loss=1.7448, lr=0.0100
[2025-05-07 00:54:13,544][train][INFO] - Epoch 357/2000, Val Acc=0.5945, Val Loss=1.7579, lr=0.0100
[2025-05-07 00:54:14,896][train][INFO] - Epoch 357/2000, Val Acc=0.5945, Val Loss=1.7579, lr=0.0100
[2025-05-07 00:54:18,755][train][INFO] - Epoch 359/2000, Val Acc=0.5673, Val Loss=1.7381, lr=0.0100
[2025-05-07 00:54:21,223][train][INFO] - Epoch 358/2000, Val Acc=0.6098, Val Loss=1.6942, lr=0.0100
[2025-05-07 00:54:22,487][train][INFO] - Epoch 358/2000, Val Acc=0.6098, Val Loss=1.6942, lr=0.0100
[2025-05-07 00:54:26,273][train][INFO] - Epoch 360/2000, Val Acc=0.5567, Val Loss=1.7636, lr=0.0100
[2025-05-07 00:54:28,788][train][INFO] - Epoch 359/2000, Val Acc=0.5869, Val Loss=1.8268, lr=0.0100
[2025-05-07 00:54:30,231][train][INFO] - Epoch 359/2000, Val Acc=0.5869, Val Loss=1.8268, lr=0.0100
[2025-05-07 00:54:34,061][train][INFO] - Epoch 361/2000, Val Acc=0.5828, Val Loss=1.6530, lr=0.0100
[2025-05-07 00:54:36,276][train][INFO] - Epoch 360/2000, Val Acc=0.5989, Val Loss=1.7138, lr=0.0100
[2025-05-07 00:54:38,030][train][INFO] - Epoch 360/2000, Val Acc=0.5989, Val Loss=1.7138, lr=0.0100
[2025-05-07 00:54:41,551][train][INFO] - Epoch 362/2000, Val Acc=0.5833, Val Loss=1.6431, lr=0.0100
[2025-05-07 00:54:43,583][train][INFO] - Epoch 361/2000, Val Acc=0.5818, Val Loss=1.8477, lr=0.0100
[2025-05-07 00:54:45,936][train][INFO] - Epoch 361/2000, Val Acc=0.5818, Val Loss=1.8477, lr=0.0100
[2025-05-07 00:54:48,913][train][INFO] - Epoch 363/2000, Val Acc=0.5649, Val Loss=1.7700, lr=0.0100
[2025-05-07 00:54:51,391][train][INFO] - Epoch 362/2000, Val Acc=0.6075, Val Loss=1.6867, lr=0.0100
[2025-05-07 00:54:53,707][train][INFO] - Epoch 362/2000, Val Acc=0.6075, Val Loss=1.6867, lr=0.0100
[2025-05-07 00:54:56,310][train][INFO] - Epoch 364/2000, Val Acc=0.5721, Val Loss=1.6999, lr=0.0100
[2025-05-07 00:54:58,974][train][INFO] - Epoch 363/2000, Val Acc=0.5963, Val Loss=1.7214, lr=0.0100
[2025-05-07 00:55:01,320][train][INFO] - Epoch 363/2000, Val Acc=0.5963, Val Loss=1.7214, lr=0.0100
[2025-05-07 00:55:03,480][train][INFO] - Epoch 365/2000, Val Acc=0.5738, Val Loss=1.7027, lr=0.0100
[2025-05-07 00:55:06,695][train][INFO] - Epoch 364/2000, Val Acc=0.6170, Val Loss=1.6191, lr=0.0100
[2025-05-07 00:55:09,373][train][INFO] - Epoch 364/2000, Val Acc=0.6170, Val Loss=1.6191, lr=0.0100
[2025-05-07 00:55:11,477][train][INFO] - Epoch 366/2000, Val Acc=0.5772, Val Loss=1.6930, lr=0.0100
[2025-05-07 00:55:14,275][train][INFO] - Epoch 365/2000, Val Acc=0.5915, Val Loss=1.7789, lr=0.0100
[2025-05-07 00:55:17,415][train][INFO] - Epoch 365/2000, Val Acc=0.5915, Val Loss=1.7789, lr=0.0100
[2025-05-07 00:55:18,446][train][INFO] - Epoch 367/2000, Val Acc=0.5565, Val Loss=1.7843, lr=0.0100
[2025-05-07 00:55:21,737][train][INFO] - Epoch 366/2000, Val Acc=0.5844, Val Loss=1.8360, lr=0.0100
[2025-05-07 00:55:24,760][train][INFO] - Epoch 366/2000, Val Acc=0.5844, Val Loss=1.8360, lr=0.0100
[2025-05-07 00:55:26,380][train][INFO] - Epoch 368/2000, Val Acc=0.5687, Val Loss=1.7269, lr=0.0100
[2025-05-07 00:55:29,193][train][INFO] - Epoch 367/2000, Val Acc=0.6013, Val Loss=1.7278, lr=0.0100
[2025-05-07 00:55:33,026][train][INFO] - Epoch 367/2000, Val Acc=0.6013, Val Loss=1.7278, lr=0.0100
[2025-05-07 00:55:34,199][train][INFO] - Epoch 369/2000, Val Acc=0.5605, Val Loss=1.7879, lr=0.0100
[2025-05-07 00:55:36,437][train][INFO] - Epoch 368/2000, Val Acc=0.6049, Val Loss=1.6757, lr=0.0100
[2025-05-07 00:55:40,837][train][INFO] - Epoch 368/2000, Val Acc=0.6049, Val Loss=1.6757, lr=0.0100
[2025-05-07 00:55:42,239][train][INFO] - Epoch 370/2000, Val Acc=0.5752, Val Loss=1.6595, lr=0.0100
[2025-05-07 00:55:44,054][train][INFO] - Epoch 369/2000, Val Acc=0.6057, Val Loss=1.6763, lr=0.0100
[2025-05-07 00:55:48,642][train][INFO] - Epoch 369/2000, Val Acc=0.6057, Val Loss=1.6763, lr=0.0100
[2025-05-07 00:55:49,815][train][INFO] - Epoch 371/2000, Val Acc=0.5765, Val Loss=1.6724, lr=0.0100
[2025-05-07 00:55:51,436][train][INFO] - Epoch 370/2000, Val Acc=0.5975, Val Loss=1.7658, lr=0.0100
[2025-05-07 00:55:56,422][train][INFO] - Epoch 370/2000, Val Acc=0.5975, Val Loss=1.7658, lr=0.0100
[2025-05-07 00:55:57,547][train][INFO] - Epoch 372/2000, Val Acc=0.5724, Val Loss=1.6851, lr=0.0100
[2025-05-07 00:55:59,353][train][INFO] - Epoch 371/2000, Val Acc=0.6058, Val Loss=1.6882, lr=0.0100
[2025-05-07 00:56:04,324][train][INFO] - Epoch 371/2000, Val Acc=0.6058, Val Loss=1.6882, lr=0.0100
[2025-05-07 00:56:04,906][train][INFO] - Epoch 373/2000, Val Acc=0.5542, Val Loss=1.8227, lr=0.0100
[2025-05-07 00:56:06,707][train][INFO] - Epoch 372/2000, Val Acc=0.5956, Val Loss=1.8130, lr=0.0100
[2025-05-07 00:56:12,576][train][INFO] - Epoch 372/2000, Val Acc=0.5956, Val Loss=1.8130, lr=0.0100
[2025-05-07 00:56:12,796][train][INFO] - Epoch 374/2000, Val Acc=0.5717, Val Loss=1.6688, lr=0.0100
[2025-05-07 00:56:14,266][train][INFO] - Epoch 373/2000, Val Acc=0.5954, Val Loss=1.7891, lr=0.0100
[2025-05-07 00:56:19,969][train][INFO] - Epoch 375/2000, Val Acc=0.5654, Val Loss=1.7474, lr=0.0100
[2025-05-07 00:56:20,346][train][INFO] - Epoch 373/2000, Val Acc=0.5954, Val Loss=1.7891, lr=0.0100
[2025-05-07 00:56:21,494][train][INFO] - Epoch 374/2000, Val Acc=0.5872, Val Loss=1.7876, lr=0.0100
[2025-05-07 00:56:27,864][train][INFO] - Epoch 376/2000, Val Acc=0.5797, Val Loss=1.6655, lr=0.0100
[2025-05-07 00:56:28,462][train][INFO] - Epoch 374/2000, Val Acc=0.5872, Val Loss=1.7876, lr=0.0100
[2025-05-07 00:56:29,389][train][INFO] - Epoch 375/2000, Val Acc=0.5915, Val Loss=1.7714, lr=0.0100
[2025-05-07 00:56:35,802][train][INFO] - Epoch 377/2000, Val Acc=0.5745, Val Loss=1.6964, lr=0.0100
[2025-05-07 00:56:36,469][train][INFO] - Epoch 375/2000, Val Acc=0.5915, Val Loss=1.7714, lr=0.0100
[2025-05-07 00:56:37,380][train][INFO] - Epoch 376/2000, Val Acc=0.5940, Val Loss=1.7505, lr=0.0100
[2025-05-07 00:56:42,899][train][INFO] - Epoch 378/2000, Val Acc=0.5761, Val Loss=1.6768, lr=0.0100
[2025-05-07 00:56:43,899][train][INFO] - Epoch 376/2000, Val Acc=0.5940, Val Loss=1.7505, lr=0.0100
[2025-05-07 00:56:45,392][train][INFO] - Epoch 377/2000, Val Acc=0.5958, Val Loss=1.7532, lr=0.0100
[2025-05-07 00:56:50,914][train][INFO] - Epoch 379/2000, Val Acc=0.5620, Val Loss=1.7493, lr=0.0100
[2025-05-07 00:56:52,087][train][INFO] - Epoch 377/2000, Val Acc=0.5958, Val Loss=1.7532, lr=0.0100
[2025-05-07 00:56:52,749][train][INFO] - Epoch 378/2000, Val Acc=0.5865, Val Loss=1.7888, lr=0.0100
[2025-05-07 00:56:58,534][train][INFO] - Epoch 380/2000, Val Acc=0.5780, Val Loss=1.6827, lr=0.0100
[2025-05-07 00:57:00,370][train][INFO] - Epoch 378/2000, Val Acc=0.5865, Val Loss=1.7888, lr=0.0100
[2025-05-07 00:57:00,643][train][INFO] - Epoch 379/2000, Val Acc=0.6105, Val Loss=1.6833, lr=0.0100
[2025-05-07 00:57:06,103][train][INFO] - Epoch 381/2000, Val Acc=0.5831, Val Loss=1.6067, lr=0.0100
[2025-05-07 00:57:08,100][train][INFO] - Epoch 380/2000, Val Acc=0.6143, Val Loss=1.6451, lr=0.0100
[2025-05-07 00:57:08,615][train][INFO] - Epoch 379/2000, Val Acc=0.6105, Val Loss=1.6833, lr=0.0100
[2025-05-07 00:57:13,828][train][INFO] - Epoch 382/2000, Val Acc=0.5734, Val Loss=1.7023, lr=0.0100
[2025-05-07 00:57:15,336][train][INFO] - Epoch 381/2000, Val Acc=0.5945, Val Loss=1.7390, lr=0.0100
[2025-05-07 00:57:16,418][train][INFO] - Epoch 380/2000, Val Acc=0.6143, Val Loss=1.6451, lr=0.0100
[2025-05-07 00:57:21,386][train][INFO] - Epoch 383/2000, Val Acc=0.5666, Val Loss=1.7347, lr=0.0100
[2025-05-07 00:57:22,984][train][INFO] - Epoch 382/2000, Val Acc=0.5914, Val Loss=1.7542, lr=0.0100
[2025-05-07 00:57:24,240][train][INFO] - Epoch 381/2000, Val Acc=0.5945, Val Loss=1.7390, lr=0.0100
[2025-05-07 00:57:28,660][train][INFO] - Epoch 384/2000, Val Acc=0.5778, Val Loss=1.7130, lr=0.0100
[2025-05-07 00:57:30,286][train][INFO] - Epoch 383/2000, Val Acc=0.6086, Val Loss=1.7110, lr=0.0100
[2025-05-07 00:57:31,934][train][INFO] - Epoch 382/2000, Val Acc=0.5914, Val Loss=1.7542, lr=0.0100
[2025-05-07 00:57:36,224][train][INFO] - Epoch 385/2000, Val Acc=0.5691, Val Loss=1.7393, lr=0.0100
[2025-05-07 00:57:38,017][train][INFO] - Epoch 384/2000, Val Acc=0.6006, Val Loss=1.7454, lr=0.0100
[2025-05-07 00:57:40,093][train][INFO] - Epoch 383/2000, Val Acc=0.6086, Val Loss=1.7110, lr=0.0100
[2025-05-07 00:57:43,872][train][INFO] - Epoch 386/2000, Val Acc=0.5579, Val Loss=1.8004, lr=0.0100
[2025-05-07 00:57:45,985][train][INFO] - Epoch 385/2000, Val Acc=0.5998, Val Loss=1.7615, lr=0.0100
[2025-05-07 00:57:48,096][train][INFO] - Epoch 384/2000, Val Acc=0.6006, Val Loss=1.7454, lr=0.0100
[2025-05-07 00:57:52,107][train][INFO] - Epoch 387/2000, Val Acc=0.5665, Val Loss=1.7738, lr=0.0100
[2025-05-07 00:57:53,957][train][INFO] - Epoch 386/2000, Val Acc=0.5995, Val Loss=1.7349, lr=0.0100
[2025-05-07 00:57:55,969][train][INFO] - Epoch 385/2000, Val Acc=0.5998, Val Loss=1.7615, lr=0.0100
[2025-05-07 00:58:00,090][train][INFO] - Epoch 388/2000, Val Acc=0.5773, Val Loss=1.6848, lr=0.0100
[2025-05-07 00:58:01,743][train][INFO] - Epoch 387/2000, Val Acc=0.5913, Val Loss=1.7912, lr=0.0100
[2025-05-07 00:58:03,783][train][INFO] - Epoch 386/2000, Val Acc=0.5995, Val Loss=1.7349, lr=0.0100
[2025-05-07 00:58:07,843][train][INFO] - Epoch 389/2000, Val Acc=0.5735, Val Loss=1.6981, lr=0.0100
[2025-05-07 00:58:09,351][train][INFO] - Epoch 388/2000, Val Acc=0.6034, Val Loss=1.7179, lr=0.0100
[2025-05-07 00:58:11,782][train][INFO] - Epoch 387/2000, Val Acc=0.5913, Val Loss=1.7912, lr=0.0100
[2025-05-07 00:58:15,729][train][INFO] - Epoch 390/2000, Val Acc=0.5726, Val Loss=1.7193, lr=0.0100
[2025-05-07 00:58:16,780][train][INFO] - Epoch 389/2000, Val Acc=0.6081, Val Loss=1.6594, lr=0.0100
[2025-05-07 00:58:19,392][train][INFO] - Epoch 388/2000, Val Acc=0.6034, Val Loss=1.7179, lr=0.0100
[2025-05-07 00:58:23,616][train][INFO] - Epoch 391/2000, Val Acc=0.5902, Val Loss=1.6322, lr=0.0100
[2025-05-07 00:58:24,392][train][INFO] - Epoch 390/2000, Val Acc=0.5885, Val Loss=1.8539, lr=0.0100
[2025-05-07 00:58:27,123][train][INFO] - Epoch 389/2000, Val Acc=0.6081, Val Loss=1.6594, lr=0.0100
[2025-05-07 00:58:31,559][train][INFO] - Epoch 392/2000, Val Acc=0.5762, Val Loss=1.7094, lr=0.0100
[2025-05-07 00:58:32,046][train][INFO] - Epoch 391/2000, Val Acc=0.6083, Val Loss=1.6842, lr=0.0100
[2025-05-07 00:58:35,009][train][INFO] - Epoch 390/2000, Val Acc=0.5885, Val Loss=1.8539, lr=0.0100
[2025-05-07 00:58:39,021][train][INFO] - Epoch 393/2000, Val Acc=0.5671, Val Loss=1.7991, lr=0.0100
[2025-05-07 00:58:39,843][train][INFO] - Epoch 392/2000, Val Acc=0.6018, Val Loss=1.7490, lr=0.0100
[2025-05-07 00:58:42,433][train][INFO] - Epoch 391/2000, Val Acc=0.6083, Val Loss=1.6842, lr=0.0100
[2025-05-07 00:58:46,832][train][INFO] - Epoch 394/2000, Val Acc=0.5508, Val Loss=1.8472, lr=0.0100
[2025-05-07 00:58:47,219][train][INFO] - Epoch 393/2000, Val Acc=0.6100, Val Loss=1.6926, lr=0.0100
[2025-05-07 00:58:50,271][train][INFO] - Epoch 392/2000, Val Acc=0.6018, Val Loss=1.7490, lr=0.0100
[2025-05-07 00:58:54,305][train][INFO] - Epoch 394/2000, Val Acc=0.6150, Val Loss=1.6707, lr=0.0100
[2025-05-07 00:58:54,719][train][INFO] - Epoch 395/2000, Val Acc=0.5769, Val Loss=1.6765, lr=0.0100
[2025-05-07 00:58:57,657][train][INFO] - Epoch 393/2000, Val Acc=0.6100, Val Loss=1.6926, lr=0.0100
[2025-05-07 00:59:01,851][train][INFO] - Epoch 395/2000, Val Acc=0.6066, Val Loss=1.7032, lr=0.0100
[2025-05-07 00:59:01,894][train][INFO] - Epoch 396/2000, Val Acc=0.5605, Val Loss=1.7783, lr=0.0100
[2025-05-07 00:59:05,464][train][INFO] - Epoch 394/2000, Val Acc=0.6150, Val Loss=1.6707, lr=0.0100
[2025-05-07 00:59:09,158][train][INFO] - Epoch 396/2000, Val Acc=0.6142, Val Loss=1.6568, lr=0.0100
[2025-05-07 00:59:09,610][train][INFO] - Epoch 397/2000, Val Acc=0.5976, Val Loss=1.6021, lr=0.0100
[2025-05-07 00:59:13,231][train][INFO] - Epoch 395/2000, Val Acc=0.6066, Val Loss=1.7032, lr=0.0100
[2025-05-07 00:59:17,010][train][INFO] - Epoch 397/2000, Val Acc=0.5910, Val Loss=1.8134, lr=0.0100
[2025-05-07 00:59:17,698][train][INFO] - Epoch 398/2000, Val Acc=0.5824, Val Loss=1.6539, lr=0.0100
[2025-05-07 00:59:20,744][train][INFO] - Epoch 396/2000, Val Acc=0.6142, Val Loss=1.6568, lr=0.0100
[2025-05-07 00:59:24,964][train][INFO] - Epoch 398/2000, Val Acc=0.6020, Val Loss=1.7283, lr=0.0100
[2025-05-07 00:59:25,814][train][INFO] - Epoch 399/2000, Val Acc=0.5484, Val Loss=1.8204, lr=0.0100
[2025-05-07 00:59:27,801][train][INFO] - Epoch 397/2000, Val Acc=0.5910, Val Loss=1.8134, lr=0.0100
[2025-05-07 00:59:32,662][train][INFO] - Epoch 399/2000, Val Acc=0.6054, Val Loss=1.6952, lr=0.0100
[2025-05-07 00:59:33,623][train][INFO] - Epoch 400/2000, Val Acc=0.5693, Val Loss=1.7119, lr=0.0100
[2025-05-07 00:59:35,397][train][INFO] - Epoch 398/2000, Val Acc=0.6020, Val Loss=1.7283, lr=0.0100
[2025-05-07 00:59:39,473][train][INFO] - Epoch 400/2000, Val Acc=0.5951, Val Loss=1.7519, lr=0.0100
[2025-05-07 00:59:40,785][train][INFO] - Epoch 401/2000, Val Acc=0.5892, Val Loss=1.5981, lr=0.0100
[2025-05-07 00:59:42,819][train][INFO] - Epoch 399/2000, Val Acc=0.6054, Val Loss=1.6952, lr=0.0100
[2025-05-07 00:59:46,490][train][INFO] - Epoch 401/2000, Val Acc=0.6075, Val Loss=1.6933, lr=0.0100
[2025-05-07 00:59:48,392][train][INFO] - Epoch 402/2000, Val Acc=0.5589, Val Loss=1.8249, lr=0.0100
[2025-05-07 00:59:50,397][train][INFO] - Epoch 400/2000, Val Acc=0.5951, Val Loss=1.7519, lr=0.0100
[2025-05-07 00:59:53,896][train][INFO] - Epoch 402/2000, Val Acc=0.6068, Val Loss=1.7118, lr=0.0100
[2025-05-07 00:59:55,931][train][INFO] - Epoch 403/2000, Val Acc=0.5734, Val Loss=1.7216, lr=0.0100
[2025-05-07 00:59:58,558][train][INFO] - Epoch 401/2000, Val Acc=0.6075, Val Loss=1.6933, lr=0.0100
[2025-05-07 01:00:01,679][train][INFO] - Epoch 403/2000, Val Acc=0.6098, Val Loss=1.6899, lr=0.0100
[2025-05-07 01:00:03,544][train][INFO] - Epoch 404/2000, Val Acc=0.5698, Val Loss=1.7738, lr=0.0100
[2025-05-07 01:00:06,160][train][INFO] - Epoch 402/2000, Val Acc=0.6068, Val Loss=1.7118, lr=0.0100
[2025-05-07 01:00:09,134][train][INFO] - Epoch 404/2000, Val Acc=0.6050, Val Loss=1.6988, lr=0.0100
[2025-05-07 01:00:11,088][train][INFO] - Epoch 405/2000, Val Acc=0.5870, Val Loss=1.6346, lr=0.0100
[2025-05-07 01:00:14,225][train][INFO] - Epoch 403/2000, Val Acc=0.6098, Val Loss=1.6899, lr=0.0100
[2025-05-07 01:00:16,505][train][INFO] - Epoch 405/2000, Val Acc=0.6171, Val Loss=1.6633, lr=0.0100
[2025-05-07 01:00:18,807][train][INFO] - Epoch 406/2000, Val Acc=0.5660, Val Loss=1.7570, lr=0.0100
[2025-05-07 01:00:21,841][train][INFO] - Epoch 404/2000, Val Acc=0.6050, Val Loss=1.6988, lr=0.0100
[2025-05-07 01:00:23,825][train][INFO] - Epoch 406/2000, Val Acc=0.6012, Val Loss=1.7643, lr=0.0100
[2025-05-07 01:00:26,324][train][INFO] - Epoch 407/2000, Val Acc=0.5783, Val Loss=1.7222, lr=0.0100
[2025-05-07 01:00:29,485][train][INFO] - Epoch 405/2000, Val Acc=0.6171, Val Loss=1.6633, lr=0.0100
[2025-05-07 01:00:31,477][train][INFO] - Epoch 407/2000, Val Acc=0.5832, Val Loss=1.8775, lr=0.0100
[2025-05-07 01:00:34,165][train][INFO] - Epoch 408/2000, Val Acc=0.5918, Val Loss=1.6324, lr=0.0100
[2025-05-07 01:00:37,147][train][INFO] - Epoch 406/2000, Val Acc=0.6012, Val Loss=1.7643, lr=0.0100
[2025-05-07 01:00:38,724][train][INFO] - Epoch 408/2000, Val Acc=0.6162, Val Loss=1.6722, lr=0.0100
[2025-05-07 01:00:41,441][train][INFO] - Epoch 409/2000, Val Acc=0.5797, Val Loss=1.6555, lr=0.0100
[2025-05-07 01:00:44,416][train][INFO] - Epoch 407/2000, Val Acc=0.5832, Val Loss=1.8775, lr=0.0100
[2025-05-07 01:00:45,898][train][INFO] - Epoch 409/2000, Val Acc=0.6077, Val Loss=1.7074, lr=0.0100
[2025-05-07 01:00:48,800][train][INFO] - Epoch 410/2000, Val Acc=0.5739, Val Loss=1.7484, lr=0.0100
[2025-05-07 01:00:52,260][train][INFO] - Epoch 408/2000, Val Acc=0.6162, Val Loss=1.6722, lr=0.0100
[2025-05-07 01:00:52,923][train][INFO] - Epoch 410/2000, Val Acc=0.6051, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:00:56,286][train][INFO] - Epoch 411/2000, Val Acc=0.5870, Val Loss=1.6548, lr=0.0100
[2025-05-07 01:01:00,095][train][INFO] - Epoch 409/2000, Val Acc=0.6077, Val Loss=1.7074, lr=0.0100
[2025-05-07 01:01:00,312][train][INFO] - Epoch 411/2000, Val Acc=0.6024, Val Loss=1.7489, lr=0.0100
[2025-05-07 01:01:03,785][train][INFO] - Epoch 412/2000, Val Acc=0.5920, Val Loss=1.6035, lr=0.0100
[2025-05-07 01:01:07,619][train][INFO] - Epoch 412/2000, Val Acc=0.5912, Val Loss=1.7938, lr=0.0100
[2025-05-07 01:01:07,955][train][INFO] - Epoch 410/2000, Val Acc=0.6051, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:01:11,237][train][INFO] - Epoch 413/2000, Val Acc=0.5843, Val Loss=1.6620, lr=0.0100
[2025-05-07 01:01:15,366][train][INFO] - Epoch 413/2000, Val Acc=0.6168, Val Loss=1.6770, lr=0.0100
[2025-05-07 01:01:15,758][train][INFO] - Epoch 411/2000, Val Acc=0.6024, Val Loss=1.7489, lr=0.0100
[2025-05-07 01:01:18,412][train][INFO] - Epoch 414/2000, Val Acc=0.5969, Val Loss=1.6251, lr=0.0100
[2025-05-07 01:01:23,222][train][INFO] - Epoch 414/2000, Val Acc=0.6038, Val Loss=1.7559, lr=0.0100
[2025-05-07 01:01:24,127][train][INFO] - Epoch 412/2000, Val Acc=0.5912, Val Loss=1.7938, lr=0.0100
[2025-05-07 01:01:26,141][train][INFO] - Epoch 415/2000, Val Acc=0.5574, Val Loss=1.7699, lr=0.0100
[2025-05-07 01:01:30,340][train][INFO] - Epoch 415/2000, Val Acc=0.6137, Val Loss=1.6604, lr=0.0100
[2025-05-07 01:01:31,793][train][INFO] - Epoch 413/2000, Val Acc=0.6168, Val Loss=1.6770, lr=0.0100
[2025-05-07 01:01:33,534][train][INFO] - Epoch 416/2000, Val Acc=0.5792, Val Loss=1.6681, lr=0.0100
[2025-05-07 01:01:37,941][train][INFO] - Epoch 416/2000, Val Acc=0.6062, Val Loss=1.6858, lr=0.0100
[2025-05-07 01:01:39,635][train][INFO] - Epoch 414/2000, Val Acc=0.6038, Val Loss=1.7559, lr=0.0100
[2025-05-07 01:01:41,062][train][INFO] - Epoch 417/2000, Val Acc=0.5757, Val Loss=1.7004, lr=0.0100
[2025-05-07 01:01:45,545][train][INFO] - Epoch 417/2000, Val Acc=0.6108, Val Loss=1.6812, lr=0.0100
[2025-05-07 01:01:47,363][train][INFO] - Epoch 415/2000, Val Acc=0.6137, Val Loss=1.6604, lr=0.0100
[2025-05-07 01:01:48,702][train][INFO] - Epoch 418/2000, Val Acc=0.5758, Val Loss=1.7057, lr=0.0100
[2025-05-07 01:01:52,908][train][INFO] - Epoch 418/2000, Val Acc=0.6072, Val Loss=1.7374, lr=0.0100
[2025-05-07 01:01:55,144][train][INFO] - Epoch 416/2000, Val Acc=0.6062, Val Loss=1.6858, lr=0.0100
[2025-05-07 01:01:56,272][train][INFO] - Epoch 419/2000, Val Acc=0.5962, Val Loss=1.5900, lr=0.0100
[2025-05-07 01:02:00,511][train][INFO] - Epoch 419/2000, Val Acc=0.6010, Val Loss=1.7569, lr=0.0100
[2025-05-07 01:02:03,352][train][INFO] - Epoch 417/2000, Val Acc=0.6108, Val Loss=1.6812, lr=0.0100
[2025-05-07 01:02:03,723][train][INFO] - Epoch 420/2000, Val Acc=0.5875, Val Loss=1.6575, lr=0.0100
[2025-05-07 01:02:08,353][train][INFO] - Epoch 420/2000, Val Acc=0.6157, Val Loss=1.6702, lr=0.0100
[2025-05-07 01:02:11,042][train][INFO] - Epoch 421/2000, Val Acc=0.5727, Val Loss=1.7373, lr=0.0100
[2025-05-07 01:02:11,411][train][INFO] - Epoch 418/2000, Val Acc=0.6072, Val Loss=1.7374, lr=0.0100
[2025-05-07 01:02:15,868][train][INFO] - Epoch 421/2000, Val Acc=0.5974, Val Loss=1.7803, lr=0.0100
[2025-05-07 01:02:18,285][train][INFO] - Epoch 422/2000, Val Acc=0.5865, Val Loss=1.6433, lr=0.0100
[2025-05-07 01:02:19,310][train][INFO] - Epoch 419/2000, Val Acc=0.6010, Val Loss=1.7569, lr=0.0100
[2025-05-07 01:02:23,382][train][INFO] - Epoch 422/2000, Val Acc=0.6073, Val Loss=1.6814, lr=0.0100
[2025-05-07 01:02:26,080][train][INFO] - Epoch 423/2000, Val Acc=0.5750, Val Loss=1.6689, lr=0.0100
[2025-05-07 01:02:27,086][train][INFO] - Epoch 420/2000, Val Acc=0.6157, Val Loss=1.6702, lr=0.0100
[2025-05-07 01:02:30,857][train][INFO] - Epoch 423/2000, Val Acc=0.6047, Val Loss=1.7028, lr=0.0100
[2025-05-07 01:02:33,960][train][INFO] - Epoch 424/2000, Val Acc=0.5520, Val Loss=1.8595, lr=0.0100
[2025-05-07 01:02:35,216][train][INFO] - Epoch 421/2000, Val Acc=0.5974, Val Loss=1.7803, lr=0.0100
[2025-05-07 01:02:38,262][train][INFO] - Epoch 424/2000, Val Acc=0.5868, Val Loss=1.8765, lr=0.0100
[2025-05-07 01:02:41,309][train][INFO] - Epoch 425/2000, Val Acc=0.5893, Val Loss=1.6359, lr=0.0100
[2025-05-07 01:02:43,047][train][INFO] - Epoch 422/2000, Val Acc=0.6073, Val Loss=1.6814, lr=0.0100
[2025-05-07 01:02:46,123][train][INFO] - Epoch 425/2000, Val Acc=0.5897, Val Loss=1.7770, lr=0.0100
[2025-05-07 01:02:48,821][train][INFO] - Epoch 426/2000, Val Acc=0.5843, Val Loss=1.6517, lr=0.0100
[2025-05-07 01:02:50,950][train][INFO] - Epoch 423/2000, Val Acc=0.6047, Val Loss=1.7028, lr=0.0100
[2025-05-07 01:02:53,314][train][INFO] - Epoch 426/2000, Val Acc=0.6077, Val Loss=1.7413, lr=0.0100
[2025-05-07 01:02:56,676][train][INFO] - Epoch 427/2000, Val Acc=0.5877, Val Loss=1.6814, lr=0.0100
[2025-05-07 01:02:58,964][train][INFO] - Epoch 424/2000, Val Acc=0.5868, Val Loss=1.8765, lr=0.0100
[2025-05-07 01:03:00,810][train][INFO] - Epoch 427/2000, Val Acc=0.6061, Val Loss=1.7091, lr=0.0100
[2025-05-07 01:03:04,108][train][INFO] - Epoch 428/2000, Val Acc=0.5813, Val Loss=1.7206, lr=0.0100
[2025-05-07 01:03:06,713][train][INFO] - Epoch 425/2000, Val Acc=0.5897, Val Loss=1.7770, lr=0.0100
[2025-05-07 01:03:07,657][train][INFO] - Epoch 428/2000, Val Acc=0.6210, Val Loss=1.6675, lr=0.0100
[2025-05-07 01:03:11,080][train][INFO] - Epoch 429/2000, Val Acc=0.5741, Val Loss=1.6954, lr=0.0100
[2025-05-07 01:03:14,730][train][INFO] - Epoch 426/2000, Val Acc=0.6077, Val Loss=1.7413, lr=0.0100
[2025-05-07 01:03:14,899][train][INFO] - Epoch 429/2000, Val Acc=0.6155, Val Loss=1.6442, lr=0.0100
[2025-05-07 01:03:18,372][train][INFO] - Epoch 430/2000, Val Acc=0.5779, Val Loss=1.6669, lr=0.0100
[2025-05-07 01:03:22,797][train][INFO] - Epoch 430/2000, Val Acc=0.6194, Val Loss=1.6356, lr=0.0100
[2025-05-07 01:03:22,887][train][INFO] - Epoch 427/2000, Val Acc=0.6061, Val Loss=1.7091, lr=0.0100
[2025-05-07 01:03:26,009][train][INFO] - Epoch 431/2000, Val Acc=0.5727, Val Loss=1.7253, lr=0.0100
[2025-05-07 01:03:30,565][train][INFO] - Epoch 431/2000, Val Acc=0.6126, Val Loss=1.6752, lr=0.0100
[2025-05-07 01:03:30,580][train][INFO] - Epoch 428/2000, Val Acc=0.6210, Val Loss=1.6675, lr=0.0100
[2025-05-07 01:03:33,931][train][INFO] - Epoch 432/2000, Val Acc=0.5925, Val Loss=1.5941, lr=0.0100
[2025-05-07 01:03:38,112][train][INFO] - Epoch 432/2000, Val Acc=0.6115, Val Loss=1.6632, lr=0.0100
[2025-05-07 01:03:38,356][train][INFO] - Epoch 429/2000, Val Acc=0.6155, Val Loss=1.6442, lr=0.0100
[2025-05-07 01:03:41,525][train][INFO] - Epoch 433/2000, Val Acc=0.5832, Val Loss=1.6564, lr=0.0100
[2025-05-07 01:03:45,346][train][INFO] - Epoch 433/2000, Val Acc=0.6177, Val Loss=1.6310, lr=0.0100
[2025-05-07 01:03:46,139][train][INFO] - Epoch 430/2000, Val Acc=0.6194, Val Loss=1.6356, lr=0.0100
[2025-05-07 01:03:49,263][train][INFO] - Epoch 434/2000, Val Acc=0.5715, Val Loss=1.7616, lr=0.0100
[2025-05-07 01:03:53,074][train][INFO] - Epoch 434/2000, Val Acc=0.6016, Val Loss=1.7412, lr=0.0100
[2025-05-07 01:03:54,392][train][INFO] - Epoch 431/2000, Val Acc=0.6126, Val Loss=1.6752, lr=0.0100
[2025-05-07 01:03:57,017][train][INFO] - Epoch 435/2000, Val Acc=0.5792, Val Loss=1.6726, lr=0.0100
[2025-05-07 01:04:00,570][train][INFO] - Epoch 435/2000, Val Acc=0.5868, Val Loss=1.8276, lr=0.0100
[2025-05-07 01:04:01,895][train][INFO] - Epoch 432/2000, Val Acc=0.6115, Val Loss=1.6632, lr=0.0100
[2025-05-07 01:04:04,900][train][INFO] - Epoch 436/2000, Val Acc=0.5786, Val Loss=1.7109, lr=0.0100
[2025-05-07 01:04:07,950][train][INFO] - Epoch 436/2000, Val Acc=0.5801, Val Loss=1.8524, lr=0.0100
[2025-05-07 01:04:09,327][train][INFO] - Epoch 433/2000, Val Acc=0.6177, Val Loss=1.6310, lr=0.0100
[2025-05-07 01:04:12,368][train][INFO] - Epoch 437/2000, Val Acc=0.5797, Val Loss=1.6927, lr=0.0100
[2025-05-07 01:04:15,043][train][INFO] - Epoch 437/2000, Val Acc=0.5966, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:04:16,825][train][INFO] - Epoch 434/2000, Val Acc=0.6016, Val Loss=1.7412, lr=0.0100
[2025-05-07 01:04:19,620][train][INFO] - Epoch 438/2000, Val Acc=0.5533, Val Loss=1.8407, lr=0.0100
[2025-05-07 01:04:22,644][train][INFO] - Epoch 438/2000, Val Acc=0.5993, Val Loss=1.7704, lr=0.0100
[2025-05-07 01:04:24,439][train][INFO] - Epoch 435/2000, Val Acc=0.5868, Val Loss=1.8276, lr=0.0100
[2025-05-07 01:04:27,422][train][INFO] - Epoch 439/2000, Val Acc=0.5887, Val Loss=1.6118, lr=0.0100
[2025-05-07 01:04:30,285][train][INFO] - Epoch 439/2000, Val Acc=0.6088, Val Loss=1.7219, lr=0.0100
[2025-05-07 01:04:31,994][train][INFO] - Epoch 436/2000, Val Acc=0.5801, Val Loss=1.8524, lr=0.0100
[2025-05-07 01:04:35,380][train][INFO] - Epoch 440/2000, Val Acc=0.5760, Val Loss=1.7027, lr=0.0100
[2025-05-07 01:04:38,119][train][INFO] - Epoch 440/2000, Val Acc=0.6031, Val Loss=1.7425, lr=0.0100
[2025-05-07 01:04:39,372][train][INFO] - Epoch 437/2000, Val Acc=0.5966, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:04:42,946][train][INFO] - Epoch 441/2000, Val Acc=0.5914, Val Loss=1.6102, lr=0.0100
[2025-05-07 01:04:46,088][train][INFO] - Epoch 441/2000, Val Acc=0.6042, Val Loss=1.7229, lr=0.0100
[2025-05-07 01:04:47,223][train][INFO] - Epoch 438/2000, Val Acc=0.5993, Val Loss=1.7704, lr=0.0100
[2025-05-07 01:04:50,108][train][INFO] - Epoch 442/2000, Val Acc=0.5849, Val Loss=1.6937, lr=0.0100
[2025-05-07 01:04:53,655][train][INFO] - Epoch 442/2000, Val Acc=0.5986, Val Loss=1.7517, lr=0.0100
[2025-05-07 01:04:54,865][train][INFO] - Epoch 439/2000, Val Acc=0.6088, Val Loss=1.7219, lr=0.0100
[2025-05-07 01:04:57,899][train][INFO] - Epoch 443/2000, Val Acc=0.5569, Val Loss=1.8016, lr=0.0100
[2025-05-07 01:05:01,548][train][INFO] - Epoch 443/2000, Val Acc=0.6056, Val Loss=1.7115, lr=0.0100
[2025-05-07 01:05:02,304][train][INFO] - Epoch 440/2000, Val Acc=0.6031, Val Loss=1.7425, lr=0.0100
[2025-05-07 01:05:05,531][train][INFO] - Epoch 444/2000, Val Acc=0.5857, Val Loss=1.6599, lr=0.0100
[2025-05-07 01:05:09,401][train][INFO] - Epoch 444/2000, Val Acc=0.6091, Val Loss=1.6662, lr=0.0100
[2025-05-07 01:05:10,214][train][INFO] - Epoch 441/2000, Val Acc=0.6042, Val Loss=1.7229, lr=0.0100
[2025-05-07 01:05:13,326][train][INFO] - Epoch 445/2000, Val Acc=0.5757, Val Loss=1.7493, lr=0.0100
[2025-05-07 01:05:16,642][train][INFO] - Epoch 445/2000, Val Acc=0.6094, Val Loss=1.6934, lr=0.0100
[2025-05-07 01:05:17,997][train][INFO] - Epoch 442/2000, Val Acc=0.5986, Val Loss=1.7517, lr=0.0100
[2025-05-07 01:05:21,091][train][INFO] - Epoch 446/2000, Val Acc=0.5737, Val Loss=1.7102, lr=0.0100
[2025-05-07 01:05:24,478][train][INFO] - Epoch 446/2000, Val Acc=0.5994, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:05:26,149][train][INFO] - Epoch 443/2000, Val Acc=0.6056, Val Loss=1.7115, lr=0.0100
[2025-05-07 01:05:28,464][train][INFO] - Epoch 447/2000, Val Acc=0.5699, Val Loss=1.7786, lr=0.0100
[2025-05-07 01:05:32,000][train][INFO] - Epoch 447/2000, Val Acc=0.5979, Val Loss=1.7695, lr=0.0100
[2025-05-07 01:05:33,388][train][INFO] - Epoch 444/2000, Val Acc=0.6091, Val Loss=1.6662, lr=0.0100
[2025-05-07 01:05:36,175][train][INFO] - Epoch 448/2000, Val Acc=0.5594, Val Loss=1.7698, lr=0.0100
[2025-05-07 01:05:39,790][train][INFO] - Epoch 448/2000, Val Acc=0.6006, Val Loss=1.7288, lr=0.0100
[2025-05-07 01:05:41,521][train][INFO] - Epoch 445/2000, Val Acc=0.6094, Val Loss=1.6934, lr=0.0100
[2025-05-07 01:05:43,818][train][INFO] - Epoch 449/2000, Val Acc=0.5706, Val Loss=1.7707, lr=0.0100
[2025-05-07 01:05:47,648][train][INFO] - Epoch 449/2000, Val Acc=0.5981, Val Loss=1.7517, lr=0.0100
[2025-05-07 01:05:49,296][train][INFO] - Epoch 446/2000, Val Acc=0.5994, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:05:51,781][train][INFO] - Epoch 450/2000, Val Acc=0.5681, Val Loss=1.7556, lr=0.0100
[2025-05-07 01:05:55,375][train][INFO] - Epoch 450/2000, Val Acc=0.6094, Val Loss=1.6896, lr=0.0100
[2025-05-07 01:05:57,808][train][INFO] - Epoch 447/2000, Val Acc=0.5979, Val Loss=1.7695, lr=0.0100
[2025-05-07 01:05:59,617][train][INFO] - Epoch 451/2000, Val Acc=0.5874, Val Loss=1.6637, lr=0.0100
[2025-05-07 01:06:02,836][train][INFO] - Epoch 451/2000, Val Acc=0.6071, Val Loss=1.7322, lr=0.0100
[2025-05-07 01:06:05,336][train][INFO] - Epoch 448/2000, Val Acc=0.6006, Val Loss=1.7288, lr=0.0100
[2025-05-07 01:06:07,408][train][INFO] - Epoch 452/2000, Val Acc=0.5907, Val Loss=1.5814, lr=0.0100
[2025-05-07 01:06:10,527][train][INFO] - Epoch 452/2000, Val Acc=0.6103, Val Loss=1.7319, lr=0.0100
[2025-05-07 01:06:13,366][train][INFO] - Epoch 449/2000, Val Acc=0.5981, Val Loss=1.7517, lr=0.0100
[2025-05-07 01:06:14,958][train][INFO] - Epoch 453/2000, Val Acc=0.5815, Val Loss=1.6489, lr=0.0100
[2025-05-07 01:06:18,608][train][INFO] - Epoch 453/2000, Val Acc=0.5925, Val Loss=1.8173, lr=0.0100
[2025-05-07 01:06:21,048][train][INFO] - Epoch 450/2000, Val Acc=0.6094, Val Loss=1.6896, lr=0.0100
[2025-05-07 01:06:22,983][train][INFO] - Epoch 454/2000, Val Acc=0.5876, Val Loss=1.6335, lr=0.0100
[2025-05-07 01:06:25,832][train][INFO] - Epoch 454/2000, Val Acc=0.5940, Val Loss=1.7722, lr=0.0100
[2025-05-07 01:06:28,815][train][INFO] - Epoch 451/2000, Val Acc=0.6071, Val Loss=1.7322, lr=0.0100
[2025-05-07 01:06:31,116][train][INFO] - Epoch 455/2000, Val Acc=0.5917, Val Loss=1.6211, lr=0.0100
[2025-05-07 01:06:33,554][train][INFO] - Epoch 455/2000, Val Acc=0.6025, Val Loss=1.7282, lr=0.0100
[2025-05-07 01:06:36,656][train][INFO] - Epoch 452/2000, Val Acc=0.6103, Val Loss=1.7319, lr=0.0100
[2025-05-07 01:06:38,983][train][INFO] - Epoch 456/2000, Val Acc=0.5816, Val Loss=1.6637, lr=0.0100
[2025-05-07 01:06:41,652][train][INFO] - Epoch 456/2000, Val Acc=0.6167, Val Loss=1.6130, lr=0.0100
[2025-05-07 01:06:44,507][train][INFO] - Epoch 453/2000, Val Acc=0.5925, Val Loss=1.8173, lr=0.0100
[2025-05-07 01:06:46,502][train][INFO] - Epoch 457/2000, Val Acc=0.5730, Val Loss=1.7280, lr=0.0100
[2025-05-07 01:06:49,528][train][INFO] - Epoch 457/2000, Val Acc=0.6152, Val Loss=1.6905, lr=0.0100
[2025-05-07 01:06:52,896][train][INFO] - Epoch 454/2000, Val Acc=0.5940, Val Loss=1.7722, lr=0.0100
[2025-05-07 01:06:53,342][train][INFO] - Epoch 458/2000, Val Acc=0.5928, Val Loss=1.6125, lr=0.0100
[2025-05-07 01:06:57,420][train][INFO] - Epoch 458/2000, Val Acc=0.5981, Val Loss=1.7487, lr=0.0100
[2025-05-07 01:07:00,532][train][INFO] - Epoch 459/2000, Val Acc=0.5805, Val Loss=1.6800, lr=0.0100
[2025-05-07 01:07:01,008][train][INFO] - Epoch 455/2000, Val Acc=0.6025, Val Loss=1.7282, lr=0.0100
[2025-05-07 01:07:05,377][train][INFO] - Epoch 459/2000, Val Acc=0.6082, Val Loss=1.7024, lr=0.0100
[2025-05-07 01:07:07,871][train][INFO] - Epoch 460/2000, Val Acc=0.5703, Val Loss=1.7438, lr=0.0100
[2025-05-07 01:07:08,783][train][INFO] - Epoch 456/2000, Val Acc=0.6167, Val Loss=1.6130, lr=0.0100
[2025-05-07 01:07:12,830][train][INFO] - Epoch 460/2000, Val Acc=0.6039, Val Loss=1.7373, lr=0.0100
[2025-05-07 01:07:15,882][train][INFO] - Epoch 461/2000, Val Acc=0.5717, Val Loss=1.7434, lr=0.0100
[2025-05-07 01:07:17,174][train][INFO] - Epoch 457/2000, Val Acc=0.6152, Val Loss=1.6905, lr=0.0100
[2025-05-07 01:07:20,155][train][INFO] - Epoch 461/2000, Val Acc=0.5951, Val Loss=1.7612, lr=0.0100
[2025-05-07 01:07:23,942][train][INFO] - Epoch 462/2000, Val Acc=0.5811, Val Loss=1.6972, lr=0.0100
[2025-05-07 01:07:25,233][train][INFO] - Epoch 458/2000, Val Acc=0.5981, Val Loss=1.7487, lr=0.0100
[2025-05-07 01:07:27,808][train][INFO] - Epoch 462/2000, Val Acc=0.6082, Val Loss=1.7288, lr=0.0100
[2025-05-07 01:07:31,034][train][INFO] - Epoch 463/2000, Val Acc=0.5791, Val Loss=1.6831, lr=0.0100
[2025-05-07 01:07:32,919][train][INFO] - Epoch 459/2000, Val Acc=0.6082, Val Loss=1.7024, lr=0.0100
[2025-05-07 01:07:35,499][train][INFO] - Epoch 463/2000, Val Acc=0.6078, Val Loss=1.6919, lr=0.0100
[2025-05-07 01:07:38,554][train][INFO] - Epoch 464/2000, Val Acc=0.5721, Val Loss=1.7419, lr=0.0100
[2025-05-07 01:07:40,728][train][INFO] - Epoch 460/2000, Val Acc=0.6039, Val Loss=1.7373, lr=0.0100
[2025-05-07 01:07:43,196][train][INFO] - Epoch 464/2000, Val Acc=0.5788, Val Loss=1.8482, lr=0.0100
[2025-05-07 01:07:46,052][train][INFO] - Epoch 465/2000, Val Acc=0.5616, Val Loss=1.7942, lr=0.0100
[2025-05-07 01:07:48,419][train][INFO] - Epoch 461/2000, Val Acc=0.5951, Val Loss=1.7612, lr=0.0100
[2025-05-07 01:07:50,989][train][INFO] - Epoch 465/2000, Val Acc=0.5987, Val Loss=1.7652, lr=0.0100
[2025-05-07 01:07:53,627][train][INFO] - Epoch 466/2000, Val Acc=0.5868, Val Loss=1.6350, lr=0.0100
[2025-05-07 01:07:56,303][train][INFO] - Epoch 462/2000, Val Acc=0.6082, Val Loss=1.7288, lr=0.0100
[2025-05-07 01:07:58,628][train][INFO] - Epoch 466/2000, Val Acc=0.5841, Val Loss=1.8179, lr=0.0100
[2025-05-07 01:08:01,028][train][INFO] - Epoch 467/2000, Val Acc=0.5871, Val Loss=1.6187, lr=0.0100
[2025-05-07 01:08:04,074][train][INFO] - Epoch 463/2000, Val Acc=0.6078, Val Loss=1.6919, lr=0.0100
[2025-05-07 01:08:06,264][train][INFO] - Epoch 467/2000, Val Acc=0.6142, Val Loss=1.6900, lr=0.0100
[2025-05-07 01:08:08,671][train][INFO] - Epoch 468/2000, Val Acc=0.5888, Val Loss=1.6312, lr=0.0100
[2025-05-07 01:08:11,795][train][INFO] - Epoch 464/2000, Val Acc=0.5788, Val Loss=1.8482, lr=0.0100
[2025-05-07 01:08:13,949][train][INFO] - Epoch 468/2000, Val Acc=0.5940, Val Loss=1.8575, lr=0.0100
[2025-05-07 01:08:16,912][train][INFO] - Epoch 469/2000, Val Acc=0.5792, Val Loss=1.6984, lr=0.0100
[2025-05-07 01:08:19,361][train][INFO] - Epoch 465/2000, Val Acc=0.5987, Val Loss=1.7652, lr=0.0100
[2025-05-07 01:08:21,446][train][INFO] - Epoch 469/2000, Val Acc=0.6043, Val Loss=1.7277, lr=0.0100
[2025-05-07 01:08:24,850][train][INFO] - Epoch 470/2000, Val Acc=0.5733, Val Loss=1.7265, lr=0.0100
[2025-05-07 01:08:26,379][train][INFO] - Epoch 466/2000, Val Acc=0.5841, Val Loss=1.8179, lr=0.0100
[2025-05-07 01:08:28,852][train][INFO] - Epoch 470/2000, Val Acc=0.6099, Val Loss=1.7044, lr=0.0100
[2025-05-07 01:08:32,600][train][INFO] - Epoch 471/2000, Val Acc=0.5855, Val Loss=1.6677, lr=0.0100
[2025-05-07 01:08:34,315][train][INFO] - Epoch 467/2000, Val Acc=0.6142, Val Loss=1.6900, lr=0.0100
[2025-05-07 01:08:36,402][train][INFO] - Epoch 471/2000, Val Acc=0.5992, Val Loss=1.7974, lr=0.0100
[2025-05-07 01:08:39,949][train][INFO] - Epoch 472/2000, Val Acc=0.5890, Val Loss=1.6816, lr=0.0100
[2025-05-07 01:08:41,357][train][INFO] - Epoch 468/2000, Val Acc=0.5940, Val Loss=1.8575, lr=0.0100
[2025-05-07 01:08:43,947][train][INFO] - Epoch 472/2000, Val Acc=0.6137, Val Loss=1.6684, lr=0.0100
[2025-05-07 01:08:47,508][train][INFO] - Epoch 473/2000, Val Acc=0.5839, Val Loss=1.6546, lr=0.0100
[2025-05-07 01:08:48,801][train][INFO] - Epoch 469/2000, Val Acc=0.6043, Val Loss=1.7277, lr=0.0100
[2025-05-07 01:08:50,942][train][INFO] - Epoch 473/2000, Val Acc=0.6172, Val Loss=1.6627, lr=0.0100
[2025-05-07 01:08:55,604][train][INFO] - Epoch 474/2000, Val Acc=0.5722, Val Loss=1.7545, lr=0.0100
[2025-05-07 01:08:56,843][train][INFO] - Epoch 470/2000, Val Acc=0.6099, Val Loss=1.7044, lr=0.0100
[2025-05-07 01:08:58,462][train][INFO] - Epoch 474/2000, Val Acc=0.6001, Val Loss=1.7322, lr=0.0100
[2025-05-07 01:09:03,627][train][INFO] - Epoch 475/2000, Val Acc=0.5796, Val Loss=1.6945, lr=0.0100
[2025-05-07 01:09:04,921][train][INFO] - Epoch 471/2000, Val Acc=0.5992, Val Loss=1.7974, lr=0.0100
[2025-05-07 01:09:06,314][train][INFO] - Epoch 475/2000, Val Acc=0.5931, Val Loss=1.7645, lr=0.0100
[2025-05-07 01:09:11,185][train][INFO] - Epoch 476/2000, Val Acc=0.5995, Val Loss=1.5967, lr=0.0100
[2025-05-07 01:09:12,967][train][INFO] - Epoch 472/2000, Val Acc=0.6137, Val Loss=1.6684, lr=0.0100
[2025-05-07 01:09:13,971][train][INFO] - Epoch 476/2000, Val Acc=0.5891, Val Loss=1.8226, lr=0.0100
[2025-05-07 01:09:19,136][train][INFO] - Epoch 477/2000, Val Acc=0.5895, Val Loss=1.6455, lr=0.0100
[2025-05-07 01:09:20,637][train][INFO] - Epoch 473/2000, Val Acc=0.6172, Val Loss=1.6627, lr=0.0100
[2025-05-07 01:09:21,800][train][INFO] - Epoch 477/2000, Val Acc=0.5831, Val Loss=1.8619, lr=0.0100
[2025-05-07 01:09:26,767][train][INFO] - Epoch 478/2000, Val Acc=0.5712, Val Loss=1.7691, lr=0.0100
[2025-05-07 01:09:29,022][train][INFO] - Epoch 474/2000, Val Acc=0.6001, Val Loss=1.7322, lr=0.0100
[2025-05-07 01:09:29,684][train][INFO] - Epoch 478/2000, Val Acc=0.6130, Val Loss=1.6755, lr=0.0100
[2025-05-07 01:09:34,005][train][INFO] - Epoch 479/2000, Val Acc=0.5776, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:09:36,492][train][INFO] - Epoch 475/2000, Val Acc=0.5931, Val Loss=1.7645, lr=0.0100
[2025-05-07 01:09:37,154][train][INFO] - Epoch 479/2000, Val Acc=0.6020, Val Loss=1.7975, lr=0.0100
[2025-05-07 01:09:41,814][train][INFO] - Epoch 480/2000, Val Acc=0.5965, Val Loss=1.6555, lr=0.0100
[2025-05-07 01:09:44,407][train][INFO] - Epoch 480/2000, Val Acc=0.6016, Val Loss=1.7192, lr=0.0100
[2025-05-07 01:09:44,734][train][INFO] - Epoch 476/2000, Val Acc=0.5891, Val Loss=1.8226, lr=0.0100
[2025-05-07 01:09:49,539][train][INFO] - Epoch 481/2000, Val Acc=0.5549, Val Loss=1.7758, lr=0.0100
[2025-05-07 01:09:51,818][train][INFO] - Epoch 477/2000, Val Acc=0.5831, Val Loss=1.8619, lr=0.0100
[2025-05-07 01:09:52,137][train][INFO] - Epoch 481/2000, Val Acc=0.5911, Val Loss=1.7676, lr=0.0100
[2025-05-07 01:09:57,008][train][INFO] - Epoch 482/2000, Val Acc=0.5785, Val Loss=1.7127, lr=0.0100
[2025-05-07 01:09:59,831][train][INFO] - Epoch 482/2000, Val Acc=0.6180, Val Loss=1.6864, lr=0.0100
[2025-05-07 01:10:00,028][train][INFO] - Epoch 478/2000, Val Acc=0.6130, Val Loss=1.6755, lr=0.0100
[2025-05-07 01:10:04,836][train][INFO] - Epoch 483/2000, Val Acc=0.5866, Val Loss=1.6901, lr=0.0100
[2025-05-07 01:10:07,645][train][INFO] - Epoch 483/2000, Val Acc=0.6027, Val Loss=1.7529, lr=0.0100
[2025-05-07 01:10:08,139][train][INFO] - Epoch 479/2000, Val Acc=0.6020, Val Loss=1.7975, lr=0.0100
[2025-05-07 01:10:12,665][train][INFO] - Epoch 484/2000, Val Acc=0.5645, Val Loss=1.7615, lr=0.0100
[2025-05-07 01:10:15,235][train][INFO] - Epoch 484/2000, Val Acc=0.6033, Val Loss=1.7144, lr=0.0100
[2025-05-07 01:10:15,567][train][INFO] - Epoch 480/2000, Val Acc=0.6016, Val Loss=1.7192, lr=0.0100
[2025-05-07 01:10:20,160][train][INFO] - Epoch 485/2000, Val Acc=0.5898, Val Loss=1.6095, lr=0.0100
[2025-05-07 01:10:22,792][train][INFO] - Epoch 485/2000, Val Acc=0.6032, Val Loss=1.7582, lr=0.0100
[2025-05-07 01:10:23,379][train][INFO] - Epoch 481/2000, Val Acc=0.5911, Val Loss=1.7676, lr=0.0100
[2025-05-07 01:10:27,688][train][INFO] - Epoch 486/2000, Val Acc=0.5580, Val Loss=1.8270, lr=0.0100
[2025-05-07 01:10:30,263][train][INFO] - Epoch 482/2000, Val Acc=0.6180, Val Loss=1.6864, lr=0.0100
[2025-05-07 01:10:30,380][train][INFO] - Epoch 486/2000, Val Acc=0.6129, Val Loss=1.6636, lr=0.0100
[2025-05-07 01:10:35,301][train][INFO] - Epoch 487/2000, Val Acc=0.5855, Val Loss=1.6750, lr=0.0100
[2025-05-07 01:10:38,344][train][INFO] - Epoch 487/2000, Val Acc=0.5980, Val Loss=1.7834, lr=0.0100
[2025-05-07 01:10:38,367][train][INFO] - Epoch 483/2000, Val Acc=0.6027, Val Loss=1.7529, lr=0.0100
[2025-05-07 01:10:43,333][train][INFO] - Epoch 488/2000, Val Acc=0.5924, Val Loss=1.6154, lr=0.0100
[2025-05-07 01:10:46,004][train][INFO] - Epoch 488/2000, Val Acc=0.5972, Val Loss=1.7553, lr=0.0100
[2025-05-07 01:10:46,440][train][INFO] - Epoch 484/2000, Val Acc=0.6033, Val Loss=1.7144, lr=0.0100
[2025-05-07 01:10:51,317][train][INFO] - Epoch 489/2000, Val Acc=0.5768, Val Loss=1.7254, lr=0.0100
[2025-05-07 01:10:54,006][train][INFO] - Epoch 489/2000, Val Acc=0.6158, Val Loss=1.6630, lr=0.0100
[2025-05-07 01:10:54,221][train][INFO] - Epoch 485/2000, Val Acc=0.6032, Val Loss=1.7582, lr=0.0100
[2025-05-07 01:10:58,785][train][INFO] - Epoch 490/2000, Val Acc=0.5917, Val Loss=1.6538, lr=0.0100
[2025-05-07 01:11:01,838][train][INFO] - Epoch 490/2000, Val Acc=0.5995, Val Loss=1.7988, lr=0.0100
[2025-05-07 01:11:02,029][train][INFO] - Epoch 486/2000, Val Acc=0.6129, Val Loss=1.6636, lr=0.0100
[2025-05-07 01:11:06,484][train][INFO] - Epoch 491/2000, Val Acc=0.5669, Val Loss=1.7599, lr=0.0100
[2025-05-07 01:11:09,046][train][INFO] - Epoch 491/2000, Val Acc=0.5988, Val Loss=1.8336, lr=0.0100
[2025-05-07 01:11:09,940][train][INFO] - Epoch 487/2000, Val Acc=0.5980, Val Loss=1.7834, lr=0.0100
[2025-05-07 01:11:14,068][train][INFO] - Epoch 492/2000, Val Acc=0.5902, Val Loss=1.6271, lr=0.0100
[2025-05-07 01:11:16,575][train][INFO] - Epoch 492/2000, Val Acc=0.6035, Val Loss=1.7189, lr=0.0100
[2025-05-07 01:11:17,206][train][INFO] - Epoch 488/2000, Val Acc=0.5972, Val Loss=1.7553, lr=0.0100
[2025-05-07 01:11:21,774][train][INFO] - Epoch 493/2000, Val Acc=0.5907, Val Loss=1.6448, lr=0.0100
[2025-05-07 01:11:24,357][train][INFO] - Epoch 493/2000, Val Acc=0.6098, Val Loss=1.6786, lr=0.0100
[2025-05-07 01:11:25,084][train][INFO] - Epoch 489/2000, Val Acc=0.6158, Val Loss=1.6630, lr=0.0100
[2025-05-07 01:11:29,770][train][INFO] - Epoch 494/2000, Val Acc=0.5647, Val Loss=1.7686, lr=0.0100
[2025-05-07 01:11:31,705][train][INFO] - Epoch 494/2000, Val Acc=0.6009, Val Loss=1.7624, lr=0.0100
[2025-05-07 01:11:32,597][train][INFO] - Epoch 490/2000, Val Acc=0.5995, Val Loss=1.7988, lr=0.0100
[2025-05-07 01:11:37,778][train][INFO] - Epoch 495/2000, Val Acc=0.5907, Val Loss=1.6425, lr=0.0100
[2025-05-07 01:11:39,376][train][INFO] - Epoch 495/2000, Val Acc=0.6079, Val Loss=1.7246, lr=0.0100
[2025-05-07 01:11:40,387][train][INFO] - Epoch 491/2000, Val Acc=0.5988, Val Loss=1.8336, lr=0.0100
[2025-05-07 01:11:45,447][train][INFO] - Epoch 496/2000, Val Acc=0.5843, Val Loss=1.7170, lr=0.0100
[2025-05-07 01:11:46,933][train][INFO] - Epoch 496/2000, Val Acc=0.6036, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:11:48,129][train][INFO] - Epoch 492/2000, Val Acc=0.6035, Val Loss=1.7189, lr=0.0100
[2025-05-07 01:11:53,401][train][INFO] - Epoch 497/2000, Val Acc=0.5674, Val Loss=1.7697, lr=0.0100
[2025-05-07 01:11:54,810][train][INFO] - Epoch 497/2000, Val Acc=0.6106, Val Loss=1.7213, lr=0.0100
[2025-05-07 01:11:56,321][train][INFO] - Epoch 493/2000, Val Acc=0.6098, Val Loss=1.6786, lr=0.0100
[2025-05-07 01:12:00,941][train][INFO] - Epoch 498/2000, Val Acc=0.5825, Val Loss=1.7273, lr=0.0100
[2025-05-07 01:12:02,454][train][INFO] - Epoch 498/2000, Val Acc=0.6150, Val Loss=1.6671, lr=0.0100
[2025-05-07 01:12:04,019][train][INFO] - Epoch 494/2000, Val Acc=0.6009, Val Loss=1.7624, lr=0.0100
[2025-05-07 01:12:08,847][train][INFO] - Epoch 499/2000, Val Acc=0.5556, Val Loss=1.8002, lr=0.0100
[2025-05-07 01:12:09,844][train][INFO] - Epoch 499/2000, Val Acc=0.6093, Val Loss=1.7248, lr=0.0100
[2025-05-07 01:12:11,532][train][INFO] - Epoch 495/2000, Val Acc=0.6079, Val Loss=1.7246, lr=0.0100
[2025-05-07 01:12:16,813][train][INFO] - Epoch 500/2000, Val Acc=0.5731, Val Loss=1.7201, lr=0.0100
[2025-05-07 01:12:17,098][train][INFO] - Epoch 500/2000, Val Acc=0.6180, Val Loss=1.6427, lr=0.0100
[2025-05-07 01:12:19,249][train][INFO] - Epoch 496/2000, Val Acc=0.6036, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:12:24,657][train][INFO] - Epoch 501/2000, Val Acc=0.5683, Val Loss=1.7623, lr=0.0100
[2025-05-07 01:12:24,830][train][INFO] - Epoch 501/2000, Val Acc=0.6263, Val Loss=1.6046, lr=0.0100
[2025-05-07 01:12:27,113][train][INFO] - Epoch 497/2000, Val Acc=0.6106, Val Loss=1.7213, lr=0.0100
[2025-05-07 01:12:31,885][train][INFO] - Epoch 502/2000, Val Acc=0.5777, Val Loss=1.7065, lr=0.0100
[2025-05-07 01:12:32,098][train][INFO] - Epoch 502/2000, Val Acc=0.6132, Val Loss=1.6769, lr=0.0100
[2025-05-07 01:12:35,241][train][INFO] - Epoch 498/2000, Val Acc=0.6150, Val Loss=1.6671, lr=0.0100
[2025-05-07 01:12:39,415][train][INFO] - Epoch 503/2000, Val Acc=0.6166, Val Loss=1.6450, lr=0.0100
[2025-05-07 01:12:39,637][train][INFO] - Epoch 503/2000, Val Acc=0.5960, Val Loss=1.5902, lr=0.0100
[2025-05-07 01:12:43,442][train][INFO] - Epoch 499/2000, Val Acc=0.6093, Val Loss=1.7248, lr=0.0100
[2025-05-07 01:12:47,223][train][INFO] - Epoch 504/2000, Val Acc=0.6095, Val Loss=1.7084, lr=0.0100
[2025-05-07 01:12:47,498][train][INFO] - Epoch 504/2000, Val Acc=0.5906, Val Loss=1.6569, lr=0.0100
[2025-05-07 01:12:51,533][train][INFO] - Epoch 500/2000, Val Acc=0.6180, Val Loss=1.6427, lr=0.0100
[2025-05-07 01:12:55,048][train][INFO] - Epoch 505/2000, Val Acc=0.6133, Val Loss=1.7214, lr=0.0100
[2025-05-07 01:12:55,064][train][INFO] - Epoch 505/2000, Val Acc=0.5782, Val Loss=1.6865, lr=0.0100
[2025-05-07 01:12:59,429][train][INFO] - Epoch 501/2000, Val Acc=0.6263, Val Loss=1.6046, lr=0.0100
[2025-05-07 01:13:03,165][train][INFO] - Epoch 506/2000, Val Acc=0.5874, Val Loss=1.6681, lr=0.0100
[2025-05-07 01:13:03,173][train][INFO] - Epoch 506/2000, Val Acc=0.6079, Val Loss=1.6985, lr=0.0100
[2025-05-07 01:13:07,549][train][INFO] - Epoch 502/2000, Val Acc=0.6132, Val Loss=1.6769, lr=0.0100
[2025-05-07 01:13:11,148][train][INFO] - Epoch 507/2000, Val Acc=0.5965, Val Loss=1.6044, lr=0.0100
[2025-05-07 01:13:11,322][train][INFO] - Epoch 507/2000, Val Acc=0.6120, Val Loss=1.7026, lr=0.0100
[2025-05-07 01:13:15,719][train][INFO] - Epoch 503/2000, Val Acc=0.6166, Val Loss=1.6450, lr=0.0100
[2025-05-07 01:13:19,034][train][INFO] - Epoch 508/2000, Val Acc=0.5787, Val Loss=1.7173, lr=0.0100
[2025-05-07 01:13:19,144][train][INFO] - Epoch 508/2000, Val Acc=0.5944, Val Loss=1.7907, lr=0.0100
[2025-05-07 01:13:23,201][train][INFO] - Epoch 504/2000, Val Acc=0.6095, Val Loss=1.7084, lr=0.0100
[2025-05-07 01:13:26,674][train][INFO] - Epoch 509/2000, Val Acc=0.5915, Val Loss=1.6214, lr=0.0100
[2025-05-07 01:13:26,796][train][INFO] - Epoch 509/2000, Val Acc=0.6049, Val Loss=1.7292, lr=0.0100
[2025-05-07 01:13:31,154][train][INFO] - Epoch 505/2000, Val Acc=0.6133, Val Loss=1.7214, lr=0.0100
[2025-05-07 01:13:34,135][train][INFO] - Epoch 510/2000, Val Acc=0.5700, Val Loss=1.7458, lr=0.0100
[2025-05-07 01:13:34,478][train][INFO] - Epoch 510/2000, Val Acc=0.6122, Val Loss=1.7231, lr=0.0100
[2025-05-07 01:13:38,813][train][INFO] - Epoch 506/2000, Val Acc=0.6079, Val Loss=1.6985, lr=0.0100
[2025-05-07 01:13:41,674][train][INFO] - Epoch 511/2000, Val Acc=0.6142, Val Loss=1.6765, lr=0.0100
[2025-05-07 01:13:41,928][train][INFO] - Epoch 511/2000, Val Acc=0.5731, Val Loss=1.7309, lr=0.0100
[2025-05-07 01:13:46,627][train][INFO] - Epoch 507/2000, Val Acc=0.6120, Val Loss=1.7026, lr=0.0100
[2025-05-07 01:13:49,244][train][INFO] - Epoch 512/2000, Val Acc=0.5531, Val Loss=1.8761, lr=0.0100
[2025-05-07 01:13:49,541][train][INFO] - Epoch 512/2000, Val Acc=0.6160, Val Loss=1.6840, lr=0.0100
[2025-05-07 01:13:54,869][train][INFO] - Epoch 508/2000, Val Acc=0.5944, Val Loss=1.7907, lr=0.0100
[2025-05-07 01:13:57,192][train][INFO] - Epoch 513/2000, Val Acc=0.6076, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:13:57,284][train][INFO] - Epoch 513/2000, Val Acc=0.5837, Val Loss=1.7212, lr=0.0100
[2025-05-07 01:14:03,083][train][INFO] - Epoch 509/2000, Val Acc=0.6049, Val Loss=1.7292, lr=0.0100
[2025-05-07 01:14:05,074][train][INFO] - Epoch 514/2000, Val Acc=0.5962, Val Loss=1.7988, lr=0.0100
[2025-05-07 01:14:05,289][train][INFO] - Epoch 514/2000, Val Acc=0.5794, Val Loss=1.6877, lr=0.0100
[2025-05-07 01:14:10,855][train][INFO] - Epoch 510/2000, Val Acc=0.6122, Val Loss=1.7231, lr=0.0100
[2025-05-07 01:14:12,663][train][INFO] - Epoch 515/2000, Val Acc=0.5920, Val Loss=1.8389, lr=0.0100
[2025-05-07 01:14:13,371][train][INFO] - Epoch 515/2000, Val Acc=0.5820, Val Loss=1.7038, lr=0.0100
[2025-05-07 01:14:18,651][train][INFO] - Epoch 511/2000, Val Acc=0.6142, Val Loss=1.6765, lr=0.0100
[2025-05-07 01:14:20,655][train][INFO] - Epoch 516/2000, Val Acc=0.5785, Val Loss=1.9062, lr=0.0100
[2025-05-07 01:14:21,021][train][INFO] - Epoch 516/2000, Val Acc=0.6008, Val Loss=1.6072, lr=0.0100
[2025-05-07 01:14:26,396][train][INFO] - Epoch 512/2000, Val Acc=0.6160, Val Loss=1.6840, lr=0.0100
[2025-05-07 01:14:28,314][train][INFO] - Epoch 517/2000, Val Acc=0.5990, Val Loss=1.7363, lr=0.0100
[2025-05-07 01:14:28,598][train][INFO] - Epoch 517/2000, Val Acc=0.5792, Val Loss=1.6792, lr=0.0100
[2025-05-07 01:14:34,687][train][INFO] - Epoch 513/2000, Val Acc=0.6076, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:14:35,538][train][INFO] - Epoch 518/2000, Val Acc=0.6086, Val Loss=1.6869, lr=0.0100
[2025-05-07 01:14:35,919][train][INFO] - Epoch 518/2000, Val Acc=0.5834, Val Loss=1.6695, lr=0.0100
[2025-05-07 01:14:42,410][train][INFO] - Epoch 514/2000, Val Acc=0.5962, Val Loss=1.7988, lr=0.0100
[2025-05-07 01:14:43,330][train][INFO] - Epoch 519/2000, Val Acc=0.5782, Val Loss=1.7026, lr=0.0100
[2025-05-07 01:14:43,452][train][INFO] - Epoch 519/2000, Val Acc=0.5950, Val Loss=1.8087, lr=0.0100
[2025-05-07 01:14:50,401][train][INFO] - Epoch 515/2000, Val Acc=0.5920, Val Loss=1.8389, lr=0.0100
[2025-05-07 01:14:50,969][train][INFO] - Epoch 520/2000, Val Acc=0.6189, Val Loss=1.6582, lr=0.0100
[2025-05-07 01:14:51,323][train][INFO] - Epoch 520/2000, Val Acc=0.5672, Val Loss=1.7782, lr=0.0100
[2025-05-07 01:14:58,004][train][INFO] - Epoch 516/2000, Val Acc=0.5785, Val Loss=1.9062, lr=0.0100
[2025-05-07 01:14:58,888][train][INFO] - Epoch 521/2000, Val Acc=0.6004, Val Loss=1.7690, lr=0.0100
[2025-05-07 01:14:59,226][train][INFO] - Epoch 521/2000, Val Acc=0.5862, Val Loss=1.6685, lr=0.0100
[2025-05-07 01:15:05,820][train][INFO] - Epoch 517/2000, Val Acc=0.5990, Val Loss=1.7363, lr=0.0100
[2025-05-07 01:15:06,899][train][INFO] - Epoch 522/2000, Val Acc=0.6047, Val Loss=1.7455, lr=0.0100
[2025-05-07 01:15:06,959][train][INFO] - Epoch 522/2000, Val Acc=0.5895, Val Loss=1.6753, lr=0.0100
[2025-05-07 01:15:13,409][train][INFO] - Epoch 518/2000, Val Acc=0.6086, Val Loss=1.6869, lr=0.0100
[2025-05-07 01:15:14,572][train][INFO] - Epoch 523/2000, Val Acc=0.6195, Val Loss=1.6582, lr=0.0100
[2025-05-07 01:15:14,672][train][INFO] - Epoch 523/2000, Val Acc=0.5851, Val Loss=1.6561, lr=0.0100
[2025-05-07 01:15:21,444][train][INFO] - Epoch 519/2000, Val Acc=0.5950, Val Loss=1.8087, lr=0.0100
[2025-05-07 01:15:21,973][train][INFO] - Epoch 524/2000, Val Acc=0.5975, Val Loss=1.7434, lr=0.0100
[2025-05-07 01:15:22,130][train][INFO] - Epoch 524/2000, Val Acc=0.5747, Val Loss=1.7167, lr=0.0100
[2025-05-07 01:15:29,543][train][INFO] - Epoch 525/2000, Val Acc=0.6087, Val Loss=1.6910, lr=0.0100
[2025-05-07 01:15:29,561][train][INFO] - Epoch 520/2000, Val Acc=0.6189, Val Loss=1.6582, lr=0.0100
[2025-05-07 01:15:30,100][train][INFO] - Epoch 525/2000, Val Acc=0.5877, Val Loss=1.6658, lr=0.0100
[2025-05-07 01:15:37,128][train][INFO] - Epoch 526/2000, Val Acc=0.6032, Val Loss=1.7565, lr=0.0100
[2025-05-07 01:15:37,615][train][INFO] - Epoch 521/2000, Val Acc=0.6004, Val Loss=1.7690, lr=0.0100
[2025-05-07 01:15:37,882][train][INFO] - Epoch 526/2000, Val Acc=0.5640, Val Loss=1.8038, lr=0.0100
[2025-05-07 01:15:44,827][train][INFO] - Epoch 527/2000, Val Acc=0.6167, Val Loss=1.6977, lr=0.0100
[2025-05-07 01:15:45,653][train][INFO] - Epoch 522/2000, Val Acc=0.6047, Val Loss=1.7455, lr=0.0100
[2025-05-07 01:15:45,985][train][INFO] - Epoch 527/2000, Val Acc=0.6029, Val Loss=1.5882, lr=0.0100
[2025-05-07 01:15:53,110][train][INFO] - Epoch 528/2000, Val Acc=0.6063, Val Loss=1.7346, lr=0.0100
[2025-05-07 01:15:53,515][train][INFO] - Epoch 523/2000, Val Acc=0.6195, Val Loss=1.6582, lr=0.0100
[2025-05-07 01:15:53,739][train][INFO] - Epoch 528/2000, Val Acc=0.5690, Val Loss=1.7750, lr=0.0100
[2025-05-07 01:16:01,000][train][INFO] - Epoch 529/2000, Val Acc=0.5990, Val Loss=1.7537, lr=0.0100
[2025-05-07 01:16:01,265][train][INFO] - Epoch 529/2000, Val Acc=0.5775, Val Loss=1.7254, lr=0.0100
[2025-05-07 01:16:01,339][train][INFO] - Epoch 524/2000, Val Acc=0.5975, Val Loss=1.7434, lr=0.0100
[2025-05-07 01:16:08,722][train][INFO] - Epoch 530/2000, Val Acc=0.6004, Val Loss=1.7921, lr=0.0100
[2025-05-07 01:16:09,049][train][INFO] - Epoch 530/2000, Val Acc=0.5613, Val Loss=1.7982, lr=0.0100
[2025-05-07 01:16:09,811][train][INFO] - Epoch 525/2000, Val Acc=0.6087, Val Loss=1.6910, lr=0.0100
[2025-05-07 01:16:16,506][train][INFO] - Epoch 531/2000, Val Acc=0.6089, Val Loss=1.7265, lr=0.0100
[2025-05-07 01:16:16,640][train][INFO] - Epoch 531/2000, Val Acc=0.5697, Val Loss=1.7834, lr=0.0100
[2025-05-07 01:16:17,688][train][INFO] - Epoch 526/2000, Val Acc=0.6032, Val Loss=1.7565, lr=0.0100
[2025-05-07 01:16:23,633][train][INFO] - Epoch 532/2000, Val Acc=0.5917, Val Loss=1.8047, lr=0.0100
[2025-05-07 01:16:24,317][train][INFO] - Epoch 532/2000, Val Acc=0.5888, Val Loss=1.6354, lr=0.0100
[2025-05-07 01:16:25,106][train][INFO] - Epoch 527/2000, Val Acc=0.6167, Val Loss=1.6977, lr=0.0100
[2025-05-07 01:16:31,106][train][INFO] - Epoch 533/2000, Val Acc=0.6207, Val Loss=1.6824, lr=0.0100
[2025-05-07 01:16:31,905][train][INFO] - Epoch 533/2000, Val Acc=0.5973, Val Loss=1.6229, lr=0.0100
[2025-05-07 01:16:32,869][train][INFO] - Epoch 528/2000, Val Acc=0.6063, Val Loss=1.7346, lr=0.0100
[2025-05-07 01:16:38,688][train][INFO] - Epoch 534/2000, Val Acc=0.5994, Val Loss=1.7298, lr=0.0100
[2025-05-07 01:16:39,864][train][INFO] - Epoch 534/2000, Val Acc=0.5697, Val Loss=1.7818, lr=0.0100
[2025-05-07 01:16:40,386][train][INFO] - Epoch 529/2000, Val Acc=0.5990, Val Loss=1.7537, lr=0.0100
[2025-05-07 01:16:46,447][train][INFO] - Epoch 535/2000, Val Acc=0.6136, Val Loss=1.6778, lr=0.0100
[2025-05-07 01:16:47,619][train][INFO] - Epoch 535/2000, Val Acc=0.5755, Val Loss=1.7291, lr=0.0100
[2025-05-07 01:16:48,300][train][INFO] - Epoch 530/2000, Val Acc=0.6004, Val Loss=1.7921, lr=0.0100
[2025-05-07 01:16:54,195][train][INFO] - Epoch 536/2000, Val Acc=0.6162, Val Loss=1.6790, lr=0.0100
[2025-05-07 01:16:55,585][train][INFO] - Epoch 536/2000, Val Acc=0.5705, Val Loss=1.7610, lr=0.0100
[2025-05-07 01:16:56,225][train][INFO] - Epoch 531/2000, Val Acc=0.6089, Val Loss=1.7265, lr=0.0100
[2025-05-07 01:17:02,179][train][INFO] - Epoch 537/2000, Val Acc=0.5961, Val Loss=1.7832, lr=0.0100
[2025-05-07 01:17:03,402][train][INFO] - Epoch 537/2000, Val Acc=0.5873, Val Loss=1.6529, lr=0.0100
[2025-05-07 01:17:04,139][train][INFO] - Epoch 532/2000, Val Acc=0.5917, Val Loss=1.8047, lr=0.0100
[2025-05-07 01:17:10,036][train][INFO] - Epoch 538/2000, Val Acc=0.6142, Val Loss=1.6705, lr=0.0100
[2025-05-07 01:17:11,183][train][INFO] - Epoch 538/2000, Val Acc=0.5782, Val Loss=1.7397, lr=0.0100
[2025-05-07 01:17:11,697][train][INFO] - Epoch 533/2000, Val Acc=0.6207, Val Loss=1.6824, lr=0.0100
[2025-05-07 01:17:17,756][train][INFO] - Epoch 539/2000, Val Acc=0.6170, Val Loss=1.6594, lr=0.0100
[2025-05-07 01:17:18,751][train][INFO] - Epoch 539/2000, Val Acc=0.5847, Val Loss=1.6644, lr=0.0100
[2025-05-07 01:17:19,835][train][INFO] - Epoch 534/2000, Val Acc=0.5994, Val Loss=1.7298, lr=0.0100
[2025-05-07 01:17:25,539][train][INFO] - Epoch 540/2000, Val Acc=0.6044, Val Loss=1.7343, lr=0.0100
[2025-05-07 01:17:26,440][train][INFO] - Epoch 540/2000, Val Acc=0.5910, Val Loss=1.6726, lr=0.0100
[2025-05-07 01:17:27,281][train][INFO] - Epoch 535/2000, Val Acc=0.6136, Val Loss=1.6778, lr=0.0100
[2025-05-07 01:17:33,080][train][INFO] - Epoch 541/2000, Val Acc=0.6083, Val Loss=1.7321, lr=0.0100
[2025-05-07 01:17:34,370][train][INFO] - Epoch 541/2000, Val Acc=0.5691, Val Loss=1.7716, lr=0.0100
[2025-05-07 01:17:35,363][train][INFO] - Epoch 536/2000, Val Acc=0.6162, Val Loss=1.6790, lr=0.0100
[2025-05-07 01:17:40,596][train][INFO] - Epoch 542/2000, Val Acc=0.6174, Val Loss=1.6886, lr=0.0100
[2025-05-07 01:17:42,243][train][INFO] - Epoch 542/2000, Val Acc=0.5917, Val Loss=1.6564, lr=0.0100
[2025-05-07 01:17:43,073][train][INFO] - Epoch 537/2000, Val Acc=0.5961, Val Loss=1.7832, lr=0.0100
[2025-05-07 01:17:48,113][train][INFO] - Epoch 543/2000, Val Acc=0.6012, Val Loss=1.7643, lr=0.0100
[2025-05-07 01:17:49,928][train][INFO] - Epoch 543/2000, Val Acc=0.5704, Val Loss=1.7555, lr=0.0100
[2025-05-07 01:17:51,003][train][INFO] - Epoch 538/2000, Val Acc=0.6142, Val Loss=1.6705, lr=0.0100
[2025-05-07 01:17:55,546][train][INFO] - Epoch 544/2000, Val Acc=0.6077, Val Loss=1.7273, lr=0.0100
[2025-05-07 01:17:57,987][train][INFO] - Epoch 544/2000, Val Acc=0.5893, Val Loss=1.6427, lr=0.0100
[2025-05-07 01:17:59,284][train][INFO] - Epoch 539/2000, Val Acc=0.6170, Val Loss=1.6594, lr=0.0100
[2025-05-07 01:18:03,110][train][INFO] - Epoch 545/2000, Val Acc=0.5923, Val Loss=1.8209, lr=0.0100
[2025-05-07 01:18:05,964][train][INFO] - Epoch 545/2000, Val Acc=0.5883, Val Loss=1.6786, lr=0.0100
[2025-05-07 01:18:07,468][train][INFO] - Epoch 540/2000, Val Acc=0.6044, Val Loss=1.7343, lr=0.0100
[2025-05-07 01:18:10,621][train][INFO] - Epoch 546/2000, Val Acc=0.6143, Val Loss=1.6674, lr=0.0100
[2025-05-07 01:18:13,886][train][INFO] - Epoch 546/2000, Val Acc=0.5838, Val Loss=1.6888, lr=0.0100
[2025-05-07 01:18:15,114][train][INFO] - Epoch 541/2000, Val Acc=0.6083, Val Loss=1.7321, lr=0.0100
[2025-05-07 01:18:18,065][train][INFO] - Epoch 547/2000, Val Acc=0.5898, Val Loss=1.8193, lr=0.0100
[2025-05-07 01:18:21,970][train][INFO] - Epoch 547/2000, Val Acc=0.5821, Val Loss=1.6957, lr=0.0100
[2025-05-07 01:18:22,945][train][INFO] - Epoch 542/2000, Val Acc=0.6174, Val Loss=1.6886, lr=0.0100
[2025-05-07 01:18:25,511][train][INFO] - Epoch 548/2000, Val Acc=0.5801, Val Loss=1.9159, lr=0.0100
[2025-05-07 01:18:29,714][train][INFO] - Epoch 548/2000, Val Acc=0.5870, Val Loss=1.7163, lr=0.0100
[2025-05-07 01:18:31,056][train][INFO] - Epoch 543/2000, Val Acc=0.6012, Val Loss=1.7643, lr=0.0100
[2025-05-07 01:18:32,825][train][INFO] - Epoch 549/2000, Val Acc=0.6151, Val Loss=1.6596, lr=0.0100
[2025-05-07 01:18:37,689][train][INFO] - Epoch 549/2000, Val Acc=0.5779, Val Loss=1.7449, lr=0.0100
[2025-05-07 01:18:38,977][train][INFO] - Epoch 544/2000, Val Acc=0.6077, Val Loss=1.7273, lr=0.0100
[2025-05-07 01:18:40,385][train][INFO] - Epoch 550/2000, Val Acc=0.6006, Val Loss=1.7927, lr=0.0100
[2025-05-07 01:18:45,664][train][INFO] - Epoch 550/2000, Val Acc=0.5839, Val Loss=1.6723, lr=0.0100
[2025-05-07 01:18:46,978][train][INFO] - Epoch 545/2000, Val Acc=0.5923, Val Loss=1.8209, lr=0.0100
[2025-05-07 01:18:48,162][train][INFO] - Epoch 551/2000, Val Acc=0.6043, Val Loss=1.7342, lr=0.0100
[2025-05-07 01:18:53,504][train][INFO] - Epoch 551/2000, Val Acc=0.5856, Val Loss=1.6835, lr=0.0100
[2025-05-07 01:18:55,027][train][INFO] - Epoch 546/2000, Val Acc=0.6143, Val Loss=1.6674, lr=0.0100
[2025-05-07 01:18:56,071][train][INFO] - Epoch 552/2000, Val Acc=0.6022, Val Loss=1.7583, lr=0.0100
[2025-05-07 01:19:01,361][train][INFO] - Epoch 552/2000, Val Acc=0.5740, Val Loss=1.6951, lr=0.0100
[2025-05-07 01:19:02,934][train][INFO] - Epoch 547/2000, Val Acc=0.5898, Val Loss=1.8193, lr=0.0100
[2025-05-07 01:19:03,917][train][INFO] - Epoch 553/2000, Val Acc=0.6026, Val Loss=1.7520, lr=0.0100
[2025-05-07 01:19:09,246][train][INFO] - Epoch 553/2000, Val Acc=0.5858, Val Loss=1.6980, lr=0.0100
[2025-05-07 01:19:10,392][train][INFO] - Epoch 548/2000, Val Acc=0.5801, Val Loss=1.9159, lr=0.0100
[2025-05-07 01:19:11,941][train][INFO] - Epoch 554/2000, Val Acc=0.6287, Val Loss=1.6171, lr=0.0100
[2025-05-07 01:19:17,419][train][INFO] - Epoch 554/2000, Val Acc=0.5805, Val Loss=1.7004, lr=0.0100
[2025-05-07 01:19:18,526][train][INFO] - Epoch 549/2000, Val Acc=0.6151, Val Loss=1.6596, lr=0.0100
[2025-05-07 01:19:19,755][train][INFO] - Epoch 555/2000, Val Acc=0.6135, Val Loss=1.6956, lr=0.0100
[2025-05-07 01:19:25,439][train][INFO] - Epoch 555/2000, Val Acc=0.5937, Val Loss=1.6374, lr=0.0100
[2025-05-07 01:19:26,628][train][INFO] - Epoch 550/2000, Val Acc=0.6006, Val Loss=1.7927, lr=0.0100
[2025-05-07 01:19:27,735][train][INFO] - Epoch 556/2000, Val Acc=0.6116, Val Loss=1.6821, lr=0.0100
[2025-05-07 01:19:32,160][train][INFO] - Epoch 556/2000, Val Acc=0.5806, Val Loss=1.7010, lr=0.0100
[2025-05-07 01:19:34,750][train][INFO] - Epoch 551/2000, Val Acc=0.6043, Val Loss=1.7342, lr=0.0100
[2025-05-07 01:19:35,531][train][INFO] - Epoch 557/2000, Val Acc=0.6096, Val Loss=1.7951, lr=0.0100
[2025-05-07 01:19:40,103][train][INFO] - Epoch 557/2000, Val Acc=0.5796, Val Loss=1.7076, lr=0.0100
[2025-05-07 01:19:42,636][train][INFO] - Epoch 552/2000, Val Acc=0.6022, Val Loss=1.7583, lr=0.0100
[2025-05-07 01:19:43,063][train][INFO] - Epoch 558/2000, Val Acc=0.6096, Val Loss=1.7196, lr=0.0100
[2025-05-07 01:19:47,914][train][INFO] - Epoch 558/2000, Val Acc=0.5841, Val Loss=1.6616, lr=0.0100
[2025-05-07 01:19:50,766][train][INFO] - Epoch 559/2000, Val Acc=0.5876, Val Loss=1.8455, lr=0.0100
[2025-05-07 01:19:51,025][train][INFO] - Epoch 553/2000, Val Acc=0.6026, Val Loss=1.7520, lr=0.0100
[2025-05-07 01:19:55,387][train][INFO] - Epoch 559/2000, Val Acc=0.5805, Val Loss=1.7148, lr=0.0100
[2025-05-07 01:19:58,555][train][INFO] - Epoch 560/2000, Val Acc=0.5949, Val Loss=1.8082, lr=0.0100
[2025-05-07 01:19:59,293][train][INFO] - Epoch 554/2000, Val Acc=0.6287, Val Loss=1.6171, lr=0.0100
[2025-05-07 01:20:02,923][train][INFO] - Epoch 560/2000, Val Acc=0.5849, Val Loss=1.6624, lr=0.0100
[2025-05-07 01:20:06,112][train][INFO] - Epoch 561/2000, Val Acc=0.5948, Val Loss=1.8372, lr=0.0100
[2025-05-07 01:20:07,300][train][INFO] - Epoch 555/2000, Val Acc=0.6135, Val Loss=1.6956, lr=0.0100
[2025-05-07 01:20:10,657][train][INFO] - Epoch 561/2000, Val Acc=0.5938, Val Loss=1.6230, lr=0.0100
[2025-05-07 01:20:14,271][train][INFO] - Epoch 562/2000, Val Acc=0.6041, Val Loss=1.7521, lr=0.0100
[2025-05-07 01:20:14,665][train][INFO] - Epoch 556/2000, Val Acc=0.6116, Val Loss=1.6821, lr=0.0100
[2025-05-07 01:20:18,397][train][INFO] - Epoch 562/2000, Val Acc=0.5823, Val Loss=1.7098, lr=0.0100
[2025-05-07 01:20:22,140][train][INFO] - Epoch 563/2000, Val Acc=0.6102, Val Loss=1.7171, lr=0.0100
[2025-05-07 01:20:22,435][train][INFO] - Epoch 557/2000, Val Acc=0.6096, Val Loss=1.7951, lr=0.0100
[2025-05-07 01:20:25,477][train][INFO] - Epoch 563/2000, Val Acc=0.5730, Val Loss=1.7272, lr=0.0100
[2025-05-07 01:20:29,887][train][INFO] - Epoch 564/2000, Val Acc=0.6088, Val Loss=1.7057, lr=0.0100
[2025-05-07 01:20:30,045][train][INFO] - Epoch 558/2000, Val Acc=0.6096, Val Loss=1.7196, lr=0.0100
[2025-05-07 01:20:33,530][train][INFO] - Epoch 564/2000, Val Acc=0.5682, Val Loss=1.7781, lr=0.0100
[2025-05-07 01:20:37,608][train][INFO] - Epoch 565/2000, Val Acc=0.5937, Val Loss=1.8231, lr=0.0100
[2025-05-07 01:20:38,012][train][INFO] - Epoch 559/2000, Val Acc=0.5876, Val Loss=1.8455, lr=0.0100
[2025-05-07 01:20:41,442][train][INFO] - Epoch 565/2000, Val Acc=0.5870, Val Loss=1.7297, lr=0.0100
[2025-05-07 01:20:45,398][train][INFO] - Epoch 566/2000, Val Acc=0.5965, Val Loss=1.8295, lr=0.0100
[2025-05-07 01:20:46,007][train][INFO] - Epoch 560/2000, Val Acc=0.5949, Val Loss=1.8082, lr=0.0100
[2025-05-07 01:20:49,221][train][INFO] - Epoch 566/2000, Val Acc=0.5780, Val Loss=1.7329, lr=0.0100
[2025-05-07 01:20:52,907][train][INFO] - Epoch 567/2000, Val Acc=0.6180, Val Loss=1.6862, lr=0.0100
[2025-05-07 01:20:53,998][train][INFO] - Epoch 561/2000, Val Acc=0.5948, Val Loss=1.8372, lr=0.0100
[2025-05-07 01:20:56,648][train][INFO] - Epoch 567/2000, Val Acc=0.5601, Val Loss=1.8501, lr=0.0100
[2025-05-07 01:20:59,876][train][INFO] - Epoch 568/2000, Val Acc=0.6166, Val Loss=1.6730, lr=0.0100
[2025-05-07 01:21:01,210][train][INFO] - Epoch 562/2000, Val Acc=0.6041, Val Loss=1.7521, lr=0.0100
[2025-05-07 01:21:04,583][train][INFO] - Epoch 568/2000, Val Acc=0.5861, Val Loss=1.6671, lr=0.0100
[2025-05-07 01:21:07,765][train][INFO] - Epoch 569/2000, Val Acc=0.6133, Val Loss=1.6867, lr=0.0100
[2025-05-07 01:21:09,205][train][INFO] - Epoch 563/2000, Val Acc=0.6102, Val Loss=1.7171, lr=0.0100
[2025-05-07 01:21:12,762][train][INFO] - Epoch 569/2000, Val Acc=0.5684, Val Loss=1.7865, lr=0.0100
[2025-05-07 01:21:15,638][train][INFO] - Epoch 570/2000, Val Acc=0.6216, Val Loss=1.6383, lr=0.0100
[2025-05-07 01:21:17,163][train][INFO] - Epoch 564/2000, Val Acc=0.6088, Val Loss=1.7057, lr=0.0100
[2025-05-07 01:21:20,237][train][INFO] - Epoch 570/2000, Val Acc=0.5878, Val Loss=1.6916, lr=0.0100
[2025-05-07 01:21:23,536][train][INFO] - Epoch 571/2000, Val Acc=0.6154, Val Loss=1.7063, lr=0.0100
[2025-05-07 01:21:25,204][train][INFO] - Epoch 565/2000, Val Acc=0.5937, Val Loss=1.8231, lr=0.0100
[2025-05-07 01:21:27,971][train][INFO] - Epoch 571/2000, Val Acc=0.5756, Val Loss=1.7275, lr=0.0100
[2025-05-07 01:21:30,551][train][INFO] - Epoch 572/2000, Val Acc=0.6154, Val Loss=1.7044, lr=0.0100
[2025-05-07 01:21:33,209][train][INFO] - Epoch 566/2000, Val Acc=0.5965, Val Loss=1.8295, lr=0.0100
[2025-05-07 01:21:35,633][train][INFO] - Epoch 572/2000, Val Acc=0.5800, Val Loss=1.7429, lr=0.0100
[2025-05-07 01:21:38,314][train][INFO] - Epoch 573/2000, Val Acc=0.6157, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:21:41,130][train][INFO] - Epoch 567/2000, Val Acc=0.6180, Val Loss=1.6862, lr=0.0100
[2025-05-07 01:21:42,786][train][INFO] - Epoch 573/2000, Val Acc=0.6024, Val Loss=1.5946, lr=0.0100
[2025-05-07 01:21:45,760][train][INFO] - Epoch 574/2000, Val Acc=0.6130, Val Loss=1.6928, lr=0.0100
[2025-05-07 01:21:49,134][train][INFO] - Epoch 568/2000, Val Acc=0.6166, Val Loss=1.6730, lr=0.0100
[2025-05-07 01:21:50,970][train][INFO] - Epoch 574/2000, Val Acc=0.5883, Val Loss=1.6542, lr=0.0100
[2025-05-07 01:21:53,292][train][INFO] - Epoch 575/2000, Val Acc=0.6226, Val Loss=1.6597, lr=0.0100
[2025-05-07 01:21:57,124][train][INFO] - Epoch 569/2000, Val Acc=0.6133, Val Loss=1.6867, lr=0.0100
[2025-05-07 01:21:57,967][train][INFO] - Epoch 575/2000, Val Acc=0.5906, Val Loss=1.6359, lr=0.0100
[2025-05-07 01:22:01,242][train][INFO] - Epoch 576/2000, Val Acc=0.6105, Val Loss=1.7381, lr=0.0100
[2025-05-07 01:22:05,046][train][INFO] - Epoch 570/2000, Val Acc=0.6216, Val Loss=1.6383, lr=0.0100
[2025-05-07 01:22:05,837][train][INFO] - Epoch 576/2000, Val Acc=0.5915, Val Loss=1.6832, lr=0.0100
[2025-05-07 01:22:08,935][train][INFO] - Epoch 577/2000, Val Acc=0.6002, Val Loss=1.7878, lr=0.0100
[2025-05-07 01:22:12,814][train][INFO] - Epoch 571/2000, Val Acc=0.6154, Val Loss=1.7063, lr=0.0100
[2025-05-07 01:22:13,346][train][INFO] - Epoch 577/2000, Val Acc=0.5453, Val Loss=1.9253, lr=0.0100
[2025-05-07 01:22:16,496][train][INFO] - Epoch 578/2000, Val Acc=0.6084, Val Loss=1.7408, lr=0.0100
[2025-05-07 01:22:20,618][train][INFO] - Epoch 572/2000, Val Acc=0.6154, Val Loss=1.7044, lr=0.0100
[2025-05-07 01:22:21,296][train][INFO] - Epoch 578/2000, Val Acc=0.5779, Val Loss=1.7079, lr=0.0100
[2025-05-07 01:22:24,570][train][INFO] - Epoch 579/2000, Val Acc=0.6022, Val Loss=1.7536, lr=0.0100
[2025-05-07 01:22:28,615][train][INFO] - Epoch 573/2000, Val Acc=0.6157, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:22:29,200][train][INFO] - Epoch 579/2000, Val Acc=0.5670, Val Loss=1.7544, lr=0.0100
[2025-05-07 01:22:32,399][train][INFO] - Epoch 580/2000, Val Acc=0.5970, Val Loss=1.7684, lr=0.0100
[2025-05-07 01:22:36,827][train][INFO] - Epoch 574/2000, Val Acc=0.6130, Val Loss=1.6928, lr=0.0100
[2025-05-07 01:22:37,324][train][INFO] - Epoch 580/2000, Val Acc=0.5760, Val Loss=1.7591, lr=0.0100
[2025-05-07 01:22:40,218][train][INFO] - Epoch 581/2000, Val Acc=0.6053, Val Loss=1.7919, lr=0.0100
[2025-05-07 01:22:44,725][train][INFO] - Epoch 581/2000, Val Acc=0.5822, Val Loss=1.6947, lr=0.0100
[2025-05-07 01:22:44,982][train][INFO] - Epoch 575/2000, Val Acc=0.6226, Val Loss=1.6597, lr=0.0100
[2025-05-07 01:22:47,891][train][INFO] - Epoch 582/2000, Val Acc=0.6122, Val Loss=1.6722, lr=0.0100
[2025-05-07 01:22:52,807][train][INFO] - Epoch 576/2000, Val Acc=0.6105, Val Loss=1.7381, lr=0.0100
[2025-05-07 01:22:52,956][train][INFO] - Epoch 582/2000, Val Acc=0.5839, Val Loss=1.7074, lr=0.0100
[2025-05-07 01:22:55,655][train][INFO] - Epoch 583/2000, Val Acc=0.6147, Val Loss=1.6633, lr=0.0100
[2025-05-07 01:23:00,492][train][INFO] - Epoch 583/2000, Val Acc=0.5645, Val Loss=1.7781, lr=0.0100
[2025-05-07 01:23:00,666][train][INFO] - Epoch 577/2000, Val Acc=0.6002, Val Loss=1.7878, lr=0.0100
[2025-05-07 01:23:03,289][train][INFO] - Epoch 584/2000, Val Acc=0.6096, Val Loss=1.7120, lr=0.0100
[2025-05-07 01:23:08,406][train][INFO] - Epoch 584/2000, Val Acc=0.5703, Val Loss=1.7181, lr=0.0100
[2025-05-07 01:23:08,707][train][INFO] - Epoch 578/2000, Val Acc=0.6084, Val Loss=1.7408, lr=0.0100
[2025-05-07 01:23:11,194][train][INFO] - Epoch 585/2000, Val Acc=0.6169, Val Loss=1.6804, lr=0.0100
[2025-05-07 01:23:16,314][train][INFO] - Epoch 585/2000, Val Acc=0.5844, Val Loss=1.6592, lr=0.0100
[2025-05-07 01:23:16,599][train][INFO] - Epoch 579/2000, Val Acc=0.6022, Val Loss=1.7536, lr=0.0100
[2025-05-07 01:23:18,467][train][INFO] - Epoch 586/2000, Val Acc=0.6071, Val Loss=1.7547, lr=0.0100
[2025-05-07 01:23:23,705][train][INFO] - Epoch 586/2000, Val Acc=0.5722, Val Loss=1.7430, lr=0.0100
[2025-05-07 01:23:24,625][train][INFO] - Epoch 580/2000, Val Acc=0.5970, Val Loss=1.7684, lr=0.0100
[2025-05-07 01:23:26,054][train][INFO] - Epoch 587/2000, Val Acc=0.6023, Val Loss=1.7297, lr=0.0100
[2025-05-07 01:23:31,001][train][INFO] - Epoch 587/2000, Val Acc=0.5880, Val Loss=1.6603, lr=0.0100
[2025-05-07 01:23:32,512][train][INFO] - Epoch 581/2000, Val Acc=0.6053, Val Loss=1.7919, lr=0.0100
[2025-05-07 01:23:33,681][train][INFO] - Epoch 588/2000, Val Acc=0.6083, Val Loss=1.7268, lr=0.0100
[2025-05-07 01:23:38,702][train][INFO] - Epoch 588/2000, Val Acc=0.6023, Val Loss=1.6074, lr=0.0100
[2025-05-07 01:23:40,361][train][INFO] - Epoch 582/2000, Val Acc=0.6122, Val Loss=1.6722, lr=0.0100
[2025-05-07 01:23:41,087][train][INFO] - Epoch 589/2000, Val Acc=0.6127, Val Loss=1.7512, lr=0.0100
[2025-05-07 01:23:46,161][train][INFO] - Epoch 589/2000, Val Acc=0.5822, Val Loss=1.7013, lr=0.0100
[2025-05-07 01:23:47,986][train][INFO] - Epoch 583/2000, Val Acc=0.6147, Val Loss=1.6633, lr=0.0100
[2025-05-07 01:23:48,877][train][INFO] - Epoch 590/2000, Val Acc=0.6042, Val Loss=1.7279, lr=0.0100
[2025-05-07 01:23:53,824][train][INFO] - Epoch 590/2000, Val Acc=0.5798, Val Loss=1.7176, lr=0.0100
[2025-05-07 01:23:55,863][train][INFO] - Epoch 584/2000, Val Acc=0.6096, Val Loss=1.7120, lr=0.0100
[2025-05-07 01:23:56,996][train][INFO] - Epoch 591/2000, Val Acc=0.6219, Val Loss=1.6747, lr=0.0100
[2025-05-07 01:24:01,216][train][INFO] - Epoch 591/2000, Val Acc=0.5732, Val Loss=1.7083, lr=0.0100
[2025-05-07 01:24:03,593][train][INFO] - Epoch 585/2000, Val Acc=0.6169, Val Loss=1.6804, lr=0.0100
[2025-05-07 01:24:04,381][train][INFO] - Epoch 592/2000, Val Acc=0.6046, Val Loss=1.7540, lr=0.0100
[2025-05-07 01:24:08,824][train][INFO] - Epoch 592/2000, Val Acc=0.5662, Val Loss=1.7868, lr=0.0100
[2025-05-07 01:24:11,712][train][INFO] - Epoch 586/2000, Val Acc=0.6071, Val Loss=1.7547, lr=0.0100
[2025-05-07 01:24:11,788][train][INFO] - Epoch 593/2000, Val Acc=0.6098, Val Loss=1.7351, lr=0.0100
[2025-05-07 01:24:16,176][train][INFO] - Epoch 593/2000, Val Acc=0.5830, Val Loss=1.6375, lr=0.0100
[2025-05-07 01:24:19,654][train][INFO] - Epoch 594/2000, Val Acc=0.6062, Val Loss=1.7396, lr=0.0100
[2025-05-07 01:24:20,042][train][INFO] - Epoch 587/2000, Val Acc=0.6023, Val Loss=1.7297, lr=0.0100
[2025-05-07 01:24:23,851][train][INFO] - Epoch 594/2000, Val Acc=0.5911, Val Loss=1.6868, lr=0.0100
[2025-05-07 01:24:27,252][train][INFO] - Epoch 595/2000, Val Acc=0.6182, Val Loss=1.6492, lr=0.0100
[2025-05-07 01:24:28,026][train][INFO] - Epoch 588/2000, Val Acc=0.6083, Val Loss=1.7268, lr=0.0100
[2025-05-07 01:24:31,772][train][INFO] - Epoch 595/2000, Val Acc=0.5843, Val Loss=1.6718, lr=0.0100
[2025-05-07 01:24:35,270][train][INFO] - Epoch 596/2000, Val Acc=0.6118, Val Loss=1.7227, lr=0.0100
[2025-05-07 01:24:36,250][train][INFO] - Epoch 589/2000, Val Acc=0.6127, Val Loss=1.7512, lr=0.0100
[2025-05-07 01:24:39,702][train][INFO] - Epoch 596/2000, Val Acc=0.5791, Val Loss=1.7097, lr=0.0100
[2025-05-07 01:24:43,300][train][INFO] - Epoch 597/2000, Val Acc=0.6173, Val Loss=1.7021, lr=0.0100
[2025-05-07 01:24:44,112][train][INFO] - Epoch 590/2000, Val Acc=0.6042, Val Loss=1.7279, lr=0.0100
[2025-05-07 01:24:47,552][train][INFO] - Epoch 597/2000, Val Acc=0.5931, Val Loss=1.6715, lr=0.0100
[2025-05-07 01:24:50,696][train][INFO] - Epoch 598/2000, Val Acc=0.6215, Val Loss=1.6734, lr=0.0100
[2025-05-07 01:24:51,898][train][INFO] - Epoch 591/2000, Val Acc=0.6219, Val Loss=1.6747, lr=0.0100
[2025-05-07 01:24:55,351][train][INFO] - Epoch 598/2000, Val Acc=0.5876, Val Loss=1.6848, lr=0.0100
[2025-05-07 01:24:58,292][train][INFO] - Epoch 599/2000, Val Acc=0.5921, Val Loss=1.8021, lr=0.0100
[2025-05-07 01:25:00,088][train][INFO] - Epoch 592/2000, Val Acc=0.6046, Val Loss=1.7540, lr=0.0100
[2025-05-07 01:25:03,137][train][INFO] - Epoch 599/2000, Val Acc=0.5944, Val Loss=1.6331, lr=0.0100
[2025-05-07 01:25:05,727][train][INFO] - Epoch 600/2000, Val Acc=0.6103, Val Loss=1.7055, lr=0.0100
[2025-05-07 01:25:07,910][train][INFO] - Epoch 593/2000, Val Acc=0.6098, Val Loss=1.7351, lr=0.0100
[2025-05-07 01:25:10,935][train][INFO] - Epoch 600/2000, Val Acc=0.5900, Val Loss=1.6455, lr=0.0100
[2025-05-07 01:25:13,140][train][INFO] - Epoch 601/2000, Val Acc=0.5895, Val Loss=1.8494, lr=0.0100
[2025-05-07 01:25:16,079][train][INFO] - Epoch 594/2000, Val Acc=0.6062, Val Loss=1.7396, lr=0.0100
[2025-05-07 01:25:19,013][train][INFO] - Epoch 601/2000, Val Acc=0.5875, Val Loss=1.6910, lr=0.0100
[2025-05-07 01:25:21,183][train][INFO] - Epoch 602/2000, Val Acc=0.6156, Val Loss=1.7104, lr=0.0100
[2025-05-07 01:25:23,555][train][INFO] - Epoch 595/2000, Val Acc=0.6182, Val Loss=1.6492, lr=0.0100
[2025-05-07 01:25:26,900][train][INFO] - Epoch 602/2000, Val Acc=0.5656, Val Loss=1.7546, lr=0.0100
[2025-05-07 01:25:28,246][train][INFO] - Epoch 603/2000, Val Acc=0.6126, Val Loss=1.7052, lr=0.0100
[2025-05-07 01:25:31,461][train][INFO] - Epoch 596/2000, Val Acc=0.6118, Val Loss=1.7227, lr=0.0100
[2025-05-07 01:25:34,748][train][INFO] - Epoch 603/2000, Val Acc=0.5967, Val Loss=1.6296, lr=0.0100
[2025-05-07 01:25:35,933][train][INFO] - Epoch 604/2000, Val Acc=0.6138, Val Loss=1.7246, lr=0.0100
[2025-05-07 01:25:39,300][train][INFO] - Epoch 597/2000, Val Acc=0.6173, Val Loss=1.7021, lr=0.0100
[2025-05-07 01:25:42,633][train][INFO] - Epoch 604/2000, Val Acc=0.5820, Val Loss=1.6749, lr=0.0100
[2025-05-07 01:25:43,486][train][INFO] - Epoch 605/2000, Val Acc=0.6040, Val Loss=1.7826, lr=0.0100
[2025-05-07 01:25:47,662][train][INFO] - Epoch 598/2000, Val Acc=0.6215, Val Loss=1.6734, lr=0.0100
[2025-05-07 01:25:50,740][train][INFO] - Epoch 605/2000, Val Acc=0.5657, Val Loss=1.7948, lr=0.0100
[2025-05-07 01:25:50,981][train][INFO] - Epoch 606/2000, Val Acc=0.6113, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:25:56,004][train][INFO] - Epoch 599/2000, Val Acc=0.5921, Val Loss=1.8021, lr=0.0100
[2025-05-07 01:25:58,244][train][INFO] - Epoch 606/2000, Val Acc=0.5714, Val Loss=1.7425, lr=0.0100
[2025-05-07 01:25:58,569][train][INFO] - Epoch 607/2000, Val Acc=0.6066, Val Loss=1.7683, lr=0.0100
[2025-05-07 01:26:03,926][train][INFO] - Epoch 600/2000, Val Acc=0.6103, Val Loss=1.7055, lr=0.0100
[2025-05-07 01:26:06,090][train][INFO] - Epoch 607/2000, Val Acc=0.5807, Val Loss=1.7332, lr=0.0100
[2025-05-07 01:26:06,376][train][INFO] - Epoch 608/2000, Val Acc=0.6232, Val Loss=1.6352, lr=0.0100
[2025-05-07 01:26:11,811][train][INFO] - Epoch 601/2000, Val Acc=0.5895, Val Loss=1.8494, lr=0.0100
[2025-05-07 01:26:13,929][train][INFO] - Epoch 608/2000, Val Acc=0.5855, Val Loss=1.7010, lr=0.0100
[2025-05-07 01:26:14,405][train][INFO] - Epoch 609/2000, Val Acc=0.6116, Val Loss=1.7476, lr=0.0100
[2025-05-07 01:26:19,357][train][INFO] - Epoch 602/2000, Val Acc=0.6156, Val Loss=1.7104, lr=0.0100
[2025-05-07 01:26:21,690][train][INFO] - Epoch 609/2000, Val Acc=0.5996, Val Loss=1.6251, lr=0.0100
[2025-05-07 01:26:22,313][train][INFO] - Epoch 610/2000, Val Acc=0.6102, Val Loss=1.7396, lr=0.0100
[2025-05-07 01:26:27,208][train][INFO] - Epoch 603/2000, Val Acc=0.6126, Val Loss=1.7052, lr=0.0100
[2025-05-07 01:26:29,784][train][INFO] - Epoch 610/2000, Val Acc=0.5844, Val Loss=1.6845, lr=0.0100
[2025-05-07 01:26:29,904][train][INFO] - Epoch 611/2000, Val Acc=0.6105, Val Loss=1.7144, lr=0.0100
[2025-05-07 01:26:35,440][train][INFO] - Epoch 604/2000, Val Acc=0.6138, Val Loss=1.7246, lr=0.0100
[2025-05-07 01:26:37,973][train][INFO] - Epoch 611/2000, Val Acc=0.5753, Val Loss=1.7575, lr=0.0100
[2025-05-07 01:26:38,039][train][INFO] - Epoch 612/2000, Val Acc=0.5935, Val Loss=1.8384, lr=0.0100
[2025-05-07 01:26:43,042][train][INFO] - Epoch 605/2000, Val Acc=0.6040, Val Loss=1.7826, lr=0.0100
[2025-05-07 01:26:44,542][train][INFO] - Epoch 612/2000, Val Acc=0.6019, Val Loss=1.5815, lr=0.0100
[2025-05-07 01:26:45,672][train][INFO] - Epoch 613/2000, Val Acc=0.6208, Val Loss=1.6575, lr=0.0100
[2025-05-07 01:26:51,263][train][INFO] - Epoch 606/2000, Val Acc=0.6113, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:26:52,376][train][INFO] - Epoch 613/2000, Val Acc=0.5525, Val Loss=1.9146, lr=0.0100
[2025-05-07 01:26:53,499][train][INFO] - Epoch 614/2000, Val Acc=0.5972, Val Loss=1.7927, lr=0.0100
[2025-05-07 01:26:59,193][train][INFO] - Epoch 607/2000, Val Acc=0.6066, Val Loss=1.7683, lr=0.0100
[2025-05-07 01:26:59,970][train][INFO] - Epoch 614/2000, Val Acc=0.5819, Val Loss=1.6593, lr=0.0100
[2025-05-07 01:27:00,950][train][INFO] - Epoch 615/2000, Val Acc=0.6007, Val Loss=1.7968, lr=0.0100
[2025-05-07 01:27:06,930][train][INFO] - Epoch 608/2000, Val Acc=0.6232, Val Loss=1.6352, lr=0.0100
[2025-05-07 01:27:07,702][train][INFO] - Epoch 615/2000, Val Acc=0.5643, Val Loss=1.8504, lr=0.0100
[2025-05-07 01:27:08,354][train][INFO] - Epoch 616/2000, Val Acc=0.5789, Val Loss=1.8468, lr=0.0100
[2025-05-07 01:27:14,588][train][INFO] - Epoch 609/2000, Val Acc=0.6116, Val Loss=1.7476, lr=0.0100
[2025-05-07 01:27:15,454][train][INFO] - Epoch 616/2000, Val Acc=0.5679, Val Loss=1.7595, lr=0.0100
[2025-05-07 01:27:15,900][train][INFO] - Epoch 617/2000, Val Acc=0.6189, Val Loss=1.6767, lr=0.0100
[2025-05-07 01:27:22,508][train][INFO] - Epoch 610/2000, Val Acc=0.6102, Val Loss=1.7396, lr=0.0100
[2025-05-07 01:27:23,184][train][INFO] - Epoch 617/2000, Val Acc=0.5748, Val Loss=1.7284, lr=0.0100
[2025-05-07 01:27:23,554][train][INFO] - Epoch 618/2000, Val Acc=0.6112, Val Loss=1.7166, lr=0.0100
[2025-05-07 01:27:30,601][train][INFO] - Epoch 618/2000, Val Acc=0.5747, Val Loss=1.7165, lr=0.0100
[2025-05-07 01:27:30,770][train][INFO] - Epoch 611/2000, Val Acc=0.6105, Val Loss=1.7144, lr=0.0100
[2025-05-07 01:27:31,236][train][INFO] - Epoch 619/2000, Val Acc=0.6131, Val Loss=1.7228, lr=0.0100
[2025-05-07 01:27:38,189][train][INFO] - Epoch 619/2000, Val Acc=0.5898, Val Loss=1.6244, lr=0.0100
[2025-05-07 01:27:38,397][train][INFO] - Epoch 612/2000, Val Acc=0.5935, Val Loss=1.8384, lr=0.0100
[2025-05-07 01:27:38,570][train][INFO] - Epoch 620/2000, Val Acc=0.6136, Val Loss=1.7195, lr=0.0100
[2025-05-07 01:27:45,751][train][INFO] - Epoch 620/2000, Val Acc=0.5879, Val Loss=1.6693, lr=0.0100
[2025-05-07 01:27:46,580][train][INFO] - Epoch 613/2000, Val Acc=0.6208, Val Loss=1.6575, lr=0.0100
[2025-05-07 01:27:46,691][train][INFO] - Epoch 621/2000, Val Acc=0.5963, Val Loss=1.8047, lr=0.0100
[2025-05-07 01:27:53,153][train][INFO] - Epoch 621/2000, Val Acc=0.5861, Val Loss=1.6835, lr=0.0100
[2025-05-07 01:27:54,073][train][INFO] - Epoch 622/2000, Val Acc=0.6128, Val Loss=1.7172, lr=0.0100
[2025-05-07 01:27:54,240][train][INFO] - Epoch 614/2000, Val Acc=0.5972, Val Loss=1.7927, lr=0.0100
[2025-05-07 01:28:00,935][train][INFO] - Epoch 622/2000, Val Acc=0.5932, Val Loss=1.6807, lr=0.0100
[2025-05-07 01:28:01,766][train][INFO] - Epoch 623/2000, Val Acc=0.5869, Val Loss=1.8736, lr=0.0100
[2025-05-07 01:28:02,105][train][INFO] - Epoch 615/2000, Val Acc=0.6007, Val Loss=1.7968, lr=0.0100
[2025-05-07 01:28:08,335][train][INFO] - Epoch 623/2000, Val Acc=0.5871, Val Loss=1.6577, lr=0.0100
[2025-05-07 01:28:09,243][train][INFO] - Epoch 624/2000, Val Acc=0.5937, Val Loss=1.8277, lr=0.0100
[2025-05-07 01:28:09,629][train][INFO] - Epoch 616/2000, Val Acc=0.5789, Val Loss=1.8468, lr=0.0100
[2025-05-07 01:28:15,855][train][INFO] - Epoch 624/2000, Val Acc=0.5959, Val Loss=1.6110, lr=0.0100
[2025-05-07 01:28:17,384][train][INFO] - Epoch 625/2000, Val Acc=0.6098, Val Loss=1.7471, lr=0.0100
[2025-05-07 01:28:18,018][train][INFO] - Epoch 617/2000, Val Acc=0.6189, Val Loss=1.6767, lr=0.0100
[2025-05-07 01:28:23,301][train][INFO] - Epoch 625/2000, Val Acc=0.5639, Val Loss=1.8048, lr=0.0100
[2025-05-07 01:28:25,278][train][INFO] - Epoch 626/2000, Val Acc=0.6088, Val Loss=1.7294, lr=0.0100
[2025-05-07 01:28:25,930][train][INFO] - Epoch 618/2000, Val Acc=0.6112, Val Loss=1.7166, lr=0.0100
[2025-05-07 01:28:31,038][train][INFO] - Epoch 626/2000, Val Acc=0.5813, Val Loss=1.7088, lr=0.0100
[2025-05-07 01:28:33,303][train][INFO] - Epoch 627/2000, Val Acc=0.6048, Val Loss=1.7550, lr=0.0100
[2025-05-07 01:28:33,432][train][INFO] - Epoch 619/2000, Val Acc=0.6131, Val Loss=1.7228, lr=0.0100
[2025-05-07 01:28:38,561][train][INFO] - Epoch 627/2000, Val Acc=0.5939, Val Loss=1.6245, lr=0.0100
[2025-05-07 01:28:40,744][train][INFO] - Epoch 620/2000, Val Acc=0.6136, Val Loss=1.7195, lr=0.0100
[2025-05-07 01:28:41,012][train][INFO] - Epoch 628/2000, Val Acc=0.6029, Val Loss=1.7624, lr=0.0100
[2025-05-07 01:28:46,610][train][INFO] - Epoch 628/2000, Val Acc=0.5735, Val Loss=1.7253, lr=0.0100
[2025-05-07 01:28:48,588][train][INFO] - Epoch 629/2000, Val Acc=0.6110, Val Loss=1.7018, lr=0.0100
[2025-05-07 01:28:48,984][train][INFO] - Epoch 621/2000, Val Acc=0.5963, Val Loss=1.8047, lr=0.0100
[2025-05-07 01:28:54,806][train][INFO] - Epoch 629/2000, Val Acc=0.5908, Val Loss=1.6514, lr=0.0100
[2025-05-07 01:28:55,926][train][INFO] - Epoch 630/2000, Val Acc=0.6212, Val Loss=1.6811, lr=0.0100
[2025-05-07 01:28:57,004][train][INFO] - Epoch 622/2000, Val Acc=0.6128, Val Loss=1.7172, lr=0.0100
[2025-05-07 01:29:02,512][train][INFO] - Epoch 630/2000, Val Acc=0.5586, Val Loss=1.8040, lr=0.0100
[2025-05-07 01:29:03,916][train][INFO] - Epoch 631/2000, Val Acc=0.6173, Val Loss=1.6726, lr=0.0100
[2025-05-07 01:29:05,261][train][INFO] - Epoch 623/2000, Val Acc=0.5869, Val Loss=1.8736, lr=0.0100
[2025-05-07 01:29:09,841][train][INFO] - Epoch 631/2000, Val Acc=0.5943, Val Loss=1.6242, lr=0.0100
[2025-05-07 01:29:11,132][train][INFO] - Epoch 632/2000, Val Acc=0.6143, Val Loss=1.7087, lr=0.0100
[2025-05-07 01:29:13,164][train][INFO] - Epoch 624/2000, Val Acc=0.5937, Val Loss=1.8277, lr=0.0100
[2025-05-07 01:29:17,947][train][INFO] - Epoch 632/2000, Val Acc=0.6002, Val Loss=1.6334, lr=0.0100
[2025-05-07 01:29:19,005][train][INFO] - Epoch 633/2000, Val Acc=0.6105, Val Loss=1.6949, lr=0.0100
[2025-05-07 01:29:20,853][train][INFO] - Epoch 625/2000, Val Acc=0.6098, Val Loss=1.7471, lr=0.0100
[2025-05-07 01:29:25,849][train][INFO] - Epoch 633/2000, Val Acc=0.5984, Val Loss=1.6167, lr=0.0100
[2025-05-07 01:29:26,803][train][INFO] - Epoch 634/2000, Val Acc=0.6061, Val Loss=1.7556, lr=0.0100
[2025-05-07 01:29:28,695][train][INFO] - Epoch 626/2000, Val Acc=0.6088, Val Loss=1.7294, lr=0.0100
[2025-05-07 01:29:33,734][train][INFO] - Epoch 634/2000, Val Acc=0.5592, Val Loss=1.7670, lr=0.0100
[2025-05-07 01:29:33,825][train][INFO] - Epoch 635/2000, Val Acc=0.6143, Val Loss=1.7219, lr=0.0100
[2025-05-07 01:29:36,417][train][INFO] - Epoch 627/2000, Val Acc=0.6048, Val Loss=1.7550, lr=0.0100
[2025-05-07 01:29:41,293][train][INFO] - Epoch 636/2000, Val Acc=0.5936, Val Loss=1.7966, lr=0.0100
[2025-05-07 01:29:41,568][train][INFO] - Epoch 635/2000, Val Acc=0.5883, Val Loss=1.6401, lr=0.0100
[2025-05-07 01:29:44,146][train][INFO] - Epoch 628/2000, Val Acc=0.6029, Val Loss=1.7624, lr=0.0100
[2025-05-07 01:29:48,678][train][INFO] - Epoch 637/2000, Val Acc=0.5814, Val Loss=1.8894, lr=0.0100
[2025-05-07 01:29:49,284][train][INFO] - Epoch 636/2000, Val Acc=0.5905, Val Loss=1.6383, lr=0.0100
[2025-05-07 01:29:51,776][train][INFO] - Epoch 629/2000, Val Acc=0.6110, Val Loss=1.7018, lr=0.0100
[2025-05-07 01:29:55,792][train][INFO] - Epoch 638/2000, Val Acc=0.5907, Val Loss=1.8488, lr=0.0100
[2025-05-07 01:29:56,963][train][INFO] - Epoch 637/2000, Val Acc=0.5901, Val Loss=1.6274, lr=0.0100
[2025-05-07 01:29:59,852][train][INFO] - Epoch 630/2000, Val Acc=0.6212, Val Loss=1.6811, lr=0.0100
[2025-05-07 01:30:03,206][train][INFO] - Epoch 639/2000, Val Acc=0.6050, Val Loss=1.7587, lr=0.0100
[2025-05-07 01:30:04,770][train][INFO] - Epoch 638/2000, Val Acc=0.5648, Val Loss=1.7735, lr=0.0100
[2025-05-07 01:30:07,824][train][INFO] - Epoch 631/2000, Val Acc=0.6173, Val Loss=1.6726, lr=0.0100
[2025-05-07 01:30:10,780][train][INFO] - Epoch 640/2000, Val Acc=0.5925, Val Loss=1.7775, lr=0.0100
[2025-05-07 01:30:12,115][train][INFO] - Epoch 639/2000, Val Acc=0.5732, Val Loss=1.7386, lr=0.0100
[2025-05-07 01:30:15,657][train][INFO] - Epoch 632/2000, Val Acc=0.6143, Val Loss=1.7087, lr=0.0100
[2025-05-07 01:30:18,651][train][INFO] - Epoch 641/2000, Val Acc=0.6004, Val Loss=1.7638, lr=0.0100
[2025-05-07 01:30:19,659][train][INFO] - Epoch 640/2000, Val Acc=0.5702, Val Loss=1.7565, lr=0.0100
[2025-05-07 01:30:23,938][train][INFO] - Epoch 633/2000, Val Acc=0.6105, Val Loss=1.6949, lr=0.0100
[2025-05-07 01:30:26,736][train][INFO] - Epoch 642/2000, Val Acc=0.6026, Val Loss=1.8173, lr=0.0100
[2025-05-07 01:30:27,196][train][INFO] - Epoch 641/2000, Val Acc=0.5846, Val Loss=1.6781, lr=0.0100
[2025-05-07 01:30:31,707][train][INFO] - Epoch 634/2000, Val Acc=0.6061, Val Loss=1.7556, lr=0.0100
[2025-05-07 01:30:33,944][train][INFO] - Epoch 643/2000, Val Acc=0.6095, Val Loss=1.7557, lr=0.0100
[2025-05-07 01:30:35,041][train][INFO] - Epoch 642/2000, Val Acc=0.5929, Val Loss=1.6500, lr=0.0100
[2025-05-07 01:30:39,806][train][INFO] - Epoch 635/2000, Val Acc=0.6143, Val Loss=1.7219, lr=0.0100
[2025-05-07 01:30:42,045][train][INFO] - Epoch 644/2000, Val Acc=0.5960, Val Loss=1.7722, lr=0.0100
[2025-05-07 01:30:42,652][train][INFO] - Epoch 643/2000, Val Acc=0.5840, Val Loss=1.6878, lr=0.0100
[2025-05-07 01:30:47,991][train][INFO] - Epoch 636/2000, Val Acc=0.5936, Val Loss=1.7966, lr=0.0100
[2025-05-07 01:30:50,316][train][INFO] - Epoch 645/2000, Val Acc=0.5992, Val Loss=1.8042, lr=0.0100
[2025-05-07 01:30:50,592][train][INFO] - Epoch 644/2000, Val Acc=0.5866, Val Loss=1.6668, lr=0.0100
[2025-05-07 01:30:55,800][train][INFO] - Epoch 637/2000, Val Acc=0.5814, Val Loss=1.8894, lr=0.0100
[2025-05-07 01:30:58,199][train][INFO] - Epoch 646/2000, Val Acc=0.6072, Val Loss=1.7303, lr=0.0100
[2025-05-07 01:30:58,579][train][INFO] - Epoch 645/2000, Val Acc=0.5704, Val Loss=1.7602, lr=0.0100
[2025-05-07 01:31:03,341][train][INFO] - Epoch 638/2000, Val Acc=0.5907, Val Loss=1.8488, lr=0.0100
[2025-05-07 01:31:05,759][train][INFO] - Epoch 647/2000, Val Acc=0.6121, Val Loss=1.7547, lr=0.0100
[2025-05-07 01:31:06,128][train][INFO] - Epoch 646/2000, Val Acc=0.5861, Val Loss=1.6907, lr=0.0100
[2025-05-07 01:31:10,744][train][INFO] - Epoch 639/2000, Val Acc=0.6050, Val Loss=1.7587, lr=0.0100
[2025-05-07 01:31:13,258][train][INFO] - Epoch 647/2000, Val Acc=0.5845, Val Loss=1.6850, lr=0.0100
[2025-05-07 01:31:13,372][train][INFO] - Epoch 648/2000, Val Acc=0.6121, Val Loss=1.7496, lr=0.0100
[2025-05-07 01:31:18,904][train][INFO] - Epoch 640/2000, Val Acc=0.5925, Val Loss=1.7775, lr=0.0100
[2025-05-07 01:31:20,925][train][INFO] - Epoch 648/2000, Val Acc=0.5900, Val Loss=1.6757, lr=0.0100
[2025-05-07 01:31:20,962][train][INFO] - Epoch 649/2000, Val Acc=0.6013, Val Loss=1.7825, lr=0.0100
[2025-05-07 01:31:26,730][train][INFO] - Epoch 641/2000, Val Acc=0.6004, Val Loss=1.7638, lr=0.0100
[2025-05-07 01:31:28,781][train][INFO] - Epoch 650/2000, Val Acc=0.6051, Val Loss=1.7419, lr=0.0100
[2025-05-07 01:31:28,888][train][INFO] - Epoch 649/2000, Val Acc=0.5896, Val Loss=1.6540, lr=0.0100
[2025-05-07 01:31:34,793][train][INFO] - Epoch 642/2000, Val Acc=0.6026, Val Loss=1.8173, lr=0.0100
[2025-05-07 01:31:35,831][train][INFO] - Epoch 651/2000, Val Acc=0.6198, Val Loss=1.6863, lr=0.0100
[2025-05-07 01:31:36,872][train][INFO] - Epoch 650/2000, Val Acc=0.5748, Val Loss=1.7853, lr=0.0100
[2025-05-07 01:31:42,942][train][INFO] - Epoch 643/2000, Val Acc=0.6095, Val Loss=1.7557, lr=0.0100
[2025-05-07 01:31:43,141][train][INFO] - Epoch 652/2000, Val Acc=0.5999, Val Loss=1.8078, lr=0.0100
[2025-05-07 01:31:44,315][train][INFO] - Epoch 651/2000, Val Acc=0.5876, Val Loss=1.6311, lr=0.0100
[2025-05-07 01:31:50,906][train][INFO] - Epoch 653/2000, Val Acc=0.6135, Val Loss=1.7153, lr=0.0100
[2025-05-07 01:31:51,266][train][INFO] - Epoch 644/2000, Val Acc=0.5960, Val Loss=1.7722, lr=0.0100
[2025-05-07 01:31:51,917][train][INFO] - Epoch 652/2000, Val Acc=0.5879, Val Loss=1.6791, lr=0.0100
[2025-05-07 01:31:58,601][train][INFO] - Epoch 654/2000, Val Acc=0.6012, Val Loss=1.7440, lr=0.0100
[2025-05-07 01:31:58,935][train][INFO] - Epoch 645/2000, Val Acc=0.5992, Val Loss=1.8042, lr=0.0100
[2025-05-07 01:31:59,875][train][INFO] - Epoch 653/2000, Val Acc=0.5825, Val Loss=1.7392, lr=0.0100
[2025-05-07 01:32:06,361][train][INFO] - Epoch 655/2000, Val Acc=0.6226, Val Loss=1.6642, lr=0.0100
[2025-05-07 01:32:06,763][train][INFO] - Epoch 646/2000, Val Acc=0.6072, Val Loss=1.7303, lr=0.0100
[2025-05-07 01:32:07,616][train][INFO] - Epoch 654/2000, Val Acc=0.5642, Val Loss=1.8130, lr=0.0100
[2025-05-07 01:32:13,413][train][INFO] - Epoch 656/2000, Val Acc=0.6080, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:32:14,496][train][INFO] - Epoch 647/2000, Val Acc=0.6121, Val Loss=1.7547, lr=0.0100
[2025-05-07 01:32:15,248][train][INFO] - Epoch 655/2000, Val Acc=0.6106, Val Loss=1.5577, lr=0.0100
[2025-05-07 01:32:21,014][train][INFO] - Epoch 657/2000, Val Acc=0.5914, Val Loss=1.8373, lr=0.0100
[2025-05-07 01:32:22,424][train][INFO] - Epoch 648/2000, Val Acc=0.6121, Val Loss=1.7496, lr=0.0100
[2025-05-07 01:32:22,581][train][INFO] - Epoch 656/2000, Val Acc=0.5871, Val Loss=1.6859, lr=0.0100
[2025-05-07 01:32:28,502][train][INFO] - Epoch 658/2000, Val Acc=0.6120, Val Loss=1.7185, lr=0.0100
[2025-05-07 01:32:30,227][train][INFO] - Epoch 657/2000, Val Acc=0.5854, Val Loss=1.6886, lr=0.0100
[2025-05-07 01:32:30,538][train][INFO] - Epoch 649/2000, Val Acc=0.6013, Val Loss=1.7825, lr=0.0100
[2025-05-07 01:32:36,391][train][INFO] - Epoch 659/2000, Val Acc=0.6031, Val Loss=1.7571, lr=0.0100
[2025-05-07 01:32:38,206][train][INFO] - Epoch 658/2000, Val Acc=0.5928, Val Loss=1.6357, lr=0.0100
[2025-05-07 01:32:38,378][train][INFO] - Epoch 650/2000, Val Acc=0.6051, Val Loss=1.7419, lr=0.0100
[2025-05-07 01:32:44,536][train][INFO] - Epoch 660/2000, Val Acc=0.6060, Val Loss=1.7287, lr=0.0100
[2025-05-07 01:32:45,887][train][INFO] - Epoch 659/2000, Val Acc=0.5732, Val Loss=1.7840, lr=0.0100
[2025-05-07 01:32:46,467][train][INFO] - Epoch 651/2000, Val Acc=0.6198, Val Loss=1.6863, lr=0.0100
[2025-05-07 01:32:52,252][train][INFO] - Epoch 661/2000, Val Acc=0.6063, Val Loss=1.7641, lr=0.0100
[2025-05-07 01:32:53,175][train][INFO] - Epoch 660/2000, Val Acc=0.5710, Val Loss=1.7518, lr=0.0100
[2025-05-07 01:32:54,463][train][INFO] - Epoch 652/2000, Val Acc=0.5999, Val Loss=1.8078, lr=0.0100
[2025-05-07 01:32:59,884][train][INFO] - Epoch 662/2000, Val Acc=0.6083, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:33:01,192][train][INFO] - Epoch 661/2000, Val Acc=0.5778, Val Loss=1.7257, lr=0.0100
[2025-05-07 01:33:02,413][train][INFO] - Epoch 653/2000, Val Acc=0.6135, Val Loss=1.7153, lr=0.0100
[2025-05-07 01:33:07,756][train][INFO] - Epoch 663/2000, Val Acc=0.6050, Val Loss=1.7573, lr=0.0100
[2025-05-07 01:33:09,041][train][INFO] - Epoch 662/2000, Val Acc=0.5975, Val Loss=1.6320, lr=0.0100
[2025-05-07 01:33:10,303][train][INFO] - Epoch 654/2000, Val Acc=0.6012, Val Loss=1.7440, lr=0.0100
[2025-05-07 01:33:15,428][train][INFO] - Epoch 664/2000, Val Acc=0.6037, Val Loss=1.7170, lr=0.0100
[2025-05-07 01:33:16,332][train][INFO] - Epoch 663/2000, Val Acc=0.5762, Val Loss=1.7129, lr=0.0100
[2025-05-07 01:33:18,305][train][INFO] - Epoch 655/2000, Val Acc=0.6226, Val Loss=1.6642, lr=0.0100
[2025-05-07 01:33:23,126][train][INFO] - Epoch 664/2000, Val Acc=0.5757, Val Loss=1.7206, lr=0.0100
[2025-05-07 01:33:23,285][train][INFO] - Epoch 665/2000, Val Acc=0.5746, Val Loss=1.9434, lr=0.0100
[2025-05-07 01:33:26,317][train][INFO] - Epoch 656/2000, Val Acc=0.6080, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:33:30,873][train][INFO] - Epoch 666/2000, Val Acc=0.5997, Val Loss=1.8095, lr=0.0100
[2025-05-07 01:33:31,033][train][INFO] - Epoch 665/2000, Val Acc=0.5708, Val Loss=1.7829, lr=0.0100
[2025-05-07 01:33:34,032][train][INFO] - Epoch 657/2000, Val Acc=0.5914, Val Loss=1.8373, lr=0.0100
[2025-05-07 01:33:38,358][train][INFO] - Epoch 667/2000, Val Acc=0.6287, Val Loss=1.6129, lr=0.0100
[2025-05-07 01:33:38,667][train][INFO] - Epoch 666/2000, Val Acc=0.5951, Val Loss=1.6338, lr=0.0100
[2025-05-07 01:33:41,926][train][INFO] - Epoch 658/2000, Val Acc=0.6120, Val Loss=1.7185, lr=0.0100
[2025-05-07 01:33:46,006][train][INFO] - Epoch 668/2000, Val Acc=0.6045, Val Loss=1.7555, lr=0.0100
[2025-05-07 01:33:46,303][train][INFO] - Epoch 667/2000, Val Acc=0.5798, Val Loss=1.7399, lr=0.0100
[2025-05-07 01:33:49,565][train][INFO] - Epoch 659/2000, Val Acc=0.6031, Val Loss=1.7571, lr=0.0100
[2025-05-07 01:33:53,776][train][INFO] - Epoch 669/2000, Val Acc=0.6018, Val Loss=1.7975, lr=0.0100
[2025-05-07 01:33:54,002][train][INFO] - Epoch 668/2000, Val Acc=0.5739, Val Loss=1.7329, lr=0.0100
[2025-05-07 01:33:57,166][train][INFO] - Epoch 660/2000, Val Acc=0.6060, Val Loss=1.7287, lr=0.0100
[2025-05-07 01:34:01,286][train][INFO] - Epoch 670/2000, Val Acc=0.5961, Val Loss=1.7891, lr=0.0100
[2025-05-07 01:34:01,860][train][INFO] - Epoch 669/2000, Val Acc=0.5781, Val Loss=1.7577, lr=0.0100
[2025-05-07 01:34:04,708][train][INFO] - Epoch 661/2000, Val Acc=0.6063, Val Loss=1.7641, lr=0.0100
[2025-05-07 01:34:08,839][train][INFO] - Epoch 671/2000, Val Acc=0.6173, Val Loss=1.7267, lr=0.0100
[2025-05-07 01:34:09,526][train][INFO] - Epoch 670/2000, Val Acc=0.5878, Val Loss=1.6797, lr=0.0100
[2025-05-07 01:34:12,497][train][INFO] - Epoch 662/2000, Val Acc=0.6083, Val Loss=1.7338, lr=0.0100
[2025-05-07 01:34:16,669][train][INFO] - Epoch 671/2000, Val Acc=0.5914, Val Loss=1.6475, lr=0.0100
[2025-05-07 01:34:16,760][train][INFO] - Epoch 672/2000, Val Acc=0.6223, Val Loss=1.6675, lr=0.0100
[2025-05-07 01:34:20,414][train][INFO] - Epoch 663/2000, Val Acc=0.6050, Val Loss=1.7573, lr=0.0100
[2025-05-07 01:34:24,302][train][INFO] - Epoch 672/2000, Val Acc=0.5854, Val Loss=1.7212, lr=0.0100
[2025-05-07 01:34:24,442][train][INFO] - Epoch 673/2000, Val Acc=0.6170, Val Loss=1.6881, lr=0.0100
[2025-05-07 01:34:28,677][train][INFO] - Epoch 664/2000, Val Acc=0.6037, Val Loss=1.7170, lr=0.0100
[2025-05-07 01:34:31,893][train][INFO] - Epoch 673/2000, Val Acc=0.5824, Val Loss=1.7227, lr=0.0100
[2025-05-07 01:34:32,009][train][INFO] - Epoch 674/2000, Val Acc=0.6075, Val Loss=1.7776, lr=0.0100
[2025-05-07 01:34:36,414][train][INFO] - Epoch 665/2000, Val Acc=0.5746, Val Loss=1.9434, lr=0.0100
[2025-05-07 01:34:39,737][train][INFO] - Epoch 674/2000, Val Acc=0.5806, Val Loss=1.7055, lr=0.0100
[2025-05-07 01:34:40,017][train][INFO] - Epoch 675/2000, Val Acc=0.6208, Val Loss=1.6453, lr=0.0100
[2025-05-07 01:34:44,125][train][INFO] - Epoch 666/2000, Val Acc=0.5997, Val Loss=1.8095, lr=0.0100
[2025-05-07 01:34:47,662][train][INFO] - Epoch 675/2000, Val Acc=0.5907, Val Loss=1.6671, lr=0.0100
[2025-05-07 01:34:48,099][train][INFO] - Epoch 676/2000, Val Acc=0.6175, Val Loss=1.7404, lr=0.0100
[2025-05-07 01:34:51,600][train][INFO] - Epoch 667/2000, Val Acc=0.6287, Val Loss=1.6129, lr=0.0100
[2025-05-07 01:34:55,299][train][INFO] - Epoch 676/2000, Val Acc=0.5879, Val Loss=1.6583, lr=0.0100
[2025-05-07 01:34:55,570][train][INFO] - Epoch 677/2000, Val Acc=0.6135, Val Loss=1.7023, lr=0.0100
[2025-05-07 01:34:58,922][train][INFO] - Epoch 668/2000, Val Acc=0.6045, Val Loss=1.7555, lr=0.0100
[2025-05-07 01:35:02,898][train][INFO] - Epoch 677/2000, Val Acc=0.5816, Val Loss=1.6984, lr=0.0100
[2025-05-07 01:35:03,133][train][INFO] - Epoch 678/2000, Val Acc=0.6163, Val Loss=1.6956, lr=0.0100
[2025-05-07 01:35:06,720][train][INFO] - Epoch 669/2000, Val Acc=0.6018, Val Loss=1.7975, lr=0.0100
[2025-05-07 01:35:10,748][train][INFO] - Epoch 678/2000, Val Acc=0.5643, Val Loss=1.7876, lr=0.0100
[2025-05-07 01:35:10,918][train][INFO] - Epoch 679/2000, Val Acc=0.5957, Val Loss=1.7792, lr=0.0100
[2025-05-07 01:35:14,513][train][INFO] - Epoch 670/2000, Val Acc=0.5961, Val Loss=1.7891, lr=0.0100
[2025-05-07 01:35:18,401][train][INFO] - Epoch 680/2000, Val Acc=0.5940, Val Loss=1.8045, lr=0.0100
[2025-05-07 01:35:18,699][train][INFO] - Epoch 679/2000, Val Acc=0.5855, Val Loss=1.6834, lr=0.0100
[2025-05-07 01:35:22,079][train][INFO] - Epoch 671/2000, Val Acc=0.6173, Val Loss=1.7267, lr=0.0100
[2025-05-07 01:35:25,504][train][INFO] - Epoch 681/2000, Val Acc=0.6018, Val Loss=1.7744, lr=0.0100
[2025-05-07 01:35:26,078][train][INFO] - Epoch 680/2000, Val Acc=0.5597, Val Loss=1.7999, lr=0.0100
[2025-05-07 01:35:29,602][train][INFO] - Epoch 672/2000, Val Acc=0.6223, Val Loss=1.6675, lr=0.0100
[2025-05-07 01:35:33,363][train][INFO] - Epoch 682/2000, Val Acc=0.6020, Val Loss=1.7791, lr=0.0100
[2025-05-07 01:35:34,036][train][INFO] - Epoch 681/2000, Val Acc=0.5888, Val Loss=1.6675, lr=0.0100
[2025-05-07 01:35:37,396][train][INFO] - Epoch 673/2000, Val Acc=0.6170, Val Loss=1.6881, lr=0.0100
[2025-05-07 01:35:40,475][train][INFO] - Epoch 683/2000, Val Acc=0.6079, Val Loss=1.7554, lr=0.0100
[2025-05-07 01:35:42,258][train][INFO] - Epoch 682/2000, Val Acc=0.5913, Val Loss=1.6485, lr=0.0100
[2025-05-07 01:35:45,164][train][INFO] - Epoch 674/2000, Val Acc=0.6075, Val Loss=1.7776, lr=0.0100
[2025-05-07 01:35:48,227][train][INFO] - Epoch 684/2000, Val Acc=0.6201, Val Loss=1.6623, lr=0.0100
[2025-05-07 01:35:50,020][train][INFO] - Epoch 683/2000, Val Acc=0.5797, Val Loss=1.7676, lr=0.0100
[2025-05-07 01:35:52,821][train][INFO] - Epoch 675/2000, Val Acc=0.6208, Val Loss=1.6453, lr=0.0100
[2025-05-07 01:35:55,866][train][INFO] - Epoch 685/2000, Val Acc=0.6176, Val Loss=1.6929, lr=0.0100
[2025-05-07 01:35:58,014][train][INFO] - Epoch 684/2000, Val Acc=0.5790, Val Loss=1.7207, lr=0.0100
[2025-05-07 01:36:00,860][train][INFO] - Epoch 676/2000, Val Acc=0.6175, Val Loss=1.7404, lr=0.0100
[2025-05-07 01:36:03,079][train][INFO] - Epoch 686/2000, Val Acc=0.6153, Val Loss=1.6965, lr=0.0100
[2025-05-07 01:36:05,762][train][INFO] - Epoch 685/2000, Val Acc=0.5897, Val Loss=1.6902, lr=0.0100
[2025-05-07 01:36:08,568][train][INFO] - Epoch 677/2000, Val Acc=0.6135, Val Loss=1.7023, lr=0.0100
[2025-05-07 01:36:10,843][train][INFO] - Epoch 687/2000, Val Acc=0.6012, Val Loss=1.7863, lr=0.0100
[2025-05-07 01:36:13,545][train][INFO] - Epoch 686/2000, Val Acc=0.5939, Val Loss=1.6081, lr=0.0100
[2025-05-07 01:36:16,155][train][INFO] - Epoch 678/2000, Val Acc=0.6163, Val Loss=1.6956, lr=0.0100
[2025-05-07 01:36:18,604][train][INFO] - Epoch 688/2000, Val Acc=0.6020, Val Loss=1.7995, lr=0.0100
[2025-05-07 01:36:20,967][train][INFO] - Epoch 687/2000, Val Acc=0.5854, Val Loss=1.7019, lr=0.0100
[2025-05-07 01:36:24,034][train][INFO] - Epoch 679/2000, Val Acc=0.5957, Val Loss=1.7792, lr=0.0100
[2025-05-07 01:36:25,596][train][INFO] - Epoch 689/2000, Val Acc=0.6204, Val Loss=1.6905, lr=0.0100
[2025-05-07 01:36:28,938][train][INFO] - Epoch 688/2000, Val Acc=0.5872, Val Loss=1.6815, lr=0.0100
[2025-05-07 01:36:31,992][train][INFO] - Epoch 680/2000, Val Acc=0.5940, Val Loss=1.8045, lr=0.0100
[2025-05-07 01:36:33,395][train][INFO] - Epoch 690/2000, Val Acc=0.5948, Val Loss=1.8415, lr=0.0100
[2025-05-07 01:36:36,633][train][INFO] - Epoch 689/2000, Val Acc=0.5768, Val Loss=1.6971, lr=0.0100
[2025-05-07 01:36:40,087][train][INFO] - Epoch 681/2000, Val Acc=0.6018, Val Loss=1.7744, lr=0.0100
[2025-05-07 01:36:41,165][train][INFO] - Epoch 691/2000, Val Acc=0.6102, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:36:44,538][train][INFO] - Epoch 690/2000, Val Acc=0.5805, Val Loss=1.7799, lr=0.0100
[2025-05-07 01:36:48,197][train][INFO] - Epoch 682/2000, Val Acc=0.6020, Val Loss=1.7791, lr=0.0100
[2025-05-07 01:36:48,860][train][INFO] - Epoch 692/2000, Val Acc=0.6121, Val Loss=1.7446, lr=0.0100
[2025-05-07 01:36:52,647][train][INFO] - Epoch 691/2000, Val Acc=0.6019, Val Loss=1.5978, lr=0.0100
[2025-05-07 01:36:56,253][train][INFO] - Epoch 683/2000, Val Acc=0.6079, Val Loss=1.7554, lr=0.0100
[2025-05-07 01:36:56,635][train][INFO] - Epoch 693/2000, Val Acc=0.6153, Val Loss=1.7276, lr=0.0100
[2025-05-07 01:37:00,368][train][INFO] - Epoch 692/2000, Val Acc=0.6124, Val Loss=1.5619, lr=0.0100
[2025-05-07 01:37:04,160][train][INFO] - Epoch 694/2000, Val Acc=0.6071, Val Loss=1.7255, lr=0.0100
[2025-05-07 01:37:04,296][train][INFO] - Epoch 684/2000, Val Acc=0.6201, Val Loss=1.6623, lr=0.0100
[2025-05-07 01:37:08,279][train][INFO] - Epoch 693/2000, Val Acc=0.5989, Val Loss=1.5933, lr=0.0100
[2025-05-07 01:37:11,883][train][INFO] - Epoch 695/2000, Val Acc=0.6167, Val Loss=1.7017, lr=0.0100
[2025-05-07 01:37:12,069][train][INFO] - Epoch 685/2000, Val Acc=0.6176, Val Loss=1.6929, lr=0.0100
[2025-05-07 01:37:15,886][train][INFO] - Epoch 694/2000, Val Acc=0.5981, Val Loss=1.6185, lr=0.0100
[2025-05-07 01:37:19,693][train][INFO] - Epoch 696/2000, Val Acc=0.6050, Val Loss=1.7068, lr=0.0100
[2025-05-07 01:37:19,845][train][INFO] - Epoch 686/2000, Val Acc=0.6153, Val Loss=1.6965, lr=0.0100
[2025-05-07 01:37:23,192][train][INFO] - Epoch 695/2000, Val Acc=0.5853, Val Loss=1.6979, lr=0.0100
[2025-05-07 01:37:27,750][train][INFO] - Epoch 697/2000, Val Acc=0.6073, Val Loss=1.7373, lr=0.0100
[2025-05-07 01:37:27,877][train][INFO] - Epoch 687/2000, Val Acc=0.6012, Val Loss=1.7863, lr=0.0100
[2025-05-07 01:37:30,754][train][INFO] - Epoch 696/2000, Val Acc=0.5943, Val Loss=1.6446, lr=0.0100
[2025-05-07 01:37:35,315][train][INFO] - Epoch 698/2000, Val Acc=0.6002, Val Loss=1.7761, lr=0.0100
[2025-05-07 01:37:35,521][train][INFO] - Epoch 688/2000, Val Acc=0.6020, Val Loss=1.7995, lr=0.0100
[2025-05-07 01:37:38,312][train][INFO] - Epoch 697/2000, Val Acc=0.5828, Val Loss=1.7226, lr=0.0100
[2025-05-07 01:37:43,128][train][INFO] - Epoch 699/2000, Val Acc=0.6246, Val Loss=1.6752, lr=0.0100
[2025-05-07 01:37:43,294][train][INFO] - Epoch 689/2000, Val Acc=0.6204, Val Loss=1.6905, lr=0.0100
[2025-05-07 01:37:46,384][train][INFO] - Epoch 698/2000, Val Acc=0.5919, Val Loss=1.6520, lr=0.0100
[2025-05-07 01:37:50,581][train][INFO] - Epoch 700/2000, Val Acc=0.6145, Val Loss=1.7362, lr=0.0100
[2025-05-07 01:37:51,436][train][INFO] - Epoch 690/2000, Val Acc=0.5948, Val Loss=1.8415, lr=0.0100
[2025-05-07 01:37:54,074][train][INFO] - Epoch 699/2000, Val Acc=0.5949, Val Loss=1.6590, lr=0.0100
[2025-05-07 01:37:58,088][train][INFO] - Epoch 701/2000, Val Acc=0.6080, Val Loss=1.7460, lr=0.0100
[2025-05-07 01:37:59,356][train][INFO] - Epoch 691/2000, Val Acc=0.6102, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:38:01,728][train][INFO] - Epoch 700/2000, Val Acc=0.5700, Val Loss=1.7939, lr=0.0100
[2025-05-07 01:38:05,589][train][INFO] - Epoch 702/2000, Val Acc=0.6056, Val Loss=1.7637, lr=0.0100
[2025-05-07 01:38:07,112][train][INFO] - Epoch 692/2000, Val Acc=0.6121, Val Loss=1.7446, lr=0.0100
[2025-05-07 01:38:09,155][train][INFO] - Epoch 701/2000, Val Acc=0.5750, Val Loss=1.7526, lr=0.0100
[2025-05-07 01:38:12,922][train][INFO] - Epoch 703/2000, Val Acc=0.6108, Val Loss=1.7100, lr=0.0100
[2025-05-07 01:38:14,904][train][INFO] - Epoch 693/2000, Val Acc=0.6153, Val Loss=1.7276, lr=0.0100
[2025-05-07 01:38:16,743][train][INFO] - Epoch 702/2000, Val Acc=0.5975, Val Loss=1.6691, lr=0.0100
[2025-05-07 01:38:20,628][train][INFO] - Epoch 704/2000, Val Acc=0.6043, Val Loss=1.7712, lr=0.0100
[2025-05-07 01:38:22,726][train][INFO] - Epoch 694/2000, Val Acc=0.6071, Val Loss=1.7255, lr=0.0100
[2025-05-07 01:38:24,659][train][INFO] - Epoch 703/2000, Val Acc=0.5714, Val Loss=1.7545, lr=0.0100
[2025-05-07 01:38:28,457][train][INFO] - Epoch 705/2000, Val Acc=0.6078, Val Loss=1.7271, lr=0.0100
[2025-05-07 01:38:30,210][train][INFO] - Epoch 695/2000, Val Acc=0.6167, Val Loss=1.7017, lr=0.0100
[2025-05-07 01:38:32,373][train][INFO] - Epoch 704/2000, Val Acc=0.5865, Val Loss=1.6877, lr=0.0100
[2025-05-07 01:38:36,088][train][INFO] - Epoch 706/2000, Val Acc=0.6003, Val Loss=1.7868, lr=0.0100
[2025-05-07 01:38:38,216][train][INFO] - Epoch 696/2000, Val Acc=0.6050, Val Loss=1.7068, lr=0.0100
[2025-05-07 01:38:39,958][train][INFO] - Epoch 705/2000, Val Acc=0.5831, Val Loss=1.6981, lr=0.0100
[2025-05-07 01:38:44,040][train][INFO] - Epoch 707/2000, Val Acc=0.6116, Val Loss=1.7168, lr=0.0100
[2025-05-07 01:38:45,763][train][INFO] - Epoch 697/2000, Val Acc=0.6073, Val Loss=1.7373, lr=0.0100
[2025-05-07 01:38:47,656][train][INFO] - Epoch 706/2000, Val Acc=0.5799, Val Loss=1.7158, lr=0.0100
[2025-05-07 01:38:51,356][train][INFO] - Epoch 708/2000, Val Acc=0.6077, Val Loss=1.7277, lr=0.0100
[2025-05-07 01:38:53,770][train][INFO] - Epoch 698/2000, Val Acc=0.6002, Val Loss=1.7761, lr=0.0100
[2025-05-07 01:38:55,533][train][INFO] - Epoch 707/2000, Val Acc=0.5927, Val Loss=1.6428, lr=0.0100
[2025-05-07 01:38:59,021][train][INFO] - Epoch 709/2000, Val Acc=0.6046, Val Loss=1.7596, lr=0.0100
[2025-05-07 01:39:01,708][train][INFO] - Epoch 699/2000, Val Acc=0.6246, Val Loss=1.6752, lr=0.0100
[2025-05-07 01:39:03,532][train][INFO] - Epoch 708/2000, Val Acc=0.5911, Val Loss=1.6711, lr=0.0100
[2025-05-07 01:39:06,747][train][INFO] - Epoch 710/2000, Val Acc=0.6146, Val Loss=1.6999, lr=0.0100
[2025-05-07 01:39:09,846][train][INFO] - Epoch 700/2000, Val Acc=0.6145, Val Loss=1.7362, lr=0.0100
[2025-05-07 01:39:11,265][train][INFO] - Epoch 709/2000, Val Acc=0.5830, Val Loss=1.6711, lr=0.0100
[2025-05-07 01:39:14,713][train][INFO] - Epoch 711/2000, Val Acc=0.5897, Val Loss=1.8449, lr=0.0100
[2025-05-07 01:39:18,015][train][INFO] - Epoch 701/2000, Val Acc=0.6080, Val Loss=1.7460, lr=0.0100
[2025-05-07 01:39:19,431][train][INFO] - Epoch 710/2000, Val Acc=0.5763, Val Loss=1.7258, lr=0.0100
[2025-05-07 01:39:22,483][train][INFO] - Epoch 712/2000, Val Acc=0.6033, Val Loss=1.7590, lr=0.0100
[2025-05-07 01:39:26,124][train][INFO] - Epoch 702/2000, Val Acc=0.6056, Val Loss=1.7637, lr=0.0100
[2025-05-07 01:39:27,514][train][INFO] - Epoch 711/2000, Val Acc=0.5696, Val Loss=1.7930, lr=0.0100
[2025-05-07 01:39:29,829][train][INFO] - Epoch 713/2000, Val Acc=0.6127, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:39:33,530][train][INFO] - Epoch 703/2000, Val Acc=0.6108, Val Loss=1.7100, lr=0.0100
[2025-05-07 01:39:35,296][train][INFO] - Epoch 712/2000, Val Acc=0.5784, Val Loss=1.7445, lr=0.0100
[2025-05-07 01:39:37,386][train][INFO] - Epoch 714/2000, Val Acc=0.6144, Val Loss=1.7142, lr=0.0100
[2025-05-07 01:39:41,598][train][INFO] - Epoch 704/2000, Val Acc=0.6043, Val Loss=1.7712, lr=0.0100
[2025-05-07 01:39:43,311][train][INFO] - Epoch 713/2000, Val Acc=0.5737, Val Loss=1.7725, lr=0.0100
[2025-05-07 01:39:44,791][train][INFO] - Epoch 715/2000, Val Acc=0.6247, Val Loss=1.6410, lr=0.0100
[2025-05-07 01:39:49,380][train][INFO] - Epoch 705/2000, Val Acc=0.6078, Val Loss=1.7271, lr=0.0100
[2025-05-07 01:39:51,120][train][INFO] - Epoch 714/2000, Val Acc=0.5654, Val Loss=1.8045, lr=0.0100
[2025-05-07 01:39:52,442][train][INFO] - Epoch 716/2000, Val Acc=0.6087, Val Loss=1.7166, lr=0.0100
[2025-05-07 01:39:57,201][train][INFO] - Epoch 706/2000, Val Acc=0.6003, Val Loss=1.7868, lr=0.0100
[2025-05-07 01:39:59,035][train][INFO] - Epoch 715/2000, Val Acc=0.5791, Val Loss=1.7162, lr=0.0100
[2025-05-07 01:40:00,249][train][INFO] - Epoch 717/2000, Val Acc=0.6083, Val Loss=1.7367, lr=0.0100
[2025-05-07 01:40:04,465][train][INFO] - Epoch 707/2000, Val Acc=0.6116, Val Loss=1.7168, lr=0.0100
[2025-05-07 01:40:06,351][train][INFO] - Epoch 716/2000, Val Acc=0.5895, Val Loss=1.6726, lr=0.0100
[2025-05-07 01:40:07,839][train][INFO] - Epoch 718/2000, Val Acc=0.6092, Val Loss=1.6960, lr=0.0100
[2025-05-07 01:40:12,622][train][INFO] - Epoch 708/2000, Val Acc=0.6077, Val Loss=1.7277, lr=0.0100
[2025-05-07 01:40:13,891][train][INFO] - Epoch 717/2000, Val Acc=0.5958, Val Loss=1.6624, lr=0.0100
[2025-05-07 01:40:15,431][train][INFO] - Epoch 719/2000, Val Acc=0.6192, Val Loss=1.6878, lr=0.0100
[2025-05-07 01:40:20,498][train][INFO] - Epoch 709/2000, Val Acc=0.6046, Val Loss=1.7596, lr=0.0100
[2025-05-07 01:40:21,533][train][INFO] - Epoch 718/2000, Val Acc=0.5875, Val Loss=1.6911, lr=0.0100
[2025-05-07 01:40:23,187][train][INFO] - Epoch 720/2000, Val Acc=0.6067, Val Loss=1.7568, lr=0.0100
[2025-05-07 01:40:28,101][train][INFO] - Epoch 710/2000, Val Acc=0.6146, Val Loss=1.6999, lr=0.0100
[2025-05-07 01:40:29,295][train][INFO] - Epoch 719/2000, Val Acc=0.5831, Val Loss=1.7518, lr=0.0100
[2025-05-07 01:40:30,818][train][INFO] - Epoch 721/2000, Val Acc=0.6071, Val Loss=1.7703, lr=0.0100
[2025-05-07 01:40:36,064][train][INFO] - Epoch 711/2000, Val Acc=0.5897, Val Loss=1.8449, lr=0.0100
[2025-05-07 01:40:36,150][train][INFO] - Epoch 720/2000, Val Acc=0.5920, Val Loss=1.6476, lr=0.0100
[2025-05-07 01:40:38,009][train][INFO] - Epoch 722/2000, Val Acc=0.6135, Val Loss=1.7140, lr=0.0100
[2025-05-07 01:40:43,861][train][INFO] - Epoch 721/2000, Val Acc=0.5833, Val Loss=1.7054, lr=0.0100
[2025-05-07 01:40:44,277][train][INFO] - Epoch 712/2000, Val Acc=0.6033, Val Loss=1.7590, lr=0.0100
[2025-05-07 01:40:45,511][train][INFO] - Epoch 723/2000, Val Acc=0.6088, Val Loss=1.7114, lr=0.0100
[2025-05-07 01:40:51,811][train][INFO] - Epoch 722/2000, Val Acc=0.6022, Val Loss=1.6161, lr=0.0100
[2025-05-07 01:40:52,633][train][INFO] - Epoch 713/2000, Val Acc=0.6127, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:40:53,002][train][INFO] - Epoch 724/2000, Val Acc=0.6033, Val Loss=1.7667, lr=0.0100
[2025-05-07 01:40:59,875][train][INFO] - Epoch 723/2000, Val Acc=0.5770, Val Loss=1.7475, lr=0.0100
[2025-05-07 01:41:00,890][train][INFO] - Epoch 714/2000, Val Acc=0.6144, Val Loss=1.7142, lr=0.0100
[2025-05-07 01:41:01,154][train][INFO] - Epoch 725/2000, Val Acc=0.6091, Val Loss=1.7515, lr=0.0100
[2025-05-07 01:41:07,765][train][INFO] - Epoch 724/2000, Val Acc=0.5796, Val Loss=1.7286, lr=0.0100
[2025-05-07 01:41:08,750][train][INFO] - Epoch 726/2000, Val Acc=0.6091, Val Loss=1.7147, lr=0.0100
[2025-05-07 01:41:08,996][train][INFO] - Epoch 715/2000, Val Acc=0.6247, Val Loss=1.6410, lr=0.0100
[2025-05-07 01:41:15,220][train][INFO] - Epoch 725/2000, Val Acc=0.5842, Val Loss=1.7126, lr=0.0100
[2025-05-07 01:41:16,570][train][INFO] - Epoch 727/2000, Val Acc=0.6170, Val Loss=1.6989, lr=0.0100
[2025-05-07 01:41:16,910][train][INFO] - Epoch 716/2000, Val Acc=0.6087, Val Loss=1.7166, lr=0.0100
[2025-05-07 01:41:22,930][train][INFO] - Epoch 728/2000, Val Acc=0.6103, Val Loss=1.7404, lr=0.0100
[2025-05-07 01:41:23,362][train][INFO] - Epoch 726/2000, Val Acc=0.5691, Val Loss=1.7962, lr=0.0100
[2025-05-07 01:41:24,659][train][INFO] - Epoch 717/2000, Val Acc=0.6083, Val Loss=1.7367, lr=0.0100
[2025-05-07 01:41:30,865][train][INFO] - Epoch 729/2000, Val Acc=0.6213, Val Loss=1.6968, lr=0.0100
[2025-05-07 01:41:31,322][train][INFO] - Epoch 727/2000, Val Acc=0.5914, Val Loss=1.6716, lr=0.0100
[2025-05-07 01:41:32,730][train][INFO] - Epoch 718/2000, Val Acc=0.6092, Val Loss=1.6960, lr=0.0100
[2025-05-07 01:41:38,812][train][INFO] - Epoch 728/2000, Val Acc=0.5838, Val Loss=1.6669, lr=0.0100
[2025-05-07 01:41:38,814][train][INFO] - Epoch 730/2000, Val Acc=0.6172, Val Loss=1.6839, lr=0.0100
[2025-05-07 01:41:40,778][train][INFO] - Epoch 719/2000, Val Acc=0.6192, Val Loss=1.6878, lr=0.0100
[2025-05-07 01:41:46,710][train][INFO] - Epoch 731/2000, Val Acc=0.6215, Val Loss=1.6717, lr=0.0100
[2025-05-07 01:41:46,754][train][INFO] - Epoch 729/2000, Val Acc=0.5805, Val Loss=1.7285, lr=0.0100
[2025-05-07 01:41:48,971][train][INFO] - Epoch 720/2000, Val Acc=0.6067, Val Loss=1.7568, lr=0.0100
[2025-05-07 01:41:54,535][train][INFO] - Epoch 732/2000, Val Acc=0.6094, Val Loss=1.7397, lr=0.0100
[2025-05-07 01:41:54,662][train][INFO] - Epoch 730/2000, Val Acc=0.5841, Val Loss=1.7047, lr=0.0100
[2025-05-07 01:41:56,484][train][INFO] - Epoch 721/2000, Val Acc=0.6071, Val Loss=1.7703, lr=0.0100
[2025-05-07 01:42:02,037][train][INFO] - Epoch 733/2000, Val Acc=0.6122, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:42:02,242][train][INFO] - Epoch 731/2000, Val Acc=0.5886, Val Loss=1.6877, lr=0.0100
[2025-05-07 01:42:04,151][train][INFO] - Epoch 722/2000, Val Acc=0.6135, Val Loss=1.7140, lr=0.0100
[2025-05-07 01:42:09,826][train][INFO] - Epoch 732/2000, Val Acc=0.5780, Val Loss=1.7496, lr=0.0100
[2025-05-07 01:42:09,958][train][INFO] - Epoch 734/2000, Val Acc=0.6111, Val Loss=1.7614, lr=0.0100
[2025-05-07 01:42:11,956][train][INFO] - Epoch 723/2000, Val Acc=0.6088, Val Loss=1.7114, lr=0.0100
[2025-05-07 01:42:17,598][train][INFO] - Epoch 735/2000, Val Acc=0.6253, Val Loss=1.6443, lr=0.0100
[2025-05-07 01:42:17,922][train][INFO] - Epoch 733/2000, Val Acc=0.5662, Val Loss=1.8148, lr=0.0100
[2025-05-07 01:42:19,795][train][INFO] - Epoch 724/2000, Val Acc=0.6033, Val Loss=1.7667, lr=0.0100
[2025-05-07 01:42:25,516][train][INFO] - Epoch 736/2000, Val Acc=0.6178, Val Loss=1.6880, lr=0.0100
[2025-05-07 01:42:25,781][train][INFO] - Epoch 734/2000, Val Acc=0.5906, Val Loss=1.6755, lr=0.0100
[2025-05-07 01:42:27,667][train][INFO] - Epoch 725/2000, Val Acc=0.6091, Val Loss=1.7515, lr=0.0100
[2025-05-07 01:42:32,881][train][INFO] - Epoch 737/2000, Val Acc=0.6044, Val Loss=1.7335, lr=0.0100
[2025-05-07 01:42:33,657][train][INFO] - Epoch 735/2000, Val Acc=0.5886, Val Loss=1.6633, lr=0.0100
[2025-05-07 01:42:35,879][train][INFO] - Epoch 726/2000, Val Acc=0.6091, Val Loss=1.7147, lr=0.0100
[2025-05-07 01:42:40,298][train][INFO] - Epoch 738/2000, Val Acc=0.6135, Val Loss=1.7358, lr=0.0100
[2025-05-07 01:42:41,389][train][INFO] - Epoch 736/2000, Val Acc=0.5798, Val Loss=1.7503, lr=0.0100
[2025-05-07 01:42:44,099][train][INFO] - Epoch 727/2000, Val Acc=0.6170, Val Loss=1.6989, lr=0.0100
[2025-05-07 01:42:48,106][train][INFO] - Epoch 739/2000, Val Acc=0.5925, Val Loss=1.8349, lr=0.0100
[2025-05-07 01:42:49,005][train][INFO] - Epoch 737/2000, Val Acc=0.5826, Val Loss=1.7272, lr=0.0100
[2025-05-07 01:42:51,743][train][INFO] - Epoch 728/2000, Val Acc=0.6103, Val Loss=1.7404, lr=0.0100
[2025-05-07 01:42:55,990][train][INFO] - Epoch 740/2000, Val Acc=0.6200, Val Loss=1.6861, lr=0.0100
[2025-05-07 01:42:57,041][train][INFO] - Epoch 738/2000, Val Acc=0.6038, Val Loss=1.5974, lr=0.0100
[2025-05-07 01:43:00,011][train][INFO] - Epoch 729/2000, Val Acc=0.6213, Val Loss=1.6968, lr=0.0100
[2025-05-07 01:43:03,647][train][INFO] - Epoch 741/2000, Val Acc=0.6051, Val Loss=1.7465, lr=0.0100
[2025-05-07 01:43:05,169][train][INFO] - Epoch 739/2000, Val Acc=0.5972, Val Loss=1.6123, lr=0.0100
[2025-05-07 01:43:08,202][train][INFO] - Epoch 730/2000, Val Acc=0.6172, Val Loss=1.6839, lr=0.0100
[2025-05-07 01:43:11,353][train][INFO] - Epoch 742/2000, Val Acc=0.6228, Val Loss=1.6749, lr=0.0100
[2025-05-07 01:43:12,530][train][INFO] - Epoch 740/2000, Val Acc=0.5726, Val Loss=1.7515, lr=0.0100
[2025-05-07 01:43:16,375][train][INFO] - Epoch 731/2000, Val Acc=0.6215, Val Loss=1.6717, lr=0.0100
[2025-05-07 01:43:19,274][train][INFO] - Epoch 743/2000, Val Acc=0.6104, Val Loss=1.7622, lr=0.0100
[2025-05-07 01:43:19,847][train][INFO] - Epoch 741/2000, Val Acc=0.5930, Val Loss=1.6458, lr=0.0100
[2025-05-07 01:43:23,927][train][INFO] - Epoch 732/2000, Val Acc=0.6094, Val Loss=1.7397, lr=0.0100
[2025-05-07 01:43:27,356][train][INFO] - Epoch 744/2000, Val Acc=0.6222, Val Loss=1.6945, lr=0.0100
[2025-05-07 01:43:27,480][train][INFO] - Epoch 742/2000, Val Acc=0.5907, Val Loss=1.7223, lr=0.0100
[2025-05-07 01:43:31,674][train][INFO] - Epoch 733/2000, Val Acc=0.6122, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:43:35,409][train][INFO] - Epoch 743/2000, Val Acc=0.5771, Val Loss=1.7357, lr=0.0100
[2025-05-07 01:43:35,580][train][INFO] - Epoch 745/2000, Val Acc=0.6219, Val Loss=1.6669, lr=0.0100
[2025-05-07 01:43:39,517][train][INFO] - Epoch 734/2000, Val Acc=0.6111, Val Loss=1.7614, lr=0.0100
[2025-05-07 01:43:43,305][train][INFO] - Epoch 744/2000, Val Acc=0.5740, Val Loss=1.7723, lr=0.0100
[2025-05-07 01:43:43,311][train][INFO] - Epoch 746/2000, Val Acc=0.6078, Val Loss=1.7630, lr=0.0100
[2025-05-07 01:43:47,680][train][INFO] - Epoch 735/2000, Val Acc=0.6253, Val Loss=1.6443, lr=0.0100
[2025-05-07 01:43:50,832][train][INFO] - Epoch 745/2000, Val Acc=0.5822, Val Loss=1.7369, lr=0.0100
[2025-05-07 01:43:51,199][train][INFO] - Epoch 747/2000, Val Acc=0.6012, Val Loss=1.8007, lr=0.0100
[2025-05-07 01:43:55,451][train][INFO] - Epoch 736/2000, Val Acc=0.6178, Val Loss=1.6880, lr=0.0100
[2025-05-07 01:43:58,545][train][INFO] - Epoch 746/2000, Val Acc=0.5980, Val Loss=1.6217, lr=0.0100
[2025-05-07 01:43:58,642][train][INFO] - Epoch 748/2000, Val Acc=0.6046, Val Loss=1.7708, lr=0.0100
[2025-05-07 01:44:02,614][train][INFO] - Epoch 737/2000, Val Acc=0.6044, Val Loss=1.7335, lr=0.0100
[2025-05-07 01:44:05,851][train][INFO] - Epoch 747/2000, Val Acc=0.5858, Val Loss=1.7074, lr=0.0100
[2025-05-07 01:44:06,325][train][INFO] - Epoch 749/2000, Val Acc=0.6037, Val Loss=1.8140, lr=0.0100
[2025-05-07 01:44:10,620][train][INFO] - Epoch 738/2000, Val Acc=0.6135, Val Loss=1.7358, lr=0.0100
[2025-05-07 01:44:13,447][train][INFO] - Epoch 748/2000, Val Acc=0.5906, Val Loss=1.6543, lr=0.0100
[2025-05-07 01:44:14,092][train][INFO] - Epoch 750/2000, Val Acc=0.6173, Val Loss=1.7199, lr=0.0100
[2025-05-07 01:44:18,495][train][INFO] - Epoch 739/2000, Val Acc=0.5925, Val Loss=1.8349, lr=0.0100
[2025-05-07 01:44:21,257][train][INFO] - Epoch 749/2000, Val Acc=0.5601, Val Loss=1.8417, lr=0.0100
[2025-05-07 01:44:21,899][train][INFO] - Epoch 751/2000, Val Acc=0.6249, Val Loss=1.6713, lr=0.0100
[2025-05-07 01:44:26,347][train][INFO] - Epoch 740/2000, Val Acc=0.6200, Val Loss=1.6861, lr=0.0100
[2025-05-07 01:44:29,087][train][INFO] - Epoch 750/2000, Val Acc=0.5827, Val Loss=1.7222, lr=0.0100
[2025-05-07 01:44:29,518][train][INFO] - Epoch 752/2000, Val Acc=0.6269, Val Loss=1.6577, lr=0.0100
[2025-05-07 01:44:34,502][train][INFO] - Epoch 741/2000, Val Acc=0.6051, Val Loss=1.7465, lr=0.0100
[2025-05-07 01:44:36,711][train][INFO] - Epoch 753/2000, Val Acc=0.6006, Val Loss=1.8160, lr=0.0100
[2025-05-07 01:44:36,745][train][INFO] - Epoch 751/2000, Val Acc=0.5771, Val Loss=1.7369, lr=0.0100
[2025-05-07 01:44:42,741][train][INFO] - Epoch 742/2000, Val Acc=0.6228, Val Loss=1.6749, lr=0.0100
[2025-05-07 01:44:44,049][train][INFO] - Epoch 754/2000, Val Acc=0.5923, Val Loss=1.8122, lr=0.0100
[2025-05-07 01:44:44,731][train][INFO] - Epoch 752/2000, Val Acc=0.5806, Val Loss=1.7306, lr=0.0100
[2025-05-07 01:44:50,582][train][INFO] - Epoch 743/2000, Val Acc=0.6104, Val Loss=1.7622, lr=0.0100
[2025-05-07 01:44:50,774][train][INFO] - Epoch 755/2000, Val Acc=0.6061, Val Loss=1.7847, lr=0.0100
[2025-05-07 01:44:52,547][train][INFO] - Epoch 753/2000, Val Acc=0.5877, Val Loss=1.6926, lr=0.0100
[2025-05-07 01:44:58,604][train][INFO] - Epoch 744/2000, Val Acc=0.6222, Val Loss=1.6945, lr=0.0100
[2025-05-07 01:44:58,606][train][INFO] - Epoch 756/2000, Val Acc=0.6022, Val Loss=1.7731, lr=0.0100
[2025-05-07 01:45:00,381][train][INFO] - Epoch 754/2000, Val Acc=0.6026, Val Loss=1.6006, lr=0.0100
[2025-05-07 01:45:06,269][train][INFO] - Epoch 757/2000, Val Acc=0.6121, Val Loss=1.7579, lr=0.0100
[2025-05-07 01:45:06,376][train][INFO] - Epoch 745/2000, Val Acc=0.6219, Val Loss=1.6669, lr=0.0100
[2025-05-07 01:45:08,294][train][INFO] - Epoch 755/2000, Val Acc=0.5796, Val Loss=1.7166, lr=0.0100
[2025-05-07 01:45:13,639][train][INFO] - Epoch 758/2000, Val Acc=0.6100, Val Loss=1.7675, lr=0.0100
[2025-05-07 01:45:14,356][train][INFO] - Epoch 746/2000, Val Acc=0.6078, Val Loss=1.7630, lr=0.0100
[2025-05-07 01:45:15,245][train][INFO] - Epoch 756/2000, Val Acc=0.5705, Val Loss=1.7708, lr=0.0100
[2025-05-07 01:45:21,172][train][INFO] - Epoch 759/2000, Val Acc=0.6079, Val Loss=1.7310, lr=0.0100
[2025-05-07 01:45:22,575][train][INFO] - Epoch 747/2000, Val Acc=0.6012, Val Loss=1.8007, lr=0.0100
[2025-05-07 01:45:23,506][train][INFO] - Epoch 757/2000, Val Acc=0.5756, Val Loss=1.7510, lr=0.0100
[2025-05-07 01:45:29,023][train][INFO] - Epoch 760/2000, Val Acc=0.6234, Val Loss=1.7189, lr=0.0100
[2025-05-07 01:45:30,238][train][INFO] - Epoch 748/2000, Val Acc=0.6046, Val Loss=1.7708, lr=0.0100
[2025-05-07 01:45:31,083][train][INFO] - Epoch 758/2000, Val Acc=0.5930, Val Loss=1.6586, lr=0.0100
[2025-05-07 01:45:36,592][train][INFO] - Epoch 761/2000, Val Acc=0.6131, Val Loss=1.7332, lr=0.0100
[2025-05-07 01:45:38,111][train][INFO] - Epoch 749/2000, Val Acc=0.6037, Val Loss=1.8140, lr=0.0100
[2025-05-07 01:45:38,770][train][INFO] - Epoch 759/2000, Val Acc=0.5879, Val Loss=1.6750, lr=0.0100
[2025-05-07 01:45:44,199][train][INFO] - Epoch 762/2000, Val Acc=0.6018, Val Loss=1.7555, lr=0.0100
[2025-05-07 01:45:45,592][train][INFO] - Epoch 750/2000, Val Acc=0.6173, Val Loss=1.7199, lr=0.0100
[2025-05-07 01:45:46,648][train][INFO] - Epoch 760/2000, Val Acc=0.5742, Val Loss=1.7657, lr=0.0100
[2025-05-07 01:45:51,714][train][INFO] - Epoch 763/2000, Val Acc=0.6144, Val Loss=1.6961, lr=0.0100
[2025-05-07 01:45:53,557][train][INFO] - Epoch 751/2000, Val Acc=0.6249, Val Loss=1.6713, lr=0.0100
[2025-05-07 01:45:54,396][train][INFO] - Epoch 761/2000, Val Acc=0.5892, Val Loss=1.6931, lr=0.0100
[2025-05-07 01:45:59,335][train][INFO] - Epoch 764/2000, Val Acc=0.6036, Val Loss=1.7810, lr=0.0100
[2025-05-07 01:46:01,739][train][INFO] - Epoch 752/2000, Val Acc=0.6269, Val Loss=1.6577, lr=0.0100
[2025-05-07 01:46:02,298][train][INFO] - Epoch 762/2000, Val Acc=0.5896, Val Loss=1.6452, lr=0.0100
[2025-05-07 01:46:06,851][train][INFO] - Epoch 765/2000, Val Acc=0.6139, Val Loss=1.7419, lr=0.0100
[2025-05-07 01:46:09,863][train][INFO] - Epoch 753/2000, Val Acc=0.6006, Val Loss=1.8160, lr=0.0100
[2025-05-07 01:46:10,150][train][INFO] - Epoch 763/2000, Val Acc=0.5818, Val Loss=1.7227, lr=0.0100
[2025-05-07 01:46:14,582][train][INFO] - Epoch 766/2000, Val Acc=0.6208, Val Loss=1.6975, lr=0.0100
[2025-05-07 01:46:17,490][train][INFO] - Epoch 764/2000, Val Acc=0.5651, Val Loss=1.8165, lr=0.0100
[2025-05-07 01:46:17,688][train][INFO] - Epoch 754/2000, Val Acc=0.5923, Val Loss=1.8122, lr=0.0100
[2025-05-07 01:46:22,418][train][INFO] - Epoch 767/2000, Val Acc=0.6128, Val Loss=1.6965, lr=0.0100
[2025-05-07 01:46:25,280][train][INFO] - Epoch 755/2000, Val Acc=0.6061, Val Loss=1.7847, lr=0.0100
[2025-05-07 01:46:25,304][train][INFO] - Epoch 765/2000, Val Acc=0.5899, Val Loss=1.6810, lr=0.0100
[2025-05-07 01:46:30,062][train][INFO] - Epoch 768/2000, Val Acc=0.6226, Val Loss=1.6528, lr=0.0100
[2025-05-07 01:46:32,771][train][INFO] - Epoch 766/2000, Val Acc=0.5880, Val Loss=1.7127, lr=0.0100
[2025-05-07 01:46:33,465][train][INFO] - Epoch 756/2000, Val Acc=0.6022, Val Loss=1.7731, lr=0.0100
[2025-05-07 01:46:38,010][train][INFO] - Epoch 769/2000, Val Acc=0.6100, Val Loss=1.7954, lr=0.0100
[2025-05-07 01:46:40,601][train][INFO] - Epoch 767/2000, Val Acc=0.5921, Val Loss=1.6639, lr=0.0100
[2025-05-07 01:46:41,239][train][INFO] - Epoch 757/2000, Val Acc=0.6121, Val Loss=1.7579, lr=0.0100
[2025-05-07 01:46:45,812][train][INFO] - Epoch 770/2000, Val Acc=0.6189, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:46:48,026][train][INFO] - Epoch 768/2000, Val Acc=0.5807, Val Loss=1.7171, lr=0.0100
[2025-05-07 01:46:49,132][train][INFO] - Epoch 758/2000, Val Acc=0.6100, Val Loss=1.7675, lr=0.0100
[2025-05-07 01:46:53,621][train][INFO] - Epoch 771/2000, Val Acc=0.6079, Val Loss=1.7353, lr=0.0100
[2025-05-07 01:46:55,166][train][INFO] - Epoch 769/2000, Val Acc=0.5907, Val Loss=1.7051, lr=0.0100
[2025-05-07 01:46:57,148][train][INFO] - Epoch 759/2000, Val Acc=0.6079, Val Loss=1.7310, lr=0.0100
[2025-05-07 01:47:01,355][train][INFO] - Epoch 772/2000, Val Acc=0.6111, Val Loss=1.7631, lr=0.0100
[2025-05-07 01:47:02,605][train][INFO] - Epoch 770/2000, Val Acc=0.5974, Val Loss=1.6663, lr=0.0100
[2025-05-07 01:47:04,265][train][INFO] - Epoch 760/2000, Val Acc=0.6234, Val Loss=1.7189, lr=0.0100
[2025-05-07 01:47:09,018][train][INFO] - Epoch 773/2000, Val Acc=0.6258, Val Loss=1.6528, lr=0.0100
[2025-05-07 01:47:10,133][train][INFO] - Epoch 771/2000, Val Acc=0.5957, Val Loss=1.6282, lr=0.0100
[2025-05-07 01:47:11,772][train][INFO] - Epoch 761/2000, Val Acc=0.6131, Val Loss=1.7332, lr=0.0100
[2025-05-07 01:47:16,969][train][INFO] - Epoch 774/2000, Val Acc=0.6224, Val Loss=1.6337, lr=0.0100
[2025-05-07 01:47:17,852][train][INFO] - Epoch 772/2000, Val Acc=0.5788, Val Loss=1.7768, lr=0.0100
[2025-05-07 01:47:19,109][train][INFO] - Epoch 762/2000, Val Acc=0.6018, Val Loss=1.7555, lr=0.0100
[2025-05-07 01:47:24,486][train][INFO] - Epoch 775/2000, Val Acc=0.6077, Val Loss=1.7316, lr=0.0100
[2025-05-07 01:47:26,273][train][INFO] - Epoch 773/2000, Val Acc=0.5794, Val Loss=1.7280, lr=0.0100
[2025-05-07 01:47:27,249][train][INFO] - Epoch 763/2000, Val Acc=0.6144, Val Loss=1.6961, lr=0.0100
[2025-05-07 01:47:32,347][train][INFO] - Epoch 776/2000, Val Acc=0.6059, Val Loss=1.7786, lr=0.0100
[2025-05-07 01:47:34,043][train][INFO] - Epoch 774/2000, Val Acc=0.5880, Val Loss=1.6979, lr=0.0100
[2025-05-07 01:47:35,414][train][INFO] - Epoch 764/2000, Val Acc=0.6036, Val Loss=1.7810, lr=0.0100
[2025-05-07 01:47:40,203][train][INFO] - Epoch 777/2000, Val Acc=0.6177, Val Loss=1.7098, lr=0.0100
[2025-05-07 01:47:41,932][train][INFO] - Epoch 775/2000, Val Acc=0.5792, Val Loss=1.7075, lr=0.0100
[2025-05-07 01:47:43,347][train][INFO] - Epoch 765/2000, Val Acc=0.6139, Val Loss=1.7419, lr=0.0100
[2025-05-07 01:47:48,017][train][INFO] - Epoch 778/2000, Val Acc=0.6044, Val Loss=1.7648, lr=0.0100
[2025-05-07 01:47:49,788][train][INFO] - Epoch 776/2000, Val Acc=0.5873, Val Loss=1.6887, lr=0.0100
[2025-05-07 01:47:51,294][train][INFO] - Epoch 766/2000, Val Acc=0.6208, Val Loss=1.6975, lr=0.0100
[2025-05-07 01:47:55,319][train][INFO] - Epoch 779/2000, Val Acc=0.6123, Val Loss=1.7045, lr=0.0100
[2025-05-07 01:47:57,197][train][INFO] - Epoch 777/2000, Val Acc=0.5911, Val Loss=1.7199, lr=0.0100
[2025-05-07 01:47:59,507][train][INFO] - Epoch 767/2000, Val Acc=0.6128, Val Loss=1.6965, lr=0.0100
[2025-05-07 01:48:03,430][train][INFO] - Epoch 780/2000, Val Acc=0.6099, Val Loss=1.7393, lr=0.0100
[2025-05-07 01:48:05,236][train][INFO] - Epoch 778/2000, Val Acc=0.6004, Val Loss=1.6274, lr=0.0100
[2025-05-07 01:48:07,087][train][INFO] - Epoch 768/2000, Val Acc=0.6226, Val Loss=1.6528, lr=0.0100
[2025-05-07 01:48:11,069][train][INFO] - Epoch 781/2000, Val Acc=0.5971, Val Loss=1.8794, lr=0.0100
[2025-05-07 01:48:13,132][train][INFO] - Epoch 779/2000, Val Acc=0.5962, Val Loss=1.6684, lr=0.0100
[2025-05-07 01:48:14,934][train][INFO] - Epoch 769/2000, Val Acc=0.6100, Val Loss=1.7954, lr=0.0100
[2025-05-07 01:48:18,636][train][INFO] - Epoch 782/2000, Val Acc=0.6130, Val Loss=1.7341, lr=0.0100
[2025-05-07 01:48:20,692][train][INFO] - Epoch 780/2000, Val Acc=0.5851, Val Loss=1.7245, lr=0.0100
[2025-05-07 01:48:22,753][train][INFO] - Epoch 770/2000, Val Acc=0.6189, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:48:26,316][train][INFO] - Epoch 783/2000, Val Acc=0.6108, Val Loss=1.7460, lr=0.0100
[2025-05-07 01:48:28,253][train][INFO] - Epoch 781/2000, Val Acc=0.5306, Val Loss=2.1301, lr=0.0100
[2025-05-07 01:48:30,490][train][INFO] - Epoch 771/2000, Val Acc=0.6079, Val Loss=1.7353, lr=0.0100
[2025-05-07 01:48:33,868][train][INFO] - Epoch 784/2000, Val Acc=0.5880, Val Loss=1.8802, lr=0.0100
[2025-05-07 01:48:36,017][train][INFO] - Epoch 782/2000, Val Acc=0.5753, Val Loss=1.7457, lr=0.0100
[2025-05-07 01:48:38,581][train][INFO] - Epoch 772/2000, Val Acc=0.6111, Val Loss=1.7631, lr=0.0100
[2025-05-07 01:48:41,172][train][INFO] - Epoch 785/2000, Val Acc=0.6181, Val Loss=1.7174, lr=0.0100
[2025-05-07 01:48:43,687][train][INFO] - Epoch 783/2000, Val Acc=0.5806, Val Loss=1.7234, lr=0.0100
[2025-05-07 01:48:46,693][train][INFO] - Epoch 773/2000, Val Acc=0.6258, Val Loss=1.6528, lr=0.0100
[2025-05-07 01:48:48,624][train][INFO] - Epoch 786/2000, Val Acc=0.6056, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:48:51,711][train][INFO] - Epoch 784/2000, Val Acc=0.6033, Val Loss=1.6014, lr=0.0100
[2025-05-07 01:48:54,395][train][INFO] - Epoch 774/2000, Val Acc=0.6224, Val Loss=1.6337, lr=0.0100
[2025-05-07 01:48:56,168][train][INFO] - Epoch 787/2000, Val Acc=0.6019, Val Loss=1.7758, lr=0.0100
[2025-05-07 01:48:59,612][train][INFO] - Epoch 785/2000, Val Acc=0.5862, Val Loss=1.7080, lr=0.0100
[2025-05-07 01:49:01,857][train][INFO] - Epoch 775/2000, Val Acc=0.6077, Val Loss=1.7316, lr=0.0100
[2025-05-07 01:49:03,645][train][INFO] - Epoch 788/2000, Val Acc=0.6060, Val Loss=1.7653, lr=0.0100
[2025-05-07 01:49:07,358][train][INFO] - Epoch 786/2000, Val Acc=0.5798, Val Loss=1.7445, lr=0.0100
[2025-05-07 01:49:09,769][train][INFO] - Epoch 776/2000, Val Acc=0.6059, Val Loss=1.7786, lr=0.0100
[2025-05-07 01:49:11,225][train][INFO] - Epoch 789/2000, Val Acc=0.6050, Val Loss=1.7854, lr=0.0100
[2025-05-07 01:49:14,927][train][INFO] - Epoch 787/2000, Val Acc=0.5962, Val Loss=1.6283, lr=0.0100
[2025-05-07 01:49:18,024][train][INFO] - Epoch 777/2000, Val Acc=0.6177, Val Loss=1.7098, lr=0.0100
[2025-05-07 01:49:19,100][train][INFO] - Epoch 790/2000, Val Acc=0.6048, Val Loss=1.7374, lr=0.0100
[2025-05-07 01:49:22,394][train][INFO] - Epoch 788/2000, Val Acc=0.5675, Val Loss=1.8767, lr=0.0100
[2025-05-07 01:49:25,392][train][INFO] - Epoch 778/2000, Val Acc=0.6044, Val Loss=1.7648, lr=0.0100
[2025-05-07 01:49:26,661][train][INFO] - Epoch 791/2000, Val Acc=0.6056, Val Loss=1.7946, lr=0.0100
[2025-05-07 01:49:30,178][train][INFO] - Epoch 789/2000, Val Acc=0.5746, Val Loss=1.7911, lr=0.0100
[2025-05-07 01:49:33,537][train][INFO] - Epoch 779/2000, Val Acc=0.6123, Val Loss=1.7045, lr=0.0100
[2025-05-07 01:49:34,370][train][INFO] - Epoch 792/2000, Val Acc=0.6070, Val Loss=1.7526, lr=0.0100
[2025-05-07 01:49:37,945][train][INFO] - Epoch 790/2000, Val Acc=0.5686, Val Loss=1.8179, lr=0.0100
[2025-05-07 01:49:40,796][train][INFO] - Epoch 780/2000, Val Acc=0.6099, Val Loss=1.7393, lr=0.0100
[2025-05-07 01:49:42,107][train][INFO] - Epoch 793/2000, Val Acc=0.6088, Val Loss=1.7326, lr=0.0100
[2025-05-07 01:49:45,638][train][INFO] - Epoch 791/2000, Val Acc=0.5764, Val Loss=1.7896, lr=0.0100
[2025-05-07 01:49:48,357][train][INFO] - Epoch 781/2000, Val Acc=0.5971, Val Loss=1.8794, lr=0.0100
[2025-05-07 01:49:49,671][train][INFO] - Epoch 794/2000, Val Acc=0.6138, Val Loss=1.7139, lr=0.0100
[2025-05-07 01:49:53,570][train][INFO] - Epoch 792/2000, Val Acc=0.5763, Val Loss=1.7645, lr=0.0100
[2025-05-07 01:49:56,422][train][INFO] - Epoch 782/2000, Val Acc=0.6130, Val Loss=1.7341, lr=0.0100
[2025-05-07 01:49:57,806][train][INFO] - Epoch 795/2000, Val Acc=0.6127, Val Loss=1.6967, lr=0.0100
[2025-05-07 01:50:01,375][train][INFO] - Epoch 793/2000, Val Acc=0.5903, Val Loss=1.6970, lr=0.0100
[2025-05-07 01:50:03,919][train][INFO] - Epoch 783/2000, Val Acc=0.6108, Val Loss=1.7460, lr=0.0100
[2025-05-07 01:50:05,130][train][INFO] - Epoch 796/2000, Val Acc=0.6013, Val Loss=1.7996, lr=0.0100
[2025-05-07 01:50:09,083][train][INFO] - Epoch 794/2000, Val Acc=0.5946, Val Loss=1.6397, lr=0.0100
[2025-05-07 01:50:11,589][train][INFO] - Epoch 784/2000, Val Acc=0.5880, Val Loss=1.8802, lr=0.0100
[2025-05-07 01:50:12,793][train][INFO] - Epoch 797/2000, Val Acc=0.6200, Val Loss=1.6913, lr=0.0100
[2025-05-07 01:50:16,359][train][INFO] - Epoch 795/2000, Val Acc=0.5833, Val Loss=1.6789, lr=0.0100
[2025-05-07 01:50:19,270][train][INFO] - Epoch 785/2000, Val Acc=0.6181, Val Loss=1.7174, lr=0.0100
[2025-05-07 01:50:20,293][train][INFO] - Epoch 798/2000, Val Acc=0.6096, Val Loss=1.7479, lr=0.0100
[2025-05-07 01:50:24,296][train][INFO] - Epoch 796/2000, Val Acc=0.5762, Val Loss=1.7891, lr=0.0100
[2025-05-07 01:50:26,958][train][INFO] - Epoch 786/2000, Val Acc=0.6056, Val Loss=1.7618, lr=0.0100
[2025-05-07 01:50:28,225][train][INFO] - Epoch 799/2000, Val Acc=0.6178, Val Loss=1.7315, lr=0.0100
[2025-05-07 01:50:31,835][train][INFO] - Epoch 797/2000, Val Acc=0.5913, Val Loss=1.6637, lr=0.0100
[2025-05-07 01:50:35,133][train][INFO] - Epoch 787/2000, Val Acc=0.6019, Val Loss=1.7758, lr=0.0100
[2025-05-07 01:50:35,561][train][INFO] - Epoch 800/2000, Val Acc=0.6180, Val Loss=1.6615, lr=0.0100
[2025-05-07 01:50:39,319][train][INFO] - Epoch 798/2000, Val Acc=0.5756, Val Loss=1.7476, lr=0.0100
[2025-05-07 01:50:42,994][train][INFO] - Epoch 788/2000, Val Acc=0.6060, Val Loss=1.7653, lr=0.0100
[2025-05-07 01:50:43,166][train][INFO] - Epoch 801/2000, Val Acc=0.6139, Val Loss=1.7347, lr=0.0100
[2025-05-07 01:50:47,034][train][INFO] - Epoch 799/2000, Val Acc=0.5972, Val Loss=1.6413, lr=0.0100
[2025-05-07 01:50:50,726][train][INFO] - Epoch 802/2000, Val Acc=0.6165, Val Loss=1.7636, lr=0.0100
[2025-05-07 01:50:51,069][train][INFO] - Epoch 789/2000, Val Acc=0.6050, Val Loss=1.7854, lr=0.0100
[2025-05-07 01:50:54,406][train][INFO] - Epoch 800/2000, Val Acc=0.5844, Val Loss=1.7277, lr=0.0100
[2025-05-07 01:50:58,378][train][INFO] - Epoch 803/2000, Val Acc=0.5943, Val Loss=1.8518, lr=0.0100
[2025-05-07 01:50:58,603][train][INFO] - Epoch 790/2000, Val Acc=0.6048, Val Loss=1.7374, lr=0.0100
[2025-05-07 01:51:02,014][train][INFO] - Epoch 801/2000, Val Acc=0.5848, Val Loss=1.7326, lr=0.0100
[2025-05-07 01:51:05,906][train][INFO] - Epoch 804/2000, Val Acc=0.5974, Val Loss=1.8447, lr=0.0100
[2025-05-07 01:51:06,320][train][INFO] - Epoch 791/2000, Val Acc=0.6056, Val Loss=1.7946, lr=0.0100
[2025-05-07 01:51:09,945][train][INFO] - Epoch 802/2000, Val Acc=0.5955, Val Loss=1.6379, lr=0.0100
[2025-05-07 01:51:13,904][train][INFO] - Epoch 805/2000, Val Acc=0.6128, Val Loss=1.6927, lr=0.0100
[2025-05-07 01:51:14,462][train][INFO] - Epoch 792/2000, Val Acc=0.6070, Val Loss=1.7526, lr=0.0100
[2025-05-07 01:51:17,325][train][INFO] - Epoch 803/2000, Val Acc=0.5680, Val Loss=1.8079, lr=0.0100
[2025-05-07 01:51:21,346][train][INFO] - Epoch 806/2000, Val Acc=0.6099, Val Loss=1.7597, lr=0.0100
[2025-05-07 01:51:22,152][train][INFO] - Epoch 793/2000, Val Acc=0.6088, Val Loss=1.7326, lr=0.0100
[2025-05-07 01:51:24,996][train][INFO] - Epoch 804/2000, Val Acc=0.5672, Val Loss=1.8377, lr=0.0100
[2025-05-07 01:51:28,870][train][INFO] - Epoch 807/2000, Val Acc=0.6054, Val Loss=1.8199, lr=0.0100
[2025-05-07 01:51:30,099][train][INFO] - Epoch 794/2000, Val Acc=0.6138, Val Loss=1.7139, lr=0.0100
[2025-05-07 01:51:32,998][train][INFO] - Epoch 805/2000, Val Acc=0.5868, Val Loss=1.6891, lr=0.0100
[2025-05-07 01:51:36,553][train][INFO] - Epoch 808/2000, Val Acc=0.6241, Val Loss=1.6445, lr=0.0100
[2025-05-07 01:51:37,803][train][INFO] - Epoch 795/2000, Val Acc=0.6127, Val Loss=1.6967, lr=0.0100
[2025-05-07 01:51:40,461][train][INFO] - Epoch 806/2000, Val Acc=0.6011, Val Loss=1.6625, lr=0.0100
[2025-05-07 01:51:44,355][train][INFO] - Epoch 809/2000, Val Acc=0.6087, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:51:45,961][train][INFO] - Epoch 796/2000, Val Acc=0.6013, Val Loss=1.7996, lr=0.0100
[2025-05-07 01:51:47,368][train][INFO] - Epoch 807/2000, Val Acc=0.5609, Val Loss=1.8856, lr=0.0100
[2025-05-07 01:51:52,134][train][INFO] - Epoch 810/2000, Val Acc=0.6040, Val Loss=1.7521, lr=0.0100
[2025-05-07 01:51:53,520][train][INFO] - Epoch 797/2000, Val Acc=0.6200, Val Loss=1.6913, lr=0.0100
[2025-05-07 01:51:55,270][train][INFO] - Epoch 808/2000, Val Acc=0.5849, Val Loss=1.7235, lr=0.0100
[2025-05-07 01:52:00,344][train][INFO] - Epoch 811/2000, Val Acc=0.6089, Val Loss=1.7445, lr=0.0100
[2025-05-07 01:52:00,775][train][INFO] - Epoch 798/2000, Val Acc=0.6096, Val Loss=1.7479, lr=0.0100
[2025-05-07 01:52:02,765][train][INFO] - Epoch 809/2000, Val Acc=0.5696, Val Loss=1.8105, lr=0.0100
[2025-05-07 01:52:07,819][train][INFO] - Epoch 812/2000, Val Acc=0.6136, Val Loss=1.7239, lr=0.0100
[2025-05-07 01:52:08,402][train][INFO] - Epoch 799/2000, Val Acc=0.6178, Val Loss=1.7315, lr=0.0100
[2025-05-07 01:52:10,528][train][INFO] - Epoch 810/2000, Val Acc=0.5905, Val Loss=1.6764, lr=0.0100
[2025-05-07 01:52:15,154][train][INFO] - Epoch 813/2000, Val Acc=0.6220, Val Loss=1.6833, lr=0.0100
[2025-05-07 01:52:16,018][train][INFO] - Epoch 800/2000, Val Acc=0.6180, Val Loss=1.6615, lr=0.0100
[2025-05-07 01:52:18,548][train][INFO] - Epoch 811/2000, Val Acc=0.5882, Val Loss=1.6695, lr=0.0100
[2025-05-07 01:52:22,561][train][INFO] - Epoch 814/2000, Val Acc=0.6140, Val Loss=1.6954, lr=0.0100
[2025-05-07 01:52:23,871][train][INFO] - Epoch 801/2000, Val Acc=0.6139, Val Loss=1.7347, lr=0.0100
[2025-05-07 01:52:26,110][train][INFO] - Epoch 812/2000, Val Acc=0.5951, Val Loss=1.6390, lr=0.0100
[2025-05-07 01:52:30,175][train][INFO] - Epoch 815/2000, Val Acc=0.6192, Val Loss=1.6533, lr=0.0100
[2025-05-07 01:52:31,581][train][INFO] - Epoch 802/2000, Val Acc=0.6165, Val Loss=1.7636, lr=0.0100
[2025-05-07 01:52:33,831][train][INFO] - Epoch 813/2000, Val Acc=0.5948, Val Loss=1.6494, lr=0.0100
[2025-05-07 01:52:37,533][train][INFO] - Epoch 816/2000, Val Acc=0.6157, Val Loss=1.7163, lr=0.0100
[2025-05-07 01:52:38,973][train][INFO] - Epoch 803/2000, Val Acc=0.5943, Val Loss=1.8518, lr=0.0100
[2025-05-07 01:52:41,611][train][INFO] - Epoch 814/2000, Val Acc=0.5645, Val Loss=1.8084, lr=0.0100
[2025-05-07 01:52:45,318][train][INFO] - Epoch 817/2000, Val Acc=0.6237, Val Loss=1.6588, lr=0.0100
[2025-05-07 01:52:46,318][train][INFO] - Epoch 804/2000, Val Acc=0.5974, Val Loss=1.8447, lr=0.0100
[2025-05-07 01:52:49,464][train][INFO] - Epoch 815/2000, Val Acc=0.6112, Val Loss=1.5780, lr=0.0100
[2025-05-07 01:52:52,925][train][INFO] - Epoch 818/2000, Val Acc=0.6235, Val Loss=1.6426, lr=0.0100
[2025-05-07 01:52:54,395][train][INFO] - Epoch 805/2000, Val Acc=0.6128, Val Loss=1.6927, lr=0.0100
[2025-05-07 01:52:57,200][train][INFO] - Epoch 816/2000, Val Acc=0.5884, Val Loss=1.6601, lr=0.0100
[2025-05-07 01:53:00,795][train][INFO] - Epoch 819/2000, Val Acc=0.6207, Val Loss=1.6843, lr=0.0100
[2025-05-07 01:53:02,375][train][INFO] - Epoch 806/2000, Val Acc=0.6099, Val Loss=1.7597, lr=0.0100
[2025-05-07 01:53:04,788][train][INFO] - Epoch 817/2000, Val Acc=0.5920, Val Loss=1.6427, lr=0.0100
[2025-05-07 01:53:08,737][train][INFO] - Epoch 820/2000, Val Acc=0.6154, Val Loss=1.6901, lr=0.0100
[2025-05-07 01:53:10,128][train][INFO] - Epoch 807/2000, Val Acc=0.6054, Val Loss=1.8199, lr=0.0100
[2025-05-07 01:53:12,328][train][INFO] - Epoch 818/2000, Val Acc=0.5948, Val Loss=1.6627, lr=0.0100
[2025-05-07 01:53:16,270][train][INFO] - Epoch 821/2000, Val Acc=0.6085, Val Loss=1.7676, lr=0.0100
[2025-05-07 01:53:17,573][train][INFO] - Epoch 808/2000, Val Acc=0.6241, Val Loss=1.6445, lr=0.0100
[2025-05-07 01:53:19,898][train][INFO] - Epoch 819/2000, Val Acc=0.5703, Val Loss=1.8122, lr=0.0100
[2025-05-07 01:53:23,618][train][INFO] - Epoch 822/2000, Val Acc=0.6147, Val Loss=1.6734, lr=0.0100
[2025-05-07 01:53:25,658][train][INFO] - Epoch 809/2000, Val Acc=0.6087, Val Loss=1.7664, lr=0.0100
[2025-05-07 01:53:27,871][train][INFO] - Epoch 820/2000, Val Acc=0.5738, Val Loss=1.7963, lr=0.0100
[2025-05-07 01:53:31,186][train][INFO] - Epoch 823/2000, Val Acc=0.6100, Val Loss=1.7630, lr=0.0100
[2025-05-07 01:53:33,578][train][INFO] - Epoch 810/2000, Val Acc=0.6040, Val Loss=1.7521, lr=0.0100
[2025-05-07 01:53:36,071][train][INFO] - Epoch 821/2000, Val Acc=0.5955, Val Loss=1.6550, lr=0.0100
[2025-05-07 01:53:38,934][train][INFO] - Epoch 824/2000, Val Acc=0.6097, Val Loss=1.7290, lr=0.0100
[2025-05-07 01:53:40,668][train][INFO] - Epoch 811/2000, Val Acc=0.6089, Val Loss=1.7445, lr=0.0100
[2025-05-07 01:53:43,921][train][INFO] - Epoch 822/2000, Val Acc=0.5464, Val Loss=1.9254, lr=0.0100
[2025-05-07 01:53:46,397][train][INFO] - Epoch 825/2000, Val Acc=0.6089, Val Loss=1.7838, lr=0.0100
[2025-05-07 01:53:48,393][train][INFO] - Epoch 812/2000, Val Acc=0.6136, Val Loss=1.7239, lr=0.0100
[2025-05-07 01:53:51,780][train][INFO] - Epoch 823/2000, Val Acc=0.6024, Val Loss=1.5911, lr=0.0100
[2025-05-07 01:53:53,995][train][INFO] - Epoch 826/2000, Val Acc=0.6039, Val Loss=1.7599, lr=0.0100
[2025-05-07 01:53:56,359][train][INFO] - Epoch 813/2000, Val Acc=0.6220, Val Loss=1.6833, lr=0.0100
[2025-05-07 01:53:59,550][train][INFO] - Epoch 824/2000, Val Acc=0.5800, Val Loss=1.7765, lr=0.0100
[2025-05-07 01:54:01,816][train][INFO] - Epoch 827/2000, Val Acc=0.5917, Val Loss=1.8531, lr=0.0100
[2025-05-07 01:54:04,068][train][INFO] - Epoch 814/2000, Val Acc=0.6140, Val Loss=1.6954, lr=0.0100
[2025-05-07 01:54:06,865][train][INFO] - Epoch 825/2000, Val Acc=0.5903, Val Loss=1.6460, lr=0.0100
[2025-05-07 01:54:09,500][train][INFO] - Epoch 828/2000, Val Acc=0.6191, Val Loss=1.6939, lr=0.0100
[2025-05-07 01:54:11,452][train][INFO] - Epoch 815/2000, Val Acc=0.6192, Val Loss=1.6533, lr=0.0100
[2025-05-07 01:54:14,614][train][INFO] - Epoch 826/2000, Val Acc=0.5861, Val Loss=1.6942, lr=0.0100
[2025-05-07 01:54:17,160][train][INFO] - Epoch 829/2000, Val Acc=0.6053, Val Loss=1.7600, lr=0.0100
[2025-05-07 01:54:19,502][train][INFO] - Epoch 816/2000, Val Acc=0.6157, Val Loss=1.7163, lr=0.0100
[2025-05-07 01:54:22,137][train][INFO] - Epoch 827/2000, Val Acc=0.5701, Val Loss=1.7734, lr=0.0100
[2025-05-07 01:54:24,906][train][INFO] - Epoch 830/2000, Val Acc=0.6143, Val Loss=1.7143, lr=0.0100
[2025-05-07 01:54:27,043][train][INFO] - Epoch 817/2000, Val Acc=0.6237, Val Loss=1.6588, lr=0.0100
[2025-05-07 01:54:29,474][train][INFO] - Epoch 828/2000, Val Acc=0.5935, Val Loss=1.6635, lr=0.0100
[2025-05-07 01:54:32,944][train][INFO] - Epoch 831/2000, Val Acc=0.5972, Val Loss=1.8781, lr=0.0100
[2025-05-07 01:54:34,891][train][INFO] - Epoch 818/2000, Val Acc=0.6235, Val Loss=1.6426, lr=0.0100
[2025-05-07 01:54:37,367][train][INFO] - Epoch 829/2000, Val Acc=0.5724, Val Loss=1.7802, lr=0.0100
[2025-05-07 01:54:40,524][train][INFO] - Epoch 832/2000, Val Acc=0.6255, Val Loss=1.6323, lr=0.0100
[2025-05-07 01:54:42,769][train][INFO] - Epoch 819/2000, Val Acc=0.6207, Val Loss=1.6843, lr=0.0100
[2025-05-07 01:54:44,977][train][INFO] - Epoch 830/2000, Val Acc=0.5875, Val Loss=1.6784, lr=0.0100
[2025-05-07 01:54:47,856][train][INFO] - Epoch 833/2000, Val Acc=0.5882, Val Loss=1.8685, lr=0.0100
[2025-05-07 01:54:50,917][train][INFO] - Epoch 820/2000, Val Acc=0.6154, Val Loss=1.6901, lr=0.0100
[2025-05-07 01:54:52,549][train][INFO] - Epoch 831/2000, Val Acc=0.5876, Val Loss=1.7148, lr=0.0100
[2025-05-07 01:54:55,723][train][INFO] - Epoch 834/2000, Val Acc=0.6118, Val Loss=1.7408, lr=0.0100
[2025-05-07 01:54:58,300][train][INFO] - Epoch 821/2000, Val Acc=0.6085, Val Loss=1.7676, lr=0.0100
[2025-05-07 01:55:00,304][train][INFO] - Epoch 832/2000, Val Acc=0.5883, Val Loss=1.6809, lr=0.0100
[2025-05-07 01:55:03,107][train][INFO] - Epoch 835/2000, Val Acc=0.6256, Val Loss=1.6994, lr=0.0100
[2025-05-07 01:55:06,571][train][INFO] - Epoch 822/2000, Val Acc=0.6147, Val Loss=1.6734, lr=0.0100
[2025-05-07 01:55:07,670][train][INFO] - Epoch 833/2000, Val Acc=0.5949, Val Loss=1.6437, lr=0.0100
[2025-05-07 01:55:10,802][train][INFO] - Epoch 836/2000, Val Acc=0.6222, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:55:14,298][train][INFO] - Epoch 823/2000, Val Acc=0.6100, Val Loss=1.7630, lr=0.0100
[2025-05-07 01:55:15,456][train][INFO] - Epoch 834/2000, Val Acc=0.5819, Val Loss=1.7334, lr=0.0100
[2025-05-07 01:55:18,046][train][INFO] - Epoch 837/2000, Val Acc=0.6107, Val Loss=1.7561, lr=0.0100
[2025-05-07 01:55:22,351][train][INFO] - Epoch 824/2000, Val Acc=0.6097, Val Loss=1.7290, lr=0.0100
[2025-05-07 01:55:23,421][train][INFO] - Epoch 835/2000, Val Acc=0.5955, Val Loss=1.6868, lr=0.0100
[2025-05-07 01:55:25,508][train][INFO] - Epoch 838/2000, Val Acc=0.5895, Val Loss=1.9170, lr=0.0100
[2025-05-07 01:55:30,364][train][INFO] - Epoch 825/2000, Val Acc=0.6089, Val Loss=1.7838, lr=0.0100
[2025-05-07 01:55:30,927][train][INFO] - Epoch 836/2000, Val Acc=0.5939, Val Loss=1.6306, lr=0.0100
[2025-05-07 01:55:32,860][train][INFO] - Epoch 839/2000, Val Acc=0.6226, Val Loss=1.6710, lr=0.0100
[2025-05-07 01:55:38,034][train][INFO] - Epoch 826/2000, Val Acc=0.6039, Val Loss=1.7599, lr=0.0100
[2025-05-07 01:55:38,492][train][INFO] - Epoch 837/2000, Val Acc=0.6032, Val Loss=1.6474, lr=0.0100
[2025-05-07 01:55:40,547][train][INFO] - Epoch 840/2000, Val Acc=0.6199, Val Loss=1.6702, lr=0.0100
[2025-05-07 01:55:45,791][train][INFO] - Epoch 827/2000, Val Acc=0.5917, Val Loss=1.8531, lr=0.0100
[2025-05-07 01:55:46,366][train][INFO] - Epoch 838/2000, Val Acc=0.5918, Val Loss=1.6435, lr=0.0100
[2025-05-07 01:55:48,221][train][INFO] - Epoch 841/2000, Val Acc=0.6165, Val Loss=1.7070, lr=0.0100
[2025-05-07 01:55:53,472][train][INFO] - Epoch 839/2000, Val Acc=0.5840, Val Loss=1.7079, lr=0.0100
[2025-05-07 01:55:53,589][train][INFO] - Epoch 828/2000, Val Acc=0.6191, Val Loss=1.6939, lr=0.0100
[2025-05-07 01:55:55,320][train][INFO] - Epoch 842/2000, Val Acc=0.6147, Val Loss=1.6850, lr=0.0100
[2025-05-07 01:56:01,331][train][INFO] - Epoch 840/2000, Val Acc=0.5839, Val Loss=1.7130, lr=0.0100
[2025-05-07 01:56:01,687][train][INFO] - Epoch 829/2000, Val Acc=0.6053, Val Loss=1.7600, lr=0.0100
[2025-05-07 01:56:03,066][train][INFO] - Epoch 843/2000, Val Acc=0.6089, Val Loss=1.7468, lr=0.0100
[2025-05-07 01:56:09,464][train][INFO] - Epoch 841/2000, Val Acc=0.5915, Val Loss=1.6486, lr=0.0100
[2025-05-07 01:56:09,528][train][INFO] - Epoch 830/2000, Val Acc=0.6143, Val Loss=1.7143, lr=0.0100
[2025-05-07 01:56:10,911][train][INFO] - Epoch 844/2000, Val Acc=0.6050, Val Loss=1.7755, lr=0.0100
[2025-05-07 01:56:16,929][train][INFO] - Epoch 842/2000, Val Acc=0.5868, Val Loss=1.7095, lr=0.0100
[2025-05-07 01:56:17,583][train][INFO] - Epoch 831/2000, Val Acc=0.5972, Val Loss=1.8781, lr=0.0100
[2025-05-07 01:56:18,640][train][INFO] - Epoch 845/2000, Val Acc=0.6105, Val Loss=1.7843, lr=0.0100
[2025-05-07 01:56:25,024][train][INFO] - Epoch 832/2000, Val Acc=0.6255, Val Loss=1.6323, lr=0.0100
[2025-05-07 01:56:25,173][train][INFO] - Epoch 843/2000, Val Acc=0.5672, Val Loss=1.7965, lr=0.0100
[2025-05-07 01:56:26,496][train][INFO] - Epoch 846/2000, Val Acc=0.6230, Val Loss=1.7116, lr=0.0100
[2025-05-07 01:56:32,512][train][INFO] - Epoch 844/2000, Val Acc=0.5933, Val Loss=1.6455, lr=0.0100
[2025-05-07 01:56:33,003][train][INFO] - Epoch 833/2000, Val Acc=0.5882, Val Loss=1.8685, lr=0.0100
[2025-05-07 01:56:34,556][train][INFO] - Epoch 847/2000, Val Acc=0.6057, Val Loss=1.7398, lr=0.0100
[2025-05-07 01:56:40,431][train][INFO] - Epoch 845/2000, Val Acc=0.5727, Val Loss=1.7900, lr=0.0100
[2025-05-07 01:56:40,798][train][INFO] - Epoch 834/2000, Val Acc=0.6118, Val Loss=1.7408, lr=0.0100
[2025-05-07 01:56:42,049][train][INFO] - Epoch 848/2000, Val Acc=0.6235, Val Loss=1.6740, lr=0.0100
[2025-05-07 01:56:48,226][train][INFO] - Epoch 835/2000, Val Acc=0.6256, Val Loss=1.6994, lr=0.0100
[2025-05-07 01:56:48,279][train][INFO] - Epoch 846/2000, Val Acc=0.5979, Val Loss=1.6666, lr=0.0100
[2025-05-07 01:56:49,694][train][INFO] - Epoch 849/2000, Val Acc=0.6136, Val Loss=1.7067, lr=0.0100
[2025-05-07 01:56:56,520][train][INFO] - Epoch 847/2000, Val Acc=0.5891, Val Loss=1.6723, lr=0.0100
[2025-05-07 01:56:56,630][train][INFO] - Epoch 850/2000, Val Acc=0.6050, Val Loss=1.7841, lr=0.0100
[2025-05-07 01:56:56,655][train][INFO] - Epoch 836/2000, Val Acc=0.6222, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:57:04,128][train][INFO] - Epoch 851/2000, Val Acc=0.6006, Val Loss=1.8089, lr=0.0100
[2025-05-07 01:57:04,298][train][INFO] - Epoch 848/2000, Val Acc=0.5862, Val Loss=1.7010, lr=0.0100
[2025-05-07 01:57:04,475][train][INFO] - Epoch 837/2000, Val Acc=0.6107, Val Loss=1.7561, lr=0.0100
[2025-05-07 01:57:12,000][train][INFO] - Epoch 852/2000, Val Acc=0.6204, Val Loss=1.6997, lr=0.0100
[2025-05-07 01:57:12,319][train][INFO] - Epoch 849/2000, Val Acc=0.5922, Val Loss=1.6770, lr=0.0100
[2025-05-07 01:57:12,645][train][INFO] - Epoch 838/2000, Val Acc=0.5895, Val Loss=1.9170, lr=0.0100
[2025-05-07 01:57:19,635][train][INFO] - Epoch 853/2000, Val Acc=0.6103, Val Loss=1.7433, lr=0.0100
[2025-05-07 01:57:20,089][train][INFO] - Epoch 850/2000, Val Acc=0.5975, Val Loss=1.6490, lr=0.0100
[2025-05-07 01:57:20,690][train][INFO] - Epoch 839/2000, Val Acc=0.6226, Val Loss=1.6710, lr=0.0100
[2025-05-07 01:57:26,581][train][INFO] - Epoch 854/2000, Val Acc=0.6169, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:57:28,041][train][INFO] - Epoch 851/2000, Val Acc=0.5825, Val Loss=1.7289, lr=0.0100
[2025-05-07 01:57:28,056][train][INFO] - Epoch 840/2000, Val Acc=0.6199, Val Loss=1.6702, lr=0.0100
[2025-05-07 01:57:34,326][train][INFO] - Epoch 855/2000, Val Acc=0.6112, Val Loss=1.7414, lr=0.0100
[2025-05-07 01:57:35,107][train][INFO] - Epoch 852/2000, Val Acc=0.5791, Val Loss=1.7410, lr=0.0100
[2025-05-07 01:57:35,900][train][INFO] - Epoch 841/2000, Val Acc=0.6165, Val Loss=1.7070, lr=0.0100
[2025-05-07 01:57:42,089][train][INFO] - Epoch 856/2000, Val Acc=0.6194, Val Loss=1.7050, lr=0.0100
[2025-05-07 01:57:42,650][train][INFO] - Epoch 853/2000, Val Acc=0.5891, Val Loss=1.6866, lr=0.0100
[2025-05-07 01:57:43,231][train][INFO] - Epoch 842/2000, Val Acc=0.6147, Val Loss=1.6850, lr=0.0100
[2025-05-07 01:57:49,867][train][INFO] - Epoch 857/2000, Val Acc=0.6061, Val Loss=1.7381, lr=0.0100
[2025-05-07 01:57:50,352][train][INFO] - Epoch 854/2000, Val Acc=0.6030, Val Loss=1.6198, lr=0.0100
[2025-05-07 01:57:51,076][train][INFO] - Epoch 843/2000, Val Acc=0.6089, Val Loss=1.7468, lr=0.0100
[2025-05-07 01:57:56,950][train][INFO] - Epoch 858/2000, Val Acc=0.6173, Val Loss=1.7070, lr=0.0100
[2025-05-07 01:57:57,903][train][INFO] - Epoch 855/2000, Val Acc=0.5975, Val Loss=1.6507, lr=0.0100
[2025-05-07 01:57:59,269][train][INFO] - Epoch 844/2000, Val Acc=0.6050, Val Loss=1.7755, lr=0.0100
[2025-05-07 01:58:05,051][train][INFO] - Epoch 859/2000, Val Acc=0.5892, Val Loss=1.8694, lr=0.0100
[2025-05-07 01:58:05,367][train][INFO] - Epoch 856/2000, Val Acc=0.5887, Val Loss=1.6871, lr=0.0100
[2025-05-07 01:58:07,617][train][INFO] - Epoch 845/2000, Val Acc=0.6105, Val Loss=1.7843, lr=0.0100
[2025-05-07 01:58:12,430][train][INFO] - Epoch 857/2000, Val Acc=0.5961, Val Loss=1.6311, lr=0.0100
[2025-05-07 01:58:12,810][train][INFO] - Epoch 860/2000, Val Acc=0.6145, Val Loss=1.7234, lr=0.0100
[2025-05-07 01:58:15,720][train][INFO] - Epoch 846/2000, Val Acc=0.6230, Val Loss=1.7116, lr=0.0100
[2025-05-07 01:58:20,235][train][INFO] - Epoch 858/2000, Val Acc=0.5882, Val Loss=1.7061, lr=0.0100
[2025-05-07 01:58:20,631][train][INFO] - Epoch 861/2000, Val Acc=0.6270, Val Loss=1.6394, lr=0.0100
[2025-05-07 01:58:23,860][train][INFO] - Epoch 847/2000, Val Acc=0.6057, Val Loss=1.7398, lr=0.0100
[2025-05-07 01:58:28,007][train][INFO] - Epoch 859/2000, Val Acc=0.5832, Val Loss=1.6813, lr=0.0100
[2025-05-07 01:58:28,509][train][INFO] - Epoch 862/2000, Val Acc=0.5899, Val Loss=1.8612, lr=0.0100
[2025-05-07 01:58:31,371][train][INFO] - Epoch 848/2000, Val Acc=0.6235, Val Loss=1.6740, lr=0.0100
[2025-05-07 01:58:35,870][train][INFO] - Epoch 860/2000, Val Acc=0.6009, Val Loss=1.6342, lr=0.0100
[2025-05-07 01:58:36,216][train][INFO] - Epoch 863/2000, Val Acc=0.6262, Val Loss=1.6535, lr=0.0100
[2025-05-07 01:58:39,586][train][INFO] - Epoch 849/2000, Val Acc=0.6136, Val Loss=1.7067, lr=0.0100
[2025-05-07 01:58:43,764][train][INFO] - Epoch 864/2000, Val Acc=0.6054, Val Loss=1.7741, lr=0.0100
[2025-05-07 01:58:43,896][train][INFO] - Epoch 861/2000, Val Acc=0.5992, Val Loss=1.6207, lr=0.0100
[2025-05-07 01:58:47,381][train][INFO] - Epoch 850/2000, Val Acc=0.6050, Val Loss=1.7841, lr=0.0100
[2025-05-07 01:58:51,444][train][INFO] - Epoch 865/2000, Val Acc=0.6153, Val Loss=1.6741, lr=0.0100
[2025-05-07 01:58:51,655][train][INFO] - Epoch 862/2000, Val Acc=0.5861, Val Loss=1.7044, lr=0.0100
[2025-05-07 01:58:55,586][train][INFO] - Epoch 851/2000, Val Acc=0.6006, Val Loss=1.8089, lr=0.0100
[2025-05-07 01:58:59,069][train][INFO] - Epoch 863/2000, Val Acc=0.5933, Val Loss=1.6627, lr=0.0100
[2025-05-07 01:58:59,282][train][INFO] - Epoch 866/2000, Val Acc=0.6121, Val Loss=1.7237, lr=0.0100
[2025-05-07 01:59:03,404][train][INFO] - Epoch 852/2000, Val Acc=0.6204, Val Loss=1.6997, lr=0.0100
[2025-05-07 01:59:06,298][train][INFO] - Epoch 867/2000, Val Acc=0.6172, Val Loss=1.6646, lr=0.0100
[2025-05-07 01:59:06,667][train][INFO] - Epoch 864/2000, Val Acc=0.5929, Val Loss=1.6776, lr=0.0100
[2025-05-07 01:59:11,372][train][INFO] - Epoch 853/2000, Val Acc=0.6103, Val Loss=1.7433, lr=0.0100
[2025-05-07 01:59:13,778][train][INFO] - Epoch 868/2000, Val Acc=0.6105, Val Loss=1.7190, lr=0.0100
[2025-05-07 01:59:14,137][train][INFO] - Epoch 865/2000, Val Acc=0.5881, Val Loss=1.6853, lr=0.0100
[2025-05-07 01:59:19,347][train][INFO] - Epoch 854/2000, Val Acc=0.6169, Val Loss=1.7008, lr=0.0100
[2025-05-07 01:59:21,497][train][INFO] - Epoch 869/2000, Val Acc=0.6219, Val Loss=1.6760, lr=0.0100
[2025-05-07 01:59:21,712][train][INFO] - Epoch 866/2000, Val Acc=0.5797, Val Loss=1.7832, lr=0.0100
[2025-05-07 01:59:26,833][train][INFO] - Epoch 855/2000, Val Acc=0.6112, Val Loss=1.7414, lr=0.0100
[2025-05-07 01:59:29,146][train][INFO] - Epoch 867/2000, Val Acc=0.5855, Val Loss=1.7023, lr=0.0100
[2025-05-07 01:59:29,549][train][INFO] - Epoch 870/2000, Val Acc=0.6150, Val Loss=1.7104, lr=0.0100
[2025-05-07 01:59:34,589][train][INFO] - Epoch 856/2000, Val Acc=0.6194, Val Loss=1.7050, lr=0.0100
[2025-05-07 01:59:36,584][train][INFO] - Epoch 868/2000, Val Acc=0.5887, Val Loss=1.7367, lr=0.0100
[2025-05-07 01:59:37,384][train][INFO] - Epoch 871/2000, Val Acc=0.6153, Val Loss=1.6898, lr=0.0100
[2025-05-07 01:59:42,313][train][INFO] - Epoch 857/2000, Val Acc=0.6061, Val Loss=1.7381, lr=0.0100
[2025-05-07 01:59:43,816][train][INFO] - Epoch 869/2000, Val Acc=0.5932, Val Loss=1.6499, lr=0.0100
[2025-05-07 01:59:44,889][train][INFO] - Epoch 872/2000, Val Acc=0.5949, Val Loss=1.8621, lr=0.0100
[2025-05-07 01:59:50,331][train][INFO] - Epoch 858/2000, Val Acc=0.6173, Val Loss=1.7070, lr=0.0100
[2025-05-07 01:59:51,692][train][INFO] - Epoch 870/2000, Val Acc=0.5738, Val Loss=1.7902, lr=0.0100
[2025-05-07 01:59:52,391][train][INFO] - Epoch 873/2000, Val Acc=0.6065, Val Loss=1.7456, lr=0.0100
[2025-05-07 01:59:58,284][train][INFO] - Epoch 859/2000, Val Acc=0.5892, Val Loss=1.8694, lr=0.0100
[2025-05-07 01:59:59,024][train][INFO] - Epoch 871/2000, Val Acc=0.5863, Val Loss=1.6842, lr=0.0100
[2025-05-07 02:00:00,093][train][INFO] - Epoch 874/2000, Val Acc=0.6036, Val Loss=1.7659, lr=0.0100
[2025-05-07 02:00:06,436][train][INFO] - Epoch 860/2000, Val Acc=0.6145, Val Loss=1.7234, lr=0.0100
[2025-05-07 02:00:06,641][train][INFO] - Epoch 872/2000, Val Acc=0.5701, Val Loss=1.7727, lr=0.0100
[2025-05-07 02:00:07,805][train][INFO] - Epoch 875/2000, Val Acc=0.6117, Val Loss=1.7019, lr=0.0100
[2025-05-07 02:00:14,438][train][INFO] - Epoch 873/2000, Val Acc=0.5825, Val Loss=1.7194, lr=0.0100
[2025-05-07 02:00:14,467][train][INFO] - Epoch 861/2000, Val Acc=0.6270, Val Loss=1.6394, lr=0.0100
[2025-05-07 02:00:15,151][train][INFO] - Epoch 876/2000, Val Acc=0.6166, Val Loss=1.7032, lr=0.0100
[2025-05-07 02:00:22,331][train][INFO] - Epoch 862/2000, Val Acc=0.5899, Val Loss=1.8612, lr=0.0100
[2025-05-07 02:00:22,434][train][INFO] - Epoch 874/2000, Val Acc=0.5823, Val Loss=1.6934, lr=0.0100
[2025-05-07 02:00:22,774][train][INFO] - Epoch 877/2000, Val Acc=0.6298, Val Loss=1.6210, lr=0.0100
[2025-05-07 02:00:30,259][train][INFO] - Epoch 875/2000, Val Acc=0.5920, Val Loss=1.6670, lr=0.0100
[2025-05-07 02:00:30,382][train][INFO] - Epoch 863/2000, Val Acc=0.6262, Val Loss=1.6535, lr=0.0100
[2025-05-07 02:00:30,545][train][INFO] - Epoch 878/2000, Val Acc=0.6075, Val Loss=1.7578, lr=0.0100
[2025-05-07 02:00:37,877][train][INFO] - Epoch 876/2000, Val Acc=0.5594, Val Loss=1.8394, lr=0.0100
[2025-05-07 02:00:38,223][train][INFO] - Epoch 879/2000, Val Acc=0.6108, Val Loss=1.7369, lr=0.0100
[2025-05-07 02:00:38,495][train][INFO] - Epoch 864/2000, Val Acc=0.6054, Val Loss=1.7741, lr=0.0100
[2025-05-07 02:00:45,282][train][INFO] - Epoch 877/2000, Val Acc=0.5893, Val Loss=1.6685, lr=0.0100
[2025-05-07 02:00:45,839][train][INFO] - Epoch 880/2000, Val Acc=0.6030, Val Loss=1.7840, lr=0.0100
[2025-05-07 02:00:46,086][train][INFO] - Epoch 865/2000, Val Acc=0.6153, Val Loss=1.6741, lr=0.0100
[2025-05-07 02:00:53,057][train][INFO] - Epoch 878/2000, Val Acc=0.5763, Val Loss=1.8095, lr=0.0100
[2025-05-07 02:00:53,316][train][INFO] - Epoch 881/2000, Val Acc=0.6256, Val Loss=1.6645, lr=0.0100
[2025-05-07 02:00:54,288][train][INFO] - Epoch 866/2000, Val Acc=0.6121, Val Loss=1.7237, lr=0.0100
[2025-05-07 02:01:00,167][train][INFO] - Epoch 882/2000, Val Acc=0.6222, Val Loss=1.6961, lr=0.0100
[2025-05-07 02:01:01,007][train][INFO] - Epoch 879/2000, Val Acc=0.5736, Val Loss=1.7936, lr=0.0100
[2025-05-07 02:01:01,215][train][INFO] - Epoch 867/2000, Val Acc=0.6172, Val Loss=1.6646, lr=0.0100
[2025-05-07 02:01:07,744][train][INFO] - Epoch 883/2000, Val Acc=0.6106, Val Loss=1.7480, lr=0.0100
[2025-05-07 02:01:08,944][train][INFO] - Epoch 868/2000, Val Acc=0.6105, Val Loss=1.7190, lr=0.0100
[2025-05-07 02:01:09,023][train][INFO] - Epoch 880/2000, Val Acc=0.5864, Val Loss=1.7355, lr=0.0100
[2025-05-07 02:01:15,688][train][INFO] - Epoch 884/2000, Val Acc=0.5723, Val Loss=2.0126, lr=0.0100
[2025-05-07 02:01:16,896][train][INFO] - Epoch 881/2000, Val Acc=0.5892, Val Loss=1.7441, lr=0.0100
[2025-05-07 02:01:17,066][train][INFO] - Epoch 869/2000, Val Acc=0.6219, Val Loss=1.6760, lr=0.0100
[2025-05-07 02:01:23,650][train][INFO] - Epoch 885/2000, Val Acc=0.6216, Val Loss=1.6751, lr=0.0100
[2025-05-07 02:01:24,634][train][INFO] - Epoch 882/2000, Val Acc=0.5951, Val Loss=1.6623, lr=0.0100
[2025-05-07 02:01:25,085][train][INFO] - Epoch 870/2000, Val Acc=0.6150, Val Loss=1.7104, lr=0.0100
[2025-05-07 02:01:30,983][train][INFO] - Epoch 886/2000, Val Acc=0.5945, Val Loss=1.8543, lr=0.0100
[2025-05-07 02:01:32,431][train][INFO] - Epoch 883/2000, Val Acc=0.5938, Val Loss=1.6392, lr=0.0100
[2025-05-07 02:01:33,745][train][INFO] - Epoch 871/2000, Val Acc=0.6153, Val Loss=1.6898, lr=0.0100
[2025-05-07 02:01:38,391][train][INFO] - Epoch 887/2000, Val Acc=0.6228, Val Loss=1.6651, lr=0.0100
[2025-05-07 02:01:40,264][train][INFO] - Epoch 884/2000, Val Acc=0.5974, Val Loss=1.6541, lr=0.0100
[2025-05-07 02:01:41,966][train][INFO] - Epoch 872/2000, Val Acc=0.5949, Val Loss=1.8621, lr=0.0100
[2025-05-07 02:01:46,315][train][INFO] - Epoch 888/2000, Val Acc=0.6174, Val Loss=1.7243, lr=0.0100
[2025-05-07 02:01:47,782][train][INFO] - Epoch 885/2000, Val Acc=0.5793, Val Loss=1.7013, lr=0.0100
[2025-05-07 02:01:49,629][train][INFO] - Epoch 873/2000, Val Acc=0.6065, Val Loss=1.7456, lr=0.0100
[2025-05-07 02:01:53,815][train][INFO] - Epoch 889/2000, Val Acc=0.6229, Val Loss=1.6734, lr=0.0100
[2025-05-07 02:01:55,350][train][INFO] - Epoch 886/2000, Val Acc=0.5746, Val Loss=1.7502, lr=0.0100
[2025-05-07 02:01:57,483][train][INFO] - Epoch 874/2000, Val Acc=0.6036, Val Loss=1.7659, lr=0.0100
[2025-05-07 02:02:01,245][train][INFO] - Epoch 890/2000, Val Acc=0.6178, Val Loss=1.6857, lr=0.0100
[2025-05-07 02:02:02,904][train][INFO] - Epoch 887/2000, Val Acc=0.5932, Val Loss=1.6987, lr=0.0100
[2025-05-07 02:02:05,677][train][INFO] - Epoch 875/2000, Val Acc=0.6117, Val Loss=1.7019, lr=0.0100
[2025-05-07 02:02:08,804][train][INFO] - Epoch 891/2000, Val Acc=0.6148, Val Loss=1.7185, lr=0.0100
[2025-05-07 02:02:10,869][train][INFO] - Epoch 888/2000, Val Acc=0.5804, Val Loss=1.7399, lr=0.0100
[2025-05-07 02:02:13,699][train][INFO] - Epoch 876/2000, Val Acc=0.6166, Val Loss=1.7032, lr=0.0100
[2025-05-07 02:02:16,571][train][INFO] - Epoch 892/2000, Val Acc=0.6127, Val Loss=1.7376, lr=0.0100
[2025-05-07 02:02:17,831][train][INFO] - Epoch 889/2000, Val Acc=0.5936, Val Loss=1.6655, lr=0.0100
[2025-05-07 02:02:21,343][train][INFO] - Epoch 877/2000, Val Acc=0.6298, Val Loss=1.6210, lr=0.0100
[2025-05-07 02:02:24,371][train][INFO] - Epoch 893/2000, Val Acc=0.6172, Val Loss=1.6892, lr=0.0100
[2025-05-07 02:02:25,329][train][INFO] - Epoch 890/2000, Val Acc=0.5755, Val Loss=1.7815, lr=0.0100
[2025-05-07 02:02:28,688][train][INFO] - Epoch 878/2000, Val Acc=0.6075, Val Loss=1.7578, lr=0.0100
[2025-05-07 02:02:32,282][train][INFO] - Epoch 894/2000, Val Acc=0.6217, Val Loss=1.6875, lr=0.0100
[2025-05-07 02:02:32,690][train][INFO] - Epoch 891/2000, Val Acc=0.5907, Val Loss=1.7255, lr=0.0100
[2025-05-07 02:02:36,725][train][INFO] - Epoch 879/2000, Val Acc=0.6108, Val Loss=1.7369, lr=0.0100
[2025-05-07 02:02:39,588][train][INFO] - Epoch 895/2000, Val Acc=0.6251, Val Loss=1.6751, lr=0.0100
[2025-05-07 02:02:40,711][train][INFO] - Epoch 892/2000, Val Acc=0.6050, Val Loss=1.6033, lr=0.0100
[2025-05-07 02:02:44,151][train][INFO] - Epoch 880/2000, Val Acc=0.6030, Val Loss=1.7840, lr=0.0100
[2025-05-07 02:02:46,991][train][INFO] - Epoch 896/2000, Val Acc=0.6061, Val Loss=1.7996, lr=0.0100
[2025-05-07 02:02:48,704][train][INFO] - Epoch 893/2000, Val Acc=0.5848, Val Loss=1.7236, lr=0.0100
[2025-05-07 02:02:52,322][train][INFO] - Epoch 881/2000, Val Acc=0.6256, Val Loss=1.6645, lr=0.0100
[2025-05-07 02:02:54,666][train][INFO] - Epoch 897/2000, Val Acc=0.6047, Val Loss=1.8018, lr=0.0100
[2025-05-07 02:02:56,291][train][INFO] - Epoch 894/2000, Val Acc=0.6056, Val Loss=1.6303, lr=0.0100
[2025-05-07 02:02:59,945][train][INFO] - Epoch 882/2000, Val Acc=0.6222, Val Loss=1.6961, lr=0.0100
[2025-05-07 02:03:02,218][train][INFO] - Epoch 898/2000, Val Acc=0.6227, Val Loss=1.6655, lr=0.0100
[2025-05-07 02:03:04,129][train][INFO] - Epoch 895/2000, Val Acc=0.5989, Val Loss=1.6213, lr=0.0100
[2025-05-07 02:03:07,857][train][INFO] - Epoch 883/2000, Val Acc=0.6106, Val Loss=1.7480, lr=0.0100
[2025-05-07 02:03:09,736][train][INFO] - Epoch 899/2000, Val Acc=0.6109, Val Loss=1.7267, lr=0.0100
[2025-05-07 02:03:11,703][train][INFO] - Epoch 896/2000, Val Acc=0.5827, Val Loss=1.7499, lr=0.0100
[2025-05-07 02:03:15,636][train][INFO] - Epoch 884/2000, Val Acc=0.5723, Val Loss=2.0126, lr=0.0100
[2025-05-07 02:03:17,261][train][INFO] - Epoch 900/2000, Val Acc=0.6088, Val Loss=1.7583, lr=0.0100
[2025-05-07 02:03:19,643][train][INFO] - Epoch 897/2000, Val Acc=0.5874, Val Loss=1.6863, lr=0.0100
[2025-05-07 02:03:23,520][train][INFO] - Epoch 885/2000, Val Acc=0.6216, Val Loss=1.6751, lr=0.0100
[2025-05-07 02:03:24,870][train][INFO] - Epoch 901/2000, Val Acc=0.6084, Val Loss=1.7415, lr=0.0100
[2025-05-07 02:03:26,838][train][INFO] - Epoch 898/2000, Val Acc=0.5875, Val Loss=1.7390, lr=0.0100
[2025-05-07 02:03:31,354][train][INFO] - Epoch 886/2000, Val Acc=0.5945, Val Loss=1.8543, lr=0.0100
[2025-05-07 02:03:32,321][train][INFO] - Epoch 902/2000, Val Acc=0.6094, Val Loss=1.7704, lr=0.0100
[2025-05-07 02:03:34,526][train][INFO] - Epoch 899/2000, Val Acc=0.5765, Val Loss=1.7741, lr=0.0100
[2025-05-07 02:03:39,388][train][INFO] - Epoch 887/2000, Val Acc=0.6228, Val Loss=1.6651, lr=0.0100
[2025-05-07 02:03:39,630][train][INFO] - Epoch 903/2000, Val Acc=0.5976, Val Loss=1.8237, lr=0.0100
[2025-05-07 02:03:42,242][train][INFO] - Epoch 900/2000, Val Acc=0.5950, Val Loss=1.6847, lr=0.0100
[2025-05-07 02:03:46,889][train][INFO] - Epoch 904/2000, Val Acc=0.6183, Val Loss=1.7362, lr=0.0100
[2025-05-07 02:03:47,154][train][INFO] - Epoch 888/2000, Val Acc=0.6174, Val Loss=1.7243, lr=0.0100
[2025-05-07 02:03:49,717][train][INFO] - Epoch 901/2000, Val Acc=0.5882, Val Loss=1.7034, lr=0.0100
[2025-05-07 02:03:54,153][train][INFO] - Epoch 905/2000, Val Acc=0.6179, Val Loss=1.6973, lr=0.0100
[2025-05-07 02:03:54,816][train][INFO] - Epoch 889/2000, Val Acc=0.6229, Val Loss=1.6734, lr=0.0100
[2025-05-07 02:03:57,416][train][INFO] - Epoch 902/2000, Val Acc=0.5869, Val Loss=1.7003, lr=0.0100
[2025-05-07 02:04:02,047][train][INFO] - Epoch 906/2000, Val Acc=0.6261, Val Loss=1.6921, lr=0.0100
[2025-05-07 02:04:02,751][train][INFO] - Epoch 890/2000, Val Acc=0.6178, Val Loss=1.6857, lr=0.0100
[2025-05-07 02:04:05,271][train][INFO] - Epoch 903/2000, Val Acc=0.5841, Val Loss=1.7330, lr=0.0100
[2025-05-07 02:04:09,410][train][INFO] - Epoch 907/2000, Val Acc=0.6203, Val Loss=1.6975, lr=0.0100
[2025-05-07 02:04:10,689][train][INFO] - Epoch 891/2000, Val Acc=0.6148, Val Loss=1.7185, lr=0.0100
[2025-05-07 02:04:12,866][train][INFO] - Epoch 904/2000, Val Acc=0.5926, Val Loss=1.6985, lr=0.0100
[2025-05-07 02:04:16,863][train][INFO] - Epoch 908/2000, Val Acc=0.6157, Val Loss=1.7453, lr=0.0100
[2025-05-07 02:04:18,455][train][INFO] - Epoch 892/2000, Val Acc=0.6127, Val Loss=1.7376, lr=0.0100
[2025-05-07 02:04:20,778][train][INFO] - Epoch 905/2000, Val Acc=0.5917, Val Loss=1.6534, lr=0.0100
[2025-05-07 02:04:24,576][train][INFO] - Epoch 909/2000, Val Acc=0.5987, Val Loss=1.8584, lr=0.0100
[2025-05-07 02:04:26,324][train][INFO] - Epoch 893/2000, Val Acc=0.6172, Val Loss=1.6892, lr=0.0100
[2025-05-07 02:04:28,706][train][INFO] - Epoch 906/2000, Val Acc=0.5911, Val Loss=1.7145, lr=0.0100
[2025-05-07 02:04:31,751][train][INFO] - Epoch 910/2000, Val Acc=0.6269, Val Loss=1.6630, lr=0.0100
[2025-05-07 02:04:34,247][train][INFO] - Epoch 894/2000, Val Acc=0.6217, Val Loss=1.6875, lr=0.0100
[2025-05-07 02:04:36,635][train][INFO] - Epoch 907/2000, Val Acc=0.5965, Val Loss=1.6691, lr=0.0100
[2025-05-07 02:04:39,650][train][INFO] - Epoch 911/2000, Val Acc=0.6152, Val Loss=1.6951, lr=0.0100
[2025-05-07 02:04:42,189][train][INFO] - Epoch 895/2000, Val Acc=0.6251, Val Loss=1.6751, lr=0.0100
[2025-05-07 02:04:44,378][train][INFO] - Epoch 908/2000, Val Acc=0.5913, Val Loss=1.6639, lr=0.0100
[2025-05-07 02:04:47,103][train][INFO] - Epoch 912/2000, Val Acc=0.6005, Val Loss=1.7758, lr=0.0100
[2025-05-07 02:04:50,210][train][INFO] - Epoch 896/2000, Val Acc=0.6061, Val Loss=1.7996, lr=0.0100
[2025-05-07 02:04:52,412][train][INFO] - Epoch 909/2000, Val Acc=0.5909, Val Loss=1.6746, lr=0.0100
[2025-05-07 02:04:54,486][train][INFO] - Epoch 913/2000, Val Acc=0.6112, Val Loss=1.7258, lr=0.0100
[2025-05-07 02:04:58,194][train][INFO] - Epoch 897/2000, Val Acc=0.6047, Val Loss=1.8018, lr=0.0100
[2025-05-07 02:05:00,303][train][INFO] - Epoch 910/2000, Val Acc=0.5829, Val Loss=1.7248, lr=0.0100
[2025-05-07 02:05:02,380][train][INFO] - Epoch 914/2000, Val Acc=0.5867, Val Loss=1.8629, lr=0.0100
[2025-05-07 02:05:06,279][train][INFO] - Epoch 898/2000, Val Acc=0.6227, Val Loss=1.6655, lr=0.0100
[2025-05-07 02:05:07,919][train][INFO] - Epoch 911/2000, Val Acc=0.5932, Val Loss=1.6698, lr=0.0100
[2025-05-07 02:05:09,899][train][INFO] - Epoch 915/2000, Val Acc=0.6175, Val Loss=1.7084, lr=0.0100
[2025-05-07 02:05:14,048][train][INFO] - Epoch 899/2000, Val Acc=0.6109, Val Loss=1.7267, lr=0.0100
[2025-05-07 02:05:15,228][train][INFO] - Epoch 912/2000, Val Acc=0.5937, Val Loss=1.6613, lr=0.0100
[2025-05-07 02:05:17,273][train][INFO] - Epoch 916/2000, Val Acc=0.6130, Val Loss=1.8125, lr=0.0100
[2025-05-07 02:05:22,290][train][INFO] - Epoch 900/2000, Val Acc=0.6088, Val Loss=1.7583, lr=0.0100
[2025-05-07 02:05:23,152][train][INFO] - Epoch 913/2000, Val Acc=0.5712, Val Loss=1.8265, lr=0.0100
[2025-05-07 02:05:24,922][train][INFO] - Epoch 917/2000, Val Acc=0.6087, Val Loss=1.7592, lr=0.0100
[2025-05-07 02:05:30,100][train][INFO] - Epoch 914/2000, Val Acc=0.5908, Val Loss=1.6937, lr=0.0100
[2025-05-07 02:05:30,219][train][INFO] - Epoch 901/2000, Val Acc=0.6084, Val Loss=1.7415, lr=0.0100
[2025-05-07 02:05:32,592][train][INFO] - Epoch 918/2000, Val Acc=0.6131, Val Loss=1.7200, lr=0.0100
[2025-05-07 02:05:37,667][train][INFO] - Epoch 915/2000, Val Acc=0.5789, Val Loss=1.7342, lr=0.0100
[2025-05-07 02:05:37,926][train][INFO] - Epoch 902/2000, Val Acc=0.6094, Val Loss=1.7704, lr=0.0100
[2025-05-07 02:05:39,944][train][INFO] - Epoch 919/2000, Val Acc=0.6119, Val Loss=1.7294, lr=0.0100
[2025-05-07 02:05:45,270][train][INFO] - Epoch 916/2000, Val Acc=0.5816, Val Loss=1.7440, lr=0.0100
[2025-05-07 02:05:46,023][train][INFO] - Epoch 903/2000, Val Acc=0.5976, Val Loss=1.8237, lr=0.0100
[2025-05-07 02:05:47,534][train][INFO] - Epoch 920/2000, Val Acc=0.6070, Val Loss=1.7646, lr=0.0100
[2025-05-07 02:05:52,876][train][INFO] - Epoch 917/2000, Val Acc=0.6041, Val Loss=1.6352, lr=0.0100
[2025-05-07 02:05:53,737][train][INFO] - Epoch 904/2000, Val Acc=0.6183, Val Loss=1.7362, lr=0.0100
[2025-05-07 02:05:55,204][train][INFO] - Epoch 921/2000, Val Acc=0.5473, Val Loss=2.2199, lr=0.0100
[2025-05-07 02:06:00,501][train][INFO] - Epoch 918/2000, Val Acc=0.5895, Val Loss=1.7078, lr=0.0100
[2025-05-07 02:06:01,570][train][INFO] - Epoch 905/2000, Val Acc=0.6179, Val Loss=1.6973, lr=0.0100
[2025-05-07 02:06:02,693][train][INFO] - Epoch 922/2000, Val Acc=0.6144, Val Loss=1.7166, lr=0.0100
[2025-05-07 02:06:08,461][train][INFO] - Epoch 919/2000, Val Acc=0.6033, Val Loss=1.6299, lr=0.0100
[2025-05-07 02:06:09,141][train][INFO] - Epoch 906/2000, Val Acc=0.6261, Val Loss=1.6921, lr=0.0100
[2025-05-07 02:06:10,483][train][INFO] - Epoch 923/2000, Val Acc=0.5923, Val Loss=1.8553, lr=0.0100
[2025-05-07 02:06:16,111][train][INFO] - Epoch 920/2000, Val Acc=0.5941, Val Loss=1.6797, lr=0.0100
[2025-05-07 02:06:17,178][train][INFO] - Epoch 907/2000, Val Acc=0.6203, Val Loss=1.6975, lr=0.0100
[2025-05-07 02:06:17,812][train][INFO] - Epoch 924/2000, Val Acc=0.6157, Val Loss=1.7896, lr=0.0100
[2025-05-07 02:06:23,676][train][INFO] - Epoch 921/2000, Val Acc=0.5887, Val Loss=1.7125, lr=0.0100
[2025-05-07 02:06:24,926][train][INFO] - Epoch 908/2000, Val Acc=0.6157, Val Loss=1.7453, lr=0.0100
[2025-05-07 02:06:25,238][train][INFO] - Epoch 925/2000, Val Acc=0.6069, Val Loss=1.7752, lr=0.0100
[2025-05-07 02:06:31,294][train][INFO] - Epoch 922/2000, Val Acc=0.6076, Val Loss=1.5930, lr=0.0100
[2025-05-07 02:06:32,929][train][INFO] - Epoch 909/2000, Val Acc=0.5987, Val Loss=1.8584, lr=0.0100
[2025-05-07 02:06:33,027][train][INFO] - Epoch 926/2000, Val Acc=0.6110, Val Loss=1.7366, lr=0.0100
[2025-05-07 02:06:39,082][train][INFO] - Epoch 923/2000, Val Acc=0.5853, Val Loss=1.7169, lr=0.0100
[2025-05-07 02:06:40,691][train][INFO] - Epoch 927/2000, Val Acc=0.6092, Val Loss=1.7889, lr=0.0100
[2025-05-07 02:06:41,076][train][INFO] - Epoch 910/2000, Val Acc=0.6269, Val Loss=1.6630, lr=0.0100
[2025-05-07 02:06:46,226][train][INFO] - Epoch 924/2000, Val Acc=0.5843, Val Loss=1.7706, lr=0.0100
[2025-05-07 02:06:48,362][train][INFO] - Epoch 928/2000, Val Acc=0.5836, Val Loss=1.9422, lr=0.0100
[2025-05-07 02:06:49,108][train][INFO] - Epoch 911/2000, Val Acc=0.6152, Val Loss=1.6951, lr=0.0100
[2025-05-07 02:06:53,635][train][INFO] - Epoch 925/2000, Val Acc=0.5930, Val Loss=1.6630, lr=0.0100
[2025-05-07 02:06:55,948][train][INFO] - Epoch 929/2000, Val Acc=0.6117, Val Loss=1.7305, lr=0.0100
[2025-05-07 02:06:56,740][train][INFO] - Epoch 912/2000, Val Acc=0.6005, Val Loss=1.7758, lr=0.0100
[2025-05-07 02:07:00,762][train][INFO] - Epoch 926/2000, Val Acc=0.5884, Val Loss=1.7253, lr=0.0100
[2025-05-07 02:07:02,774][train][INFO] - Epoch 930/2000, Val Acc=0.6222, Val Loss=1.6801, lr=0.0100
[2025-05-07 02:07:04,440][train][INFO] - Epoch 913/2000, Val Acc=0.6112, Val Loss=1.7258, lr=0.0100
[2025-05-07 02:07:08,384][train][INFO] - Epoch 927/2000, Val Acc=0.6010, Val Loss=1.6409, lr=0.0100
[2025-05-07 02:07:10,366][train][INFO] - Epoch 931/2000, Val Acc=0.6226, Val Loss=1.6944, lr=0.0100
[2025-05-07 02:07:12,455][train][INFO] - Epoch 914/2000, Val Acc=0.5867, Val Loss=1.8629, lr=0.0100
[2025-05-07 02:07:15,745][train][INFO] - Epoch 928/2000, Val Acc=0.5868, Val Loss=1.7339, lr=0.0100
[2025-05-07 02:07:18,244][train][INFO] - Epoch 932/2000, Val Acc=0.6187, Val Loss=1.7400, lr=0.0100
[2025-05-07 02:07:19,744][train][INFO] - Epoch 915/2000, Val Acc=0.6175, Val Loss=1.7084, lr=0.0100
[2025-05-07 02:07:23,020][train][INFO] - Epoch 929/2000, Val Acc=0.5941, Val Loss=1.6965, lr=0.0100
[2025-05-07 02:07:25,595][train][INFO] - Epoch 933/2000, Val Acc=0.5807, Val Loss=1.9550, lr=0.0100
[2025-05-07 02:07:28,097][train][INFO] - Epoch 916/2000, Val Acc=0.6130, Val Loss=1.8125, lr=0.0100
[2025-05-07 02:07:30,804][train][INFO] - Epoch 930/2000, Val Acc=0.5823, Val Loss=1.7458, lr=0.0100
[2025-05-07 02:07:32,868][train][INFO] - Epoch 934/2000, Val Acc=0.6050, Val Loss=1.8221, lr=0.0100
[2025-05-07 02:07:35,550][train][INFO] - Epoch 917/2000, Val Acc=0.6087, Val Loss=1.7592, lr=0.0100
[2025-05-07 02:07:38,659][train][INFO] - Epoch 931/2000, Val Acc=0.6036, Val Loss=1.6256, lr=0.0100
[2025-05-07 02:07:40,407][train][INFO] - Epoch 935/2000, Val Acc=0.5954, Val Loss=1.8754, lr=0.0100
[2025-05-07 02:07:43,617][train][INFO] - Epoch 918/2000, Val Acc=0.6131, Val Loss=1.7200, lr=0.0100
[2025-05-07 02:07:46,188][train][INFO] - Epoch 932/2000, Val Acc=0.5736, Val Loss=1.7883, lr=0.0100
[2025-05-07 02:07:47,810][train][INFO] - Epoch 936/2000, Val Acc=0.6245, Val Loss=1.6776, lr=0.0100
[2025-05-07 02:07:51,078][train][INFO] - Epoch 919/2000, Val Acc=0.6119, Val Loss=1.7294, lr=0.0100
[2025-05-07 02:07:53,715][train][INFO] - Epoch 933/2000, Val Acc=0.5709, Val Loss=1.8504, lr=0.0100
[2025-05-07 02:07:55,481][train][INFO] - Epoch 937/2000, Val Acc=0.6014, Val Loss=1.7592, lr=0.0100
[2025-05-07 02:07:58,717][train][INFO] - Epoch 920/2000, Val Acc=0.6070, Val Loss=1.7646, lr=0.0100
[2025-05-07 02:08:01,650][train][INFO] - Epoch 934/2000, Val Acc=0.5854, Val Loss=1.7314, lr=0.0100
[2025-05-07 02:08:03,137][train][INFO] - Epoch 938/2000, Val Acc=0.5862, Val Loss=1.9224, lr=0.0100
[2025-05-07 02:08:06,995][train][INFO] - Epoch 921/2000, Val Acc=0.5473, Val Loss=2.2199, lr=0.0100
[2025-05-07 02:08:09,156][train][INFO] - Epoch 935/2000, Val Acc=0.5886, Val Loss=1.6720, lr=0.0100
[2025-05-07 02:08:10,709][train][INFO] - Epoch 939/2000, Val Acc=0.6169, Val Loss=1.7404, lr=0.0100
[2025-05-07 02:08:14,523][train][INFO] - Epoch 922/2000, Val Acc=0.6144, Val Loss=1.7166, lr=0.0100
[2025-05-07 02:08:16,725][train][INFO] - Epoch 936/2000, Val Acc=0.5934, Val Loss=1.6535, lr=0.0100
[2025-05-07 02:08:18,631][train][INFO] - Epoch 940/2000, Val Acc=0.6008, Val Loss=1.8756, lr=0.0100
[2025-05-07 02:08:22,423][train][INFO] - Epoch 923/2000, Val Acc=0.5923, Val Loss=1.8553, lr=0.0100
[2025-05-07 02:08:24,328][train][INFO] - Epoch 937/2000, Val Acc=0.5703, Val Loss=1.7995, lr=0.0100
[2025-05-07 02:08:26,177][train][INFO] - Epoch 941/2000, Val Acc=0.6131, Val Loss=1.7238, lr=0.0100
[2025-05-07 02:08:30,552][train][INFO] - Epoch 924/2000, Val Acc=0.6157, Val Loss=1.7896, lr=0.0100
[2025-05-07 02:08:32,293][train][INFO] - Epoch 938/2000, Val Acc=0.5950, Val Loss=1.6676, lr=0.0100
[2025-05-07 02:08:33,710][train][INFO] - Epoch 942/2000, Val Acc=0.6173, Val Loss=1.7035, lr=0.0100
[2025-05-07 02:08:38,559][train][INFO] - Epoch 925/2000, Val Acc=0.6069, Val Loss=1.7752, lr=0.0100
[2025-05-07 02:08:40,208][train][INFO] - Epoch 939/2000, Val Acc=0.5886, Val Loss=1.7295, lr=0.0100
[2025-05-07 02:08:41,434][train][INFO] - Epoch 943/2000, Val Acc=0.6077, Val Loss=1.7701, lr=0.0100
[2025-05-07 02:08:46,128][train][INFO] - Epoch 926/2000, Val Acc=0.6110, Val Loss=1.7366, lr=0.0100
[2025-05-07 02:08:47,140][train][INFO] - Epoch 940/2000, Val Acc=0.5788, Val Loss=1.7647, lr=0.0100
[2025-05-07 02:08:49,129][train][INFO] - Epoch 944/2000, Val Acc=0.5979, Val Loss=1.8634, lr=0.0100
[2025-05-07 02:08:53,766][train][INFO] - Epoch 927/2000, Val Acc=0.6092, Val Loss=1.7889, lr=0.0100
[2025-05-07 02:08:55,096][train][INFO] - Epoch 941/2000, Val Acc=0.5808, Val Loss=1.7432, lr=0.0100
[2025-05-07 02:08:56,290][train][INFO] - Epoch 945/2000, Val Acc=0.6217, Val Loss=1.7131, lr=0.0100
[2025-05-07 02:09:01,236][train][INFO] - Epoch 928/2000, Val Acc=0.5836, Val Loss=1.9422, lr=0.0100
[2025-05-07 02:09:02,802][train][INFO] - Epoch 942/2000, Val Acc=0.5945, Val Loss=1.6495, lr=0.0100
[2025-05-07 02:09:04,272][train][INFO] - Epoch 946/2000, Val Acc=0.6044, Val Loss=1.7957, lr=0.0100
[2025-05-07 02:09:08,929][train][INFO] - Epoch 929/2000, Val Acc=0.6117, Val Loss=1.7305, lr=0.0100
[2025-05-07 02:09:10,456][train][INFO] - Epoch 943/2000, Val Acc=0.5872, Val Loss=1.7050, lr=0.0100
[2025-05-07 02:09:12,042][train][INFO] - Epoch 947/2000, Val Acc=0.6127, Val Loss=1.7482, lr=0.0100
[2025-05-07 02:09:16,450][train][INFO] - Epoch 930/2000, Val Acc=0.6222, Val Loss=1.6801, lr=0.0100
[2025-05-07 02:09:18,399][train][INFO] - Epoch 944/2000, Val Acc=0.5861, Val Loss=1.6939, lr=0.0100
[2025-05-07 02:09:19,609][train][INFO] - Epoch 948/2000, Val Acc=0.6216, Val Loss=1.7173, lr=0.0100
[2025-05-07 02:09:23,987][train][INFO] - Epoch 931/2000, Val Acc=0.6226, Val Loss=1.6944, lr=0.0100
[2025-05-07 02:09:26,024][train][INFO] - Epoch 945/2000, Val Acc=0.5865, Val Loss=1.6694, lr=0.0100
[2025-05-07 02:09:27,018][train][INFO] - Epoch 949/2000, Val Acc=0.6179, Val Loss=1.6764, lr=0.0100
[2025-05-07 02:09:32,047][train][INFO] - Epoch 932/2000, Val Acc=0.6187, Val Loss=1.7400, lr=0.0100
[2025-05-07 02:09:33,902][train][INFO] - Epoch 946/2000, Val Acc=0.5643, Val Loss=1.8437, lr=0.0100
[2025-05-07 02:09:34,525][train][INFO] - Epoch 950/2000, Val Acc=0.6045, Val Loss=1.8093, lr=0.0100
[2025-05-07 02:09:40,030][train][INFO] - Epoch 933/2000, Val Acc=0.5807, Val Loss=1.9550, lr=0.0100
[2025-05-07 02:09:41,595][train][INFO] - Epoch 951/2000, Val Acc=0.6238, Val Loss=1.6509, lr=0.0100
[2025-05-07 02:09:42,050][train][INFO] - Epoch 947/2000, Val Acc=0.5809, Val Loss=1.7028, lr=0.0100
[2025-05-07 02:09:48,566][train][INFO] - Epoch 934/2000, Val Acc=0.6050, Val Loss=1.8221, lr=0.0100
[2025-05-07 02:09:48,989][train][INFO] - Epoch 952/2000, Val Acc=0.6171, Val Loss=1.7209, lr=0.0100
[2025-05-07 02:09:50,146][train][INFO] - Epoch 948/2000, Val Acc=0.5493, Val Loss=1.9257, lr=0.0100
[2025-05-07 02:09:56,288][train][INFO] - Epoch 935/2000, Val Acc=0.5954, Val Loss=1.8754, lr=0.0100
[2025-05-07 02:09:56,709][train][INFO] - Epoch 953/2000, Val Acc=0.6187, Val Loss=1.6743, lr=0.0100
[2025-05-07 02:09:57,922][train][INFO] - Epoch 949/2000, Val Acc=0.5692, Val Loss=1.7628, lr=0.0100
[2025-05-07 02:10:04,041][train][INFO] - Epoch 936/2000, Val Acc=0.6245, Val Loss=1.6776, lr=0.0100
[2025-05-07 02:10:04,175][train][INFO] - Epoch 954/2000, Val Acc=0.6211, Val Loss=1.7146, lr=0.0100
[2025-05-07 02:10:05,364][train][INFO] - Epoch 950/2000, Val Acc=0.5762, Val Loss=1.7474, lr=0.0100
[2025-05-07 02:10:10,695][train][INFO] - Epoch 955/2000, Val Acc=0.6115, Val Loss=1.7472, lr=0.0100
[2025-05-07 02:10:11,511][train][INFO] - Epoch 937/2000, Val Acc=0.6014, Val Loss=1.7592, lr=0.0100
[2025-05-07 02:10:12,966][train][INFO] - Epoch 951/2000, Val Acc=0.5923, Val Loss=1.6805, lr=0.0100
[2025-05-07 02:10:18,035][train][INFO] - Epoch 956/2000, Val Acc=0.6165, Val Loss=1.6713, lr=0.0100
[2025-05-07 02:10:19,142][train][INFO] - Epoch 938/2000, Val Acc=0.5862, Val Loss=1.9224, lr=0.0100
[2025-05-07 02:10:20,416][train][INFO] - Epoch 952/2000, Val Acc=0.5733, Val Loss=1.8219, lr=0.0100
[2025-05-07 02:10:25,834][train][INFO] - Epoch 957/2000, Val Acc=0.6060, Val Loss=1.8091, lr=0.0100
[2025-05-07 02:10:27,396][train][INFO] - Epoch 939/2000, Val Acc=0.6169, Val Loss=1.7404, lr=0.0100
[2025-05-07 02:10:28,078][train][INFO] - Epoch 953/2000, Val Acc=0.5697, Val Loss=1.8010, lr=0.0100
[2025-05-07 02:10:33,733][train][INFO] - Epoch 958/2000, Val Acc=0.6209, Val Loss=1.6781, lr=0.0100
[2025-05-07 02:10:35,513][train][INFO] - Epoch 940/2000, Val Acc=0.6008, Val Loss=1.8756, lr=0.0100
[2025-05-07 02:10:35,545][train][INFO] - Epoch 954/2000, Val Acc=0.5850, Val Loss=1.7141, lr=0.0100
[2025-05-07 02:10:41,243][train][INFO] - Epoch 959/2000, Val Acc=0.5965, Val Loss=1.8508, lr=0.0100
[2025-05-07 02:10:43,574][train][INFO] - Epoch 941/2000, Val Acc=0.6131, Val Loss=1.7238, lr=0.0100
[2025-05-07 02:10:43,651][train][INFO] - Epoch 955/2000, Val Acc=0.5996, Val Loss=1.6649, lr=0.0100
[2025-05-07 02:10:49,106][train][INFO] - Epoch 960/2000, Val Acc=0.6191, Val Loss=1.7096, lr=0.0100
[2025-05-07 02:10:51,245][train][INFO] - Epoch 942/2000, Val Acc=0.6173, Val Loss=1.7035, lr=0.0100
[2025-05-07 02:10:51,325][train][INFO] - Epoch 956/2000, Val Acc=0.5906, Val Loss=1.6882, lr=0.0100
[2025-05-07 02:10:56,722][train][INFO] - Epoch 961/2000, Val Acc=0.6155, Val Loss=1.7160, lr=0.0100
[2025-05-07 02:10:58,938][train][INFO] - Epoch 957/2000, Val Acc=0.6047, Val Loss=1.6024, lr=0.0100
[2025-05-07 02:10:59,245][train][INFO] - Epoch 943/2000, Val Acc=0.6077, Val Loss=1.7701, lr=0.0100
[2025-05-07 02:11:04,153][train][INFO] - Epoch 962/2000, Val Acc=0.6056, Val Loss=1.7633, lr=0.0100
[2025-05-07 02:11:06,643][train][INFO] - Epoch 958/2000, Val Acc=0.5791, Val Loss=1.7574, lr=0.0100
[2025-05-07 02:11:06,913][train][INFO] - Epoch 944/2000, Val Acc=0.5979, Val Loss=1.8634, lr=0.0100
[2025-05-07 02:11:11,057][train][INFO] - Epoch 963/2000, Val Acc=0.6103, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:11:14,500][train][INFO] - Epoch 959/2000, Val Acc=0.5793, Val Loss=1.7454, lr=0.0100
[2025-05-07 02:11:14,906][train][INFO] - Epoch 945/2000, Val Acc=0.6217, Val Loss=1.7131, lr=0.0100
[2025-05-07 02:11:18,853][train][INFO] - Epoch 964/2000, Val Acc=0.6081, Val Loss=1.7577, lr=0.0100
[2025-05-07 02:11:22,236][train][INFO] - Epoch 960/2000, Val Acc=0.5834, Val Loss=1.7481, lr=0.0100
[2025-05-07 02:11:22,880][train][INFO] - Epoch 946/2000, Val Acc=0.6044, Val Loss=1.7957, lr=0.0100
[2025-05-07 02:11:26,685][train][INFO] - Epoch 965/2000, Val Acc=0.5626, Val Loss=2.0012, lr=0.0100
[2025-05-07 02:11:29,449][train][INFO] - Epoch 961/2000, Val Acc=0.5595, Val Loss=1.9082, lr=0.0100
[2025-05-07 02:11:31,059][train][INFO] - Epoch 947/2000, Val Acc=0.6127, Val Loss=1.7482, lr=0.0100
[2025-05-07 02:11:34,289][train][INFO] - Epoch 966/2000, Val Acc=0.6162, Val Loss=1.6984, lr=0.0100
[2025-05-07 02:11:36,945][train][INFO] - Epoch 962/2000, Val Acc=0.5596, Val Loss=1.8509, lr=0.0100
[2025-05-07 02:11:39,212][train][INFO] - Epoch 948/2000, Val Acc=0.6216, Val Loss=1.7173, lr=0.0100
[2025-05-07 02:11:41,659][train][INFO] - Epoch 967/2000, Val Acc=0.6052, Val Loss=1.7427, lr=0.0100
[2025-05-07 02:11:44,508][train][INFO] - Epoch 963/2000, Val Acc=0.5840, Val Loss=1.7308, lr=0.0100
[2025-05-07 02:11:47,326][train][INFO] - Epoch 949/2000, Val Acc=0.6179, Val Loss=1.6764, lr=0.0100
[2025-05-07 02:11:48,937][train][INFO] - Epoch 968/2000, Val Acc=0.6146, Val Loss=1.7131, lr=0.0100
[2025-05-07 02:11:52,538][train][INFO] - Epoch 964/2000, Val Acc=0.5974, Val Loss=1.6794, lr=0.0100
[2025-05-07 02:11:55,288][train][INFO] - Epoch 950/2000, Val Acc=0.6045, Val Loss=1.8093, lr=0.0100
[2025-05-07 02:11:56,807][train][INFO] - Epoch 969/2000, Val Acc=0.6096, Val Loss=1.7553, lr=0.0100
[2025-05-07 02:12:00,406][train][INFO] - Epoch 965/2000, Val Acc=0.5904, Val Loss=1.6999, lr=0.0100
[2025-05-07 02:12:03,515][train][INFO] - Epoch 951/2000, Val Acc=0.6238, Val Loss=1.6509, lr=0.0100
[2025-05-07 02:12:04,197][train][INFO] - Epoch 970/2000, Val Acc=0.5992, Val Loss=1.8881, lr=0.0100
[2025-05-07 02:12:07,971][train][INFO] - Epoch 966/2000, Val Acc=0.5977, Val Loss=1.6698, lr=0.0100
[2025-05-07 02:12:10,832][train][INFO] - Epoch 952/2000, Val Acc=0.6171, Val Loss=1.7209, lr=0.0100
[2025-05-07 02:12:11,590][train][INFO] - Epoch 971/2000, Val Acc=0.6128, Val Loss=1.7141, lr=0.0100
[2025-05-07 02:12:15,337][train][INFO] - Epoch 967/2000, Val Acc=0.5765, Val Loss=1.7756, lr=0.0100
[2025-05-07 02:12:18,699][train][INFO] - Epoch 953/2000, Val Acc=0.6187, Val Loss=1.6743, lr=0.0100
[2025-05-07 02:12:19,401][train][INFO] - Epoch 972/2000, Val Acc=0.6184, Val Loss=1.7172, lr=0.0100
[2025-05-07 02:12:22,953][train][INFO] - Epoch 968/2000, Val Acc=0.5882, Val Loss=1.6911, lr=0.0100
[2025-05-07 02:12:26,961][train][INFO] - Epoch 973/2000, Val Acc=0.6142, Val Loss=1.7405, lr=0.0100
[2025-05-07 02:12:27,036][train][INFO] - Epoch 954/2000, Val Acc=0.6211, Val Loss=1.7146, lr=0.0100
[2025-05-07 02:12:30,336][train][INFO] - Epoch 969/2000, Val Acc=0.5909, Val Loss=1.6887, lr=0.0100
[2025-05-07 02:12:34,458][train][INFO] - Epoch 955/2000, Val Acc=0.6115, Val Loss=1.7472, lr=0.0100
[2025-05-07 02:12:34,548][train][INFO] - Epoch 974/2000, Val Acc=0.6215, Val Loss=1.6812, lr=0.0100
[2025-05-07 02:12:37,891][train][INFO] - Epoch 970/2000, Val Acc=0.5973, Val Loss=1.6254, lr=0.0100
[2025-05-07 02:12:42,302][train][INFO] - Epoch 975/2000, Val Acc=0.6256, Val Loss=1.6584, lr=0.0100
[2025-05-07 02:12:42,433][train][INFO] - Epoch 956/2000, Val Acc=0.6165, Val Loss=1.6713, lr=0.0100
[2025-05-07 02:12:45,738][train][INFO] - Epoch 971/2000, Val Acc=0.5905, Val Loss=1.6516, lr=0.0100
[2025-05-07 02:12:50,175][train][INFO] - Epoch 976/2000, Val Acc=0.6245, Val Loss=1.6618, lr=0.0100
[2025-05-07 02:12:50,449][train][INFO] - Epoch 957/2000, Val Acc=0.6060, Val Loss=1.8091, lr=0.0100
[2025-05-07 02:12:53,315][train][INFO] - Epoch 972/2000, Val Acc=0.5869, Val Loss=1.7359, lr=0.0100
[2025-05-07 02:12:57,741][train][INFO] - Epoch 977/2000, Val Acc=0.6006, Val Loss=1.8320, lr=0.0100
[2025-05-07 02:12:58,443][train][INFO] - Epoch 958/2000, Val Acc=0.6209, Val Loss=1.6781, lr=0.0100
[2025-05-07 02:13:00,597][train][INFO] - Epoch 973/2000, Val Acc=0.5866, Val Loss=1.7148, lr=0.0100
[2025-05-07 02:13:04,907][train][INFO] - Epoch 978/2000, Val Acc=0.6305, Val Loss=1.6428, lr=0.0100
[2025-05-07 02:13:06,162][train][INFO] - Epoch 959/2000, Val Acc=0.5965, Val Loss=1.8508, lr=0.0100
[2025-05-07 02:13:08,518][train][INFO] - Epoch 974/2000, Val Acc=0.5766, Val Loss=1.7668, lr=0.0100
[2025-05-07 02:13:11,722][train][INFO] - Epoch 979/2000, Val Acc=0.6181, Val Loss=1.7321, lr=0.0100
[2025-05-07 02:13:14,315][train][INFO] - Epoch 960/2000, Val Acc=0.6191, Val Loss=1.7096, lr=0.0100
[2025-05-07 02:13:16,106][train][INFO] - Epoch 975/2000, Val Acc=0.5916, Val Loss=1.6906, lr=0.0100
[2025-05-07 02:13:18,666][train][INFO] - Epoch 980/2000, Val Acc=0.6139, Val Loss=1.7764, lr=0.0100
[2025-05-07 02:13:22,135][train][INFO] - Epoch 961/2000, Val Acc=0.6155, Val Loss=1.7160, lr=0.0100
[2025-05-07 02:13:23,955][train][INFO] - Epoch 976/2000, Val Acc=0.5684, Val Loss=1.8640, lr=0.0100
[2025-05-07 02:13:26,177][train][INFO] - Epoch 981/2000, Val Acc=0.6046, Val Loss=1.7741, lr=0.0100
[2025-05-07 02:13:29,659][train][INFO] - Epoch 962/2000, Val Acc=0.6056, Val Loss=1.7633, lr=0.0100
[2025-05-07 02:13:31,169][train][INFO] - Epoch 977/2000, Val Acc=0.5846, Val Loss=1.7021, lr=0.0100
[2025-05-07 02:13:33,737][train][INFO] - Epoch 982/2000, Val Acc=0.6095, Val Loss=1.7497, lr=0.0100
[2025-05-07 02:13:37,622][train][INFO] - Epoch 963/2000, Val Acc=0.6103, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:13:39,186][train][INFO] - Epoch 978/2000, Val Acc=0.5887, Val Loss=1.6971, lr=0.0100
[2025-05-07 02:13:41,423][train][INFO] - Epoch 983/2000, Val Acc=0.6081, Val Loss=1.7875, lr=0.0100
[2025-05-07 02:13:45,459][train][INFO] - Epoch 964/2000, Val Acc=0.6081, Val Loss=1.7577, lr=0.0100
[2025-05-07 02:13:46,900][train][INFO] - Epoch 979/2000, Val Acc=0.5887, Val Loss=1.7219, lr=0.0100
[2025-05-07 02:13:48,969][train][INFO] - Epoch 984/2000, Val Acc=0.6179, Val Loss=1.7360, lr=0.0100
[2025-05-07 02:13:53,352][train][INFO] - Epoch 965/2000, Val Acc=0.5626, Val Loss=2.0012, lr=0.0100
[2025-05-07 02:13:54,410][train][INFO] - Epoch 980/2000, Val Acc=0.5910, Val Loss=1.6917, lr=0.0100
[2025-05-07 02:13:56,370][train][INFO] - Epoch 985/2000, Val Acc=0.6148, Val Loss=1.6962, lr=0.0100
[2025-05-07 02:14:01,415][train][INFO] - Epoch 966/2000, Val Acc=0.6162, Val Loss=1.6984, lr=0.0100
[2025-05-07 02:14:02,303][train][INFO] - Epoch 981/2000, Val Acc=0.5586, Val Loss=1.9045, lr=0.0100
[2025-05-07 02:14:03,983][train][INFO] - Epoch 986/2000, Val Acc=0.6103, Val Loss=1.7261, lr=0.0100
[2025-05-07 02:14:08,820][train][INFO] - Epoch 967/2000, Val Acc=0.6052, Val Loss=1.7427, lr=0.0100
[2025-05-07 02:14:10,072][train][INFO] - Epoch 982/2000, Val Acc=0.5949, Val Loss=1.6563, lr=0.0100
[2025-05-07 02:14:11,429][train][INFO] - Epoch 987/2000, Val Acc=0.6151, Val Loss=1.7671, lr=0.0100
[2025-05-07 02:14:16,843][train][INFO] - Epoch 968/2000, Val Acc=0.6146, Val Loss=1.7131, lr=0.0100
[2025-05-07 02:14:17,730][train][INFO] - Epoch 983/2000, Val Acc=0.5764, Val Loss=1.7498, lr=0.0100
[2025-05-07 02:14:18,718][train][INFO] - Epoch 988/2000, Val Acc=0.6083, Val Loss=1.7913, lr=0.0100
[2025-05-07 02:14:24,238][train][INFO] - Epoch 969/2000, Val Acc=0.6096, Val Loss=1.7553, lr=0.0100
[2025-05-07 02:14:25,033][train][INFO] - Epoch 984/2000, Val Acc=0.5931, Val Loss=1.6769, lr=0.0100
[2025-05-07 02:14:26,286][train][INFO] - Epoch 989/2000, Val Acc=0.6132, Val Loss=1.7424, lr=0.0100
[2025-05-07 02:14:31,826][train][INFO] - Epoch 970/2000, Val Acc=0.5992, Val Loss=1.8881, lr=0.0100
[2025-05-07 02:14:32,551][train][INFO] - Epoch 985/2000, Val Acc=0.5828, Val Loss=1.7587, lr=0.0100
[2025-05-07 02:14:33,886][train][INFO] - Epoch 990/2000, Val Acc=0.6124, Val Loss=1.7610, lr=0.0100
[2025-05-07 02:14:39,128][train][INFO] - Epoch 971/2000, Val Acc=0.6128, Val Loss=1.7141, lr=0.0100
[2025-05-07 02:14:40,622][train][INFO] - Epoch 986/2000, Val Acc=0.5824, Val Loss=1.7300, lr=0.0100
[2025-05-07 02:14:41,372][train][INFO] - Epoch 991/2000, Val Acc=0.6091, Val Loss=1.7783, lr=0.0100
[2025-05-07 02:14:47,375][train][INFO] - Epoch 972/2000, Val Acc=0.6184, Val Loss=1.7172, lr=0.0100
[2025-05-07 02:14:48,697][train][INFO] - Epoch 987/2000, Val Acc=0.5877, Val Loss=1.7231, lr=0.0100
[2025-05-07 02:14:48,857][train][INFO] - Epoch 992/2000, Val Acc=0.6124, Val Loss=1.7274, lr=0.0100
[2025-05-07 02:14:54,885][train][INFO] - Epoch 973/2000, Val Acc=0.6142, Val Loss=1.7405, lr=0.0100
[2025-05-07 02:14:56,144][train][INFO] - Epoch 993/2000, Val Acc=0.6176, Val Loss=1.6942, lr=0.0100
[2025-05-07 02:14:56,644][train][INFO] - Epoch 988/2000, Val Acc=0.5849, Val Loss=1.7271, lr=0.0100
[2025-05-07 02:15:02,955][train][INFO] - Epoch 974/2000, Val Acc=0.6215, Val Loss=1.6812, lr=0.0100
[2025-05-07 02:15:03,711][train][INFO] - Epoch 994/2000, Val Acc=0.6220, Val Loss=1.6983, lr=0.0100
[2025-05-07 02:15:04,184][train][INFO] - Epoch 989/2000, Val Acc=0.5937, Val Loss=1.6545, lr=0.0100
[2025-05-07 02:15:10,185][train][INFO] - Epoch 975/2000, Val Acc=0.6256, Val Loss=1.6584, lr=0.0100
[2025-05-07 02:15:11,477][train][INFO] - Epoch 995/2000, Val Acc=0.6059, Val Loss=1.8029, lr=0.0100
[2025-05-07 02:15:11,809][train][INFO] - Epoch 990/2000, Val Acc=0.5940, Val Loss=1.6842, lr=0.0100
[2025-05-07 02:15:18,068][train][INFO] - Epoch 976/2000, Val Acc=0.6245, Val Loss=1.6618, lr=0.0100
[2025-05-07 02:15:19,362][train][INFO] - Epoch 996/2000, Val Acc=0.6141, Val Loss=1.7184, lr=0.0100
[2025-05-07 02:15:19,495][train][INFO] - Epoch 991/2000, Val Acc=0.5877, Val Loss=1.7324, lr=0.0100
[2025-05-07 02:15:25,867][train][INFO] - Epoch 977/2000, Val Acc=0.6006, Val Loss=1.8320, lr=0.0100
[2025-05-07 02:15:25,992][train][INFO] - Epoch 997/2000, Val Acc=0.6111, Val Loss=1.7196, lr=0.0100
[2025-05-07 02:15:27,144][train][INFO] - Epoch 992/2000, Val Acc=0.5914, Val Loss=1.6504, lr=0.0100
[2025-05-07 02:15:33,466][train][INFO] - Epoch 998/2000, Val Acc=0.6048, Val Loss=1.7929, lr=0.0100
[2025-05-07 02:15:33,526][train][INFO] - Epoch 978/2000, Val Acc=0.6305, Val Loss=1.6428, lr=0.0100
[2025-05-07 02:15:34,675][train][INFO] - Epoch 993/2000, Val Acc=0.5921, Val Loss=1.6592, lr=0.0100
[2025-05-07 02:15:41,103][train][INFO] - Epoch 999/2000, Val Acc=0.6168, Val Loss=1.6876, lr=0.0100
[2025-05-07 02:15:41,354][train][INFO] - Epoch 979/2000, Val Acc=0.6181, Val Loss=1.7321, lr=0.0100
[2025-05-07 02:15:42,211][train][INFO] - Epoch 994/2000, Val Acc=0.5961, Val Loss=1.6808, lr=0.0100
[2025-05-07 02:15:49,077][train][INFO] - Epoch 1000/2000, Val Acc=0.6067, Val Loss=1.7464, lr=0.0100
[2025-05-07 02:15:49,455][train][INFO] - Epoch 980/2000, Val Acc=0.6139, Val Loss=1.7764, lr=0.0100
[2025-05-07 02:15:49,746][train][INFO] - Epoch 995/2000, Val Acc=0.6016, Val Loss=1.6532, lr=0.0100
[2025-05-07 02:15:56,321][train][INFO] - Epoch 1001/2000, Val Acc=0.6051, Val Loss=1.8092, lr=0.0100
[2025-05-07 02:15:57,280][train][INFO] - Epoch 981/2000, Val Acc=0.6046, Val Loss=1.7741, lr=0.0100
[2025-05-07 02:15:57,423][train][INFO] - Epoch 996/2000, Val Acc=0.5895, Val Loss=1.6811, lr=0.0100
[2025-05-07 02:16:03,919][train][INFO] - Epoch 1002/2000, Val Acc=0.6123, Val Loss=1.7386, lr=0.0100
[2025-05-07 02:16:05,079][train][INFO] - Epoch 982/2000, Val Acc=0.6095, Val Loss=1.7497, lr=0.0100
[2025-05-07 02:16:05,111][train][INFO] - Epoch 997/2000, Val Acc=0.5608, Val Loss=1.8580, lr=0.0100
[2025-05-07 02:16:11,513][train][INFO] - Epoch 1003/2000, Val Acc=0.6167, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:16:12,271][train][INFO] - Epoch 998/2000, Val Acc=0.6011, Val Loss=1.6528, lr=0.0100
[2025-05-07 02:16:12,857][train][INFO] - Epoch 983/2000, Val Acc=0.6081, Val Loss=1.7875, lr=0.0100
[2025-05-07 02:16:19,234][train][INFO] - Epoch 1004/2000, Val Acc=0.6232, Val Loss=1.6654, lr=0.0100
[2025-05-07 02:16:19,522][train][INFO] - Epoch 999/2000, Val Acc=0.5528, Val Loss=1.9094, lr=0.0100
[2025-05-07 02:16:20,791][train][INFO] - Epoch 984/2000, Val Acc=0.6179, Val Loss=1.7360, lr=0.0100
[2025-05-07 02:16:26,583][train][INFO] - Epoch 1005/2000, Val Acc=0.6221, Val Loss=1.6577, lr=0.0100
[2025-05-07 02:16:27,416][train][INFO] - Epoch 1000/2000, Val Acc=0.6025, Val Loss=1.6243, lr=0.0100
[2025-05-07 02:16:28,585][train][INFO] - Epoch 985/2000, Val Acc=0.6148, Val Loss=1.6962, lr=0.0100
[2025-05-07 02:16:33,861][train][INFO] - Epoch 1006/2000, Val Acc=0.6175, Val Loss=1.6919, lr=0.0100
[2025-05-07 02:16:35,126][train][INFO] - Epoch 1001/2000, Val Acc=0.5709, Val Loss=1.8118, lr=0.0100
[2025-05-07 02:16:36,350][train][INFO] - Epoch 986/2000, Val Acc=0.6103, Val Loss=1.7261, lr=0.0100
[2025-05-07 02:16:41,865][train][INFO] - Epoch 1007/2000, Val Acc=0.6215, Val Loss=1.7157, lr=0.0100
[2025-05-07 02:16:42,937][train][INFO] - Epoch 1002/2000, Val Acc=0.5825, Val Loss=1.7260, lr=0.0100
[2025-05-07 02:16:44,196][train][INFO] - Epoch 987/2000, Val Acc=0.6151, Val Loss=1.7671, lr=0.0100
[2025-05-07 02:16:49,327][train][INFO] - Epoch 1008/2000, Val Acc=0.6180, Val Loss=1.7109, lr=0.0100
[2025-05-07 02:16:50,778][train][INFO] - Epoch 1003/2000, Val Acc=0.6072, Val Loss=1.6139, lr=0.0100
[2025-05-07 02:16:52,312][train][INFO] - Epoch 988/2000, Val Acc=0.6083, Val Loss=1.7913, lr=0.0100
[2025-05-07 02:16:57,062][train][INFO] - Epoch 1009/2000, Val Acc=0.6171, Val Loss=1.7097, lr=0.0100
[2025-05-07 02:16:58,536][train][INFO] - Epoch 1004/2000, Val Acc=0.5940, Val Loss=1.6529, lr=0.0100
[2025-05-07 02:17:00,424][train][INFO] - Epoch 989/2000, Val Acc=0.6132, Val Loss=1.7424, lr=0.0100
[2025-05-07 02:17:04,445][train][INFO] - Epoch 1010/2000, Val Acc=0.6140, Val Loss=1.7801, lr=0.0100
[2025-05-07 02:17:06,191][train][INFO] - Epoch 1005/2000, Val Acc=0.5836, Val Loss=1.7110, lr=0.0100
[2025-05-07 02:17:08,082][train][INFO] - Epoch 990/2000, Val Acc=0.6124, Val Loss=1.7610, lr=0.0100
[2025-05-07 02:17:12,136][train][INFO] - Epoch 1011/2000, Val Acc=0.6216, Val Loss=1.6745, lr=0.0100
[2025-05-07 02:17:14,004][train][INFO] - Epoch 1006/2000, Val Acc=0.5900, Val Loss=1.6902, lr=0.0100
[2025-05-07 02:17:15,929][train][INFO] - Epoch 991/2000, Val Acc=0.6091, Val Loss=1.7783, lr=0.0100
[2025-05-07 02:17:19,690][train][INFO] - Epoch 1012/2000, Val Acc=0.6120, Val Loss=1.7575, lr=0.0100
[2025-05-07 02:17:21,320][train][INFO] - Epoch 1007/2000, Val Acc=0.5743, Val Loss=1.8047, lr=0.0100
[2025-05-07 02:17:23,873][train][INFO] - Epoch 992/2000, Val Acc=0.6124, Val Loss=1.7274, lr=0.0100
[2025-05-07 02:17:27,084][train][INFO] - Epoch 1013/2000, Val Acc=0.6204, Val Loss=1.7051, lr=0.0100
[2025-05-07 02:17:29,130][train][INFO] - Epoch 1008/2000, Val Acc=0.5959, Val Loss=1.6731, lr=0.0100
[2025-05-07 02:17:31,580][train][INFO] - Epoch 993/2000, Val Acc=0.6176, Val Loss=1.6942, lr=0.0100
[2025-05-07 02:17:34,917][train][INFO] - Epoch 1014/2000, Val Acc=0.6200, Val Loss=1.7186, lr=0.0100
[2025-05-07 02:17:36,681][train][INFO] - Epoch 1009/2000, Val Acc=0.5800, Val Loss=1.7632, lr=0.0100
[2025-05-07 02:17:39,169][train][INFO] - Epoch 994/2000, Val Acc=0.6220, Val Loss=1.6983, lr=0.0100
[2025-05-07 02:17:42,500][train][INFO] - Epoch 1015/2000, Val Acc=0.5961, Val Loss=1.8386, lr=0.0100
[2025-05-07 02:17:44,398][train][INFO] - Epoch 1010/2000, Val Acc=0.6046, Val Loss=1.6173, lr=0.0100
[2025-05-07 02:17:46,651][train][INFO] - Epoch 995/2000, Val Acc=0.6059, Val Loss=1.8029, lr=0.0100
[2025-05-07 02:17:50,165][train][INFO] - Epoch 1016/2000, Val Acc=0.6169, Val Loss=1.7241, lr=0.0100
[2025-05-07 02:17:51,695][train][INFO] - Epoch 1011/2000, Val Acc=0.5743, Val Loss=1.7883, lr=0.0100
[2025-05-07 02:17:54,545][train][INFO] - Epoch 996/2000, Val Acc=0.6141, Val Loss=1.7184, lr=0.0100
[2025-05-07 02:17:57,678][train][INFO] - Epoch 1017/2000, Val Acc=0.6159, Val Loss=1.7340, lr=0.0100
[2025-05-07 02:17:59,366][train][INFO] - Epoch 1012/2000, Val Acc=0.6049, Val Loss=1.6129, lr=0.0100
[2025-05-07 02:18:02,578][train][INFO] - Epoch 997/2000, Val Acc=0.6111, Val Loss=1.7196, lr=0.0100
[2025-05-07 02:18:05,428][train][INFO] - Epoch 1018/2000, Val Acc=0.6164, Val Loss=1.7242, lr=0.0100
[2025-05-07 02:18:06,877][train][INFO] - Epoch 1013/2000, Val Acc=0.5931, Val Loss=1.7128, lr=0.0100
[2025-05-07 02:18:10,620][train][INFO] - Epoch 998/2000, Val Acc=0.6048, Val Loss=1.7929, lr=0.0100
[2025-05-07 02:18:12,498][train][INFO] - Epoch 1019/2000, Val Acc=0.6129, Val Loss=1.7380, lr=0.0100
[2025-05-07 02:18:15,001][train][INFO] - Epoch 1014/2000, Val Acc=0.5864, Val Loss=1.7307, lr=0.0100
[2025-05-07 02:18:18,869][train][INFO] - Epoch 999/2000, Val Acc=0.6168, Val Loss=1.6876, lr=0.0100
[2025-05-07 02:18:20,394][train][INFO] - Epoch 1020/2000, Val Acc=0.6257, Val Loss=1.6650, lr=0.0100
[2025-05-07 02:18:23,098][train][INFO] - Epoch 1015/2000, Val Acc=0.5942, Val Loss=1.6618, lr=0.0100
[2025-05-07 02:18:26,860][train][INFO] - Epoch 1000/2000, Val Acc=0.6067, Val Loss=1.7464, lr=0.0100
[2025-05-07 02:18:27,881][train][INFO] - Epoch 1021/2000, Val Acc=0.6076, Val Loss=1.8146, lr=0.0100
[2025-05-07 02:18:30,957][train][INFO] - Epoch 1016/2000, Val Acc=0.5972, Val Loss=1.6141, lr=0.0100
[2025-05-07 02:18:34,809][train][INFO] - Epoch 1001/2000, Val Acc=0.6051, Val Loss=1.8092, lr=0.0100
[2025-05-07 02:18:35,787][train][INFO] - Epoch 1022/2000, Val Acc=0.6130, Val Loss=1.7338, lr=0.0100
[2025-05-07 02:18:38,612][train][INFO] - Epoch 1017/2000, Val Acc=0.5982, Val Loss=1.6473, lr=0.0100
[2025-05-07 02:18:42,588][train][INFO] - Epoch 1002/2000, Val Acc=0.6123, Val Loss=1.7386, lr=0.0100
[2025-05-07 02:18:43,383][train][INFO] - Epoch 1023/2000, Val Acc=0.6235, Val Loss=1.6832, lr=0.0100
[2025-05-07 02:18:46,063][train][INFO] - Epoch 1018/2000, Val Acc=0.5854, Val Loss=1.7483, lr=0.0100
[2025-05-07 02:18:50,407][train][INFO] - Epoch 1003/2000, Val Acc=0.6167, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:18:51,240][train][INFO] - Epoch 1024/2000, Val Acc=0.5935, Val Loss=1.8593, lr=0.0100
[2025-05-07 02:18:53,877][train][INFO] - Epoch 1019/2000, Val Acc=0.6134, Val Loss=1.5668, lr=0.0100
[2025-05-07 02:18:58,564][train][INFO] - Epoch 1004/2000, Val Acc=0.6232, Val Loss=1.6654, lr=0.0100
[2025-05-07 02:18:58,976][train][INFO] - Epoch 1025/2000, Val Acc=0.6048, Val Loss=1.7870, lr=0.0100
[2025-05-07 02:19:01,761][train][INFO] - Epoch 1020/2000, Val Acc=0.5863, Val Loss=1.7403, lr=0.0100
[2025-05-07 02:19:06,374][train][INFO] - Epoch 1005/2000, Val Acc=0.6221, Val Loss=1.6577, lr=0.0100
[2025-05-07 02:19:06,714][train][INFO] - Epoch 1026/2000, Val Acc=0.6062, Val Loss=1.7887, lr=0.0100
[2025-05-07 02:19:09,781][train][INFO] - Epoch 1021/2000, Val Acc=0.5718, Val Loss=1.8303, lr=0.0100
[2025-05-07 02:19:13,845][train][INFO] - Epoch 1027/2000, Val Acc=0.6311, Val Loss=1.6587, lr=0.0100
[2025-05-07 02:19:14,294][train][INFO] - Epoch 1006/2000, Val Acc=0.6175, Val Loss=1.6919, lr=0.0100
[2025-05-07 02:19:17,164][train][INFO] - Epoch 1022/2000, Val Acc=0.5980, Val Loss=1.6529, lr=0.0100
[2025-05-07 02:19:21,004][train][INFO] - Epoch 1028/2000, Val Acc=0.6095, Val Loss=1.7752, lr=0.0100
[2025-05-07 02:19:22,229][train][INFO] - Epoch 1007/2000, Val Acc=0.6215, Val Loss=1.7157, lr=0.0100
[2025-05-07 02:19:25,059][train][INFO] - Epoch 1023/2000, Val Acc=0.6080, Val Loss=1.6003, lr=0.0100
[2025-05-07 02:19:28,334][train][INFO] - Epoch 1029/2000, Val Acc=0.6249, Val Loss=1.6590, lr=0.0100
[2025-05-07 02:19:29,940][train][INFO] - Epoch 1008/2000, Val Acc=0.6180, Val Loss=1.7109, lr=0.0100
[2025-05-07 02:19:32,610][train][INFO] - Epoch 1024/2000, Val Acc=0.5700, Val Loss=1.7993, lr=0.0100
[2025-05-07 02:19:35,927][train][INFO] - Epoch 1030/2000, Val Acc=0.6213, Val Loss=1.6709, lr=0.0100
[2025-05-07 02:19:37,964][train][INFO] - Epoch 1009/2000, Val Acc=0.6171, Val Loss=1.7097, lr=0.0100
[2025-05-07 02:19:40,185][train][INFO] - Epoch 1025/2000, Val Acc=0.6049, Val Loss=1.5852, lr=0.0100
[2025-05-07 02:19:43,265][train][INFO] - Epoch 1031/2000, Val Acc=0.6354, Val Loss=1.6333, lr=0.0100
[2025-05-07 02:19:45,872][train][INFO] - Epoch 1010/2000, Val Acc=0.6140, Val Loss=1.7801, lr=0.0100
[2025-05-07 02:19:47,667][train][INFO] - Epoch 1026/2000, Val Acc=0.5981, Val Loss=1.6875, lr=0.0100
[2025-05-07 02:19:50,864][train][INFO] - Epoch 1032/2000, Val Acc=0.6056, Val Loss=1.7838, lr=0.0100
[2025-05-07 02:19:54,102][train][INFO] - Epoch 1011/2000, Val Acc=0.6216, Val Loss=1.6745, lr=0.0100
[2025-05-07 02:19:55,416][train][INFO] - Epoch 1027/2000, Val Acc=0.5864, Val Loss=1.7582, lr=0.0100
[2025-05-07 02:19:58,638][train][INFO] - Epoch 1033/2000, Val Acc=0.6077, Val Loss=1.7802, lr=0.0100
[2025-05-07 02:20:01,857][train][INFO] - Epoch 1012/2000, Val Acc=0.6120, Val Loss=1.7575, lr=0.0100
[2025-05-07 02:20:03,170][train][INFO] - Epoch 1028/2000, Val Acc=0.6099, Val Loss=1.6033, lr=0.0100
[2025-05-07 02:20:06,380][train][INFO] - Epoch 1034/2000, Val Acc=0.6099, Val Loss=1.7853, lr=0.0100
[2025-05-07 02:20:09,208][train][INFO] - Epoch 1013/2000, Val Acc=0.6204, Val Loss=1.7051, lr=0.0100
[2025-05-07 02:20:10,889][train][INFO] - Epoch 1029/2000, Val Acc=0.5944, Val Loss=1.6605, lr=0.0100
[2025-05-07 02:20:13,984][train][INFO] - Epoch 1035/2000, Val Acc=0.6112, Val Loss=1.7493, lr=0.0100
[2025-05-07 02:20:16,983][train][INFO] - Epoch 1014/2000, Val Acc=0.6200, Val Loss=1.7186, lr=0.0100
[2025-05-07 02:20:18,568][train][INFO] - Epoch 1030/2000, Val Acc=0.5834, Val Loss=1.7260, lr=0.0100
[2025-05-07 02:20:21,837][train][INFO] - Epoch 1036/2000, Val Acc=0.6087, Val Loss=1.7982, lr=0.0100
[2025-05-07 02:20:24,584][train][INFO] - Epoch 1015/2000, Val Acc=0.5961, Val Loss=1.8386, lr=0.0100
[2025-05-07 02:20:25,848][train][INFO] - Epoch 1031/2000, Val Acc=0.5839, Val Loss=1.7594, lr=0.0100
[2025-05-07 02:20:29,561][train][INFO] - Epoch 1037/2000, Val Acc=0.6159, Val Loss=1.7537, lr=0.0100
[2025-05-07 02:20:32,487][train][INFO] - Epoch 1016/2000, Val Acc=0.6169, Val Loss=1.7241, lr=0.0100
[2025-05-07 02:20:33,326][train][INFO] - Epoch 1032/2000, Val Acc=0.5672, Val Loss=1.8296, lr=0.0100
[2025-05-07 02:20:37,373][train][INFO] - Epoch 1038/2000, Val Acc=0.6199, Val Loss=1.6945, lr=0.0100
[2025-05-07 02:20:40,613][train][INFO] - Epoch 1017/2000, Val Acc=0.6159, Val Loss=1.7340, lr=0.0100
[2025-05-07 02:20:41,198][train][INFO] - Epoch 1033/2000, Val Acc=0.5791, Val Loss=1.7523, lr=0.0100
[2025-05-07 02:20:44,954][train][INFO] - Epoch 1039/2000, Val Acc=0.6168, Val Loss=1.7341, lr=0.0100
[2025-05-07 02:20:48,475][train][INFO] - Epoch 1034/2000, Val Acc=0.6041, Val Loss=1.5932, lr=0.0100
[2025-05-07 02:20:48,492][train][INFO] - Epoch 1018/2000, Val Acc=0.6164, Val Loss=1.7242, lr=0.0100
[2025-05-07 02:20:52,499][train][INFO] - Epoch 1040/2000, Val Acc=0.6095, Val Loss=1.7573, lr=0.0100
[2025-05-07 02:20:55,853][train][INFO] - Epoch 1035/2000, Val Acc=0.5802, Val Loss=1.7477, lr=0.0100
[2025-05-07 02:20:56,602][train][INFO] - Epoch 1019/2000, Val Acc=0.6129, Val Loss=1.7380, lr=0.0100
[2025-05-07 02:20:59,831][train][INFO] - Epoch 1041/2000, Val Acc=0.6138, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:21:03,811][train][INFO] - Epoch 1036/2000, Val Acc=0.6024, Val Loss=1.6302, lr=0.0100
[2025-05-07 02:21:04,261][train][INFO] - Epoch 1020/2000, Val Acc=0.6257, Val Loss=1.6650, lr=0.0100
[2025-05-07 02:21:06,966][train][INFO] - Epoch 1042/2000, Val Acc=0.6171, Val Loss=1.7249, lr=0.0100
[2025-05-07 02:21:11,909][train][INFO] - Epoch 1037/2000, Val Acc=0.5921, Val Loss=1.6973, lr=0.0100
[2025-05-07 02:21:12,256][train][INFO] - Epoch 1021/2000, Val Acc=0.6076, Val Loss=1.8146, lr=0.0100
[2025-05-07 02:21:14,714][train][INFO] - Epoch 1043/2000, Val Acc=0.6124, Val Loss=1.7596, lr=0.0100
[2025-05-07 02:21:19,612][train][INFO] - Epoch 1038/2000, Val Acc=0.5925, Val Loss=1.6728, lr=0.0100
[2025-05-07 02:21:19,946][train][INFO] - Epoch 1022/2000, Val Acc=0.6130, Val Loss=1.7338, lr=0.0100
[2025-05-07 02:21:22,295][train][INFO] - Epoch 1044/2000, Val Acc=0.6099, Val Loss=1.7769, lr=0.0100
[2025-05-07 02:21:27,115][train][INFO] - Epoch 1023/2000, Val Acc=0.6235, Val Loss=1.6832, lr=0.0100
[2025-05-07 02:21:27,418][train][INFO] - Epoch 1039/2000, Val Acc=0.5846, Val Loss=1.7171, lr=0.0100
[2025-05-07 02:21:29,714][train][INFO] - Epoch 1045/2000, Val Acc=0.6095, Val Loss=1.7654, lr=0.0100
[2025-05-07 02:21:34,597][train][INFO] - Epoch 1024/2000, Val Acc=0.5935, Val Loss=1.8593, lr=0.0100
[2025-05-07 02:21:35,483][train][INFO] - Epoch 1040/2000, Val Acc=0.5828, Val Loss=1.7541, lr=0.0100
[2025-05-07 02:21:37,118][train][INFO] - Epoch 1046/2000, Val Acc=0.6118, Val Loss=1.7260, lr=0.0100
[2025-05-07 02:21:42,524][train][INFO] - Epoch 1025/2000, Val Acc=0.6048, Val Loss=1.7870, lr=0.0100
[2025-05-07 02:21:43,378][train][INFO] - Epoch 1041/2000, Val Acc=0.5813, Val Loss=1.7302, lr=0.0100
[2025-05-07 02:21:44,676][train][INFO] - Epoch 1047/2000, Val Acc=0.6293, Val Loss=1.6601, lr=0.0100
[2025-05-07 02:21:50,122][train][INFO] - Epoch 1026/2000, Val Acc=0.6062, Val Loss=1.7887, lr=0.0100
[2025-05-07 02:21:51,296][train][INFO] - Epoch 1042/2000, Val Acc=0.5967, Val Loss=1.6813, lr=0.0100
[2025-05-07 02:21:51,904][train][INFO] - Epoch 1048/2000, Val Acc=0.6226, Val Loss=1.6498, lr=0.0100
[2025-05-07 02:21:57,775][train][INFO] - Epoch 1027/2000, Val Acc=0.6311, Val Loss=1.6587, lr=0.0100
[2025-05-07 02:21:58,896][train][INFO] - Epoch 1049/2000, Val Acc=0.6177, Val Loss=1.7174, lr=0.0100
[2025-05-07 02:21:59,167][train][INFO] - Epoch 1043/2000, Val Acc=0.5961, Val Loss=1.6493, lr=0.0100
[2025-05-07 02:22:05,910][train][INFO] - Epoch 1028/2000, Val Acc=0.6095, Val Loss=1.7752, lr=0.0100
[2025-05-07 02:22:06,759][train][INFO] - Epoch 1044/2000, Val Acc=0.5723, Val Loss=1.8215, lr=0.0100
[2025-05-07 02:22:07,262][train][INFO] - Epoch 1050/2000, Val Acc=0.6045, Val Loss=1.7818, lr=0.0100
[2025-05-07 02:22:13,511][train][INFO] - Epoch 1029/2000, Val Acc=0.6249, Val Loss=1.6590, lr=0.0100
[2025-05-07 02:22:14,407][train][INFO] - Epoch 1045/2000, Val Acc=0.5959, Val Loss=1.6528, lr=0.0100
[2025-05-07 02:22:15,325][train][INFO] - Epoch 1051/2000, Val Acc=0.6203, Val Loss=1.6996, lr=0.0100
[2025-05-07 02:22:21,378][train][INFO] - Epoch 1030/2000, Val Acc=0.6213, Val Loss=1.6709, lr=0.0100
[2025-05-07 02:22:21,972][train][INFO] - Epoch 1046/2000, Val Acc=0.5943, Val Loss=1.6621, lr=0.0100
[2025-05-07 02:22:22,911][train][INFO] - Epoch 1052/2000, Val Acc=0.6060, Val Loss=1.7715, lr=0.0100
[2025-05-07 02:22:29,187][train][INFO] - Epoch 1031/2000, Val Acc=0.6354, Val Loss=1.6333, lr=0.0100
[2025-05-07 02:22:29,314][train][INFO] - Epoch 1047/2000, Val Acc=0.5973, Val Loss=1.6504, lr=0.0100
[2025-05-07 02:22:30,358][train][INFO] - Epoch 1053/2000, Val Acc=0.5975, Val Loss=1.8623, lr=0.0100
[2025-05-07 02:22:37,094][train][INFO] - Epoch 1048/2000, Val Acc=0.5973, Val Loss=1.6283, lr=0.0100
[2025-05-07 02:22:37,234][train][INFO] - Epoch 1032/2000, Val Acc=0.6056, Val Loss=1.7838, lr=0.0100
[2025-05-07 02:22:38,164][train][INFO] - Epoch 1054/2000, Val Acc=0.6110, Val Loss=1.7590, lr=0.0100
[2025-05-07 02:22:44,663][train][INFO] - Epoch 1033/2000, Val Acc=0.6077, Val Loss=1.7802, lr=0.0100
[2025-05-07 02:22:45,156][train][INFO] - Epoch 1049/2000, Val Acc=0.5908, Val Loss=1.6930, lr=0.0100
[2025-05-07 02:22:45,666][train][INFO] - Epoch 1055/2000, Val Acc=0.6007, Val Loss=1.8127, lr=0.0100
[2025-05-07 02:22:52,545][train][INFO] - Epoch 1034/2000, Val Acc=0.6099, Val Loss=1.7853, lr=0.0100
[2025-05-07 02:22:52,617][train][INFO] - Epoch 1050/2000, Val Acc=0.5805, Val Loss=1.7467, lr=0.0100
[2025-05-07 02:22:53,419][train][INFO] - Epoch 1056/2000, Val Acc=0.6191, Val Loss=1.7004, lr=0.0100
[2025-05-07 02:23:00,376][train][INFO] - Epoch 1035/2000, Val Acc=0.6112, Val Loss=1.7493, lr=0.0100
[2025-05-07 02:23:00,506][train][INFO] - Epoch 1051/2000, Val Acc=0.5777, Val Loss=1.7361, lr=0.0100
[2025-05-07 02:23:00,953][train][INFO] - Epoch 1057/2000, Val Acc=0.6175, Val Loss=1.7058, lr=0.0100
[2025-05-07 02:23:08,319][train][INFO] - Epoch 1036/2000, Val Acc=0.6087, Val Loss=1.7982, lr=0.0100
[2025-05-07 02:23:08,336][train][INFO] - Epoch 1052/2000, Val Acc=0.5795, Val Loss=1.7741, lr=0.0100
[2025-05-07 02:23:08,904][train][INFO] - Epoch 1058/2000, Val Acc=0.6138, Val Loss=1.7344, lr=0.0100
[2025-05-07 02:23:15,726][train][INFO] - Epoch 1037/2000, Val Acc=0.6159, Val Loss=1.7537, lr=0.0100
[2025-05-07 02:23:16,380][train][INFO] - Epoch 1053/2000, Val Acc=0.5982, Val Loss=1.6298, lr=0.0100
[2025-05-07 02:23:16,772][train][INFO] - Epoch 1059/2000, Val Acc=0.6123, Val Loss=1.7646, lr=0.0100
[2025-05-07 02:23:23,223][train][INFO] - Epoch 1038/2000, Val Acc=0.6199, Val Loss=1.6945, lr=0.0100
[2025-05-07 02:23:24,379][train][INFO] - Epoch 1054/2000, Val Acc=0.5929, Val Loss=1.6702, lr=0.0100
[2025-05-07 02:23:24,482][train][INFO] - Epoch 1060/2000, Val Acc=0.6090, Val Loss=1.7599, lr=0.0100
[2025-05-07 02:23:30,894][train][INFO] - Epoch 1039/2000, Val Acc=0.6168, Val Loss=1.7341, lr=0.0100
[2025-05-07 02:23:32,017][train][INFO] - Epoch 1055/2000, Val Acc=0.5901, Val Loss=1.6975, lr=0.0100
[2025-05-07 02:23:32,095][train][INFO] - Epoch 1061/2000, Val Acc=0.6246, Val Loss=1.6615, lr=0.0100
[2025-05-07 02:23:38,790][train][INFO] - Epoch 1040/2000, Val Acc=0.6095, Val Loss=1.7573, lr=0.0100
[2025-05-07 02:23:38,920][train][INFO] - Epoch 1056/2000, Val Acc=0.6007, Val Loss=1.6494, lr=0.0100
[2025-05-07 02:23:39,901][train][INFO] - Epoch 1062/2000, Val Acc=0.6061, Val Loss=1.7657, lr=0.0100
[2025-05-07 02:23:46,215][train][INFO] - Epoch 1057/2000, Val Acc=0.6054, Val Loss=1.6067, lr=0.0100
[2025-05-07 02:23:47,050][train][INFO] - Epoch 1041/2000, Val Acc=0.6138, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:23:47,426][train][INFO] - Epoch 1063/2000, Val Acc=0.6112, Val Loss=1.6958, lr=0.0100
[2025-05-07 02:23:54,157][train][INFO] - Epoch 1058/2000, Val Acc=0.6034, Val Loss=1.5786, lr=0.0100
[2025-05-07 02:23:54,813][train][INFO] - Epoch 1042/2000, Val Acc=0.6171, Val Loss=1.7249, lr=0.0100
[2025-05-07 02:23:55,453][train][INFO] - Epoch 1064/2000, Val Acc=0.6242, Val Loss=1.7089, lr=0.0100
[2025-05-07 02:24:02,045][train][INFO] - Epoch 1059/2000, Val Acc=0.5937, Val Loss=1.6744, lr=0.0100
[2025-05-07 02:24:02,696][train][INFO] - Epoch 1043/2000, Val Acc=0.6124, Val Loss=1.7596, lr=0.0100
[2025-05-07 02:24:03,268][train][INFO] - Epoch 1065/2000, Val Acc=0.6106, Val Loss=1.7662, lr=0.0100
[2025-05-07 02:24:09,479][train][INFO] - Epoch 1060/2000, Val Acc=0.5779, Val Loss=1.7721, lr=0.0100
[2025-05-07 02:24:10,283][train][INFO] - Epoch 1044/2000, Val Acc=0.6099, Val Loss=1.7769, lr=0.0100
[2025-05-07 02:24:11,037][train][INFO] - Epoch 1066/2000, Val Acc=0.6229, Val Loss=1.6862, lr=0.0100
[2025-05-07 02:24:16,908][train][INFO] - Epoch 1061/2000, Val Acc=0.5920, Val Loss=1.6819, lr=0.0100
[2025-05-07 02:24:18,145][train][INFO] - Epoch 1045/2000, Val Acc=0.6095, Val Loss=1.7654, lr=0.0100
[2025-05-07 02:24:18,973][train][INFO] - Epoch 1067/2000, Val Acc=0.6261, Val Loss=1.6999, lr=0.0100
[2025-05-07 02:24:24,729][train][INFO] - Epoch 1062/2000, Val Acc=0.5878, Val Loss=1.7647, lr=0.0100
[2025-05-07 02:24:26,208][train][INFO] - Epoch 1046/2000, Val Acc=0.6118, Val Loss=1.7260, lr=0.0100
[2025-05-07 02:24:26,289][train][INFO] - Epoch 1068/2000, Val Acc=0.6004, Val Loss=1.8198, lr=0.0100
[2025-05-07 02:24:32,401][train][INFO] - Epoch 1063/2000, Val Acc=0.5840, Val Loss=1.7420, lr=0.0100
[2025-05-07 02:24:33,870][train][INFO] - Epoch 1047/2000, Val Acc=0.6293, Val Loss=1.6601, lr=0.0100
[2025-05-07 02:24:33,988][train][INFO] - Epoch 1069/2000, Val Acc=0.6246, Val Loss=1.6845, lr=0.0100
[2025-05-07 02:24:40,252][train][INFO] - Epoch 1064/2000, Val Acc=0.5872, Val Loss=1.7170, lr=0.0100
[2025-05-07 02:24:41,544][train][INFO] - Epoch 1070/2000, Val Acc=0.6092, Val Loss=1.7388, lr=0.0100
[2025-05-07 02:24:41,755][train][INFO] - Epoch 1048/2000, Val Acc=0.6226, Val Loss=1.6498, lr=0.0100
[2025-05-07 02:24:48,211][train][INFO] - Epoch 1065/2000, Val Acc=0.5868, Val Loss=1.7270, lr=0.0100
[2025-05-07 02:24:49,129][train][INFO] - Epoch 1071/2000, Val Acc=0.6115, Val Loss=1.7420, lr=0.0100
[2025-05-07 02:24:49,804][train][INFO] - Epoch 1049/2000, Val Acc=0.6177, Val Loss=1.7174, lr=0.0100
[2025-05-07 02:24:55,891][train][INFO] - Epoch 1066/2000, Val Acc=0.6069, Val Loss=1.5986, lr=0.0100
[2025-05-07 02:24:56,665][train][INFO] - Epoch 1072/2000, Val Acc=0.6301, Val Loss=1.6441, lr=0.0100
[2025-05-07 02:24:57,960][train][INFO] - Epoch 1050/2000, Val Acc=0.6045, Val Loss=1.7818, lr=0.0100
[2025-05-07 02:25:03,388][train][INFO] - Epoch 1067/2000, Val Acc=0.5575, Val Loss=1.9184, lr=0.0100
[2025-05-07 02:25:04,254][train][INFO] - Epoch 1073/2000, Val Acc=0.6198, Val Loss=1.6805, lr=0.0100
[2025-05-07 02:25:05,750][train][INFO] - Epoch 1051/2000, Val Acc=0.6203, Val Loss=1.6996, lr=0.0100
[2025-05-07 02:25:11,408][train][INFO] - Epoch 1068/2000, Val Acc=0.5775, Val Loss=1.7634, lr=0.0100
[2025-05-07 02:25:12,145][train][INFO] - Epoch 1074/2000, Val Acc=0.5915, Val Loss=1.8724, lr=0.0100
[2025-05-07 02:25:13,376][train][INFO] - Epoch 1052/2000, Val Acc=0.6060, Val Loss=1.7715, lr=0.0100
[2025-05-07 02:25:19,526][train][INFO] - Epoch 1069/2000, Val Acc=0.5859, Val Loss=1.7375, lr=0.0100
[2025-05-07 02:25:20,152][train][INFO] - Epoch 1075/2000, Val Acc=0.6267, Val Loss=1.6555, lr=0.0100
[2025-05-07 02:25:21,141][train][INFO] - Epoch 1053/2000, Val Acc=0.5975, Val Loss=1.8623, lr=0.0100
[2025-05-07 02:25:27,107][train][INFO] - Epoch 1076/2000, Val Acc=0.6297, Val Loss=1.6746, lr=0.0100
[2025-05-07 02:25:27,246][train][INFO] - Epoch 1070/2000, Val Acc=0.5920, Val Loss=1.6758, lr=0.0100
[2025-05-07 02:25:29,067][train][INFO] - Epoch 1054/2000, Val Acc=0.6110, Val Loss=1.7590, lr=0.0100
[2025-05-07 02:25:34,528][train][INFO] - Epoch 1077/2000, Val Acc=0.6117, Val Loss=1.6979, lr=0.0100
[2025-05-07 02:25:34,628][train][INFO] - Epoch 1071/2000, Val Acc=0.5880, Val Loss=1.7629, lr=0.0100
[2025-05-07 02:25:36,827][train][INFO] - Epoch 1055/2000, Val Acc=0.6007, Val Loss=1.8127, lr=0.0100
[2025-05-07 02:25:42,264][train][INFO] - Epoch 1072/2000, Val Acc=0.5988, Val Loss=1.6384, lr=0.0100
[2025-05-07 02:25:42,383][train][INFO] - Epoch 1078/2000, Val Acc=0.6137, Val Loss=1.7509, lr=0.0100
[2025-05-07 02:25:44,501][train][INFO] - Epoch 1056/2000, Val Acc=0.6191, Val Loss=1.7004, lr=0.0100
[2025-05-07 02:25:49,518][train][INFO] - Epoch 1079/2000, Val Acc=0.6279, Val Loss=1.6475, lr=0.0100
[2025-05-07 02:25:49,751][train][INFO] - Epoch 1073/2000, Val Acc=0.5957, Val Loss=1.6471, lr=0.0100
[2025-05-07 02:25:52,478][train][INFO] - Epoch 1057/2000, Val Acc=0.6175, Val Loss=1.7058, lr=0.0100
[2025-05-07 02:25:57,085][train][INFO] - Epoch 1080/2000, Val Acc=0.6143, Val Loss=1.7348, lr=0.0100
[2025-05-07 02:25:57,683][train][INFO] - Epoch 1074/2000, Val Acc=0.5818, Val Loss=1.7184, lr=0.0100
[2025-05-07 02:26:00,061][train][INFO] - Epoch 1058/2000, Val Acc=0.6138, Val Loss=1.7344, lr=0.0100
[2025-05-07 02:26:04,660][train][INFO] - Epoch 1081/2000, Val Acc=0.6106, Val Loss=1.7536, lr=0.0100
[2025-05-07 02:26:05,311][train][INFO] - Epoch 1075/2000, Val Acc=0.6014, Val Loss=1.6213, lr=0.0100
[2025-05-07 02:26:07,576][train][INFO] - Epoch 1059/2000, Val Acc=0.6123, Val Loss=1.7646, lr=0.0100
[2025-05-07 02:26:11,901][train][INFO] - Epoch 1082/2000, Val Acc=0.6146, Val Loss=1.7443, lr=0.0100
[2025-05-07 02:26:12,658][train][INFO] - Epoch 1076/2000, Val Acc=0.5752, Val Loss=1.7734, lr=0.0100
[2025-05-07 02:26:15,640][train][INFO] - Epoch 1060/2000, Val Acc=0.6090, Val Loss=1.7599, lr=0.0100
[2025-05-07 02:26:19,500][train][INFO] - Epoch 1083/2000, Val Acc=0.6080, Val Loss=1.7493, lr=0.0100
[2025-05-07 02:26:20,105][train][INFO] - Epoch 1077/2000, Val Acc=0.5857, Val Loss=1.7049, lr=0.0100
[2025-05-07 02:26:23,354][train][INFO] - Epoch 1061/2000, Val Acc=0.6246, Val Loss=1.6615, lr=0.0100
[2025-05-07 02:26:27,037][train][INFO] - Epoch 1084/2000, Val Acc=0.6058, Val Loss=1.7862, lr=0.0100
[2025-05-07 02:26:28,186][train][INFO] - Epoch 1078/2000, Val Acc=0.5748, Val Loss=1.7856, lr=0.0100
[2025-05-07 02:26:30,366][train][INFO] - Epoch 1062/2000, Val Acc=0.6061, Val Loss=1.7657, lr=0.0100
[2025-05-07 02:26:34,432][train][INFO] - Epoch 1085/2000, Val Acc=0.6071, Val Loss=1.8034, lr=0.0100
[2025-05-07 02:26:36,122][train][INFO] - Epoch 1079/2000, Val Acc=0.5897, Val Loss=1.7254, lr=0.0100
[2025-05-07 02:26:37,705][train][INFO] - Epoch 1063/2000, Val Acc=0.6112, Val Loss=1.6958, lr=0.0100
[2025-05-07 02:26:42,115][train][INFO] - Epoch 1086/2000, Val Acc=0.6113, Val Loss=1.7800, lr=0.0100
[2025-05-07 02:26:43,735][train][INFO] - Epoch 1080/2000, Val Acc=0.6042, Val Loss=1.6471, lr=0.0100
[2025-05-07 02:26:45,544][train][INFO] - Epoch 1064/2000, Val Acc=0.6242, Val Loss=1.7089, lr=0.0100
[2025-05-07 02:26:49,663][train][INFO] - Epoch 1087/2000, Val Acc=0.6128, Val Loss=1.7514, lr=0.0100
[2025-05-07 02:26:51,405][train][INFO] - Epoch 1081/2000, Val Acc=0.5838, Val Loss=1.7762, lr=0.0100
[2025-05-07 02:26:53,440][train][INFO] - Epoch 1065/2000, Val Acc=0.6106, Val Loss=1.7662, lr=0.0100
[2025-05-07 02:26:56,970][train][INFO] - Epoch 1088/2000, Val Acc=0.6047, Val Loss=1.7758, lr=0.0100
[2025-05-07 02:26:59,139][train][INFO] - Epoch 1082/2000, Val Acc=0.5874, Val Loss=1.7117, lr=0.0100
[2025-05-07 02:27:01,548][train][INFO] - Epoch 1066/2000, Val Acc=0.6229, Val Loss=1.6862, lr=0.0100
[2025-05-07 02:27:04,715][train][INFO] - Epoch 1089/2000, Val Acc=0.6084, Val Loss=1.7721, lr=0.0100
[2025-05-07 02:27:06,561][train][INFO] - Epoch 1083/2000, Val Acc=0.5862, Val Loss=1.7192, lr=0.0100
[2025-05-07 02:27:09,174][train][INFO] - Epoch 1067/2000, Val Acc=0.6261, Val Loss=1.6999, lr=0.0100
[2025-05-07 02:27:12,006][train][INFO] - Epoch 1090/2000, Val Acc=0.6094, Val Loss=1.7436, lr=0.0100
[2025-05-07 02:27:13,783][train][INFO] - Epoch 1084/2000, Val Acc=0.5968, Val Loss=1.6598, lr=0.0100
[2025-05-07 02:27:17,085][train][INFO] - Epoch 1068/2000, Val Acc=0.6004, Val Loss=1.8198, lr=0.0100
[2025-05-07 02:27:19,679][train][INFO] - Epoch 1091/2000, Val Acc=0.6144, Val Loss=1.7292, lr=0.0100
[2025-05-07 02:27:21,382][train][INFO] - Epoch 1085/2000, Val Acc=0.5820, Val Loss=1.7568, lr=0.0100
[2025-05-07 02:27:24,508][train][INFO] - Epoch 1069/2000, Val Acc=0.6246, Val Loss=1.6845, lr=0.0100
[2025-05-07 02:27:27,167][train][INFO] - Epoch 1092/2000, Val Acc=0.6139, Val Loss=1.7147, lr=0.0100
[2025-05-07 02:27:29,130][train][INFO] - Epoch 1086/2000, Val Acc=0.6024, Val Loss=1.6224, lr=0.0100
[2025-05-07 02:27:32,295][train][INFO] - Epoch 1070/2000, Val Acc=0.6092, Val Loss=1.7388, lr=0.0100
[2025-05-07 02:27:34,706][train][INFO] - Epoch 1093/2000, Val Acc=0.6256, Val Loss=1.6888, lr=0.0100
[2025-05-07 02:27:37,057][train][INFO] - Epoch 1087/2000, Val Acc=0.5949, Val Loss=1.7001, lr=0.0100
[2025-05-07 02:27:40,265][train][INFO] - Epoch 1071/2000, Val Acc=0.6115, Val Loss=1.7420, lr=0.0100
[2025-05-07 02:27:41,827][train][INFO] - Epoch 1094/2000, Val Acc=0.6230, Val Loss=1.7248, lr=0.0100
[2025-05-07 02:27:44,745][train][INFO] - Epoch 1088/2000, Val Acc=0.5789, Val Loss=1.7947, lr=0.0100
[2025-05-07 02:27:48,426][train][INFO] - Epoch 1072/2000, Val Acc=0.6301, Val Loss=1.6441, lr=0.0100
[2025-05-07 02:27:49,581][train][INFO] - Epoch 1095/2000, Val Acc=0.6252, Val Loss=1.6866, lr=0.0100
[2025-05-07 02:27:52,224][train][INFO] - Epoch 1089/2000, Val Acc=0.5850, Val Loss=1.7102, lr=0.0100
[2025-05-07 02:27:56,276][train][INFO] - Epoch 1073/2000, Val Acc=0.6198, Val Loss=1.6805, lr=0.0100
[2025-05-07 02:27:57,133][train][INFO] - Epoch 1096/2000, Val Acc=0.6183, Val Loss=1.6815, lr=0.0100
[2025-05-07 02:27:59,551][train][INFO] - Epoch 1090/2000, Val Acc=0.5923, Val Loss=1.6784, lr=0.0100
[2025-05-07 02:28:04,043][train][INFO] - Epoch 1074/2000, Val Acc=0.5915, Val Loss=1.8724, lr=0.0100
[2025-05-07 02:28:04,648][train][INFO] - Epoch 1097/2000, Val Acc=0.6220, Val Loss=1.6793, lr=0.0100
[2025-05-07 02:28:07,331][train][INFO] - Epoch 1091/2000, Val Acc=0.5868, Val Loss=1.7359, lr=0.0100
[2025-05-07 02:28:12,000][train][INFO] - Epoch 1075/2000, Val Acc=0.6267, Val Loss=1.6555, lr=0.0100
[2025-05-07 02:28:12,461][train][INFO] - Epoch 1098/2000, Val Acc=0.6364, Val Loss=1.6221, lr=0.0100
[2025-05-07 02:28:15,139][train][INFO] - Epoch 1092/2000, Val Acc=0.5793, Val Loss=1.7479, lr=0.0100
[2025-05-07 02:28:20,008][train][INFO] - Epoch 1076/2000, Val Acc=0.6297, Val Loss=1.6746, lr=0.0100
[2025-05-07 02:28:20,290][train][INFO] - Epoch 1099/2000, Val Acc=0.6136, Val Loss=1.7148, lr=0.0100
[2025-05-07 02:28:23,029][train][INFO] - Epoch 1093/2000, Val Acc=0.5838, Val Loss=1.7259, lr=0.0100
[2025-05-07 02:28:27,572][train][INFO] - Epoch 1077/2000, Val Acc=0.6117, Val Loss=1.6979, lr=0.0100
[2025-05-07 02:28:28,416][train][INFO] - Epoch 1100/2000, Val Acc=0.6182, Val Loss=1.7325, lr=0.0100
[2025-05-07 02:28:30,918][train][INFO] - Epoch 1094/2000, Val Acc=0.5848, Val Loss=1.7390, lr=0.0100
[2025-05-07 02:28:35,699][train][INFO] - Epoch 1078/2000, Val Acc=0.6137, Val Loss=1.7509, lr=0.0100
[2025-05-07 02:28:35,899][train][INFO] - Epoch 1101/2000, Val Acc=0.6173, Val Loss=1.6823, lr=0.0100
[2025-05-07 02:28:38,863][train][INFO] - Epoch 1095/2000, Val Acc=0.5803, Val Loss=1.7538, lr=0.0100
[2025-05-07 02:28:43,026][train][INFO] - Epoch 1102/2000, Val Acc=0.6314, Val Loss=1.6339, lr=0.0100
[2025-05-07 02:28:43,242][train][INFO] - Epoch 1079/2000, Val Acc=0.6279, Val Loss=1.6475, lr=0.0100
[2025-05-07 02:28:46,376][train][INFO] - Epoch 1096/2000, Val Acc=0.5912, Val Loss=1.7096, lr=0.0100
[2025-05-07 02:28:50,632][train][INFO] - Epoch 1103/2000, Val Acc=0.6260, Val Loss=1.6706, lr=0.0100
[2025-05-07 02:28:50,801][train][INFO] - Epoch 1080/2000, Val Acc=0.6143, Val Loss=1.7348, lr=0.0100
[2025-05-07 02:28:53,936][train][INFO] - Epoch 1097/2000, Val Acc=0.5866, Val Loss=1.6705, lr=0.0100
[2025-05-07 02:28:57,989][train][INFO] - Epoch 1104/2000, Val Acc=0.6010, Val Loss=1.7985, lr=0.0100
[2025-05-07 02:28:58,202][train][INFO] - Epoch 1081/2000, Val Acc=0.6106, Val Loss=1.7536, lr=0.0100
[2025-05-07 02:29:01,879][train][INFO] - Epoch 1098/2000, Val Acc=0.5919, Val Loss=1.6832, lr=0.0100
[2025-05-07 02:29:05,779][train][INFO] - Epoch 1105/2000, Val Acc=0.6085, Val Loss=1.7745, lr=0.0100
[2025-05-07 02:29:06,231][train][INFO] - Epoch 1082/2000, Val Acc=0.6146, Val Loss=1.7443, lr=0.0100
[2025-05-07 02:29:09,438][train][INFO] - Epoch 1099/2000, Val Acc=0.5977, Val Loss=1.6473, lr=0.0100
[2025-05-07 02:29:13,412][train][INFO] - Epoch 1106/2000, Val Acc=0.6202, Val Loss=1.7338, lr=0.0100
[2025-05-07 02:29:13,926][train][INFO] - Epoch 1083/2000, Val Acc=0.6080, Val Loss=1.7493, lr=0.0100
[2025-05-07 02:29:17,547][train][INFO] - Epoch 1100/2000, Val Acc=0.5905, Val Loss=1.6958, lr=0.0100
[2025-05-07 02:29:20,427][train][INFO] - Epoch 1107/2000, Val Acc=0.6111, Val Loss=1.7609, lr=0.0100
[2025-05-07 02:29:21,975][train][INFO] - Epoch 1084/2000, Val Acc=0.6058, Val Loss=1.7862, lr=0.0100
[2025-05-07 02:29:25,222][train][INFO] - Epoch 1101/2000, Val Acc=0.5846, Val Loss=1.7160, lr=0.0100
[2025-05-07 02:29:28,074][train][INFO] - Epoch 1108/2000, Val Acc=0.6179, Val Loss=1.6709, lr=0.0100
[2025-05-07 02:29:30,113][train][INFO] - Epoch 1085/2000, Val Acc=0.6071, Val Loss=1.8034, lr=0.0100
[2025-05-07 02:29:32,615][train][INFO] - Epoch 1102/2000, Val Acc=0.6054, Val Loss=1.6323, lr=0.0100
[2025-05-07 02:29:35,778][train][INFO] - Epoch 1109/2000, Val Acc=0.6169, Val Loss=1.7259, lr=0.0100
[2025-05-07 02:29:38,052][train][INFO] - Epoch 1086/2000, Val Acc=0.6113, Val Loss=1.7800, lr=0.0100
[2025-05-07 02:29:39,996][train][INFO] - Epoch 1103/2000, Val Acc=0.5855, Val Loss=1.7249, lr=0.0100
[2025-05-07 02:29:43,184][train][INFO] - Epoch 1110/2000, Val Acc=0.6208, Val Loss=1.7214, lr=0.0100
[2025-05-07 02:29:45,523][train][INFO] - Epoch 1087/2000, Val Acc=0.6128, Val Loss=1.7514, lr=0.0100
[2025-05-07 02:29:47,566][train][INFO] - Epoch 1104/2000, Val Acc=0.5792, Val Loss=1.7404, lr=0.0100
[2025-05-07 02:29:50,814][train][INFO] - Epoch 1111/2000, Val Acc=0.6209, Val Loss=1.6964, lr=0.0100
[2025-05-07 02:29:53,660][train][INFO] - Epoch 1088/2000, Val Acc=0.6047, Val Loss=1.7758, lr=0.0100
[2025-05-07 02:29:55,052][train][INFO] - Epoch 1105/2000, Val Acc=0.5769, Val Loss=1.8009, lr=0.0100
[2025-05-07 02:29:58,109][train][INFO] - Epoch 1112/2000, Val Acc=0.6121, Val Loss=1.7306, lr=0.0100
[2025-05-07 02:30:01,971][train][INFO] - Epoch 1089/2000, Val Acc=0.6084, Val Loss=1.7721, lr=0.0100
[2025-05-07 02:30:02,705][train][INFO] - Epoch 1106/2000, Val Acc=0.5877, Val Loss=1.7156, lr=0.0100
[2025-05-07 02:30:05,941][train][INFO] - Epoch 1113/2000, Val Acc=0.6033, Val Loss=1.8061, lr=0.0100
[2025-05-07 02:30:09,758][train][INFO] - Epoch 1090/2000, Val Acc=0.6094, Val Loss=1.7436, lr=0.0100
[2025-05-07 02:30:10,778][train][INFO] - Epoch 1107/2000, Val Acc=0.6085, Val Loss=1.6307, lr=0.0100
[2025-05-07 02:30:13,178][train][INFO] - Epoch 1114/2000, Val Acc=0.6167, Val Loss=1.7139, lr=0.0100
[2025-05-07 02:30:17,668][train][INFO] - Epoch 1091/2000, Val Acc=0.6144, Val Loss=1.7292, lr=0.0100
[2025-05-07 02:30:18,594][train][INFO] - Epoch 1108/2000, Val Acc=0.5860, Val Loss=1.7465, lr=0.0100
[2025-05-07 02:30:20,514][train][INFO] - Epoch 1115/2000, Val Acc=0.6198, Val Loss=1.7187, lr=0.0100
[2025-05-07 02:30:25,517][train][INFO] - Epoch 1092/2000, Val Acc=0.6139, Val Loss=1.7147, lr=0.0100
[2025-05-07 02:30:26,741][train][INFO] - Epoch 1109/2000, Val Acc=0.6104, Val Loss=1.5755, lr=0.0100
[2025-05-07 02:30:28,048][train][INFO] - Epoch 1116/2000, Val Acc=0.6222, Val Loss=1.6826, lr=0.0100
[2025-05-07 02:30:33,143][train][INFO] - Epoch 1093/2000, Val Acc=0.6256, Val Loss=1.6888, lr=0.0100
[2025-05-07 02:30:34,588][train][INFO] - Epoch 1110/2000, Val Acc=0.5874, Val Loss=1.6909, lr=0.0100
[2025-05-07 02:30:35,380][train][INFO] - Epoch 1117/2000, Val Acc=0.6104, Val Loss=1.7928, lr=0.0100
[2025-05-07 02:30:41,074][train][INFO] - Epoch 1094/2000, Val Acc=0.6230, Val Loss=1.7248, lr=0.0100
[2025-05-07 02:30:42,401][train][INFO] - Epoch 1111/2000, Val Acc=0.5924, Val Loss=1.6736, lr=0.0100
[2025-05-07 02:30:43,251][train][INFO] - Epoch 1118/2000, Val Acc=0.6190, Val Loss=1.7325, lr=0.0100
[2025-05-07 02:30:49,171][train][INFO] - Epoch 1095/2000, Val Acc=0.6252, Val Loss=1.6866, lr=0.0100
[2025-05-07 02:30:50,196][train][INFO] - Epoch 1112/2000, Val Acc=0.5893, Val Loss=1.7399, lr=0.0100
[2025-05-07 02:30:50,419][train][INFO] - Epoch 1119/2000, Val Acc=0.5963, Val Loss=1.8657, lr=0.0100
[2025-05-07 02:30:57,305][train][INFO] - Epoch 1096/2000, Val Acc=0.6183, Val Loss=1.6815, lr=0.0100
[2025-05-07 02:30:57,441][train][INFO] - Epoch 1113/2000, Val Acc=0.5633, Val Loss=1.8877, lr=0.0100
[2025-05-07 02:30:58,077][train][INFO] - Epoch 1120/2000, Val Acc=0.6159, Val Loss=1.7077, lr=0.0100
[2025-05-07 02:31:05,015][train][INFO] - Epoch 1097/2000, Val Acc=0.6220, Val Loss=1.6793, lr=0.0100
[2025-05-07 02:31:05,128][train][INFO] - Epoch 1114/2000, Val Acc=0.5963, Val Loss=1.7126, lr=0.0100
[2025-05-07 02:31:05,926][train][INFO] - Epoch 1121/2000, Val Acc=0.6177, Val Loss=1.7362, lr=0.0100
[2025-05-07 02:31:13,026][train][INFO] - Epoch 1098/2000, Val Acc=0.6364, Val Loss=1.6221, lr=0.0100
[2025-05-07 02:31:13,145][train][INFO] - Epoch 1115/2000, Val Acc=0.5864, Val Loss=1.7244, lr=0.0100
[2025-05-07 02:31:13,614][train][INFO] - Epoch 1122/2000, Val Acc=0.6213, Val Loss=1.7080, lr=0.0100
[2025-05-07 02:31:21,164][train][INFO] - Epoch 1099/2000, Val Acc=0.6136, Val Loss=1.7148, lr=0.0100
[2025-05-07 02:31:21,501][train][INFO] - Epoch 1116/2000, Val Acc=0.5816, Val Loss=1.7290, lr=0.0100
[2025-05-07 02:31:21,654][train][INFO] - Epoch 1123/2000, Val Acc=0.6206, Val Loss=1.6933, lr=0.0100
[2025-05-07 02:31:28,915][train][INFO] - Epoch 1124/2000, Val Acc=0.6217, Val Loss=1.7101, lr=0.0100
[2025-05-07 02:31:29,040][train][INFO] - Epoch 1100/2000, Val Acc=0.6182, Val Loss=1.7325, lr=0.0100
[2025-05-07 02:31:29,329][train][INFO] - Epoch 1117/2000, Val Acc=0.5820, Val Loss=1.7750, lr=0.0100
[2025-05-07 02:31:36,838][train][INFO] - Epoch 1125/2000, Val Acc=0.6094, Val Loss=1.7578, lr=0.0100
[2025-05-07 02:31:37,141][train][INFO] - Epoch 1118/2000, Val Acc=0.5771, Val Loss=1.7555, lr=0.0100
[2025-05-07 02:31:37,267][train][INFO] - Epoch 1101/2000, Val Acc=0.6173, Val Loss=1.6823, lr=0.0100
[2025-05-07 02:31:44,580][train][INFO] - Epoch 1119/2000, Val Acc=0.5953, Val Loss=1.6814, lr=0.0100
[2025-05-07 02:31:44,885][train][INFO] - Epoch 1126/2000, Val Acc=0.6091, Val Loss=1.8154, lr=0.0100
[2025-05-07 02:31:45,701][train][INFO] - Epoch 1102/2000, Val Acc=0.6314, Val Loss=1.6339, lr=0.0100
[2025-05-07 02:31:52,617][train][INFO] - Epoch 1127/2000, Val Acc=0.6129, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:31:52,705][train][INFO] - Epoch 1120/2000, Val Acc=0.5933, Val Loss=1.6704, lr=0.0100
[2025-05-07 02:31:53,841][train][INFO] - Epoch 1103/2000, Val Acc=0.6260, Val Loss=1.6706, lr=0.0100
[2025-05-07 02:32:00,096][train][INFO] - Epoch 1128/2000, Val Acc=0.6137, Val Loss=1.7575, lr=0.0100
[2025-05-07 02:32:00,626][train][INFO] - Epoch 1121/2000, Val Acc=0.5834, Val Loss=1.7262, lr=0.0100
[2025-05-07 02:32:01,822][train][INFO] - Epoch 1104/2000, Val Acc=0.6010, Val Loss=1.7985, lr=0.0100
[2025-05-07 02:32:07,167][train][INFO] - Epoch 1129/2000, Val Acc=0.6156, Val Loss=1.7580, lr=0.0100
[2025-05-07 02:32:08,441][train][INFO] - Epoch 1122/2000, Val Acc=0.5865, Val Loss=1.7730, lr=0.0100
[2025-05-07 02:32:10,167][train][INFO] - Epoch 1105/2000, Val Acc=0.6085, Val Loss=1.7745, lr=0.0100
[2025-05-07 02:32:15,044][train][INFO] - Epoch 1130/2000, Val Acc=0.6166, Val Loss=1.7040, lr=0.0100
[2025-05-07 02:32:16,117][train][INFO] - Epoch 1123/2000, Val Acc=0.6035, Val Loss=1.6233, lr=0.0100
[2025-05-07 02:32:18,348][train][INFO] - Epoch 1106/2000, Val Acc=0.6202, Val Loss=1.7338, lr=0.0100
[2025-05-07 02:32:22,775][train][INFO] - Epoch 1131/2000, Val Acc=0.6064, Val Loss=1.7994, lr=0.0100
[2025-05-07 02:32:23,905][train][INFO] - Epoch 1124/2000, Val Acc=0.5972, Val Loss=1.6203, lr=0.0100
[2025-05-07 02:32:26,273][train][INFO] - Epoch 1107/2000, Val Acc=0.6111, Val Loss=1.7609, lr=0.0100
[2025-05-07 02:32:30,414][train][INFO] - Epoch 1132/2000, Val Acc=0.6267, Val Loss=1.6270, lr=0.0100
[2025-05-07 02:32:31,095][train][INFO] - Epoch 1125/2000, Val Acc=0.5978, Val Loss=1.6924, lr=0.0100
[2025-05-07 02:32:34,214][train][INFO] - Epoch 1108/2000, Val Acc=0.6179, Val Loss=1.6709, lr=0.0100
[2025-05-07 02:32:38,153][train][INFO] - Epoch 1133/2000, Val Acc=0.6189, Val Loss=1.7014, lr=0.0100
[2025-05-07 02:32:38,841][train][INFO] - Epoch 1126/2000, Val Acc=0.5905, Val Loss=1.6729, lr=0.0100
[2025-05-07 02:32:41,693][train][INFO] - Epoch 1109/2000, Val Acc=0.6169, Val Loss=1.7259, lr=0.0100
[2025-05-07 02:32:45,860][train][INFO] - Epoch 1134/2000, Val Acc=0.6191, Val Loss=1.6875, lr=0.0100
[2025-05-07 02:32:46,419][train][INFO] - Epoch 1127/2000, Val Acc=0.6072, Val Loss=1.6178, lr=0.0100
[2025-05-07 02:32:49,585][train][INFO] - Epoch 1110/2000, Val Acc=0.6208, Val Loss=1.7214, lr=0.0100
[2025-05-07 02:32:53,686][train][INFO] - Epoch 1135/2000, Val Acc=0.6186, Val Loss=1.7022, lr=0.0100
[2025-05-07 02:32:53,933][train][INFO] - Epoch 1128/2000, Val Acc=0.5808, Val Loss=1.7691, lr=0.0100
[2025-05-07 02:32:57,064][train][INFO] - Epoch 1111/2000, Val Acc=0.6209, Val Loss=1.6964, lr=0.0100
[2025-05-07 02:33:01,680][train][INFO] - Epoch 1136/2000, Val Acc=0.6122, Val Loss=1.7486, lr=0.0100
[2025-05-07 02:33:01,989][train][INFO] - Epoch 1129/2000, Val Acc=0.5952, Val Loss=1.6441, lr=0.0100
[2025-05-07 02:33:04,604][train][INFO] - Epoch 1112/2000, Val Acc=0.6121, Val Loss=1.7306, lr=0.0100
[2025-05-07 02:33:08,996][train][INFO] - Epoch 1137/2000, Val Acc=0.6171, Val Loss=1.7289, lr=0.0100
[2025-05-07 02:33:09,835][train][INFO] - Epoch 1130/2000, Val Acc=0.5861, Val Loss=1.7354, lr=0.0100
[2025-05-07 02:33:12,277][train][INFO] - Epoch 1113/2000, Val Acc=0.6033, Val Loss=1.8061, lr=0.0100
[2025-05-07 02:33:16,902][train][INFO] - Epoch 1138/2000, Val Acc=0.6047, Val Loss=1.7782, lr=0.0100
[2025-05-07 02:33:17,587][train][INFO] - Epoch 1131/2000, Val Acc=0.5904, Val Loss=1.6726, lr=0.0100
[2025-05-07 02:33:19,636][train][INFO] - Epoch 1114/2000, Val Acc=0.6167, Val Loss=1.7139, lr=0.0100
[2025-05-07 02:33:24,076][train][INFO] - Epoch 1139/2000, Val Acc=0.6150, Val Loss=1.7294, lr=0.0100
[2025-05-07 02:33:25,500][train][INFO] - Epoch 1132/2000, Val Acc=0.5936, Val Loss=1.6686, lr=0.0100
[2025-05-07 02:33:27,750][train][INFO] - Epoch 1115/2000, Val Acc=0.6198, Val Loss=1.7187, lr=0.0100
[2025-05-07 02:33:31,338][train][INFO] - Epoch 1140/2000, Val Acc=0.5898, Val Loss=1.8794, lr=0.0100
[2025-05-07 02:33:33,107][train][INFO] - Epoch 1133/2000, Val Acc=0.5978, Val Loss=1.6799, lr=0.0100
[2025-05-07 02:33:35,471][train][INFO] - Epoch 1116/2000, Val Acc=0.6222, Val Loss=1.6826, lr=0.0100
[2025-05-07 02:33:39,135][train][INFO] - Epoch 1141/2000, Val Acc=0.6356, Val Loss=1.6590, lr=0.0100
[2025-05-07 02:33:41,000][train][INFO] - Epoch 1134/2000, Val Acc=0.5827, Val Loss=1.7594, lr=0.0100
[2025-05-07 02:33:43,385][train][INFO] - Epoch 1117/2000, Val Acc=0.6104, Val Loss=1.7928, lr=0.0100
[2025-05-07 02:33:46,714][train][INFO] - Epoch 1142/2000, Val Acc=0.6323, Val Loss=1.6414, lr=0.0100
[2025-05-07 02:33:48,839][train][INFO] - Epoch 1135/2000, Val Acc=0.5855, Val Loss=1.7365, lr=0.0100
[2025-05-07 02:33:50,730][train][INFO] - Epoch 1118/2000, Val Acc=0.6190, Val Loss=1.7325, lr=0.0100
[2025-05-07 02:33:54,649][train][INFO] - Epoch 1143/2000, Val Acc=0.6236, Val Loss=1.6851, lr=0.0100
[2025-05-07 02:33:56,690][train][INFO] - Epoch 1136/2000, Val Acc=0.5975, Val Loss=1.6679, lr=0.0100
[2025-05-07 02:33:58,934][train][INFO] - Epoch 1119/2000, Val Acc=0.5963, Val Loss=1.8657, lr=0.0100
[2025-05-07 02:34:02,223][train][INFO] - Epoch 1144/2000, Val Acc=0.6230, Val Loss=1.6883, lr=0.0100
[2025-05-07 02:34:04,710][train][INFO] - Epoch 1137/2000, Val Acc=0.5837, Val Loss=1.6989, lr=0.0100
[2025-05-07 02:34:06,658][train][INFO] - Epoch 1120/2000, Val Acc=0.6159, Val Loss=1.7077, lr=0.0100
[2025-05-07 02:34:09,791][train][INFO] - Epoch 1145/2000, Val Acc=0.6174, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:34:12,298][train][INFO] - Epoch 1138/2000, Val Acc=0.5915, Val Loss=1.6682, lr=0.0100
[2025-05-07 02:34:13,888][train][INFO] - Epoch 1121/2000, Val Acc=0.6177, Val Loss=1.7362, lr=0.0100
[2025-05-07 02:34:17,079][train][INFO] - Epoch 1146/2000, Val Acc=0.6147, Val Loss=1.6972, lr=0.0100
[2025-05-07 02:34:19,924][train][INFO] - Epoch 1139/2000, Val Acc=0.5960, Val Loss=1.6334, lr=0.0100
[2025-05-07 02:34:22,054][train][INFO] - Epoch 1122/2000, Val Acc=0.6213, Val Loss=1.7080, lr=0.0100
[2025-05-07 02:34:24,478][train][INFO] - Epoch 1147/2000, Val Acc=0.6155, Val Loss=1.7653, lr=0.0100
[2025-05-07 02:34:27,765][train][INFO] - Epoch 1140/2000, Val Acc=0.5692, Val Loss=1.8461, lr=0.0100
[2025-05-07 02:34:30,230][train][INFO] - Epoch 1123/2000, Val Acc=0.6206, Val Loss=1.6933, lr=0.0100
[2025-05-07 02:34:32,066][train][INFO] - Epoch 1148/2000, Val Acc=0.5986, Val Loss=1.8435, lr=0.0100
[2025-05-07 02:34:35,328][train][INFO] - Epoch 1141/2000, Val Acc=0.5854, Val Loss=1.7092, lr=0.0100
[2025-05-07 02:34:38,243][train][INFO] - Epoch 1124/2000, Val Acc=0.6217, Val Loss=1.7101, lr=0.0100
[2025-05-07 02:34:39,838][train][INFO] - Epoch 1149/2000, Val Acc=0.6232, Val Loss=1.6865, lr=0.0100
[2025-05-07 02:34:42,823][train][INFO] - Epoch 1142/2000, Val Acc=0.5796, Val Loss=1.7635, lr=0.0100
[2025-05-07 02:34:45,269][train][INFO] - Epoch 1125/2000, Val Acc=0.6094, Val Loss=1.7578, lr=0.0100
[2025-05-07 02:34:47,221][train][INFO] - Epoch 1150/2000, Val Acc=0.5935, Val Loss=1.8104, lr=0.0100
[2025-05-07 02:34:50,468][train][INFO] - Epoch 1143/2000, Val Acc=0.5943, Val Loss=1.6628, lr=0.0100
[2025-05-07 02:34:53,171][train][INFO] - Epoch 1126/2000, Val Acc=0.6091, Val Loss=1.8154, lr=0.0100
[2025-05-07 02:34:54,934][train][INFO] - Epoch 1151/2000, Val Acc=0.6132, Val Loss=1.7233, lr=0.0100
[2025-05-07 02:34:58,156][train][INFO] - Epoch 1144/2000, Val Acc=0.5771, Val Loss=1.7615, lr=0.0100
[2025-05-07 02:35:01,055][train][INFO] - Epoch 1127/2000, Val Acc=0.6129, Val Loss=1.7379, lr=0.0100
[2025-05-07 02:35:02,456][train][INFO] - Epoch 1152/2000, Val Acc=0.6098, Val Loss=1.7271, lr=0.0100
[2025-05-07 02:35:05,718][train][INFO] - Epoch 1145/2000, Val Acc=0.5781, Val Loss=1.7733, lr=0.0100
[2025-05-07 02:35:08,837][train][INFO] - Epoch 1128/2000, Val Acc=0.6137, Val Loss=1.7575, lr=0.0100
[2025-05-07 02:35:10,469][train][INFO] - Epoch 1153/2000, Val Acc=0.6143, Val Loss=1.7252, lr=0.0100
[2025-05-07 02:35:13,420][train][INFO] - Epoch 1146/2000, Val Acc=0.5955, Val Loss=1.6733, lr=0.0100
[2025-05-07 02:35:16,705][train][INFO] - Epoch 1129/2000, Val Acc=0.6156, Val Loss=1.7580, lr=0.0100
[2025-05-07 02:35:18,302][train][INFO] - Epoch 1154/2000, Val Acc=0.6083, Val Loss=1.7637, lr=0.0100
[2025-05-07 02:35:20,609][train][INFO] - Epoch 1147/2000, Val Acc=0.5499, Val Loss=1.9402, lr=0.0100
[2025-05-07 02:35:24,449][train][INFO] - Epoch 1130/2000, Val Acc=0.6166, Val Loss=1.7040, lr=0.0100
[2025-05-07 02:35:25,887][train][INFO] - Epoch 1155/2000, Val Acc=0.6235, Val Loss=1.6669, lr=0.0100
[2025-05-07 02:35:28,246][train][INFO] - Epoch 1148/2000, Val Acc=0.5877, Val Loss=1.6929, lr=0.0100
[2025-05-07 02:35:32,454][train][INFO] - Epoch 1131/2000, Val Acc=0.6064, Val Loss=1.7994, lr=0.0100
[2025-05-07 02:35:33,394][train][INFO] - Epoch 1156/2000, Val Acc=0.6112, Val Loss=1.7417, lr=0.0100
[2025-05-07 02:35:35,925][train][INFO] - Epoch 1149/2000, Val Acc=0.5790, Val Loss=1.7523, lr=0.0100
[2025-05-07 02:35:40,430][train][INFO] - Epoch 1132/2000, Val Acc=0.6267, Val Loss=1.6270, lr=0.0100
[2025-05-07 02:35:41,040][train][INFO] - Epoch 1157/2000, Val Acc=0.6034, Val Loss=1.8078, lr=0.0100
[2025-05-07 02:35:43,306][train][INFO] - Epoch 1150/2000, Val Acc=0.6011, Val Loss=1.6409, lr=0.0100
[2025-05-07 02:35:48,613][train][INFO] - Epoch 1133/2000, Val Acc=0.6189, Val Loss=1.7014, lr=0.0100
[2025-05-07 02:35:48,815][train][INFO] - Epoch 1158/2000, Val Acc=0.6102, Val Loss=1.7867, lr=0.0100
[2025-05-07 02:35:51,381][train][INFO] - Epoch 1151/2000, Val Acc=0.5986, Val Loss=1.6690, lr=0.0100
[2025-05-07 02:35:56,241][train][INFO] - Epoch 1134/2000, Val Acc=0.6191, Val Loss=1.6875, lr=0.0100
[2025-05-07 02:35:56,392][train][INFO] - Epoch 1159/2000, Val Acc=0.6086, Val Loss=1.7945, lr=0.0100
[2025-05-07 02:35:59,146][train][INFO] - Epoch 1152/2000, Val Acc=0.5863, Val Loss=1.7527, lr=0.0100
[2025-05-07 02:36:03,849][train][INFO] - Epoch 1135/2000, Val Acc=0.6186, Val Loss=1.7022, lr=0.0100
[2025-05-07 02:36:04,015][train][INFO] - Epoch 1160/2000, Val Acc=0.6201, Val Loss=1.7273, lr=0.0100
[2025-05-07 02:36:07,182][train][INFO] - Epoch 1153/2000, Val Acc=0.5929, Val Loss=1.7178, lr=0.0100
[2025-05-07 02:36:11,194][train][INFO] - Epoch 1161/2000, Val Acc=0.6231, Val Loss=1.6744, lr=0.0100
[2025-05-07 02:36:11,727][train][INFO] - Epoch 1136/2000, Val Acc=0.6122, Val Loss=1.7486, lr=0.0100
[2025-05-07 02:36:14,953][train][INFO] - Epoch 1154/2000, Val Acc=0.5823, Val Loss=1.7256, lr=0.0100
[2025-05-07 02:36:19,135][train][INFO] - Epoch 1162/2000, Val Acc=0.6107, Val Loss=1.7619, lr=0.0100
[2025-05-07 02:36:19,420][train][INFO] - Epoch 1137/2000, Val Acc=0.6171, Val Loss=1.7289, lr=0.0100
[2025-05-07 02:36:22,820][train][INFO] - Epoch 1155/2000, Val Acc=0.5726, Val Loss=1.7707, lr=0.0100
[2025-05-07 02:36:26,990][train][INFO] - Epoch 1163/2000, Val Acc=0.5880, Val Loss=1.8967, lr=0.0100
[2025-05-07 02:36:27,056][train][INFO] - Epoch 1138/2000, Val Acc=0.6047, Val Loss=1.7782, lr=0.0100
[2025-05-07 02:36:30,591][train][INFO] - Epoch 1156/2000, Val Acc=0.6060, Val Loss=1.5895, lr=0.0100
[2025-05-07 02:36:34,400][train][INFO] - Epoch 1139/2000, Val Acc=0.6150, Val Loss=1.7294, lr=0.0100
[2025-05-07 02:36:34,448][train][INFO] - Epoch 1164/2000, Val Acc=0.6187, Val Loss=1.6981, lr=0.0100
[2025-05-07 02:36:38,332][train][INFO] - Epoch 1157/2000, Val Acc=0.5842, Val Loss=1.7403, lr=0.0100
[2025-05-07 02:36:41,925][train][INFO] - Epoch 1165/2000, Val Acc=0.6031, Val Loss=1.8462, lr=0.0100
[2025-05-07 02:36:42,610][train][INFO] - Epoch 1140/2000, Val Acc=0.5898, Val Loss=1.8794, lr=0.0100
[2025-05-07 02:36:45,364][train][INFO] - Epoch 1158/2000, Val Acc=0.5963, Val Loss=1.6592, lr=0.0100
[2025-05-07 02:36:49,491][train][INFO] - Epoch 1166/2000, Val Acc=0.6226, Val Loss=1.6960, lr=0.0100
[2025-05-07 02:36:50,327][train][INFO] - Epoch 1141/2000, Val Acc=0.6356, Val Loss=1.6590, lr=0.0100
[2025-05-07 02:36:52,872][train][INFO] - Epoch 1159/2000, Val Acc=0.5909, Val Loss=1.7076, lr=0.0100
[2025-05-07 02:36:57,035][train][INFO] - Epoch 1167/2000, Val Acc=0.6055, Val Loss=1.8159, lr=0.0100
[2025-05-07 02:36:58,534][train][INFO] - Epoch 1142/2000, Val Acc=0.6323, Val Loss=1.6414, lr=0.0100
[2025-05-07 02:37:00,330][train][INFO] - Epoch 1160/2000, Val Acc=0.5879, Val Loss=1.7177, lr=0.0100
[2025-05-07 02:37:04,295][train][INFO] - Epoch 1168/2000, Val Acc=0.6275, Val Loss=1.6843, lr=0.0100
[2025-05-07 02:37:06,475][train][INFO] - Epoch 1143/2000, Val Acc=0.6236, Val Loss=1.6851, lr=0.0100
[2025-05-07 02:37:07,851][train][INFO] - Epoch 1161/2000, Val Acc=0.5809, Val Loss=1.7085, lr=0.0100
[2025-05-07 02:37:11,702][train][INFO] - Epoch 1169/2000, Val Acc=0.6161, Val Loss=1.7139, lr=0.0100
[2025-05-07 02:37:14,379][train][INFO] - Epoch 1144/2000, Val Acc=0.6230, Val Loss=1.6883, lr=0.0100
[2025-05-07 02:37:15,842][train][INFO] - Epoch 1162/2000, Val Acc=0.5733, Val Loss=1.8242, lr=0.0100
[2025-05-07 02:37:19,354][train][INFO] - Epoch 1170/2000, Val Acc=0.6254, Val Loss=1.6583, lr=0.0100
[2025-05-07 02:37:22,435][train][INFO] - Epoch 1145/2000, Val Acc=0.6174, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:37:23,627][train][INFO] - Epoch 1163/2000, Val Acc=0.5974, Val Loss=1.6692, lr=0.0100
[2025-05-07 02:37:27,234][train][INFO] - Epoch 1171/2000, Val Acc=0.6106, Val Loss=1.7567, lr=0.0100
[2025-05-07 02:37:30,393][train][INFO] - Epoch 1146/2000, Val Acc=0.6147, Val Loss=1.6972, lr=0.0100
[2025-05-07 02:37:31,114][train][INFO] - Epoch 1164/2000, Val Acc=0.5803, Val Loss=1.7476, lr=0.0100
[2025-05-07 02:37:34,829][train][INFO] - Epoch 1172/2000, Val Acc=0.6196, Val Loss=1.7103, lr=0.0100
[2025-05-07 02:37:38,161][train][INFO] - Epoch 1147/2000, Val Acc=0.6155, Val Loss=1.7653, lr=0.0100
[2025-05-07 02:37:38,984][train][INFO] - Epoch 1165/2000, Val Acc=0.5917, Val Loss=1.7213, lr=0.0100
[2025-05-07 02:37:41,997][train][INFO] - Epoch 1173/2000, Val Acc=0.6224, Val Loss=1.7120, lr=0.0100
[2025-05-07 02:37:46,193][train][INFO] - Epoch 1148/2000, Val Acc=0.5986, Val Loss=1.8435, lr=0.0100
[2025-05-07 02:37:46,429][train][INFO] - Epoch 1166/2000, Val Acc=0.5974, Val Loss=1.7022, lr=0.0100
[2025-05-07 02:37:49,750][train][INFO] - Epoch 1174/2000, Val Acc=0.6159, Val Loss=1.7467, lr=0.0100
[2025-05-07 02:37:53,701][train][INFO] - Epoch 1149/2000, Val Acc=0.6232, Val Loss=1.6865, lr=0.0100
[2025-05-07 02:37:54,163][train][INFO] - Epoch 1167/2000, Val Acc=0.5971, Val Loss=1.6775, lr=0.0100
[2025-05-07 02:37:57,480][train][INFO] - Epoch 1175/2000, Val Acc=0.6282, Val Loss=1.6291, lr=0.0100
[2025-05-07 02:38:01,294][train][INFO] - Epoch 1150/2000, Val Acc=0.5935, Val Loss=1.8104, lr=0.0100
[2025-05-07 02:38:01,978][train][INFO] - Epoch 1168/2000, Val Acc=0.5818, Val Loss=1.7328, lr=0.0100
[2025-05-07 02:38:05,413][train][INFO] - Epoch 1176/2000, Val Acc=0.6161, Val Loss=1.7256, lr=0.0100
[2025-05-07 02:38:09,030][train][INFO] - Epoch 1151/2000, Val Acc=0.6132, Val Loss=1.7233, lr=0.0100
[2025-05-07 02:38:09,717][train][INFO] - Epoch 1169/2000, Val Acc=0.6025, Val Loss=1.6309, lr=0.0100
[2025-05-07 02:38:13,266][train][INFO] - Epoch 1177/2000, Val Acc=0.6023, Val Loss=1.8277, lr=0.0100
[2025-05-07 02:38:16,671][train][INFO] - Epoch 1152/2000, Val Acc=0.6098, Val Loss=1.7271, lr=0.0100
[2025-05-07 02:38:17,178][train][INFO] - Epoch 1170/2000, Val Acc=0.6009, Val Loss=1.6410, lr=0.0100
[2025-05-07 02:38:20,589][train][INFO] - Epoch 1178/2000, Val Acc=0.6260, Val Loss=1.6649, lr=0.0100
[2025-05-07 02:38:24,366][train][INFO] - Epoch 1171/2000, Val Acc=0.5878, Val Loss=1.6893, lr=0.0100
[2025-05-07 02:38:24,968][train][INFO] - Epoch 1153/2000, Val Acc=0.6143, Val Loss=1.7252, lr=0.0100
[2025-05-07 02:38:28,243][train][INFO] - Epoch 1179/2000, Val Acc=0.6222, Val Loss=1.7290, lr=0.0100
[2025-05-07 02:38:31,885][train][INFO] - Epoch 1172/2000, Val Acc=0.5775, Val Loss=1.8011, lr=0.0100
[2025-05-07 02:38:33,129][train][INFO] - Epoch 1154/2000, Val Acc=0.6083, Val Loss=1.7637, lr=0.0100
[2025-05-07 02:38:36,230][train][INFO] - Epoch 1180/2000, Val Acc=0.6128, Val Loss=1.7650, lr=0.0100
[2025-05-07 02:38:39,702][train][INFO] - Epoch 1173/2000, Val Acc=0.5948, Val Loss=1.6881, lr=0.0100
[2025-05-07 02:38:40,836][train][INFO] - Epoch 1155/2000, Val Acc=0.6235, Val Loss=1.6669, lr=0.0100
[2025-05-07 02:38:43,637][train][INFO] - Epoch 1181/2000, Val Acc=0.6235, Val Loss=1.7068, lr=0.0100
[2025-05-07 02:38:47,476][train][INFO] - Epoch 1174/2000, Val Acc=0.5980, Val Loss=1.6626, lr=0.0100
[2025-05-07 02:38:48,872][train][INFO] - Epoch 1156/2000, Val Acc=0.6112, Val Loss=1.7417, lr=0.0100
[2025-05-07 02:38:51,060][train][INFO] - Epoch 1182/2000, Val Acc=0.6040, Val Loss=1.8118, lr=0.0100
[2025-05-07 02:38:54,536][train][INFO] - Epoch 1175/2000, Val Acc=0.5983, Val Loss=1.6544, lr=0.0100
[2025-05-07 02:38:57,169][train][INFO] - Epoch 1157/2000, Val Acc=0.6034, Val Loss=1.8078, lr=0.0100
[2025-05-07 02:38:58,797][train][INFO] - Epoch 1183/2000, Val Acc=0.6265, Val Loss=1.6637, lr=0.0100
[2025-05-07 02:39:02,204][train][INFO] - Epoch 1176/2000, Val Acc=0.5966, Val Loss=1.6820, lr=0.0100
[2025-05-07 02:39:05,143][train][INFO] - Epoch 1158/2000, Val Acc=0.6102, Val Loss=1.7867, lr=0.0100
[2025-05-07 02:39:06,314][train][INFO] - Epoch 1184/2000, Val Acc=0.6094, Val Loss=1.7705, lr=0.0100
[2025-05-07 02:39:09,898][train][INFO] - Epoch 1177/2000, Val Acc=0.6017, Val Loss=1.6404, lr=0.0100
[2025-05-07 02:39:12,666][train][INFO] - Epoch 1159/2000, Val Acc=0.6086, Val Loss=1.7945, lr=0.0100
[2025-05-07 02:39:14,074][train][INFO] - Epoch 1185/2000, Val Acc=0.6183, Val Loss=1.7270, lr=0.0100
[2025-05-07 02:39:17,678][train][INFO] - Epoch 1178/2000, Val Acc=0.5866, Val Loss=1.6846, lr=0.0100
[2025-05-07 02:39:20,623][train][INFO] - Epoch 1160/2000, Val Acc=0.6201, Val Loss=1.7273, lr=0.0100
[2025-05-07 02:39:21,481][train][INFO] - Epoch 1186/2000, Val Acc=0.6037, Val Loss=1.7959, lr=0.0100
[2025-05-07 02:39:24,557][train][INFO] - Epoch 1179/2000, Val Acc=0.5944, Val Loss=1.7131, lr=0.0100
[2025-05-07 02:39:27,857][train][INFO] - Epoch 1161/2000, Val Acc=0.6231, Val Loss=1.6744, lr=0.0100
[2025-05-07 02:39:28,731][train][INFO] - Epoch 1187/2000, Val Acc=0.6127, Val Loss=1.7409, lr=0.0100
[2025-05-07 02:39:32,021][train][INFO] - Epoch 1180/2000, Val Acc=0.5909, Val Loss=1.6899, lr=0.0100
[2025-05-07 02:39:35,695][train][INFO] - Epoch 1162/2000, Val Acc=0.6107, Val Loss=1.7619, lr=0.0100
[2025-05-07 02:39:36,779][train][INFO] - Epoch 1188/2000, Val Acc=0.6192, Val Loss=1.7016, lr=0.0100
[2025-05-07 02:39:39,043][train][INFO] - Epoch 1181/2000, Val Acc=0.6035, Val Loss=1.6507, lr=0.0100
[2025-05-07 02:39:43,710][train][INFO] - Epoch 1163/2000, Val Acc=0.5880, Val Loss=1.8967, lr=0.0100
[2025-05-07 02:39:44,555][train][INFO] - Epoch 1189/2000, Val Acc=0.6162, Val Loss=1.7308, lr=0.0100
[2025-05-07 02:39:46,207][train][INFO] - Epoch 1182/2000, Val Acc=0.5958, Val Loss=1.6928, lr=0.0100
[2025-05-07 02:39:51,468][train][INFO] - Epoch 1164/2000, Val Acc=0.6187, Val Loss=1.6981, lr=0.0100
[2025-05-07 02:39:52,517][train][INFO] - Epoch 1190/2000, Val Acc=0.6238, Val Loss=1.6662, lr=0.0100
[2025-05-07 02:39:53,434][train][INFO] - Epoch 1183/2000, Val Acc=0.5884, Val Loss=1.6856, lr=0.0100
[2025-05-07 02:39:59,581][train][INFO] - Epoch 1165/2000, Val Acc=0.6031, Val Loss=1.8462, lr=0.0100
[2025-05-07 02:40:00,220][train][INFO] - Epoch 1191/2000, Val Acc=0.6113, Val Loss=1.7272, lr=0.0100
[2025-05-07 02:40:01,011][train][INFO] - Epoch 1184/2000, Val Acc=0.5933, Val Loss=1.6493, lr=0.0100
[2025-05-07 02:40:07,384][train][INFO] - Epoch 1192/2000, Val Acc=0.6160, Val Loss=1.7129, lr=0.0100
[2025-05-07 02:40:07,400][train][INFO] - Epoch 1166/2000, Val Acc=0.6226, Val Loss=1.6960, lr=0.0100
[2025-05-07 02:40:08,595][train][INFO] - Epoch 1185/2000, Val Acc=0.5747, Val Loss=1.7790, lr=0.0100
[2025-05-07 02:40:14,567][train][INFO] - Epoch 1193/2000, Val Acc=0.6132, Val Loss=1.7561, lr=0.0100
[2025-05-07 02:40:14,842][train][INFO] - Epoch 1167/2000, Val Acc=0.6055, Val Loss=1.8159, lr=0.0100
[2025-05-07 02:40:16,513][train][INFO] - Epoch 1186/2000, Val Acc=0.6009, Val Loss=1.6694, lr=0.0100
[2025-05-07 02:40:21,625][train][INFO] - Epoch 1194/2000, Val Acc=0.6146, Val Loss=1.7051, lr=0.0100
[2025-05-07 02:40:22,476][train][INFO] - Epoch 1168/2000, Val Acc=0.6275, Val Loss=1.6843, lr=0.0100
[2025-05-07 02:40:24,369][train][INFO] - Epoch 1187/2000, Val Acc=0.6002, Val Loss=1.6759, lr=0.0100
[2025-05-07 02:40:29,583][train][INFO] - Epoch 1195/2000, Val Acc=0.6117, Val Loss=1.7223, lr=0.0100
[2025-05-07 02:40:30,410][train][INFO] - Epoch 1169/2000, Val Acc=0.6161, Val Loss=1.7139, lr=0.0100
[2025-05-07 02:40:31,941][train][INFO] - Epoch 1188/2000, Val Acc=0.5666, Val Loss=1.8409, lr=0.0100
[2025-05-07 02:40:36,679][train][INFO] - Epoch 1196/2000, Val Acc=0.6138, Val Loss=1.7235, lr=0.0100
[2025-05-07 02:40:37,899][train][INFO] - Epoch 1170/2000, Val Acc=0.6254, Val Loss=1.6583, lr=0.0100
[2025-05-07 02:40:39,846][train][INFO] - Epoch 1189/2000, Val Acc=0.5783, Val Loss=1.8097, lr=0.0100
[2025-05-07 02:40:44,030][train][INFO] - Epoch 1197/2000, Val Acc=0.6021, Val Loss=1.7952, lr=0.0100
[2025-05-07 02:40:45,840][train][INFO] - Epoch 1171/2000, Val Acc=0.6106, Val Loss=1.7567, lr=0.0100
[2025-05-07 02:40:47,973][train][INFO] - Epoch 1190/2000, Val Acc=0.5979, Val Loss=1.6461, lr=0.0100
[2025-05-07 02:40:51,780][train][INFO] - Epoch 1198/2000, Val Acc=0.5995, Val Loss=1.7984, lr=0.0100
[2025-05-07 02:40:53,651][train][INFO] - Epoch 1172/2000, Val Acc=0.6196, Val Loss=1.7103, lr=0.0100
[2025-05-07 02:40:55,568][train][INFO] - Epoch 1191/2000, Val Acc=0.5906, Val Loss=1.7110, lr=0.0100
[2025-05-07 02:40:59,115][train][INFO] - Epoch 1199/2000, Val Acc=0.6259, Val Loss=1.6746, lr=0.0100
[2025-05-07 02:41:01,429][train][INFO] - Epoch 1173/2000, Val Acc=0.6224, Val Loss=1.7120, lr=0.0100
[2025-05-07 02:41:03,186][train][INFO] - Epoch 1192/2000, Val Acc=0.5959, Val Loss=1.6520, lr=0.0100
[2025-05-07 02:41:06,633][train][INFO] - Epoch 1200/2000, Val Acc=0.5935, Val Loss=1.9021, lr=0.0100
[2025-05-07 02:41:09,117][train][INFO] - Epoch 1174/2000, Val Acc=0.6159, Val Loss=1.7467, lr=0.0100
[2025-05-07 02:41:10,390][train][INFO] - Epoch 1193/2000, Val Acc=0.6074, Val Loss=1.6299, lr=0.0100
[2025-05-07 02:41:14,050][train][INFO] - Epoch 1201/2000, Val Acc=0.6193, Val Loss=1.7400, lr=0.0100
[2025-05-07 02:41:16,974][train][INFO] - Epoch 1175/2000, Val Acc=0.6282, Val Loss=1.6291, lr=0.0100
[2025-05-07 02:41:18,427][train][INFO] - Epoch 1194/2000, Val Acc=0.5799, Val Loss=1.7582, lr=0.0100
[2025-05-07 02:41:21,327][train][INFO] - Epoch 1202/2000, Val Acc=0.6123, Val Loss=1.7580, lr=0.0100
[2025-05-07 02:41:24,929][train][INFO] - Epoch 1176/2000, Val Acc=0.6161, Val Loss=1.7256, lr=0.0100
[2025-05-07 02:41:26,216][train][INFO] - Epoch 1195/2000, Val Acc=0.5651, Val Loss=1.8254, lr=0.0100
[2025-05-07 02:41:28,582][train][INFO] - Epoch 1203/2000, Val Acc=0.6234, Val Loss=1.6698, lr=0.0100
[2025-05-07 02:41:32,802][train][INFO] - Epoch 1177/2000, Val Acc=0.6023, Val Loss=1.8277, lr=0.0100
[2025-05-07 02:41:33,795][train][INFO] - Epoch 1196/2000, Val Acc=0.5866, Val Loss=1.7135, lr=0.0100
[2025-05-07 02:41:36,521][train][INFO] - Epoch 1204/2000, Val Acc=0.6145, Val Loss=1.7130, lr=0.0100
[2025-05-07 02:41:40,728][train][INFO] - Epoch 1178/2000, Val Acc=0.6260, Val Loss=1.6649, lr=0.0100
[2025-05-07 02:41:41,385][train][INFO] - Epoch 1197/2000, Val Acc=0.5898, Val Loss=1.7226, lr=0.0100
[2025-05-07 02:41:44,184][train][INFO] - Epoch 1205/2000, Val Acc=0.6138, Val Loss=1.7133, lr=0.0100
[2025-05-07 02:41:48,543][train][INFO] - Epoch 1179/2000, Val Acc=0.6222, Val Loss=1.7290, lr=0.0100
[2025-05-07 02:41:49,215][train][INFO] - Epoch 1198/2000, Val Acc=0.5961, Val Loss=1.6795, lr=0.0100
[2025-05-07 02:41:51,931][train][INFO] - Epoch 1206/2000, Val Acc=0.6144, Val Loss=1.7321, lr=0.0100
[2025-05-07 02:41:56,152][train][INFO] - Epoch 1180/2000, Val Acc=0.6128, Val Loss=1.7650, lr=0.0100
[2025-05-07 02:41:56,969][train][INFO] - Epoch 1199/2000, Val Acc=0.5863, Val Loss=1.7571, lr=0.0100
[2025-05-07 02:41:59,142][train][INFO] - Epoch 1207/2000, Val Acc=0.6102, Val Loss=1.7436, lr=0.0100
[2025-05-07 02:42:03,850][train][INFO] - Epoch 1181/2000, Val Acc=0.6235, Val Loss=1.7068, lr=0.0100
[2025-05-07 02:42:04,412][train][INFO] - Epoch 1200/2000, Val Acc=0.5958, Val Loss=1.7238, lr=0.0100
[2025-05-07 02:42:06,882][train][INFO] - Epoch 1208/2000, Val Acc=0.6060, Val Loss=1.7961, lr=0.0100
[2025-05-07 02:42:11,884][train][INFO] - Epoch 1182/2000, Val Acc=0.6040, Val Loss=1.8118, lr=0.0100
[2025-05-07 02:42:12,088][train][INFO] - Epoch 1201/2000, Val Acc=0.6010, Val Loss=1.6589, lr=0.0100
[2025-05-07 02:42:14,631][train][INFO] - Epoch 1209/2000, Val Acc=0.6221, Val Loss=1.6922, lr=0.0100
[2025-05-07 02:42:19,688][train][INFO] - Epoch 1202/2000, Val Acc=0.5796, Val Loss=1.7899, lr=0.0100
[2025-05-07 02:42:19,824][train][INFO] - Epoch 1183/2000, Val Acc=0.6265, Val Loss=1.6637, lr=0.0100
[2025-05-07 02:42:22,088][train][INFO] - Epoch 1210/2000, Val Acc=0.6244, Val Loss=1.6574, lr=0.0100
[2025-05-07 02:42:26,804][train][INFO] - Epoch 1203/2000, Val Acc=0.5695, Val Loss=1.8225, lr=0.0100
[2025-05-07 02:42:27,623][train][INFO] - Epoch 1184/2000, Val Acc=0.6094, Val Loss=1.7705, lr=0.0100
[2025-05-07 02:42:29,922][train][INFO] - Epoch 1211/2000, Val Acc=0.6266, Val Loss=1.6986, lr=0.0100
[2025-05-07 02:42:34,544][train][INFO] - Epoch 1204/2000, Val Acc=0.5932, Val Loss=1.6767, lr=0.0100
[2025-05-07 02:42:34,852][train][INFO] - Epoch 1185/2000, Val Acc=0.6183, Val Loss=1.7270, lr=0.0100
[2025-05-07 02:42:37,353][train][INFO] - Epoch 1212/2000, Val Acc=0.6197, Val Loss=1.6988, lr=0.0100
[2025-05-07 02:42:42,078][train][INFO] - Epoch 1205/2000, Val Acc=0.5728, Val Loss=1.7740, lr=0.0100
[2025-05-07 02:42:42,443][train][INFO] - Epoch 1186/2000, Val Acc=0.6037, Val Loss=1.7959, lr=0.0100
[2025-05-07 02:42:44,791][train][INFO] - Epoch 1213/2000, Val Acc=0.6039, Val Loss=1.8047, lr=0.0100
[2025-05-07 02:42:50,085][train][INFO] - Epoch 1206/2000, Val Acc=0.5948, Val Loss=1.6682, lr=0.0100
[2025-05-07 02:42:50,485][train][INFO] - Epoch 1187/2000, Val Acc=0.6127, Val Loss=1.7409, lr=0.0100
[2025-05-07 02:42:52,272][train][INFO] - Epoch 1214/2000, Val Acc=0.6303, Val Loss=1.6310, lr=0.0100
[2025-05-07 02:42:57,635][train][INFO] - Epoch 1207/2000, Val Acc=0.5951, Val Loss=1.6785, lr=0.0100
[2025-05-07 02:42:58,450][train][INFO] - Epoch 1188/2000, Val Acc=0.6192, Val Loss=1.7016, lr=0.0100
[2025-05-07 02:42:59,872][train][INFO] - Epoch 1215/2000, Val Acc=0.6128, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:43:05,451][train][INFO] - Epoch 1208/2000, Val Acc=0.5969, Val Loss=1.6770, lr=0.0100
[2025-05-07 02:43:06,707][train][INFO] - Epoch 1189/2000, Val Acc=0.6162, Val Loss=1.7308, lr=0.0100
[2025-05-07 02:43:07,453][train][INFO] - Epoch 1216/2000, Val Acc=0.6022, Val Loss=1.8032, lr=0.0100
[2025-05-07 02:43:13,011][train][INFO] - Epoch 1209/2000, Val Acc=0.5946, Val Loss=1.6864, lr=0.0100
[2025-05-07 02:43:14,204][train][INFO] - Epoch 1190/2000, Val Acc=0.6238, Val Loss=1.6662, lr=0.0100
[2025-05-07 02:43:15,221][train][INFO] - Epoch 1217/2000, Val Acc=0.6149, Val Loss=1.7301, lr=0.0100
[2025-05-07 02:43:20,359][train][INFO] - Epoch 1210/2000, Val Acc=0.5827, Val Loss=1.7068, lr=0.0100
[2025-05-07 02:43:21,887][train][INFO] - Epoch 1191/2000, Val Acc=0.6113, Val Loss=1.7272, lr=0.0100
[2025-05-07 02:43:23,070][train][INFO] - Epoch 1218/2000, Val Acc=0.6250, Val Loss=1.6683, lr=0.0100
[2025-05-07 02:43:28,316][train][INFO] - Epoch 1211/2000, Val Acc=0.5615, Val Loss=1.8724, lr=0.0100
[2025-05-07 02:43:30,073][train][INFO] - Epoch 1192/2000, Val Acc=0.6160, Val Loss=1.7129, lr=0.0100
[2025-05-07 02:43:30,649][train][INFO] - Epoch 1219/2000, Val Acc=0.5945, Val Loss=1.8337, lr=0.0100
[2025-05-07 02:43:36,442][train][INFO] - Epoch 1212/2000, Val Acc=0.5965, Val Loss=1.7289, lr=0.0100
[2025-05-07 02:43:38,254][train][INFO] - Epoch 1193/2000, Val Acc=0.6132, Val Loss=1.7561, lr=0.0100
[2025-05-07 02:43:38,315][train][INFO] - Epoch 1220/2000, Val Acc=0.6202, Val Loss=1.7071, lr=0.0100
[2025-05-07 02:43:43,676][train][INFO] - Epoch 1213/2000, Val Acc=0.5941, Val Loss=1.6800, lr=0.0100
[2025-05-07 02:43:45,983][train][INFO] - Epoch 1221/2000, Val Acc=0.6219, Val Loss=1.6864, lr=0.0100
[2025-05-07 02:43:46,310][train][INFO] - Epoch 1194/2000, Val Acc=0.6146, Val Loss=1.7051, lr=0.0100
[2025-05-07 02:43:51,301][train][INFO] - Epoch 1214/2000, Val Acc=0.5950, Val Loss=1.6901, lr=0.0100
[2025-05-07 02:43:53,381][train][INFO] - Epoch 1222/2000, Val Acc=0.6045, Val Loss=1.7858, lr=0.0100
[2025-05-07 02:43:54,343][train][INFO] - Epoch 1195/2000, Val Acc=0.6117, Val Loss=1.7223, lr=0.0100
[2025-05-07 02:43:59,158][train][INFO] - Epoch 1215/2000, Val Acc=0.5815, Val Loss=1.7688, lr=0.0100
[2025-05-07 02:44:00,626][train][INFO] - Epoch 1223/2000, Val Acc=0.6133, Val Loss=1.7589, lr=0.0100
[2025-05-07 02:44:02,224][train][INFO] - Epoch 1196/2000, Val Acc=0.6138, Val Loss=1.7235, lr=0.0100
[2025-05-07 02:44:06,923][train][INFO] - Epoch 1216/2000, Val Acc=0.5770, Val Loss=1.8079, lr=0.0100
[2025-05-07 02:44:08,411][train][INFO] - Epoch 1224/2000, Val Acc=0.6176, Val Loss=1.7215, lr=0.0100
[2025-05-07 02:44:09,973][train][INFO] - Epoch 1197/2000, Val Acc=0.6021, Val Loss=1.7952, lr=0.0100
[2025-05-07 02:44:14,834][train][INFO] - Epoch 1217/2000, Val Acc=0.5953, Val Loss=1.6934, lr=0.0100
[2025-05-07 02:44:15,940][train][INFO] - Epoch 1225/2000, Val Acc=0.6026, Val Loss=1.8576, lr=0.0100
[2025-05-07 02:44:17,569][train][INFO] - Epoch 1198/2000, Val Acc=0.5995, Val Loss=1.7984, lr=0.0100
[2025-05-07 02:44:22,238][train][INFO] - Epoch 1218/2000, Val Acc=0.5969, Val Loss=1.6806, lr=0.0100
[2025-05-07 02:44:23,619][train][INFO] - Epoch 1226/2000, Val Acc=0.5981, Val Loss=1.8307, lr=0.0100
[2025-05-07 02:44:25,345][train][INFO] - Epoch 1199/2000, Val Acc=0.6259, Val Loss=1.6746, lr=0.0100
[2025-05-07 02:44:30,139][train][INFO] - Epoch 1219/2000, Val Acc=0.5702, Val Loss=1.8323, lr=0.0100
[2025-05-07 02:44:31,048][train][INFO] - Epoch 1227/2000, Val Acc=0.6090, Val Loss=1.8557, lr=0.0100
[2025-05-07 02:44:32,696][train][INFO] - Epoch 1200/2000, Val Acc=0.5935, Val Loss=1.9021, lr=0.0100
[2025-05-07 02:44:37,611][train][INFO] - Epoch 1220/2000, Val Acc=0.5883, Val Loss=1.7058, lr=0.0100
[2025-05-07 02:44:38,661][train][INFO] - Epoch 1228/2000, Val Acc=0.6137, Val Loss=1.7296, lr=0.0100
[2025-05-07 02:44:40,579][train][INFO] - Epoch 1201/2000, Val Acc=0.6193, Val Loss=1.7400, lr=0.0100
[2025-05-07 02:44:45,474][train][INFO] - Epoch 1221/2000, Val Acc=0.6000, Val Loss=1.6651, lr=0.0100
[2025-05-07 02:44:45,928][train][INFO] - Epoch 1229/2000, Val Acc=0.6004, Val Loss=1.8149, lr=0.0100
[2025-05-07 02:44:48,448][train][INFO] - Epoch 1202/2000, Val Acc=0.6123, Val Loss=1.7580, lr=0.0100
[2025-05-07 02:44:52,706][train][INFO] - Epoch 1222/2000, Val Acc=0.5837, Val Loss=1.7377, lr=0.0100
[2025-05-07 02:44:53,845][train][INFO] - Epoch 1230/2000, Val Acc=0.6018, Val Loss=1.7923, lr=0.0100
[2025-05-07 02:44:56,609][train][INFO] - Epoch 1203/2000, Val Acc=0.6234, Val Loss=1.6698, lr=0.0100
[2025-05-07 02:45:00,115][train][INFO] - Epoch 1223/2000, Val Acc=0.5973, Val Loss=1.6927, lr=0.0100
[2025-05-07 02:45:01,368][train][INFO] - Epoch 1231/2000, Val Acc=0.6239, Val Loss=1.7125, lr=0.0100
[2025-05-07 02:45:04,427][train][INFO] - Epoch 1204/2000, Val Acc=0.6145, Val Loss=1.7130, lr=0.0100
[2025-05-07 02:45:08,029][train][INFO] - Epoch 1224/2000, Val Acc=0.5980, Val Loss=1.6790, lr=0.0100
[2025-05-07 02:45:09,179][train][INFO] - Epoch 1232/2000, Val Acc=0.6309, Val Loss=1.6694, lr=0.0100
[2025-05-07 02:45:12,320][train][INFO] - Epoch 1205/2000, Val Acc=0.6138, Val Loss=1.7133, lr=0.0100
[2025-05-07 02:45:15,646][train][INFO] - Epoch 1225/2000, Val Acc=0.5856, Val Loss=1.6826, lr=0.0100
[2025-05-07 02:45:16,791][train][INFO] - Epoch 1233/2000, Val Acc=0.6174, Val Loss=1.7173, lr=0.0100
[2025-05-07 02:45:20,249][train][INFO] - Epoch 1206/2000, Val Acc=0.6144, Val Loss=1.7321, lr=0.0100
[2025-05-07 02:45:23,449][train][INFO] - Epoch 1226/2000, Val Acc=0.5959, Val Loss=1.6449, lr=0.0100
[2025-05-07 02:45:24,243][train][INFO] - Epoch 1234/2000, Val Acc=0.6224, Val Loss=1.6940, lr=0.0100
[2025-05-07 02:45:28,023][train][INFO] - Epoch 1207/2000, Val Acc=0.6102, Val Loss=1.7436, lr=0.0100
[2025-05-07 02:45:31,207][train][INFO] - Epoch 1227/2000, Val Acc=0.5911, Val Loss=1.7382, lr=0.0100
[2025-05-07 02:45:31,692][train][INFO] - Epoch 1235/2000, Val Acc=0.6337, Val Loss=1.6560, lr=0.0100
[2025-05-07 02:45:35,831][train][INFO] - Epoch 1208/2000, Val Acc=0.6060, Val Loss=1.7961, lr=0.0100
[2025-05-07 02:45:38,699][train][INFO] - Epoch 1228/2000, Val Acc=0.6025, Val Loss=1.6319, lr=0.0100
[2025-05-07 02:45:38,992][train][INFO] - Epoch 1236/2000, Val Acc=0.6171, Val Loss=1.7085, lr=0.0100
[2025-05-07 02:45:43,650][train][INFO] - Epoch 1209/2000, Val Acc=0.6221, Val Loss=1.6922, lr=0.0100
[2025-05-07 02:45:46,210][train][INFO] - Epoch 1229/2000, Val Acc=0.5770, Val Loss=1.7853, lr=0.0100
[2025-05-07 02:45:46,860][train][INFO] - Epoch 1237/2000, Val Acc=0.6231, Val Loss=1.6852, lr=0.0100
[2025-05-07 02:45:51,480][train][INFO] - Epoch 1210/2000, Val Acc=0.6244, Val Loss=1.6574, lr=0.0100
[2025-05-07 02:45:52,869][train][INFO] - Epoch 1230/2000, Val Acc=0.5823, Val Loss=1.7014, lr=0.0100
[2025-05-07 02:45:54,600][train][INFO] - Epoch 1238/2000, Val Acc=0.6269, Val Loss=1.6824, lr=0.0100
[2025-05-07 02:45:59,323][train][INFO] - Epoch 1211/2000, Val Acc=0.6266, Val Loss=1.6986, lr=0.0100
[2025-05-07 02:46:00,664][train][INFO] - Epoch 1231/2000, Val Acc=0.5946, Val Loss=1.6993, lr=0.0100
[2025-05-07 02:46:02,380][train][INFO] - Epoch 1239/2000, Val Acc=0.6023, Val Loss=1.8157, lr=0.0100
[2025-05-07 02:46:07,046][train][INFO] - Epoch 1212/2000, Val Acc=0.6197, Val Loss=1.6988, lr=0.0100
[2025-05-07 02:46:08,232][train][INFO] - Epoch 1232/2000, Val Acc=0.6048, Val Loss=1.6097, lr=0.0100
[2025-05-07 02:46:09,483][train][INFO] - Epoch 1240/2000, Val Acc=0.6213, Val Loss=1.7397, lr=0.0100
[2025-05-07 02:46:15,114][train][INFO] - Epoch 1213/2000, Val Acc=0.6039, Val Loss=1.8047, lr=0.0100
[2025-05-07 02:46:16,381][train][INFO] - Epoch 1233/2000, Val Acc=0.5895, Val Loss=1.7178, lr=0.0100
[2025-05-07 02:46:16,667][train][INFO] - Epoch 1241/2000, Val Acc=0.6040, Val Loss=1.7812, lr=0.0100
[2025-05-07 02:46:22,787][train][INFO] - Epoch 1214/2000, Val Acc=0.6303, Val Loss=1.6310, lr=0.0100
[2025-05-07 02:46:24,256][train][INFO] - Epoch 1234/2000, Val Acc=0.5726, Val Loss=1.8001, lr=0.0100
[2025-05-07 02:46:24,350][train][INFO] - Epoch 1242/2000, Val Acc=0.6078, Val Loss=1.7880, lr=0.0100
[2025-05-07 02:46:30,552][train][INFO] - Epoch 1215/2000, Val Acc=0.6128, Val Loss=1.7434, lr=0.0100
[2025-05-07 02:46:32,129][train][INFO] - Epoch 1235/2000, Val Acc=0.5923, Val Loss=1.6843, lr=0.0100
[2025-05-07 02:46:32,204][train][INFO] - Epoch 1243/2000, Val Acc=0.6230, Val Loss=1.7079, lr=0.0100
[2025-05-07 02:46:38,514][train][INFO] - Epoch 1216/2000, Val Acc=0.6022, Val Loss=1.8032, lr=0.0100
[2025-05-07 02:46:39,774][train][INFO] - Epoch 1236/2000, Val Acc=0.5924, Val Loss=1.6614, lr=0.0100
[2025-05-07 02:46:40,053][train][INFO] - Epoch 1244/2000, Val Acc=0.6146, Val Loss=1.7219, lr=0.0100
[2025-05-07 02:46:46,610][train][INFO] - Epoch 1217/2000, Val Acc=0.6149, Val Loss=1.7301, lr=0.0100
[2025-05-07 02:46:47,360][train][INFO] - Epoch 1237/2000, Val Acc=0.5979, Val Loss=1.6715, lr=0.0100
[2025-05-07 02:46:47,473][train][INFO] - Epoch 1245/2000, Val Acc=0.6235, Val Loss=1.7076, lr=0.0100
[2025-05-07 02:46:54,843][train][INFO] - Epoch 1218/2000, Val Acc=0.6250, Val Loss=1.6683, lr=0.0100
[2025-05-07 02:46:55,213][train][INFO] - Epoch 1246/2000, Val Acc=0.6297, Val Loss=1.6510, lr=0.0100
[2025-05-07 02:46:55,539][train][INFO] - Epoch 1238/2000, Val Acc=0.5850, Val Loss=1.7537, lr=0.0100
[2025-05-07 02:47:02,582][train][INFO] - Epoch 1219/2000, Val Acc=0.5945, Val Loss=1.8337, lr=0.0100
[2025-05-07 02:47:02,851][train][INFO] - Epoch 1247/2000, Val Acc=0.6096, Val Loss=1.7737, lr=0.0100
[2025-05-07 02:47:03,398][train][INFO] - Epoch 1239/2000, Val Acc=0.5972, Val Loss=1.6585, lr=0.0100
[2025-05-07 02:47:10,315][train][INFO] - Epoch 1248/2000, Val Acc=0.6103, Val Loss=1.7620, lr=0.0100
[2025-05-07 02:47:10,563][train][INFO] - Epoch 1220/2000, Val Acc=0.6202, Val Loss=1.7071, lr=0.0100
[2025-05-07 02:47:10,694][train][INFO] - Epoch 1240/2000, Val Acc=0.5805, Val Loss=1.7528, lr=0.0100
[2025-05-07 02:47:17,206][train][INFO] - Epoch 1249/2000, Val Acc=0.6249, Val Loss=1.6469, lr=0.0100
[2025-05-07 02:47:18,787][train][INFO] - Epoch 1241/2000, Val Acc=0.6031, Val Loss=1.6586, lr=0.0100
[2025-05-07 02:47:18,967][train][INFO] - Epoch 1221/2000, Val Acc=0.6219, Val Loss=1.6864, lr=0.0100
[2025-05-07 02:47:24,289][train][INFO] - Epoch 1250/2000, Val Acc=0.6052, Val Loss=1.7689, lr=0.0100
[2025-05-07 02:47:26,082][train][INFO] - Epoch 1242/2000, Val Acc=0.5956, Val Loss=1.6723, lr=0.0100
[2025-05-07 02:47:26,669][train][INFO] - Epoch 1222/2000, Val Acc=0.6045, Val Loss=1.7858, lr=0.0100
[2025-05-07 02:47:31,689][train][INFO] - Epoch 1251/2000, Val Acc=0.6202, Val Loss=1.7002, lr=0.0100
[2025-05-07 02:47:34,040][train][INFO] - Epoch 1223/2000, Val Acc=0.6133, Val Loss=1.7589, lr=0.0100
[2025-05-07 02:47:34,081][train][INFO] - Epoch 1243/2000, Val Acc=0.5917, Val Loss=1.6803, lr=0.0100
[2025-05-07 02:47:39,652][train][INFO] - Epoch 1252/2000, Val Acc=0.6268, Val Loss=1.6620, lr=0.0100
[2025-05-07 02:47:41,855][train][INFO] - Epoch 1244/2000, Val Acc=0.5914, Val Loss=1.6844, lr=0.0100
[2025-05-07 02:47:41,968][train][INFO] - Epoch 1224/2000, Val Acc=0.6176, Val Loss=1.7215, lr=0.0100
[2025-05-07 02:47:47,466][train][INFO] - Epoch 1253/2000, Val Acc=0.6153, Val Loss=1.7535, lr=0.0100
[2025-05-07 02:47:49,445][train][INFO] - Epoch 1245/2000, Val Acc=0.5950, Val Loss=1.6753, lr=0.0100
[2025-05-07 02:47:49,757][train][INFO] - Epoch 1225/2000, Val Acc=0.6026, Val Loss=1.8576, lr=0.0100
[2025-05-07 02:47:55,106][train][INFO] - Epoch 1254/2000, Val Acc=0.6274, Val Loss=1.6455, lr=0.0100
[2025-05-07 02:47:57,291][train][INFO] - Epoch 1246/2000, Val Acc=0.5767, Val Loss=1.7709, lr=0.0100
[2025-05-07 02:47:57,536][train][INFO] - Epoch 1226/2000, Val Acc=0.5981, Val Loss=1.8307, lr=0.0100
[2025-05-07 02:48:03,083][train][INFO] - Epoch 1255/2000, Val Acc=0.6153, Val Loss=1.7264, lr=0.0100
[2025-05-07 02:48:05,308][train][INFO] - Epoch 1227/2000, Val Acc=0.6090, Val Loss=1.8557, lr=0.0100
[2025-05-07 02:48:05,352][train][INFO] - Epoch 1247/2000, Val Acc=0.5890, Val Loss=1.7601, lr=0.0100
[2025-05-07 02:48:10,381][train][INFO] - Epoch 1256/2000, Val Acc=0.6165, Val Loss=1.7373, lr=0.0100
[2025-05-07 02:48:13,090][train][INFO] - Epoch 1248/2000, Val Acc=0.5979, Val Loss=1.6355, lr=0.0100
[2025-05-07 02:48:13,267][train][INFO] - Epoch 1228/2000, Val Acc=0.6137, Val Loss=1.7296, lr=0.0100
[2025-05-07 02:48:18,244][train][INFO] - Epoch 1257/2000, Val Acc=0.6213, Val Loss=1.7076, lr=0.0100
[2025-05-07 02:48:20,607][train][INFO] - Epoch 1249/2000, Val Acc=0.5835, Val Loss=1.7431, lr=0.0100
[2025-05-07 02:48:21,226][train][INFO] - Epoch 1229/2000, Val Acc=0.6004, Val Loss=1.8149, lr=0.0100
[2025-05-07 02:48:25,626][train][INFO] - Epoch 1258/2000, Val Acc=0.6144, Val Loss=1.7530, lr=0.0100
[2025-05-07 02:48:28,197][train][INFO] - Epoch 1250/2000, Val Acc=0.5902, Val Loss=1.6743, lr=0.0100
[2025-05-07 02:48:29,343][train][INFO] - Epoch 1230/2000, Val Acc=0.6018, Val Loss=1.7923, lr=0.0100
[2025-05-07 02:48:32,739][train][INFO] - Epoch 1259/2000, Val Acc=0.6076, Val Loss=1.8284, lr=0.0100
[2025-05-07 02:48:36,016][train][INFO] - Epoch 1251/2000, Val Acc=0.5867, Val Loss=1.7135, lr=0.0100
[2025-05-07 02:48:37,343][train][INFO] - Epoch 1231/2000, Val Acc=0.6239, Val Loss=1.7125, lr=0.0100
[2025-05-07 02:48:40,303][train][INFO] - Epoch 1260/2000, Val Acc=0.6228, Val Loss=1.6871, lr=0.0100
[2025-05-07 02:48:43,729][train][INFO] - Epoch 1252/2000, Val Acc=0.5866, Val Loss=1.7334, lr=0.0100
[2025-05-07 02:48:44,953][train][INFO] - Epoch 1232/2000, Val Acc=0.6309, Val Loss=1.6694, lr=0.0100
[2025-05-07 02:48:48,100][train][INFO] - Epoch 1261/2000, Val Acc=0.6106, Val Loss=1.7529, lr=0.0100
[2025-05-07 02:48:51,382][train][INFO] - Epoch 1253/2000, Val Acc=0.5795, Val Loss=1.7542, lr=0.0100
[2025-05-07 02:48:52,613][train][INFO] - Epoch 1233/2000, Val Acc=0.6174, Val Loss=1.7173, lr=0.0100
[2025-05-07 02:48:55,988][train][INFO] - Epoch 1262/2000, Val Acc=0.6286, Val Loss=1.6510, lr=0.0100
[2025-05-07 02:48:59,232][train][INFO] - Epoch 1254/2000, Val Acc=0.5919, Val Loss=1.7287, lr=0.0100
[2025-05-07 02:49:00,370][train][INFO] - Epoch 1234/2000, Val Acc=0.6224, Val Loss=1.6940, lr=0.0100
[2025-05-07 02:49:04,088][train][INFO] - Epoch 1263/2000, Val Acc=0.6208, Val Loss=1.6978, lr=0.0100
[2025-05-07 02:49:06,980][train][INFO] - Epoch 1255/2000, Val Acc=0.5951, Val Loss=1.6748, lr=0.0100
[2025-05-07 02:49:07,960][train][INFO] - Epoch 1235/2000, Val Acc=0.6337, Val Loss=1.6560, lr=0.0100
[2025-05-07 02:49:11,544][train][INFO] - Epoch 1264/2000, Val Acc=0.6115, Val Loss=1.7176, lr=0.0100
[2025-05-07 02:49:14,218][train][INFO] - Epoch 1256/2000, Val Acc=0.5893, Val Loss=1.6926, lr=0.0100
[2025-05-07 02:49:15,596][train][INFO] - Epoch 1236/2000, Val Acc=0.6171, Val Loss=1.7085, lr=0.0100
[2025-05-07 02:49:19,220][train][INFO] - Epoch 1265/2000, Val Acc=0.6082, Val Loss=1.7704, lr=0.0100
[2025-05-07 02:49:22,062][train][INFO] - Epoch 1257/2000, Val Acc=0.6007, Val Loss=1.6708, lr=0.0100
[2025-05-07 02:49:23,048][train][INFO] - Epoch 1237/2000, Val Acc=0.6231, Val Loss=1.6852, lr=0.0100
[2025-05-07 02:49:26,813][train][INFO] - Epoch 1266/2000, Val Acc=0.6169, Val Loss=1.7006, lr=0.0100
[2025-05-07 02:49:29,133][train][INFO] - Epoch 1258/2000, Val Acc=0.5835, Val Loss=1.7329, lr=0.0100
[2025-05-07 02:49:30,555][train][INFO] - Epoch 1238/2000, Val Acc=0.6269, Val Loss=1.6824, lr=0.0100
[2025-05-07 02:49:34,379][train][INFO] - Epoch 1267/2000, Val Acc=0.6210, Val Loss=1.7168, lr=0.0100
[2025-05-07 02:49:36,617][train][INFO] - Epoch 1259/2000, Val Acc=0.5985, Val Loss=1.6495, lr=0.0100
[2025-05-07 02:49:38,371][train][INFO] - Epoch 1239/2000, Val Acc=0.6023, Val Loss=1.8157, lr=0.0100
[2025-05-07 02:49:42,387][train][INFO] - Epoch 1268/2000, Val Acc=0.6303, Val Loss=1.6692, lr=0.0100
[2025-05-07 02:49:44,541][train][INFO] - Epoch 1260/2000, Val Acc=0.5957, Val Loss=1.6513, lr=0.0100
[2025-05-07 02:49:45,905][train][INFO] - Epoch 1240/2000, Val Acc=0.6213, Val Loss=1.7397, lr=0.0100
[2025-05-07 02:49:49,829][train][INFO] - Epoch 1269/2000, Val Acc=0.6114, Val Loss=1.7429, lr=0.0100
[2025-05-07 02:49:52,289][train][INFO] - Epoch 1261/2000, Val Acc=0.5890, Val Loss=1.7083, lr=0.0100
[2025-05-07 02:49:54,208][train][INFO] - Epoch 1241/2000, Val Acc=0.6040, Val Loss=1.7812, lr=0.0100
[2025-05-07 02:49:57,404][train][INFO] - Epoch 1270/2000, Val Acc=0.6188, Val Loss=1.6670, lr=0.0100
[2025-05-07 02:50:00,089][train][INFO] - Epoch 1262/2000, Val Acc=0.5943, Val Loss=1.6993, lr=0.0100
[2025-05-07 02:50:01,990][train][INFO] - Epoch 1242/2000, Val Acc=0.6078, Val Loss=1.7880, lr=0.0100
[2025-05-07 02:50:04,880][train][INFO] - Epoch 1271/2000, Val Acc=0.6260, Val Loss=1.6711, lr=0.0100
[2025-05-07 02:50:07,311][train][INFO] - Epoch 1263/2000, Val Acc=0.5848, Val Loss=1.7046, lr=0.0100
[2025-05-07 02:50:09,166][train][INFO] - Epoch 1243/2000, Val Acc=0.6230, Val Loss=1.7079, lr=0.0100
[2025-05-07 02:50:11,711][train][INFO] - Epoch 1272/2000, Val Acc=0.5915, Val Loss=1.8832, lr=0.0100
[2025-05-07 02:50:14,488][train][INFO] - Epoch 1264/2000, Val Acc=0.5876, Val Loss=1.7176, lr=0.0100
[2025-05-07 02:50:16,508][train][INFO] - Epoch 1244/2000, Val Acc=0.6146, Val Loss=1.7219, lr=0.0100
[2025-05-07 02:50:18,544][train][INFO] - Epoch 1273/2000, Val Acc=0.6100, Val Loss=1.7462, lr=0.0100
[2025-05-07 02:50:21,448][train][INFO] - Epoch 1265/2000, Val Acc=0.5712, Val Loss=1.8388, lr=0.0100
[2025-05-07 02:50:23,175][train][INFO] - Epoch 1245/2000, Val Acc=0.6235, Val Loss=1.7076, lr=0.0100
[2025-05-07 02:50:25,408][train][INFO] - Epoch 1274/2000, Val Acc=0.5983, Val Loss=1.8732, lr=0.0100
[2025-05-07 02:50:28,645][train][INFO] - Epoch 1266/2000, Val Acc=0.5812, Val Loss=1.7896, lr=0.0100
[2025-05-07 02:50:30,483][train][INFO] - Epoch 1246/2000, Val Acc=0.6297, Val Loss=1.6510, lr=0.0100
[2025-05-07 02:50:32,494][train][INFO] - Epoch 1275/2000, Val Acc=0.6140, Val Loss=1.7778, lr=0.0100
[2025-05-07 02:50:35,906][train][INFO] - Epoch 1267/2000, Val Acc=0.5940, Val Loss=1.6607, lr=0.0100
[2025-05-07 02:50:37,860][train][INFO] - Epoch 1247/2000, Val Acc=0.6096, Val Loss=1.7737, lr=0.0100
[2025-05-07 02:50:39,540][train][INFO] - Epoch 1276/2000, Val Acc=0.6253, Val Loss=1.6701, lr=0.0100
[2025-05-07 02:50:42,967][train][INFO] - Epoch 1268/2000, Val Acc=0.5959, Val Loss=1.6667, lr=0.0100
[2025-05-07 02:50:45,414][train][INFO] - Epoch 1248/2000, Val Acc=0.6103, Val Loss=1.7620, lr=0.0100
[2025-05-07 02:50:46,498][train][INFO] - Epoch 1277/2000, Val Acc=0.6035, Val Loss=1.7884, lr=0.0100
[2025-05-07 02:50:50,085][train][INFO] - Epoch 1269/2000, Val Acc=0.5917, Val Loss=1.6924, lr=0.0100
[2025-05-07 02:50:52,789][train][INFO] - Epoch 1249/2000, Val Acc=0.6249, Val Loss=1.6469, lr=0.0100
[2025-05-07 02:50:53,664][train][INFO] - Epoch 1278/2000, Val Acc=0.6148, Val Loss=1.7234, lr=0.0100
[2025-05-07 02:50:57,092][train][INFO] - Epoch 1270/2000, Val Acc=0.5816, Val Loss=1.7238, lr=0.0100
[2025-05-07 02:51:00,076][train][INFO] - Epoch 1250/2000, Val Acc=0.6052, Val Loss=1.7689, lr=0.0100
[2025-05-07 02:51:00,602][train][INFO] - Epoch 1279/2000, Val Acc=0.6333, Val Loss=1.6405, lr=0.0100
[2025-05-07 02:51:04,082][train][INFO] - Epoch 1271/2000, Val Acc=0.5840, Val Loss=1.7449, lr=0.0100
[2025-05-07 02:51:07,394][train][INFO] - Epoch 1251/2000, Val Acc=0.6202, Val Loss=1.7002, lr=0.0100
[2025-05-07 02:51:07,560][train][INFO] - Epoch 1280/2000, Val Acc=0.6129, Val Loss=1.7230, lr=0.0100
[2025-05-07 02:51:11,151][train][INFO] - Epoch 1272/2000, Val Acc=0.5912, Val Loss=1.7339, lr=0.0100
[2025-05-07 02:51:14,432][train][INFO] - Epoch 1281/2000, Val Acc=0.6203, Val Loss=1.6816, lr=0.0100
[2025-05-07 02:51:14,572][train][INFO] - Epoch 1252/2000, Val Acc=0.6268, Val Loss=1.6620, lr=0.0100
[2025-05-07 02:51:18,535][train][INFO] - Epoch 1273/2000, Val Acc=0.5856, Val Loss=1.7476, lr=0.0100
[2025-05-07 02:51:21,589][train][INFO] - Epoch 1282/2000, Val Acc=0.6160, Val Loss=1.7117, lr=0.0100
[2025-05-07 02:51:21,856][train][INFO] - Epoch 1253/2000, Val Acc=0.6153, Val Loss=1.7535, lr=0.0100
[2025-05-07 02:51:25,545][train][INFO] - Epoch 1274/2000, Val Acc=0.5967, Val Loss=1.6564, lr=0.0100
[2025-05-07 02:51:28,704][train][INFO] - Epoch 1283/2000, Val Acc=0.6095, Val Loss=1.7488, lr=0.0100
[2025-05-07 02:51:29,415][train][INFO] - Epoch 1254/2000, Val Acc=0.6274, Val Loss=1.6455, lr=0.0100
[2025-05-07 02:51:32,659][train][INFO] - Epoch 1275/2000, Val Acc=0.5856, Val Loss=1.7537, lr=0.0100
[2025-05-07 02:51:35,697][train][INFO] - Epoch 1284/2000, Val Acc=0.6153, Val Loss=1.7455, lr=0.0100
[2025-05-07 02:51:36,693][train][INFO] - Epoch 1255/2000, Val Acc=0.6153, Val Loss=1.7264, lr=0.0100
[2025-05-07 02:51:39,870][train][INFO] - Epoch 1276/2000, Val Acc=0.5963, Val Loss=1.6806, lr=0.0100
[2025-05-07 02:51:42,723][train][INFO] - Epoch 1285/2000, Val Acc=0.6278, Val Loss=1.7034, lr=0.0100
[2025-05-07 02:51:44,146][train][INFO] - Epoch 1256/2000, Val Acc=0.6165, Val Loss=1.7373, lr=0.0100
[2025-05-07 02:51:47,249][train][INFO] - Epoch 1277/2000, Val Acc=0.5824, Val Loss=1.7578, lr=0.0100
[2025-05-07 02:51:49,986][train][INFO] - Epoch 1286/2000, Val Acc=0.6139, Val Loss=1.7390, lr=0.0100
[2025-05-07 02:51:52,133][train][INFO] - Epoch 1257/2000, Val Acc=0.6213, Val Loss=1.7076, lr=0.0100
[2025-05-07 02:51:54,514][train][INFO] - Epoch 1278/2000, Val Acc=0.5644, Val Loss=1.8350, lr=0.0100
[2025-05-07 02:51:56,930][train][INFO] - Epoch 1287/2000, Val Acc=0.6316, Val Loss=1.6857, lr=0.0100
[2025-05-07 02:51:59,843][train][INFO] - Epoch 1258/2000, Val Acc=0.6144, Val Loss=1.7530, lr=0.0100
[2025-05-07 02:52:02,127][train][INFO] - Epoch 1279/2000, Val Acc=0.6040, Val Loss=1.6440, lr=0.0100
[2025-05-07 02:52:04,308][train][INFO] - Epoch 1288/2000, Val Acc=0.6188, Val Loss=1.7009, lr=0.0100
[2025-05-07 02:52:07,639][train][INFO] - Epoch 1259/2000, Val Acc=0.6076, Val Loss=1.8284, lr=0.0100
[2025-05-07 02:52:09,363][train][INFO] - Epoch 1280/2000, Val Acc=0.5699, Val Loss=1.8324, lr=0.0100
[2025-05-07 02:52:11,625][train][INFO] - Epoch 1289/2000, Val Acc=0.6201, Val Loss=1.7019, lr=0.0100
[2025-05-07 02:52:14,844][train][INFO] - Epoch 1260/2000, Val Acc=0.6228, Val Loss=1.6871, lr=0.0100
[2025-05-07 02:52:16,557][train][INFO] - Epoch 1281/2000, Val Acc=0.5723, Val Loss=1.8065, lr=0.0100
[2025-05-07 02:52:18,789][train][INFO] - Epoch 1290/2000, Val Acc=0.6250, Val Loss=1.6286, lr=0.0100
[2025-05-07 02:52:22,382][train][INFO] - Epoch 1261/2000, Val Acc=0.6106, Val Loss=1.7529, lr=0.0100
[2025-05-07 02:52:24,170][train][INFO] - Epoch 1282/2000, Val Acc=0.5968, Val Loss=1.6384, lr=0.0100
[2025-05-07 02:52:25,874][train][INFO] - Epoch 1291/2000, Val Acc=0.6272, Val Loss=1.6457, lr=0.0100
[2025-05-07 02:52:30,033][train][INFO] - Epoch 1262/2000, Val Acc=0.6286, Val Loss=1.6510, lr=0.0100
[2025-05-07 02:52:31,741][train][INFO] - Epoch 1283/2000, Val Acc=0.5985, Val Loss=1.6901, lr=0.0100
[2025-05-07 02:52:33,092][train][INFO] - Epoch 1292/2000, Val Acc=0.6190, Val Loss=1.7002, lr=0.0100
[2025-05-07 02:52:37,872][train][INFO] - Epoch 1263/2000, Val Acc=0.6208, Val Loss=1.6978, lr=0.0100
[2025-05-07 02:52:38,998][train][INFO] - Epoch 1284/2000, Val Acc=0.5909, Val Loss=1.6757, lr=0.0100
[2025-05-07 02:52:40,144][train][INFO] - Epoch 1293/2000, Val Acc=0.6287, Val Loss=1.6509, lr=0.0100
[2025-05-07 02:52:45,456][train][INFO] - Epoch 1264/2000, Val Acc=0.6115, Val Loss=1.7176, lr=0.0100
[2025-05-07 02:52:46,431][train][INFO] - Epoch 1285/2000, Val Acc=0.5882, Val Loss=1.7087, lr=0.0100
[2025-05-07 02:52:47,228][train][INFO] - Epoch 1294/2000, Val Acc=0.6323, Val Loss=1.6557, lr=0.0100
[2025-05-07 02:52:53,037][train][INFO] - Epoch 1265/2000, Val Acc=0.6082, Val Loss=1.7704, lr=0.0100
[2025-05-07 02:52:53,661][train][INFO] - Epoch 1286/2000, Val Acc=0.5895, Val Loss=1.7171, lr=0.0100
[2025-05-07 02:52:54,491][train][INFO] - Epoch 1295/2000, Val Acc=0.6169, Val Loss=1.7218, lr=0.0100
[2025-05-07 02:53:00,677][train][INFO] - Epoch 1266/2000, Val Acc=0.6169, Val Loss=1.7006, lr=0.0100
[2025-05-07 02:53:00,694][train][INFO] - Epoch 1287/2000, Val Acc=0.6045, Val Loss=1.6578, lr=0.0100
[2025-05-07 02:53:01,741][train][INFO] - Epoch 1296/2000, Val Acc=0.6157, Val Loss=1.6987, lr=0.0100
[2025-05-07 02:53:07,814][train][INFO] - Epoch 1288/2000, Val Acc=0.5828, Val Loss=1.7751, lr=0.0100
[2025-05-07 02:53:08,180][train][INFO] - Epoch 1267/2000, Val Acc=0.6210, Val Loss=1.7168, lr=0.0100
[2025-05-07 02:53:09,034][train][INFO] - Epoch 1297/2000, Val Acc=0.6314, Val Loss=1.6131, lr=0.0100
[2025-05-07 02:53:15,372][train][INFO] - Epoch 1289/2000, Val Acc=0.5919, Val Loss=1.7090, lr=0.0100
[2025-05-07 02:53:15,964][train][INFO] - Epoch 1268/2000, Val Acc=0.6303, Val Loss=1.6692, lr=0.0100
[2025-05-07 02:53:16,259][train][INFO] - Epoch 1298/2000, Val Acc=0.6224, Val Loss=1.7124, lr=0.0100
[2025-05-07 02:53:22,713][train][INFO] - Epoch 1290/2000, Val Acc=0.5933, Val Loss=1.7053, lr=0.0100
[2025-05-07 02:53:23,328][train][INFO] - Epoch 1299/2000, Val Acc=0.6136, Val Loss=1.7313, lr=0.0100
[2025-05-07 02:53:23,542][train][INFO] - Epoch 1269/2000, Val Acc=0.6114, Val Loss=1.7429, lr=0.0100
[2025-05-07 02:53:30,352][train][INFO] - Epoch 1291/2000, Val Acc=0.5932, Val Loss=1.6894, lr=0.0100
[2025-05-07 02:53:30,567][train][INFO] - Epoch 1300/2000, Val Acc=0.6274, Val Loss=1.6794, lr=0.0100
[2025-05-07 02:53:31,402][train][INFO] - Epoch 1270/2000, Val Acc=0.6188, Val Loss=1.6670, lr=0.0100
[2025-05-07 02:53:37,739][train][INFO] - Epoch 1292/2000, Val Acc=0.5969, Val Loss=1.6497, lr=0.0100
[2025-05-07 02:53:37,802][train][INFO] - Epoch 1301/2000, Val Acc=0.6086, Val Loss=1.8045, lr=0.0100
[2025-05-07 02:53:38,733][train][INFO] - Epoch 1271/2000, Val Acc=0.6260, Val Loss=1.6711, lr=0.0100
[2025-05-07 02:53:44,956][train][INFO] - Epoch 1293/2000, Val Acc=0.5991, Val Loss=1.6421, lr=0.0100
[2025-05-07 02:53:45,043][train][INFO] - Epoch 1302/2000, Val Acc=0.6329, Val Loss=1.6274, lr=0.0100
[2025-05-07 02:53:46,353][train][INFO] - Epoch 1272/2000, Val Acc=0.5915, Val Loss=1.8832, lr=0.0100
[2025-05-07 02:53:52,215][train][INFO] - Epoch 1303/2000, Val Acc=0.6084, Val Loss=1.7175, lr=0.0100
[2025-05-07 02:53:52,358][train][INFO] - Epoch 1294/2000, Val Acc=0.5945, Val Loss=1.6928, lr=0.0100
[2025-05-07 02:53:53,599][train][INFO] - Epoch 1273/2000, Val Acc=0.6100, Val Loss=1.7462, lr=0.0100
[2025-05-07 02:53:59,969][train][INFO] - Epoch 1304/2000, Val Acc=0.6057, Val Loss=1.8234, lr=0.0100
[2025-05-07 02:54:00,034][train][INFO] - Epoch 1295/2000, Val Acc=0.6007, Val Loss=1.6635, lr=0.0100
[2025-05-07 02:54:01,054][train][INFO] - Epoch 1274/2000, Val Acc=0.5983, Val Loss=1.8732, lr=0.0100
[2025-05-07 02:54:07,130][train][INFO] - Epoch 1296/2000, Val Acc=0.5935, Val Loss=1.7003, lr=0.0100
[2025-05-07 02:54:07,245][train][INFO] - Epoch 1305/2000, Val Acc=0.6146, Val Loss=1.7395, lr=0.0100
[2025-05-07 02:54:08,526][train][INFO] - Epoch 1275/2000, Val Acc=0.6140, Val Loss=1.7778, lr=0.0100
[2025-05-07 02:54:14,486][train][INFO] - Epoch 1306/2000, Val Acc=0.6178, Val Loss=1.7086, lr=0.0100
[2025-05-07 02:54:15,112][train][INFO] - Epoch 1297/2000, Val Acc=0.5904, Val Loss=1.7122, lr=0.0100
[2025-05-07 02:54:16,400][train][INFO] - Epoch 1276/2000, Val Acc=0.6253, Val Loss=1.6701, lr=0.0100
[2025-05-07 02:54:21,635][train][INFO] - Epoch 1307/2000, Val Acc=0.6214, Val Loss=1.7339, lr=0.0100
[2025-05-07 02:54:22,593][train][INFO] - Epoch 1298/2000, Val Acc=0.5751, Val Loss=1.8339, lr=0.0100
[2025-05-07 02:54:24,371][train][INFO] - Epoch 1277/2000, Val Acc=0.6035, Val Loss=1.7884, lr=0.0100
[2025-05-07 02:54:28,709][train][INFO] - Epoch 1308/2000, Val Acc=0.6234, Val Loss=1.7192, lr=0.0100
[2025-05-07 02:54:30,427][train][INFO] - Epoch 1299/2000, Val Acc=0.6076, Val Loss=1.6118, lr=0.0100
[2025-05-07 02:54:32,281][train][INFO] - Epoch 1278/2000, Val Acc=0.6148, Val Loss=1.7234, lr=0.0100
[2025-05-07 02:54:36,573][train][INFO] - Epoch 1309/2000, Val Acc=0.6191, Val Loss=1.6854, lr=0.0100
[2025-05-07 02:54:37,689][train][INFO] - Epoch 1300/2000, Val Acc=0.5904, Val Loss=1.7382, lr=0.0100
[2025-05-07 02:54:39,859][train][INFO] - Epoch 1279/2000, Val Acc=0.6333, Val Loss=1.6405, lr=0.0100
[2025-05-07 02:54:44,005][train][INFO] - Epoch 1310/2000, Val Acc=0.6139, Val Loss=1.7784, lr=0.0100
[2025-05-07 02:54:45,334][train][INFO] - Epoch 1301/2000, Val Acc=0.5932, Val Loss=1.6775, lr=0.0100
[2025-05-07 02:54:47,591][train][INFO] - Epoch 1280/2000, Val Acc=0.6129, Val Loss=1.7230, lr=0.0100
[2025-05-07 02:54:51,498][train][INFO] - Epoch 1311/2000, Val Acc=0.6287, Val Loss=1.6488, lr=0.0100
[2025-05-07 02:54:52,884][train][INFO] - Epoch 1302/2000, Val Acc=0.5927, Val Loss=1.6873, lr=0.0100
[2025-05-07 02:54:54,768][train][INFO] - Epoch 1281/2000, Val Acc=0.6203, Val Loss=1.6816, lr=0.0100
[2025-05-07 02:54:58,794][train][INFO] - Epoch 1312/2000, Val Acc=0.6186, Val Loss=1.6877, lr=0.0100
[2025-05-07 02:54:59,932][train][INFO] - Epoch 1303/2000, Val Acc=0.5883, Val Loss=1.7106, lr=0.0100
[2025-05-07 02:55:02,630][train][INFO] - Epoch 1282/2000, Val Acc=0.6160, Val Loss=1.7117, lr=0.0100
[2025-05-07 02:55:06,318][train][INFO] - Epoch 1313/2000, Val Acc=0.6155, Val Loss=1.7447, lr=0.0100
[2025-05-07 02:55:07,816][train][INFO] - Epoch 1304/2000, Val Acc=0.5859, Val Loss=1.7592, lr=0.0100
[2025-05-07 02:55:10,720][train][INFO] - Epoch 1283/2000, Val Acc=0.6095, Val Loss=1.7488, lr=0.0100
[2025-05-07 02:55:14,020][train][INFO] - Epoch 1314/2000, Val Acc=0.6134, Val Loss=1.7214, lr=0.0100
[2025-05-07 02:55:15,277][train][INFO] - Epoch 1305/2000, Val Acc=0.5740, Val Loss=1.8147, lr=0.0100
[2025-05-07 02:55:18,685][train][INFO] - Epoch 1284/2000, Val Acc=0.6153, Val Loss=1.7455, lr=0.0100
[2025-05-07 02:55:21,501][train][INFO] - Epoch 1315/2000, Val Acc=0.6142, Val Loss=1.7273, lr=0.0100
[2025-05-07 02:55:23,271][train][INFO] - Epoch 1306/2000, Val Acc=0.5872, Val Loss=1.7144, lr=0.0100
[2025-05-07 02:55:26,584][train][INFO] - Epoch 1285/2000, Val Acc=0.6278, Val Loss=1.7034, lr=0.0100
[2025-05-07 02:55:29,131][train][INFO] - Epoch 1316/2000, Val Acc=0.6001, Val Loss=1.8455, lr=0.0100
[2025-05-07 02:55:30,955][train][INFO] - Epoch 1307/2000, Val Acc=0.5847, Val Loss=1.7128, lr=0.0100
[2025-05-07 02:55:34,242][train][INFO] - Epoch 1286/2000, Val Acc=0.6139, Val Loss=1.7390, lr=0.0100
[2025-05-07 02:55:36,521][train][INFO] - Epoch 1317/2000, Val Acc=0.6258, Val Loss=1.6603, lr=0.0100
[2025-05-07 02:55:38,654][train][INFO] - Epoch 1308/2000, Val Acc=0.6102, Val Loss=1.6319, lr=0.0100
[2025-05-07 02:55:42,089][train][INFO] - Epoch 1287/2000, Val Acc=0.6316, Val Loss=1.6857, lr=0.0100
[2025-05-07 02:55:44,225][train][INFO] - Epoch 1318/2000, Val Acc=0.6190, Val Loss=1.6548, lr=0.0100
[2025-05-07 02:55:46,354][train][INFO] - Epoch 1309/2000, Val Acc=0.5944, Val Loss=1.6947, lr=0.0100
[2025-05-07 02:55:49,884][train][INFO] - Epoch 1288/2000, Val Acc=0.6188, Val Loss=1.7009, lr=0.0100
[2025-05-07 02:55:51,644][train][INFO] - Epoch 1319/2000, Val Acc=0.6171, Val Loss=1.7167, lr=0.0100
[2025-05-07 02:55:54,211][train][INFO] - Epoch 1310/2000, Val Acc=0.5845, Val Loss=1.7332, lr=0.0100
[2025-05-07 02:55:57,553][train][INFO] - Epoch 1289/2000, Val Acc=0.6201, Val Loss=1.7019, lr=0.0100
[2025-05-07 02:55:59,225][train][INFO] - Epoch 1320/2000, Val Acc=0.6259, Val Loss=1.6716, lr=0.0100
[2025-05-07 02:56:01,724][train][INFO] - Epoch 1311/2000, Val Acc=0.5973, Val Loss=1.6793, lr=0.0100
[2025-05-07 02:56:05,522][train][INFO] - Epoch 1290/2000, Val Acc=0.6250, Val Loss=1.6286, lr=0.0100
[2025-05-07 02:56:07,145][train][INFO] - Epoch 1321/2000, Val Acc=0.6163, Val Loss=1.7345, lr=0.0100
[2025-05-07 02:56:09,289][train][INFO] - Epoch 1312/2000, Val Acc=0.5896, Val Loss=1.7481, lr=0.0100
[2025-05-07 02:56:13,070][train][INFO] - Epoch 1291/2000, Val Acc=0.6272, Val Loss=1.6457, lr=0.0100
[2025-05-07 02:56:14,726][train][INFO] - Epoch 1322/2000, Val Acc=0.6131, Val Loss=1.7276, lr=0.0100
[2025-05-07 02:56:17,087][train][INFO] - Epoch 1313/2000, Val Acc=0.6000, Val Loss=1.6178, lr=0.0100
[2025-05-07 02:56:20,663][train][INFO] - Epoch 1292/2000, Val Acc=0.6190, Val Loss=1.7002, lr=0.0100
[2025-05-07 02:56:22,224][train][INFO] - Epoch 1323/2000, Val Acc=0.6245, Val Loss=1.6559, lr=0.0100
[2025-05-07 02:56:24,820][train][INFO] - Epoch 1314/2000, Val Acc=0.6069, Val Loss=1.6376, lr=0.0100
[2025-05-07 02:56:28,410][train][INFO] - Epoch 1293/2000, Val Acc=0.6287, Val Loss=1.6509, lr=0.0100
[2025-05-07 02:56:29,731][train][INFO] - Epoch 1324/2000, Val Acc=0.6227, Val Loss=1.6992, lr=0.0100
[2025-05-07 02:56:32,509][train][INFO] - Epoch 1315/2000, Val Acc=0.5686, Val Loss=1.7879, lr=0.0100
[2025-05-07 02:56:36,188][train][INFO] - Epoch 1294/2000, Val Acc=0.6323, Val Loss=1.6557, lr=0.0100
[2025-05-07 02:56:37,181][train][INFO] - Epoch 1325/2000, Val Acc=0.6190, Val Loss=1.7142, lr=0.0100
[2025-05-07 02:56:40,347][train][INFO] - Epoch 1316/2000, Val Acc=0.5964, Val Loss=1.6903, lr=0.0100
[2025-05-07 02:56:44,319][train][INFO] - Epoch 1295/2000, Val Acc=0.6169, Val Loss=1.7218, lr=0.0100
[2025-05-07 02:56:44,907][train][INFO] - Epoch 1326/2000, Val Acc=0.6165, Val Loss=1.6944, lr=0.0100
[2025-05-07 02:56:47,871][train][INFO] - Epoch 1317/2000, Val Acc=0.5993, Val Loss=1.6509, lr=0.0100
[2025-05-07 02:56:52,346][train][INFO] - Epoch 1296/2000, Val Acc=0.6157, Val Loss=1.6987, lr=0.0100
[2025-05-07 02:56:52,581][train][INFO] - Epoch 1327/2000, Val Acc=0.6024, Val Loss=1.8092, lr=0.0100
[2025-05-07 02:56:55,620][train][INFO] - Epoch 1318/2000, Val Acc=0.5890, Val Loss=1.7207, lr=0.0100
[2025-05-07 02:57:00,102][train][INFO] - Epoch 1328/2000, Val Acc=0.6100, Val Loss=1.7925, lr=0.0100
[2025-05-07 02:57:00,424][train][INFO] - Epoch 1297/2000, Val Acc=0.6314, Val Loss=1.6131, lr=0.0100
[2025-05-07 02:57:02,867][train][INFO] - Epoch 1319/2000, Val Acc=0.5699, Val Loss=1.8089, lr=0.0100
[2025-05-07 02:57:07,843][train][INFO] - Epoch 1329/2000, Val Acc=0.6267, Val Loss=1.6379, lr=0.0100
[2025-05-07 02:57:08,359][train][INFO] - Epoch 1298/2000, Val Acc=0.6224, Val Loss=1.7124, lr=0.0100
[2025-05-07 02:57:10,264][train][INFO] - Epoch 1320/2000, Val Acc=0.5906, Val Loss=1.7367, lr=0.0100
[2025-05-07 02:57:15,112][train][INFO] - Epoch 1330/2000, Val Acc=0.6157, Val Loss=1.7018, lr=0.0100
[2025-05-07 02:57:16,497][train][INFO] - Epoch 1299/2000, Val Acc=0.6136, Val Loss=1.7313, lr=0.0100
[2025-05-07 02:57:17,981][train][INFO] - Epoch 1321/2000, Val Acc=0.5865, Val Loss=1.7580, lr=0.0100
[2025-05-07 02:57:22,422][train][INFO] - Epoch 1331/2000, Val Acc=0.6254, Val Loss=1.6444, lr=0.0100
[2025-05-07 02:57:24,009][train][INFO] - Epoch 1300/2000, Val Acc=0.6274, Val Loss=1.6794, lr=0.0100
[2025-05-07 02:57:25,608][train][INFO] - Epoch 1322/2000, Val Acc=0.5888, Val Loss=1.7255, lr=0.0100
[2025-05-07 02:57:29,810][train][INFO] - Epoch 1332/2000, Val Acc=0.6192, Val Loss=1.7221, lr=0.0100
[2025-05-07 02:57:31,816][train][INFO] - Epoch 1301/2000, Val Acc=0.6086, Val Loss=1.8045, lr=0.0100
[2025-05-07 02:57:33,295][train][INFO] - Epoch 1323/2000, Val Acc=0.5931, Val Loss=1.6613, lr=0.0100
[2025-05-07 02:57:37,423][train][INFO] - Epoch 1333/2000, Val Acc=0.6286, Val Loss=1.6282, lr=0.0100
[2025-05-07 02:57:39,425][train][INFO] - Epoch 1302/2000, Val Acc=0.6329, Val Loss=1.6274, lr=0.0100
[2025-05-07 02:57:40,917][train][INFO] - Epoch 1324/2000, Val Acc=0.5817, Val Loss=1.7410, lr=0.0100
[2025-05-07 02:57:45,108][train][INFO] - Epoch 1334/2000, Val Acc=0.5728, Val Loss=2.0033, lr=0.0100
[2025-05-07 02:57:47,039][train][INFO] - Epoch 1303/2000, Val Acc=0.6084, Val Loss=1.7175, lr=0.0100
[2025-05-07 02:57:48,844][train][INFO] - Epoch 1325/2000, Val Acc=0.5773, Val Loss=1.7747, lr=0.0100
[2025-05-07 02:57:52,605][train][INFO] - Epoch 1335/2000, Val Acc=0.6153, Val Loss=1.7420, lr=0.0100
[2025-05-07 02:57:54,316][train][INFO] - Epoch 1304/2000, Val Acc=0.6057, Val Loss=1.8234, lr=0.0100
[2025-05-07 02:57:56,435][train][INFO] - Epoch 1326/2000, Val Acc=0.5863, Val Loss=1.7251, lr=0.0100
[2025-05-07 02:58:00,280][train][INFO] - Epoch 1336/2000, Val Acc=0.6103, Val Loss=1.7414, lr=0.0100
[2025-05-07 02:58:01,890][train][INFO] - Epoch 1305/2000, Val Acc=0.6146, Val Loss=1.7395, lr=0.0100
[2025-05-07 02:58:03,813][train][INFO] - Epoch 1327/2000, Val Acc=0.6015, Val Loss=1.6306, lr=0.0100
[2025-05-07 02:58:08,089][train][INFO] - Epoch 1337/2000, Val Acc=0.6233, Val Loss=1.6609, lr=0.0100
[2025-05-07 02:58:09,686][train][INFO] - Epoch 1306/2000, Val Acc=0.6178, Val Loss=1.7086, lr=0.0100
[2025-05-07 02:58:11,800][train][INFO] - Epoch 1328/2000, Val Acc=0.5964, Val Loss=1.7111, lr=0.0100
[2025-05-07 02:58:15,675][train][INFO] - Epoch 1338/2000, Val Acc=0.6122, Val Loss=1.7605, lr=0.0100
[2025-05-07 02:58:17,470][train][INFO] - Epoch 1307/2000, Val Acc=0.6214, Val Loss=1.7339, lr=0.0100
[2025-05-07 02:58:19,878][train][INFO] - Epoch 1329/2000, Val Acc=0.5827, Val Loss=1.7222, lr=0.0100
[2025-05-07 02:58:23,451][train][INFO] - Epoch 1339/2000, Val Acc=0.6325, Val Loss=1.6451, lr=0.0100
[2025-05-07 02:58:25,439][train][INFO] - Epoch 1308/2000, Val Acc=0.6234, Val Loss=1.7192, lr=0.0100
[2025-05-07 02:58:27,347][train][INFO] - Epoch 1330/2000, Val Acc=0.5929, Val Loss=1.6857, lr=0.0100
[2025-05-07 02:58:31,014][train][INFO] - Epoch 1340/2000, Val Acc=0.6186, Val Loss=1.7689, lr=0.0100
[2025-05-07 02:58:32,920][train][INFO] - Epoch 1309/2000, Val Acc=0.6191, Val Loss=1.6854, lr=0.0100
[2025-05-07 02:58:35,186][train][INFO] - Epoch 1331/2000, Val Acc=0.6031, Val Loss=1.6761, lr=0.0100
[2025-05-07 02:58:38,350][train][INFO] - Epoch 1341/2000, Val Acc=0.6070, Val Loss=1.7699, lr=0.0100
[2025-05-07 02:58:40,874][train][INFO] - Epoch 1310/2000, Val Acc=0.6139, Val Loss=1.7784, lr=0.0100
[2025-05-07 02:58:42,710][train][INFO] - Epoch 1332/2000, Val Acc=0.6020, Val Loss=1.6532, lr=0.0100
[2025-05-07 02:58:45,963][train][INFO] - Epoch 1342/2000, Val Acc=0.6304, Val Loss=1.6713, lr=0.0100
[2025-05-07 02:58:48,715][train][INFO] - Epoch 1311/2000, Val Acc=0.6287, Val Loss=1.6488, lr=0.0100
[2025-05-07 02:58:50,494][train][INFO] - Epoch 1333/2000, Val Acc=0.6078, Val Loss=1.6536, lr=0.0100
[2025-05-07 02:58:53,416][train][INFO] - Epoch 1343/2000, Val Acc=0.6130, Val Loss=1.7410, lr=0.0100
[2025-05-07 02:58:56,495][train][INFO] - Epoch 1312/2000, Val Acc=0.6186, Val Loss=1.6877, lr=0.0100
[2025-05-07 02:58:58,165][train][INFO] - Epoch 1334/2000, Val Acc=0.5879, Val Loss=1.7477, lr=0.0100
[2025-05-07 02:59:00,862][train][INFO] - Epoch 1344/2000, Val Acc=0.6154, Val Loss=1.7284, lr=0.0100
[2025-05-07 02:59:04,051][train][INFO] - Epoch 1313/2000, Val Acc=0.6155, Val Loss=1.7447, lr=0.0100
[2025-05-07 02:59:05,828][train][INFO] - Epoch 1335/2000, Val Acc=0.5879, Val Loss=1.7370, lr=0.0100
[2025-05-07 02:59:08,282][train][INFO] - Epoch 1345/2000, Val Acc=0.6146, Val Loss=1.7612, lr=0.0100
[2025-05-07 02:59:11,870][train][INFO] - Epoch 1314/2000, Val Acc=0.6134, Val Loss=1.7214, lr=0.0100
[2025-05-07 02:59:13,319][train][INFO] - Epoch 1336/2000, Val Acc=0.5863, Val Loss=1.7342, lr=0.0100
[2025-05-07 02:59:15,568][train][INFO] - Epoch 1346/2000, Val Acc=0.6071, Val Loss=1.7822, lr=0.0100
[2025-05-07 02:59:19,193][train][INFO] - Epoch 1315/2000, Val Acc=0.6142, Val Loss=1.7273, lr=0.0100
[2025-05-07 02:59:20,507][train][INFO] - Epoch 1337/2000, Val Acc=0.5890, Val Loss=1.7155, lr=0.0100
[2025-05-07 02:59:23,328][train][INFO] - Epoch 1347/2000, Val Acc=0.6148, Val Loss=1.7458, lr=0.0100
[2025-05-07 02:59:27,165][train][INFO] - Epoch 1316/2000, Val Acc=0.6001, Val Loss=1.8455, lr=0.0100
[2025-05-07 02:59:28,076][train][INFO] - Epoch 1338/2000, Val Acc=0.6000, Val Loss=1.6508, lr=0.0100
[2025-05-07 02:59:31,059][train][INFO] - Epoch 1348/2000, Val Acc=0.6185, Val Loss=1.7075, lr=0.0100
[2025-05-07 02:59:35,207][train][INFO] - Epoch 1317/2000, Val Acc=0.6258, Val Loss=1.6603, lr=0.0100
[2025-05-07 02:59:35,305][train][INFO] - Epoch 1339/2000, Val Acc=0.5911, Val Loss=1.7407, lr=0.0100
[2025-05-07 02:59:39,075][train][INFO] - Epoch 1349/2000, Val Acc=0.6267, Val Loss=1.6840, lr=0.0100
[2025-05-07 02:59:42,965][train][INFO] - Epoch 1318/2000, Val Acc=0.6190, Val Loss=1.6548, lr=0.0100
[2025-05-07 02:59:43,111][train][INFO] - Epoch 1340/2000, Val Acc=0.5866, Val Loss=1.7396, lr=0.0100
[2025-05-07 02:59:46,470][train][INFO] - Epoch 1350/2000, Val Acc=0.6078, Val Loss=1.7854, lr=0.0100
[2025-05-07 02:59:50,702][train][INFO] - Epoch 1341/2000, Val Acc=0.5959, Val Loss=1.6587, lr=0.0100
[2025-05-07 02:59:50,807][train][INFO] - Epoch 1319/2000, Val Acc=0.6171, Val Loss=1.7167, lr=0.0100
[2025-05-07 02:59:54,391][train][INFO] - Epoch 1351/2000, Val Acc=0.6180, Val Loss=1.7018, lr=0.0100
[2025-05-07 02:59:58,046][train][INFO] - Epoch 1342/2000, Val Acc=0.5801, Val Loss=1.8088, lr=0.0100
[2025-05-07 02:59:58,078][train][INFO] - Epoch 1320/2000, Val Acc=0.6259, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:00:02,091][train][INFO] - Epoch 1352/2000, Val Acc=0.6253, Val Loss=1.7085, lr=0.0100
[2025-05-07 03:00:05,580][train][INFO] - Epoch 1321/2000, Val Acc=0.6163, Val Loss=1.7345, lr=0.0100
[2025-05-07 03:00:05,640][train][INFO] - Epoch 1343/2000, Val Acc=0.5951, Val Loss=1.7080, lr=0.0100
[2025-05-07 03:00:09,622][train][INFO] - Epoch 1353/2000, Val Acc=0.6042, Val Loss=1.7902, lr=0.0100
[2025-05-07 03:00:13,405][train][INFO] - Epoch 1322/2000, Val Acc=0.6131, Val Loss=1.7276, lr=0.0100
[2025-05-07 03:00:13,751][train][INFO] - Epoch 1344/2000, Val Acc=0.6051, Val Loss=1.6233, lr=0.0100
[2025-05-07 03:00:16,639][train][INFO] - Epoch 1354/2000, Val Acc=0.6104, Val Loss=1.7525, lr=0.0100
[2025-05-07 03:00:21,286][train][INFO] - Epoch 1345/2000, Val Acc=0.5792, Val Loss=1.8094, lr=0.0100
[2025-05-07 03:00:21,447][train][INFO] - Epoch 1323/2000, Val Acc=0.6245, Val Loss=1.6559, lr=0.0100
[2025-05-07 03:00:23,886][train][INFO] - Epoch 1355/2000, Val Acc=0.6151, Val Loss=1.7470, lr=0.0100
[2025-05-07 03:00:29,047][train][INFO] - Epoch 1346/2000, Val Acc=0.6097, Val Loss=1.6145, lr=0.0100
[2025-05-07 03:00:29,610][train][INFO] - Epoch 1324/2000, Val Acc=0.6227, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:00:31,279][train][INFO] - Epoch 1356/2000, Val Acc=0.6204, Val Loss=1.7239, lr=0.0100
[2025-05-07 03:00:36,768][train][INFO] - Epoch 1347/2000, Val Acc=0.5791, Val Loss=1.7637, lr=0.0100
[2025-05-07 03:00:37,285][train][INFO] - Epoch 1325/2000, Val Acc=0.6190, Val Loss=1.7142, lr=0.0100
[2025-05-07 03:00:38,956][train][INFO] - Epoch 1357/2000, Val Acc=0.6207, Val Loss=1.6990, lr=0.0100
[2025-05-07 03:00:44,729][train][INFO] - Epoch 1348/2000, Val Acc=0.6049, Val Loss=1.6320, lr=0.0100
[2025-05-07 03:00:45,110][train][INFO] - Epoch 1326/2000, Val Acc=0.6165, Val Loss=1.6944, lr=0.0100
[2025-05-07 03:00:46,019][train][INFO] - Epoch 1358/2000, Val Acc=0.6160, Val Loss=1.6935, lr=0.0100
[2025-05-07 03:00:51,942][train][INFO] - Epoch 1349/2000, Val Acc=0.5844, Val Loss=1.7691, lr=0.0100
[2025-05-07 03:00:53,108][train][INFO] - Epoch 1327/2000, Val Acc=0.6024, Val Loss=1.8092, lr=0.0100
[2025-05-07 03:00:53,775][train][INFO] - Epoch 1359/2000, Val Acc=0.6187, Val Loss=1.6869, lr=0.0100
[2025-05-07 03:00:59,950][train][INFO] - Epoch 1350/2000, Val Acc=0.5739, Val Loss=1.7702, lr=0.0100
[2025-05-07 03:01:01,580][train][INFO] - Epoch 1328/2000, Val Acc=0.6100, Val Loss=1.7925, lr=0.0100
[2025-05-07 03:01:01,689][train][INFO] - Epoch 1360/2000, Val Acc=0.6194, Val Loss=1.7105, lr=0.0100
[2025-05-07 03:01:07,776][train][INFO] - Epoch 1351/2000, Val Acc=0.5965, Val Loss=1.6537, lr=0.0100
[2025-05-07 03:01:09,507][train][INFO] - Epoch 1361/2000, Val Acc=0.6235, Val Loss=1.6766, lr=0.0100
[2025-05-07 03:01:09,720][train][INFO] - Epoch 1329/2000, Val Acc=0.6267, Val Loss=1.6379, lr=0.0100
[2025-05-07 03:01:15,482][train][INFO] - Epoch 1352/2000, Val Acc=0.5995, Val Loss=1.6813, lr=0.0100
[2025-05-07 03:01:17,388][train][INFO] - Epoch 1362/2000, Val Acc=0.6154, Val Loss=1.7296, lr=0.0100
[2025-05-07 03:01:17,420][train][INFO] - Epoch 1330/2000, Val Acc=0.6157, Val Loss=1.7018, lr=0.0100
[2025-05-07 03:01:23,586][train][INFO] - Epoch 1353/2000, Val Acc=0.5725, Val Loss=1.8226, lr=0.0100
[2025-05-07 03:01:25,015][train][INFO] - Epoch 1363/2000, Val Acc=0.6242, Val Loss=1.7144, lr=0.0100
[2025-05-07 03:01:25,319][train][INFO] - Epoch 1331/2000, Val Acc=0.6254, Val Loss=1.6444, lr=0.0100
[2025-05-07 03:01:31,201][train][INFO] - Epoch 1354/2000, Val Acc=0.5766, Val Loss=1.7766, lr=0.0100
[2025-05-07 03:01:32,262][train][INFO] - Epoch 1364/2000, Val Acc=0.6228, Val Loss=1.6999, lr=0.0100
[2025-05-07 03:01:33,232][train][INFO] - Epoch 1332/2000, Val Acc=0.6192, Val Loss=1.7221, lr=0.0100
[2025-05-07 03:01:39,047][train][INFO] - Epoch 1355/2000, Val Acc=0.6017, Val Loss=1.6150, lr=0.0100
[2025-05-07 03:01:39,920][train][INFO] - Epoch 1365/2000, Val Acc=0.6182, Val Loss=1.6867, lr=0.0100
[2025-05-07 03:01:41,291][train][INFO] - Epoch 1333/2000, Val Acc=0.6286, Val Loss=1.6282, lr=0.0100
[2025-05-07 03:01:46,101][train][INFO] - Epoch 1356/2000, Val Acc=0.6014, Val Loss=1.6751, lr=0.0100
[2025-05-07 03:01:47,428][train][INFO] - Epoch 1366/2000, Val Acc=0.6022, Val Loss=1.8253, lr=0.0100
[2025-05-07 03:01:48,969][train][INFO] - Epoch 1334/2000, Val Acc=0.5728, Val Loss=2.0033, lr=0.0100
[2025-05-07 03:01:53,806][train][INFO] - Epoch 1357/2000, Val Acc=0.5888, Val Loss=1.7290, lr=0.0100
[2025-05-07 03:01:55,135][train][INFO] - Epoch 1367/2000, Val Acc=0.6011, Val Loss=1.7953, lr=0.0100
[2025-05-07 03:01:56,557][train][INFO] - Epoch 1335/2000, Val Acc=0.6153, Val Loss=1.7420, lr=0.0100
[2025-05-07 03:02:01,617][train][INFO] - Epoch 1358/2000, Val Acc=0.5970, Val Loss=1.6666, lr=0.0100
[2025-05-07 03:02:02,691][train][INFO] - Epoch 1368/2000, Val Acc=0.6106, Val Loss=1.7795, lr=0.0100
[2025-05-07 03:02:04,106][train][INFO] - Epoch 1336/2000, Val Acc=0.6103, Val Loss=1.7414, lr=0.0100
[2025-05-07 03:02:09,377][train][INFO] - Epoch 1359/2000, Val Acc=0.5832, Val Loss=1.7388, lr=0.0100
[2025-05-07 03:02:10,419][train][INFO] - Epoch 1369/2000, Val Acc=0.6191, Val Loss=1.7194, lr=0.0100
[2025-05-07 03:02:12,142][train][INFO] - Epoch 1337/2000, Val Acc=0.6233, Val Loss=1.6609, lr=0.0100
[2025-05-07 03:02:17,270][train][INFO] - Epoch 1360/2000, Val Acc=0.5888, Val Loss=1.7039, lr=0.0100
[2025-05-07 03:02:17,758][train][INFO] - Epoch 1370/2000, Val Acc=0.6054, Val Loss=1.8473, lr=0.0100
[2025-05-07 03:02:20,129][train][INFO] - Epoch 1338/2000, Val Acc=0.6122, Val Loss=1.7605, lr=0.0100
[2025-05-07 03:02:24,832][train][INFO] - Epoch 1361/2000, Val Acc=0.6033, Val Loss=1.6347, lr=0.0100
[2025-05-07 03:02:24,953][train][INFO] - Epoch 1371/2000, Val Acc=0.6147, Val Loss=1.7507, lr=0.0100
[2025-05-07 03:02:28,037][train][INFO] - Epoch 1339/2000, Val Acc=0.6325, Val Loss=1.6451, lr=0.0100
[2025-05-07 03:02:32,512][train][INFO] - Epoch 1362/2000, Val Acc=0.5988, Val Loss=1.6732, lr=0.0100
[2025-05-07 03:02:32,951][train][INFO] - Epoch 1372/2000, Val Acc=0.6288, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:02:36,068][train][INFO] - Epoch 1340/2000, Val Acc=0.6186, Val Loss=1.7689, lr=0.0100
[2025-05-07 03:02:40,268][train][INFO] - Epoch 1363/2000, Val Acc=0.6013, Val Loss=1.6293, lr=0.0100
[2025-05-07 03:02:40,502][train][INFO] - Epoch 1373/2000, Val Acc=0.6238, Val Loss=1.6516, lr=0.0100
[2025-05-07 03:02:44,003][train][INFO] - Epoch 1341/2000, Val Acc=0.6070, Val Loss=1.7699, lr=0.0100
[2025-05-07 03:02:47,553][train][INFO] - Epoch 1364/2000, Val Acc=0.5969, Val Loss=1.6616, lr=0.0100
[2025-05-07 03:02:48,046][train][INFO] - Epoch 1374/2000, Val Acc=0.6206, Val Loss=1.6825, lr=0.0100
[2025-05-07 03:02:52,065][train][INFO] - Epoch 1342/2000, Val Acc=0.6304, Val Loss=1.6713, lr=0.0100
[2025-05-07 03:02:55,266][train][INFO] - Epoch 1365/2000, Val Acc=0.5871, Val Loss=1.7722, lr=0.0100
[2025-05-07 03:02:55,527][train][INFO] - Epoch 1375/2000, Val Acc=0.6235, Val Loss=1.6680, lr=0.0100
[2025-05-07 03:02:59,615][train][INFO] - Epoch 1343/2000, Val Acc=0.6130, Val Loss=1.7410, lr=0.0100
[2025-05-07 03:03:03,149][train][INFO] - Epoch 1376/2000, Val Acc=0.6141, Val Loss=1.7502, lr=0.0100
[2025-05-07 03:03:03,269][train][INFO] - Epoch 1366/2000, Val Acc=0.5980, Val Loss=1.6545, lr=0.0100
[2025-05-07 03:03:07,691][train][INFO] - Epoch 1344/2000, Val Acc=0.6154, Val Loss=1.7284, lr=0.0100
[2025-05-07 03:03:10,714][train][INFO] - Epoch 1377/2000, Val Acc=0.6346, Val Loss=1.6344, lr=0.0100
[2025-05-07 03:03:10,999][train][INFO] - Epoch 1367/2000, Val Acc=0.5991, Val Loss=1.6732, lr=0.0100
[2025-05-07 03:03:15,198][train][INFO] - Epoch 1345/2000, Val Acc=0.6146, Val Loss=1.7612, lr=0.0100
[2025-05-07 03:03:18,155][train][INFO] - Epoch 1378/2000, Val Acc=0.6193, Val Loss=1.7120, lr=0.0100
[2025-05-07 03:03:18,301][train][INFO] - Epoch 1368/2000, Val Acc=0.5856, Val Loss=1.7560, lr=0.0100
[2025-05-07 03:03:23,062][train][INFO] - Epoch 1346/2000, Val Acc=0.6071, Val Loss=1.7822, lr=0.0100
[2025-05-07 03:03:25,286][train][INFO] - Epoch 1369/2000, Val Acc=0.5795, Val Loss=1.7873, lr=0.0100
[2025-05-07 03:03:25,309][train][INFO] - Epoch 1379/2000, Val Acc=0.6138, Val Loss=1.7360, lr=0.0100
[2025-05-07 03:03:30,630][train][INFO] - Epoch 1347/2000, Val Acc=0.6148, Val Loss=1.7458, lr=0.0100
[2025-05-07 03:03:32,184][train][INFO] - Epoch 1370/2000, Val Acc=0.5988, Val Loss=1.6475, lr=0.0100
[2025-05-07 03:03:32,763][train][INFO] - Epoch 1380/2000, Val Acc=0.6192, Val Loss=1.7092, lr=0.0100
[2025-05-07 03:03:38,656][train][INFO] - Epoch 1348/2000, Val Acc=0.6185, Val Loss=1.7075, lr=0.0100
[2025-05-07 03:03:40,015][train][INFO] - Epoch 1381/2000, Val Acc=0.6178, Val Loss=1.7156, lr=0.0100
[2025-05-07 03:03:40,055][train][INFO] - Epoch 1371/2000, Val Acc=0.5800, Val Loss=1.8147, lr=0.0100
[2025-05-07 03:03:46,529][train][INFO] - Epoch 1349/2000, Val Acc=0.6267, Val Loss=1.6840, lr=0.0100
[2025-05-07 03:03:47,482][train][INFO] - Epoch 1382/2000, Val Acc=0.6079, Val Loss=1.7770, lr=0.0100
[2025-05-07 03:03:47,781][train][INFO] - Epoch 1372/2000, Val Acc=0.5993, Val Loss=1.6889, lr=0.0100
[2025-05-07 03:03:54,484][train][INFO] - Epoch 1350/2000, Val Acc=0.6078, Val Loss=1.7854, lr=0.0100
[2025-05-07 03:03:55,100][train][INFO] - Epoch 1383/2000, Val Acc=0.6077, Val Loss=1.8111, lr=0.0100
[2025-05-07 03:03:55,561][train][INFO] - Epoch 1373/2000, Val Acc=0.5881, Val Loss=1.7207, lr=0.0100
[2025-05-07 03:04:02,516][train][INFO] - Epoch 1351/2000, Val Acc=0.6180, Val Loss=1.7018, lr=0.0100
[2025-05-07 03:04:03,150][train][INFO] - Epoch 1384/2000, Val Acc=0.6285, Val Loss=1.6798, lr=0.0100
[2025-05-07 03:04:03,506][train][INFO] - Epoch 1374/2000, Val Acc=0.5898, Val Loss=1.7414, lr=0.0100
[2025-05-07 03:04:09,910][train][INFO] - Epoch 1352/2000, Val Acc=0.6253, Val Loss=1.7085, lr=0.0100
[2025-05-07 03:04:10,744][train][INFO] - Epoch 1375/2000, Val Acc=0.5883, Val Loss=1.6863, lr=0.0100
[2025-05-07 03:04:11,159][train][INFO] - Epoch 1385/2000, Val Acc=0.6062, Val Loss=1.7679, lr=0.0100
[2025-05-07 03:04:18,198][train][INFO] - Epoch 1353/2000, Val Acc=0.6042, Val Loss=1.7902, lr=0.0100
[2025-05-07 03:04:18,519][train][INFO] - Epoch 1376/2000, Val Acc=0.6009, Val Loss=1.6687, lr=0.0100
[2025-05-07 03:04:19,390][train][INFO] - Epoch 1386/2000, Val Acc=0.5958, Val Loss=1.8512, lr=0.0100
[2025-05-07 03:04:26,157][train][INFO] - Epoch 1354/2000, Val Acc=0.6104, Val Loss=1.7525, lr=0.0100
[2025-05-07 03:04:26,302][train][INFO] - Epoch 1377/2000, Val Acc=0.6035, Val Loss=1.6400, lr=0.0100
[2025-05-07 03:04:27,346][train][INFO] - Epoch 1387/2000, Val Acc=0.6042, Val Loss=1.7883, lr=0.0100
[2025-05-07 03:04:33,753][train][INFO] - Epoch 1378/2000, Val Acc=0.5896, Val Loss=1.7071, lr=0.0100
[2025-05-07 03:04:33,920][train][INFO] - Epoch 1355/2000, Val Acc=0.6151, Val Loss=1.7470, lr=0.0100
[2025-05-07 03:04:34,840][train][INFO] - Epoch 1388/2000, Val Acc=0.6008, Val Loss=1.8331, lr=0.0100
[2025-05-07 03:04:41,176][train][INFO] - Epoch 1356/2000, Val Acc=0.6204, Val Loss=1.7239, lr=0.0100
[2025-05-07 03:04:41,835][train][INFO] - Epoch 1379/2000, Val Acc=0.5763, Val Loss=1.8115, lr=0.0100
[2025-05-07 03:04:42,389][train][INFO] - Epoch 1389/2000, Val Acc=0.6193, Val Loss=1.7108, lr=0.0100
[2025-05-07 03:04:48,673][train][INFO] - Epoch 1357/2000, Val Acc=0.6207, Val Loss=1.6990, lr=0.0100
[2025-05-07 03:04:49,569][train][INFO] - Epoch 1380/2000, Val Acc=0.5894, Val Loss=1.7124, lr=0.0100
[2025-05-07 03:04:50,286][train][INFO] - Epoch 1390/2000, Val Acc=0.6236, Val Loss=1.6772, lr=0.0100
[2025-05-07 03:04:56,863][train][INFO] - Epoch 1358/2000, Val Acc=0.6160, Val Loss=1.6935, lr=0.0100
[2025-05-07 03:04:57,113][train][INFO] - Epoch 1391/2000, Val Acc=0.6092, Val Loss=1.7297, lr=0.0100
[2025-05-07 03:04:57,240][train][INFO] - Epoch 1381/2000, Val Acc=0.5894, Val Loss=1.6964, lr=0.0100
[2025-05-07 03:05:04,561][train][INFO] - Epoch 1382/2000, Val Acc=0.5807, Val Loss=1.7759, lr=0.0100
[2025-05-07 03:05:04,749][train][INFO] - Epoch 1392/2000, Val Acc=0.6111, Val Loss=1.7446, lr=0.0100
[2025-05-07 03:05:04,787][train][INFO] - Epoch 1359/2000, Val Acc=0.6187, Val Loss=1.6869, lr=0.0100
[2025-05-07 03:05:12,588][train][INFO] - Epoch 1383/2000, Val Acc=0.5948, Val Loss=1.6828, lr=0.0100
[2025-05-07 03:05:12,643][train][INFO] - Epoch 1360/2000, Val Acc=0.6194, Val Loss=1.7105, lr=0.0100
[2025-05-07 03:05:12,688][train][INFO] - Epoch 1393/2000, Val Acc=0.6248, Val Loss=1.6779, lr=0.0100
[2025-05-07 03:05:20,381][train][INFO] - Epoch 1394/2000, Val Acc=0.6226, Val Loss=1.6657, lr=0.0100
[2025-05-07 03:05:20,467][train][INFO] - Epoch 1384/2000, Val Acc=0.5896, Val Loss=1.6957, lr=0.0100
[2025-05-07 03:05:20,793][train][INFO] - Epoch 1361/2000, Val Acc=0.6235, Val Loss=1.6766, lr=0.0100
[2025-05-07 03:05:27,854][train][INFO] - Epoch 1395/2000, Val Acc=0.6143, Val Loss=1.7388, lr=0.0100
[2025-05-07 03:05:28,614][train][INFO] - Epoch 1385/2000, Val Acc=0.5786, Val Loss=1.7715, lr=0.0100
[2025-05-07 03:05:29,133][train][INFO] - Epoch 1362/2000, Val Acc=0.6154, Val Loss=1.7296, lr=0.0100
[2025-05-07 03:05:34,941][train][INFO] - Epoch 1396/2000, Val Acc=0.6011, Val Loss=1.8377, lr=0.0100
[2025-05-07 03:05:36,661][train][INFO] - Epoch 1386/2000, Val Acc=0.5905, Val Loss=1.7156, lr=0.0100
[2025-05-07 03:05:37,094][train][INFO] - Epoch 1363/2000, Val Acc=0.6242, Val Loss=1.7144, lr=0.0100
[2025-05-07 03:05:42,754][train][INFO] - Epoch 1397/2000, Val Acc=0.6257, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:05:44,175][train][INFO] - Epoch 1387/2000, Val Acc=0.5860, Val Loss=1.7329, lr=0.0100
[2025-05-07 03:05:45,473][train][INFO] - Epoch 1364/2000, Val Acc=0.6228, Val Loss=1.6999, lr=0.0100
[2025-05-07 03:05:50,198][train][INFO] - Epoch 1398/2000, Val Acc=0.6175, Val Loss=1.7395, lr=0.0100
[2025-05-07 03:05:51,367][train][INFO] - Epoch 1388/2000, Val Acc=0.5829, Val Loss=1.6739, lr=0.0100
[2025-05-07 03:05:53,606][train][INFO] - Epoch 1365/2000, Val Acc=0.6182, Val Loss=1.6867, lr=0.0100
[2025-05-07 03:05:57,660][train][INFO] - Epoch 1399/2000, Val Acc=0.6221, Val Loss=1.7294, lr=0.0100
[2025-05-07 03:05:59,154][train][INFO] - Epoch 1389/2000, Val Acc=0.5915, Val Loss=1.7083, lr=0.0100
[2025-05-07 03:06:01,829][train][INFO] - Epoch 1366/2000, Val Acc=0.6022, Val Loss=1.8253, lr=0.0100
[2025-05-07 03:06:05,232][train][INFO] - Epoch 1400/2000, Val Acc=0.6328, Val Loss=1.6030, lr=0.0100
[2025-05-07 03:06:06,643][train][INFO] - Epoch 1390/2000, Val Acc=0.5649, Val Loss=1.8366, lr=0.0100
[2025-05-07 03:06:09,282][train][INFO] - Epoch 1367/2000, Val Acc=0.6011, Val Loss=1.7953, lr=0.0100
[2025-05-07 03:06:12,807][train][INFO] - Epoch 1401/2000, Val Acc=0.6165, Val Loss=1.7214, lr=0.0100
[2025-05-07 03:06:14,569][train][INFO] - Epoch 1391/2000, Val Acc=0.5927, Val Loss=1.6961, lr=0.0100
[2025-05-07 03:06:17,259][train][INFO] - Epoch 1368/2000, Val Acc=0.6106, Val Loss=1.7795, lr=0.0100
[2025-05-07 03:06:20,874][train][INFO] - Epoch 1402/2000, Val Acc=0.6174, Val Loss=1.7231, lr=0.0100
[2025-05-07 03:06:22,460][train][INFO] - Epoch 1392/2000, Val Acc=0.5805, Val Loss=1.7476, lr=0.0100
[2025-05-07 03:06:24,843][train][INFO] - Epoch 1369/2000, Val Acc=0.6191, Val Loss=1.7194, lr=0.0100
[2025-05-07 03:06:28,103][train][INFO] - Epoch 1403/2000, Val Acc=0.6068, Val Loss=1.8058, lr=0.0100
[2025-05-07 03:06:29,979][train][INFO] - Epoch 1393/2000, Val Acc=0.6091, Val Loss=1.5949, lr=0.0100
[2025-05-07 03:06:32,408][train][INFO] - Epoch 1370/2000, Val Acc=0.6054, Val Loss=1.8473, lr=0.0100
[2025-05-07 03:06:35,506][train][INFO] - Epoch 1404/2000, Val Acc=0.6082, Val Loss=1.8048, lr=0.0100
[2025-05-07 03:06:37,260][train][INFO] - Epoch 1394/2000, Val Acc=0.5926, Val Loss=1.6963, lr=0.0100
[2025-05-07 03:06:40,451][train][INFO] - Epoch 1371/2000, Val Acc=0.6147, Val Loss=1.7507, lr=0.0100
[2025-05-07 03:06:43,289][train][INFO] - Epoch 1405/2000, Val Acc=0.6083, Val Loss=1.8043, lr=0.0100
[2025-05-07 03:06:45,138][train][INFO] - Epoch 1395/2000, Val Acc=0.5825, Val Loss=1.7446, lr=0.0100
[2025-05-07 03:06:48,257][train][INFO] - Epoch 1372/2000, Val Acc=0.6288, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:06:51,211][train][INFO] - Epoch 1406/2000, Val Acc=0.6286, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:06:52,796][train][INFO] - Epoch 1396/2000, Val Acc=0.5984, Val Loss=1.6581, lr=0.0100
[2025-05-07 03:06:56,265][train][INFO] - Epoch 1373/2000, Val Acc=0.6238, Val Loss=1.6516, lr=0.0100
[2025-05-07 03:06:58,706][train][INFO] - Epoch 1407/2000, Val Acc=0.6079, Val Loss=1.7755, lr=0.0100
[2025-05-07 03:07:00,479][train][INFO] - Epoch 1397/2000, Val Acc=0.6072, Val Loss=1.6292, lr=0.0100
[2025-05-07 03:07:03,896][train][INFO] - Epoch 1374/2000, Val Acc=0.6206, Val Loss=1.6825, lr=0.0100
[2025-05-07 03:07:06,577][train][INFO] - Epoch 1408/2000, Val Acc=0.6173, Val Loss=1.7405, lr=0.0100
[2025-05-07 03:07:08,020][train][INFO] - Epoch 1398/2000, Val Acc=0.5911, Val Loss=1.6874, lr=0.0100
[2025-05-07 03:07:11,994][train][INFO] - Epoch 1375/2000, Val Acc=0.6235, Val Loss=1.6680, lr=0.0100
[2025-05-07 03:07:14,054][train][INFO] - Epoch 1409/2000, Val Acc=0.6189, Val Loss=1.7110, lr=0.0100
[2025-05-07 03:07:15,793][train][INFO] - Epoch 1399/2000, Val Acc=0.6077, Val Loss=1.6282, lr=0.0100
[2025-05-07 03:07:19,644][train][INFO] - Epoch 1376/2000, Val Acc=0.6141, Val Loss=1.7502, lr=0.0100
[2025-05-07 03:07:21,237][train][INFO] - Epoch 1410/2000, Val Acc=0.6304, Val Loss=1.7015, lr=0.0100
[2025-05-07 03:07:23,422][train][INFO] - Epoch 1400/2000, Val Acc=0.6009, Val Loss=1.6752, lr=0.0100
[2025-05-07 03:07:27,866][train][INFO] - Epoch 1377/2000, Val Acc=0.6346, Val Loss=1.6344, lr=0.0100
[2025-05-07 03:07:28,553][train][INFO] - Epoch 1411/2000, Val Acc=0.6097, Val Loss=1.7801, lr=0.0100
[2025-05-07 03:07:31,482][train][INFO] - Epoch 1401/2000, Val Acc=0.6020, Val Loss=1.6539, lr=0.0100
[2025-05-07 03:07:35,271][train][INFO] - Epoch 1378/2000, Val Acc=0.6193, Val Loss=1.7120, lr=0.0100
[2025-05-07 03:07:36,296][train][INFO] - Epoch 1412/2000, Val Acc=0.6142, Val Loss=1.7350, lr=0.0100
[2025-05-07 03:07:38,989][train][INFO] - Epoch 1402/2000, Val Acc=0.5917, Val Loss=1.7248, lr=0.0100
[2025-05-07 03:07:43,486][train][INFO] - Epoch 1379/2000, Val Acc=0.6138, Val Loss=1.7360, lr=0.0100
[2025-05-07 03:07:43,627][train][INFO] - Epoch 1413/2000, Val Acc=0.6022, Val Loss=1.8489, lr=0.0100
[2025-05-07 03:07:46,519][train][INFO] - Epoch 1403/2000, Val Acc=0.5805, Val Loss=1.7576, lr=0.0100
[2025-05-07 03:07:50,930][train][INFO] - Epoch 1380/2000, Val Acc=0.6192, Val Loss=1.7092, lr=0.0100
[2025-05-07 03:07:51,526][train][INFO] - Epoch 1414/2000, Val Acc=0.6287, Val Loss=1.6733, lr=0.0100
[2025-05-07 03:07:54,190][train][INFO] - Epoch 1404/2000, Val Acc=0.5979, Val Loss=1.6601, lr=0.0100
[2025-05-07 03:07:58,694][train][INFO] - Epoch 1381/2000, Val Acc=0.6178, Val Loss=1.7156, lr=0.0100
[2025-05-07 03:07:59,272][train][INFO] - Epoch 1415/2000, Val Acc=0.6123, Val Loss=1.7533, lr=0.0100
[2025-05-07 03:08:01,318][train][INFO] - Epoch 1405/2000, Val Acc=0.5776, Val Loss=1.7961, lr=0.0100
[2025-05-07 03:08:06,048][train][INFO] - Epoch 1382/2000, Val Acc=0.6079, Val Loss=1.7770, lr=0.0100
[2025-05-07 03:08:06,524][train][INFO] - Epoch 1416/2000, Val Acc=0.6212, Val Loss=1.7097, lr=0.0100
[2025-05-07 03:08:08,851][train][INFO] - Epoch 1406/2000, Val Acc=0.5992, Val Loss=1.6754, lr=0.0100
[2025-05-07 03:08:13,790][train][INFO] - Epoch 1383/2000, Val Acc=0.6077, Val Loss=1.8111, lr=0.0100
[2025-05-07 03:08:14,165][train][INFO] - Epoch 1417/2000, Val Acc=0.6082, Val Loss=1.7763, lr=0.0100
[2025-05-07 03:08:16,341][train][INFO] - Epoch 1407/2000, Val Acc=0.5979, Val Loss=1.6851, lr=0.0100
[2025-05-07 03:08:21,246][train][INFO] - Epoch 1418/2000, Val Acc=0.6113, Val Loss=1.7743, lr=0.0100
[2025-05-07 03:08:21,987][train][INFO] - Epoch 1384/2000, Val Acc=0.6285, Val Loss=1.6798, lr=0.0100
[2025-05-07 03:08:24,039][train][INFO] - Epoch 1408/2000, Val Acc=0.5887, Val Loss=1.6972, lr=0.0100
[2025-05-07 03:08:28,221][train][INFO] - Epoch 1419/2000, Val Acc=0.6205, Val Loss=1.6875, lr=0.0100
[2025-05-07 03:08:29,844][train][INFO] - Epoch 1385/2000, Val Acc=0.6062, Val Loss=1.7679, lr=0.0100
[2025-05-07 03:08:31,855][train][INFO] - Epoch 1409/2000, Val Acc=0.6139, Val Loss=1.5979, lr=0.0100
[2025-05-07 03:08:35,933][train][INFO] - Epoch 1420/2000, Val Acc=0.6296, Val Loss=1.6654, lr=0.0100
[2025-05-07 03:08:37,601][train][INFO] - Epoch 1386/2000, Val Acc=0.5958, Val Loss=1.8512, lr=0.0100
[2025-05-07 03:08:39,729][train][INFO] - Epoch 1410/2000, Val Acc=0.5862, Val Loss=1.7311, lr=0.0100
[2025-05-07 03:08:43,247][train][INFO] - Epoch 1421/2000, Val Acc=0.6117, Val Loss=1.7481, lr=0.0100
[2025-05-07 03:08:45,563][train][INFO] - Epoch 1387/2000, Val Acc=0.6042, Val Loss=1.7883, lr=0.0100
[2025-05-07 03:08:47,572][train][INFO] - Epoch 1411/2000, Val Acc=0.5775, Val Loss=1.8264, lr=0.0100
[2025-05-07 03:08:50,795][train][INFO] - Epoch 1422/2000, Val Acc=0.6095, Val Loss=1.7772, lr=0.0100
[2025-05-07 03:08:53,034][train][INFO] - Epoch 1388/2000, Val Acc=0.6008, Val Loss=1.8331, lr=0.0100
[2025-05-07 03:08:55,169][train][INFO] - Epoch 1412/2000, Val Acc=0.5918, Val Loss=1.6842, lr=0.0100
[2025-05-07 03:08:58,712][train][INFO] - Epoch 1423/2000, Val Acc=0.6058, Val Loss=1.8372, lr=0.0100
[2025-05-07 03:09:01,217][train][INFO] - Epoch 1389/2000, Val Acc=0.6193, Val Loss=1.7108, lr=0.0100
[2025-05-07 03:09:02,878][train][INFO] - Epoch 1413/2000, Val Acc=0.5774, Val Loss=1.8318, lr=0.0100
[2025-05-07 03:09:06,337][train][INFO] - Epoch 1424/2000, Val Acc=0.6225, Val Loss=1.6607, lr=0.0100
[2025-05-07 03:09:08,995][train][INFO] - Epoch 1390/2000, Val Acc=0.6236, Val Loss=1.6772, lr=0.0100
[2025-05-07 03:09:10,899][train][INFO] - Epoch 1414/2000, Val Acc=0.5987, Val Loss=1.6628, lr=0.0100
[2025-05-07 03:09:13,960][train][INFO] - Epoch 1425/2000, Val Acc=0.6059, Val Loss=1.8076, lr=0.0100
[2025-05-07 03:09:16,565][train][INFO] - Epoch 1391/2000, Val Acc=0.6092, Val Loss=1.7297, lr=0.0100
[2025-05-07 03:09:18,792][train][INFO] - Epoch 1415/2000, Val Acc=0.5873, Val Loss=1.7291, lr=0.0100
[2025-05-07 03:09:21,305][train][INFO] - Epoch 1426/2000, Val Acc=0.6221, Val Loss=1.6903, lr=0.0100
[2025-05-07 03:09:24,389][train][INFO] - Epoch 1392/2000, Val Acc=0.6111, Val Loss=1.7446, lr=0.0100
[2025-05-07 03:09:26,253][train][INFO] - Epoch 1416/2000, Val Acc=0.6068, Val Loss=1.6331, lr=0.0100
[2025-05-07 03:09:28,737][train][INFO] - Epoch 1427/2000, Val Acc=0.6237, Val Loss=1.6942, lr=0.0100
[2025-05-07 03:09:32,435][train][INFO] - Epoch 1393/2000, Val Acc=0.6248, Val Loss=1.6779, lr=0.0100
[2025-05-07 03:09:33,910][train][INFO] - Epoch 1417/2000, Val Acc=0.5818, Val Loss=1.7532, lr=0.0100
[2025-05-07 03:09:36,216][train][INFO] - Epoch 1428/2000, Val Acc=0.5933, Val Loss=1.8944, lr=0.0100
[2025-05-07 03:09:40,779][train][INFO] - Epoch 1394/2000, Val Acc=0.6226, Val Loss=1.6657, lr=0.0100
[2025-05-07 03:09:41,541][train][INFO] - Epoch 1418/2000, Val Acc=0.5907, Val Loss=1.6972, lr=0.0100
[2025-05-07 03:09:43,717][train][INFO] - Epoch 1429/2000, Val Acc=0.6206, Val Loss=1.7043, lr=0.0100
[2025-05-07 03:09:48,885][train][INFO] - Epoch 1395/2000, Val Acc=0.6143, Val Loss=1.7388, lr=0.0100
[2025-05-07 03:09:49,193][train][INFO] - Epoch 1419/2000, Val Acc=0.5782, Val Loss=1.8031, lr=0.0100
[2025-05-07 03:09:51,229][train][INFO] - Epoch 1430/2000, Val Acc=0.6086, Val Loss=1.7564, lr=0.0100
[2025-05-07 03:09:56,920][train][INFO] - Epoch 1420/2000, Val Acc=0.5933, Val Loss=1.6698, lr=0.0100
[2025-05-07 03:09:57,075][train][INFO] - Epoch 1396/2000, Val Acc=0.6011, Val Loss=1.8377, lr=0.0100
[2025-05-07 03:09:58,719][train][INFO] - Epoch 1431/2000, Val Acc=0.5931, Val Loss=1.8941, lr=0.0100
[2025-05-07 03:10:04,267][train][INFO] - Epoch 1421/2000, Val Acc=0.5738, Val Loss=1.8628, lr=0.0100
[2025-05-07 03:10:05,489][train][INFO] - Epoch 1397/2000, Val Acc=0.6257, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:10:05,894][train][INFO] - Epoch 1432/2000, Val Acc=0.6120, Val Loss=1.7457, lr=0.0100
[2025-05-07 03:10:11,835][train][INFO] - Epoch 1422/2000, Val Acc=0.5956, Val Loss=1.6662, lr=0.0100
[2025-05-07 03:10:13,752][train][INFO] - Epoch 1433/2000, Val Acc=0.6158, Val Loss=1.6824, lr=0.0100
[2025-05-07 03:10:13,789][train][INFO] - Epoch 1398/2000, Val Acc=0.6175, Val Loss=1.7395, lr=0.0100
[2025-05-07 03:10:19,501][train][INFO] - Epoch 1423/2000, Val Acc=0.5963, Val Loss=1.7189, lr=0.0100
[2025-05-07 03:10:21,605][train][INFO] - Epoch 1434/2000, Val Acc=0.6270, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:10:21,703][train][INFO] - Epoch 1399/2000, Val Acc=0.6221, Val Loss=1.7294, lr=0.0100
[2025-05-07 03:10:27,344][train][INFO] - Epoch 1424/2000, Val Acc=0.6026, Val Loss=1.6891, lr=0.0100
[2025-05-07 03:10:29,345][train][INFO] - Epoch 1435/2000, Val Acc=0.6202, Val Loss=1.6724, lr=0.0100
[2025-05-07 03:10:29,562][train][INFO] - Epoch 1400/2000, Val Acc=0.6328, Val Loss=1.6030, lr=0.0100
[2025-05-07 03:10:35,289][train][INFO] - Epoch 1425/2000, Val Acc=0.6061, Val Loss=1.6428, lr=0.0100
[2025-05-07 03:10:37,304][train][INFO] - Epoch 1436/2000, Val Acc=0.6112, Val Loss=1.7408, lr=0.0100
[2025-05-07 03:10:37,538][train][INFO] - Epoch 1401/2000, Val Acc=0.6165, Val Loss=1.7214, lr=0.0100
[2025-05-07 03:10:43,343][train][INFO] - Epoch 1426/2000, Val Acc=0.5879, Val Loss=1.6943, lr=0.0100
[2025-05-07 03:10:45,144][train][INFO] - Epoch 1437/2000, Val Acc=0.6103, Val Loss=1.7191, lr=0.0100
[2025-05-07 03:10:45,708][train][INFO] - Epoch 1402/2000, Val Acc=0.6174, Val Loss=1.7231, lr=0.0100
[2025-05-07 03:10:51,146][train][INFO] - Epoch 1427/2000, Val Acc=0.5840, Val Loss=1.7462, lr=0.0100
[2025-05-07 03:10:52,750][train][INFO] - Epoch 1438/2000, Val Acc=0.6185, Val Loss=1.7329, lr=0.0100
[2025-05-07 03:10:53,774][train][INFO] - Epoch 1403/2000, Val Acc=0.6068, Val Loss=1.8058, lr=0.0100
[2025-05-07 03:10:58,747][train][INFO] - Epoch 1428/2000, Val Acc=0.5797, Val Loss=1.7715, lr=0.0100
[2025-05-07 03:11:00,573][train][INFO] - Epoch 1439/2000, Val Acc=0.6182, Val Loss=1.7504, lr=0.0100
[2025-05-07 03:11:01,818][train][INFO] - Epoch 1404/2000, Val Acc=0.6082, Val Loss=1.8048, lr=0.0100
[2025-05-07 03:11:05,836][train][INFO] - Epoch 1429/2000, Val Acc=0.5910, Val Loss=1.6855, lr=0.0100
[2025-05-07 03:11:08,278][train][INFO] - Epoch 1440/2000, Val Acc=0.6143, Val Loss=1.7410, lr=0.0100
[2025-05-07 03:11:09,457][train][INFO] - Epoch 1405/2000, Val Acc=0.6083, Val Loss=1.8043, lr=0.0100
[2025-05-07 03:11:13,483][train][INFO] - Epoch 1430/2000, Val Acc=0.6009, Val Loss=1.6508, lr=0.0100
[2025-05-07 03:11:16,296][train][INFO] - Epoch 1441/2000, Val Acc=0.6263, Val Loss=1.6950, lr=0.0100
[2025-05-07 03:11:17,750][train][INFO] - Epoch 1406/2000, Val Acc=0.6286, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:11:21,331][train][INFO] - Epoch 1431/2000, Val Acc=0.5877, Val Loss=1.7122, lr=0.0100
[2025-05-07 03:11:23,903][train][INFO] - Epoch 1442/2000, Val Acc=0.6034, Val Loss=1.8296, lr=0.0100
[2025-05-07 03:11:25,318][train][INFO] - Epoch 1407/2000, Val Acc=0.6079, Val Loss=1.7755, lr=0.0100
[2025-05-07 03:11:28,806][train][INFO] - Epoch 1432/2000, Val Acc=0.5986, Val Loss=1.6748, lr=0.0100
[2025-05-07 03:11:31,349][train][INFO] - Epoch 1443/2000, Val Acc=0.5968, Val Loss=1.8907, lr=0.0100
[2025-05-07 03:11:33,526][train][INFO] - Epoch 1408/2000, Val Acc=0.6173, Val Loss=1.7405, lr=0.0100
[2025-05-07 03:11:36,125][train][INFO] - Epoch 1433/2000, Val Acc=0.5811, Val Loss=1.7720, lr=0.0100
[2025-05-07 03:11:39,128][train][INFO] - Epoch 1444/2000, Val Acc=0.6113, Val Loss=1.7877, lr=0.0100
[2025-05-07 03:11:41,319][train][INFO] - Epoch 1409/2000, Val Acc=0.6189, Val Loss=1.7110, lr=0.0100
[2025-05-07 03:11:43,838][train][INFO] - Epoch 1434/2000, Val Acc=0.5943, Val Loss=1.6844, lr=0.0100
[2025-05-07 03:11:46,229][train][INFO] - Epoch 1445/2000, Val Acc=0.6205, Val Loss=1.7385, lr=0.0100
[2025-05-07 03:11:49,454][train][INFO] - Epoch 1410/2000, Val Acc=0.6304, Val Loss=1.7015, lr=0.0100
[2025-05-07 03:11:51,651][train][INFO] - Epoch 1435/2000, Val Acc=0.5908, Val Loss=1.6845, lr=0.0100
[2025-05-07 03:11:53,944][train][INFO] - Epoch 1446/2000, Val Acc=0.6249, Val Loss=1.7110, lr=0.0100
[2025-05-07 03:11:57,244][train][INFO] - Epoch 1411/2000, Val Acc=0.6097, Val Loss=1.7801, lr=0.0100
[2025-05-07 03:11:59,210][train][INFO] - Epoch 1436/2000, Val Acc=0.6030, Val Loss=1.6380, lr=0.0100
[2025-05-07 03:12:01,616][train][INFO] - Epoch 1447/2000, Val Acc=0.6230, Val Loss=1.6986, lr=0.0100
[2025-05-07 03:12:05,317][train][INFO] - Epoch 1412/2000, Val Acc=0.6142, Val Loss=1.7350, lr=0.0100
[2025-05-07 03:12:06,832][train][INFO] - Epoch 1437/2000, Val Acc=0.5833, Val Loss=1.7363, lr=0.0100
[2025-05-07 03:12:08,737][train][INFO] - Epoch 1448/2000, Val Acc=0.6254, Val Loss=1.6835, lr=0.0100
[2025-05-07 03:12:13,406][train][INFO] - Epoch 1413/2000, Val Acc=0.6022, Val Loss=1.8489, lr=0.0100
[2025-05-07 03:12:14,511][train][INFO] - Epoch 1438/2000, Val Acc=0.5994, Val Loss=1.6613, lr=0.0100
[2025-05-07 03:12:16,492][train][INFO] - Epoch 1449/2000, Val Acc=0.6219, Val Loss=1.7012, lr=0.0100
[2025-05-07 03:12:21,204][train][INFO] - Epoch 1439/2000, Val Acc=0.5846, Val Loss=1.7379, lr=0.0100
[2025-05-07 03:12:21,230][train][INFO] - Epoch 1414/2000, Val Acc=0.6287, Val Loss=1.6733, lr=0.0100
[2025-05-07 03:12:24,153][train][INFO] - Epoch 1450/2000, Val Acc=0.6233, Val Loss=1.7257, lr=0.0100
[2025-05-07 03:12:28,582][train][INFO] - Epoch 1440/2000, Val Acc=0.5882, Val Loss=1.7212, lr=0.0100
[2025-05-07 03:12:29,217][train][INFO] - Epoch 1415/2000, Val Acc=0.6123, Val Loss=1.7533, lr=0.0100
[2025-05-07 03:12:31,897][train][INFO] - Epoch 1451/2000, Val Acc=0.6272, Val Loss=1.6820, lr=0.0100
[2025-05-07 03:12:35,903][train][INFO] - Epoch 1441/2000, Val Acc=0.5917, Val Loss=1.6964, lr=0.0100
[2025-05-07 03:12:37,108][train][INFO] - Epoch 1416/2000, Val Acc=0.6212, Val Loss=1.7097, lr=0.0100
[2025-05-07 03:12:39,671][train][INFO] - Epoch 1452/2000, Val Acc=0.6277, Val Loss=1.6662, lr=0.0100
[2025-05-07 03:12:43,864][train][INFO] - Epoch 1442/2000, Val Acc=0.5921, Val Loss=1.6929, lr=0.0100
[2025-05-07 03:12:44,795][train][INFO] - Epoch 1417/2000, Val Acc=0.6082, Val Loss=1.7763, lr=0.0100
[2025-05-07 03:12:47,253][train][INFO] - Epoch 1453/2000, Val Acc=0.6264, Val Loss=1.7104, lr=0.0100
[2025-05-07 03:12:51,606][train][INFO] - Epoch 1443/2000, Val Acc=0.5959, Val Loss=1.6836, lr=0.0100
[2025-05-07 03:12:52,756][train][INFO] - Epoch 1418/2000, Val Acc=0.6113, Val Loss=1.7743, lr=0.0100
[2025-05-07 03:12:55,013][train][INFO] - Epoch 1454/2000, Val Acc=0.6180, Val Loss=1.7230, lr=0.0100
[2025-05-07 03:12:59,388][train][INFO] - Epoch 1444/2000, Val Acc=0.6013, Val Loss=1.6810, lr=0.0100
[2025-05-07 03:13:00,473][train][INFO] - Epoch 1419/2000, Val Acc=0.6205, Val Loss=1.6875, lr=0.0100
[2025-05-07 03:13:02,620][train][INFO] - Epoch 1455/2000, Val Acc=0.6330, Val Loss=1.6345, lr=0.0100
[2025-05-07 03:13:06,934][train][INFO] - Epoch 1445/2000, Val Acc=0.5842, Val Loss=1.7482, lr=0.0100
[2025-05-07 03:13:08,230][train][INFO] - Epoch 1420/2000, Val Acc=0.6296, Val Loss=1.6654, lr=0.0100
[2025-05-07 03:13:10,384][train][INFO] - Epoch 1456/2000, Val Acc=0.6380, Val Loss=1.6241, lr=0.0100
[2025-05-07 03:13:14,930][train][INFO] - Epoch 1446/2000, Val Acc=0.5854, Val Loss=1.7217, lr=0.0100
[2025-05-07 03:13:16,438][train][INFO] - Epoch 1421/2000, Val Acc=0.6117, Val Loss=1.7481, lr=0.0100
[2025-05-07 03:13:17,987][train][INFO] - Epoch 1457/2000, Val Acc=0.6216, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:13:22,476][train][INFO] - Epoch 1447/2000, Val Acc=0.5990, Val Loss=1.7069, lr=0.0100
[2025-05-07 03:13:24,380][train][INFO] - Epoch 1422/2000, Val Acc=0.6095, Val Loss=1.7772, lr=0.0100
[2025-05-07 03:13:25,270][train][INFO] - Epoch 1458/2000, Val Acc=0.6060, Val Loss=1.7999, lr=0.0100
[2025-05-07 03:13:30,343][train][INFO] - Epoch 1448/2000, Val Acc=0.5801, Val Loss=1.7425, lr=0.0100
[2025-05-07 03:13:32,550][train][INFO] - Epoch 1423/2000, Val Acc=0.6058, Val Loss=1.8372, lr=0.0100
[2025-05-07 03:13:32,994][train][INFO] - Epoch 1459/2000, Val Acc=0.6257, Val Loss=1.6645, lr=0.0100
[2025-05-07 03:13:37,815][train][INFO] - Epoch 1449/2000, Val Acc=0.5988, Val Loss=1.6333, lr=0.0100
[2025-05-07 03:13:40,659][train][INFO] - Epoch 1424/2000, Val Acc=0.6225, Val Loss=1.6607, lr=0.0100
[2025-05-07 03:13:40,868][train][INFO] - Epoch 1460/2000, Val Acc=0.6221, Val Loss=1.6464, lr=0.0100
[2025-05-07 03:13:45,800][train][INFO] - Epoch 1450/2000, Val Acc=0.5985, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:13:48,178][train][INFO] - Epoch 1461/2000, Val Acc=0.6187, Val Loss=1.7075, lr=0.0100
[2025-05-07 03:13:48,267][train][INFO] - Epoch 1425/2000, Val Acc=0.6059, Val Loss=1.8076, lr=0.0100
[2025-05-07 03:13:53,257][train][INFO] - Epoch 1451/2000, Val Acc=0.5858, Val Loss=1.7255, lr=0.0100
[2025-05-07 03:13:55,598][train][INFO] - Epoch 1462/2000, Val Acc=0.6231, Val Loss=1.7011, lr=0.0100
[2025-05-07 03:13:55,887][train][INFO] - Epoch 1426/2000, Val Acc=0.6221, Val Loss=1.6903, lr=0.0100
[2025-05-07 03:14:01,011][train][INFO] - Epoch 1452/2000, Val Acc=0.5814, Val Loss=1.7531, lr=0.0100
[2025-05-07 03:14:03,141][train][INFO] - Epoch 1463/2000, Val Acc=0.5948, Val Loss=1.8931, lr=0.0100
[2025-05-07 03:14:03,731][train][INFO] - Epoch 1427/2000, Val Acc=0.6237, Val Loss=1.6942, lr=0.0100
[2025-05-07 03:14:08,110][train][INFO] - Epoch 1453/2000, Val Acc=0.5840, Val Loss=1.7942, lr=0.0100
[2025-05-07 03:14:10,564][train][INFO] - Epoch 1464/2000, Val Acc=0.6259, Val Loss=1.6537, lr=0.0100
[2025-05-07 03:14:11,292][train][INFO] - Epoch 1428/2000, Val Acc=0.5933, Val Loss=1.8944, lr=0.0100
[2025-05-07 03:14:15,756][train][INFO] - Epoch 1454/2000, Val Acc=0.5860, Val Loss=1.7534, lr=0.0100
[2025-05-07 03:14:18,108][train][INFO] - Epoch 1465/2000, Val Acc=0.6092, Val Loss=1.7734, lr=0.0100
[2025-05-07 03:14:19,235][train][INFO] - Epoch 1429/2000, Val Acc=0.6206, Val Loss=1.7043, lr=0.0100
[2025-05-07 03:14:23,200][train][INFO] - Epoch 1455/2000, Val Acc=0.5905, Val Loss=1.6768, lr=0.0100
[2025-05-07 03:14:25,765][train][INFO] - Epoch 1466/2000, Val Acc=0.6326, Val Loss=1.6532, lr=0.0100
[2025-05-07 03:14:26,942][train][INFO] - Epoch 1430/2000, Val Acc=0.6086, Val Loss=1.7564, lr=0.0100
[2025-05-07 03:14:31,157][train][INFO] - Epoch 1456/2000, Val Acc=0.5891, Val Loss=1.6954, lr=0.0100
[2025-05-07 03:14:33,882][train][INFO] - Epoch 1467/2000, Val Acc=0.6297, Val Loss=1.6899, lr=0.0100
[2025-05-07 03:14:34,782][train][INFO] - Epoch 1431/2000, Val Acc=0.5931, Val Loss=1.8941, lr=0.0100
[2025-05-07 03:14:39,051][train][INFO] - Epoch 1457/2000, Val Acc=0.5902, Val Loss=1.7011, lr=0.0100
[2025-05-07 03:14:41,150][train][INFO] - Epoch 1468/2000, Val Acc=0.6172, Val Loss=1.6983, lr=0.0100
[2025-05-07 03:14:42,934][train][INFO] - Epoch 1432/2000, Val Acc=0.6120, Val Loss=1.7457, lr=0.0100
[2025-05-07 03:14:46,747][train][INFO] - Epoch 1458/2000, Val Acc=0.5997, Val Loss=1.6580, lr=0.0100
[2025-05-07 03:14:48,430][train][INFO] - Epoch 1469/2000, Val Acc=0.6150, Val Loss=1.7665, lr=0.0100
[2025-05-07 03:14:50,846][train][INFO] - Epoch 1433/2000, Val Acc=0.6158, Val Loss=1.6824, lr=0.0100
[2025-05-07 03:14:54,152][train][INFO] - Epoch 1459/2000, Val Acc=0.5908, Val Loss=1.6941, lr=0.0100
[2025-05-07 03:14:55,770][train][INFO] - Epoch 1470/2000, Val Acc=0.6336, Val Loss=1.6572, lr=0.0100
[2025-05-07 03:14:58,577][train][INFO] - Epoch 1434/2000, Val Acc=0.6270, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:15:02,013][train][INFO] - Epoch 1460/2000, Val Acc=0.5918, Val Loss=1.6981, lr=0.0100
[2025-05-07 03:15:03,790][train][INFO] - Epoch 1471/2000, Val Acc=0.6172, Val Loss=1.7474, lr=0.0100
[2025-05-07 03:15:05,843][train][INFO] - Epoch 1435/2000, Val Acc=0.6202, Val Loss=1.6724, lr=0.0100
[2025-05-07 03:15:09,831][train][INFO] - Epoch 1461/2000, Val Acc=0.5985, Val Loss=1.6713, lr=0.0100
[2025-05-07 03:15:11,614][train][INFO] - Epoch 1472/2000, Val Acc=0.6149, Val Loss=1.7559, lr=0.0100
[2025-05-07 03:15:14,017][train][INFO] - Epoch 1436/2000, Val Acc=0.6112, Val Loss=1.7408, lr=0.0100
[2025-05-07 03:15:17,242][train][INFO] - Epoch 1462/2000, Val Acc=0.5847, Val Loss=1.7079, lr=0.0100
[2025-05-07 03:15:18,875][train][INFO] - Epoch 1473/2000, Val Acc=0.6088, Val Loss=1.7985, lr=0.0100
[2025-05-07 03:15:21,942][train][INFO] - Epoch 1437/2000, Val Acc=0.6103, Val Loss=1.7191, lr=0.0100
[2025-05-07 03:15:24,832][train][INFO] - Epoch 1463/2000, Val Acc=0.5861, Val Loss=1.7076, lr=0.0100
[2025-05-07 03:15:26,504][train][INFO] - Epoch 1474/2000, Val Acc=0.6202, Val Loss=1.6816, lr=0.0100
[2025-05-07 03:15:30,100][train][INFO] - Epoch 1438/2000, Val Acc=0.6185, Val Loss=1.7329, lr=0.0100
[2025-05-07 03:15:32,612][train][INFO] - Epoch 1464/2000, Val Acc=0.6024, Val Loss=1.6431, lr=0.0100
[2025-05-07 03:15:33,867][train][INFO] - Epoch 1475/2000, Val Acc=0.6264, Val Loss=1.6563, lr=0.0100
[2025-05-07 03:15:37,380][train][INFO] - Epoch 1439/2000, Val Acc=0.6182, Val Loss=1.7504, lr=0.0100
[2025-05-07 03:15:40,151][train][INFO] - Epoch 1465/2000, Val Acc=0.5921, Val Loss=1.6763, lr=0.0100
[2025-05-07 03:15:41,500][train][INFO] - Epoch 1476/2000, Val Acc=0.6196, Val Loss=1.6924, lr=0.0100
[2025-05-07 03:15:45,426][train][INFO] - Epoch 1440/2000, Val Acc=0.6143, Val Loss=1.7410, lr=0.0100
[2025-05-07 03:15:48,166][train][INFO] - Epoch 1466/2000, Val Acc=0.5943, Val Loss=1.6775, lr=0.0100
[2025-05-07 03:15:49,072][train][INFO] - Epoch 1477/2000, Val Acc=0.6049, Val Loss=1.7989, lr=0.0100
[2025-05-07 03:15:53,141][train][INFO] - Epoch 1441/2000, Val Acc=0.6263, Val Loss=1.6950, lr=0.0100
[2025-05-07 03:15:55,995][train][INFO] - Epoch 1467/2000, Val Acc=0.5881, Val Loss=1.7364, lr=0.0100
[2025-05-07 03:15:56,721][train][INFO] - Epoch 1478/2000, Val Acc=0.6056, Val Loss=1.7970, lr=0.0100
[2025-05-07 03:16:00,940][train][INFO] - Epoch 1442/2000, Val Acc=0.6034, Val Loss=1.8296, lr=0.0100
[2025-05-07 03:16:03,543][train][INFO] - Epoch 1468/2000, Val Acc=0.5812, Val Loss=1.7491, lr=0.0100
[2025-05-07 03:16:04,374][train][INFO] - Epoch 1479/2000, Val Acc=0.6295, Val Loss=1.6708, lr=0.0100
[2025-05-07 03:16:08,693][train][INFO] - Epoch 1443/2000, Val Acc=0.5968, Val Loss=1.8907, lr=0.0100
[2025-05-07 03:16:11,379][train][INFO] - Epoch 1469/2000, Val Acc=0.5911, Val Loss=1.7059, lr=0.0100
[2025-05-07 03:16:11,831][train][INFO] - Epoch 1480/2000, Val Acc=0.6296, Val Loss=1.6658, lr=0.0100
[2025-05-07 03:16:16,480][train][INFO] - Epoch 1444/2000, Val Acc=0.6113, Val Loss=1.7877, lr=0.0100
[2025-05-07 03:16:18,908][train][INFO] - Epoch 1470/2000, Val Acc=0.6021, Val Loss=1.6354, lr=0.0100
[2025-05-07 03:16:19,921][train][INFO] - Epoch 1481/2000, Val Acc=0.6211, Val Loss=1.6665, lr=0.0100
[2025-05-07 03:16:24,274][train][INFO] - Epoch 1445/2000, Val Acc=0.6205, Val Loss=1.7385, lr=0.0100
[2025-05-07 03:16:26,086][train][INFO] - Epoch 1471/2000, Val Acc=0.5849, Val Loss=1.7575, lr=0.0100
[2025-05-07 03:16:27,566][train][INFO] - Epoch 1482/2000, Val Acc=0.6256, Val Loss=1.6707, lr=0.0100
[2025-05-07 03:16:32,195][train][INFO] - Epoch 1446/2000, Val Acc=0.6249, Val Loss=1.7110, lr=0.0100
[2025-05-07 03:16:33,726][train][INFO] - Epoch 1472/2000, Val Acc=0.5669, Val Loss=1.8697, lr=0.0100
[2025-05-07 03:16:35,235][train][INFO] - Epoch 1483/2000, Val Acc=0.6162, Val Loss=1.7315, lr=0.0100
[2025-05-07 03:16:39,968][train][INFO] - Epoch 1447/2000, Val Acc=0.6230, Val Loss=1.6986, lr=0.0100
[2025-05-07 03:16:41,032][train][INFO] - Epoch 1473/2000, Val Acc=0.5773, Val Loss=1.7907, lr=0.0100
[2025-05-07 03:16:42,711][train][INFO] - Epoch 1484/2000, Val Acc=0.6102, Val Loss=1.7203, lr=0.0100
[2025-05-07 03:16:47,478][train][INFO] - Epoch 1448/2000, Val Acc=0.6254, Val Loss=1.6835, lr=0.0100
[2025-05-07 03:16:48,695][train][INFO] - Epoch 1474/2000, Val Acc=0.6036, Val Loss=1.6417, lr=0.0100
[2025-05-07 03:16:50,341][train][INFO] - Epoch 1485/2000, Val Acc=0.6078, Val Loss=1.7845, lr=0.0100
[2025-05-07 03:16:55,270][train][INFO] - Epoch 1449/2000, Val Acc=0.6219, Val Loss=1.7012, lr=0.0100
[2025-05-07 03:16:56,107][train][INFO] - Epoch 1475/2000, Val Acc=0.5981, Val Loss=1.7198, lr=0.0100
[2025-05-07 03:16:57,341][train][INFO] - Epoch 1486/2000, Val Acc=0.6332, Val Loss=1.6259, lr=0.0100
[2025-05-07 03:17:03,173][train][INFO] - Epoch 1450/2000, Val Acc=0.6233, Val Loss=1.7257, lr=0.0100
[2025-05-07 03:17:03,737][train][INFO] - Epoch 1476/2000, Val Acc=0.5945, Val Loss=1.6751, lr=0.0100
[2025-05-07 03:17:05,107][train][INFO] - Epoch 1487/2000, Val Acc=0.6058, Val Loss=1.8319, lr=0.0100
[2025-05-07 03:17:11,040][train][INFO] - Epoch 1451/2000, Val Acc=0.6272, Val Loss=1.6820, lr=0.0100
[2025-05-07 03:17:11,616][train][INFO] - Epoch 1477/2000, Val Acc=0.5691, Val Loss=1.7940, lr=0.0100
[2025-05-07 03:17:12,680][train][INFO] - Epoch 1488/2000, Val Acc=0.6191, Val Loss=1.7479, lr=0.0100
[2025-05-07 03:17:19,064][train][INFO] - Epoch 1452/2000, Val Acc=0.6277, Val Loss=1.6662, lr=0.0100
[2025-05-07 03:17:19,431][train][INFO] - Epoch 1478/2000, Val Acc=0.5832, Val Loss=1.7420, lr=0.0100
[2025-05-07 03:17:20,915][train][INFO] - Epoch 1489/2000, Val Acc=0.6100, Val Loss=1.7852, lr=0.0100
[2025-05-07 03:17:26,567][train][INFO] - Epoch 1479/2000, Val Acc=0.5955, Val Loss=1.6803, lr=0.0100
[2025-05-07 03:17:26,617][train][INFO] - Epoch 1453/2000, Val Acc=0.6264, Val Loss=1.7104, lr=0.0100
[2025-05-07 03:17:28,291][train][INFO] - Epoch 1490/2000, Val Acc=0.6225, Val Loss=1.6572, lr=0.0100
[2025-05-07 03:17:33,994][train][INFO] - Epoch 1480/2000, Val Acc=0.6021, Val Loss=1.6728, lr=0.0100
[2025-05-07 03:17:34,894][train][INFO] - Epoch 1454/2000, Val Acc=0.6180, Val Loss=1.7230, lr=0.0100
[2025-05-07 03:17:35,632][train][INFO] - Epoch 1491/2000, Val Acc=0.6084, Val Loss=1.7747, lr=0.0100
[2025-05-07 03:17:41,245][train][INFO] - Epoch 1481/2000, Val Acc=0.5768, Val Loss=1.7606, lr=0.0100
[2025-05-07 03:17:42,969][train][INFO] - Epoch 1492/2000, Val Acc=0.6048, Val Loss=1.7658, lr=0.0100
[2025-05-07 03:17:43,138][train][INFO] - Epoch 1455/2000, Val Acc=0.6330, Val Loss=1.6345, lr=0.0100
[2025-05-07 03:17:48,873][train][INFO] - Epoch 1482/2000, Val Acc=0.5695, Val Loss=1.7875, lr=0.0100
[2025-05-07 03:17:50,996][train][INFO] - Epoch 1493/2000, Val Acc=0.6210, Val Loss=1.6830, lr=0.0100
[2025-05-07 03:17:51,583][train][INFO] - Epoch 1456/2000, Val Acc=0.6380, Val Loss=1.6241, lr=0.0100
[2025-05-07 03:17:56,546][train][INFO] - Epoch 1483/2000, Val Acc=0.5912, Val Loss=1.7000, lr=0.0100
[2025-05-07 03:17:58,779][train][INFO] - Epoch 1494/2000, Val Acc=0.6194, Val Loss=1.7075, lr=0.0100
[2025-05-07 03:17:59,461][train][INFO] - Epoch 1457/2000, Val Acc=0.6216, Val Loss=1.6660, lr=0.0100
[2025-05-07 03:18:04,344][train][INFO] - Epoch 1484/2000, Val Acc=0.5819, Val Loss=1.7603, lr=0.0100
[2025-05-07 03:18:06,439][train][INFO] - Epoch 1495/2000, Val Acc=0.6315, Val Loss=1.6510, lr=0.0100
[2025-05-07 03:18:07,463][train][INFO] - Epoch 1458/2000, Val Acc=0.6060, Val Loss=1.7999, lr=0.0100
[2025-05-07 03:18:11,887][train][INFO] - Epoch 1485/2000, Val Acc=0.6030, Val Loss=1.6593, lr=0.0100
[2025-05-07 03:18:14,334][train][INFO] - Epoch 1496/2000, Val Acc=0.6177, Val Loss=1.7146, lr=0.0100
[2025-05-07 03:18:15,420][train][INFO] - Epoch 1459/2000, Val Acc=0.6257, Val Loss=1.6645, lr=0.0100
[2025-05-07 03:18:19,741][train][INFO] - Epoch 1486/2000, Val Acc=0.5657, Val Loss=1.8551, lr=0.0100
[2025-05-07 03:18:22,043][train][INFO] - Epoch 1497/2000, Val Acc=0.6262, Val Loss=1.6854, lr=0.0100
[2025-05-07 03:18:23,584][train][INFO] - Epoch 1460/2000, Val Acc=0.6221, Val Loss=1.6464, lr=0.0100
[2025-05-07 03:18:27,050][train][INFO] - Epoch 1487/2000, Val Acc=0.5747, Val Loss=1.7996, lr=0.0100
[2025-05-07 03:18:29,971][train][INFO] - Epoch 1498/2000, Val Acc=0.6282, Val Loss=1.6656, lr=0.0100
[2025-05-07 03:18:31,213][train][INFO] - Epoch 1461/2000, Val Acc=0.6187, Val Loss=1.7075, lr=0.0100
[2025-05-07 03:18:34,496][train][INFO] - Epoch 1488/2000, Val Acc=0.6004, Val Loss=1.6428, lr=0.0100
[2025-05-07 03:18:37,985][train][INFO] - Epoch 1499/2000, Val Acc=0.6058, Val Loss=1.7747, lr=0.0100
[2025-05-07 03:18:39,593][train][INFO] - Epoch 1462/2000, Val Acc=0.6231, Val Loss=1.7011, lr=0.0100
[2025-05-07 03:18:41,939][train][INFO] - Epoch 1489/2000, Val Acc=0.5903, Val Loss=1.6678, lr=0.0100
[2025-05-07 03:18:45,395][train][INFO] - Epoch 1500/2000, Val Acc=0.6262, Val Loss=1.6441, lr=0.0100
[2025-05-07 03:18:47,470][train][INFO] - Epoch 1463/2000, Val Acc=0.5948, Val Loss=1.8931, lr=0.0100
[2025-05-07 03:18:49,387][train][INFO] - Epoch 1490/2000, Val Acc=0.6057, Val Loss=1.6583, lr=0.0100
[2025-05-07 03:18:53,252][train][INFO] - Epoch 1501/2000, Val Acc=0.6113, Val Loss=1.7744, lr=0.0100
[2025-05-07 03:18:55,593][train][INFO] - Epoch 1464/2000, Val Acc=0.6259, Val Loss=1.6537, lr=0.0100
[2025-05-07 03:18:57,432][train][INFO] - Epoch 1491/2000, Val Acc=0.5777, Val Loss=1.7509, lr=0.0100
[2025-05-07 03:19:00,288][train][INFO] - Epoch 1502/2000, Val Acc=0.6309, Val Loss=1.6609, lr=0.0100
[2025-05-07 03:19:03,505][train][INFO] - Epoch 1465/2000, Val Acc=0.6092, Val Loss=1.7734, lr=0.0100
[2025-05-07 03:19:05,244][train][INFO] - Epoch 1492/2000, Val Acc=0.6041, Val Loss=1.6552, lr=0.0100
[2025-05-07 03:19:07,638][train][INFO] - Epoch 1503/2000, Val Acc=0.6138, Val Loss=1.7417, lr=0.0100
[2025-05-07 03:19:11,430][train][INFO] - Epoch 1466/2000, Val Acc=0.6326, Val Loss=1.6532, lr=0.0100
[2025-05-07 03:19:12,966][train][INFO] - Epoch 1493/2000, Val Acc=0.5873, Val Loss=1.7274, lr=0.0100
[2025-05-07 03:19:15,286][train][INFO] - Epoch 1504/2000, Val Acc=0.6051, Val Loss=1.7992, lr=0.0100
[2025-05-07 03:19:19,518][train][INFO] - Epoch 1467/2000, Val Acc=0.6297, Val Loss=1.6899, lr=0.0100
[2025-05-07 03:19:21,036][train][INFO] - Epoch 1494/2000, Val Acc=0.6047, Val Loss=1.6410, lr=0.0100
[2025-05-07 03:19:23,363][train][INFO] - Epoch 1505/2000, Val Acc=0.6271, Val Loss=1.6570, lr=0.0100
[2025-05-07 03:19:27,680][train][INFO] - Epoch 1468/2000, Val Acc=0.6172, Val Loss=1.6983, lr=0.0100
[2025-05-07 03:19:28,916][train][INFO] - Epoch 1495/2000, Val Acc=0.5960, Val Loss=1.7399, lr=0.0100
[2025-05-07 03:19:31,079][train][INFO] - Epoch 1506/2000, Val Acc=0.6017, Val Loss=1.7752, lr=0.0100
[2025-05-07 03:19:34,965][train][INFO] - Epoch 1469/2000, Val Acc=0.6150, Val Loss=1.7665, lr=0.0100
[2025-05-07 03:19:36,615][train][INFO] - Epoch 1496/2000, Val Acc=0.5934, Val Loss=1.6974, lr=0.0100
[2025-05-07 03:19:38,675][train][INFO] - Epoch 1507/2000, Val Acc=0.6064, Val Loss=1.8171, lr=0.0100
[2025-05-07 03:19:42,693][train][INFO] - Epoch 1470/2000, Val Acc=0.6336, Val Loss=1.6572, lr=0.0100
[2025-05-07 03:19:44,495][train][INFO] - Epoch 1497/2000, Val Acc=0.5636, Val Loss=1.8944, lr=0.0100
[2025-05-07 03:19:45,905][train][INFO] - Epoch 1508/2000, Val Acc=0.6183, Val Loss=1.7096, lr=0.0100
[2025-05-07 03:19:50,631][train][INFO] - Epoch 1471/2000, Val Acc=0.6172, Val Loss=1.7474, lr=0.0100
[2025-05-07 03:19:52,209][train][INFO] - Epoch 1498/2000, Val Acc=0.5612, Val Loss=1.9254, lr=0.0100
[2025-05-07 03:19:53,848][train][INFO] - Epoch 1509/2000, Val Acc=0.6278, Val Loss=1.6782, lr=0.0100
[2025-05-07 03:19:58,441][train][INFO] - Epoch 1472/2000, Val Acc=0.6149, Val Loss=1.7559, lr=0.0100
[2025-05-07 03:19:59,534][train][INFO] - Epoch 1499/2000, Val Acc=0.5841, Val Loss=1.7283, lr=0.0100
[2025-05-07 03:20:01,549][train][INFO] - Epoch 1510/2000, Val Acc=0.6243, Val Loss=1.6781, lr=0.0100
[2025-05-07 03:20:06,389][train][INFO] - Epoch 1473/2000, Val Acc=0.6088, Val Loss=1.7985, lr=0.0100
[2025-05-07 03:20:06,638][train][INFO] - Epoch 1500/2000, Val Acc=0.5866, Val Loss=1.7111, lr=0.0100
[2025-05-07 03:20:09,422][train][INFO] - Epoch 1511/2000, Val Acc=0.6280, Val Loss=1.6689, lr=0.0100
[2025-05-07 03:20:14,590][train][INFO] - Epoch 1501/2000, Val Acc=0.5969, Val Loss=1.6676, lr=0.0100
[2025-05-07 03:20:14,610][train][INFO] - Epoch 1474/2000, Val Acc=0.6202, Val Loss=1.6816, lr=0.0100
[2025-05-07 03:20:17,150][train][INFO] - Epoch 1512/2000, Val Acc=0.6049, Val Loss=1.7995, lr=0.0100
[2025-05-07 03:20:22,203][train][INFO] - Epoch 1502/2000, Val Acc=0.6036, Val Loss=1.6612, lr=0.0100
[2025-05-07 03:20:22,476][train][INFO] - Epoch 1475/2000, Val Acc=0.6264, Val Loss=1.6563, lr=0.0100
[2025-05-07 03:20:25,201][train][INFO] - Epoch 1513/2000, Val Acc=0.6254, Val Loss=1.6741, lr=0.0100
[2025-05-07 03:20:29,570][train][INFO] - Epoch 1503/2000, Val Acc=0.5816, Val Loss=1.7338, lr=0.0100
[2025-05-07 03:20:29,641][train][INFO] - Epoch 1476/2000, Val Acc=0.6196, Val Loss=1.6924, lr=0.0100
[2025-05-07 03:20:32,890][train][INFO] - Epoch 1514/2000, Val Acc=0.6121, Val Loss=1.7480, lr=0.0100
[2025-05-07 03:20:36,977][train][INFO] - Epoch 1477/2000, Val Acc=0.6049, Val Loss=1.7989, lr=0.0100
[2025-05-07 03:20:37,067][train][INFO] - Epoch 1504/2000, Val Acc=0.6031, Val Loss=1.6389, lr=0.0100
[2025-05-07 03:20:40,509][train][INFO] - Epoch 1515/2000, Val Acc=0.6315, Val Loss=1.6689, lr=0.0100
[2025-05-07 03:20:44,754][train][INFO] - Epoch 1478/2000, Val Acc=0.6056, Val Loss=1.7970, lr=0.0100
[2025-05-07 03:20:44,955][train][INFO] - Epoch 1505/2000, Val Acc=0.5730, Val Loss=1.7943, lr=0.0100
[2025-05-07 03:20:47,876][train][INFO] - Epoch 1516/2000, Val Acc=0.6185, Val Loss=1.7089, lr=0.0100
[2025-05-07 03:20:52,716][train][INFO] - Epoch 1479/2000, Val Acc=0.6295, Val Loss=1.6708, lr=0.0100
[2025-05-07 03:20:52,851][train][INFO] - Epoch 1506/2000, Val Acc=0.5840, Val Loss=1.7419, lr=0.0100
[2025-05-07 03:20:55,585][train][INFO] - Epoch 1517/2000, Val Acc=0.6342, Val Loss=1.6026, lr=0.0100
[2025-05-07 03:21:00,531][train][INFO] - Epoch 1507/2000, Val Acc=0.5712, Val Loss=1.8416, lr=0.0100
[2025-05-07 03:21:00,654][train][INFO] - Epoch 1480/2000, Val Acc=0.6296, Val Loss=1.6658, lr=0.0100
[2025-05-07 03:21:03,196][train][INFO] - Epoch 1518/2000, Val Acc=0.6062, Val Loss=1.7876, lr=0.0100
[2025-05-07 03:21:08,531][train][INFO] - Epoch 1508/2000, Val Acc=0.6042, Val Loss=1.6422, lr=0.0100
[2025-05-07 03:21:08,804][train][INFO] - Epoch 1481/2000, Val Acc=0.6211, Val Loss=1.6665, lr=0.0100
[2025-05-07 03:21:09,949][train][INFO] - Epoch 1519/2000, Val Acc=0.6268, Val Loss=1.6720, lr=0.0100
[2025-05-07 03:21:16,433][train][INFO] - Epoch 1509/2000, Val Acc=0.5730, Val Loss=1.8549, lr=0.0100
[2025-05-07 03:21:16,762][train][INFO] - Epoch 1482/2000, Val Acc=0.6256, Val Loss=1.6707, lr=0.0100
[2025-05-07 03:21:17,611][train][INFO] - Epoch 1520/2000, Val Acc=0.6181, Val Loss=1.7054, lr=0.0100
[2025-05-07 03:21:24,314][train][INFO] - Epoch 1510/2000, Val Acc=0.5913, Val Loss=1.7216, lr=0.0100
[2025-05-07 03:21:24,447][train][INFO] - Epoch 1483/2000, Val Acc=0.6162, Val Loss=1.7315, lr=0.0100
[2025-05-07 03:21:25,432][train][INFO] - Epoch 1521/2000, Val Acc=0.6122, Val Loss=1.7634, lr=0.0100
[2025-05-07 03:21:31,591][train][INFO] - Epoch 1511/2000, Val Acc=0.5970, Val Loss=1.6939, lr=0.0100
[2025-05-07 03:21:32,158][train][INFO] - Epoch 1484/2000, Val Acc=0.6102, Val Loss=1.7203, lr=0.0100
[2025-05-07 03:21:32,959][train][INFO] - Epoch 1522/2000, Val Acc=0.6246, Val Loss=1.7054, lr=0.0100
[2025-05-07 03:21:39,330][train][INFO] - Epoch 1512/2000, Val Acc=0.5901, Val Loss=1.7219, lr=0.0100
[2025-05-07 03:21:40,098][train][INFO] - Epoch 1485/2000, Val Acc=0.6078, Val Loss=1.7845, lr=0.0100
[2025-05-07 03:21:40,559][train][INFO] - Epoch 1523/2000, Val Acc=0.6153, Val Loss=1.7463, lr=0.0100
[2025-05-07 03:21:47,013][train][INFO] - Epoch 1513/2000, Val Acc=0.6013, Val Loss=1.6658, lr=0.0100
[2025-05-07 03:21:47,681][train][INFO] - Epoch 1486/2000, Val Acc=0.6332, Val Loss=1.6259, lr=0.0100
[2025-05-07 03:21:48,345][train][INFO] - Epoch 1524/2000, Val Acc=0.6194, Val Loss=1.7474, lr=0.0100
[2025-05-07 03:21:54,403][train][INFO] - Epoch 1514/2000, Val Acc=0.5987, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:21:55,608][train][INFO] - Epoch 1525/2000, Val Acc=0.6218, Val Loss=1.6696, lr=0.0100
[2025-05-07 03:21:55,645][train][INFO] - Epoch 1487/2000, Val Acc=0.6058, Val Loss=1.8319, lr=0.0100
[2025-05-07 03:22:02,255][train][INFO] - Epoch 1515/2000, Val Acc=0.5794, Val Loss=1.8162, lr=0.0100
[2025-05-07 03:22:02,941][train][INFO] - Epoch 1526/2000, Val Acc=0.6110, Val Loss=1.7575, lr=0.0100
[2025-05-07 03:22:03,249][train][INFO] - Epoch 1488/2000, Val Acc=0.6191, Val Loss=1.7479, lr=0.0100
[2025-05-07 03:22:09,449][train][INFO] - Epoch 1516/2000, Val Acc=0.6067, Val Loss=1.6326, lr=0.0100
[2025-05-07 03:22:10,672][train][INFO] - Epoch 1527/2000, Val Acc=0.6197, Val Loss=1.6990, lr=0.0100
[2025-05-07 03:22:11,479][train][INFO] - Epoch 1489/2000, Val Acc=0.6100, Val Loss=1.7852, lr=0.0100
[2025-05-07 03:22:17,001][train][INFO] - Epoch 1517/2000, Val Acc=0.5957, Val Loss=1.6879, lr=0.0100
[2025-05-07 03:22:18,136][train][INFO] - Epoch 1528/2000, Val Acc=0.6273, Val Loss=1.6436, lr=0.0100
[2025-05-07 03:22:19,365][train][INFO] - Epoch 1490/2000, Val Acc=0.6225, Val Loss=1.6572, lr=0.0100
[2025-05-07 03:22:24,382][train][INFO] - Epoch 1518/2000, Val Acc=0.5845, Val Loss=1.7514, lr=0.0100
[2025-05-07 03:22:25,493][train][INFO] - Epoch 1529/2000, Val Acc=0.6125, Val Loss=1.7490, lr=0.0100
[2025-05-07 03:22:26,740][train][INFO] - Epoch 1491/2000, Val Acc=0.6084, Val Loss=1.7747, lr=0.0100
[2025-05-07 03:22:32,449][train][INFO] - Epoch 1519/2000, Val Acc=0.6003, Val Loss=1.6854, lr=0.0100
[2025-05-07 03:22:32,684][train][INFO] - Epoch 1530/2000, Val Acc=0.6236, Val Loss=1.6676, lr=0.0100
[2025-05-07 03:22:34,521][train][INFO] - Epoch 1492/2000, Val Acc=0.6048, Val Loss=1.7658, lr=0.0100
[2025-05-07 03:22:40,003][train][INFO] - Epoch 1520/2000, Val Acc=0.5936, Val Loss=1.7345, lr=0.0100
[2025-05-07 03:22:40,068][train][INFO] - Epoch 1531/2000, Val Acc=0.6167, Val Loss=1.7069, lr=0.0100
[2025-05-07 03:22:42,220][train][INFO] - Epoch 1493/2000, Val Acc=0.6210, Val Loss=1.6830, lr=0.0100
[2025-05-07 03:22:47,661][train][INFO] - Epoch 1532/2000, Val Acc=0.6128, Val Loss=1.7373, lr=0.0100
[2025-05-07 03:22:48,062][train][INFO] - Epoch 1521/2000, Val Acc=0.6011, Val Loss=1.6592, lr=0.0100
[2025-05-07 03:22:50,268][train][INFO] - Epoch 1494/2000, Val Acc=0.6194, Val Loss=1.7075, lr=0.0100
[2025-05-07 03:22:54,874][train][INFO] - Epoch 1533/2000, Val Acc=0.6292, Val Loss=1.6792, lr=0.0100
[2025-05-07 03:22:55,112][train][INFO] - Epoch 1522/2000, Val Acc=0.5878, Val Loss=1.7294, lr=0.0100
[2025-05-07 03:22:58,074][train][INFO] - Epoch 1495/2000, Val Acc=0.6315, Val Loss=1.6510, lr=0.0100
[2025-05-07 03:23:02,850][train][INFO] - Epoch 1523/2000, Val Acc=0.5921, Val Loss=1.7119, lr=0.0100
[2025-05-07 03:23:02,896][train][INFO] - Epoch 1534/2000, Val Acc=0.6323, Val Loss=1.6447, lr=0.0100
[2025-05-07 03:23:05,822][train][INFO] - Epoch 1496/2000, Val Acc=0.6177, Val Loss=1.7146, lr=0.0100
[2025-05-07 03:23:10,410][train][INFO] - Epoch 1524/2000, Val Acc=0.5927, Val Loss=1.7383, lr=0.0100
[2025-05-07 03:23:10,806][train][INFO] - Epoch 1535/2000, Val Acc=0.6179, Val Loss=1.7453, lr=0.0100
[2025-05-07 03:23:13,538][train][INFO] - Epoch 1497/2000, Val Acc=0.6262, Val Loss=1.6854, lr=0.0100
[2025-05-07 03:23:18,047][train][INFO] - Epoch 1536/2000, Val Acc=0.6208, Val Loss=1.7276, lr=0.0100
[2025-05-07 03:23:18,266][train][INFO] - Epoch 1525/2000, Val Acc=0.5904, Val Loss=1.7475, lr=0.0100
[2025-05-07 03:23:21,263][train][INFO] - Epoch 1498/2000, Val Acc=0.6282, Val Loss=1.6656, lr=0.0100
[2025-05-07 03:23:25,749][train][INFO] - Epoch 1537/2000, Val Acc=0.6210, Val Loss=1.7622, lr=0.0100
[2025-05-07 03:23:25,885][train][INFO] - Epoch 1526/2000, Val Acc=0.6024, Val Loss=1.6781, lr=0.0100
[2025-05-07 03:23:28,867][train][INFO] - Epoch 1499/2000, Val Acc=0.6058, Val Loss=1.7747, lr=0.0100
[2025-05-07 03:23:33,384][train][INFO] - Epoch 1527/2000, Val Acc=0.6072, Val Loss=1.6500, lr=0.0100
[2025-05-07 03:23:33,484][train][INFO] - Epoch 1538/2000, Val Acc=0.6309, Val Loss=1.6407, lr=0.0100
[2025-05-07 03:23:36,702][train][INFO] - Epoch 1500/2000, Val Acc=0.6262, Val Loss=1.6441, lr=0.0100
[2025-05-07 03:23:41,313][train][INFO] - Epoch 1528/2000, Val Acc=0.6035, Val Loss=1.6249, lr=0.0100
[2025-05-07 03:23:41,332][train][INFO] - Epoch 1539/2000, Val Acc=0.5949, Val Loss=1.8872, lr=0.0100
[2025-05-07 03:23:44,150][train][INFO] - Epoch 1501/2000, Val Acc=0.6113, Val Loss=1.7744, lr=0.0100
[2025-05-07 03:23:48,683][train][INFO] - Epoch 1529/2000, Val Acc=0.5932, Val Loss=1.7150, lr=0.0100
[2025-05-07 03:23:48,985][train][INFO] - Epoch 1540/2000, Val Acc=0.6238, Val Loss=1.6610, lr=0.0100
[2025-05-07 03:23:51,966][train][INFO] - Epoch 1502/2000, Val Acc=0.6309, Val Loss=1.6609, lr=0.0100
[2025-05-07 03:23:55,802][train][INFO] - Epoch 1530/2000, Val Acc=0.5948, Val Loss=1.6911, lr=0.0100
[2025-05-07 03:23:57,056][train][INFO] - Epoch 1541/2000, Val Acc=0.6067, Val Loss=1.8250, lr=0.0100
[2025-05-07 03:23:59,988][train][INFO] - Epoch 1503/2000, Val Acc=0.6138, Val Loss=1.7417, lr=0.0100
[2025-05-07 03:24:03,957][train][INFO] - Epoch 1531/2000, Val Acc=0.5695, Val Loss=1.7926, lr=0.0100
[2025-05-07 03:24:04,624][train][INFO] - Epoch 1542/2000, Val Acc=0.6126, Val Loss=1.7506, lr=0.0100
[2025-05-07 03:24:08,234][train][INFO] - Epoch 1504/2000, Val Acc=0.6051, Val Loss=1.7992, lr=0.0100
[2025-05-07 03:24:11,817][train][INFO] - Epoch 1532/2000, Val Acc=0.5869, Val Loss=1.7494, lr=0.0100
[2025-05-07 03:24:12,257][train][INFO] - Epoch 1543/2000, Val Acc=0.6173, Val Loss=1.7240, lr=0.0100
[2025-05-07 03:24:15,899][train][INFO] - Epoch 1505/2000, Val Acc=0.6271, Val Loss=1.6570, lr=0.0100
[2025-05-07 03:24:19,776][train][INFO] - Epoch 1544/2000, Val Acc=0.6144, Val Loss=1.7355, lr=0.0100
[2025-05-07 03:24:19,812][train][INFO] - Epoch 1533/2000, Val Acc=0.5987, Val Loss=1.6825, lr=0.0100
[2025-05-07 03:24:23,318][train][INFO] - Epoch 1506/2000, Val Acc=0.6017, Val Loss=1.7752, lr=0.0100
[2025-05-07 03:24:26,963][train][INFO] - Epoch 1545/2000, Val Acc=0.6244, Val Loss=1.6497, lr=0.0100
[2025-05-07 03:24:27,742][train][INFO] - Epoch 1534/2000, Val Acc=0.6063, Val Loss=1.6453, lr=0.0100
[2025-05-07 03:24:30,890][train][INFO] - Epoch 1507/2000, Val Acc=0.6064, Val Loss=1.8171, lr=0.0100
[2025-05-07 03:24:34,704][train][INFO] - Epoch 1546/2000, Val Acc=0.5979, Val Loss=1.8481, lr=0.0100
[2025-05-07 03:24:35,313][train][INFO] - Epoch 1535/2000, Val Acc=0.5992, Val Loss=1.6392, lr=0.0100
[2025-05-07 03:24:38,113][train][INFO] - Epoch 1508/2000, Val Acc=0.6183, Val Loss=1.7096, lr=0.0100
[2025-05-07 03:24:41,912][train][INFO] - Epoch 1547/2000, Val Acc=0.6149, Val Loss=1.7730, lr=0.0100
[2025-05-07 03:24:42,873][train][INFO] - Epoch 1536/2000, Val Acc=0.5996, Val Loss=1.6621, lr=0.0100
[2025-05-07 03:24:46,156][train][INFO] - Epoch 1509/2000, Val Acc=0.6278, Val Loss=1.6782, lr=0.0100
[2025-05-07 03:24:49,711][train][INFO] - Epoch 1548/2000, Val Acc=0.6205, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:24:50,441][train][INFO] - Epoch 1537/2000, Val Acc=0.5947, Val Loss=1.7090, lr=0.0100
[2025-05-07 03:24:54,045][train][INFO] - Epoch 1510/2000, Val Acc=0.6243, Val Loss=1.6781, lr=0.0100
[2025-05-07 03:24:57,068][train][INFO] - Epoch 1549/2000, Val Acc=0.6252, Val Loss=1.6555, lr=0.0100
[2025-05-07 03:24:58,503][train][INFO] - Epoch 1538/2000, Val Acc=0.5916, Val Loss=1.7142, lr=0.0100
[2025-05-07 03:25:01,866][train][INFO] - Epoch 1511/2000, Val Acc=0.6280, Val Loss=1.6689, lr=0.0100
[2025-05-07 03:25:05,080][train][INFO] - Epoch 1550/2000, Val Acc=0.6149, Val Loss=1.7490, lr=0.0100
[2025-05-07 03:25:05,703][train][INFO] - Epoch 1539/2000, Val Acc=0.5737, Val Loss=1.8297, lr=0.0100
[2025-05-07 03:25:10,023][train][INFO] - Epoch 1512/2000, Val Acc=0.6049, Val Loss=1.7995, lr=0.0100
[2025-05-07 03:25:12,941][train][INFO] - Epoch 1551/2000, Val Acc=0.5992, Val Loss=1.7724, lr=0.0100
[2025-05-07 03:25:13,318][train][INFO] - Epoch 1540/2000, Val Acc=0.6000, Val Loss=1.6617, lr=0.0100
[2025-05-07 03:25:17,705][train][INFO] - Epoch 1513/2000, Val Acc=0.6254, Val Loss=1.6741, lr=0.0100
[2025-05-07 03:25:20,630][train][INFO] - Epoch 1541/2000, Val Acc=0.5958, Val Loss=1.7024, lr=0.0100
[2025-05-07 03:25:20,858][train][INFO] - Epoch 1552/2000, Val Acc=0.6077, Val Loss=1.8073, lr=0.0100
[2025-05-07 03:25:25,507][train][INFO] - Epoch 1514/2000, Val Acc=0.6121, Val Loss=1.7480, lr=0.0100
[2025-05-07 03:25:28,428][train][INFO] - Epoch 1553/2000, Val Acc=0.6108, Val Loss=1.7844, lr=0.0100
[2025-05-07 03:25:28,444][train][INFO] - Epoch 1542/2000, Val Acc=0.6018, Val Loss=1.6967, lr=0.0100
[2025-05-07 03:25:33,465][train][INFO] - Epoch 1515/2000, Val Acc=0.6315, Val Loss=1.6689, lr=0.0100
[2025-05-07 03:25:35,903][train][INFO] - Epoch 1543/2000, Val Acc=0.6143, Val Loss=1.5867, lr=0.0100
[2025-05-07 03:25:35,947][train][INFO] - Epoch 1554/2000, Val Acc=0.6241, Val Loss=1.6630, lr=0.0100
[2025-05-07 03:25:41,406][train][INFO] - Epoch 1516/2000, Val Acc=0.6185, Val Loss=1.7089, lr=0.0100
[2025-05-07 03:25:42,784][train][INFO] - Epoch 1555/2000, Val Acc=0.6133, Val Loss=1.7551, lr=0.0100
[2025-05-07 03:25:43,632][train][INFO] - Epoch 1544/2000, Val Acc=0.6041, Val Loss=1.6426, lr=0.0100
[2025-05-07 03:25:49,417][train][INFO] - Epoch 1517/2000, Val Acc=0.6342, Val Loss=1.6026, lr=0.0100
[2025-05-07 03:25:50,516][train][INFO] - Epoch 1556/2000, Val Acc=0.6219, Val Loss=1.6622, lr=0.0100
[2025-05-07 03:25:51,347][train][INFO] - Epoch 1545/2000, Val Acc=0.5946, Val Loss=1.6679, lr=0.0100
[2025-05-07 03:25:57,188][train][INFO] - Epoch 1518/2000, Val Acc=0.6062, Val Loss=1.7876, lr=0.0100
[2025-05-07 03:25:58,519][train][INFO] - Epoch 1557/2000, Val Acc=0.6083, Val Loss=1.8106, lr=0.0100
[2025-05-07 03:25:59,215][train][INFO] - Epoch 1546/2000, Val Acc=0.6090, Val Loss=1.6265, lr=0.0100
[2025-05-07 03:26:05,329][train][INFO] - Epoch 1519/2000, Val Acc=0.6268, Val Loss=1.6720, lr=0.0100
[2025-05-07 03:26:06,229][train][INFO] - Epoch 1558/2000, Val Acc=0.6118, Val Loss=1.7411, lr=0.0100
[2025-05-07 03:26:06,802][train][INFO] - Epoch 1547/2000, Val Acc=0.6018, Val Loss=1.6534, lr=0.0100
[2025-05-07 03:26:13,456][train][INFO] - Epoch 1520/2000, Val Acc=0.6181, Val Loss=1.7054, lr=0.0100
[2025-05-07 03:26:13,654][train][INFO] - Epoch 1559/2000, Val Acc=0.6302, Val Loss=1.6475, lr=0.0100
[2025-05-07 03:26:14,051][train][INFO] - Epoch 1548/2000, Val Acc=0.6071, Val Loss=1.6476, lr=0.0100
[2025-05-07 03:26:21,257][train][INFO] - Epoch 1521/2000, Val Acc=0.6122, Val Loss=1.7634, lr=0.0100
[2025-05-07 03:26:21,819][train][INFO] - Epoch 1560/2000, Val Acc=0.6148, Val Loss=1.7383, lr=0.0100
[2025-05-07 03:26:22,153][train][INFO] - Epoch 1549/2000, Val Acc=0.5666, Val Loss=1.8220, lr=0.0100
[2025-05-07 03:26:29,442][train][INFO] - Epoch 1522/2000, Val Acc=0.6246, Val Loss=1.7054, lr=0.0100
[2025-05-07 03:26:29,620][train][INFO] - Epoch 1561/2000, Val Acc=0.6125, Val Loss=1.7534, lr=0.0100
[2025-05-07 03:26:29,901][train][INFO] - Epoch 1550/2000, Val Acc=0.5986, Val Loss=1.6906, lr=0.0100
[2025-05-07 03:26:37,199][train][INFO] - Epoch 1523/2000, Val Acc=0.6153, Val Loss=1.7463, lr=0.0100
[2025-05-07 03:26:37,248][train][INFO] - Epoch 1562/2000, Val Acc=0.6251, Val Loss=1.6946, lr=0.0100
[2025-05-07 03:26:37,819][train][INFO] - Epoch 1551/2000, Val Acc=0.5898, Val Loss=1.7153, lr=0.0100
[2025-05-07 03:26:44,991][train][INFO] - Epoch 1524/2000, Val Acc=0.6194, Val Loss=1.7474, lr=0.0100
[2025-05-07 03:26:45,239][train][INFO] - Epoch 1552/2000, Val Acc=0.5836, Val Loss=1.7428, lr=0.0100
[2025-05-07 03:26:45,300][train][INFO] - Epoch 1563/2000, Val Acc=0.6148, Val Loss=1.7568, lr=0.0100
[2025-05-07 03:26:53,076][train][INFO] - Epoch 1553/2000, Val Acc=0.5894, Val Loss=1.6932, lr=0.0100
[2025-05-07 03:26:53,110][train][INFO] - Epoch 1525/2000, Val Acc=0.6218, Val Loss=1.6696, lr=0.0100
[2025-05-07 03:26:53,256][train][INFO] - Epoch 1564/2000, Val Acc=0.5975, Val Loss=1.8517, lr=0.0100
[2025-05-07 03:27:00,112][train][INFO] - Epoch 1554/2000, Val Acc=0.5878, Val Loss=1.7064, lr=0.0100
[2025-05-07 03:27:01,051][train][INFO] - Epoch 1565/2000, Val Acc=0.6189, Val Loss=1.7323, lr=0.0100
[2025-05-07 03:27:01,398][train][INFO] - Epoch 1526/2000, Val Acc=0.6110, Val Loss=1.7575, lr=0.0100
[2025-05-07 03:27:08,223][train][INFO] - Epoch 1555/2000, Val Acc=0.5932, Val Loss=1.6926, lr=0.0100
[2025-05-07 03:27:09,327][train][INFO] - Epoch 1566/2000, Val Acc=0.6199, Val Loss=1.7057, lr=0.0100
[2025-05-07 03:27:09,653][train][INFO] - Epoch 1527/2000, Val Acc=0.6197, Val Loss=1.6990, lr=0.0100
[2025-05-07 03:27:16,160][train][INFO] - Epoch 1556/2000, Val Acc=0.5827, Val Loss=1.7631, lr=0.0100
[2025-05-07 03:27:16,852][train][INFO] - Epoch 1567/2000, Val Acc=0.6160, Val Loss=1.7742, lr=0.0100
[2025-05-07 03:27:17,685][train][INFO] - Epoch 1528/2000, Val Acc=0.6273, Val Loss=1.6436, lr=0.0100
[2025-05-07 03:27:23,974][train][INFO] - Epoch 1568/2000, Val Acc=0.6212, Val Loss=1.7119, lr=0.0100
[2025-05-07 03:27:24,272][train][INFO] - Epoch 1557/2000, Val Acc=0.5675, Val Loss=1.8477, lr=0.0100
[2025-05-07 03:27:25,655][train][INFO] - Epoch 1529/2000, Val Acc=0.6125, Val Loss=1.7490, lr=0.0100
[2025-05-07 03:27:31,488][train][INFO] - Epoch 1569/2000, Val Acc=0.6204, Val Loss=1.7391, lr=0.0100
[2025-05-07 03:27:32,395][train][INFO] - Epoch 1558/2000, Val Acc=0.6040, Val Loss=1.6599, lr=0.0100
[2025-05-07 03:27:33,570][train][INFO] - Epoch 1530/2000, Val Acc=0.6236, Val Loss=1.6676, lr=0.0100
[2025-05-07 03:27:38,873][train][INFO] - Epoch 1570/2000, Val Acc=0.6113, Val Loss=1.7799, lr=0.0100
[2025-05-07 03:27:39,612][train][INFO] - Epoch 1559/2000, Val Acc=0.6099, Val Loss=1.6213, lr=0.0100
[2025-05-07 03:27:41,811][train][INFO] - Epoch 1531/2000, Val Acc=0.6167, Val Loss=1.7069, lr=0.0100
[2025-05-07 03:27:46,778][train][INFO] - Epoch 1571/2000, Val Acc=0.6006, Val Loss=1.7959, lr=0.0100
[2025-05-07 03:27:47,505][train][INFO] - Epoch 1560/2000, Val Acc=0.5970, Val Loss=1.6886, lr=0.0100
[2025-05-07 03:27:49,600][train][INFO] - Epoch 1532/2000, Val Acc=0.6128, Val Loss=1.7373, lr=0.0100
[2025-05-07 03:27:53,988][train][INFO] - Epoch 1572/2000, Val Acc=0.6216, Val Loss=1.6824, lr=0.0100
[2025-05-07 03:27:54,983][train][INFO] - Epoch 1561/2000, Val Acc=0.5905, Val Loss=1.6803, lr=0.0100
[2025-05-07 03:27:57,456][train][INFO] - Epoch 1533/2000, Val Acc=0.6292, Val Loss=1.6792, lr=0.0100
[2025-05-07 03:28:01,784][train][INFO] - Epoch 1573/2000, Val Acc=0.6094, Val Loss=1.7803, lr=0.0100
[2025-05-07 03:28:03,010][train][INFO] - Epoch 1562/2000, Val Acc=0.5889, Val Loss=1.6817, lr=0.0100
[2025-05-07 03:28:05,165][train][INFO] - Epoch 1534/2000, Val Acc=0.6323, Val Loss=1.6447, lr=0.0100
[2025-05-07 03:28:09,333][train][INFO] - Epoch 1574/2000, Val Acc=0.6147, Val Loss=1.7261, lr=0.0100
[2025-05-07 03:28:10,868][train][INFO] - Epoch 1563/2000, Val Acc=0.6071, Val Loss=1.6093, lr=0.0100
[2025-05-07 03:28:13,352][train][INFO] - Epoch 1535/2000, Val Acc=0.6179, Val Loss=1.7453, lr=0.0100
[2025-05-07 03:28:16,681][train][INFO] - Epoch 1575/2000, Val Acc=0.6178, Val Loss=1.7494, lr=0.0100
[2025-05-07 03:28:19,040][train][INFO] - Epoch 1564/2000, Val Acc=0.5935, Val Loss=1.6679, lr=0.0100
[2025-05-07 03:28:21,335][train][INFO] - Epoch 1536/2000, Val Acc=0.6208, Val Loss=1.7276, lr=0.0100
[2025-05-07 03:28:24,309][train][INFO] - Epoch 1576/2000, Val Acc=0.6173, Val Loss=1.6907, lr=0.0100
[2025-05-07 03:28:26,730][train][INFO] - Epoch 1565/2000, Val Acc=0.5789, Val Loss=1.8341, lr=0.0100
[2025-05-07 03:28:29,319][train][INFO] - Epoch 1537/2000, Val Acc=0.6210, Val Loss=1.7622, lr=0.0100
[2025-05-07 03:28:31,740][train][INFO] - Epoch 1577/2000, Val Acc=0.6259, Val Loss=1.6916, lr=0.0100
[2025-05-07 03:28:34,411][train][INFO] - Epoch 1566/2000, Val Acc=0.5934, Val Loss=1.6981, lr=0.0100
[2025-05-07 03:28:37,269][train][INFO] - Epoch 1538/2000, Val Acc=0.6309, Val Loss=1.6407, lr=0.0100
[2025-05-07 03:28:39,781][train][INFO] - Epoch 1578/2000, Val Acc=0.6204, Val Loss=1.6941, lr=0.0100
[2025-05-07 03:28:42,265][train][INFO] - Epoch 1567/2000, Val Acc=0.6010, Val Loss=1.6732, lr=0.0100
[2025-05-07 03:28:45,417][train][INFO] - Epoch 1539/2000, Val Acc=0.5949, Val Loss=1.8872, lr=0.0100
[2025-05-07 03:28:47,183][train][INFO] - Epoch 1579/2000, Val Acc=0.6210, Val Loss=1.7241, lr=0.0100
[2025-05-07 03:28:49,888][train][INFO] - Epoch 1568/2000, Val Acc=0.5996, Val Loss=1.6686, lr=0.0100
[2025-05-07 03:28:53,311][train][INFO] - Epoch 1540/2000, Val Acc=0.6238, Val Loss=1.6610, lr=0.0100
[2025-05-07 03:28:54,346][train][INFO] - Epoch 1580/2000, Val Acc=0.6192, Val Loss=1.7149, lr=0.0100
[2025-05-07 03:28:57,305][train][INFO] - Epoch 1569/2000, Val Acc=0.5903, Val Loss=1.7204, lr=0.0100
[2025-05-07 03:29:00,897][train][INFO] - Epoch 1541/2000, Val Acc=0.6067, Val Loss=1.8250, lr=0.0100
[2025-05-07 03:29:01,994][train][INFO] - Epoch 1581/2000, Val Acc=0.6291, Val Loss=1.6575, lr=0.0100
[2025-05-07 03:29:05,174][train][INFO] - Epoch 1570/2000, Val Acc=0.5938, Val Loss=1.7331, lr=0.0100
[2025-05-07 03:29:09,058][train][INFO] - Epoch 1542/2000, Val Acc=0.6126, Val Loss=1.7506, lr=0.0100
[2025-05-07 03:29:09,829][train][INFO] - Epoch 1582/2000, Val Acc=0.6180, Val Loss=1.7050, lr=0.0100
[2025-05-07 03:29:13,134][train][INFO] - Epoch 1571/2000, Val Acc=0.5965, Val Loss=1.6951, lr=0.0100
[2025-05-07 03:29:17,061][train][INFO] - Epoch 1543/2000, Val Acc=0.6173, Val Loss=1.7240, lr=0.0100
[2025-05-07 03:29:17,377][train][INFO] - Epoch 1583/2000, Val Acc=0.6161, Val Loss=1.7222, lr=0.0100
[2025-05-07 03:29:20,634][train][INFO] - Epoch 1572/2000, Val Acc=0.5949, Val Loss=1.7059, lr=0.0100
[2025-05-07 03:29:24,937][train][INFO] - Epoch 1544/2000, Val Acc=0.6144, Val Loss=1.7355, lr=0.0100
[2025-05-07 03:29:25,330][train][INFO] - Epoch 1584/2000, Val Acc=0.6150, Val Loss=1.7428, lr=0.0100
[2025-05-07 03:29:28,510][train][INFO] - Epoch 1573/2000, Val Acc=0.5969, Val Loss=1.6873, lr=0.0100
[2025-05-07 03:29:32,826][train][INFO] - Epoch 1585/2000, Val Acc=0.6219, Val Loss=1.6936, lr=0.0100
[2025-05-07 03:29:33,192][train][INFO] - Epoch 1545/2000, Val Acc=0.6244, Val Loss=1.6497, lr=0.0100
[2025-05-07 03:29:36,281][train][INFO] - Epoch 1574/2000, Val Acc=0.5890, Val Loss=1.7494, lr=0.0100
[2025-05-07 03:29:40,382][train][INFO] - Epoch 1586/2000, Val Acc=0.6171, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:29:41,071][train][INFO] - Epoch 1546/2000, Val Acc=0.5979, Val Loss=1.8481, lr=0.0100
[2025-05-07 03:29:44,364][train][INFO] - Epoch 1575/2000, Val Acc=0.5857, Val Loss=1.7844, lr=0.0100
[2025-05-07 03:29:47,565][train][INFO] - Epoch 1587/2000, Val Acc=0.6104, Val Loss=1.7732, lr=0.0100
[2025-05-07 03:29:48,999][train][INFO] - Epoch 1547/2000, Val Acc=0.6149, Val Loss=1.7730, lr=0.0100
[2025-05-07 03:29:51,566][train][INFO] - Epoch 1576/2000, Val Acc=0.5915, Val Loss=1.7161, lr=0.0100
[2025-05-07 03:29:55,260][train][INFO] - Epoch 1588/2000, Val Acc=0.6177, Val Loss=1.7302, lr=0.0100
[2025-05-07 03:29:57,039][train][INFO] - Epoch 1548/2000, Val Acc=0.6205, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:29:59,314][train][INFO] - Epoch 1577/2000, Val Acc=0.5907, Val Loss=1.7375, lr=0.0100
[2025-05-07 03:30:02,705][train][INFO] - Epoch 1589/2000, Val Acc=0.6119, Val Loss=1.7580, lr=0.0100
[2025-05-07 03:30:05,097][train][INFO] - Epoch 1549/2000, Val Acc=0.6252, Val Loss=1.6555, lr=0.0100
[2025-05-07 03:30:07,241][train][INFO] - Epoch 1578/2000, Val Acc=0.5715, Val Loss=1.7846, lr=0.0100
[2025-05-07 03:30:10,465][train][INFO] - Epoch 1590/2000, Val Acc=0.6169, Val Loss=1.7311, lr=0.0100
[2025-05-07 03:30:13,064][train][INFO] - Epoch 1550/2000, Val Acc=0.6149, Val Loss=1.7490, lr=0.0100
[2025-05-07 03:30:14,958][train][INFO] - Epoch 1579/2000, Val Acc=0.6049, Val Loss=1.6497, lr=0.0100
[2025-05-07 03:30:18,301][train][INFO] - Epoch 1591/2000, Val Acc=0.6190, Val Loss=1.7164, lr=0.0100
[2025-05-07 03:30:20,745][train][INFO] - Epoch 1551/2000, Val Acc=0.5992, Val Loss=1.7724, lr=0.0100
[2025-05-07 03:30:22,431][train][INFO] - Epoch 1580/2000, Val Acc=0.5937, Val Loss=1.7112, lr=0.0100
[2025-05-07 03:30:25,973][train][INFO] - Epoch 1592/2000, Val Acc=0.6130, Val Loss=1.7151, lr=0.0100
[2025-05-07 03:30:28,733][train][INFO] - Epoch 1552/2000, Val Acc=0.6077, Val Loss=1.8073, lr=0.0100
[2025-05-07 03:30:30,087][train][INFO] - Epoch 1581/2000, Val Acc=0.5845, Val Loss=1.7456, lr=0.0100
[2025-05-07 03:30:33,418][train][INFO] - Epoch 1593/2000, Val Acc=0.6245, Val Loss=1.6718, lr=0.0100
[2025-05-07 03:30:36,221][train][INFO] - Epoch 1553/2000, Val Acc=0.6108, Val Loss=1.7844, lr=0.0100
[2025-05-07 03:30:37,914][train][INFO] - Epoch 1582/2000, Val Acc=0.6078, Val Loss=1.6243, lr=0.0100
[2025-05-07 03:30:41,158][train][INFO] - Epoch 1594/2000, Val Acc=0.5987, Val Loss=1.8505, lr=0.0100
[2025-05-07 03:30:43,988][train][INFO] - Epoch 1554/2000, Val Acc=0.6241, Val Loss=1.6630, lr=0.0100
[2025-05-07 03:30:45,509][train][INFO] - Epoch 1583/2000, Val Acc=0.5991, Val Loss=1.6731, lr=0.0100
[2025-05-07 03:30:48,480][train][INFO] - Epoch 1595/2000, Val Acc=0.6265, Val Loss=1.6591, lr=0.0100
[2025-05-07 03:30:51,742][train][INFO] - Epoch 1555/2000, Val Acc=0.6133, Val Loss=1.7551, lr=0.0100
[2025-05-07 03:30:52,886][train][INFO] - Epoch 1584/2000, Val Acc=0.5864, Val Loss=1.7101, lr=0.0100
[2025-05-07 03:30:56,263][train][INFO] - Epoch 1596/2000, Val Acc=0.6099, Val Loss=1.8410, lr=0.0100
[2025-05-07 03:30:59,879][train][INFO] - Epoch 1556/2000, Val Acc=0.6219, Val Loss=1.6622, lr=0.0100
[2025-05-07 03:31:00,412][train][INFO] - Epoch 1585/2000, Val Acc=0.5875, Val Loss=1.7257, lr=0.0100
[2025-05-07 03:31:03,916][train][INFO] - Epoch 1597/2000, Val Acc=0.6231, Val Loss=1.6722, lr=0.0100
[2025-05-07 03:31:07,055][train][INFO] - Epoch 1557/2000, Val Acc=0.6083, Val Loss=1.8106, lr=0.0100
[2025-05-07 03:31:08,275][train][INFO] - Epoch 1586/2000, Val Acc=0.5895, Val Loss=1.7011, lr=0.0100
[2025-05-07 03:31:12,045][train][INFO] - Epoch 1598/2000, Val Acc=0.6193, Val Loss=1.7055, lr=0.0100
[2025-05-07 03:31:15,142][train][INFO] - Epoch 1558/2000, Val Acc=0.6118, Val Loss=1.7411, lr=0.0100
[2025-05-07 03:31:15,988][train][INFO] - Epoch 1587/2000, Val Acc=0.6018, Val Loss=1.6521, lr=0.0100
[2025-05-07 03:31:19,583][train][INFO] - Epoch 1599/2000, Val Acc=0.6208, Val Loss=1.7193, lr=0.0100
[2025-05-07 03:31:22,667][train][INFO] - Epoch 1559/2000, Val Acc=0.6302, Val Loss=1.6475, lr=0.0100
[2025-05-07 03:31:23,469][train][INFO] - Epoch 1588/2000, Val Acc=0.5830, Val Loss=1.7606, lr=0.0100
[2025-05-07 03:31:26,979][train][INFO] - Epoch 1600/2000, Val Acc=0.6250, Val Loss=1.7093, lr=0.0100
[2025-05-07 03:31:30,648][train][INFO] - Epoch 1560/2000, Val Acc=0.6148, Val Loss=1.7383, lr=0.0100
[2025-05-07 03:31:30,982][train][INFO] - Epoch 1589/2000, Val Acc=0.6073, Val Loss=1.6100, lr=0.0100
[2025-05-07 03:31:34,493][train][INFO] - Epoch 1601/2000, Val Acc=0.6287, Val Loss=1.6654, lr=0.0100
[2025-05-07 03:31:38,281][train][INFO] - Epoch 1561/2000, Val Acc=0.6125, Val Loss=1.7534, lr=0.0100
[2025-05-07 03:31:39,251][train][INFO] - Epoch 1590/2000, Val Acc=0.5806, Val Loss=1.8289, lr=0.0100
[2025-05-07 03:31:41,827][train][INFO] - Epoch 1602/2000, Val Acc=0.6160, Val Loss=1.7462, lr=0.0100
[2025-05-07 03:31:45,808][train][INFO] - Epoch 1562/2000, Val Acc=0.6251, Val Loss=1.6946, lr=0.0100
[2025-05-07 03:31:46,741][train][INFO] - Epoch 1591/2000, Val Acc=0.5752, Val Loss=1.7914, lr=0.0100
[2025-05-07 03:31:49,655][train][INFO] - Epoch 1603/2000, Val Acc=0.6172, Val Loss=1.7414, lr=0.0100
[2025-05-07 03:31:53,886][train][INFO] - Epoch 1563/2000, Val Acc=0.6148, Val Loss=1.7568, lr=0.0100
[2025-05-07 03:31:54,367][train][INFO] - Epoch 1592/2000, Val Acc=0.5937, Val Loss=1.6974, lr=0.0100
[2025-05-07 03:31:57,147][train][INFO] - Epoch 1604/2000, Val Acc=0.6285, Val Loss=1.6709, lr=0.0100
[2025-05-07 03:32:01,628][train][INFO] - Epoch 1564/2000, Val Acc=0.5975, Val Loss=1.8517, lr=0.0100
[2025-05-07 03:32:01,941][train][INFO] - Epoch 1593/2000, Val Acc=0.5965, Val Loss=1.6481, lr=0.0100
[2025-05-07 03:32:04,899][train][INFO] - Epoch 1605/2000, Val Acc=0.6198, Val Loss=1.7266, lr=0.0100
[2025-05-07 03:32:09,702][train][INFO] - Epoch 1565/2000, Val Acc=0.6189, Val Loss=1.7323, lr=0.0100
[2025-05-07 03:32:09,848][train][INFO] - Epoch 1594/2000, Val Acc=0.5936, Val Loss=1.7554, lr=0.0100
[2025-05-07 03:32:12,773][train][INFO] - Epoch 1606/2000, Val Acc=0.6286, Val Loss=1.6612, lr=0.0100
[2025-05-07 03:32:17,360][train][INFO] - Epoch 1595/2000, Val Acc=0.5873, Val Loss=1.7433, lr=0.0100
[2025-05-07 03:32:17,416][train][INFO] - Epoch 1566/2000, Val Acc=0.6199, Val Loss=1.7057, lr=0.0100
[2025-05-07 03:32:20,843][train][INFO] - Epoch 1607/2000, Val Acc=0.6017, Val Loss=1.8164, lr=0.0100
[2025-05-07 03:32:24,646][train][INFO] - Epoch 1596/2000, Val Acc=0.5835, Val Loss=1.7822, lr=0.0100
[2025-05-07 03:32:25,806][train][INFO] - Epoch 1567/2000, Val Acc=0.6160, Val Loss=1.7742, lr=0.0100
[2025-05-07 03:32:28,371][train][INFO] - Epoch 1608/2000, Val Acc=0.6022, Val Loss=1.8392, lr=0.0100
[2025-05-07 03:32:32,206][train][INFO] - Epoch 1597/2000, Val Acc=0.5898, Val Loss=1.7300, lr=0.0100
[2025-05-07 03:32:33,686][train][INFO] - Epoch 1568/2000, Val Acc=0.6212, Val Loss=1.7119, lr=0.0100
[2025-05-07 03:32:36,105][train][INFO] - Epoch 1609/2000, Val Acc=0.6234, Val Loss=1.6792, lr=0.0100
[2025-05-07 03:32:40,185][train][INFO] - Epoch 1598/2000, Val Acc=0.5754, Val Loss=1.8431, lr=0.0100
[2025-05-07 03:32:41,959][train][INFO] - Epoch 1569/2000, Val Acc=0.6204, Val Loss=1.7391, lr=0.0100
[2025-05-07 03:32:43,768][train][INFO] - Epoch 1610/2000, Val Acc=0.6307, Val Loss=1.6514, lr=0.0100
[2025-05-07 03:32:47,739][train][INFO] - Epoch 1599/2000, Val Acc=0.6026, Val Loss=1.6399, lr=0.0100
[2025-05-07 03:32:49,258][train][INFO] - Epoch 1570/2000, Val Acc=0.6113, Val Loss=1.7799, lr=0.0100
[2025-05-07 03:32:51,387][train][INFO] - Epoch 1611/2000, Val Acc=0.6199, Val Loss=1.6850, lr=0.0100
[2025-05-07 03:32:55,660][train][INFO] - Epoch 1600/2000, Val Acc=0.5819, Val Loss=1.7525, lr=0.0100
[2025-05-07 03:32:57,300][train][INFO] - Epoch 1571/2000, Val Acc=0.6006, Val Loss=1.7959, lr=0.0100
[2025-05-07 03:32:59,159][train][INFO] - Epoch 1612/2000, Val Acc=0.6152, Val Loss=1.7834, lr=0.0100
[2025-05-07 03:33:03,232][train][INFO] - Epoch 1601/2000, Val Acc=0.5918, Val Loss=1.7051, lr=0.0100
[2025-05-07 03:33:05,049][train][INFO] - Epoch 1572/2000, Val Acc=0.6216, Val Loss=1.6824, lr=0.0100
[2025-05-07 03:33:06,625][train][INFO] - Epoch 1613/2000, Val Acc=0.6205, Val Loss=1.6830, lr=0.0100
[2025-05-07 03:33:11,100][train][INFO] - Epoch 1602/2000, Val Acc=0.5686, Val Loss=1.8386, lr=0.0100
[2025-05-07 03:33:12,966][train][INFO] - Epoch 1573/2000, Val Acc=0.6094, Val Loss=1.7803, lr=0.0100
[2025-05-07 03:33:13,835][train][INFO] - Epoch 1614/2000, Val Acc=0.6162, Val Loss=1.7256, lr=0.0100
[2025-05-07 03:33:18,708][train][INFO] - Epoch 1603/2000, Val Acc=0.5893, Val Loss=1.7354, lr=0.0100
[2025-05-07 03:33:20,640][train][INFO] - Epoch 1574/2000, Val Acc=0.6147, Val Loss=1.7261, lr=0.0100
[2025-05-07 03:33:21,499][train][INFO] - Epoch 1615/2000, Val Acc=0.6120, Val Loss=1.7765, lr=0.0100
[2025-05-07 03:33:26,015][train][INFO] - Epoch 1604/2000, Val Acc=0.5988, Val Loss=1.6330, lr=0.0100
[2025-05-07 03:33:28,762][train][INFO] - Epoch 1575/2000, Val Acc=0.6178, Val Loss=1.7494, lr=0.0100
[2025-05-07 03:33:28,966][train][INFO] - Epoch 1616/2000, Val Acc=0.6056, Val Loss=1.7992, lr=0.0100
[2025-05-07 03:33:33,497][train][INFO] - Epoch 1605/2000, Val Acc=0.5728, Val Loss=1.8504, lr=0.0100
[2025-05-07 03:33:36,139][train][INFO] - Epoch 1617/2000, Val Acc=0.6183, Val Loss=1.7159, lr=0.0100
[2025-05-07 03:33:36,795][train][INFO] - Epoch 1576/2000, Val Acc=0.6173, Val Loss=1.6907, lr=0.0100
[2025-05-07 03:33:41,422][train][INFO] - Epoch 1606/2000, Val Acc=0.6108, Val Loss=1.6067, lr=0.0100
[2025-05-07 03:33:43,821][train][INFO] - Epoch 1618/2000, Val Acc=0.6204, Val Loss=1.7125, lr=0.0100
[2025-05-07 03:33:44,236][train][INFO] - Epoch 1577/2000, Val Acc=0.6259, Val Loss=1.6916, lr=0.0100
[2025-05-07 03:33:48,970][train][INFO] - Epoch 1607/2000, Val Acc=0.5901, Val Loss=1.7161, lr=0.0100
[2025-05-07 03:33:51,453][train][INFO] - Epoch 1619/2000, Val Acc=0.6184, Val Loss=1.6962, lr=0.0100
[2025-05-07 03:33:51,810][train][INFO] - Epoch 1578/2000, Val Acc=0.6204, Val Loss=1.6941, lr=0.0100
[2025-05-07 03:33:56,334][train][INFO] - Epoch 1608/2000, Val Acc=0.5906, Val Loss=1.7516, lr=0.0100
[2025-05-07 03:33:59,097][train][INFO] - Epoch 1579/2000, Val Acc=0.6210, Val Loss=1.7241, lr=0.0100
[2025-05-07 03:33:59,302][train][INFO] - Epoch 1620/2000, Val Acc=0.6220, Val Loss=1.7140, lr=0.0100
[2025-05-07 03:34:03,645][train][INFO] - Epoch 1609/2000, Val Acc=0.5857, Val Loss=1.7583, lr=0.0100
[2025-05-07 03:34:06,811][train][INFO] - Epoch 1580/2000, Val Acc=0.6192, Val Loss=1.7149, lr=0.0100
[2025-05-07 03:34:07,025][train][INFO] - Epoch 1621/2000, Val Acc=0.6158, Val Loss=1.7374, lr=0.0100
[2025-05-07 03:34:10,905][train][INFO] - Epoch 1610/2000, Val Acc=0.6192, Val Loss=1.5670, lr=0.0100
[2025-05-07 03:34:14,689][train][INFO] - Epoch 1581/2000, Val Acc=0.6291, Val Loss=1.6575, lr=0.0100
[2025-05-07 03:34:14,747][train][INFO] - Epoch 1622/2000, Val Acc=0.6121, Val Loss=1.7460, lr=0.0100
[2025-05-07 03:34:18,795][train][INFO] - Epoch 1611/2000, Val Acc=0.5740, Val Loss=1.8089, lr=0.0100
[2025-05-07 03:34:22,555][train][INFO] - Epoch 1623/2000, Val Acc=0.6084, Val Loss=1.8340, lr=0.0100
[2025-05-07 03:34:22,696][train][INFO] - Epoch 1582/2000, Val Acc=0.6180, Val Loss=1.7050, lr=0.0100
[2025-05-07 03:34:26,949][train][INFO] - Epoch 1612/2000, Val Acc=0.5937, Val Loss=1.7005, lr=0.0100
[2025-05-07 03:34:29,883][train][INFO] - Epoch 1624/2000, Val Acc=0.6076, Val Loss=1.8096, lr=0.0100
[2025-05-07 03:34:30,530][train][INFO] - Epoch 1583/2000, Val Acc=0.6161, Val Loss=1.7222, lr=0.0100
[2025-05-07 03:34:34,652][train][INFO] - Epoch 1613/2000, Val Acc=0.5880, Val Loss=1.7541, lr=0.0100
[2025-05-07 03:34:37,711][train][INFO] - Epoch 1625/2000, Val Acc=0.6286, Val Loss=1.6733, lr=0.0100
[2025-05-07 03:34:38,821][train][INFO] - Epoch 1584/2000, Val Acc=0.6150, Val Loss=1.7428, lr=0.0100
[2025-05-07 03:34:42,764][train][INFO] - Epoch 1614/2000, Val Acc=0.5868, Val Loss=1.7438, lr=0.0100
[2025-05-07 03:34:45,860][train][INFO] - Epoch 1626/2000, Val Acc=0.6266, Val Loss=1.6777, lr=0.0100
[2025-05-07 03:34:46,563][train][INFO] - Epoch 1585/2000, Val Acc=0.6219, Val Loss=1.6936, lr=0.0100
[2025-05-07 03:34:50,617][train][INFO] - Epoch 1615/2000, Val Acc=0.5794, Val Loss=1.7623, lr=0.0100
[2025-05-07 03:34:53,421][train][INFO] - Epoch 1627/2000, Val Acc=0.6277, Val Loss=1.6530, lr=0.0100
[2025-05-07 03:34:53,735][train][INFO] - Epoch 1586/2000, Val Acc=0.6171, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:34:58,632][train][INFO] - Epoch 1616/2000, Val Acc=0.5840, Val Loss=1.7476, lr=0.0100
[2025-05-07 03:35:01,009][train][INFO] - Epoch 1628/2000, Val Acc=0.6118, Val Loss=1.7426, lr=0.0100
[2025-05-07 03:35:01,762][train][INFO] - Epoch 1587/2000, Val Acc=0.6104, Val Loss=1.7732, lr=0.0100
[2025-05-07 03:35:06,287][train][INFO] - Epoch 1617/2000, Val Acc=0.5948, Val Loss=1.7000, lr=0.0100
[2025-05-07 03:35:08,224][train][INFO] - Epoch 1629/2000, Val Acc=0.6019, Val Loss=1.7817, lr=0.0100
[2025-05-07 03:35:09,752][train][INFO] - Epoch 1588/2000, Val Acc=0.6177, Val Loss=1.7302, lr=0.0100
[2025-05-07 03:35:13,763][train][INFO] - Epoch 1618/2000, Val Acc=0.5835, Val Loss=1.7593, lr=0.0100
[2025-05-07 03:35:16,002][train][INFO] - Epoch 1630/2000, Val Acc=0.6068, Val Loss=1.7615, lr=0.0100
[2025-05-07 03:35:17,703][train][INFO] - Epoch 1589/2000, Val Acc=0.6119, Val Loss=1.7580, lr=0.0100
[2025-05-07 03:35:21,431][train][INFO] - Epoch 1619/2000, Val Acc=0.6048, Val Loss=1.6608, lr=0.0100
[2025-05-07 03:35:23,656][train][INFO] - Epoch 1631/2000, Val Acc=0.6101, Val Loss=1.7489, lr=0.0100
[2025-05-07 03:35:24,851][train][INFO] - Epoch 1590/2000, Val Acc=0.6169, Val Loss=1.7311, lr=0.0100
[2025-05-07 03:35:29,106][train][INFO] - Epoch 1620/2000, Val Acc=0.6009, Val Loss=1.6724, lr=0.0100
[2025-05-07 03:35:31,316][train][INFO] - Epoch 1632/2000, Val Acc=0.6090, Val Loss=1.8014, lr=0.0100
[2025-05-07 03:35:33,041][train][INFO] - Epoch 1591/2000, Val Acc=0.6190, Val Loss=1.7164, lr=0.0100
[2025-05-07 03:35:36,588][train][INFO] - Epoch 1621/2000, Val Acc=0.6005, Val Loss=1.6534, lr=0.0100
[2025-05-07 03:35:38,645][train][INFO] - Epoch 1633/2000, Val Acc=0.6170, Val Loss=1.7320, lr=0.0100
[2025-05-07 03:35:41,234][train][INFO] - Epoch 1592/2000, Val Acc=0.6130, Val Loss=1.7151, lr=0.0100
[2025-05-07 03:35:44,493][train][INFO] - Epoch 1622/2000, Val Acc=0.5756, Val Loss=1.7941, lr=0.0100
[2025-05-07 03:35:46,212][train][INFO] - Epoch 1634/2000, Val Acc=0.6006, Val Loss=1.8132, lr=0.0100
[2025-05-07 03:35:49,117][train][INFO] - Epoch 1593/2000, Val Acc=0.6245, Val Loss=1.6718, lr=0.0100
[2025-05-07 03:35:51,861][train][INFO] - Epoch 1623/2000, Val Acc=0.5966, Val Loss=1.6730, lr=0.0100
[2025-05-07 03:35:53,988][train][INFO] - Epoch 1635/2000, Val Acc=0.6199, Val Loss=1.7254, lr=0.0100
[2025-05-07 03:35:57,060][train][INFO] - Epoch 1594/2000, Val Acc=0.5987, Val Loss=1.8505, lr=0.0100
[2025-05-07 03:35:59,535][train][INFO] - Epoch 1624/2000, Val Acc=0.5981, Val Loss=1.7055, lr=0.0100
[2025-05-07 03:36:01,691][train][INFO] - Epoch 1636/2000, Val Acc=0.6238, Val Loss=1.6424, lr=0.0100
[2025-05-07 03:36:05,221][train][INFO] - Epoch 1595/2000, Val Acc=0.6265, Val Loss=1.6591, lr=0.0100
[2025-05-07 03:36:07,121][train][INFO] - Epoch 1625/2000, Val Acc=0.5764, Val Loss=1.8137, lr=0.0100
[2025-05-07 03:36:09,139][train][INFO] - Epoch 1637/2000, Val Acc=0.6159, Val Loss=1.7516, lr=0.0100
[2025-05-07 03:36:12,626][train][INFO] - Epoch 1596/2000, Val Acc=0.6099, Val Loss=1.8410, lr=0.0100
[2025-05-07 03:36:14,128][train][INFO] - Epoch 1626/2000, Val Acc=0.5874, Val Loss=1.7362, lr=0.0100
[2025-05-07 03:36:16,988][train][INFO] - Epoch 1638/2000, Val Acc=0.6198, Val Loss=1.6780, lr=0.0100
[2025-05-07 03:36:20,805][train][INFO] - Epoch 1597/2000, Val Acc=0.6231, Val Loss=1.6722, lr=0.0100
[2025-05-07 03:36:22,001][train][INFO] - Epoch 1627/2000, Val Acc=0.5903, Val Loss=1.7183, lr=0.0100
[2025-05-07 03:36:24,847][train][INFO] - Epoch 1639/2000, Val Acc=0.6262, Val Loss=1.6427, lr=0.0100
[2025-05-07 03:36:28,686][train][INFO] - Epoch 1598/2000, Val Acc=0.6193, Val Loss=1.7055, lr=0.0100
[2025-05-07 03:36:29,701][train][INFO] - Epoch 1628/2000, Val Acc=0.5948, Val Loss=1.6808, lr=0.0100
[2025-05-07 03:36:32,531][train][INFO] - Epoch 1640/2000, Val Acc=0.6139, Val Loss=1.7404, lr=0.0100
[2025-05-07 03:36:36,851][train][INFO] - Epoch 1599/2000, Val Acc=0.6208, Val Loss=1.7193, lr=0.0100
[2025-05-07 03:36:37,748][train][INFO] - Epoch 1629/2000, Val Acc=0.5904, Val Loss=1.7269, lr=0.0100
[2025-05-07 03:36:40,635][train][INFO] - Epoch 1641/2000, Val Acc=0.6127, Val Loss=1.7099, lr=0.0100
[2025-05-07 03:36:44,559][train][INFO] - Epoch 1600/2000, Val Acc=0.6250, Val Loss=1.7093, lr=0.0100
[2025-05-07 03:36:45,596][train][INFO] - Epoch 1630/2000, Val Acc=0.5765, Val Loss=1.7806, lr=0.0100
[2025-05-07 03:36:47,967][train][INFO] - Epoch 1642/2000, Val Acc=0.5951, Val Loss=1.8579, lr=0.0100
[2025-05-07 03:36:52,701][train][INFO] - Epoch 1601/2000, Val Acc=0.6287, Val Loss=1.6654, lr=0.0100
[2025-05-07 03:36:53,342][train][INFO] - Epoch 1631/2000, Val Acc=0.5740, Val Loss=1.8103, lr=0.0100
[2025-05-07 03:36:55,852][train][INFO] - Epoch 1643/2000, Val Acc=0.5971, Val Loss=1.8223, lr=0.0100
[2025-05-07 03:37:00,560][train][INFO] - Epoch 1602/2000, Val Acc=0.6160, Val Loss=1.7462, lr=0.0100
[2025-05-07 03:37:01,135][train][INFO] - Epoch 1632/2000, Val Acc=0.5890, Val Loss=1.7668, lr=0.0100
[2025-05-07 03:37:03,336][train][INFO] - Epoch 1644/2000, Val Acc=0.6120, Val Loss=1.7611, lr=0.0100
[2025-05-07 03:37:07,881][train][INFO] - Epoch 1603/2000, Val Acc=0.6172, Val Loss=1.7414, lr=0.0100
[2025-05-07 03:37:09,222][train][INFO] - Epoch 1633/2000, Val Acc=0.5986, Val Loss=1.6740, lr=0.0100
[2025-05-07 03:37:11,115][train][INFO] - Epoch 1645/2000, Val Acc=0.6123, Val Loss=1.7619, lr=0.0100
[2025-05-07 03:37:15,722][train][INFO] - Epoch 1604/2000, Val Acc=0.6285, Val Loss=1.6709, lr=0.0100
[2025-05-07 03:37:16,669][train][INFO] - Epoch 1634/2000, Val Acc=0.6037, Val Loss=1.6433, lr=0.0100
[2025-05-07 03:37:18,944][train][INFO] - Epoch 1646/2000, Val Acc=0.6006, Val Loss=1.8213, lr=0.0100
[2025-05-07 03:37:23,882][train][INFO] - Epoch 1605/2000, Val Acc=0.6198, Val Loss=1.7266, lr=0.0100
[2025-05-07 03:37:24,272][train][INFO] - Epoch 1635/2000, Val Acc=0.5940, Val Loss=1.7085, lr=0.0100
[2025-05-07 03:37:26,474][train][INFO] - Epoch 1647/2000, Val Acc=0.6254, Val Loss=1.6604, lr=0.0100
[2025-05-07 03:37:31,619][train][INFO] - Epoch 1636/2000, Val Acc=0.5901, Val Loss=1.6785, lr=0.0100
[2025-05-07 03:37:31,844][train][INFO] - Epoch 1606/2000, Val Acc=0.6286, Val Loss=1.6612, lr=0.0100
[2025-05-07 03:37:33,853][train][INFO] - Epoch 1648/2000, Val Acc=0.6165, Val Loss=1.7475, lr=0.0100
[2025-05-07 03:37:39,624][train][INFO] - Epoch 1637/2000, Val Acc=0.5733, Val Loss=1.8229, lr=0.0100
[2025-05-07 03:37:39,814][train][INFO] - Epoch 1607/2000, Val Acc=0.6017, Val Loss=1.8164, lr=0.0100
[2025-05-07 03:37:41,525][train][INFO] - Epoch 1649/2000, Val Acc=0.6115, Val Loss=1.7782, lr=0.0100
[2025-05-07 03:37:47,649][train][INFO] - Epoch 1638/2000, Val Acc=0.5973, Val Loss=1.7048, lr=0.0100
[2025-05-07 03:37:48,002][train][INFO] - Epoch 1608/2000, Val Acc=0.6022, Val Loss=1.8392, lr=0.0100
[2025-05-07 03:37:49,318][train][INFO] - Epoch 1650/2000, Val Acc=0.5980, Val Loss=1.8587, lr=0.0100
[2025-05-07 03:37:55,649][train][INFO] - Epoch 1639/2000, Val Acc=0.5907, Val Loss=1.6981, lr=0.0100
[2025-05-07 03:37:56,148][train][INFO] - Epoch 1609/2000, Val Acc=0.6234, Val Loss=1.6792, lr=0.0100
[2025-05-07 03:37:57,267][train][INFO] - Epoch 1651/2000, Val Acc=0.6100, Val Loss=1.7872, lr=0.0100
[2025-05-07 03:38:03,098][train][INFO] - Epoch 1640/2000, Val Acc=0.5726, Val Loss=1.8208, lr=0.0100
[2025-05-07 03:38:04,055][train][INFO] - Epoch 1610/2000, Val Acc=0.6307, Val Loss=1.6514, lr=0.0100
[2025-05-07 03:38:04,886][train][INFO] - Epoch 1652/2000, Val Acc=0.6066, Val Loss=1.8260, lr=0.0100
[2025-05-07 03:38:10,733][train][INFO] - Epoch 1641/2000, Val Acc=0.6023, Val Loss=1.6344, lr=0.0100
[2025-05-07 03:38:11,970][train][INFO] - Epoch 1611/2000, Val Acc=0.6199, Val Loss=1.6850, lr=0.0100
[2025-05-07 03:38:12,780][train][INFO] - Epoch 1653/2000, Val Acc=0.6246, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:38:18,575][train][INFO] - Epoch 1642/2000, Val Acc=0.5980, Val Loss=1.6715, lr=0.0100
[2025-05-07 03:38:19,840][train][INFO] - Epoch 1612/2000, Val Acc=0.6152, Val Loss=1.7834, lr=0.0100
[2025-05-07 03:38:20,441][train][INFO] - Epoch 1654/2000, Val Acc=0.6197, Val Loss=1.7072, lr=0.0100
[2025-05-07 03:38:26,398][train][INFO] - Epoch 1643/2000, Val Acc=0.5904, Val Loss=1.7394, lr=0.0100
[2025-05-07 03:38:27,905][train][INFO] - Epoch 1613/2000, Val Acc=0.6205, Val Loss=1.6830, lr=0.0100
[2025-05-07 03:38:28,187][train][INFO] - Epoch 1655/2000, Val Acc=0.6304, Val Loss=1.6802, lr=0.0100
[2025-05-07 03:38:33,921][train][INFO] - Epoch 1644/2000, Val Acc=0.6032, Val Loss=1.6455, lr=0.0100
[2025-05-07 03:38:35,845][train][INFO] - Epoch 1656/2000, Val Acc=0.6182, Val Loss=1.7554, lr=0.0100
[2025-05-07 03:38:35,992][train][INFO] - Epoch 1614/2000, Val Acc=0.6162, Val Loss=1.7256, lr=0.0100
[2025-05-07 03:38:41,874][train][INFO] - Epoch 1645/2000, Val Acc=0.6001, Val Loss=1.6745, lr=0.0100
[2025-05-07 03:38:43,597][train][INFO] - Epoch 1657/2000, Val Acc=0.6244, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:38:44,045][train][INFO] - Epoch 1615/2000, Val Acc=0.6120, Val Loss=1.7765, lr=0.0100
[2025-05-07 03:38:49,450][train][INFO] - Epoch 1646/2000, Val Acc=0.5853, Val Loss=1.7530, lr=0.0100
[2025-05-07 03:38:51,021][train][INFO] - Epoch 1658/2000, Val Acc=0.6177, Val Loss=1.7151, lr=0.0100
[2025-05-07 03:38:51,990][train][INFO] - Epoch 1616/2000, Val Acc=0.6056, Val Loss=1.7992, lr=0.0100
[2025-05-07 03:38:57,523][train][INFO] - Epoch 1647/2000, Val Acc=0.5901, Val Loss=1.7050, lr=0.0100
[2025-05-07 03:38:58,308][train][INFO] - Epoch 1659/2000, Val Acc=0.6203, Val Loss=1.7320, lr=0.0100
[2025-05-07 03:38:59,759][train][INFO] - Epoch 1617/2000, Val Acc=0.6183, Val Loss=1.7159, lr=0.0100
[2025-05-07 03:39:05,365][train][INFO] - Epoch 1648/2000, Val Acc=0.6007, Val Loss=1.6704, lr=0.0100
[2025-05-07 03:39:06,098][train][INFO] - Epoch 1660/2000, Val Acc=0.6253, Val Loss=1.6974, lr=0.0100
[2025-05-07 03:39:07,705][train][INFO] - Epoch 1618/2000, Val Acc=0.6204, Val Loss=1.7125, lr=0.0100
[2025-05-07 03:39:12,762][train][INFO] - Epoch 1649/2000, Val Acc=0.5928, Val Loss=1.7499, lr=0.0100
[2025-05-07 03:39:13,734][train][INFO] - Epoch 1661/2000, Val Acc=0.6222, Val Loss=1.7134, lr=0.0100
[2025-05-07 03:39:16,174][train][INFO] - Epoch 1619/2000, Val Acc=0.6184, Val Loss=1.6962, lr=0.0100
[2025-05-07 03:39:20,374][train][INFO] - Epoch 1650/2000, Val Acc=0.5679, Val Loss=1.8540, lr=0.0100
[2025-05-07 03:39:21,175][train][INFO] - Epoch 1662/2000, Val Acc=0.6099, Val Loss=1.7765, lr=0.0100
[2025-05-07 03:39:24,039][train][INFO] - Epoch 1620/2000, Val Acc=0.6220, Val Loss=1.7140, lr=0.0100
[2025-05-07 03:39:28,213][train][INFO] - Epoch 1651/2000, Val Acc=0.5814, Val Loss=1.7992, lr=0.0100
[2025-05-07 03:39:29,096][train][INFO] - Epoch 1663/2000, Val Acc=0.6220, Val Loss=1.7108, lr=0.0100
[2025-05-07 03:39:31,846][train][INFO] - Epoch 1621/2000, Val Acc=0.6158, Val Loss=1.7374, lr=0.0100
[2025-05-07 03:39:35,958][train][INFO] - Epoch 1652/2000, Val Acc=0.5996, Val Loss=1.6925, lr=0.0100
[2025-05-07 03:39:36,120][train][INFO] - Epoch 1664/2000, Val Acc=0.6108, Val Loss=1.7963, lr=0.0100
[2025-05-07 03:39:39,636][train][INFO] - Epoch 1622/2000, Val Acc=0.6121, Val Loss=1.7460, lr=0.0100
[2025-05-07 03:39:43,295][train][INFO] - Epoch 1653/2000, Val Acc=0.5955, Val Loss=1.7037, lr=0.0100
[2025-05-07 03:39:43,665][train][INFO] - Epoch 1665/2000, Val Acc=0.6069, Val Loss=1.7812, lr=0.0100
[2025-05-07 03:39:47,588][train][INFO] - Epoch 1623/2000, Val Acc=0.6084, Val Loss=1.8340, lr=0.0100
[2025-05-07 03:39:50,781][train][INFO] - Epoch 1666/2000, Val Acc=0.6093, Val Loss=1.7900, lr=0.0100
[2025-05-07 03:39:51,000][train][INFO] - Epoch 1654/2000, Val Acc=0.5996, Val Loss=1.6869, lr=0.0100
[2025-05-07 03:39:55,524][train][INFO] - Epoch 1624/2000, Val Acc=0.6076, Val Loss=1.8096, lr=0.0100
[2025-05-07 03:39:58,286][train][INFO] - Epoch 1655/2000, Val Acc=0.6034, Val Loss=1.6430, lr=0.0100
[2025-05-07 03:39:58,553][train][INFO] - Epoch 1667/2000, Val Acc=0.6225, Val Loss=1.6895, lr=0.0100
[2025-05-07 03:40:03,456][train][INFO] - Epoch 1625/2000, Val Acc=0.6286, Val Loss=1.6733, lr=0.0100
[2025-05-07 03:40:05,928][train][INFO] - Epoch 1656/2000, Val Acc=0.5966, Val Loss=1.6910, lr=0.0100
[2025-05-07 03:40:05,958][train][INFO] - Epoch 1668/2000, Val Acc=0.6135, Val Loss=1.7693, lr=0.0100
[2025-05-07 03:40:11,304][train][INFO] - Epoch 1626/2000, Val Acc=0.6266, Val Loss=1.6777, lr=0.0100
[2025-05-07 03:40:13,489][train][INFO] - Epoch 1657/2000, Val Acc=0.6058, Val Loss=1.6179, lr=0.0100
[2025-05-07 03:40:13,538][train][INFO] - Epoch 1669/2000, Val Acc=0.6200, Val Loss=1.7441, lr=0.0100
[2025-05-07 03:40:18,631][train][INFO] - Epoch 1627/2000, Val Acc=0.6277, Val Loss=1.6530, lr=0.0100
[2025-05-07 03:40:21,136][train][INFO] - Epoch 1658/2000, Val Acc=0.5934, Val Loss=1.7014, lr=0.0100
[2025-05-07 03:40:21,326][train][INFO] - Epoch 1670/2000, Val Acc=0.5979, Val Loss=1.8497, lr=0.0100
[2025-05-07 03:40:26,156][train][INFO] - Epoch 1628/2000, Val Acc=0.6118, Val Loss=1.7426, lr=0.0100
[2025-05-07 03:40:28,386][train][INFO] - Epoch 1671/2000, Val Acc=0.6248, Val Loss=1.6840, lr=0.0100
[2025-05-07 03:40:28,838][train][INFO] - Epoch 1659/2000, Val Acc=0.5860, Val Loss=1.7475, lr=0.0100
[2025-05-07 03:40:33,235][train][INFO] - Epoch 1629/2000, Val Acc=0.6019, Val Loss=1.7817, lr=0.0100
[2025-05-07 03:40:35,556][train][INFO] - Epoch 1672/2000, Val Acc=0.6031, Val Loss=1.8031, lr=0.0100
[2025-05-07 03:40:36,221][train][INFO] - Epoch 1660/2000, Val Acc=0.5928, Val Loss=1.7176, lr=0.0100
[2025-05-07 03:40:41,220][train][INFO] - Epoch 1630/2000, Val Acc=0.6068, Val Loss=1.7615, lr=0.0100
[2025-05-07 03:40:43,083][train][INFO] - Epoch 1673/2000, Val Acc=0.6093, Val Loss=1.7939, lr=0.0100
[2025-05-07 03:40:43,624][train][INFO] - Epoch 1661/2000, Val Acc=0.5917, Val Loss=1.6983, lr=0.0100
[2025-05-07 03:40:48,938][train][INFO] - Epoch 1631/2000, Val Acc=0.6101, Val Loss=1.7489, lr=0.0100
[2025-05-07 03:40:50,624][train][INFO] - Epoch 1674/2000, Val Acc=0.6237, Val Loss=1.6956, lr=0.0100
[2025-05-07 03:40:51,414][train][INFO] - Epoch 1662/2000, Val Acc=0.5894, Val Loss=1.7663, lr=0.0100
[2025-05-07 03:40:56,919][train][INFO] - Epoch 1632/2000, Val Acc=0.6090, Val Loss=1.8014, lr=0.0100
[2025-05-07 03:40:58,284][train][INFO] - Epoch 1675/2000, Val Acc=0.6185, Val Loss=1.7448, lr=0.0100
[2025-05-07 03:40:59,042][train][INFO] - Epoch 1663/2000, Val Acc=0.6134, Val Loss=1.5965, lr=0.0100
[2025-05-07 03:41:04,765][train][INFO] - Epoch 1633/2000, Val Acc=0.6170, Val Loss=1.7320, lr=0.0100
[2025-05-07 03:41:05,743][train][INFO] - Epoch 1676/2000, Val Acc=0.6199, Val Loss=1.7214, lr=0.0100
[2025-05-07 03:41:06,937][train][INFO] - Epoch 1664/2000, Val Acc=0.5840, Val Loss=1.7058, lr=0.0100
[2025-05-07 03:41:12,477][train][INFO] - Epoch 1634/2000, Val Acc=0.6006, Val Loss=1.8132, lr=0.0100
[2025-05-07 03:41:13,254][train][INFO] - Epoch 1677/2000, Val Acc=0.6160, Val Loss=1.7314, lr=0.0100
[2025-05-07 03:41:14,556][train][INFO] - Epoch 1665/2000, Val Acc=0.5833, Val Loss=1.7978, lr=0.0100
[2025-05-07 03:41:20,528][train][INFO] - Epoch 1635/2000, Val Acc=0.6199, Val Loss=1.7254, lr=0.0100
[2025-05-07 03:41:20,743][train][INFO] - Epoch 1678/2000, Val Acc=0.6194, Val Loss=1.7037, lr=0.0100
[2025-05-07 03:41:22,311][train][INFO] - Epoch 1666/2000, Val Acc=0.5957, Val Loss=1.6954, lr=0.0100
[2025-05-07 03:41:28,087][train][INFO] - Epoch 1636/2000, Val Acc=0.6238, Val Loss=1.6424, lr=0.0100
[2025-05-07 03:41:28,265][train][INFO] - Epoch 1679/2000, Val Acc=0.6182, Val Loss=1.7279, lr=0.0100
[2025-05-07 03:41:30,107][train][INFO] - Epoch 1667/2000, Val Acc=0.5950, Val Loss=1.6781, lr=0.0100
[2025-05-07 03:41:35,999][train][INFO] - Epoch 1680/2000, Val Acc=0.6216, Val Loss=1.6635, lr=0.0100
[2025-05-07 03:41:36,144][train][INFO] - Epoch 1637/2000, Val Acc=0.6159, Val Loss=1.7516, lr=0.0100
[2025-05-07 03:41:38,039][train][INFO] - Epoch 1668/2000, Val Acc=0.5978, Val Loss=1.6665, lr=0.0100
[2025-05-07 03:41:43,448][train][INFO] - Epoch 1638/2000, Val Acc=0.6198, Val Loss=1.6780, lr=0.0100
[2025-05-07 03:41:43,688][train][INFO] - Epoch 1681/2000, Val Acc=0.6219, Val Loss=1.7344, lr=0.0100
[2025-05-07 03:41:45,831][train][INFO] - Epoch 1669/2000, Val Acc=0.6033, Val Loss=1.6663, lr=0.0100
[2025-05-07 03:41:51,437][train][INFO] - Epoch 1682/2000, Val Acc=0.6125, Val Loss=1.7835, lr=0.0100
[2025-05-07 03:41:51,885][train][INFO] - Epoch 1639/2000, Val Acc=0.6262, Val Loss=1.6427, lr=0.0100
[2025-05-07 03:41:53,628][train][INFO] - Epoch 1670/2000, Val Acc=0.5849, Val Loss=1.7406, lr=0.0100
[2025-05-07 03:41:59,070][train][INFO] - Epoch 1683/2000, Val Acc=0.6268, Val Loss=1.6474, lr=0.0100
[2025-05-07 03:41:59,421][train][INFO] - Epoch 1640/2000, Val Acc=0.6139, Val Loss=1.7404, lr=0.0100
[2025-05-07 03:42:01,294][train][INFO] - Epoch 1671/2000, Val Acc=0.5971, Val Loss=1.6867, lr=0.0100
[2025-05-07 03:42:06,700][train][INFO] - Epoch 1684/2000, Val Acc=0.6178, Val Loss=1.7039, lr=0.0100
[2025-05-07 03:42:07,088][train][INFO] - Epoch 1641/2000, Val Acc=0.6127, Val Loss=1.7099, lr=0.0100
[2025-05-07 03:42:09,132][train][INFO] - Epoch 1672/2000, Val Acc=0.5940, Val Loss=1.7080, lr=0.0100
[2025-05-07 03:42:13,892][train][INFO] - Epoch 1685/2000, Val Acc=0.6332, Val Loss=1.6547, lr=0.0100
[2025-05-07 03:42:14,957][train][INFO] - Epoch 1642/2000, Val Acc=0.5951, Val Loss=1.8579, lr=0.0100
[2025-05-07 03:42:16,773][train][INFO] - Epoch 1673/2000, Val Acc=0.5841, Val Loss=1.7479, lr=0.0100
[2025-05-07 03:42:21,460][train][INFO] - Epoch 1686/2000, Val Acc=0.6210, Val Loss=1.7100, lr=0.0100
[2025-05-07 03:42:22,768][train][INFO] - Epoch 1643/2000, Val Acc=0.5971, Val Loss=1.8223, lr=0.0100
[2025-05-07 03:42:24,554][train][INFO] - Epoch 1674/2000, Val Acc=0.6041, Val Loss=1.6294, lr=0.0100
[2025-05-07 03:42:28,991][train][INFO] - Epoch 1687/2000, Val Acc=0.5947, Val Loss=1.8592, lr=0.0100
[2025-05-07 03:42:30,860][train][INFO] - Epoch 1644/2000, Val Acc=0.6120, Val Loss=1.7611, lr=0.0100
[2025-05-07 03:42:32,448][train][INFO] - Epoch 1675/2000, Val Acc=0.5866, Val Loss=1.7455, lr=0.0100
[2025-05-07 03:42:36,781][train][INFO] - Epoch 1688/2000, Val Acc=0.6073, Val Loss=1.8166, lr=0.0100
[2025-05-07 03:42:38,790][train][INFO] - Epoch 1645/2000, Val Acc=0.6123, Val Loss=1.7619, lr=0.0100
[2025-05-07 03:42:40,548][train][INFO] - Epoch 1676/2000, Val Acc=0.5860, Val Loss=1.7403, lr=0.0100
[2025-05-07 03:42:44,733][train][INFO] - Epoch 1689/2000, Val Acc=0.6266, Val Loss=1.6652, lr=0.0100
[2025-05-07 03:42:45,713][train][INFO] - Epoch 1646/2000, Val Acc=0.6006, Val Loss=1.8213, lr=0.0100
[2025-05-07 03:42:48,445][train][INFO] - Epoch 1677/2000, Val Acc=0.5899, Val Loss=1.6918, lr=0.0100
[2025-05-07 03:42:52,393][train][INFO] - Epoch 1690/2000, Val Acc=0.6278, Val Loss=1.6724, lr=0.0100
[2025-05-07 03:42:53,330][train][INFO] - Epoch 1647/2000, Val Acc=0.6254, Val Loss=1.6604, lr=0.0100
[2025-05-07 03:42:55,651][train][INFO] - Epoch 1678/2000, Val Acc=0.5972, Val Loss=1.6818, lr=0.0100
[2025-05-07 03:43:00,246][train][INFO] - Epoch 1691/2000, Val Acc=0.6164, Val Loss=1.7610, lr=0.0100
[2025-05-07 03:43:01,003][train][INFO] - Epoch 1648/2000, Val Acc=0.6165, Val Loss=1.7475, lr=0.0100
[2025-05-07 03:43:02,823][train][INFO] - Epoch 1679/2000, Val Acc=0.6066, Val Loss=1.6276, lr=0.0100
[2025-05-07 03:43:07,998][train][INFO] - Epoch 1692/2000, Val Acc=0.6125, Val Loss=1.6935, lr=0.0100
[2025-05-07 03:43:08,978][train][INFO] - Epoch 1649/2000, Val Acc=0.6115, Val Loss=1.7782, lr=0.0100
[2025-05-07 03:43:10,447][train][INFO] - Epoch 1680/2000, Val Acc=0.5939, Val Loss=1.7086, lr=0.0100
[2025-05-07 03:43:15,446][train][INFO] - Epoch 1693/2000, Val Acc=0.6329, Val Loss=1.6227, lr=0.0100
[2025-05-07 03:43:17,179][train][INFO] - Epoch 1650/2000, Val Acc=0.5980, Val Loss=1.8587, lr=0.0100
[2025-05-07 03:43:18,396][train][INFO] - Epoch 1681/2000, Val Acc=0.5861, Val Loss=1.7747, lr=0.0100
[2025-05-07 03:43:22,565][train][INFO] - Epoch 1694/2000, Val Acc=0.6190, Val Loss=1.7455, lr=0.0100
[2025-05-07 03:43:25,470][train][INFO] - Epoch 1651/2000, Val Acc=0.6100, Val Loss=1.7872, lr=0.0100
[2025-05-07 03:43:26,066][train][INFO] - Epoch 1682/2000, Val Acc=0.6100, Val Loss=1.6098, lr=0.0100
[2025-05-07 03:43:29,954][train][INFO] - Epoch 1695/2000, Val Acc=0.6173, Val Loss=1.7081, lr=0.0100
[2025-05-07 03:43:32,834][train][INFO] - Epoch 1652/2000, Val Acc=0.6066, Val Loss=1.8260, lr=0.0100
[2025-05-07 03:43:33,768][train][INFO] - Epoch 1683/2000, Val Acc=0.5798, Val Loss=1.7562, lr=0.0100
[2025-05-07 03:43:37,359][train][INFO] - Epoch 1696/2000, Val Acc=0.6106, Val Loss=1.7817, lr=0.0100
[2025-05-07 03:43:41,138][train][INFO] - Epoch 1653/2000, Val Acc=0.6246, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:43:41,547][train][INFO] - Epoch 1684/2000, Val Acc=0.5999, Val Loss=1.6314, lr=0.0100
[2025-05-07 03:43:44,616][train][INFO] - Epoch 1697/2000, Val Acc=0.6298, Val Loss=1.6878, lr=0.0100
[2025-05-07 03:43:49,492][train][INFO] - Epoch 1685/2000, Val Acc=0.5911, Val Loss=1.7254, lr=0.0100
[2025-05-07 03:43:49,668][train][INFO] - Epoch 1654/2000, Val Acc=0.6197, Val Loss=1.7072, lr=0.0100
[2025-05-07 03:43:52,451][train][INFO] - Epoch 1698/2000, Val Acc=0.6202, Val Loss=1.6870, lr=0.0100
[2025-05-07 03:43:57,276][train][INFO] - Epoch 1655/2000, Val Acc=0.6304, Val Loss=1.6802, lr=0.0100
[2025-05-07 03:43:57,352][train][INFO] - Epoch 1686/2000, Val Acc=0.5885, Val Loss=1.7546, lr=0.0100
[2025-05-07 03:44:00,223][train][INFO] - Epoch 1699/2000, Val Acc=0.6200, Val Loss=1.7112, lr=0.0100
[2025-05-07 03:44:05,002][train][INFO] - Epoch 1656/2000, Val Acc=0.6182, Val Loss=1.7554, lr=0.0100
[2025-05-07 03:44:05,255][train][INFO] - Epoch 1687/2000, Val Acc=0.5792, Val Loss=1.7987, lr=0.0100
[2025-05-07 03:44:07,849][train][INFO] - Epoch 1700/2000, Val Acc=0.6110, Val Loss=1.7735, lr=0.0100
[2025-05-07 03:44:12,763][train][INFO] - Epoch 1688/2000, Val Acc=0.5852, Val Loss=1.7295, lr=0.0100
[2025-05-07 03:44:12,990][train][INFO] - Epoch 1657/2000, Val Acc=0.6244, Val Loss=1.6716, lr=0.0100
[2025-05-07 03:44:15,194][train][INFO] - Epoch 1701/2000, Val Acc=0.6338, Val Loss=1.6625, lr=0.0100
[2025-05-07 03:44:20,579][train][INFO] - Epoch 1689/2000, Val Acc=0.5902, Val Loss=1.7053, lr=0.0100
[2025-05-07 03:44:21,195][train][INFO] - Epoch 1658/2000, Val Acc=0.6177, Val Loss=1.7151, lr=0.0100
[2025-05-07 03:44:22,780][train][INFO] - Epoch 1702/2000, Val Acc=0.6230, Val Loss=1.6965, lr=0.0100
[2025-05-07 03:44:27,744][train][INFO] - Epoch 1690/2000, Val Acc=0.5976, Val Loss=1.6597, lr=0.0100
[2025-05-07 03:44:29,016][train][INFO] - Epoch 1659/2000, Val Acc=0.6203, Val Loss=1.7320, lr=0.0100
[2025-05-07 03:44:30,068][train][INFO] - Epoch 1703/2000, Val Acc=0.6055, Val Loss=1.7998, lr=0.0100
[2025-05-07 03:44:35,822][train][INFO] - Epoch 1691/2000, Val Acc=0.5951, Val Loss=1.6880, lr=0.0100
[2025-05-07 03:44:36,776][train][INFO] - Epoch 1660/2000, Val Acc=0.6253, Val Loss=1.6974, lr=0.0100
[2025-05-07 03:44:38,089][train][INFO] - Epoch 1704/2000, Val Acc=0.6178, Val Loss=1.7646, lr=0.0100
[2025-05-07 03:44:43,113][train][INFO] - Epoch 1692/2000, Val Acc=0.5876, Val Loss=1.7370, lr=0.0100
[2025-05-07 03:44:44,559][train][INFO] - Epoch 1661/2000, Val Acc=0.6222, Val Loss=1.7134, lr=0.0100
[2025-05-07 03:44:45,656][train][INFO] - Epoch 1705/2000, Val Acc=0.5986, Val Loss=1.8002, lr=0.0100
[2025-05-07 03:44:50,931][train][INFO] - Epoch 1693/2000, Val Acc=0.5894, Val Loss=1.7384, lr=0.0100
[2025-05-07 03:44:52,690][train][INFO] - Epoch 1662/2000, Val Acc=0.6099, Val Loss=1.7765, lr=0.0100
[2025-05-07 03:44:53,497][train][INFO] - Epoch 1706/2000, Val Acc=0.6146, Val Loss=1.7558, lr=0.0100
[2025-05-07 03:44:58,577][train][INFO] - Epoch 1694/2000, Val Acc=0.5853, Val Loss=1.7352, lr=0.0100
[2025-05-07 03:45:00,774][train][INFO] - Epoch 1663/2000, Val Acc=0.6220, Val Loss=1.7108, lr=0.0100
[2025-05-07 03:45:01,264][train][INFO] - Epoch 1707/2000, Val Acc=0.6035, Val Loss=1.8629, lr=0.0100
[2025-05-07 03:45:06,177][train][INFO] - Epoch 1695/2000, Val Acc=0.5797, Val Loss=1.7713, lr=0.0100
[2025-05-07 03:45:08,688][train][INFO] - Epoch 1708/2000, Val Acc=0.6079, Val Loss=1.7857, lr=0.0100
[2025-05-07 03:45:08,899][train][INFO] - Epoch 1664/2000, Val Acc=0.6108, Val Loss=1.7963, lr=0.0100
[2025-05-07 03:45:13,928][train][INFO] - Epoch 1696/2000, Val Acc=0.5911, Val Loss=1.7250, lr=0.0100
[2025-05-07 03:45:16,385][train][INFO] - Epoch 1709/2000, Val Acc=0.6268, Val Loss=1.6973, lr=0.0100
[2025-05-07 03:45:16,944][train][INFO] - Epoch 1665/2000, Val Acc=0.6069, Val Loss=1.7812, lr=0.0100
[2025-05-07 03:45:21,544][train][INFO] - Epoch 1697/2000, Val Acc=0.5893, Val Loss=1.7109, lr=0.0100
[2025-05-07 03:45:23,617][train][INFO] - Epoch 1710/2000, Val Acc=0.5933, Val Loss=1.8696, lr=0.0100
[2025-05-07 03:45:24,705][train][INFO] - Epoch 1666/2000, Val Acc=0.6093, Val Loss=1.7900, lr=0.0100
[2025-05-07 03:45:29,290][train][INFO] - Epoch 1698/2000, Val Acc=0.5965, Val Loss=1.6881, lr=0.0100
[2025-05-07 03:45:31,463][train][INFO] - Epoch 1711/2000, Val Acc=0.6360, Val Loss=1.6683, lr=0.0100
[2025-05-07 03:45:32,665][train][INFO] - Epoch 1667/2000, Val Acc=0.6225, Val Loss=1.6895, lr=0.0100
[2025-05-07 03:45:37,221][train][INFO] - Epoch 1699/2000, Val Acc=0.5958, Val Loss=1.6971, lr=0.0100
[2025-05-07 03:45:39,532][train][INFO] - Epoch 1712/2000, Val Acc=0.6296, Val Loss=1.7125, lr=0.0100
[2025-05-07 03:45:40,130][train][INFO] - Epoch 1668/2000, Val Acc=0.6135, Val Loss=1.7693, lr=0.0100
[2025-05-07 03:45:45,062][train][INFO] - Epoch 1700/2000, Val Acc=0.6018, Val Loss=1.6970, lr=0.0100
[2025-05-07 03:45:46,941][train][INFO] - Epoch 1713/2000, Val Acc=0.6065, Val Loss=1.7993, lr=0.0100
[2025-05-07 03:45:48,204][train][INFO] - Epoch 1669/2000, Val Acc=0.6200, Val Loss=1.7441, lr=0.0100
[2025-05-07 03:45:53,274][train][INFO] - Epoch 1701/2000, Val Acc=0.6004, Val Loss=1.7116, lr=0.0100
[2025-05-07 03:45:54,923][train][INFO] - Epoch 1714/2000, Val Acc=0.6290, Val Loss=1.6501, lr=0.0100
[2025-05-07 03:45:56,071][train][INFO] - Epoch 1670/2000, Val Acc=0.5979, Val Loss=1.8497, lr=0.0100
[2025-05-07 03:46:01,102][train][INFO] - Epoch 1702/2000, Val Acc=0.6026, Val Loss=1.6561, lr=0.0100
[2025-05-07 03:46:02,772][train][INFO] - Epoch 1715/2000, Val Acc=0.6117, Val Loss=1.7792, lr=0.0100
[2025-05-07 03:46:03,750][train][INFO] - Epoch 1671/2000, Val Acc=0.6248, Val Loss=1.6840, lr=0.0100
[2025-05-07 03:46:08,917][train][INFO] - Epoch 1703/2000, Val Acc=0.5938, Val Loss=1.7232, lr=0.0100
[2025-05-07 03:46:10,474][train][INFO] - Epoch 1716/2000, Val Acc=0.6264, Val Loss=1.7209, lr=0.0100
[2025-05-07 03:46:11,458][train][INFO] - Epoch 1672/2000, Val Acc=0.6031, Val Loss=1.8031, lr=0.0100
[2025-05-07 03:46:16,638][train][INFO] - Epoch 1704/2000, Val Acc=0.5829, Val Loss=1.7680, lr=0.0100
[2025-05-07 03:46:17,975][train][INFO] - Epoch 1717/2000, Val Acc=0.6339, Val Loss=1.6892, lr=0.0100
[2025-05-07 03:46:19,249][train][INFO] - Epoch 1673/2000, Val Acc=0.6093, Val Loss=1.7939, lr=0.0100
[2025-05-07 03:46:23,926][train][INFO] - Epoch 1705/2000, Val Acc=0.6048, Val Loss=1.6426, lr=0.0100
[2025-05-07 03:46:25,419][train][INFO] - Epoch 1718/2000, Val Acc=0.6120, Val Loss=1.7546, lr=0.0100
[2025-05-07 03:46:27,234][train][INFO] - Epoch 1674/2000, Val Acc=0.6237, Val Loss=1.6956, lr=0.0100
[2025-05-07 03:46:31,480][train][INFO] - Epoch 1706/2000, Val Acc=0.5851, Val Loss=1.7601, lr=0.0100
[2025-05-07 03:46:32,328][train][INFO] - Epoch 1719/2000, Val Acc=0.6187, Val Loss=1.6980, lr=0.0100
[2025-05-07 03:46:34,984][train][INFO] - Epoch 1675/2000, Val Acc=0.6185, Val Loss=1.7448, lr=0.0100
[2025-05-07 03:46:39,956][train][INFO] - Epoch 1707/2000, Val Acc=0.5969, Val Loss=1.6896, lr=0.0100
[2025-05-07 03:46:40,234][train][INFO] - Epoch 1720/2000, Val Acc=0.6138, Val Loss=1.7282, lr=0.0100
[2025-05-07 03:46:43,091][train][INFO] - Epoch 1676/2000, Val Acc=0.6199, Val Loss=1.7214, lr=0.0100
[2025-05-07 03:46:47,932][train][INFO] - Epoch 1708/2000, Val Acc=0.5989, Val Loss=1.6605, lr=0.0100
[2025-05-07 03:46:47,994][train][INFO] - Epoch 1721/2000, Val Acc=0.6193, Val Loss=1.7167, lr=0.0100
[2025-05-07 03:46:50,707][train][INFO] - Epoch 1677/2000, Val Acc=0.6160, Val Loss=1.7314, lr=0.0100
[2025-05-07 03:46:55,680][train][INFO] - Epoch 1722/2000, Val Acc=0.6333, Val Loss=1.6544, lr=0.0100
[2025-05-07 03:46:55,809][train][INFO] - Epoch 1709/2000, Val Acc=0.5890, Val Loss=1.7564, lr=0.0100
[2025-05-07 03:46:58,545][train][INFO] - Epoch 1678/2000, Val Acc=0.6194, Val Loss=1.7037, lr=0.0100
[2025-05-07 03:47:03,052][train][INFO] - Epoch 1723/2000, Val Acc=0.6199, Val Loss=1.7107, lr=0.0100
[2025-05-07 03:47:03,826][train][INFO] - Epoch 1710/2000, Val Acc=0.5932, Val Loss=1.6655, lr=0.0100
[2025-05-07 03:47:06,515][train][INFO] - Epoch 1679/2000, Val Acc=0.6182, Val Loss=1.7279, lr=0.0100
[2025-05-07 03:47:10,847][train][INFO] - Epoch 1724/2000, Val Acc=0.6178, Val Loss=1.7405, lr=0.0100
[2025-05-07 03:47:11,602][train][INFO] - Epoch 1711/2000, Val Acc=0.5969, Val Loss=1.6512, lr=0.0100
[2025-05-07 03:47:14,768][train][INFO] - Epoch 1680/2000, Val Acc=0.6216, Val Loss=1.6635, lr=0.0100
[2025-05-07 03:47:18,635][train][INFO] - Epoch 1725/2000, Val Acc=0.6104, Val Loss=1.7912, lr=0.0100
[2025-05-07 03:47:19,390][train][INFO] - Epoch 1712/2000, Val Acc=0.5977, Val Loss=1.6619, lr=0.0100
[2025-05-07 03:47:22,434][train][INFO] - Epoch 1681/2000, Val Acc=0.6219, Val Loss=1.7344, lr=0.0100
[2025-05-07 03:47:26,302][train][INFO] - Epoch 1726/2000, Val Acc=0.6137, Val Loss=1.7799, lr=0.0100
[2025-05-07 03:47:26,794][train][INFO] - Epoch 1713/2000, Val Acc=0.6003, Val Loss=1.6763, lr=0.0100
[2025-05-07 03:47:29,876][train][INFO] - Epoch 1682/2000, Val Acc=0.6125, Val Loss=1.7835, lr=0.0100
[2025-05-07 03:47:34,000][train][INFO] - Epoch 1727/2000, Val Acc=0.6320, Val Loss=1.6575, lr=0.0100
[2025-05-07 03:47:35,023][train][INFO] - Epoch 1714/2000, Val Acc=0.5840, Val Loss=1.7616, lr=0.0100
[2025-05-07 03:47:37,943][train][INFO] - Epoch 1683/2000, Val Acc=0.6268, Val Loss=1.6474, lr=0.0100
[2025-05-07 03:47:41,684][train][INFO] - Epoch 1728/2000, Val Acc=0.6056, Val Loss=1.8137, lr=0.0100
[2025-05-07 03:47:42,628][train][INFO] - Epoch 1715/2000, Val Acc=0.5931, Val Loss=1.7080, lr=0.0100
[2025-05-07 03:47:45,478][train][INFO] - Epoch 1684/2000, Val Acc=0.6178, Val Loss=1.7039, lr=0.0100
[2025-05-07 03:47:49,438][train][INFO] - Epoch 1729/2000, Val Acc=0.5980, Val Loss=1.8146, lr=0.0100
[2025-05-07 03:47:50,394][train][INFO] - Epoch 1716/2000, Val Acc=0.5989, Val Loss=1.6717, lr=0.0100
[2025-05-07 03:47:53,671][train][INFO] - Epoch 1685/2000, Val Acc=0.6332, Val Loss=1.6547, lr=0.0100
[2025-05-07 03:47:56,901][train][INFO] - Epoch 1730/2000, Val Acc=0.5834, Val Loss=1.8863, lr=0.0100
[2025-05-07 03:47:58,196][train][INFO] - Epoch 1717/2000, Val Acc=0.5994, Val Loss=1.6979, lr=0.0100
[2025-05-07 03:48:01,380][train][INFO] - Epoch 1686/2000, Val Acc=0.6210, Val Loss=1.7100, lr=0.0100
[2025-05-07 03:48:04,052][train][INFO] - Epoch 1731/2000, Val Acc=0.6372, Val Loss=1.6179, lr=0.0100
[2025-05-07 03:48:05,369][train][INFO] - Epoch 1718/2000, Val Acc=0.5940, Val Loss=1.6776, lr=0.0100
[2025-05-07 03:48:09,033][train][INFO] - Epoch 1687/2000, Val Acc=0.5947, Val Loss=1.8592, lr=0.0100
[2025-05-07 03:48:11,736][train][INFO] - Epoch 1732/2000, Val Acc=0.6155, Val Loss=1.7685, lr=0.0100
[2025-05-07 03:48:12,863][train][INFO] - Epoch 1719/2000, Val Acc=0.5918, Val Loss=1.7343, lr=0.0100
[2025-05-07 03:48:16,824][train][INFO] - Epoch 1688/2000, Val Acc=0.6073, Val Loss=1.8166, lr=0.0100
[2025-05-07 03:48:19,629][train][INFO] - Epoch 1733/2000, Val Acc=0.6239, Val Loss=1.6811, lr=0.0100
[2025-05-07 03:48:20,237][train][INFO] - Epoch 1720/2000, Val Acc=0.5882, Val Loss=1.6971, lr=0.0100
[2025-05-07 03:48:25,104][train][INFO] - Epoch 1689/2000, Val Acc=0.6266, Val Loss=1.6652, lr=0.0100
[2025-05-07 03:48:27,327][train][INFO] - Epoch 1734/2000, Val Acc=0.6300, Val Loss=1.6756, lr=0.0100
[2025-05-07 03:48:27,728][train][INFO] - Epoch 1721/2000, Val Acc=0.5831, Val Loss=1.7672, lr=0.0100
[2025-05-07 03:48:32,738][train][INFO] - Epoch 1690/2000, Val Acc=0.6278, Val Loss=1.6724, lr=0.0100
[2025-05-07 03:48:35,195][train][INFO] - Epoch 1735/2000, Val Acc=0.6127, Val Loss=1.8101, lr=0.0100
[2025-05-07 03:48:35,641][train][INFO] - Epoch 1722/2000, Val Acc=0.5950, Val Loss=1.7109, lr=0.0100
[2025-05-07 03:48:40,505][train][INFO] - Epoch 1691/2000, Val Acc=0.6164, Val Loss=1.7610, lr=0.0100
[2025-05-07 03:48:42,948][train][INFO] - Epoch 1736/2000, Val Acc=0.6039, Val Loss=1.8093, lr=0.0100
[2025-05-07 03:48:43,214][train][INFO] - Epoch 1723/2000, Val Acc=0.5920, Val Loss=1.7027, lr=0.0100
[2025-05-07 03:48:48,178][train][INFO] - Epoch 1692/2000, Val Acc=0.6125, Val Loss=1.6935, lr=0.0100
[2025-05-07 03:48:50,616][train][INFO] - Epoch 1737/2000, Val Acc=0.6180, Val Loss=1.7491, lr=0.0100
[2025-05-07 03:48:51,201][train][INFO] - Epoch 1724/2000, Val Acc=0.5964, Val Loss=1.6980, lr=0.0100
[2025-05-07 03:48:56,053][train][INFO] - Epoch 1693/2000, Val Acc=0.6329, Val Loss=1.6227, lr=0.0100
[2025-05-07 03:48:58,227][train][INFO] - Epoch 1738/2000, Val Acc=0.6157, Val Loss=1.7144, lr=0.0100
[2025-05-07 03:48:59,076][train][INFO] - Epoch 1725/2000, Val Acc=0.5718, Val Loss=1.8489, lr=0.0100
[2025-05-07 03:49:03,562][train][INFO] - Epoch 1694/2000, Val Acc=0.6190, Val Loss=1.7455, lr=0.0100
[2025-05-07 03:49:05,583][train][INFO] - Epoch 1739/2000, Val Acc=0.6196, Val Loss=1.7030, lr=0.0100
[2025-05-07 03:49:07,245][train][INFO] - Epoch 1726/2000, Val Acc=0.5729, Val Loss=1.8238, lr=0.0100
[2025-05-07 03:49:11,242][train][INFO] - Epoch 1695/2000, Val Acc=0.6173, Val Loss=1.7081, lr=0.0100
[2025-05-07 03:49:12,872][train][INFO] - Epoch 1740/2000, Val Acc=0.6177, Val Loss=1.7092, lr=0.0100
[2025-05-07 03:49:15,110][train][INFO] - Epoch 1727/2000, Val Acc=0.5992, Val Loss=1.6665, lr=0.0100
[2025-05-07 03:49:18,870][train][INFO] - Epoch 1696/2000, Val Acc=0.6106, Val Loss=1.7817, lr=0.0100
[2025-05-07 03:49:20,313][train][INFO] - Epoch 1741/2000, Val Acc=0.6319, Val Loss=1.6397, lr=0.0100
[2025-05-07 03:49:22,621][train][INFO] - Epoch 1728/2000, Val Acc=0.5992, Val Loss=1.6699, lr=0.0100
[2025-05-07 03:49:26,723][train][INFO] - Epoch 1697/2000, Val Acc=0.6298, Val Loss=1.6878, lr=0.0100
[2025-05-07 03:49:27,659][train][INFO] - Epoch 1742/2000, Val Acc=0.6240, Val Loss=1.6949, lr=0.0100
[2025-05-07 03:49:30,517][train][INFO] - Epoch 1729/2000, Val Acc=0.6107, Val Loss=1.6154, lr=0.0100
[2025-05-07 03:49:34,728][train][INFO] - Epoch 1743/2000, Val Acc=0.6123, Val Loss=1.7646, lr=0.0100
[2025-05-07 03:49:34,906][train][INFO] - Epoch 1698/2000, Val Acc=0.6202, Val Loss=1.6870, lr=0.0100
[2025-05-07 03:49:38,451][train][INFO] - Epoch 1730/2000, Val Acc=0.6037, Val Loss=1.6338, lr=0.0100
[2025-05-07 03:49:42,392][train][INFO] - Epoch 1744/2000, Val Acc=0.6128, Val Loss=1.7689, lr=0.0100
[2025-05-07 03:49:42,695][train][INFO] - Epoch 1699/2000, Val Acc=0.6200, Val Loss=1.7112, lr=0.0100
[2025-05-07 03:49:46,287][train][INFO] - Epoch 1731/2000, Val Acc=0.6067, Val Loss=1.6383, lr=0.0100
[2025-05-07 03:49:49,967][train][INFO] - Epoch 1745/2000, Val Acc=0.6199, Val Loss=1.6899, lr=0.0100
[2025-05-07 03:49:50,558][train][INFO] - Epoch 1700/2000, Val Acc=0.6110, Val Loss=1.7735, lr=0.0100
[2025-05-07 03:49:53,952][train][INFO] - Epoch 1732/2000, Val Acc=0.5989, Val Loss=1.6709, lr=0.0100
[2025-05-07 03:49:57,575][train][INFO] - Epoch 1746/2000, Val Acc=0.6005, Val Loss=1.8168, lr=0.0100
[2025-05-07 03:49:58,356][train][INFO] - Epoch 1701/2000, Val Acc=0.6338, Val Loss=1.6625, lr=0.0100
[2025-05-07 03:50:01,637][train][INFO] - Epoch 1733/2000, Val Acc=0.6134, Val Loss=1.6005, lr=0.0100
[2025-05-07 03:50:05,455][train][INFO] - Epoch 1747/2000, Val Acc=0.6213, Val Loss=1.7097, lr=0.0100
[2025-05-07 03:50:06,346][train][INFO] - Epoch 1702/2000, Val Acc=0.6230, Val Loss=1.6965, lr=0.0100
[2025-05-07 03:50:09,092][train][INFO] - Epoch 1734/2000, Val Acc=0.6056, Val Loss=1.6586, lr=0.0100
[2025-05-07 03:50:13,258][train][INFO] - Epoch 1748/2000, Val Acc=0.6332, Val Loss=1.6581, lr=0.0100
[2025-05-07 03:50:14,213][train][INFO] - Epoch 1703/2000, Val Acc=0.6055, Val Loss=1.7998, lr=0.0100
[2025-05-07 03:50:17,056][train][INFO] - Epoch 1735/2000, Val Acc=0.5815, Val Loss=1.7823, lr=0.0100
[2025-05-07 03:50:20,880][train][INFO] - Epoch 1749/2000, Val Acc=0.6233, Val Loss=1.7127, lr=0.0100
[2025-05-07 03:50:22,288][train][INFO] - Epoch 1704/2000, Val Acc=0.6178, Val Loss=1.7646, lr=0.0100
[2025-05-07 03:50:24,830][train][INFO] - Epoch 1736/2000, Val Acc=0.5981, Val Loss=1.6946, lr=0.0100
[2025-05-07 03:50:28,680][train][INFO] - Epoch 1750/2000, Val Acc=0.6194, Val Loss=1.7369, lr=0.0100
[2025-05-07 03:50:30,130][train][INFO] - Epoch 1705/2000, Val Acc=0.5986, Val Loss=1.8002, lr=0.0100
[2025-05-07 03:50:32,536][train][INFO] - Epoch 1737/2000, Val Acc=0.5837, Val Loss=1.7560, lr=0.0100
[2025-05-07 03:50:36,596][train][INFO] - Epoch 1751/2000, Val Acc=0.6251, Val Loss=1.6947, lr=0.0100
[2025-05-07 03:50:37,519][train][INFO] - Epoch 1706/2000, Val Acc=0.6146, Val Loss=1.7558, lr=0.0100
[2025-05-07 03:50:40,110][train][INFO] - Epoch 1738/2000, Val Acc=0.6013, Val Loss=1.6889, lr=0.0100
[2025-05-07 03:50:44,221][train][INFO] - Epoch 1752/2000, Val Acc=0.6138, Val Loss=1.7369, lr=0.0100
[2025-05-07 03:50:45,649][train][INFO] - Epoch 1707/2000, Val Acc=0.6035, Val Loss=1.8629, lr=0.0100
[2025-05-07 03:50:47,892][train][INFO] - Epoch 1739/2000, Val Acc=0.6080, Val Loss=1.6599, lr=0.0100
[2025-05-07 03:50:51,702][train][INFO] - Epoch 1753/2000, Val Acc=0.6165, Val Loss=1.7606, lr=0.0100
[2025-05-07 03:50:53,155][train][INFO] - Epoch 1708/2000, Val Acc=0.6079, Val Loss=1.7857, lr=0.0100
[2025-05-07 03:50:55,540][train][INFO] - Epoch 1740/2000, Val Acc=0.5670, Val Loss=1.8599, lr=0.0100
[2025-05-07 03:50:59,308][train][INFO] - Epoch 1754/2000, Val Acc=0.6086, Val Loss=1.7891, lr=0.0100
[2025-05-07 03:51:01,065][train][INFO] - Epoch 1709/2000, Val Acc=0.6268, Val Loss=1.6973, lr=0.0100
[2025-05-07 03:51:03,499][train][INFO] - Epoch 1741/2000, Val Acc=0.5791, Val Loss=1.8178, lr=0.0100
[2025-05-07 03:51:07,329][train][INFO] - Epoch 1755/2000, Val Acc=0.6272, Val Loss=1.6620, lr=0.0100
[2025-05-07 03:51:09,034][train][INFO] - Epoch 1710/2000, Val Acc=0.5933, Val Loss=1.8696, lr=0.0100
[2025-05-07 03:51:11,231][train][INFO] - Epoch 1742/2000, Val Acc=0.5934, Val Loss=1.7038, lr=0.0100
[2025-05-07 03:51:14,853][train][INFO] - Epoch 1756/2000, Val Acc=0.6110, Val Loss=1.7333, lr=0.0100
[2025-05-07 03:51:16,993][train][INFO] - Epoch 1711/2000, Val Acc=0.6360, Val Loss=1.6683, lr=0.0100
[2025-05-07 03:51:19,362][train][INFO] - Epoch 1743/2000, Val Acc=0.5986, Val Loss=1.6476, lr=0.0100
[2025-05-07 03:51:22,619][train][INFO] - Epoch 1757/2000, Val Acc=0.6110, Val Loss=1.7769, lr=0.0100
[2025-05-07 03:51:25,106][train][INFO] - Epoch 1712/2000, Val Acc=0.6296, Val Loss=1.7125, lr=0.0100
[2025-05-07 03:51:27,205][train][INFO] - Epoch 1744/2000, Val Acc=0.5769, Val Loss=1.8049, lr=0.0100
[2025-05-07 03:51:29,560][train][INFO] - Epoch 1758/2000, Val Acc=0.6142, Val Loss=1.7826, lr=0.0100
[2025-05-07 03:51:32,933][train][INFO] - Epoch 1713/2000, Val Acc=0.6065, Val Loss=1.7993, lr=0.0100
[2025-05-07 03:51:34,709][train][INFO] - Epoch 1745/2000, Val Acc=0.5967, Val Loss=1.6728, lr=0.0100
[2025-05-07 03:51:37,199][train][INFO] - Epoch 1759/2000, Val Acc=0.6157, Val Loss=1.7533, lr=0.0100
[2025-05-07 03:51:40,920][train][INFO] - Epoch 1714/2000, Val Acc=0.6290, Val Loss=1.6501, lr=0.0100
[2025-05-07 03:51:42,182][train][INFO] - Epoch 1746/2000, Val Acc=0.5974, Val Loss=1.6768, lr=0.0100
[2025-05-07 03:51:44,501][train][INFO] - Epoch 1760/2000, Val Acc=0.6110, Val Loss=1.7776, lr=0.0100
[2025-05-07 03:51:48,690][train][INFO] - Epoch 1715/2000, Val Acc=0.6117, Val Loss=1.7792, lr=0.0100
[2025-05-07 03:51:49,819][train][INFO] - Epoch 1747/2000, Val Acc=0.5768, Val Loss=1.8077, lr=0.0100
[2025-05-07 03:51:52,265][train][INFO] - Epoch 1761/2000, Val Acc=0.6270, Val Loss=1.6788, lr=0.0100
[2025-05-07 03:51:56,503][train][INFO] - Epoch 1716/2000, Val Acc=0.6264, Val Loss=1.7209, lr=0.0100
[2025-05-07 03:51:57,511][train][INFO] - Epoch 1748/2000, Val Acc=0.5927, Val Loss=1.7067, lr=0.0100
[2025-05-07 03:51:59,866][train][INFO] - Epoch 1762/2000, Val Acc=0.6028, Val Loss=1.8312, lr=0.0100
[2025-05-07 03:52:04,443][train][INFO] - Epoch 1717/2000, Val Acc=0.6339, Val Loss=1.6892, lr=0.0100
[2025-05-07 03:52:05,302][train][INFO] - Epoch 1749/2000, Val Acc=0.6001, Val Loss=1.6910, lr=0.0100
[2025-05-07 03:52:07,841][train][INFO] - Epoch 1763/2000, Val Acc=0.6182, Val Loss=1.7299, lr=0.0100
[2025-05-07 03:52:12,309][train][INFO] - Epoch 1718/2000, Val Acc=0.6120, Val Loss=1.7546, lr=0.0100
[2025-05-07 03:52:12,788][train][INFO] - Epoch 1750/2000, Val Acc=0.5872, Val Loss=1.7295, lr=0.0100
[2025-05-07 03:52:15,360][train][INFO] - Epoch 1764/2000, Val Acc=0.6119, Val Loss=1.7865, lr=0.0100
[2025-05-07 03:52:20,170][train][INFO] - Epoch 1719/2000, Val Acc=0.6187, Val Loss=1.6980, lr=0.0100
[2025-05-07 03:52:20,880][train][INFO] - Epoch 1751/2000, Val Acc=0.6060, Val Loss=1.6354, lr=0.0100
[2025-05-07 03:52:22,899][train][INFO] - Epoch 1765/2000, Val Acc=0.6185, Val Loss=1.6994, lr=0.0100
[2025-05-07 03:52:27,556][train][INFO] - Epoch 1720/2000, Val Acc=0.6138, Val Loss=1.7282, lr=0.0100
[2025-05-07 03:52:28,813][train][INFO] - Epoch 1752/2000, Val Acc=0.6150, Val Loss=1.6077, lr=0.0100
[2025-05-07 03:52:30,472][train][INFO] - Epoch 1766/2000, Val Acc=0.6269, Val Loss=1.6927, lr=0.0100
[2025-05-07 03:52:35,567][train][INFO] - Epoch 1721/2000, Val Acc=0.6193, Val Loss=1.7167, lr=0.0100
[2025-05-07 03:52:36,169][train][INFO] - Epoch 1753/2000, Val Acc=0.5800, Val Loss=1.7894, lr=0.0100
[2025-05-07 03:52:37,774][train][INFO] - Epoch 1767/2000, Val Acc=0.6235, Val Loss=1.7200, lr=0.0100
[2025-05-07 03:52:43,040][train][INFO] - Epoch 1722/2000, Val Acc=0.6333, Val Loss=1.6544, lr=0.0100
[2025-05-07 03:52:43,927][train][INFO] - Epoch 1754/2000, Val Acc=0.6035, Val Loss=1.6494, lr=0.0100
[2025-05-07 03:52:45,495][train][INFO] - Epoch 1768/2000, Val Acc=0.6154, Val Loss=1.7730, lr=0.0100
[2025-05-07 03:52:51,142][train][INFO] - Epoch 1723/2000, Val Acc=0.6199, Val Loss=1.7107, lr=0.0100
[2025-05-07 03:52:52,015][train][INFO] - Epoch 1755/2000, Val Acc=0.6111, Val Loss=1.6182, lr=0.0100
[2025-05-07 03:52:53,279][train][INFO] - Epoch 1769/2000, Val Acc=0.6260, Val Loss=1.6844, lr=0.0100
[2025-05-07 03:52:59,370][train][INFO] - Epoch 1724/2000, Val Acc=0.6178, Val Loss=1.7405, lr=0.0100
[2025-05-07 03:52:59,895][train][INFO] - Epoch 1756/2000, Val Acc=0.5861, Val Loss=1.7449, lr=0.0100
[2025-05-07 03:53:00,530][train][INFO] - Epoch 1770/2000, Val Acc=0.6280, Val Loss=1.6462, lr=0.0100
[2025-05-07 03:53:07,576][train][INFO] - Epoch 1725/2000, Val Acc=0.6104, Val Loss=1.7912, lr=0.0100
[2025-05-07 03:53:07,595][train][INFO] - Epoch 1757/2000, Val Acc=0.5824, Val Loss=1.7508, lr=0.0100
[2025-05-07 03:53:07,967][train][INFO] - Epoch 1771/2000, Val Acc=0.6242, Val Loss=1.6748, lr=0.0100
[2025-05-07 03:53:15,045][train][INFO] - Epoch 1772/2000, Val Acc=0.5988, Val Loss=1.8700, lr=0.0100
[2025-05-07 03:53:15,383][train][INFO] - Epoch 1758/2000, Val Acc=0.5901, Val Loss=1.6943, lr=0.0100
[2025-05-07 03:53:15,671][train][INFO] - Epoch 1726/2000, Val Acc=0.6137, Val Loss=1.7799, lr=0.0100
[2025-05-07 03:53:22,555][train][INFO] - Epoch 1773/2000, Val Acc=0.6214, Val Loss=1.7141, lr=0.0100
[2025-05-07 03:53:22,981][train][INFO] - Epoch 1759/2000, Val Acc=0.5842, Val Loss=1.7367, lr=0.0100
[2025-05-07 03:53:23,115][train][INFO] - Epoch 1727/2000, Val Acc=0.6320, Val Loss=1.6575, lr=0.0100
[2025-05-07 03:53:30,284][train][INFO] - Epoch 1760/2000, Val Acc=0.5875, Val Loss=1.7404, lr=0.0100
[2025-05-07 03:53:30,554][train][INFO] - Epoch 1774/2000, Val Acc=0.6164, Val Loss=1.7013, lr=0.0100
[2025-05-07 03:53:30,752][train][INFO] - Epoch 1728/2000, Val Acc=0.6056, Val Loss=1.8137, lr=0.0100
[2025-05-07 03:53:37,753][train][INFO] - Epoch 1761/2000, Val Acc=0.5952, Val Loss=1.6861, lr=0.0100
[2025-05-07 03:53:38,615][train][INFO] - Epoch 1729/2000, Val Acc=0.5980, Val Loss=1.8146, lr=0.0100
[2025-05-07 03:53:38,707][train][INFO] - Epoch 1775/2000, Val Acc=0.6236, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:53:45,692][train][INFO] - Epoch 1762/2000, Val Acc=0.5822, Val Loss=1.7738, lr=0.0100
[2025-05-07 03:53:46,271][train][INFO] - Epoch 1776/2000, Val Acc=0.6268, Val Loss=1.6745, lr=0.0100
[2025-05-07 03:53:46,935][train][INFO] - Epoch 1730/2000, Val Acc=0.5834, Val Loss=1.8863, lr=0.0100
[2025-05-07 03:53:53,182][train][INFO] - Epoch 1763/2000, Val Acc=0.5890, Val Loss=1.7485, lr=0.0100
[2025-05-07 03:53:54,056][train][INFO] - Epoch 1777/2000, Val Acc=0.6174, Val Loss=1.7179, lr=0.0100
[2025-05-07 03:53:54,630][train][INFO] - Epoch 1731/2000, Val Acc=0.6372, Val Loss=1.6179, lr=0.0100
[2025-05-07 03:54:00,671][train][INFO] - Epoch 1764/2000, Val Acc=0.5833, Val Loss=1.7546, lr=0.0100
[2025-05-07 03:54:01,749][train][INFO] - Epoch 1778/2000, Val Acc=0.6027, Val Loss=1.8405, lr=0.0100
[2025-05-07 03:54:02,775][train][INFO] - Epoch 1732/2000, Val Acc=0.6155, Val Loss=1.7685, lr=0.0100
[2025-05-07 03:54:08,659][train][INFO] - Epoch 1765/2000, Val Acc=0.5895, Val Loss=1.7346, lr=0.0100
[2025-05-07 03:54:09,616][train][INFO] - Epoch 1779/2000, Val Acc=0.6152, Val Loss=1.7256, lr=0.0100
[2025-05-07 03:54:10,594][train][INFO] - Epoch 1733/2000, Val Acc=0.6239, Val Loss=1.6811, lr=0.0100
[2025-05-07 03:54:16,614][train][INFO] - Epoch 1766/2000, Val Acc=0.5941, Val Loss=1.6981, lr=0.0100
[2025-05-07 03:54:17,551][train][INFO] - Epoch 1780/2000, Val Acc=0.5998, Val Loss=1.8898, lr=0.0100
[2025-05-07 03:54:18,556][train][INFO] - Epoch 1734/2000, Val Acc=0.6300, Val Loss=1.6756, lr=0.0100
[2025-05-07 03:54:24,468][train][INFO] - Epoch 1767/2000, Val Acc=0.5785, Val Loss=1.7635, lr=0.0100
[2025-05-07 03:54:25,043][train][INFO] - Epoch 1781/2000, Val Acc=0.6217, Val Loss=1.7130, lr=0.0100
[2025-05-07 03:54:26,701][train][INFO] - Epoch 1735/2000, Val Acc=0.6127, Val Loss=1.8101, lr=0.0100
[2025-05-07 03:54:32,270][train][INFO] - Epoch 1768/2000, Val Acc=0.5966, Val Loss=1.6814, lr=0.0100
[2025-05-07 03:54:33,051][train][INFO] - Epoch 1782/2000, Val Acc=0.6153, Val Loss=1.7395, lr=0.0100
[2025-05-07 03:54:34,631][train][INFO] - Epoch 1736/2000, Val Acc=0.6039, Val Loss=1.8093, lr=0.0100
[2025-05-07 03:54:40,132][train][INFO] - Epoch 1769/2000, Val Acc=0.6029, Val Loss=1.6590, lr=0.0100
[2025-05-07 03:54:40,394][train][INFO] - Epoch 1783/2000, Val Acc=0.6277, Val Loss=1.6694, lr=0.0100
[2025-05-07 03:54:42,949][train][INFO] - Epoch 1737/2000, Val Acc=0.6180, Val Loss=1.7491, lr=0.0100
[2025-05-07 03:54:47,349][train][INFO] - Epoch 1770/2000, Val Acc=0.5923, Val Loss=1.7173, lr=0.0100
[2025-05-07 03:54:48,123][train][INFO] - Epoch 1784/2000, Val Acc=0.6188, Val Loss=1.7478, lr=0.0100
[2025-05-07 03:54:51,225][train][INFO] - Epoch 1738/2000, Val Acc=0.6157, Val Loss=1.7144, lr=0.0100
[2025-05-07 03:54:54,519][train][INFO] - Epoch 1771/2000, Val Acc=0.5970, Val Loss=1.6665, lr=0.0100
[2025-05-07 03:54:55,501][train][INFO] - Epoch 1785/2000, Val Acc=0.6212, Val Loss=1.7034, lr=0.0100
[2025-05-07 03:54:59,064][train][INFO] - Epoch 1739/2000, Val Acc=0.6196, Val Loss=1.7030, lr=0.0100
[2025-05-07 03:55:02,253][train][INFO] - Epoch 1772/2000, Val Acc=0.5979, Val Loss=1.6572, lr=0.0100
[2025-05-07 03:55:03,265][train][INFO] - Epoch 1786/2000, Val Acc=0.6307, Val Loss=1.6689, lr=0.0100
[2025-05-07 03:55:06,370][train][INFO] - Epoch 1740/2000, Val Acc=0.6177, Val Loss=1.7092, lr=0.0100
[2025-05-07 03:55:10,034][train][INFO] - Epoch 1773/2000, Val Acc=0.6147, Val Loss=1.6249, lr=0.0100
[2025-05-07 03:55:10,982][train][INFO] - Epoch 1787/2000, Val Acc=0.6157, Val Loss=1.7262, lr=0.0100
[2025-05-07 03:55:14,221][train][INFO] - Epoch 1741/2000, Val Acc=0.6319, Val Loss=1.6397, lr=0.0100
[2025-05-07 03:55:17,778][train][INFO] - Epoch 1774/2000, Val Acc=0.5880, Val Loss=1.6950, lr=0.0100
[2025-05-07 03:55:18,107][train][INFO] - Epoch 1788/2000, Val Acc=0.6252, Val Loss=1.6818, lr=0.0100
[2025-05-07 03:55:21,568][train][INFO] - Epoch 1742/2000, Val Acc=0.6240, Val Loss=1.6949, lr=0.0100
[2025-05-07 03:55:24,941][train][INFO] - Epoch 1775/2000, Val Acc=0.5878, Val Loss=1.6956, lr=0.0100
[2025-05-07 03:55:25,413][train][INFO] - Epoch 1789/2000, Val Acc=0.6284, Val Loss=1.6920, lr=0.0100
[2025-05-07 03:55:29,237][train][INFO] - Epoch 1743/2000, Val Acc=0.6123, Val Loss=1.7646, lr=0.0100
[2025-05-07 03:55:32,555][train][INFO] - Epoch 1776/2000, Val Acc=0.6076, Val Loss=1.6432, lr=0.0100
[2025-05-07 03:55:33,274][train][INFO] - Epoch 1790/2000, Val Acc=0.6098, Val Loss=1.7635, lr=0.0100
[2025-05-07 03:55:37,466][train][INFO] - Epoch 1744/2000, Val Acc=0.6128, Val Loss=1.7689, lr=0.0100
[2025-05-07 03:55:40,590][train][INFO] - Epoch 1777/2000, Val Acc=0.5964, Val Loss=1.6902, lr=0.0100
[2025-05-07 03:55:41,226][train][INFO] - Epoch 1791/2000, Val Acc=0.6144, Val Loss=1.7846, lr=0.0100
[2025-05-07 03:55:45,236][train][INFO] - Epoch 1745/2000, Val Acc=0.6199, Val Loss=1.6899, lr=0.0100
[2025-05-07 03:55:48,248][train][INFO] - Epoch 1778/2000, Val Acc=0.5795, Val Loss=1.7954, lr=0.0100
[2025-05-07 03:55:48,953][train][INFO] - Epoch 1792/2000, Val Acc=0.6201, Val Loss=1.7192, lr=0.0100
[2025-05-07 03:55:52,586][train][INFO] - Epoch 1746/2000, Val Acc=0.6005, Val Loss=1.8168, lr=0.0100
[2025-05-07 03:55:55,911][train][INFO] - Epoch 1793/2000, Val Acc=0.6085, Val Loss=1.8512, lr=0.0100
[2025-05-07 03:55:56,235][train][INFO] - Epoch 1779/2000, Val Acc=0.6093, Val Loss=1.6068, lr=0.0100
[2025-05-07 03:56:00,343][train][INFO] - Epoch 1747/2000, Val Acc=0.6213, Val Loss=1.7097, lr=0.0100
[2025-05-07 03:56:03,680][train][INFO] - Epoch 1794/2000, Val Acc=0.6250, Val Loss=1.6884, lr=0.0100
[2025-05-07 03:56:04,205][train][INFO] - Epoch 1780/2000, Val Acc=0.5969, Val Loss=1.6679, lr=0.0100
[2025-05-07 03:56:07,999][train][INFO] - Epoch 1748/2000, Val Acc=0.6332, Val Loss=1.6581, lr=0.0100
[2025-05-07 03:56:11,028][train][INFO] - Epoch 1795/2000, Val Acc=0.6265, Val Loss=1.6850, lr=0.0100
[2025-05-07 03:56:11,631][train][INFO] - Epoch 1781/2000, Val Acc=0.6014, Val Loss=1.6607, lr=0.0100
[2025-05-07 03:56:15,755][train][INFO] - Epoch 1749/2000, Val Acc=0.6233, Val Loss=1.7127, lr=0.0100
[2025-05-07 03:56:18,789][train][INFO] - Epoch 1796/2000, Val Acc=0.6233, Val Loss=1.6619, lr=0.0100
[2025-05-07 03:56:19,702][train][INFO] - Epoch 1782/2000, Val Acc=0.5991, Val Loss=1.6693, lr=0.0100
[2025-05-07 03:56:23,654][train][INFO] - Epoch 1750/2000, Val Acc=0.6194, Val Loss=1.7369, lr=0.0100
[2025-05-07 03:56:26,523][train][INFO] - Epoch 1797/2000, Val Acc=0.6190, Val Loss=1.7127, lr=0.0100
[2025-05-07 03:56:27,512][train][INFO] - Epoch 1783/2000, Val Acc=0.5902, Val Loss=1.7146, lr=0.0100
[2025-05-07 03:56:31,339][train][INFO] - Epoch 1751/2000, Val Acc=0.6251, Val Loss=1.6947, lr=0.0100
[2025-05-07 03:56:34,307][train][INFO] - Epoch 1798/2000, Val Acc=0.6168, Val Loss=1.7579, lr=0.0100
[2025-05-07 03:56:35,456][train][INFO] - Epoch 1784/2000, Val Acc=0.5863, Val Loss=1.7208, lr=0.0100
[2025-05-07 03:56:39,099][train][INFO] - Epoch 1752/2000, Val Acc=0.6138, Val Loss=1.7369, lr=0.0100
[2025-05-07 03:56:41,800][train][INFO] - Epoch 1799/2000, Val Acc=0.6256, Val Loss=1.6446, lr=0.0100
[2025-05-07 03:56:43,101][train][INFO] - Epoch 1785/2000, Val Acc=0.6011, Val Loss=1.6594, lr=0.0100
[2025-05-07 03:56:46,440][train][INFO] - Epoch 1753/2000, Val Acc=0.6165, Val Loss=1.7606, lr=0.0100
[2025-05-07 03:56:49,033][train][INFO] - Epoch 1800/2000, Val Acc=0.6044, Val Loss=1.7739, lr=0.0100
[2025-05-07 03:56:50,677][train][INFO] - Epoch 1786/2000, Val Acc=0.6080, Val Loss=1.5938, lr=0.0100
[2025-05-07 03:56:54,223][train][INFO] - Epoch 1754/2000, Val Acc=0.6086, Val Loss=1.7891, lr=0.0100
[2025-05-07 03:56:57,058][train][INFO] - Epoch 1801/2000, Val Acc=0.6268, Val Loss=1.6762, lr=0.0100
[2025-05-07 03:56:58,069][train][INFO] - Epoch 1787/2000, Val Acc=0.5899, Val Loss=1.6767, lr=0.0100
[2025-05-07 03:57:01,925][train][INFO] - Epoch 1755/2000, Val Acc=0.6272, Val Loss=1.6620, lr=0.0100
[2025-05-07 03:57:05,047][train][INFO] - Epoch 1802/2000, Val Acc=0.6324, Val Loss=1.6234, lr=0.0100
[2025-05-07 03:57:05,922][train][INFO] - Epoch 1788/2000, Val Acc=0.6002, Val Loss=1.6836, lr=0.0100
[2025-05-07 03:57:09,677][train][INFO] - Epoch 1756/2000, Val Acc=0.6110, Val Loss=1.7333, lr=0.0100
[2025-05-07 03:57:12,551][train][INFO] - Epoch 1803/2000, Val Acc=0.6118, Val Loss=1.7926, lr=0.0100
[2025-05-07 03:57:13,488][train][INFO] - Epoch 1789/2000, Val Acc=0.6080, Val Loss=1.6626, lr=0.0100
[2025-05-07 03:57:16,792][train][INFO] - Epoch 1757/2000, Val Acc=0.6110, Val Loss=1.7769, lr=0.0100
[2025-05-07 03:57:20,321][train][INFO] - Epoch 1804/2000, Val Acc=0.6312, Val Loss=1.6389, lr=0.0100
[2025-05-07 03:57:21,062][train][INFO] - Epoch 1790/2000, Val Acc=0.5843, Val Loss=1.7337, lr=0.0100
[2025-05-07 03:57:24,714][train][INFO] - Epoch 1758/2000, Val Acc=0.6142, Val Loss=1.7826, lr=0.0100
[2025-05-07 03:57:27,759][train][INFO] - Epoch 1805/2000, Val Acc=0.6222, Val Loss=1.7089, lr=0.0100
[2025-05-07 03:57:28,769][train][INFO] - Epoch 1791/2000, Val Acc=0.6048, Val Loss=1.6781, lr=0.0100
[2025-05-07 03:57:32,319][train][INFO] - Epoch 1759/2000, Val Acc=0.6157, Val Loss=1.7533, lr=0.0100
[2025-05-07 03:57:35,115][train][INFO] - Epoch 1806/2000, Val Acc=0.6190, Val Loss=1.7025, lr=0.0100
[2025-05-07 03:57:36,932][train][INFO] - Epoch 1792/2000, Val Acc=0.5951, Val Loss=1.7219, lr=0.0100
[2025-05-07 03:57:40,162][train][INFO] - Epoch 1760/2000, Val Acc=0.6110, Val Loss=1.7776, lr=0.0100
[2025-05-07 03:57:42,777][train][INFO] - Epoch 1807/2000, Val Acc=0.6198, Val Loss=1.7099, lr=0.0100
[2025-05-07 03:57:44,508][train][INFO] - Epoch 1793/2000, Val Acc=0.5996, Val Loss=1.6676, lr=0.0100
[2025-05-07 03:57:48,181][train][INFO] - Epoch 1761/2000, Val Acc=0.6270, Val Loss=1.6788, lr=0.0100
[2025-05-07 03:57:50,614][train][INFO] - Epoch 1808/2000, Val Acc=0.6094, Val Loss=1.7739, lr=0.0100
[2025-05-07 03:57:52,332][train][INFO] - Epoch 1794/2000, Val Acc=0.5929, Val Loss=1.6741, lr=0.0100
[2025-05-07 03:57:56,137][train][INFO] - Epoch 1762/2000, Val Acc=0.6028, Val Loss=1.8312, lr=0.0100
[2025-05-07 03:57:57,991][train][INFO] - Epoch 1809/2000, Val Acc=0.6102, Val Loss=1.7942, lr=0.0100
[2025-05-07 03:57:59,553][train][INFO] - Epoch 1795/2000, Val Acc=0.6070, Val Loss=1.6427, lr=0.0100
[2025-05-07 03:58:04,102][train][INFO] - Epoch 1763/2000, Val Acc=0.6182, Val Loss=1.7299, lr=0.0100
[2025-05-07 03:58:05,019][train][INFO] - Epoch 1810/2000, Val Acc=0.6144, Val Loss=1.7666, lr=0.0100
[2025-05-07 03:58:06,862][train][INFO] - Epoch 1796/2000, Val Acc=0.6014, Val Loss=1.6543, lr=0.0100
[2025-05-07 03:58:12,150][train][INFO] - Epoch 1764/2000, Val Acc=0.6119, Val Loss=1.7865, lr=0.0100
[2025-05-07 03:58:12,568][train][INFO] - Epoch 1811/2000, Val Acc=0.6217, Val Loss=1.6823, lr=0.0100
[2025-05-07 03:58:14,132][train][INFO] - Epoch 1797/2000, Val Acc=0.5784, Val Loss=1.8364, lr=0.0100
[2025-05-07 03:58:20,161][train][INFO] - Epoch 1765/2000, Val Acc=0.6185, Val Loss=1.6994, lr=0.0100
[2025-05-07 03:58:20,295][train][INFO] - Epoch 1812/2000, Val Acc=0.6285, Val Loss=1.6564, lr=0.0100
[2025-05-07 03:58:21,458][train][INFO] - Epoch 1798/2000, Val Acc=0.6004, Val Loss=1.6465, lr=0.0100
[2025-05-07 03:58:27,716][train][INFO] - Epoch 1813/2000, Val Acc=0.6218, Val Loss=1.7099, lr=0.0100
[2025-05-07 03:58:28,024][train][INFO] - Epoch 1766/2000, Val Acc=0.6269, Val Loss=1.6927, lr=0.0100
[2025-05-07 03:58:29,081][train][INFO] - Epoch 1799/2000, Val Acc=0.5887, Val Loss=1.7431, lr=0.0100
[2025-05-07 03:58:35,263][train][INFO] - Epoch 1814/2000, Val Acc=0.6254, Val Loss=1.6899, lr=0.0100
[2025-05-07 03:58:35,860][train][INFO] - Epoch 1767/2000, Val Acc=0.6235, Val Loss=1.7200, lr=0.0100
[2025-05-07 03:58:36,754][train][INFO] - Epoch 1800/2000, Val Acc=0.5797, Val Loss=1.7617, lr=0.0100
[2025-05-07 03:58:43,323][train][INFO] - Epoch 1815/2000, Val Acc=0.6147, Val Loss=1.7402, lr=0.0100
[2025-05-07 03:58:43,465][train][INFO] - Epoch 1768/2000, Val Acc=0.6154, Val Loss=1.7730, lr=0.0100
[2025-05-07 03:58:44,447][train][INFO] - Epoch 1801/2000, Val Acc=0.6069, Val Loss=1.6452, lr=0.0100
[2025-05-07 03:58:50,634][train][INFO] - Epoch 1816/2000, Val Acc=0.6260, Val Loss=1.6935, lr=0.0100
[2025-05-07 03:58:51,342][train][INFO] - Epoch 1769/2000, Val Acc=0.6260, Val Loss=1.6844, lr=0.0100
[2025-05-07 03:58:52,106][train][INFO] - Epoch 1802/2000, Val Acc=0.5865, Val Loss=1.7443, lr=0.0100
[2025-05-07 03:58:58,165][train][INFO] - Epoch 1817/2000, Val Acc=0.6411, Val Loss=1.6050, lr=0.0100
[2025-05-07 03:58:58,971][train][INFO] - Epoch 1770/2000, Val Acc=0.6280, Val Loss=1.6462, lr=0.0100
[2025-05-07 03:58:59,946][train][INFO] - Epoch 1803/2000, Val Acc=0.5586, Val Loss=1.8996, lr=0.0100
[2025-05-07 03:59:06,330][train][INFO] - Epoch 1818/2000, Val Acc=0.6064, Val Loss=1.8143, lr=0.0100
[2025-05-07 03:59:07,005][train][INFO] - Epoch 1771/2000, Val Acc=0.6242, Val Loss=1.6748, lr=0.0100
[2025-05-07 03:59:07,404][train][INFO] - Epoch 1804/2000, Val Acc=0.5800, Val Loss=1.7969, lr=0.0100
[2025-05-07 03:59:14,112][train][INFO] - Epoch 1819/2000, Val Acc=0.6082, Val Loss=1.7883, lr=0.0100
[2025-05-07 03:59:14,781][train][INFO] - Epoch 1772/2000, Val Acc=0.5988, Val Loss=1.8700, lr=0.0100
[2025-05-07 03:59:14,860][train][INFO] - Epoch 1805/2000, Val Acc=0.6014, Val Loss=1.6446, lr=0.0100
[2025-05-07 03:59:21,617][train][INFO] - Epoch 1820/2000, Val Acc=0.6215, Val Loss=1.6928, lr=0.0100
[2025-05-07 03:59:22,560][train][INFO] - Epoch 1773/2000, Val Acc=0.6214, Val Loss=1.7141, lr=0.0100
[2025-05-07 03:59:22,586][train][INFO] - Epoch 1806/2000, Val Acc=0.6039, Val Loss=1.6514, lr=0.0100
[2025-05-07 03:59:29,563][train][INFO] - Epoch 1821/2000, Val Acc=0.6138, Val Loss=1.7386, lr=0.0100
[2025-05-07 03:59:30,442][train][INFO] - Epoch 1807/2000, Val Acc=0.5889, Val Loss=1.7358, lr=0.0100
[2025-05-07 03:59:30,789][train][INFO] - Epoch 1774/2000, Val Acc=0.6164, Val Loss=1.7013, lr=0.0100
[2025-05-07 03:59:36,790][train][INFO] - Epoch 1822/2000, Val Acc=0.6028, Val Loss=1.8595, lr=0.0100
[2025-05-07 03:59:37,858][train][INFO] - Epoch 1808/2000, Val Acc=0.5866, Val Loss=1.7102, lr=0.0100
[2025-05-07 03:59:38,238][train][INFO] - Epoch 1775/2000, Val Acc=0.6236, Val Loss=1.6992, lr=0.0100
[2025-05-07 03:59:44,475][train][INFO] - Epoch 1823/2000, Val Acc=0.6204, Val Loss=1.7351, lr=0.0100
[2025-05-07 03:59:45,903][train][INFO] - Epoch 1809/2000, Val Acc=0.5729, Val Loss=1.8124, lr=0.0100
[2025-05-07 03:59:46,274][train][INFO] - Epoch 1776/2000, Val Acc=0.6268, Val Loss=1.6745, lr=0.0100
[2025-05-07 03:59:51,906][train][INFO] - Epoch 1824/2000, Val Acc=0.6177, Val Loss=1.7224, lr=0.0100
[2025-05-07 03:59:53,744][train][INFO] - Epoch 1810/2000, Val Acc=0.5932, Val Loss=1.7305, lr=0.0100
[2025-05-07 03:59:54,474][train][INFO] - Epoch 1777/2000, Val Acc=0.6174, Val Loss=1.7179, lr=0.0100
[2025-05-07 03:59:59,428][train][INFO] - Epoch 1825/2000, Val Acc=0.6287, Val Loss=1.6729, lr=0.0100
[2025-05-07 04:00:01,417][train][INFO] - Epoch 1811/2000, Val Acc=0.5923, Val Loss=1.7021, lr=0.0100
[2025-05-07 04:00:02,410][train][INFO] - Epoch 1778/2000, Val Acc=0.6027, Val Loss=1.8405, lr=0.0100
[2025-05-07 04:00:07,051][train][INFO] - Epoch 1826/2000, Val Acc=0.6075, Val Loss=1.8032, lr=0.0100
[2025-05-07 04:00:08,978][train][INFO] - Epoch 1812/2000, Val Acc=0.5873, Val Loss=1.7693, lr=0.0100
[2025-05-07 04:00:10,530][train][INFO] - Epoch 1779/2000, Val Acc=0.6152, Val Loss=1.7256, lr=0.0100
[2025-05-07 04:00:14,753][train][INFO] - Epoch 1827/2000, Val Acc=0.6145, Val Loss=1.7516, lr=0.0100
[2025-05-07 04:00:16,720][train][INFO] - Epoch 1813/2000, Val Acc=0.5970, Val Loss=1.6886, lr=0.0100
[2025-05-07 04:00:18,169][train][INFO] - Epoch 1780/2000, Val Acc=0.5998, Val Loss=1.8898, lr=0.0100
[2025-05-07 04:00:22,338][train][INFO] - Epoch 1828/2000, Val Acc=0.6113, Val Loss=1.7727, lr=0.0100
[2025-05-07 04:00:24,338][train][INFO] - Epoch 1814/2000, Val Acc=0.5860, Val Loss=1.7221, lr=0.0100
[2025-05-07 04:00:25,934][train][INFO] - Epoch 1781/2000, Val Acc=0.6217, Val Loss=1.7130, lr=0.0100
[2025-05-07 04:00:29,965][train][INFO] - Epoch 1829/2000, Val Acc=0.6112, Val Loss=1.7663, lr=0.0100
[2025-05-07 04:00:31,398][train][INFO] - Epoch 1815/2000, Val Acc=0.6004, Val Loss=1.6740, lr=0.0100
[2025-05-07 04:00:33,414][train][INFO] - Epoch 1782/2000, Val Acc=0.6153, Val Loss=1.7395, lr=0.0100
[2025-05-07 04:00:37,385][train][INFO] - Epoch 1830/2000, Val Acc=0.6098, Val Loss=1.7666, lr=0.0100
[2025-05-07 04:00:39,412][train][INFO] - Epoch 1816/2000, Val Acc=0.5997, Val Loss=1.6719, lr=0.0100
[2025-05-07 04:00:40,859][train][INFO] - Epoch 1783/2000, Val Acc=0.6277, Val Loss=1.6694, lr=0.0100
[2025-05-07 04:00:44,930][train][INFO] - Epoch 1831/2000, Val Acc=0.5953, Val Loss=1.8181, lr=0.0100
[2025-05-07 04:00:46,833][train][INFO] - Epoch 1817/2000, Val Acc=0.5897, Val Loss=1.7060, lr=0.0100
[2025-05-07 04:00:48,858][train][INFO] - Epoch 1784/2000, Val Acc=0.6188, Val Loss=1.7478, lr=0.0100
[2025-05-07 04:00:52,795][train][INFO] - Epoch 1832/2000, Val Acc=0.6153, Val Loss=1.7444, lr=0.0100
[2025-05-07 04:00:54,624][train][INFO] - Epoch 1818/2000, Val Acc=0.5857, Val Loss=1.7674, lr=0.0100
[2025-05-07 04:00:56,717][train][INFO] - Epoch 1785/2000, Val Acc=0.6212, Val Loss=1.7034, lr=0.0100
[2025-05-07 04:01:00,225][train][INFO] - Epoch 1833/2000, Val Acc=0.6268, Val Loss=1.6769, lr=0.0100
[2025-05-07 04:01:02,396][train][INFO] - Epoch 1819/2000, Val Acc=0.5878, Val Loss=1.6984, lr=0.0100
[2025-05-07 04:01:04,668][train][INFO] - Epoch 1786/2000, Val Acc=0.6307, Val Loss=1.6689, lr=0.0100
[2025-05-07 04:01:07,522][train][INFO] - Epoch 1834/2000, Val Acc=0.6296, Val Loss=1.7083, lr=0.0100
[2025-05-07 04:01:09,574][train][INFO] - Epoch 1820/2000, Val Acc=0.5941, Val Loss=1.6952, lr=0.0100
[2025-05-07 04:01:12,345][train][INFO] - Epoch 1787/2000, Val Acc=0.6157, Val Loss=1.7262, lr=0.0100
[2025-05-07 04:01:15,086][train][INFO] - Epoch 1835/2000, Val Acc=0.6057, Val Loss=1.8261, lr=0.0100
[2025-05-07 04:01:17,627][train][INFO] - Epoch 1821/2000, Val Acc=0.6081, Val Loss=1.6270, lr=0.0100
[2025-05-07 04:01:20,225][train][INFO] - Epoch 1788/2000, Val Acc=0.6252, Val Loss=1.6818, lr=0.0100
[2025-05-07 04:01:22,483][train][INFO] - Epoch 1836/2000, Val Acc=0.6169, Val Loss=1.7447, lr=0.0100
[2025-05-07 04:01:25,183][train][INFO] - Epoch 1822/2000, Val Acc=0.5937, Val Loss=1.7293, lr=0.0100
[2025-05-07 04:01:27,705][train][INFO] - Epoch 1789/2000, Val Acc=0.6284, Val Loss=1.6920, lr=0.0100
[2025-05-07 04:01:29,687][train][INFO] - Epoch 1837/2000, Val Acc=0.5981, Val Loss=1.8415, lr=0.0100
[2025-05-07 04:01:32,783][train][INFO] - Epoch 1823/2000, Val Acc=0.5892, Val Loss=1.6976, lr=0.0100
[2025-05-07 04:01:35,736][train][INFO] - Epoch 1790/2000, Val Acc=0.6098, Val Loss=1.7635, lr=0.0100
[2025-05-07 04:01:36,870][train][INFO] - Epoch 1838/2000, Val Acc=0.6224, Val Loss=1.7101, lr=0.0100
[2025-05-07 04:01:39,695][train][INFO] - Epoch 1824/2000, Val Acc=0.6072, Val Loss=1.6412, lr=0.0100
[2025-05-07 04:01:43,361][train][INFO] - Epoch 1791/2000, Val Acc=0.6144, Val Loss=1.7846, lr=0.0100
[2025-05-07 04:01:44,498][train][INFO] - Epoch 1839/2000, Val Acc=0.6114, Val Loss=1.7320, lr=0.0100
[2025-05-07 04:01:47,441][train][INFO] - Epoch 1825/2000, Val Acc=0.6026, Val Loss=1.6410, lr=0.0100
[2025-05-07 04:01:51,597][train][INFO] - Epoch 1792/2000, Val Acc=0.6201, Val Loss=1.7192, lr=0.0100
[2025-05-07 04:01:52,360][train][INFO] - Epoch 1840/2000, Val Acc=0.6269, Val Loss=1.7196, lr=0.0100
[2025-05-07 04:01:55,325][train][INFO] - Epoch 1826/2000, Val Acc=0.6086, Val Loss=1.6103, lr=0.0100
[2025-05-07 04:01:59,619][train][INFO] - Epoch 1793/2000, Val Acc=0.6085, Val Loss=1.8512, lr=0.0100
[2025-05-07 04:02:00,080][train][INFO] - Epoch 1841/2000, Val Acc=0.6225, Val Loss=1.7090, lr=0.0100
[2025-05-07 04:02:03,568][train][INFO] - Epoch 1827/2000, Val Acc=0.6035, Val Loss=1.6737, lr=0.0100
[2025-05-07 04:02:07,514][train][INFO] - Epoch 1842/2000, Val Acc=0.6069, Val Loss=1.7863, lr=0.0100
[2025-05-07 04:02:07,571][train][INFO] - Epoch 1794/2000, Val Acc=0.6250, Val Loss=1.6884, lr=0.0100
[2025-05-07 04:02:11,043][train][INFO] - Epoch 1828/2000, Val Acc=0.5943, Val Loss=1.6833, lr=0.0100
[2025-05-07 04:02:14,758][train][INFO] - Epoch 1795/2000, Val Acc=0.6265, Val Loss=1.6850, lr=0.0100
[2025-05-07 04:02:15,081][train][INFO] - Epoch 1843/2000, Val Acc=0.6205, Val Loss=1.7228, lr=0.0100
[2025-05-07 04:02:18,822][train][INFO] - Epoch 1829/2000, Val Acc=0.6082, Val Loss=1.6289, lr=0.0100
[2025-05-07 04:02:21,859][train][INFO] - Epoch 1796/2000, Val Acc=0.6233, Val Loss=1.6619, lr=0.0100
[2025-05-07 04:02:22,569][train][INFO] - Epoch 1844/2000, Val Acc=0.6280, Val Loss=1.7060, lr=0.0100
[2025-05-07 04:02:25,529][train][INFO] - Epoch 1830/2000, Val Acc=0.5869, Val Loss=1.7183, lr=0.0100
[2025-05-07 04:02:29,704][train][INFO] - Epoch 1797/2000, Val Acc=0.6190, Val Loss=1.7127, lr=0.0100
[2025-05-07 04:02:30,157][train][INFO] - Epoch 1845/2000, Val Acc=0.6208, Val Loss=1.7114, lr=0.0100
[2025-05-07 04:02:33,566][train][INFO] - Epoch 1831/2000, Val Acc=0.6024, Val Loss=1.6224, lr=0.0100
[2025-05-07 04:02:37,402][train][INFO] - Epoch 1846/2000, Val Acc=0.6119, Val Loss=1.7479, lr=0.0100
[2025-05-07 04:02:37,743][train][INFO] - Epoch 1798/2000, Val Acc=0.6168, Val Loss=1.7579, lr=0.0100
[2025-05-07 04:02:41,336][train][INFO] - Epoch 1832/2000, Val Acc=0.5859, Val Loss=1.7824, lr=0.0100
[2025-05-07 04:02:44,954][train][INFO] - Epoch 1847/2000, Val Acc=0.5934, Val Loss=1.8701, lr=0.0100
[2025-05-07 04:02:45,320][train][INFO] - Epoch 1799/2000, Val Acc=0.6256, Val Loss=1.6446, lr=0.0100
[2025-05-07 04:02:49,216][train][INFO] - Epoch 1833/2000, Val Acc=0.5716, Val Loss=1.8222, lr=0.0100
[2025-05-07 04:02:52,063][train][INFO] - Epoch 1848/2000, Val Acc=0.6110, Val Loss=1.7543, lr=0.0100
[2025-05-07 04:02:52,874][train][INFO] - Epoch 1800/2000, Val Acc=0.6044, Val Loss=1.7739, lr=0.0100
[2025-05-07 04:02:56,681][train][INFO] - Epoch 1834/2000, Val Acc=0.5878, Val Loss=1.7195, lr=0.0100
[2025-05-07 04:02:59,702][train][INFO] - Epoch 1849/2000, Val Acc=0.6002, Val Loss=1.8465, lr=0.0100
[2025-05-07 04:03:00,474][train][INFO] - Epoch 1801/2000, Val Acc=0.6268, Val Loss=1.6762, lr=0.0100
[2025-05-07 04:03:04,421][train][INFO] - Epoch 1835/2000, Val Acc=0.6001, Val Loss=1.6780, lr=0.0100
[2025-05-07 04:03:07,408][train][INFO] - Epoch 1850/2000, Val Acc=0.6200, Val Loss=1.7130, lr=0.0100
[2025-05-07 04:03:08,375][train][INFO] - Epoch 1802/2000, Val Acc=0.6324, Val Loss=1.6234, lr=0.0100
[2025-05-07 04:03:11,911][train][INFO] - Epoch 1836/2000, Val Acc=0.5758, Val Loss=1.8246, lr=0.0100
[2025-05-07 04:03:14,921][train][INFO] - Epoch 1851/2000, Val Acc=0.6819, Val Loss=1.4141, lr=0.0010
[2025-05-07 04:03:16,422][train][INFO] - Epoch 1803/2000, Val Acc=0.6118, Val Loss=1.7926, lr=0.0100
[2025-05-07 04:03:19,282][train][INFO] - Epoch 1837/2000, Val Acc=0.5748, Val Loss=1.8078, lr=0.0100
[2025-05-07 04:03:22,126][train][INFO] - Epoch 1852/2000, Val Acc=0.6825, Val Loss=1.4238, lr=0.0010
[2025-05-07 04:03:24,079][train][INFO] - Epoch 1804/2000, Val Acc=0.6312, Val Loss=1.6389, lr=0.0100
[2025-05-07 04:03:26,953][train][INFO] - Epoch 1838/2000, Val Acc=0.5868, Val Loss=1.7253, lr=0.0100
[2025-05-07 04:03:29,867][train][INFO] - Epoch 1853/2000, Val Acc=0.6853, Val Loss=1.4287, lr=0.0010
[2025-05-07 04:03:31,881][train][INFO] - Epoch 1805/2000, Val Acc=0.6222, Val Loss=1.7089, lr=0.0100
[2025-05-07 04:03:34,672][train][INFO] - Epoch 1839/2000, Val Acc=0.6027, Val Loss=1.6715, lr=0.0100
[2025-05-07 04:03:36,801][train][INFO] - Epoch 1854/2000, Val Acc=0.6844, Val Loss=1.4408, lr=0.0010
[2025-05-07 04:03:39,906][train][INFO] - Epoch 1806/2000, Val Acc=0.6190, Val Loss=1.7025, lr=0.0100
[2025-05-07 04:03:42,615][train][INFO] - Epoch 1840/2000, Val Acc=0.5983, Val Loss=1.6555, lr=0.0100
[2025-05-07 04:03:44,728][train][INFO] - Epoch 1855/2000, Val Acc=0.6891, Val Loss=1.4494, lr=0.0010
[2025-05-07 04:03:47,678][train][INFO] - Epoch 1807/2000, Val Acc=0.6198, Val Loss=1.7099, lr=0.0100
[2025-05-07 04:03:50,175][train][INFO] - Epoch 1841/2000, Val Acc=0.5842, Val Loss=1.7683, lr=0.0100
[2025-05-07 04:03:52,452][train][INFO] - Epoch 1856/2000, Val Acc=0.6885, Val Loss=1.4518, lr=0.0010
[2025-05-07 04:03:55,558][train][INFO] - Epoch 1808/2000, Val Acc=0.6094, Val Loss=1.7739, lr=0.0100
[2025-05-07 04:03:57,726][train][INFO] - Epoch 1842/2000, Val Acc=0.5940, Val Loss=1.7064, lr=0.0100
[2025-05-07 04:03:59,920][train][INFO] - Epoch 1857/2000, Val Acc=0.6881, Val Loss=1.4641, lr=0.0010
[2025-05-07 04:04:03,243][train][INFO] - Epoch 1809/2000, Val Acc=0.6102, Val Loss=1.7942, lr=0.0100
[2025-05-07 04:04:05,409][train][INFO] - Epoch 1843/2000, Val Acc=0.5964, Val Loss=1.6895, lr=0.0100
[2025-05-07 04:04:07,754][train][INFO] - Epoch 1858/2000, Val Acc=0.6863, Val Loss=1.4820, lr=0.0010
[2025-05-07 04:04:10,772][train][INFO] - Epoch 1810/2000, Val Acc=0.6144, Val Loss=1.7666, lr=0.0100
[2025-05-07 04:04:13,322][train][INFO] - Epoch 1844/2000, Val Acc=0.5844, Val Loss=1.8030, lr=0.0100
[2025-05-07 04:04:15,311][train][INFO] - Epoch 1859/2000, Val Acc=0.6882, Val Loss=1.4825, lr=0.0010
[2025-05-07 04:04:18,728][train][INFO] - Epoch 1811/2000, Val Acc=0.6217, Val Loss=1.6823, lr=0.0100
[2025-05-07 04:04:21,206][train][INFO] - Epoch 1845/2000, Val Acc=0.5908, Val Loss=1.7226, lr=0.0100
[2025-05-07 04:04:22,816][train][INFO] - Epoch 1860/2000, Val Acc=0.6882, Val Loss=1.4836, lr=0.0010
[2025-05-07 04:04:26,542][train][INFO] - Epoch 1812/2000, Val Acc=0.6285, Val Loss=1.6564, lr=0.0100
[2025-05-07 04:04:29,033][train][INFO] - Epoch 1846/2000, Val Acc=0.5672, Val Loss=1.8477, lr=0.0100
[2025-05-07 04:04:29,841][train][INFO] - Epoch 1861/2000, Val Acc=0.6886, Val Loss=1.4848, lr=0.0010
[2025-05-07 04:04:33,875][train][INFO] - Epoch 1813/2000, Val Acc=0.6218, Val Loss=1.7099, lr=0.0100
[2025-05-07 04:04:36,897][train][INFO] - Epoch 1847/2000, Val Acc=0.5926, Val Loss=1.6999, lr=0.0100
[2025-05-07 04:04:37,466][train][INFO] - Epoch 1862/2000, Val Acc=0.6857, Val Loss=1.5080, lr=0.0010
[2025-05-07 04:04:41,921][train][INFO] - Epoch 1814/2000, Val Acc=0.6254, Val Loss=1.6899, lr=0.0100
[2025-05-07 04:04:44,072][train][INFO] - Epoch 1848/2000, Val Acc=0.5853, Val Loss=1.7015, lr=0.0100
[2025-05-07 04:04:45,026][train][INFO] - Epoch 1863/2000, Val Acc=0.6891, Val Loss=1.4986, lr=0.0010
[2025-05-07 04:04:50,009][train][INFO] - Epoch 1815/2000, Val Acc=0.6147, Val Loss=1.7402, lr=0.0100
[2025-05-07 04:04:51,776][train][INFO] - Epoch 1849/2000, Val Acc=0.5890, Val Loss=1.7393, lr=0.0100
[2025-05-07 04:04:52,478][train][INFO] - Epoch 1864/2000, Val Acc=0.6861, Val Loss=1.5178, lr=0.0010
[2025-05-07 04:04:57,396][train][INFO] - Epoch 1816/2000, Val Acc=0.6260, Val Loss=1.6935, lr=0.0100
[2025-05-07 04:04:59,751][train][INFO] - Epoch 1850/2000, Val Acc=0.5936, Val Loss=1.7168, lr=0.0100
[2025-05-07 04:05:00,296][train][INFO] - Epoch 1865/2000, Val Acc=0.6905, Val Loss=1.5120, lr=0.0010
[2025-05-07 04:05:05,631][train][INFO] - Epoch 1817/2000, Val Acc=0.6411, Val Loss=1.6050, lr=0.0100
[2025-05-07 04:05:07,386][train][INFO] - Epoch 1851/2000, Val Acc=0.6612, Val Loss=1.3695, lr=0.0010
[2025-05-07 04:05:07,516][train][INFO] - Epoch 1866/2000, Val Acc=0.6878, Val Loss=1.5246, lr=0.0010
[2025-05-07 04:05:13,363][train][INFO] - Epoch 1818/2000, Val Acc=0.6064, Val Loss=1.8143, lr=0.0100
[2025-05-07 04:05:14,794][train][INFO] - Epoch 1852/2000, Val Acc=0.6635, Val Loss=1.3758, lr=0.0010
[2025-05-07 04:05:14,940][train][INFO] - Epoch 1867/2000, Val Acc=0.6870, Val Loss=1.5207, lr=0.0010
[2025-05-07 04:05:21,624][train][INFO] - Epoch 1819/2000, Val Acc=0.6082, Val Loss=1.7883, lr=0.0100
[2025-05-07 04:05:22,309][train][INFO] - Epoch 1868/2000, Val Acc=0.6879, Val Loss=1.5323, lr=0.0010
[2025-05-07 04:05:22,501][train][INFO] - Epoch 1853/2000, Val Acc=0.6676, Val Loss=1.3798, lr=0.0010
[2025-05-07 04:05:29,073][train][INFO] - Epoch 1820/2000, Val Acc=0.6215, Val Loss=1.6928, lr=0.0100
[2025-05-07 04:05:29,978][train][INFO] - Epoch 1869/2000, Val Acc=0.6899, Val Loss=1.5359, lr=0.0010
[2025-05-07 04:05:30,460][train][INFO] - Epoch 1854/2000, Val Acc=0.6678, Val Loss=1.3853, lr=0.0010
[2025-05-07 04:05:36,885][train][INFO] - Epoch 1821/2000, Val Acc=0.6138, Val Loss=1.7386, lr=0.0100
[2025-05-07 04:05:37,892][train][INFO] - Epoch 1870/2000, Val Acc=0.6874, Val Loss=1.5381, lr=0.0010
[2025-05-07 04:05:38,022][train][INFO] - Epoch 1855/2000, Val Acc=0.6663, Val Loss=1.3997, lr=0.0010
[2025-05-07 04:05:44,706][train][INFO] - Epoch 1822/2000, Val Acc=0.6028, Val Loss=1.8595, lr=0.0100
[2025-05-07 04:05:45,393][train][INFO] - Epoch 1856/2000, Val Acc=0.6702, Val Loss=1.4061, lr=0.0010
[2025-05-07 04:05:45,552][train][INFO] - Epoch 1871/2000, Val Acc=0.6882, Val Loss=1.5376, lr=0.0010
[2025-05-07 04:05:52,599][train][INFO] - Epoch 1823/2000, Val Acc=0.6204, Val Loss=1.7351, lr=0.0100
[2025-05-07 04:05:52,817][train][INFO] - Epoch 1857/2000, Val Acc=0.6685, Val Loss=1.4077, lr=0.0010
[2025-05-07 04:05:53,278][train][INFO] - Epoch 1872/2000, Val Acc=0.6875, Val Loss=1.5441, lr=0.0010
[2025-05-07 04:05:59,939][train][INFO] - Epoch 1824/2000, Val Acc=0.6177, Val Loss=1.7224, lr=0.0100
[2025-05-07 04:06:00,656][train][INFO] - Epoch 1858/2000, Val Acc=0.6694, Val Loss=1.4200, lr=0.0010
[2025-05-07 04:06:00,673][train][INFO] - Epoch 1873/2000, Val Acc=0.6867, Val Loss=1.5503, lr=0.0010
[2025-05-07 04:06:07,770][train][INFO] - Epoch 1859/2000, Val Acc=0.6679, Val Loss=1.4288, lr=0.0010
[2025-05-07 04:06:08,092][train][INFO] - Epoch 1825/2000, Val Acc=0.6287, Val Loss=1.6729, lr=0.0100
[2025-05-07 04:06:08,537][train][INFO] - Epoch 1874/2000, Val Acc=0.6867, Val Loss=1.5595, lr=0.0010
[2025-05-07 04:06:15,216][train][INFO] - Epoch 1860/2000, Val Acc=0.6701, Val Loss=1.4372, lr=0.0010
[2025-05-07 04:06:15,870][train][INFO] - Epoch 1826/2000, Val Acc=0.6075, Val Loss=1.8032, lr=0.0100
[2025-05-07 04:06:15,875][train][INFO] - Epoch 1875/2000, Val Acc=0.6899, Val Loss=1.5508, lr=0.0010
[2025-05-07 04:06:23,104][train][INFO] - Epoch 1861/2000, Val Acc=0.6646, Val Loss=1.4393, lr=0.0010
[2025-05-07 04:06:23,225][train][INFO] - Epoch 1876/2000, Val Acc=0.6877, Val Loss=1.5622, lr=0.0010
[2025-05-07 04:06:23,807][train][INFO] - Epoch 1827/2000, Val Acc=0.6145, Val Loss=1.7516, lr=0.0100
[2025-05-07 04:06:30,434][train][INFO] - Epoch 1877/2000, Val Acc=0.6880, Val Loss=1.5649, lr=0.0010
[2025-05-07 04:06:30,556][train][INFO] - Epoch 1862/2000, Val Acc=0.6701, Val Loss=1.4401, lr=0.0010
[2025-05-07 04:06:31,292][train][INFO] - Epoch 1828/2000, Val Acc=0.6113, Val Loss=1.7727, lr=0.0100
[2025-05-07 04:06:37,961][train][INFO] - Epoch 1878/2000, Val Acc=0.6891, Val Loss=1.5739, lr=0.0010
[2025-05-07 04:06:38,037][train][INFO] - Epoch 1863/2000, Val Acc=0.6679, Val Loss=1.4534, lr=0.0010
[2025-05-07 04:06:39,177][train][INFO] - Epoch 1829/2000, Val Acc=0.6112, Val Loss=1.7663, lr=0.0100
[2025-05-07 04:06:44,791][train][INFO] - Epoch 1879/2000, Val Acc=0.6878, Val Loss=1.5721, lr=0.0010
[2025-05-07 04:06:45,827][train][INFO] - Epoch 1864/2000, Val Acc=0.6659, Val Loss=1.4585, lr=0.0010
[2025-05-07 04:06:46,900][train][INFO] - Epoch 1830/2000, Val Acc=0.6098, Val Loss=1.7666, lr=0.0100
[2025-05-07 04:06:52,107][train][INFO] - Epoch 1880/2000, Val Acc=0.6882, Val Loss=1.5730, lr=0.0010
[2025-05-07 04:06:53,424][train][INFO] - Epoch 1865/2000, Val Acc=0.6684, Val Loss=1.4630, lr=0.0010
[2025-05-07 04:06:54,756][train][INFO] - Epoch 1831/2000, Val Acc=0.5953, Val Loss=1.8181, lr=0.0100
[2025-05-07 04:06:59,852][train][INFO] - Epoch 1881/2000, Val Acc=0.6878, Val Loss=1.5750, lr=0.0010
[2025-05-07 04:07:01,038][train][INFO] - Epoch 1866/2000, Val Acc=0.6669, Val Loss=1.4636, lr=0.0010
[2025-05-07 04:07:02,760][train][INFO] - Epoch 1832/2000, Val Acc=0.6153, Val Loss=1.7444, lr=0.0100
[2025-05-07 04:07:07,471][train][INFO] - Epoch 1882/2000, Val Acc=0.6882, Val Loss=1.5766, lr=0.0010
[2025-05-07 04:07:08,733][train][INFO] - Epoch 1867/2000, Val Acc=0.6683, Val Loss=1.4675, lr=0.0010
[2025-05-07 04:07:10,289][train][INFO] - Epoch 1833/2000, Val Acc=0.6268, Val Loss=1.6769, lr=0.0100
[2025-05-07 04:07:14,772][train][INFO] - Epoch 1883/2000, Val Acc=0.6903, Val Loss=1.5812, lr=0.0010
[2025-05-07 04:07:16,621][train][INFO] - Epoch 1868/2000, Val Acc=0.6618, Val Loss=1.4801, lr=0.0010
[2025-05-07 04:07:17,502][train][INFO] - Epoch 1834/2000, Val Acc=0.6296, Val Loss=1.7083, lr=0.0100
[2025-05-07 04:07:22,575][train][INFO] - Epoch 1884/2000, Val Acc=0.6894, Val Loss=1.5773, lr=0.0010
[2025-05-07 04:07:24,254][train][INFO] - Epoch 1869/2000, Val Acc=0.6663, Val Loss=1.4799, lr=0.0010
[2025-05-07 04:07:25,183][train][INFO] - Epoch 1835/2000, Val Acc=0.6057, Val Loss=1.8261, lr=0.0100
[2025-05-07 04:07:29,988][train][INFO] - Epoch 1885/2000, Val Acc=0.6865, Val Loss=1.5841, lr=0.0010
[2025-05-07 04:07:32,045][train][INFO] - Epoch 1870/2000, Val Acc=0.6691, Val Loss=1.4826, lr=0.0010
[2025-05-07 04:07:33,311][train][INFO] - Epoch 1836/2000, Val Acc=0.6169, Val Loss=1.7447, lr=0.0100
[2025-05-07 04:07:37,820][train][INFO] - Epoch 1886/2000, Val Acc=0.6856, Val Loss=1.6013, lr=0.0010
[2025-05-07 04:07:39,673][train][INFO] - Epoch 1871/2000, Val Acc=0.6671, Val Loss=1.4897, lr=0.0010
[2025-05-07 04:07:41,112][train][INFO] - Epoch 1837/2000, Val Acc=0.5981, Val Loss=1.8415, lr=0.0100
[2025-05-07 04:07:45,223][train][INFO] - Epoch 1887/2000, Val Acc=0.6859, Val Loss=1.6108, lr=0.0010
[2025-05-07 04:07:47,199][train][INFO] - Epoch 1872/2000, Val Acc=0.6662, Val Loss=1.5022, lr=0.0010
[2025-05-07 04:07:48,670][train][INFO] - Epoch 1838/2000, Val Acc=0.6224, Val Loss=1.7101, lr=0.0100
[2025-05-07 04:07:53,249][train][INFO] - Epoch 1888/2000, Val Acc=0.6856, Val Loss=1.6026, lr=0.0010
[2025-05-07 04:07:54,793][train][INFO] - Epoch 1873/2000, Val Acc=0.6681, Val Loss=1.4962, lr=0.0010
[2025-05-07 04:07:56,450][train][INFO] - Epoch 1839/2000, Val Acc=0.6114, Val Loss=1.7320, lr=0.0100
[2025-05-07 04:08:00,868][train][INFO] - Epoch 1889/2000, Val Acc=0.6856, Val Loss=1.6089, lr=0.0010
[2025-05-07 04:08:02,563][train][INFO] - Epoch 1874/2000, Val Acc=0.6675, Val Loss=1.5067, lr=0.0010
[2025-05-07 04:08:04,181][train][INFO] - Epoch 1840/2000, Val Acc=0.6269, Val Loss=1.7196, lr=0.0100
[2025-05-07 04:08:08,740][train][INFO] - Epoch 1890/2000, Val Acc=0.6902, Val Loss=1.6037, lr=0.0010
[2025-05-07 04:08:09,944][train][INFO] - Epoch 1875/2000, Val Acc=0.6675, Val Loss=1.5021, lr=0.0010
[2025-05-07 04:08:11,717][train][INFO] - Epoch 1841/2000, Val Acc=0.6225, Val Loss=1.7090, lr=0.0100
[2025-05-07 04:08:16,394][train][INFO] - Epoch 1891/2000, Val Acc=0.6912, Val Loss=1.6036, lr=0.0010
[2025-05-07 04:08:17,602][train][INFO] - Epoch 1876/2000, Val Acc=0.6634, Val Loss=1.5155, lr=0.0010
[2025-05-07 04:08:19,563][train][INFO] - Epoch 1842/2000, Val Acc=0.6069, Val Loss=1.7863, lr=0.0100
[2025-05-07 04:08:24,176][train][INFO] - Epoch 1892/2000, Val Acc=0.6874, Val Loss=1.6136, lr=0.0010
[2025-05-07 04:08:25,294][train][INFO] - Epoch 1877/2000, Val Acc=0.6663, Val Loss=1.5146, lr=0.0010
[2025-05-07 04:08:27,304][train][INFO] - Epoch 1843/2000, Val Acc=0.6205, Val Loss=1.7228, lr=0.0100
[2025-05-07 04:08:31,289][train][INFO] - Epoch 1893/2000, Val Acc=0.6850, Val Loss=1.6172, lr=0.0010
[2025-05-07 04:08:32,930][train][INFO] - Epoch 1878/2000, Val Acc=0.6671, Val Loss=1.5158, lr=0.0010
[2025-05-07 04:08:35,101][train][INFO] - Epoch 1844/2000, Val Acc=0.6280, Val Loss=1.7060, lr=0.0100
[2025-05-07 04:08:38,832][train][INFO] - Epoch 1894/2000, Val Acc=0.6845, Val Loss=1.6206, lr=0.0010
[2025-05-07 04:08:40,306][train][INFO] - Epoch 1879/2000, Val Acc=0.6627, Val Loss=1.5352, lr=0.0010
[2025-05-07 04:08:43,065][train][INFO] - Epoch 1845/2000, Val Acc=0.6208, Val Loss=1.7114, lr=0.0100
[2025-05-07 04:08:46,366][train][INFO] - Epoch 1895/2000, Val Acc=0.6885, Val Loss=1.6124, lr=0.0010
[2025-05-07 04:08:48,018][train][INFO] - Epoch 1880/2000, Val Acc=0.6632, Val Loss=1.5397, lr=0.0010
[2025-05-07 04:08:50,637][train][INFO] - Epoch 1846/2000, Val Acc=0.6119, Val Loss=1.7479, lr=0.0100
[2025-05-07 04:08:53,899][train][INFO] - Epoch 1896/2000, Val Acc=0.6853, Val Loss=1.6200, lr=0.0010
[2025-05-07 04:08:55,556][train][INFO] - Epoch 1881/2000, Val Acc=0.6638, Val Loss=1.5343, lr=0.0010
[2025-05-07 04:08:58,405][train][INFO] - Epoch 1847/2000, Val Acc=0.5934, Val Loss=1.8701, lr=0.0100
[2025-05-07 04:09:01,167][train][INFO] - Epoch 1897/2000, Val Acc=0.6891, Val Loss=1.6163, lr=0.0010
[2025-05-07 04:09:03,241][train][INFO] - Epoch 1882/2000, Val Acc=0.6630, Val Loss=1.5431, lr=0.0010
[2025-05-07 04:09:06,420][train][INFO] - Epoch 1848/2000, Val Acc=0.6110, Val Loss=1.7543, lr=0.0100
[2025-05-07 04:09:09,116][train][INFO] - Epoch 1898/2000, Val Acc=0.6862, Val Loss=1.6245, lr=0.0010
[2025-05-07 04:09:10,610][train][INFO] - Epoch 1883/2000, Val Acc=0.6621, Val Loss=1.5450, lr=0.0010
[2025-05-07 04:09:14,085][train][INFO] - Epoch 1849/2000, Val Acc=0.6002, Val Loss=1.8465, lr=0.0100
[2025-05-07 04:09:16,805][train][INFO] - Epoch 1899/2000, Val Acc=0.6873, Val Loss=1.6258, lr=0.0010
[2025-05-07 04:09:18,360][train][INFO] - Epoch 1884/2000, Val Acc=0.6627, Val Loss=1.5453, lr=0.0010
[2025-05-07 04:09:22,079][train][INFO] - Epoch 1850/2000, Val Acc=0.6200, Val Loss=1.7130, lr=0.0100
[2025-05-07 04:09:24,102][train][INFO] - Epoch 1900/2000, Val Acc=0.6854, Val Loss=1.6219, lr=0.0010
[2025-05-07 04:09:25,520][train][INFO] - Epoch 1885/2000, Val Acc=0.6629, Val Loss=1.5500, lr=0.0010
[2025-05-07 04:09:29,475][train][INFO] - Epoch 1851/2000, Val Acc=0.6819, Val Loss=1.4141, lr=0.0010
[2025-05-07 04:09:31,689][train][INFO] - Epoch 1901/2000, Val Acc=0.6882, Val Loss=1.6251, lr=0.0010
[2025-05-07 04:09:33,099][train][INFO] - Epoch 1886/2000, Val Acc=0.6649, Val Loss=1.5651, lr=0.0010
[2025-05-07 04:09:37,277][train][INFO] - Epoch 1852/2000, Val Acc=0.6825, Val Loss=1.4238, lr=0.0010
[2025-05-07 04:09:39,263][train][INFO] - Epoch 1902/2000, Val Acc=0.6868, Val Loss=1.6260, lr=0.0010
[2025-05-07 04:09:40,779][train][INFO] - Epoch 1887/2000, Val Acc=0.6649, Val Loss=1.5582, lr=0.0010
[2025-05-07 04:09:45,330][train][INFO] - Epoch 1853/2000, Val Acc=0.6853, Val Loss=1.4287, lr=0.0010
[2025-05-07 04:09:46,892][train][INFO] - Epoch 1903/2000, Val Acc=0.6843, Val Loss=1.6254, lr=0.0010
[2025-05-07 04:09:48,341][train][INFO] - Epoch 1888/2000, Val Acc=0.6605, Val Loss=1.5700, lr=0.0010
[2025-05-07 04:09:53,351][train][INFO] - Epoch 1854/2000, Val Acc=0.6844, Val Loss=1.4408, lr=0.0010
[2025-05-07 04:09:54,300][train][INFO] - Epoch 1904/2000, Val Acc=0.6864, Val Loss=1.6326, lr=0.0010
[2025-05-07 04:09:56,336][train][INFO] - Epoch 1889/2000, Val Acc=0.6602, Val Loss=1.5756, lr=0.0010
[2025-05-07 04:10:00,881][train][INFO] - Epoch 1855/2000, Val Acc=0.6891, Val Loss=1.4494, lr=0.0010
[2025-05-07 04:10:01,689][train][INFO] - Epoch 1905/2000, Val Acc=0.6858, Val Loss=1.6247, lr=0.0010
[2025-05-07 04:10:03,682][train][INFO] - Epoch 1890/2000, Val Acc=0.6611, Val Loss=1.5693, lr=0.0010
[2025-05-07 04:10:09,091][train][INFO] - Epoch 1856/2000, Val Acc=0.6885, Val Loss=1.4518, lr=0.0010
[2025-05-07 04:10:09,458][train][INFO] - Epoch 1906/2000, Val Acc=0.6853, Val Loss=1.6451, lr=0.0010
[2025-05-07 04:10:11,523][train][INFO] - Epoch 1891/2000, Val Acc=0.6625, Val Loss=1.5586, lr=0.0010
[2025-05-07 04:10:16,682][train][INFO] - Epoch 1857/2000, Val Acc=0.6881, Val Loss=1.4641, lr=0.0010
[2025-05-07 04:10:16,739][train][INFO] - Epoch 1907/2000, Val Acc=0.6867, Val Loss=1.6352, lr=0.0010
[2025-05-07 04:10:19,004][train][INFO] - Epoch 1892/2000, Val Acc=0.6602, Val Loss=1.5746, lr=0.0010
[2025-05-07 04:10:24,476][train][INFO] - Epoch 1908/2000, Val Acc=0.6863, Val Loss=1.6376, lr=0.0010
[2025-05-07 04:10:24,617][train][INFO] - Epoch 1858/2000, Val Acc=0.6863, Val Loss=1.4820, lr=0.0010
[2025-05-07 04:10:26,682][train][INFO] - Epoch 1893/2000, Val Acc=0.6653, Val Loss=1.5820, lr=0.0010
[2025-05-07 04:10:32,054][train][INFO] - Epoch 1909/2000, Val Acc=0.6867, Val Loss=1.6376, lr=0.0010
[2025-05-07 04:10:32,626][train][INFO] - Epoch 1859/2000, Val Acc=0.6882, Val Loss=1.4825, lr=0.0010
[2025-05-07 04:10:34,159][train][INFO] - Epoch 1894/2000, Val Acc=0.6617, Val Loss=1.5890, lr=0.0010
[2025-05-07 04:10:39,424][train][INFO] - Epoch 1910/2000, Val Acc=0.6861, Val Loss=1.6444, lr=0.0010
[2025-05-07 04:10:40,536][train][INFO] - Epoch 1860/2000, Val Acc=0.6882, Val Loss=1.4836, lr=0.0010
[2025-05-07 04:10:41,870][train][INFO] - Epoch 1895/2000, Val Acc=0.6621, Val Loss=1.5849, lr=0.0010
[2025-05-07 04:10:46,870][train][INFO] - Epoch 1911/2000, Val Acc=0.6872, Val Loss=1.6536, lr=0.0010
[2025-05-07 04:10:48,005][train][INFO] - Epoch 1861/2000, Val Acc=0.6886, Val Loss=1.4848, lr=0.0010
[2025-05-07 04:10:49,621][train][INFO] - Epoch 1896/2000, Val Acc=0.6596, Val Loss=1.5942, lr=0.0010
[2025-05-07 04:10:53,770][train][INFO] - Epoch 1912/2000, Val Acc=0.6893, Val Loss=1.6413, lr=0.0010
[2025-05-07 04:10:56,000][train][INFO] - Epoch 1862/2000, Val Acc=0.6857, Val Loss=1.5080, lr=0.0010
[2025-05-07 04:10:57,508][train][INFO] - Epoch 1897/2000, Val Acc=0.6613, Val Loss=1.5997, lr=0.0010
[2025-05-07 04:11:01,552][train][INFO] - Epoch 1913/2000, Val Acc=0.6873, Val Loss=1.6462, lr=0.0010
[2025-05-07 04:11:03,724][train][INFO] - Epoch 1863/2000, Val Acc=0.6891, Val Loss=1.4986, lr=0.0010
[2025-05-07 04:11:05,076][train][INFO] - Epoch 1898/2000, Val Acc=0.6601, Val Loss=1.6114, lr=0.0010
[2025-05-07 04:11:08,916][train][INFO] - Epoch 1914/2000, Val Acc=0.6859, Val Loss=1.6365, lr=0.0010
[2025-05-07 04:11:11,606][train][INFO] - Epoch 1864/2000, Val Acc=0.6861, Val Loss=1.5178, lr=0.0010
[2025-05-07 04:11:12,828][train][INFO] - Epoch 1899/2000, Val Acc=0.6634, Val Loss=1.6158, lr=0.0010
[2025-05-07 04:11:16,260][train][INFO] - Epoch 1915/2000, Val Acc=0.6877, Val Loss=1.6524, lr=0.0010
[2025-05-07 04:11:19,215][train][INFO] - Epoch 1865/2000, Val Acc=0.6905, Val Loss=1.5120, lr=0.0010
[2025-05-07 04:11:20,382][train][INFO] - Epoch 1900/2000, Val Acc=0.6642, Val Loss=1.6045, lr=0.0010
[2025-05-07 04:11:24,208][train][INFO] - Epoch 1916/2000, Val Acc=0.6863, Val Loss=1.6471, lr=0.0010
[2025-05-07 04:11:27,015][train][INFO] - Epoch 1866/2000, Val Acc=0.6878, Val Loss=1.5246, lr=0.0010
[2025-05-07 04:11:28,069][train][INFO] - Epoch 1901/2000, Val Acc=0.6616, Val Loss=1.6104, lr=0.0010
[2025-05-07 04:11:31,355][train][INFO] - Epoch 1917/2000, Val Acc=0.6852, Val Loss=1.6591, lr=0.0010
[2025-05-07 04:11:34,363][train][INFO] - Epoch 1867/2000, Val Acc=0.6870, Val Loss=1.5207, lr=0.0010
[2025-05-07 04:11:35,420][train][INFO] - Epoch 1902/2000, Val Acc=0.6646, Val Loss=1.5953, lr=0.0010
[2025-05-07 04:11:39,018][train][INFO] - Epoch 1918/2000, Val Acc=0.6903, Val Loss=1.6476, lr=0.0010
[2025-05-07 04:11:42,472][train][INFO] - Epoch 1868/2000, Val Acc=0.6879, Val Loss=1.5323, lr=0.0010
[2025-05-07 04:11:43,262][train][INFO] - Epoch 1903/2000, Val Acc=0.6616, Val Loss=1.6101, lr=0.0010
[2025-05-07 04:11:46,556][train][INFO] - Epoch 1919/2000, Val Acc=0.6871, Val Loss=1.6661, lr=0.0010
[2025-05-07 04:11:49,678][train][INFO] - Epoch 1869/2000, Val Acc=0.6899, Val Loss=1.5359, lr=0.0010
[2025-05-07 04:11:51,088][train][INFO] - Epoch 1904/2000, Val Acc=0.6609, Val Loss=1.6188, lr=0.0010
[2025-05-07 04:11:53,914][train][INFO] - Epoch 1920/2000, Val Acc=0.6865, Val Loss=1.6629, lr=0.0010
[2025-05-07 04:11:57,177][train][INFO] - Epoch 1870/2000, Val Acc=0.6874, Val Loss=1.5381, lr=0.0010
[2025-05-07 04:11:58,258][train][INFO] - Epoch 1905/2000, Val Acc=0.6632, Val Loss=1.6187, lr=0.0010
[2025-05-07 04:12:01,332][train][INFO] - Epoch 1921/2000, Val Acc=0.6832, Val Loss=1.6689, lr=0.0010
[2025-05-07 04:12:05,096][train][INFO] - Epoch 1871/2000, Val Acc=0.6882, Val Loss=1.5376, lr=0.0010
[2025-05-07 04:12:05,833][train][INFO] - Epoch 1906/2000, Val Acc=0.6602, Val Loss=1.6285, lr=0.0010
[2025-05-07 04:12:08,749][train][INFO] - Epoch 1922/2000, Val Acc=0.6833, Val Loss=1.6734, lr=0.0010
[2025-05-07 04:12:12,619][train][INFO] - Epoch 1872/2000, Val Acc=0.6875, Val Loss=1.5441, lr=0.0010
[2025-05-07 04:12:13,103][train][INFO] - Epoch 1907/2000, Val Acc=0.6601, Val Loss=1.6214, lr=0.0010
[2025-05-07 04:12:16,266][train][INFO] - Epoch 1923/2000, Val Acc=0.6886, Val Loss=1.6514, lr=0.0010
[2025-05-07 04:12:20,561][train][INFO] - Epoch 1908/2000, Val Acc=0.6593, Val Loss=1.6106, lr=0.0010
[2025-05-07 04:12:20,931][train][INFO] - Epoch 1873/2000, Val Acc=0.6867, Val Loss=1.5503, lr=0.0010
[2025-05-07 04:12:23,739][train][INFO] - Epoch 1924/2000, Val Acc=0.6851, Val Loss=1.6501, lr=0.0010
[2025-05-07 04:12:28,600][train][INFO] - Epoch 1909/2000, Val Acc=0.6589, Val Loss=1.6327, lr=0.0010
[2025-05-07 04:12:28,761][train][INFO] - Epoch 1874/2000, Val Acc=0.6867, Val Loss=1.5595, lr=0.0010
[2025-05-07 04:12:31,304][train][INFO] - Epoch 1925/2000, Val Acc=0.6889, Val Loss=1.6374, lr=0.0010
[2025-05-07 04:12:36,109][train][INFO] - Epoch 1910/2000, Val Acc=0.6606, Val Loss=1.6330, lr=0.0010
[2025-05-07 04:12:36,293][train][INFO] - Epoch 1875/2000, Val Acc=0.6899, Val Loss=1.5508, lr=0.0010
[2025-05-07 04:12:38,837][train][INFO] - Epoch 1926/2000, Val Acc=0.6845, Val Loss=1.6590, lr=0.0010
[2025-05-07 04:12:43,586][train][INFO] - Epoch 1911/2000, Val Acc=0.6603, Val Loss=1.6419, lr=0.0010
[2025-05-07 04:12:44,370][train][INFO] - Epoch 1876/2000, Val Acc=0.6877, Val Loss=1.5622, lr=0.0010
[2025-05-07 04:12:46,296][train][INFO] - Epoch 1927/2000, Val Acc=0.6903, Val Loss=1.6501, lr=0.0010
[2025-05-07 04:12:51,196][train][INFO] - Epoch 1912/2000, Val Acc=0.6577, Val Loss=1.6454, lr=0.0010
[2025-05-07 04:12:52,421][train][INFO] - Epoch 1877/2000, Val Acc=0.6880, Val Loss=1.5649, lr=0.0010
[2025-05-07 04:12:53,985][train][INFO] - Epoch 1928/2000, Val Acc=0.6871, Val Loss=1.6678, lr=0.0010
[2025-05-07 04:12:58,818][train][INFO] - Epoch 1913/2000, Val Acc=0.6624, Val Loss=1.6435, lr=0.0010
[2025-05-07 04:13:00,074][train][INFO] - Epoch 1878/2000, Val Acc=0.6891, Val Loss=1.5739, lr=0.0010
[2025-05-07 04:13:01,735][train][INFO] - Epoch 1929/2000, Val Acc=0.6880, Val Loss=1.6580, lr=0.0010
[2025-05-07 04:13:06,638][train][INFO] - Epoch 1914/2000, Val Acc=0.6582, Val Loss=1.6542, lr=0.0010
[2025-05-07 04:13:08,078][train][INFO] - Epoch 1879/2000, Val Acc=0.6878, Val Loss=1.5721, lr=0.0010
[2025-05-07 04:13:09,229][train][INFO] - Epoch 1930/2000, Val Acc=0.6865, Val Loss=1.6741, lr=0.0010
[2025-05-07 04:13:14,414][train][INFO] - Epoch 1915/2000, Val Acc=0.6626, Val Loss=1.6302, lr=0.0010
[2025-05-07 04:13:15,719][train][INFO] - Epoch 1880/2000, Val Acc=0.6882, Val Loss=1.5730, lr=0.0010
[2025-05-07 04:13:16,957][train][INFO] - Epoch 1931/2000, Val Acc=0.6874, Val Loss=1.6720, lr=0.0010
[2025-05-07 04:13:22,148][train][INFO] - Epoch 1916/2000, Val Acc=0.6624, Val Loss=1.6322, lr=0.0010
[2025-05-07 04:13:23,273][train][INFO] - Epoch 1881/2000, Val Acc=0.6878, Val Loss=1.5750, lr=0.0010
[2025-05-07 04:13:24,421][train][INFO] - Epoch 1932/2000, Val Acc=0.6895, Val Loss=1.6612, lr=0.0010
[2025-05-07 04:13:29,819][train][INFO] - Epoch 1917/2000, Val Acc=0.6632, Val Loss=1.6388, lr=0.0010
[2025-05-07 04:13:31,360][train][INFO] - Epoch 1882/2000, Val Acc=0.6882, Val Loss=1.5766, lr=0.0010
[2025-05-07 04:13:32,316][train][INFO] - Epoch 1933/2000, Val Acc=0.6900, Val Loss=1.6685, lr=0.0010
[2025-05-07 04:13:37,441][train][INFO] - Epoch 1918/2000, Val Acc=0.6593, Val Loss=1.6378, lr=0.0010
[2025-05-07 04:13:39,398][train][INFO] - Epoch 1883/2000, Val Acc=0.6903, Val Loss=1.5812, lr=0.0010
[2025-05-07 04:13:39,717][train][INFO] - Epoch 1934/2000, Val Acc=0.6869, Val Loss=1.6632, lr=0.0010
[2025-05-07 04:13:45,286][train][INFO] - Epoch 1919/2000, Val Acc=0.6573, Val Loss=1.6587, lr=0.0010
[2025-05-07 04:13:47,290][train][INFO] - Epoch 1884/2000, Val Acc=0.6894, Val Loss=1.5773, lr=0.0010
[2025-05-07 04:13:47,458][train][INFO] - Epoch 1935/2000, Val Acc=0.6875, Val Loss=1.6697, lr=0.0010
[2025-05-07 04:13:53,310][train][INFO] - Epoch 1920/2000, Val Acc=0.6586, Val Loss=1.6518, lr=0.0010
[2025-05-07 04:13:55,200][train][INFO] - Epoch 1885/2000, Val Acc=0.6865, Val Loss=1.5841, lr=0.0010
[2025-05-07 04:13:55,304][train][INFO] - Epoch 1936/2000, Val Acc=0.6848, Val Loss=1.6672, lr=0.0010
[2025-05-07 04:14:00,842][train][INFO] - Epoch 1921/2000, Val Acc=0.6589, Val Loss=1.6552, lr=0.0010
[2025-05-07 04:14:03,058][train][INFO] - Epoch 1937/2000, Val Acc=0.6854, Val Loss=1.6736, lr=0.0010
[2025-05-07 04:14:03,189][train][INFO] - Epoch 1886/2000, Val Acc=0.6856, Val Loss=1.6013, lr=0.0010
[2025-05-07 04:14:08,888][train][INFO] - Epoch 1922/2000, Val Acc=0.6604, Val Loss=1.6532, lr=0.0010
[2025-05-07 04:14:10,965][train][INFO] - Epoch 1938/2000, Val Acc=0.6849, Val Loss=1.6852, lr=0.0010
[2025-05-07 04:14:11,474][train][INFO] - Epoch 1887/2000, Val Acc=0.6859, Val Loss=1.6108, lr=0.0010
[2025-05-07 04:14:16,274][train][INFO] - Epoch 1923/2000, Val Acc=0.6587, Val Loss=1.6483, lr=0.0010
[2025-05-07 04:14:18,583][train][INFO] - Epoch 1939/2000, Val Acc=0.6880, Val Loss=1.6772, lr=0.0010
[2025-05-07 04:14:19,183][train][INFO] - Epoch 1888/2000, Val Acc=0.6856, Val Loss=1.6026, lr=0.0010
[2025-05-07 04:14:24,217][train][INFO] - Epoch 1924/2000, Val Acc=0.6550, Val Loss=1.6704, lr=0.0010
[2025-05-07 04:14:26,308][train][INFO] - Epoch 1940/2000, Val Acc=0.6880, Val Loss=1.6763, lr=0.0010
[2025-05-07 04:14:27,100][train][INFO] - Epoch 1889/2000, Val Acc=0.6856, Val Loss=1.6089, lr=0.0010
[2025-05-07 04:14:31,887][train][INFO] - Epoch 1925/2000, Val Acc=0.6597, Val Loss=1.6624, lr=0.0010
[2025-05-07 04:14:33,799][train][INFO] - Epoch 1941/2000, Val Acc=0.6863, Val Loss=1.6879, lr=0.0010
[2025-05-07 04:14:35,063][train][INFO] - Epoch 1890/2000, Val Acc=0.6902, Val Loss=1.6037, lr=0.0010
[2025-05-07 04:14:39,713][train][INFO] - Epoch 1926/2000, Val Acc=0.6596, Val Loss=1.6635, lr=0.0010
[2025-05-07 04:14:40,950][train][INFO] - Epoch 1942/2000, Val Acc=0.6891, Val Loss=1.6792, lr=0.0010
[2025-05-07 04:14:43,209][train][INFO] - Epoch 1891/2000, Val Acc=0.6912, Val Loss=1.6036, lr=0.0010
[2025-05-07 04:14:47,206][train][INFO] - Epoch 1927/2000, Val Acc=0.6557, Val Loss=1.6768, lr=0.0010
[2025-05-07 04:14:48,112][train][INFO] - Epoch 1943/2000, Val Acc=0.6903, Val Loss=1.6686, lr=0.0010
[2025-05-07 04:14:50,771][train][INFO] - Epoch 1892/2000, Val Acc=0.6874, Val Loss=1.6136, lr=0.0010
[2025-05-07 04:14:54,595][train][INFO] - Epoch 1928/2000, Val Acc=0.6557, Val Loss=1.6801, lr=0.0010
[2025-05-07 04:14:55,587][train][INFO] - Epoch 1944/2000, Val Acc=0.6883, Val Loss=1.6844, lr=0.0010
[2025-05-07 04:14:58,391][train][INFO] - Epoch 1893/2000, Val Acc=0.6850, Val Loss=1.6172, lr=0.0010
[2025-05-07 04:15:02,176][train][INFO] - Epoch 1929/2000, Val Acc=0.6558, Val Loss=1.6840, lr=0.0010
[2025-05-07 04:15:03,020][train][INFO] - Epoch 1945/2000, Val Acc=0.6868, Val Loss=1.6857, lr=0.0010
[2025-05-07 04:15:05,611][train][INFO] - Epoch 1894/2000, Val Acc=0.6845, Val Loss=1.6206, lr=0.0010
[2025-05-07 04:15:09,689][train][INFO] - Epoch 1930/2000, Val Acc=0.6596, Val Loss=1.6707, lr=0.0010
[2025-05-07 04:15:10,486][train][INFO] - Epoch 1946/2000, Val Acc=0.6884, Val Loss=1.6847, lr=0.0010
[2025-05-07 04:15:13,413][train][INFO] - Epoch 1895/2000, Val Acc=0.6885, Val Loss=1.6124, lr=0.0010
[2025-05-07 04:15:17,517][train][INFO] - Epoch 1931/2000, Val Acc=0.6568, Val Loss=1.6806, lr=0.0010
[2025-05-07 04:15:18,090][train][INFO] - Epoch 1947/2000, Val Acc=0.6894, Val Loss=1.6839, lr=0.0010
[2025-05-07 04:15:20,693][train][INFO] - Epoch 1896/2000, Val Acc=0.6853, Val Loss=1.6200, lr=0.0010
[2025-05-07 04:15:25,052][train][INFO] - Epoch 1932/2000, Val Acc=0.6563, Val Loss=1.6868, lr=0.0010
[2025-05-07 04:15:25,140][train][INFO] - Epoch 1948/2000, Val Acc=0.6862, Val Loss=1.7012, lr=0.0010
[2025-05-07 04:15:28,251][train][INFO] - Epoch 1897/2000, Val Acc=0.6891, Val Loss=1.6163, lr=0.0010
[2025-05-07 04:15:32,966][train][INFO] - Epoch 1933/2000, Val Acc=0.6550, Val Loss=1.6865, lr=0.0010
[2025-05-07 04:15:33,038][train][INFO] - Epoch 1949/2000, Val Acc=0.6889, Val Loss=1.6827, lr=0.0010
[2025-05-07 04:15:36,293][train][INFO] - Epoch 1898/2000, Val Acc=0.6862, Val Loss=1.6245, lr=0.0010
[2025-05-07 04:15:40,580][train][INFO] - Epoch 1950/2000, Val Acc=0.6861, Val Loss=1.6760, lr=0.0010
[2025-05-07 04:15:40,944][train][INFO] - Epoch 1934/2000, Val Acc=0.6594, Val Loss=1.6744, lr=0.0010
[2025-05-07 04:15:44,308][train][INFO] - Epoch 1899/2000, Val Acc=0.6873, Val Loss=1.6258, lr=0.0010
[2025-05-07 04:15:48,587][train][INFO] - Epoch 1951/2000, Val Acc=0.6862, Val Loss=1.6775, lr=0.0001
[2025-05-07 04:15:48,837][train][INFO] - Epoch 1935/2000, Val Acc=0.6517, Val Loss=1.6982, lr=0.0010
[2025-05-07 04:15:52,211][train][INFO] - Epoch 1900/2000, Val Acc=0.6854, Val Loss=1.6219, lr=0.0010
[2025-05-07 04:15:56,257][train][INFO] - Epoch 1952/2000, Val Acc=0.6886, Val Loss=1.6778, lr=0.0001
[2025-05-07 04:15:56,578][train][INFO] - Epoch 1936/2000, Val Acc=0.6607, Val Loss=1.6731, lr=0.0010
[2025-05-07 04:15:59,673][train][INFO] - Epoch 1901/2000, Val Acc=0.6882, Val Loss=1.6251, lr=0.0010
[2025-05-07 04:16:03,773][train][INFO] - Epoch 1953/2000, Val Acc=0.6886, Val Loss=1.6807, lr=0.0001
[2025-05-07 04:16:03,820][train][INFO] - Epoch 1937/2000, Val Acc=0.6534, Val Loss=1.6893, lr=0.0010
[2025-05-07 04:16:07,470][train][INFO] - Epoch 1902/2000, Val Acc=0.6868, Val Loss=1.6260, lr=0.0010
[2025-05-07 04:16:11,528][train][INFO] - Epoch 1954/2000, Val Acc=0.6891, Val Loss=1.6775, lr=0.0001
[2025-05-07 04:16:11,613][train][INFO] - Epoch 1938/2000, Val Acc=0.6566, Val Loss=1.6978, lr=0.0010
[2025-05-07 04:16:15,484][train][INFO] - Epoch 1903/2000, Val Acc=0.6843, Val Loss=1.6254, lr=0.0010
[2025-05-07 04:16:19,015][train][INFO] - Epoch 1939/2000, Val Acc=0.6552, Val Loss=1.7024, lr=0.0010
[2025-05-07 04:16:19,018][train][INFO] - Epoch 1955/2000, Val Acc=0.6888, Val Loss=1.6767, lr=0.0001
[2025-05-07 04:16:23,391][train][INFO] - Epoch 1904/2000, Val Acc=0.6864, Val Loss=1.6326, lr=0.0010
[2025-05-07 04:16:26,848][train][INFO] - Epoch 1940/2000, Val Acc=0.6553, Val Loss=1.6890, lr=0.0010
[2025-05-07 04:16:26,869][train][INFO] - Epoch 1956/2000, Val Acc=0.6889, Val Loss=1.6787, lr=0.0001
[2025-05-07 04:16:31,430][train][INFO] - Epoch 1905/2000, Val Acc=0.6858, Val Loss=1.6247, lr=0.0010
[2025-05-07 04:16:34,285][train][INFO] - Epoch 1957/2000, Val Acc=0.6900, Val Loss=1.6753, lr=0.0001
[2025-05-07 04:16:34,475][train][INFO] - Epoch 1941/2000, Val Acc=0.6562, Val Loss=1.6805, lr=0.0010
[2025-05-07 04:16:39,040][train][INFO] - Epoch 1906/2000, Val Acc=0.6853, Val Loss=1.6451, lr=0.0010
[2025-05-07 04:16:41,778][train][INFO] - Epoch 1958/2000, Val Acc=0.6900, Val Loss=1.6814, lr=0.0001
[2025-05-07 04:16:41,910][train][INFO] - Epoch 1942/2000, Val Acc=0.6586, Val Loss=1.6820, lr=0.0010
[2025-05-07 04:16:47,127][train][INFO] - Epoch 1907/2000, Val Acc=0.6867, Val Loss=1.6352, lr=0.0010
[2025-05-07 04:16:49,462][train][INFO] - Epoch 1959/2000, Val Acc=0.6905, Val Loss=1.6738, lr=0.0001
[2025-05-07 04:16:49,650][train][INFO] - Epoch 1943/2000, Val Acc=0.6586, Val Loss=1.6974, lr=0.0010
[2025-05-07 04:16:54,949][train][INFO] - Epoch 1908/2000, Val Acc=0.6863, Val Loss=1.6376, lr=0.0010
[2025-05-07 04:16:56,763][train][INFO] - Epoch 1960/2000, Val Acc=0.6899, Val Loss=1.6741, lr=0.0001
[2025-05-07 04:16:57,527][train][INFO] - Epoch 1944/2000, Val Acc=0.6563, Val Loss=1.6886, lr=0.0010
[2025-05-07 04:17:02,945][train][INFO] - Epoch 1909/2000, Val Acc=0.6867, Val Loss=1.6376, lr=0.0010
[2025-05-07 04:17:04,289][train][INFO] - Epoch 1961/2000, Val Acc=0.6901, Val Loss=1.6733, lr=0.0001
[2025-05-07 04:17:05,175][train][INFO] - Epoch 1945/2000, Val Acc=0.6578, Val Loss=1.7020, lr=0.0010
[2025-05-07 04:17:10,669][train][INFO] - Epoch 1910/2000, Val Acc=0.6861, Val Loss=1.6444, lr=0.0010
[2025-05-07 04:17:12,033][train][INFO] - Epoch 1962/2000, Val Acc=0.6900, Val Loss=1.6732, lr=0.0001
[2025-05-07 04:17:12,689][train][INFO] - Epoch 1946/2000, Val Acc=0.6560, Val Loss=1.6999, lr=0.0010
[2025-05-07 04:17:18,620][train][INFO] - Epoch 1911/2000, Val Acc=0.6872, Val Loss=1.6536, lr=0.0010
[2025-05-07 04:17:19,825][train][INFO] - Epoch 1963/2000, Val Acc=0.6887, Val Loss=1.6819, lr=0.0001
[2025-05-07 04:17:20,369][train][INFO] - Epoch 1947/2000, Val Acc=0.6536, Val Loss=1.7013, lr=0.0010
[2025-05-07 04:17:26,239][train][INFO] - Epoch 1912/2000, Val Acc=0.6893, Val Loss=1.6413, lr=0.0010
[2025-05-07 04:17:27,255][train][INFO] - Epoch 1964/2000, Val Acc=0.6891, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:17:28,507][train][INFO] - Epoch 1948/2000, Val Acc=0.6558, Val Loss=1.6883, lr=0.0010
[2025-05-07 04:17:34,166][train][INFO] - Epoch 1913/2000, Val Acc=0.6873, Val Loss=1.6462, lr=0.0010
[2025-05-07 04:17:34,859][train][INFO] - Epoch 1965/2000, Val Acc=0.6898, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:17:36,183][train][INFO] - Epoch 1949/2000, Val Acc=0.6573, Val Loss=1.6986, lr=0.0010
[2025-05-07 04:17:41,979][train][INFO] - Epoch 1914/2000, Val Acc=0.6859, Val Loss=1.6365, lr=0.0010
[2025-05-07 04:17:42,802][train][INFO] - Epoch 1966/2000, Val Acc=0.6889, Val Loss=1.6728, lr=0.0001
[2025-05-07 04:17:44,102][train][INFO] - Epoch 1950/2000, Val Acc=0.6536, Val Loss=1.7061, lr=0.0010
[2025-05-07 04:17:49,632][train][INFO] - Epoch 1915/2000, Val Acc=0.6877, Val Loss=1.6524, lr=0.0010
[2025-05-07 04:17:50,485][train][INFO] - Epoch 1967/2000, Val Acc=0.6896, Val Loss=1.6708, lr=0.0001
[2025-05-07 04:17:51,628][train][INFO] - Epoch 1951/2000, Val Acc=0.6588, Val Loss=1.6847, lr=0.0001
[2025-05-07 04:17:57,457][train][INFO] - Epoch 1916/2000, Val Acc=0.6863, Val Loss=1.6471, lr=0.0010
[2025-05-07 04:17:57,792][train][INFO] - Epoch 1968/2000, Val Acc=0.6904, Val Loss=1.6706, lr=0.0001
[2025-05-07 04:17:59,347][train][INFO] - Epoch 1952/2000, Val Acc=0.6585, Val Loss=1.6866, lr=0.0001
[2025-05-07 04:18:05,144][train][INFO] - Epoch 1969/2000, Val Acc=0.6883, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:18:05,278][train][INFO] - Epoch 1917/2000, Val Acc=0.6852, Val Loss=1.6591, lr=0.0010
[2025-05-07 04:18:06,785][train][INFO] - Epoch 1953/2000, Val Acc=0.6599, Val Loss=1.6868, lr=0.0001
[2025-05-07 04:18:12,519][train][INFO] - Epoch 1970/2000, Val Acc=0.6902, Val Loss=1.6745, lr=0.0001
[2025-05-07 04:18:13,210][train][INFO] - Epoch 1918/2000, Val Acc=0.6903, Val Loss=1.6476, lr=0.0010
[2025-05-07 04:18:14,530][train][INFO] - Epoch 1954/2000, Val Acc=0.6617, Val Loss=1.6879, lr=0.0001
[2025-05-07 04:18:19,913][train][INFO] - Epoch 1971/2000, Val Acc=0.6904, Val Loss=1.6721, lr=0.0001
[2025-05-07 04:18:20,879][train][INFO] - Epoch 1919/2000, Val Acc=0.6871, Val Loss=1.6661, lr=0.0010
[2025-05-07 04:18:22,218][train][INFO] - Epoch 1955/2000, Val Acc=0.6606, Val Loss=1.6871, lr=0.0001
[2025-05-07 04:18:27,242][train][INFO] - Epoch 1972/2000, Val Acc=0.6910, Val Loss=1.6759, lr=0.0001
[2025-05-07 04:18:28,535][train][INFO] - Epoch 1920/2000, Val Acc=0.6865, Val Loss=1.6629, lr=0.0010
[2025-05-07 04:18:29,875][train][INFO] - Epoch 1956/2000, Val Acc=0.6587, Val Loss=1.6870, lr=0.0001
[2025-05-07 04:18:34,436][train][INFO] - Epoch 1973/2000, Val Acc=0.6888, Val Loss=1.6751, lr=0.0001
[2025-05-07 04:18:36,239][train][INFO] - Epoch 1921/2000, Val Acc=0.6832, Val Loss=1.6689, lr=0.0010
[2025-05-07 04:18:37,381][train][INFO] - Epoch 1957/2000, Val Acc=0.6617, Val Loss=1.6816, lr=0.0001
[2025-05-07 04:18:41,864][train][INFO] - Epoch 1974/2000, Val Acc=0.6881, Val Loss=1.6725, lr=0.0001
[2025-05-07 04:18:44,594][train][INFO] - Epoch 1922/2000, Val Acc=0.6833, Val Loss=1.6734, lr=0.0010
[2025-05-07 04:18:44,853][train][INFO] - Epoch 1958/2000, Val Acc=0.6602, Val Loss=1.6900, lr=0.0001
[2025-05-07 04:18:49,641][train][INFO] - Epoch 1975/2000, Val Acc=0.6909, Val Loss=1.6675, lr=0.0001
[2025-05-07 04:18:52,311][train][INFO] - Epoch 1923/2000, Val Acc=0.6886, Val Loss=1.6514, lr=0.0010
[2025-05-07 04:18:52,458][train][INFO] - Epoch 1959/2000, Val Acc=0.6607, Val Loss=1.6869, lr=0.0001
[2025-05-07 04:18:57,175][train][INFO] - Epoch 1976/2000, Val Acc=0.6890, Val Loss=1.6731, lr=0.0001
[2025-05-07 04:18:59,350][train][INFO] - Epoch 1960/2000, Val Acc=0.6617, Val Loss=1.6828, lr=0.0001
[2025-05-07 04:18:59,795][train][INFO] - Epoch 1924/2000, Val Acc=0.6851, Val Loss=1.6501, lr=0.0010
[2025-05-07 04:19:05,133][train][INFO] - Epoch 1977/2000, Val Acc=0.6888, Val Loss=1.6768, lr=0.0001
[2025-05-07 04:19:07,422][train][INFO] - Epoch 1961/2000, Val Acc=0.6618, Val Loss=1.6867, lr=0.0001
[2025-05-07 04:19:07,757][train][INFO] - Epoch 1925/2000, Val Acc=0.6889, Val Loss=1.6374, lr=0.0010
[2025-05-07 04:19:12,942][train][INFO] - Epoch 1978/2000, Val Acc=0.6890, Val Loss=1.6714, lr=0.0001
[2025-05-07 04:19:15,179][train][INFO] - Epoch 1962/2000, Val Acc=0.6619, Val Loss=1.6907, lr=0.0001
[2025-05-07 04:19:15,563][train][INFO] - Epoch 1926/2000, Val Acc=0.6845, Val Loss=1.6590, lr=0.0010
[2025-05-07 04:19:20,383][train][INFO] - Epoch 1979/2000, Val Acc=0.6910, Val Loss=1.6764, lr=0.0001
[2025-05-07 04:19:22,608][train][INFO] - Epoch 1963/2000, Val Acc=0.6594, Val Loss=1.6961, lr=0.0001
[2025-05-07 04:19:23,419][train][INFO] - Epoch 1927/2000, Val Acc=0.6903, Val Loss=1.6501, lr=0.0010
[2025-05-07 04:19:27,461][train][INFO] - Epoch 1980/2000, Val Acc=0.6888, Val Loss=1.6802, lr=0.0001
[2025-05-07 04:19:30,461][train][INFO] - Epoch 1964/2000, Val Acc=0.6619, Val Loss=1.6929, lr=0.0001
[2025-05-07 04:19:31,313][train][INFO] - Epoch 1928/2000, Val Acc=0.6871, Val Loss=1.6678, lr=0.0010
[2025-05-07 04:19:35,148][train][INFO] - Epoch 1981/2000, Val Acc=0.6890, Val Loss=1.6769, lr=0.0001
[2025-05-07 04:19:37,937][train][INFO] - Epoch 1965/2000, Val Acc=0.6615, Val Loss=1.6856, lr=0.0001
[2025-05-07 04:19:39,154][train][INFO] - Epoch 1929/2000, Val Acc=0.6880, Val Loss=1.6580, lr=0.0010
[2025-05-07 04:19:42,521][train][INFO] - Epoch 1982/2000, Val Acc=0.6906, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:19:45,595][train][INFO] - Epoch 1966/2000, Val Acc=0.6630, Val Loss=1.6845, lr=0.0001
[2025-05-07 04:19:46,856][train][INFO] - Epoch 1930/2000, Val Acc=0.6865, Val Loss=1.6741, lr=0.0010
[2025-05-07 04:19:49,660][train][INFO] - Epoch 1983/2000, Val Acc=0.6904, Val Loss=1.6722, lr=0.0001
[2025-05-07 04:19:53,354][train][INFO] - Epoch 1967/2000, Val Acc=0.6621, Val Loss=1.6817, lr=0.0001
[2025-05-07 04:19:54,797][train][INFO] - Epoch 1931/2000, Val Acc=0.6874, Val Loss=1.6720, lr=0.0010
[2025-05-07 04:19:57,142][train][INFO] - Epoch 1984/2000, Val Acc=0.6897, Val Loss=1.6738, lr=0.0001
[2025-05-07 04:20:01,016][train][INFO] - Epoch 1968/2000, Val Acc=0.6614, Val Loss=1.6855, lr=0.0001
[2025-05-07 04:20:02,292][train][INFO] - Epoch 1932/2000, Val Acc=0.6895, Val Loss=1.6612, lr=0.0010
[2025-05-07 04:20:05,148][train][INFO] - Epoch 1985/2000, Val Acc=0.6894, Val Loss=1.6712, lr=0.0001
[2025-05-07 04:20:08,857][train][INFO] - Epoch 1969/2000, Val Acc=0.6609, Val Loss=1.6993, lr=0.0001
[2025-05-07 04:20:09,934][train][INFO] - Epoch 1933/2000, Val Acc=0.6900, Val Loss=1.6685, lr=0.0010
[2025-05-07 04:20:12,352][train][INFO] - Epoch 1986/2000, Val Acc=0.6897, Val Loss=1.6771, lr=0.0001
[2025-05-07 04:20:16,284][train][INFO] - Epoch 1970/2000, Val Acc=0.6623, Val Loss=1.6940, lr=0.0001
[2025-05-07 04:20:17,823][train][INFO] - Epoch 1934/2000, Val Acc=0.6869, Val Loss=1.6632, lr=0.0010
[2025-05-07 04:20:19,770][train][INFO] - Epoch 1987/2000, Val Acc=0.6899, Val Loss=1.6717, lr=0.0001
[2025-05-07 04:20:23,392][train][INFO] - Epoch 1971/2000, Val Acc=0.6620, Val Loss=1.6867, lr=0.0001
[2025-05-07 04:20:25,270][train][INFO] - Epoch 1935/2000, Val Acc=0.6875, Val Loss=1.6697, lr=0.0010
[2025-05-07 04:20:27,026][train][INFO] - Epoch 1988/2000, Val Acc=0.6895, Val Loss=1.6762, lr=0.0001
[2025-05-07 04:20:30,860][train][INFO] - Epoch 1972/2000, Val Acc=0.6620, Val Loss=1.6904, lr=0.0001
[2025-05-07 04:20:33,059][train][INFO] - Epoch 1936/2000, Val Acc=0.6848, Val Loss=1.6672, lr=0.0010
[2025-05-07 04:20:34,484][train][INFO] - Epoch 1989/2000, Val Acc=0.6892, Val Loss=1.6722, lr=0.0001
[2025-05-07 04:20:38,761][train][INFO] - Epoch 1973/2000, Val Acc=0.6615, Val Loss=1.7026, lr=0.0001
[2025-05-07 04:20:40,889][train][INFO] - Epoch 1937/2000, Val Acc=0.6854, Val Loss=1.6736, lr=0.0010
[2025-05-07 04:20:42,134][train][INFO] - Epoch 1990/2000, Val Acc=0.6901, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:20:46,647][train][INFO] - Epoch 1974/2000, Val Acc=0.6604, Val Loss=1.6972, lr=0.0001
[2025-05-07 04:20:48,153][train][INFO] - Epoch 1938/2000, Val Acc=0.6849, Val Loss=1.6852, lr=0.0010
[2025-05-07 04:20:49,497][train][INFO] - Epoch 1991/2000, Val Acc=0.6884, Val Loss=1.6761, lr=0.0001
[2025-05-07 04:20:53,928][train][INFO] - Epoch 1975/2000, Val Acc=0.6613, Val Loss=1.6909, lr=0.0001
[2025-05-07 04:20:56,133][train][INFO] - Epoch 1939/2000, Val Acc=0.6880, Val Loss=1.6772, lr=0.0010
[2025-05-07 04:20:56,684][train][INFO] - Epoch 1992/2000, Val Acc=0.6887, Val Loss=1.6782, lr=0.0001
[2025-05-07 04:21:01,300][train][INFO] - Epoch 1976/2000, Val Acc=0.6599, Val Loss=1.6958, lr=0.0001
[2025-05-07 04:21:03,833][train][INFO] - Epoch 1940/2000, Val Acc=0.6880, Val Loss=1.6763, lr=0.0010
[2025-05-07 04:21:04,298][train][INFO] - Epoch 1993/2000, Val Acc=0.6885, Val Loss=1.6728, lr=0.0001
[2025-05-07 04:21:08,977][train][INFO] - Epoch 1977/2000, Val Acc=0.6604, Val Loss=1.6973, lr=0.0001
[2025-05-07 04:21:11,709][train][INFO] - Epoch 1941/2000, Val Acc=0.6863, Val Loss=1.6879, lr=0.0010
[2025-05-07 04:21:11,863][train][INFO] - Epoch 1994/2000, Val Acc=0.6886, Val Loss=1.6698, lr=0.0001
[2025-05-07 04:21:16,551][train][INFO] - Epoch 1978/2000, Val Acc=0.6604, Val Loss=1.6954, lr=0.0001
[2025-05-07 04:21:19,463][train][INFO] - Epoch 1995/2000, Val Acc=0.6914, Val Loss=1.6753, lr=0.0001
[2025-05-07 04:21:19,509][train][INFO] - Epoch 1942/2000, Val Acc=0.6891, Val Loss=1.6792, lr=0.0010
[2025-05-07 04:21:23,620][train][INFO] - Epoch 1979/2000, Val Acc=0.6618, Val Loss=1.7098, lr=0.0001
[2025-05-07 04:21:27,012][train][INFO] - Epoch 1996/2000, Val Acc=0.6898, Val Loss=1.6713, lr=0.0001
[2025-05-07 04:21:27,315][train][INFO] - Epoch 1943/2000, Val Acc=0.6903, Val Loss=1.6686, lr=0.0010
[2025-05-07 04:21:30,796][train][INFO] - Epoch 1980/2000, Val Acc=0.6603, Val Loss=1.7018, lr=0.0001
[2025-05-07 04:21:34,765][train][INFO] - Epoch 1997/2000, Val Acc=0.6892, Val Loss=1.6752, lr=0.0001
[2025-05-07 04:21:35,459][train][INFO] - Epoch 1944/2000, Val Acc=0.6883, Val Loss=1.6844, lr=0.0010
[2025-05-07 04:21:38,887][train][INFO] - Epoch 1981/2000, Val Acc=0.6599, Val Loss=1.6976, lr=0.0001
[2025-05-07 04:21:42,227][train][INFO] - Epoch 1998/2000, Val Acc=0.6895, Val Loss=1.6760, lr=0.0001
[2025-05-07 04:21:43,241][train][INFO] - Epoch 1945/2000, Val Acc=0.6868, Val Loss=1.6857, lr=0.0010
[2025-05-07 04:21:46,452][train][INFO] - Epoch 1982/2000, Val Acc=0.6609, Val Loss=1.6980, lr=0.0001
[2025-05-07 04:21:49,903][train][INFO] - Epoch 1999/2000, Val Acc=0.6905, Val Loss=1.6733, lr=0.0001
[2025-05-07 04:21:51,238][train][INFO] - Epoch 1946/2000, Val Acc=0.6884, Val Loss=1.6847, lr=0.0010
[2025-05-07 04:21:53,832][train][INFO] - Epoch 1983/2000, Val Acc=0.6605, Val Loss=1.6972, lr=0.0001
[2025-05-07 04:21:57,203][train][INFO] - Epoch 2000/2000, Val Acc=0.6893, Val Loss=1.6819, lr=0.0001
[2025-05-07 04:21:59,045][train][INFO] - Epoch 1947/2000, Val Acc=0.6894, Val Loss=1.6839, lr=0.0010
[2025-05-07 04:22:01,654][train][INFO] - Epoch 1984/2000, Val Acc=0.6607, Val Loss=1.7041, lr=0.0001
[2025-05-07 04:22:02,443][train][INFO] - After training : Train Acc=0.9982  Val Acc=0.6914
[2025-05-07 04:22:07,400][train][INFO] - Epoch 1948/2000, Val Acc=0.6862, Val Loss=1.7012, lr=0.0010
[2025-05-07 04:22:08,939][train][INFO] - Epoch 1985/2000, Val Acc=0.6625, Val Loss=1.7013, lr=0.0001
[2025-05-07 04:22:13,245][Progressive pruning][INFO] - Train acc : 0.009999999776482582   Val acc : 0.009999999776482582
[2025-05-07 04:22:13,245][Progressive pruning][INFO] - Current speed up: 4.47
[2025-05-07 04:22:15,079][train][INFO] - Epoch 1949/2000, Val Acc=0.6889, Val Loss=1.6827, lr=0.0010
[2025-05-07 04:22:16,558][train][INFO] - Epoch 1986/2000, Val Acc=0.6620, Val Loss=1.7003, lr=0.0001
[2025-05-07 04:22:18,393][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-05-07 04:22:22,603][train][INFO] - Epoch 1950/2000, Val Acc=0.6861, Val Loss=1.6760, lr=0.0010
[2025-05-07 04:22:24,170][train][INFO] - Epoch 1987/2000, Val Acc=0.6642, Val Loss=1.6989, lr=0.0001
[2025-05-07 04:22:26,161][train][INFO] - Epoch 1/2000, Val Acc=0.5271, Val Loss=2.0096, lr=0.0100
[2025-05-07 04:22:30,117][train][INFO] - Epoch 1951/2000, Val Acc=0.6862, Val Loss=1.6775, lr=0.0001
[2025-05-07 04:22:31,289][train][INFO] - Epoch 1988/2000, Val Acc=0.6618, Val Loss=1.7078, lr=0.0001
[2025-05-07 04:22:33,122][train][INFO] - Epoch 2/2000, Val Acc=0.5680, Val Loss=1.7878, lr=0.0100
[2025-05-07 04:22:38,053][train][INFO] - Epoch 1952/2000, Val Acc=0.6886, Val Loss=1.6778, lr=0.0001
[2025-05-07 04:22:38,489][train][INFO] - Epoch 1989/2000, Val Acc=0.6611, Val Loss=1.7000, lr=0.0001
[2025-05-07 04:22:40,142][train][INFO] - Epoch 3/2000, Val Acc=0.5647, Val Loss=1.8531, lr=0.0100
[2025-05-07 04:22:45,813][train][INFO] - Epoch 1953/2000, Val Acc=0.6886, Val Loss=1.6807, lr=0.0001
[2025-05-07 04:22:46,284][train][INFO] - Epoch 1990/2000, Val Acc=0.6602, Val Loss=1.7082, lr=0.0001
[2025-05-07 04:22:47,762][train][INFO] - Epoch 4/2000, Val Acc=0.5762, Val Loss=1.7648, lr=0.0100
[2025-05-07 04:22:53,466][train][INFO] - Epoch 1954/2000, Val Acc=0.6891, Val Loss=1.6775, lr=0.0001
[2025-05-07 04:22:53,701][train][INFO] - Epoch 1991/2000, Val Acc=0.6614, Val Loss=1.7095, lr=0.0001
[2025-05-07 04:22:55,405][train][INFO] - Epoch 5/2000, Val Acc=0.5763, Val Loss=1.7883, lr=0.0100
[2025-05-07 04:23:00,886][train][INFO] - Epoch 1992/2000, Val Acc=0.6605, Val Loss=1.7074, lr=0.0001
[2025-05-07 04:23:01,170][train][INFO] - Epoch 1955/2000, Val Acc=0.6888, Val Loss=1.6767, lr=0.0001
[2025-05-07 04:23:03,077][train][INFO] - Epoch 6/2000, Val Acc=0.5858, Val Loss=1.7734, lr=0.0100
[2025-05-07 04:23:08,473][train][INFO] - Epoch 1993/2000, Val Acc=0.6610, Val Loss=1.7011, lr=0.0001
[2025-05-07 04:23:08,829][train][INFO] - Epoch 1956/2000, Val Acc=0.6889, Val Loss=1.6787, lr=0.0001
[2025-05-07 04:23:10,471][train][INFO] - Epoch 7/2000, Val Acc=0.5846, Val Loss=1.7850, lr=0.0100
[2025-05-07 04:23:15,855][train][INFO] - Epoch 1994/2000, Val Acc=0.6590, Val Loss=1.7047, lr=0.0001
[2025-05-07 04:23:16,888][train][INFO] - Epoch 1957/2000, Val Acc=0.6900, Val Loss=1.6753, lr=0.0001
[2025-05-07 04:23:17,865][train][INFO] - Epoch 8/2000, Val Acc=0.5906, Val Loss=1.7782, lr=0.0100
[2025-05-07 04:23:23,616][train][INFO] - Epoch 1995/2000, Val Acc=0.6618, Val Loss=1.7052, lr=0.0001
[2025-05-07 04:23:24,831][train][INFO] - Epoch 1958/2000, Val Acc=0.6900, Val Loss=1.6814, lr=0.0001
[2025-05-07 04:23:25,437][train][INFO] - Epoch 9/2000, Val Acc=0.5933, Val Loss=1.7402, lr=0.0100
[2025-05-07 04:23:31,367][train][INFO] - Epoch 1996/2000, Val Acc=0.6611, Val Loss=1.7029, lr=0.0001
[2025-05-07 04:23:32,709][train][INFO] - Epoch 10/2000, Val Acc=0.5973, Val Loss=1.7259, lr=0.0100
[2025-05-07 04:23:32,843][train][INFO] - Epoch 1959/2000, Val Acc=0.6905, Val Loss=1.6738, lr=0.0001
[2025-05-07 04:23:39,205][train][INFO] - Epoch 1997/2000, Val Acc=0.6592, Val Loss=1.7074, lr=0.0001
[2025-05-07 04:23:40,263][train][INFO] - Epoch 11/2000, Val Acc=0.6035, Val Loss=1.6946, lr=0.0100
[2025-05-07 04:23:40,570][train][INFO] - Epoch 1960/2000, Val Acc=0.6899, Val Loss=1.6741, lr=0.0001
[2025-05-07 04:23:47,096][train][INFO] - Epoch 1998/2000, Val Acc=0.6613, Val Loss=1.7036, lr=0.0001
[2025-05-07 04:23:47,289][train][INFO] - Epoch 12/2000, Val Acc=0.5918, Val Loss=1.7606, lr=0.0100
[2025-05-07 04:23:48,379][train][INFO] - Epoch 1961/2000, Val Acc=0.6901, Val Loss=1.6733, lr=0.0001
[2025-05-07 04:23:54,576][train][INFO] - Epoch 13/2000, Val Acc=0.5984, Val Loss=1.7467, lr=0.0100
[2025-05-07 04:23:54,660][train][INFO] - Epoch 1999/2000, Val Acc=0.6595, Val Loss=1.7094, lr=0.0001
[2025-05-07 04:23:55,848][train][INFO] - Epoch 1962/2000, Val Acc=0.6900, Val Loss=1.6732, lr=0.0001
[2025-05-07 04:24:01,509][train][INFO] - Epoch 14/2000, Val Acc=0.5901, Val Loss=1.8030, lr=0.0100
[2025-05-07 04:24:02,327][train][INFO] - Epoch 2000/2000, Val Acc=0.6601, Val Loss=1.7084, lr=0.0001
[2025-05-07 04:24:03,905][train][INFO] - Epoch 1963/2000, Val Acc=0.6887, Val Loss=1.6819, lr=0.0001
[2025-05-07 04:24:07,639][train][INFO] - After training : Train Acc=0.9231  Val Acc=0.6702
[2025-05-07 04:24:07,644][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-07 04:24:09,172][train][INFO] - Epoch 15/2000, Val Acc=0.6215, Val Loss=1.6257, lr=0.0100
[2025-05-07 04:24:11,572][train][INFO] - Epoch 1964/2000, Val Acc=0.6891, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:24:16,794][train][INFO] - Epoch 16/2000, Val Acc=0.5838, Val Loss=1.8449, lr=0.0100
[2025-05-07 04:24:19,527][train][INFO] - Epoch 1965/2000, Val Acc=0.6898, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:24:24,441][train][INFO] - Epoch 17/2000, Val Acc=0.6007, Val Loss=1.7213, lr=0.0100
[2025-05-07 04:24:27,688][train][INFO] - Epoch 1966/2000, Val Acc=0.6889, Val Loss=1.6728, lr=0.0001
[2025-05-07 04:24:32,150][train][INFO] - Epoch 18/2000, Val Acc=0.6048, Val Loss=1.6681, lr=0.0100
[2025-05-07 04:24:35,371][train][INFO] - Epoch 1967/2000, Val Acc=0.6896, Val Loss=1.6708, lr=0.0001
[2025-05-07 04:24:39,964][train][INFO] - Epoch 19/2000, Val Acc=0.5983, Val Loss=1.7923, lr=0.0100
[2025-05-07 04:24:43,383][train][INFO] - Epoch 1968/2000, Val Acc=0.6904, Val Loss=1.6706, lr=0.0001
[2025-05-07 04:24:47,911][train][INFO] - Epoch 20/2000, Val Acc=0.6018, Val Loss=1.7472, lr=0.0100
[2025-05-07 04:24:51,735][train][INFO] - Epoch 1969/2000, Val Acc=0.6883, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:24:55,237][train][INFO] - Epoch 21/2000, Val Acc=0.5657, Val Loss=1.9543, lr=0.0100
[2025-05-07 04:24:59,464][train][INFO] - Epoch 1970/2000, Val Acc=0.6902, Val Loss=1.6745, lr=0.0001
[2025-05-07 04:25:02,881][train][INFO] - Epoch 22/2000, Val Acc=0.5999, Val Loss=1.7248, lr=0.0100
[2025-05-07 04:25:07,222][train][INFO] - Epoch 1971/2000, Val Acc=0.6904, Val Loss=1.6721, lr=0.0001
[2025-05-07 04:25:10,597][train][INFO] - Epoch 23/2000, Val Acc=0.6267, Val Loss=1.6454, lr=0.0100
[2025-05-07 04:25:15,243][train][INFO] - Epoch 1972/2000, Val Acc=0.6910, Val Loss=1.6759, lr=0.0001
[2025-05-07 04:25:18,334][train][INFO] - Epoch 24/2000, Val Acc=0.6093, Val Loss=1.7006, lr=0.0100
[2025-05-07 04:25:23,510][train][INFO] - Epoch 1973/2000, Val Acc=0.6888, Val Loss=1.6751, lr=0.0001
[2025-05-07 04:25:26,016][train][INFO] - Epoch 25/2000, Val Acc=0.6101, Val Loss=1.6908, lr=0.0100
[2025-05-07 04:25:31,526][train][INFO] - Epoch 1974/2000, Val Acc=0.6881, Val Loss=1.6725, lr=0.0001
[2025-05-07 04:25:33,824][train][INFO] - Epoch 26/2000, Val Acc=0.5789, Val Loss=1.8854, lr=0.0100
[2025-05-07 04:25:39,504][train][INFO] - Epoch 1975/2000, Val Acc=0.6909, Val Loss=1.6675, lr=0.0001
[2025-05-07 04:25:41,567][train][INFO] - Epoch 27/2000, Val Acc=0.5992, Val Loss=1.7998, lr=0.0100
[2025-05-07 04:25:47,275][train][INFO] - Epoch 1976/2000, Val Acc=0.6890, Val Loss=1.6731, lr=0.0001
[2025-05-07 04:25:49,467][train][INFO] - Epoch 28/2000, Val Acc=0.6186, Val Loss=1.6597, lr=0.0100
[2025-05-07 04:25:55,146][train][INFO] - Epoch 1977/2000, Val Acc=0.6888, Val Loss=1.6768, lr=0.0001
[2025-05-07 04:25:57,349][train][INFO] - Epoch 29/2000, Val Acc=0.6228, Val Loss=1.6351, lr=0.0100
[2025-05-07 04:25:59,500][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-07 04:26:02,875][train][INFO] - Epoch 1978/2000, Val Acc=0.6890, Val Loss=1.6714, lr=0.0001
[2025-05-07 04:26:04,954][train][INFO] - Epoch 30/2000, Val Acc=0.6135, Val Loss=1.6986, lr=0.0100
[2025-05-07 04:26:10,457][train][INFO] - Epoch 1979/2000, Val Acc=0.6910, Val Loss=1.6764, lr=0.0001
[2025-05-07 04:26:12,530][train][INFO] - Epoch 31/2000, Val Acc=0.6058, Val Loss=1.7130, lr=0.0100
[2025-05-07 04:26:18,661][train][INFO] - Epoch 1980/2000, Val Acc=0.6888, Val Loss=1.6802, lr=0.0001
[2025-05-07 04:26:20,128][train][INFO] - Epoch 32/2000, Val Acc=0.6017, Val Loss=1.7572, lr=0.0100
[2025-05-07 04:26:26,776][train][INFO] - Epoch 1981/2000, Val Acc=0.6890, Val Loss=1.6769, lr=0.0001
[2025-05-07 04:26:27,789][train][INFO] - Epoch 33/2000, Val Acc=0.6038, Val Loss=1.7638, lr=0.0100
[2025-05-07 04:26:34,713][train][INFO] - Epoch 1982/2000, Val Acc=0.6906, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:26:35,157][train][INFO] - Epoch 34/2000, Val Acc=0.5760, Val Loss=1.9400, lr=0.0100
[2025-05-07 04:26:42,345][train][INFO] - Epoch 35/2000, Val Acc=0.6069, Val Loss=1.7019, lr=0.0100
[2025-05-07 04:26:42,618][train][INFO] - Epoch 1983/2000, Val Acc=0.6904, Val Loss=1.6722, lr=0.0001
[2025-05-07 04:26:49,470][train][INFO] - Epoch 36/2000, Val Acc=0.5805, Val Loss=1.8987, lr=0.0100
[2025-05-07 04:26:50,501][train][INFO] - Epoch 1984/2000, Val Acc=0.6897, Val Loss=1.6738, lr=0.0001
[2025-05-07 04:26:56,887][train][INFO] - Epoch 37/2000, Val Acc=0.5960, Val Loss=1.8561, lr=0.0100
[2025-05-07 04:26:58,509][train][INFO] - Epoch 1985/2000, Val Acc=0.6894, Val Loss=1.6712, lr=0.0001
[2025-05-07 04:27:04,935][train][INFO] - Epoch 38/2000, Val Acc=0.5970, Val Loss=1.8243, lr=0.0100
[2025-05-07 04:27:06,630][train][INFO] - Epoch 1986/2000, Val Acc=0.6897, Val Loss=1.6771, lr=0.0001
[2025-05-07 04:27:12,424][train][INFO] - Epoch 39/2000, Val Acc=0.6199, Val Loss=1.6682, lr=0.0100
[2025-05-07 04:27:14,717][train][INFO] - Epoch 1987/2000, Val Acc=0.6899, Val Loss=1.6717, lr=0.0001
[2025-05-07 04:27:19,786][train][INFO] - Epoch 40/2000, Val Acc=0.6063, Val Loss=1.7346, lr=0.0100
[2025-05-07 04:27:22,550][train][INFO] - Epoch 1988/2000, Val Acc=0.6895, Val Loss=1.6762, lr=0.0001
[2025-05-07 04:27:27,756][train][INFO] - Epoch 41/2000, Val Acc=0.6033, Val Loss=1.8022, lr=0.0100
[2025-05-07 04:27:30,547][train][INFO] - Epoch 1989/2000, Val Acc=0.6892, Val Loss=1.6722, lr=0.0001
[2025-05-07 04:27:35,462][train][INFO] - Epoch 42/2000, Val Acc=0.6198, Val Loss=1.6640, lr=0.0100
[2025-05-07 04:27:38,921][train][INFO] - Epoch 1990/2000, Val Acc=0.6901, Val Loss=1.6788, lr=0.0001
[2025-05-07 04:27:43,261][train][INFO] - Epoch 43/2000, Val Acc=0.6034, Val Loss=1.7980, lr=0.0100
[2025-05-07 04:27:46,897][train][INFO] - Epoch 1991/2000, Val Acc=0.6884, Val Loss=1.6761, lr=0.0001
[2025-05-07 04:27:50,894][train][INFO] - Epoch 44/2000, Val Acc=0.6106, Val Loss=1.7343, lr=0.0100
[2025-05-07 04:27:54,667][train][INFO] - Epoch 1992/2000, Val Acc=0.6887, Val Loss=1.6782, lr=0.0001
[2025-05-07 04:27:58,811][train][INFO] - Epoch 45/2000, Val Acc=0.6167, Val Loss=1.7039, lr=0.0100
[2025-05-07 04:28:02,269][train][INFO] - Epoch 1993/2000, Val Acc=0.6885, Val Loss=1.6728, lr=0.0001
[2025-05-07 04:28:04,757][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-07 04:28:05,212][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-07 04:28:06,764][train][INFO] - Epoch 46/2000, Val Acc=0.6056, Val Loss=1.7646, lr=0.0100
[2025-05-07 04:28:10,766][train][INFO] - Epoch 1994/2000, Val Acc=0.6886, Val Loss=1.6698, lr=0.0001
[2025-05-07 04:28:14,556][train][INFO] - Epoch 47/2000, Val Acc=0.5995, Val Loss=1.7761, lr=0.0100
[2025-05-07 04:28:18,970][train][INFO] - Epoch 1995/2000, Val Acc=0.6914, Val Loss=1.6753, lr=0.0001
[2025-05-07 04:28:22,630][train][INFO] - Epoch 48/2000, Val Acc=0.6125, Val Loss=1.7291, lr=0.0100
[2025-05-07 04:28:27,249][train][INFO] - Epoch 1996/2000, Val Acc=0.6898, Val Loss=1.6713, lr=0.0001
[2025-05-07 04:28:30,730][train][INFO] - Epoch 49/2000, Val Acc=0.6017, Val Loss=1.7761, lr=0.0100
[2025-05-07 04:28:34,932][train][INFO] - Epoch 1997/2000, Val Acc=0.6892, Val Loss=1.6752, lr=0.0001
[2025-05-07 04:28:38,937][train][INFO] - Epoch 50/2000, Val Acc=0.5993, Val Loss=1.7724, lr=0.0100
[2025-05-07 04:28:43,575][train][INFO] - Epoch 1998/2000, Val Acc=0.6895, Val Loss=1.6760, lr=0.0001
[2025-05-07 04:28:47,138][train][INFO] - Epoch 51/2000, Val Acc=0.6024, Val Loss=1.8081, lr=0.0100
[2025-05-07 04:28:51,660][train][INFO] - Epoch 1999/2000, Val Acc=0.6905, Val Loss=1.6733, lr=0.0001
[2025-05-07 04:28:54,990][train][INFO] - Epoch 52/2000, Val Acc=0.6071, Val Loss=1.7591, lr=0.0100
[2025-05-07 04:28:59,967][train][INFO] - Epoch 2000/2000, Val Acc=0.6893, Val Loss=1.6819, lr=0.0001
[2025-05-07 04:29:02,745][train][INFO] - Epoch 53/2000, Val Acc=0.6015, Val Loss=1.7969, lr=0.0100
[2025-05-07 04:29:05,228][train][INFO] - After training : Train Acc=0.9982  Val Acc=0.6914
[2025-05-07 04:29:05,233][Visualize acc speed up curve][INFO] - Start visualizing
[2025-05-07 04:29:10,970][train][INFO] - Epoch 54/2000, Val Acc=0.5937, Val Loss=1.8232, lr=0.0100
[2025-05-07 04:29:18,533][train][INFO] - Epoch 55/2000, Val Acc=0.5936, Val Loss=1.8189, lr=0.0100
[2025-05-07 04:29:26,689][train][INFO] - Epoch 56/2000, Val Acc=0.6109, Val Loss=1.7195, lr=0.0100
[2025-05-07 04:29:34,739][train][INFO] - Epoch 57/2000, Val Acc=0.6058, Val Loss=1.7454, lr=0.0100
[2025-05-07 04:29:42,715][train][INFO] - Epoch 58/2000, Val Acc=0.6126, Val Loss=1.7306, lr=0.0100
[2025-05-07 04:29:50,835][train][INFO] - Epoch 59/2000, Val Acc=0.6190, Val Loss=1.7013, lr=0.0100
[2025-05-07 04:29:58,315][train][INFO] - Epoch 60/2000, Val Acc=0.6002, Val Loss=1.8318, lr=0.0100
[2025-05-07 04:30:06,295][train][INFO] - Epoch 61/2000, Val Acc=0.6185, Val Loss=1.6774, lr=0.0100
[2025-05-07 04:30:14,629][train][INFO] - Epoch 62/2000, Val Acc=0.6114, Val Loss=1.7281, lr=0.0100
[2025-05-07 04:30:22,594][train][INFO] - Epoch 63/2000, Val Acc=0.6105, Val Loss=1.7280, lr=0.0100
[2025-05-07 04:30:30,960][train][INFO] - Epoch 64/2000, Val Acc=0.6085, Val Loss=1.7397, lr=0.0100
[2025-05-07 04:30:38,762][train][INFO] - Epoch 65/2000, Val Acc=0.5998, Val Loss=1.7826, lr=0.0100
[2025-05-07 04:30:46,258][train][INFO] - Epoch 66/2000, Val Acc=0.6182, Val Loss=1.6712, lr=0.0100
[2025-05-07 04:30:54,207][train][INFO] - Epoch 67/2000, Val Acc=0.6078, Val Loss=1.7375, lr=0.0100
[2025-05-07 04:31:01,468][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-05-07 04:31:01,740][train][INFO] - Epoch 68/2000, Val Acc=0.6124, Val Loss=1.7003, lr=0.0100
[2025-05-07 04:31:09,455][train][INFO] - Epoch 69/2000, Val Acc=0.6197, Val Loss=1.7026, lr=0.0100
[2025-05-07 04:31:17,551][train][INFO] - Epoch 70/2000, Val Acc=0.5894, Val Loss=1.8842, lr=0.0100
[2025-05-07 04:31:25,528][train][INFO] - Epoch 71/2000, Val Acc=0.6108, Val Loss=1.7171, lr=0.0100
[2025-05-07 04:31:33,077][train][INFO] - Epoch 72/2000, Val Acc=0.6108, Val Loss=1.7364, lr=0.0100
[2025-05-07 04:31:41,014][train][INFO] - Epoch 73/2000, Val Acc=0.6167, Val Loss=1.7217, lr=0.0100
[2025-05-07 04:31:48,817][train][INFO] - Epoch 74/2000, Val Acc=0.6127, Val Loss=1.7271, lr=0.0100
[2025-05-07 04:31:57,084][train][INFO] - Epoch 75/2000, Val Acc=0.6080, Val Loss=1.7912, lr=0.0100
[2025-05-07 04:32:05,181][train][INFO] - Epoch 76/2000, Val Acc=0.5948, Val Loss=1.8486, lr=0.0100
[2025-05-07 04:32:13,209][train][INFO] - Epoch 77/2000, Val Acc=0.6052, Val Loss=1.8338, lr=0.0100
[2025-05-07 04:32:21,226][train][INFO] - Epoch 78/2000, Val Acc=0.6154, Val Loss=1.7528, lr=0.0100
[2025-05-07 04:32:29,024][train][INFO] - Epoch 79/2000, Val Acc=0.6202, Val Loss=1.7024, lr=0.0100
[2025-05-07 04:32:36,985][train][INFO] - Epoch 80/2000, Val Acc=0.6162, Val Loss=1.7325, lr=0.0100
[2025-05-07 04:32:45,189][train][INFO] - Epoch 81/2000, Val Acc=0.6128, Val Loss=1.7228, lr=0.0100
[2025-05-07 04:32:53,304][train][INFO] - Epoch 82/2000, Val Acc=0.6144, Val Loss=1.6909, lr=0.0100
[2025-05-07 04:33:01,383][train][INFO] - Epoch 83/2000, Val Acc=0.5992, Val Loss=1.8006, lr=0.0100
[2025-05-07 04:33:09,358][train][INFO] - Epoch 84/2000, Val Acc=0.6218, Val Loss=1.6624, lr=0.0100
[2025-05-07 04:33:17,074][train][INFO] - Epoch 85/2000, Val Acc=0.6167, Val Loss=1.7189, lr=0.0100
[2025-05-07 04:33:24,995][train][INFO] - Epoch 86/2000, Val Acc=0.5995, Val Loss=1.7727, lr=0.0100
[2025-05-07 04:33:32,987][train][INFO] - Epoch 87/2000, Val Acc=0.6241, Val Loss=1.7189, lr=0.0100
[2025-05-07 04:33:34,737][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-05-07 04:33:35,201][Visualize acc speed up curve][INFO] - End visualizing
[2025-05-07 04:33:40,270][train][INFO] - Epoch 88/2000, Val Acc=0.5916, Val Loss=1.9070, lr=0.0100
[2025-05-07 04:33:47,907][train][INFO] - Epoch 89/2000, Val Acc=0.6143, Val Loss=1.7029, lr=0.0100
[2025-05-07 04:33:55,601][train][INFO] - Epoch 90/2000, Val Acc=0.6203, Val Loss=1.7043, lr=0.0100
[2025-05-07 04:34:03,188][train][INFO] - Epoch 91/2000, Val Acc=0.5987, Val Loss=1.8363, lr=0.0100
[2025-05-07 04:34:10,753][train][INFO] - Epoch 92/2000, Val Acc=0.6197, Val Loss=1.7023, lr=0.0100
[2025-05-07 04:34:18,505][train][INFO] - Epoch 93/2000, Val Acc=0.6041, Val Loss=1.7673, lr=0.0100
[2025-05-07 04:34:26,027][train][INFO] - Epoch 94/2000, Val Acc=0.6091, Val Loss=1.7579, lr=0.0100
[2025-05-07 04:34:33,628][train][INFO] - Epoch 95/2000, Val Acc=0.6132, Val Loss=1.7142, lr=0.0100
[2025-05-07 04:34:41,268][train][INFO] - Epoch 96/2000, Val Acc=0.6115, Val Loss=1.7596, lr=0.0100
[2025-05-07 04:34:49,100][train][INFO] - Epoch 97/2000, Val Acc=0.5996, Val Loss=1.7592, lr=0.0100
[2025-05-07 04:34:56,452][train][INFO] - Epoch 98/2000, Val Acc=0.6246, Val Loss=1.6845, lr=0.0100
[2025-05-07 04:35:04,505][train][INFO] - Epoch 99/2000, Val Acc=0.6079, Val Loss=1.7756, lr=0.0100
[2025-05-07 04:35:11,521][train][INFO] - Epoch 100/2000, Val Acc=0.6076, Val Loss=1.7620, lr=0.0100
[2025-05-07 04:35:19,235][train][INFO] - Epoch 101/2000, Val Acc=0.6076, Val Loss=1.7731, lr=0.0100
[2025-05-07 04:35:26,765][train][INFO] - Epoch 102/2000, Val Acc=0.6200, Val Loss=1.6800, lr=0.0100
[2025-05-07 04:35:34,480][train][INFO] - Epoch 103/2000, Val Acc=0.5889, Val Loss=1.8708, lr=0.0100
[2025-05-07 04:35:42,248][train][INFO] - Epoch 104/2000, Val Acc=0.6014, Val Loss=1.7686, lr=0.0100
[2025-05-07 04:35:49,782][train][INFO] - Epoch 105/2000, Val Acc=0.6200, Val Loss=1.7101, lr=0.0100
[2025-05-07 04:35:58,036][train][INFO] - Epoch 106/2000, Val Acc=0.6060, Val Loss=1.8083, lr=0.0100
[2025-05-07 04:36:05,873][train][INFO] - Epoch 107/2000, Val Acc=0.5816, Val Loss=1.9643, lr=0.0100
[2025-05-07 04:36:13,312][train][INFO] - Epoch 108/2000, Val Acc=0.6134, Val Loss=1.7491, lr=0.0100
[2025-05-07 04:36:21,282][train][INFO] - Epoch 109/2000, Val Acc=0.6057, Val Loss=1.7908, lr=0.0100
[2025-05-07 04:36:28,817][train][INFO] - Epoch 110/2000, Val Acc=0.5981, Val Loss=1.8285, lr=0.0100
[2025-05-07 04:36:36,457][train][INFO] - Epoch 111/2000, Val Acc=0.5965, Val Loss=1.8369, lr=0.0100
[2025-05-07 04:36:44,209][train][INFO] - Epoch 112/2000, Val Acc=0.6138, Val Loss=1.7687, lr=0.0100
[2025-05-07 04:36:52,094][train][INFO] - Epoch 113/2000, Val Acc=0.6136, Val Loss=1.7226, lr=0.0100
[2025-05-07 04:36:59,803][train][INFO] - Epoch 114/2000, Val Acc=0.5977, Val Loss=1.8503, lr=0.0100
[2025-05-07 04:37:07,339][train][INFO] - Epoch 115/2000, Val Acc=0.6175, Val Loss=1.7199, lr=0.0100
[2025-05-07 04:37:14,930][train][INFO] - Epoch 116/2000, Val Acc=0.6087, Val Loss=1.7573, lr=0.0100
[2025-05-07 04:37:22,547][train][INFO] - Epoch 117/2000, Val Acc=0.6137, Val Loss=1.7403, lr=0.0100
[2025-05-07 04:37:29,908][train][INFO] - Epoch 118/2000, Val Acc=0.6098, Val Loss=1.7758, lr=0.0100
[2025-05-07 04:37:37,350][train][INFO] - Epoch 119/2000, Val Acc=0.6191, Val Loss=1.7079, lr=0.0100
[2025-05-07 04:37:45,246][train][INFO] - Epoch 120/2000, Val Acc=0.6302, Val Loss=1.6470, lr=0.0100
[2025-05-07 04:37:52,994][train][INFO] - Epoch 121/2000, Val Acc=0.6046, Val Loss=1.7390, lr=0.0100
[2025-05-07 04:38:00,825][train][INFO] - Epoch 122/2000, Val Acc=0.6135, Val Loss=1.7603, lr=0.0100
[2025-05-07 04:38:08,161][train][INFO] - Epoch 123/2000, Val Acc=0.6108, Val Loss=1.7615, lr=0.0100
[2025-05-07 04:38:15,232][train][INFO] - Epoch 124/2000, Val Acc=0.6091, Val Loss=1.7849, lr=0.0100
[2025-05-07 04:38:22,722][train][INFO] - Epoch 125/2000, Val Acc=0.6111, Val Loss=1.7741, lr=0.0100
[2025-05-07 04:38:30,332][train][INFO] - Epoch 126/2000, Val Acc=0.6155, Val Loss=1.7103, lr=0.0100
[2025-05-07 04:38:37,030][train][INFO] - Epoch 127/2000, Val Acc=0.6032, Val Loss=1.8667, lr=0.0100
[2025-05-07 04:38:44,529][train][INFO] - Epoch 128/2000, Val Acc=0.6069, Val Loss=1.7670, lr=0.0100
[2025-05-07 04:38:52,233][train][INFO] - Epoch 129/2000, Val Acc=0.6179, Val Loss=1.6967, lr=0.0100
[2025-05-07 04:38:59,738][train][INFO] - Epoch 130/2000, Val Acc=0.6020, Val Loss=1.7991, lr=0.0100
[2025-05-07 04:39:07,208][train][INFO] - Epoch 131/2000, Val Acc=0.5941, Val Loss=1.8985, lr=0.0100
[2025-05-07 04:39:14,401][train][INFO] - Epoch 132/2000, Val Acc=0.6166, Val Loss=1.7244, lr=0.0100
[2025-05-07 04:39:22,100][train][INFO] - Epoch 133/2000, Val Acc=0.6179, Val Loss=1.6839, lr=0.0100
[2025-05-07 04:39:29,642][train][INFO] - Epoch 134/2000, Val Acc=0.6053, Val Loss=1.7811, lr=0.0100
[2025-05-07 04:39:36,320][train][INFO] - Epoch 135/2000, Val Acc=0.6089, Val Loss=1.7669, lr=0.0100
[2025-05-07 04:39:44,230][train][INFO] - Epoch 136/2000, Val Acc=0.6186, Val Loss=1.6809, lr=0.0100
[2025-05-07 04:39:51,333][train][INFO] - Epoch 137/2000, Val Acc=0.6226, Val Loss=1.6924, lr=0.0100
[2025-05-07 04:39:58,501][train][INFO] - Epoch 138/2000, Val Acc=0.6045, Val Loss=1.8005, lr=0.0100
[2025-05-07 04:40:06,726][train][INFO] - Epoch 139/2000, Val Acc=0.6144, Val Loss=1.7756, lr=0.0100
[2025-05-07 04:40:15,006][train][INFO] - Epoch 140/2000, Val Acc=0.6104, Val Loss=1.7682, lr=0.0100
[2025-05-07 04:40:22,172][train][INFO] - Epoch 141/2000, Val Acc=0.5966, Val Loss=1.8238, lr=0.0100
[2025-05-07 04:40:29,584][train][INFO] - Epoch 142/2000, Val Acc=0.6137, Val Loss=1.7448, lr=0.0100
[2025-05-07 04:40:36,906][train][INFO] - Epoch 143/2000, Val Acc=0.6073, Val Loss=1.7588, lr=0.0100
[2025-05-07 04:40:44,510][train][INFO] - Epoch 144/2000, Val Acc=0.5834, Val Loss=1.9642, lr=0.0100
[2025-05-07 04:40:52,011][train][INFO] - Epoch 145/2000, Val Acc=0.6078, Val Loss=1.7760, lr=0.0100
[2025-05-07 04:40:59,799][train][INFO] - Epoch 146/2000, Val Acc=0.6103, Val Loss=1.7991, lr=0.0100
[2025-05-07 04:41:07,208][train][INFO] - Epoch 147/2000, Val Acc=0.6212, Val Loss=1.7157, lr=0.0100
[2025-05-07 04:41:14,908][train][INFO] - Epoch 148/2000, Val Acc=0.6128, Val Loss=1.7993, lr=0.0100
[2025-05-07 04:41:22,409][train][INFO] - Epoch 149/2000, Val Acc=0.6231, Val Loss=1.7088, lr=0.0100
[2025-05-07 04:41:30,020][train][INFO] - Epoch 150/2000, Val Acc=0.6103, Val Loss=1.7747, lr=0.0100
[2025-05-07 04:41:36,647][train][INFO] - Epoch 151/2000, Val Acc=0.6252, Val Loss=1.6735, lr=0.0100
[2025-05-07 04:41:43,489][train][INFO] - Epoch 152/2000, Val Acc=0.6126, Val Loss=1.7663, lr=0.0100
[2025-05-07 04:41:51,141][train][INFO] - Epoch 153/2000, Val Acc=0.6073, Val Loss=1.7605, lr=0.0100
[2025-05-07 04:41:58,564][train][INFO] - Epoch 154/2000, Val Acc=0.6191, Val Loss=1.7102, lr=0.0100
[2025-05-07 04:42:06,629][train][INFO] - Epoch 155/2000, Val Acc=0.6162, Val Loss=1.7437, lr=0.0100
[2025-05-07 04:42:14,289][train][INFO] - Epoch 156/2000, Val Acc=0.5676, Val Loss=2.0443, lr=0.0100
[2025-05-07 04:42:21,090][train][INFO] - Epoch 157/2000, Val Acc=0.6182, Val Loss=1.6946, lr=0.0100
[2025-05-07 04:42:29,282][train][INFO] - Epoch 158/2000, Val Acc=0.6017, Val Loss=1.8013, lr=0.0100
[2025-05-07 04:42:36,706][train][INFO] - Epoch 159/2000, Val Acc=0.6064, Val Loss=1.7765, lr=0.0100
[2025-05-07 04:42:44,547][train][INFO] - Epoch 160/2000, Val Acc=0.6026, Val Loss=1.8051, lr=0.0100
[2025-05-07 04:42:52,578][train][INFO] - Epoch 161/2000, Val Acc=0.6078, Val Loss=1.7467, lr=0.0100
[2025-05-07 04:42:59,581][train][INFO] - Epoch 162/2000, Val Acc=0.6187, Val Loss=1.7047, lr=0.0100
[2025-05-07 04:43:07,307][train][INFO] - Epoch 163/2000, Val Acc=0.5973, Val Loss=1.8442, lr=0.0100
[2025-05-07 04:43:15,187][train][INFO] - Epoch 164/2000, Val Acc=0.6141, Val Loss=1.7119, lr=0.0100
[2025-05-07 04:43:22,975][train][INFO] - Epoch 165/2000, Val Acc=0.6117, Val Loss=1.7637, lr=0.0100
[2025-05-07 04:43:31,130][train][INFO] - Epoch 166/2000, Val Acc=0.6166, Val Loss=1.7327, lr=0.0100
[2025-05-07 04:43:39,041][train][INFO] - Epoch 167/2000, Val Acc=0.6149, Val Loss=1.7323, lr=0.0100
[2025-05-07 04:43:46,465][train][INFO] - Epoch 168/2000, Val Acc=0.6188, Val Loss=1.6998, lr=0.0100
[2025-05-07 04:43:54,334][train][INFO] - Epoch 169/2000, Val Acc=0.6194, Val Loss=1.7176, lr=0.0100
[2025-05-07 04:44:01,858][train][INFO] - Epoch 170/2000, Val Acc=0.6025, Val Loss=1.7569, lr=0.0100
[2025-05-07 04:44:09,721][train][INFO] - Epoch 171/2000, Val Acc=0.6202, Val Loss=1.6987, lr=0.0100
[2025-05-07 04:44:17,502][train][INFO] - Epoch 172/2000, Val Acc=0.6112, Val Loss=1.7637, lr=0.0100
[2025-05-07 04:44:25,816][train][INFO] - Epoch 173/2000, Val Acc=0.6257, Val Loss=1.6728, lr=0.0100
[2025-05-07 04:44:33,674][train][INFO] - Epoch 174/2000, Val Acc=0.6109, Val Loss=1.7529, lr=0.0100
[2025-05-07 04:44:41,300][train][INFO] - Epoch 175/2000, Val Acc=0.6093, Val Loss=1.7641, lr=0.0100
[2025-05-07 04:44:48,583][train][INFO] - Epoch 176/2000, Val Acc=0.6103, Val Loss=1.7673, lr=0.0100
[2025-05-07 04:44:56,129][train][INFO] - Epoch 177/2000, Val Acc=0.6148, Val Loss=1.7145, lr=0.0100
[2025-05-07 04:45:03,842][train][INFO] - Epoch 178/2000, Val Acc=0.5975, Val Loss=1.8460, lr=0.0100
[2025-05-07 04:45:11,672][train][INFO] - Epoch 179/2000, Val Acc=0.6256, Val Loss=1.6638, lr=0.0100
[2025-05-07 04:45:19,679][train][INFO] - Epoch 180/2000, Val Acc=0.6142, Val Loss=1.7504, lr=0.0100
[2025-05-07 04:45:27,242][train][INFO] - Epoch 181/2000, Val Acc=0.5970, Val Loss=1.8526, lr=0.0100
[2025-05-07 04:45:35,224][train][INFO] - Epoch 182/2000, Val Acc=0.6132, Val Loss=1.7467, lr=0.0100
[2025-05-07 04:45:43,111][train][INFO] - Epoch 183/2000, Val Acc=0.6005, Val Loss=1.7722, lr=0.0100
[2025-05-07 04:45:50,405][train][INFO] - Epoch 184/2000, Val Acc=0.6098, Val Loss=1.7671, lr=0.0100
[2025-05-07 04:45:58,192][train][INFO] - Epoch 185/2000, Val Acc=0.6230, Val Loss=1.6558, lr=0.0100
[2025-05-07 04:46:05,898][train][INFO] - Epoch 186/2000, Val Acc=0.6070, Val Loss=1.8188, lr=0.0100
[2025-05-07 04:46:13,355][train][INFO] - Epoch 187/2000, Val Acc=0.6003, Val Loss=1.7894, lr=0.0100
[2025-05-07 04:46:21,567][train][INFO] - Epoch 188/2000, Val Acc=0.6105, Val Loss=1.7279, lr=0.0100
[2025-05-07 04:46:29,145][train][INFO] - Epoch 189/2000, Val Acc=0.5989, Val Loss=1.7965, lr=0.0100
[2025-05-07 04:46:36,869][train][INFO] - Epoch 190/2000, Val Acc=0.6031, Val Loss=1.8209, lr=0.0100
[2025-05-07 04:46:44,990][train][INFO] - Epoch 191/2000, Val Acc=0.6098, Val Loss=1.7804, lr=0.0100
[2025-05-07 04:46:52,917][train][INFO] - Epoch 192/2000, Val Acc=0.6138, Val Loss=1.7679, lr=0.0100
[2025-05-07 04:47:00,585][train][INFO] - Epoch 193/2000, Val Acc=0.6117, Val Loss=1.7791, lr=0.0100
[2025-05-07 04:47:08,428][train][INFO] - Epoch 194/2000, Val Acc=0.6088, Val Loss=1.7851, lr=0.0100
[2025-05-07 04:47:15,527][train][INFO] - Epoch 195/2000, Val Acc=0.5937, Val Loss=1.8724, lr=0.0100
[2025-05-07 04:47:23,602][train][INFO] - Epoch 196/2000, Val Acc=0.6173, Val Loss=1.7402, lr=0.0100
[2025-05-07 04:47:32,000][train][INFO] - Epoch 197/2000, Val Acc=0.6226, Val Loss=1.7100, lr=0.0100
[2025-05-07 04:47:39,106][train][INFO] - Epoch 198/2000, Val Acc=0.6039, Val Loss=1.7876, lr=0.0100
[2025-05-07 04:47:46,698][train][INFO] - Epoch 199/2000, Val Acc=0.6107, Val Loss=1.7616, lr=0.0100
[2025-05-07 04:47:53,946][train][INFO] - Epoch 200/2000, Val Acc=0.6169, Val Loss=1.7437, lr=0.0100
[2025-05-07 04:48:01,435][train][INFO] - Epoch 201/2000, Val Acc=0.6204, Val Loss=1.7591, lr=0.0100
[2025-05-07 04:48:09,002][train][INFO] - Epoch 202/2000, Val Acc=0.6089, Val Loss=1.7861, lr=0.0100
[2025-05-07 04:48:16,095][train][INFO] - Epoch 203/2000, Val Acc=0.6109, Val Loss=1.8242, lr=0.0100
[2025-05-07 04:48:23,616][train][INFO] - Epoch 204/2000, Val Acc=0.6192, Val Loss=1.6825, lr=0.0100
[2025-05-07 04:48:31,567][train][INFO] - Epoch 205/2000, Val Acc=0.5970, Val Loss=1.8330, lr=0.0100
[2025-05-07 04:48:39,540][train][INFO] - Epoch 206/2000, Val Acc=0.6231, Val Loss=1.7217, lr=0.0100
[2025-05-07 04:48:46,730][train][INFO] - Epoch 207/2000, Val Acc=0.5955, Val Loss=1.8757, lr=0.0100
[2025-05-07 04:48:54,342][train][INFO] - Epoch 208/2000, Val Acc=0.6177, Val Loss=1.7747, lr=0.0100
[2025-05-07 04:49:01,873][train][INFO] - Epoch 209/2000, Val Acc=0.6136, Val Loss=1.7282, lr=0.0100
[2025-05-07 04:49:09,213][train][INFO] - Epoch 210/2000, Val Acc=0.6130, Val Loss=1.7236, lr=0.0100
[2025-05-07 04:49:16,847][train][INFO] - Epoch 211/2000, Val Acc=0.6000, Val Loss=1.8009, lr=0.0100
[2025-05-07 04:49:24,769][train][INFO] - Epoch 212/2000, Val Acc=0.5953, Val Loss=1.8407, lr=0.0100
[2025-05-07 04:49:32,443][train][INFO] - Epoch 213/2000, Val Acc=0.6175, Val Loss=1.7038, lr=0.0100
[2025-05-07 04:49:40,302][train][INFO] - Epoch 214/2000, Val Acc=0.6128, Val Loss=1.7449, lr=0.0100
[2025-05-07 04:49:48,282][train][INFO] - Epoch 215/2000, Val Acc=0.6035, Val Loss=1.7826, lr=0.0100
[2025-05-07 04:49:56,172][train][INFO] - Epoch 216/2000, Val Acc=0.5975, Val Loss=1.9021, lr=0.0100
[2025-05-07 04:50:03,620][train][INFO] - Epoch 217/2000, Val Acc=0.6083, Val Loss=1.7529, lr=0.0100
[2025-05-07 04:50:11,464][train][INFO] - Epoch 218/2000, Val Acc=0.5839, Val Loss=1.9013, lr=0.0100
[2025-05-07 04:50:18,962][train][INFO] - Epoch 219/2000, Val Acc=0.6093, Val Loss=1.7692, lr=0.0100
[2025-05-07 04:50:27,068][train][INFO] - Epoch 220/2000, Val Acc=0.6128, Val Loss=1.7691, lr=0.0100
[2025-05-07 04:50:34,299][train][INFO] - Epoch 221/2000, Val Acc=0.6042, Val Loss=1.8005, lr=0.0100
[2025-05-07 04:50:41,631][train][INFO] - Epoch 222/2000, Val Acc=0.6050, Val Loss=1.8091, lr=0.0100
[2025-05-07 04:50:49,821][train][INFO] - Epoch 223/2000, Val Acc=0.6216, Val Loss=1.7199, lr=0.0100
[2025-05-07 04:50:56,840][train][INFO] - Epoch 224/2000, Val Acc=0.6170, Val Loss=1.7104, lr=0.0100
[2025-05-07 04:51:04,716][train][INFO] - Epoch 225/2000, Val Acc=0.6121, Val Loss=1.7707, lr=0.0100
[2025-05-07 04:51:12,372][train][INFO] - Epoch 226/2000, Val Acc=0.6175, Val Loss=1.7278, lr=0.0100
[2025-05-07 04:51:20,510][train][INFO] - Epoch 227/2000, Val Acc=0.6088, Val Loss=1.7844, lr=0.0100
[2025-05-07 04:51:28,055][train][INFO] - Epoch 228/2000, Val Acc=0.6117, Val Loss=1.7814, lr=0.0100
[2025-05-07 04:51:35,698][train][INFO] - Epoch 229/2000, Val Acc=0.6044, Val Loss=1.7977, lr=0.0100
[2025-05-07 04:51:42,836][train][INFO] - Epoch 230/2000, Val Acc=0.5998, Val Loss=1.8558, lr=0.0100
[2025-05-07 04:51:50,119][train][INFO] - Epoch 231/2000, Val Acc=0.6244, Val Loss=1.7130, lr=0.0100
[2025-05-07 04:51:57,792][train][INFO] - Epoch 232/2000, Val Acc=0.5888, Val Loss=1.8947, lr=0.0100
[2025-05-07 04:52:05,333][train][INFO] - Epoch 233/2000, Val Acc=0.5829, Val Loss=1.9365, lr=0.0100
[2025-05-07 04:52:13,366][train][INFO] - Epoch 234/2000, Val Acc=0.5979, Val Loss=1.8085, lr=0.0100
[2025-05-07 04:52:20,985][train][INFO] - Epoch 235/2000, Val Acc=0.6049, Val Loss=1.7807, lr=0.0100
[2025-05-07 04:52:28,906][train][INFO] - Epoch 236/2000, Val Acc=0.6181, Val Loss=1.6848, lr=0.0100
[2025-05-07 04:52:36,550][train][INFO] - Epoch 237/2000, Val Acc=0.5989, Val Loss=1.8793, lr=0.0100
[2025-05-07 04:52:44,662][train][INFO] - Epoch 238/2000, Val Acc=0.6133, Val Loss=1.7601, lr=0.0100
[2025-05-07 04:52:52,118][train][INFO] - Epoch 239/2000, Val Acc=0.6063, Val Loss=1.7561, lr=0.0100
[2025-05-07 04:52:59,695][train][INFO] - Epoch 240/2000, Val Acc=0.6298, Val Loss=1.6113, lr=0.0100
[2025-05-07 04:53:07,213][train][INFO] - Epoch 241/2000, Val Acc=0.6218, Val Loss=1.7216, lr=0.0100
[2025-05-07 04:53:15,362][train][INFO] - Epoch 242/2000, Val Acc=0.6029, Val Loss=1.7936, lr=0.0100
[2025-05-07 04:53:22,802][train][INFO] - Epoch 243/2000, Val Acc=0.6038, Val Loss=1.8578, lr=0.0100
[2025-05-07 04:53:30,041][train][INFO] - Epoch 244/2000, Val Acc=0.6221, Val Loss=1.6817, lr=0.0100
[2025-05-07 04:53:37,544][train][INFO] - Epoch 245/2000, Val Acc=0.6070, Val Loss=1.7650, lr=0.0100
[2025-05-07 04:53:45,646][train][INFO] - Epoch 246/2000, Val Acc=0.6121, Val Loss=1.7213, lr=0.0100
[2025-05-07 04:53:53,443][train][INFO] - Epoch 247/2000, Val Acc=0.6117, Val Loss=1.7510, lr=0.0100
[2025-05-07 04:54:00,829][train][INFO] - Epoch 248/2000, Val Acc=0.6011, Val Loss=1.8259, lr=0.0100
[2025-05-07 04:54:08,132][train][INFO] - Epoch 249/2000, Val Acc=0.6240, Val Loss=1.6769, lr=0.0100
[2025-05-07 04:54:15,778][train][INFO] - Epoch 250/2000, Val Acc=0.6296, Val Loss=1.6840, lr=0.0100
[2025-05-07 04:54:23,501][train][INFO] - Epoch 251/2000, Val Acc=0.6131, Val Loss=1.7578, lr=0.0100
[2025-05-07 04:54:30,622][train][INFO] - Epoch 252/2000, Val Acc=0.6199, Val Loss=1.7187, lr=0.0100
[2025-05-07 04:54:37,328][train][INFO] - Epoch 253/2000, Val Acc=0.6066, Val Loss=1.7918, lr=0.0100
[2025-05-07 04:54:44,672][train][INFO] - Epoch 254/2000, Val Acc=0.6103, Val Loss=1.7875, lr=0.0100
[2025-05-07 04:54:52,053][train][INFO] - Epoch 255/2000, Val Acc=0.6031, Val Loss=1.7941, lr=0.0100
[2025-05-07 04:54:59,407][train][INFO] - Epoch 256/2000, Val Acc=0.6002, Val Loss=1.8358, lr=0.0100
[2025-05-07 04:55:07,111][train][INFO] - Epoch 257/2000, Val Acc=0.6050, Val Loss=1.8292, lr=0.0100
[2025-05-07 04:55:14,465][train][INFO] - Epoch 258/2000, Val Acc=0.6123, Val Loss=1.7557, lr=0.0100
[2025-05-07 04:55:22,422][train][INFO] - Epoch 259/2000, Val Acc=0.6137, Val Loss=1.7401, lr=0.0100
[2025-05-07 04:55:30,616][train][INFO] - Epoch 260/2000, Val Acc=0.6085, Val Loss=1.7682, lr=0.0100
[2025-05-07 04:55:39,160][train][INFO] - Epoch 261/2000, Val Acc=0.6251, Val Loss=1.7095, lr=0.0100
[2025-05-07 04:55:46,970][train][INFO] - Epoch 262/2000, Val Acc=0.6007, Val Loss=1.8459, lr=0.0100
[2025-05-07 04:55:55,002][train][INFO] - Epoch 263/2000, Val Acc=0.6131, Val Loss=1.7325, lr=0.0100
[2025-05-07 04:56:03,327][train][INFO] - Epoch 264/2000, Val Acc=0.6160, Val Loss=1.7189, lr=0.0100
[2025-05-07 04:56:11,732][train][INFO] - Epoch 265/2000, Val Acc=0.6203, Val Loss=1.7134, lr=0.0100
[2025-05-07 04:56:19,601][train][INFO] - Epoch 266/2000, Val Acc=0.6003, Val Loss=1.7904, lr=0.0100
[2025-05-07 04:56:28,203][train][INFO] - Epoch 267/2000, Val Acc=0.6116, Val Loss=1.7013, lr=0.0100
[2025-05-07 04:56:35,997][train][INFO] - Epoch 268/2000, Val Acc=0.5963, Val Loss=1.8809, lr=0.0100
[2025-05-07 04:56:44,359][train][INFO] - Epoch 269/2000, Val Acc=0.6189, Val Loss=1.7285, lr=0.0100
[2025-05-07 04:56:51,947][train][INFO] - Epoch 270/2000, Val Acc=0.6016, Val Loss=1.7888, lr=0.0100
[2025-05-07 04:56:59,626][train][INFO] - Epoch 271/2000, Val Acc=0.6097, Val Loss=1.7513, lr=0.0100
[2025-05-07 04:57:07,783][train][INFO] - Epoch 272/2000, Val Acc=0.6131, Val Loss=1.7498, lr=0.0100
[2025-05-07 04:57:16,332][train][INFO] - Epoch 273/2000, Val Acc=0.6121, Val Loss=1.7518, lr=0.0100
[2025-05-07 04:57:24,719][train][INFO] - Epoch 274/2000, Val Acc=0.6223, Val Loss=1.6877, lr=0.0100
[2025-05-07 04:57:33,232][train][INFO] - Epoch 275/2000, Val Acc=0.6025, Val Loss=1.8178, lr=0.0100
[2025-05-07 04:57:41,422][train][INFO] - Epoch 276/2000, Val Acc=0.5975, Val Loss=1.8410, lr=0.0100
[2025-05-07 04:57:49,356][train][INFO] - Epoch 277/2000, Val Acc=0.6097, Val Loss=1.8118, lr=0.0100
[2025-05-07 04:57:56,522][train][INFO] - Epoch 278/2000, Val Acc=0.6001, Val Loss=1.8338, lr=0.0100
[2025-05-07 04:58:03,740][train][INFO] - Epoch 279/2000, Val Acc=0.6145, Val Loss=1.7486, lr=0.0100
[2025-05-07 04:58:11,233][train][INFO] - Epoch 280/2000, Val Acc=0.6215, Val Loss=1.7534, lr=0.0100
[2025-05-07 04:58:18,354][train][INFO] - Epoch 281/2000, Val Acc=0.6071, Val Loss=1.7750, lr=0.0100
[2025-05-07 04:58:26,451][train][INFO] - Epoch 282/2000, Val Acc=0.5951, Val Loss=1.8705, lr=0.0100
[2025-05-07 04:58:34,160][train][INFO] - Epoch 283/2000, Val Acc=0.6081, Val Loss=1.8137, lr=0.0100
[2025-05-07 04:58:42,093][train][INFO] - Epoch 284/2000, Val Acc=0.6026, Val Loss=1.8046, lr=0.0100
[2025-05-07 04:58:49,688][train][INFO] - Epoch 285/2000, Val Acc=0.6102, Val Loss=1.7653, lr=0.0100
[2025-05-07 04:58:57,547][train][INFO] - Epoch 286/2000, Val Acc=0.6069, Val Loss=1.7493, lr=0.0100
[2025-05-07 04:59:05,504][train][INFO] - Epoch 287/2000, Val Acc=0.6193, Val Loss=1.6957, lr=0.0100
[2025-05-07 04:59:12,957][train][INFO] - Epoch 288/2000, Val Acc=0.6033, Val Loss=1.8096, lr=0.0100
[2025-05-07 04:59:20,508][train][INFO] - Epoch 289/2000, Val Acc=0.6136, Val Loss=1.7480, lr=0.0100
[2025-05-07 04:59:28,766][train][INFO] - Epoch 290/2000, Val Acc=0.6039, Val Loss=1.7523, lr=0.0100
[2025-05-07 04:59:36,172][train][INFO] - Epoch 291/2000, Val Acc=0.6279, Val Loss=1.6646, lr=0.0100
[2025-05-07 04:59:43,544][train][INFO] - Epoch 292/2000, Val Acc=0.6144, Val Loss=1.7400, lr=0.0100
[2025-05-07 04:59:51,108][train][INFO] - Epoch 293/2000, Val Acc=0.6114, Val Loss=1.7688, lr=0.0100
[2025-05-07 04:59:58,342][train][INFO] - Epoch 294/2000, Val Acc=0.6150, Val Loss=1.7948, lr=0.0100
[2025-05-07 05:00:06,255][train][INFO] - Epoch 295/2000, Val Acc=0.6035, Val Loss=1.7915, lr=0.0100
[2025-05-07 05:00:13,854][train][INFO] - Epoch 296/2000, Val Acc=0.6151, Val Loss=1.7353, lr=0.0100
[2025-05-07 05:00:21,273][train][INFO] - Epoch 297/2000, Val Acc=0.5859, Val Loss=1.8737, lr=0.0100
[2025-05-07 05:00:29,452][train][INFO] - Epoch 298/2000, Val Acc=0.5804, Val Loss=2.0144, lr=0.0100
[2025-05-07 05:00:37,092][train][INFO] - Epoch 299/2000, Val Acc=0.6030, Val Loss=1.7721, lr=0.0100
[2025-05-07 05:00:45,061][train][INFO] - Epoch 300/2000, Val Acc=0.6165, Val Loss=1.7602, lr=0.0100
[2025-05-07 05:00:52,751][train][INFO] - Epoch 301/2000, Val Acc=0.6158, Val Loss=1.7514, lr=0.0100
[2025-05-07 05:01:00,713][train][INFO] - Epoch 302/2000, Val Acc=0.6197, Val Loss=1.7250, lr=0.0100
[2025-05-07 05:01:08,406][train][INFO] - Epoch 303/2000, Val Acc=0.6192, Val Loss=1.7238, lr=0.0100
[2025-05-07 05:01:15,786][train][INFO] - Epoch 304/2000, Val Acc=0.5712, Val Loss=2.0577, lr=0.0100
[2025-05-07 05:01:23,715][train][INFO] - Epoch 305/2000, Val Acc=0.6062, Val Loss=1.7644, lr=0.0100
[2025-05-07 05:01:31,295][train][INFO] - Epoch 306/2000, Val Acc=0.6058, Val Loss=1.8295, lr=0.0100
[2025-05-07 05:01:39,373][train][INFO] - Epoch 307/2000, Val Acc=0.6138, Val Loss=1.7107, lr=0.0100
[2025-05-07 05:01:47,327][train][INFO] - Epoch 308/2000, Val Acc=0.6288, Val Loss=1.6630, lr=0.0100
[2025-05-07 05:01:55,836][train][INFO] - Epoch 309/2000, Val Acc=0.6124, Val Loss=1.7669, lr=0.0100
[2025-05-07 05:02:03,461][train][INFO] - Epoch 310/2000, Val Acc=0.6259, Val Loss=1.7012, lr=0.0100
[2025-05-07 05:02:11,834][train][INFO] - Epoch 311/2000, Val Acc=0.6212, Val Loss=1.6940, lr=0.0100
[2025-05-07 05:02:19,558][train][INFO] - Epoch 312/2000, Val Acc=0.6146, Val Loss=1.7038, lr=0.0100
[2025-05-07 05:02:26,832][train][INFO] - Epoch 313/2000, Val Acc=0.6146, Val Loss=1.7603, lr=0.0100
[2025-05-07 05:02:35,132][train][INFO] - Epoch 314/2000, Val Acc=0.6112, Val Loss=1.7747, lr=0.0100
[2025-05-07 05:02:42,357][train][INFO] - Epoch 315/2000, Val Acc=0.6200, Val Loss=1.7182, lr=0.0100
[2025-05-07 05:02:49,866][train][INFO] - Epoch 316/2000, Val Acc=0.6136, Val Loss=1.7423, lr=0.0100
[2025-05-07 05:02:57,643][train][INFO] - Epoch 317/2000, Val Acc=0.6029, Val Loss=1.8504, lr=0.0100
[2025-05-07 05:03:05,471][train][INFO] - Epoch 318/2000, Val Acc=0.6078, Val Loss=1.8242, lr=0.0100
[2025-05-07 05:03:13,811][train][INFO] - Epoch 319/2000, Val Acc=0.6139, Val Loss=1.7698, lr=0.0100
[2025-05-07 05:03:20,835][train][INFO] - Epoch 320/2000, Val Acc=0.6032, Val Loss=1.8182, lr=0.0100
[2025-05-07 05:03:27,254][train][INFO] - Epoch 321/2000, Val Acc=0.6131, Val Loss=1.7101, lr=0.0100
[2025-05-07 05:03:35,200][train][INFO] - Epoch 322/2000, Val Acc=0.6195, Val Loss=1.6716, lr=0.0100
[2025-05-07 05:03:42,487][train][INFO] - Epoch 323/2000, Val Acc=0.6046, Val Loss=1.7875, lr=0.0100
[2025-05-07 05:03:50,012][train][INFO] - Epoch 324/2000, Val Acc=0.6188, Val Loss=1.6921, lr=0.0100
[2025-05-07 05:03:57,266][train][INFO] - Epoch 325/2000, Val Acc=0.6176, Val Loss=1.7036, lr=0.0100
[2025-05-07 05:04:04,845][train][INFO] - Epoch 326/2000, Val Acc=0.6152, Val Loss=1.7092, lr=0.0100
[2025-05-07 05:04:12,509][train][INFO] - Epoch 327/2000, Val Acc=0.6137, Val Loss=1.7365, lr=0.0100
[2025-05-07 05:04:20,232][train][INFO] - Epoch 328/2000, Val Acc=0.6014, Val Loss=1.8051, lr=0.0100
[2025-05-07 05:04:27,931][train][INFO] - Epoch 329/2000, Val Acc=0.6150, Val Loss=1.7460, lr=0.0100
[2025-05-07 05:04:35,583][train][INFO] - Epoch 330/2000, Val Acc=0.6035, Val Loss=1.8553, lr=0.0100
[2025-05-07 05:04:43,411][train][INFO] - Epoch 331/2000, Val Acc=0.5938, Val Loss=1.8772, lr=0.0100
[2025-05-07 05:04:51,120][train][INFO] - Epoch 332/2000, Val Acc=0.6288, Val Loss=1.6468, lr=0.0100
[2025-05-07 05:04:58,515][train][INFO] - Epoch 333/2000, Val Acc=0.6177, Val Loss=1.7472, lr=0.0100
[2025-05-07 05:05:05,633][train][INFO] - Epoch 334/2000, Val Acc=0.6113, Val Loss=1.7802, lr=0.0100
[2025-05-07 05:05:13,168][train][INFO] - Epoch 335/2000, Val Acc=0.6094, Val Loss=1.7644, lr=0.0100
[2025-05-07 05:05:21,326][train][INFO] - Epoch 336/2000, Val Acc=0.6251, Val Loss=1.6793, lr=0.0100
[2025-05-07 05:05:29,081][train][INFO] - Epoch 337/2000, Val Acc=0.6172, Val Loss=1.7351, lr=0.0100
[2025-05-07 05:05:36,428][train][INFO] - Epoch 338/2000, Val Acc=0.6040, Val Loss=1.8567, lr=0.0100
[2025-05-07 05:05:44,299][train][INFO] - Epoch 339/2000, Val Acc=0.6225, Val Loss=1.6889, lr=0.0100
[2025-05-07 05:05:51,730][train][INFO] - Epoch 340/2000, Val Acc=0.6172, Val Loss=1.7508, lr=0.0100
[2025-05-07 05:05:59,656][train][INFO] - Epoch 341/2000, Val Acc=0.6229, Val Loss=1.6792, lr=0.0100
[2025-05-07 05:06:07,265][train][INFO] - Epoch 342/2000, Val Acc=0.6035, Val Loss=1.8266, lr=0.0100
[2025-05-07 05:06:15,187][train][INFO] - Epoch 343/2000, Val Acc=0.6045, Val Loss=1.7608, lr=0.0100
[2025-05-07 05:06:23,040][train][INFO] - Epoch 344/2000, Val Acc=0.6042, Val Loss=1.7712, lr=0.0100
[2025-05-07 05:06:30,764][train][INFO] - Epoch 345/2000, Val Acc=0.5919, Val Loss=1.8671, lr=0.0100
[2025-05-07 05:06:38,400][train][INFO] - Epoch 346/2000, Val Acc=0.6179, Val Loss=1.7447, lr=0.0100
[2025-05-07 05:06:45,764][train][INFO] - Epoch 347/2000, Val Acc=0.5996, Val Loss=1.8380, lr=0.0100
[2025-05-07 05:06:53,518][train][INFO] - Epoch 348/2000, Val Acc=0.5989, Val Loss=1.8117, lr=0.0100
[2025-05-07 05:07:00,884][train][INFO] - Epoch 349/2000, Val Acc=0.5931, Val Loss=1.8694, lr=0.0100
[2025-05-07 05:07:08,630][train][INFO] - Epoch 350/2000, Val Acc=0.6081, Val Loss=1.7525, lr=0.0100
[2025-05-07 05:07:16,743][train][INFO] - Epoch 351/2000, Val Acc=0.6197, Val Loss=1.7160, lr=0.0100
[2025-05-07 05:07:24,615][train][INFO] - Epoch 352/2000, Val Acc=0.6162, Val Loss=1.7305, lr=0.0100
[2025-05-07 05:07:32,366][train][INFO] - Epoch 353/2000, Val Acc=0.6159, Val Loss=1.7212, lr=0.0100
[2025-05-07 05:07:40,472][train][INFO] - Epoch 354/2000, Val Acc=0.5980, Val Loss=1.8404, lr=0.0100
[2025-05-07 05:07:48,122][train][INFO] - Epoch 355/2000, Val Acc=0.6048, Val Loss=1.8024, lr=0.0100
[2025-05-07 05:07:55,654][train][INFO] - Epoch 356/2000, Val Acc=0.6051, Val Loss=1.8326, lr=0.0100
[2025-05-07 05:08:03,227][train][INFO] - Epoch 357/2000, Val Acc=0.5998, Val Loss=1.7904, lr=0.0100
[2025-05-07 05:08:11,290][train][INFO] - Epoch 358/2000, Val Acc=0.6124, Val Loss=1.7622, lr=0.0100
[2025-05-07 05:08:18,765][train][INFO] - Epoch 359/2000, Val Acc=0.5913, Val Loss=1.8822, lr=0.0100
[2025-05-07 05:08:26,693][train][INFO] - Epoch 360/2000, Val Acc=0.6054, Val Loss=1.8230, lr=0.0100
[2025-05-07 05:08:33,719][train][INFO] - Epoch 361/2000, Val Acc=0.6224, Val Loss=1.6817, lr=0.0100
[2025-05-07 05:08:41,279][train][INFO] - Epoch 362/2000, Val Acc=0.5927, Val Loss=1.9161, lr=0.0100
[2025-05-07 05:08:49,571][train][INFO] - Epoch 363/2000, Val Acc=0.6023, Val Loss=1.8206, lr=0.0100
[2025-05-07 05:08:56,718][train][INFO] - Epoch 364/2000, Val Acc=0.6026, Val Loss=1.8325, lr=0.0100
[2025-05-07 05:09:04,034][train][INFO] - Epoch 365/2000, Val Acc=0.6082, Val Loss=1.7899, lr=0.0100
[2025-05-07 05:09:11,865][train][INFO] - Epoch 366/2000, Val Acc=0.6172, Val Loss=1.7169, lr=0.0100
[2025-05-07 05:09:20,353][train][INFO] - Epoch 367/2000, Val Acc=0.6204, Val Loss=1.7115, lr=0.0100
[2025-05-07 05:09:29,138][train][INFO] - Epoch 368/2000, Val Acc=0.6184, Val Loss=1.7295, lr=0.0100
[2025-05-07 05:09:37,275][train][INFO] - Epoch 369/2000, Val Acc=0.6061, Val Loss=1.7850, lr=0.0100
[2025-05-07 05:09:45,578][train][INFO] - Epoch 370/2000, Val Acc=0.6117, Val Loss=1.7241, lr=0.0100
[2025-05-07 05:09:54,092][train][INFO] - Epoch 371/2000, Val Acc=0.5846, Val Loss=1.9536, lr=0.0100
[2025-05-07 05:10:01,534][train][INFO] - Epoch 372/2000, Val Acc=0.6144, Val Loss=1.7318, lr=0.0100
[2025-05-07 05:10:09,286][train][INFO] - Epoch 373/2000, Val Acc=0.6263, Val Loss=1.7310, lr=0.0100
[2025-05-07 05:10:17,243][train][INFO] - Epoch 374/2000, Val Acc=0.6250, Val Loss=1.6704, lr=0.0100
[2025-05-07 05:10:24,893][train][INFO] - Epoch 375/2000, Val Acc=0.6228, Val Loss=1.6804, lr=0.0100
[2025-05-07 05:10:32,532][train][INFO] - Epoch 376/2000, Val Acc=0.6203, Val Loss=1.7283, lr=0.0100
[2025-05-07 05:10:40,200][train][INFO] - Epoch 377/2000, Val Acc=0.6141, Val Loss=1.6897, lr=0.0100
[2025-05-07 05:10:48,263][train][INFO] - Epoch 378/2000, Val Acc=0.6138, Val Loss=1.7686, lr=0.0100
[2025-05-07 05:10:55,891][train][INFO] - Epoch 379/2000, Val Acc=0.6131, Val Loss=1.7437, lr=0.0100
[2025-05-07 05:11:03,351][train][INFO] - Epoch 380/2000, Val Acc=0.6033, Val Loss=1.7904, lr=0.0100
[2025-05-07 05:11:10,918][train][INFO] - Epoch 381/2000, Val Acc=0.5956, Val Loss=1.8445, lr=0.0100
[2025-05-07 05:11:18,009][train][INFO] - Epoch 382/2000, Val Acc=0.6245, Val Loss=1.6549, lr=0.0100
[2025-05-07 05:11:25,798][train][INFO] - Epoch 383/2000, Val Acc=0.6043, Val Loss=1.8394, lr=0.0100
[2025-05-07 05:11:33,887][train][INFO] - Epoch 384/2000, Val Acc=0.5989, Val Loss=1.8304, lr=0.0100
[2025-05-07 05:11:41,884][train][INFO] - Epoch 385/2000, Val Acc=0.6244, Val Loss=1.6961, lr=0.0100
[2025-05-07 05:11:49,240][train][INFO] - Epoch 386/2000, Val Acc=0.6105, Val Loss=1.7732, lr=0.0100
[2025-05-07 05:11:56,887][train][INFO] - Epoch 387/2000, Val Acc=0.6086, Val Loss=1.7832, lr=0.0100
[2025-05-07 05:12:04,796][train][INFO] - Epoch 388/2000, Val Acc=0.6158, Val Loss=1.7177, lr=0.0100
[2025-05-07 05:12:12,794][train][INFO] - Epoch 389/2000, Val Acc=0.6120, Val Loss=1.7735, lr=0.0100
[2025-05-07 05:12:20,216][train][INFO] - Epoch 390/2000, Val Acc=0.6170, Val Loss=1.7304, lr=0.0100
[2025-05-07 05:12:28,029][train][INFO] - Epoch 391/2000, Val Acc=0.6050, Val Loss=1.8299, lr=0.0100
[2025-05-07 05:12:35,079][train][INFO] - Epoch 392/2000, Val Acc=0.6183, Val Loss=1.7262, lr=0.0100
[2025-05-07 05:12:42,492][train][INFO] - Epoch 393/2000, Val Acc=0.6044, Val Loss=1.8491, lr=0.0100
[2025-05-07 05:12:50,384][train][INFO] - Epoch 394/2000, Val Acc=0.6155, Val Loss=1.7346, lr=0.0100
[2025-05-07 05:12:56,732][train][INFO] - Epoch 395/2000, Val Acc=0.5989, Val Loss=1.8420, lr=0.0100
[2025-05-07 05:13:05,029][train][INFO] - Epoch 396/2000, Val Acc=0.6108, Val Loss=1.7287, lr=0.0100
[2025-05-07 05:13:13,396][train][INFO] - Epoch 397/2000, Val Acc=0.6134, Val Loss=1.7804, lr=0.0100
[2025-05-07 05:13:21,393][train][INFO] - Epoch 398/2000, Val Acc=0.6068, Val Loss=1.8138, lr=0.0100
[2025-05-07 05:13:30,107][train][INFO] - Epoch 399/2000, Val Acc=0.6089, Val Loss=1.8000, lr=0.0100
[2025-05-07 05:13:37,900][train][INFO] - Epoch 400/2000, Val Acc=0.6106, Val Loss=1.7246, lr=0.0100
[2025-05-07 05:13:46,098][train][INFO] - Epoch 401/2000, Val Acc=0.6024, Val Loss=1.8340, lr=0.0100
[2025-05-07 05:13:54,030][train][INFO] - Epoch 402/2000, Val Acc=0.6099, Val Loss=1.7466, lr=0.0100
[2025-05-07 05:14:01,999][train][INFO] - Epoch 403/2000, Val Acc=0.6192, Val Loss=1.7102, lr=0.0100
[2025-05-07 05:14:09,966][train][INFO] - Epoch 404/2000, Val Acc=0.5998, Val Loss=1.8524, lr=0.0100
[2025-05-07 05:14:17,716][train][INFO] - Epoch 405/2000, Val Acc=0.6137, Val Loss=1.7531, lr=0.0100
[2025-05-07 05:14:25,394][train][INFO] - Epoch 406/2000, Val Acc=0.5970, Val Loss=1.8913, lr=0.0100
[2025-05-07 05:14:32,864][train][INFO] - Epoch 407/2000, Val Acc=0.6273, Val Loss=1.6713, lr=0.0100
[2025-05-07 05:14:41,485][train][INFO] - Epoch 408/2000, Val Acc=0.6240, Val Loss=1.7388, lr=0.0100
[2025-05-07 05:14:49,423][train][INFO] - Epoch 409/2000, Val Acc=0.6247, Val Loss=1.7069, lr=0.0100
[2025-05-07 05:14:57,190][train][INFO] - Epoch 410/2000, Val Acc=0.6267, Val Loss=1.7003, lr=0.0100
[2025-05-07 05:15:05,247][train][INFO] - Epoch 411/2000, Val Acc=0.6211, Val Loss=1.6987, lr=0.0100
[2025-05-07 05:15:13,449][train][INFO] - Epoch 412/2000, Val Acc=0.6185, Val Loss=1.7267, lr=0.0100
[2025-05-07 05:15:21,053][train][INFO] - Epoch 413/2000, Val Acc=0.6116, Val Loss=1.7736, lr=0.0100
[2025-05-07 05:15:28,745][train][INFO] - Epoch 414/2000, Val Acc=0.6164, Val Loss=1.7913, lr=0.0100
[2025-05-07 05:15:36,434][train][INFO] - Epoch 415/2000, Val Acc=0.6063, Val Loss=1.7579, lr=0.0100
[2025-05-07 05:15:44,625][train][INFO] - Epoch 416/2000, Val Acc=0.6127, Val Loss=1.7503, lr=0.0100
[2025-05-07 05:15:52,320][train][INFO] - Epoch 417/2000, Val Acc=0.6108, Val Loss=1.7957, lr=0.0100
[2025-05-07 05:15:59,651][train][INFO] - Epoch 418/2000, Val Acc=0.6226, Val Loss=1.7154, lr=0.0100
[2025-05-07 05:16:07,630][train][INFO] - Epoch 419/2000, Val Acc=0.6142, Val Loss=1.7700, lr=0.0100
[2025-05-07 05:16:15,045][train][INFO] - Epoch 420/2000, Val Acc=0.6183, Val Loss=1.7278, lr=0.0100
[2025-05-07 05:16:22,813][train][INFO] - Epoch 421/2000, Val Acc=0.6075, Val Loss=1.7731, lr=0.0100
[2025-05-07 05:16:30,923][train][INFO] - Epoch 422/2000, Val Acc=0.6110, Val Loss=1.7868, lr=0.0100
[2025-05-07 05:16:38,912][train][INFO] - Epoch 423/2000, Val Acc=0.6258, Val Loss=1.6943, lr=0.0100
[2025-05-07 05:16:46,991][train][INFO] - Epoch 424/2000, Val Acc=0.6013, Val Loss=1.8083, lr=0.0100
[2025-05-07 05:16:55,456][train][INFO] - Epoch 425/2000, Val Acc=0.6257, Val Loss=1.7001, lr=0.0100
[2025-05-07 05:17:03,728][train][INFO] - Epoch 426/2000, Val Acc=0.6029, Val Loss=1.7961, lr=0.0100
[2025-05-07 05:17:11,996][train][INFO] - Epoch 427/2000, Val Acc=0.6130, Val Loss=1.7752, lr=0.0100
[2025-05-07 05:17:19,711][train][INFO] - Epoch 428/2000, Val Acc=0.6062, Val Loss=1.7948, lr=0.0100
[2025-05-07 05:17:27,739][train][INFO] - Epoch 429/2000, Val Acc=0.6152, Val Loss=1.7719, lr=0.0100
[2025-05-07 05:17:34,902][train][INFO] - Epoch 430/2000, Val Acc=0.6050, Val Loss=1.7885, lr=0.0100
[2025-05-07 05:17:43,242][train][INFO] - Epoch 431/2000, Val Acc=0.6211, Val Loss=1.7013, lr=0.0100
[2025-05-07 05:17:50,628][train][INFO] - Epoch 432/2000, Val Acc=0.6174, Val Loss=1.7768, lr=0.0100
[2025-05-07 05:17:58,849][train][INFO] - Epoch 433/2000, Val Acc=0.5944, Val Loss=1.8486, lr=0.0100
[2025-05-07 05:18:07,405][train][INFO] - Epoch 434/2000, Val Acc=0.6120, Val Loss=1.7850, lr=0.0100
[2025-05-07 05:18:14,686][train][INFO] - Epoch 435/2000, Val Acc=0.6335, Val Loss=1.6477, lr=0.0100
[2025-05-07 05:18:22,756][train][INFO] - Epoch 436/2000, Val Acc=0.6061, Val Loss=1.8109, lr=0.0100
[2025-05-07 05:18:30,352][train][INFO] - Epoch 437/2000, Val Acc=0.6137, Val Loss=1.7286, lr=0.0100
[2025-05-07 05:18:38,773][train][INFO] - Epoch 438/2000, Val Acc=0.6008, Val Loss=1.8326, lr=0.0100
[2025-05-07 05:18:46,687][train][INFO] - Epoch 439/2000, Val Acc=0.6112, Val Loss=1.8034, lr=0.0100
[2025-05-07 05:18:54,754][train][INFO] - Epoch 440/2000, Val Acc=0.6313, Val Loss=1.6804, lr=0.0100
[2025-05-07 05:19:02,636][train][INFO] - Epoch 441/2000, Val Acc=0.6066, Val Loss=1.8193, lr=0.0100
[2025-05-07 05:19:09,712][train][INFO] - Epoch 442/2000, Val Acc=0.6125, Val Loss=1.7686, lr=0.0100
[2025-05-07 05:19:17,482][train][INFO] - Epoch 443/2000, Val Acc=0.6223, Val Loss=1.7182, lr=0.0100
[2025-05-07 05:19:25,851][train][INFO] - Epoch 444/2000, Val Acc=0.6128, Val Loss=1.7241, lr=0.0100
[2025-05-07 05:19:33,683][train][INFO] - Epoch 445/2000, Val Acc=0.6172, Val Loss=1.7357, lr=0.0100
[2025-05-07 05:19:42,170][train][INFO] - Epoch 446/2000, Val Acc=0.6220, Val Loss=1.7117, lr=0.0100
[2025-05-07 05:19:50,554][train][INFO] - Epoch 447/2000, Val Acc=0.5887, Val Loss=1.8992, lr=0.0100
[2025-05-07 05:19:58,202][train][INFO] - Epoch 448/2000, Val Acc=0.6130, Val Loss=1.7353, lr=0.0100
[2025-05-07 05:20:05,862][train][INFO] - Epoch 449/2000, Val Acc=0.6213, Val Loss=1.6952, lr=0.0100
[2025-05-07 05:20:13,432][train][INFO] - Epoch 450/2000, Val Acc=0.6186, Val Loss=1.7425, lr=0.0100
[2025-05-07 05:20:21,170][train][INFO] - Epoch 451/2000, Val Acc=0.5963, Val Loss=1.8504, lr=0.0100
[2025-05-07 05:20:28,734][train][INFO] - Epoch 452/2000, Val Acc=0.6141, Val Loss=1.7741, lr=0.0100
[2025-05-07 05:20:36,700][train][INFO] - Epoch 453/2000, Val Acc=0.6023, Val Loss=1.8274, lr=0.0100
[2025-05-07 05:20:44,271][train][INFO] - Epoch 454/2000, Val Acc=0.6074, Val Loss=1.7591, lr=0.0100
[2025-05-07 05:20:51,984][train][INFO] - Epoch 455/2000, Val Acc=0.6010, Val Loss=1.7964, lr=0.0100
[2025-05-07 05:20:59,474][train][INFO] - Epoch 456/2000, Val Acc=0.6165, Val Loss=1.7306, lr=0.0100
[2025-05-07 05:21:06,671][train][INFO] - Epoch 457/2000, Val Acc=0.6190, Val Loss=1.7292, lr=0.0100
[2025-05-07 05:21:14,733][train][INFO] - Epoch 458/2000, Val Acc=0.6122, Val Loss=1.7434, lr=0.0100
[2025-05-07 05:21:21,800][train][INFO] - Epoch 459/2000, Val Acc=0.6119, Val Loss=1.7399, lr=0.0100
[2025-05-07 05:21:30,031][train][INFO] - Epoch 460/2000, Val Acc=0.6046, Val Loss=1.7933, lr=0.0100
[2025-05-07 05:21:37,717][train][INFO] - Epoch 461/2000, Val Acc=0.5949, Val Loss=1.8182, lr=0.0100
[2025-05-07 05:21:45,849][train][INFO] - Epoch 462/2000, Val Acc=0.6077, Val Loss=1.8529, lr=0.0100
[2025-05-07 05:21:53,634][train][INFO] - Epoch 463/2000, Val Acc=0.6128, Val Loss=1.7546, lr=0.0100
[2025-05-07 05:22:01,667][train][INFO] - Epoch 464/2000, Val Acc=0.6159, Val Loss=1.7186, lr=0.0100
[2025-05-07 05:22:09,743][train][INFO] - Epoch 465/2000, Val Acc=0.6242, Val Loss=1.7344, lr=0.0100
[2025-05-07 05:22:18,006][train][INFO] - Epoch 466/2000, Val Acc=0.6163, Val Loss=1.7741, lr=0.0100
[2025-05-07 05:22:26,117][train][INFO] - Epoch 467/2000, Val Acc=0.6125, Val Loss=1.7527, lr=0.0100
[2025-05-07 05:22:33,809][train][INFO] - Epoch 468/2000, Val Acc=0.6154, Val Loss=1.7750, lr=0.0100
[2025-05-07 05:22:42,087][train][INFO] - Epoch 469/2000, Val Acc=0.6200, Val Loss=1.7093, lr=0.0100
[2025-05-07 05:22:50,092][train][INFO] - Epoch 470/2000, Val Acc=0.6092, Val Loss=1.7386, lr=0.0100
[2025-05-07 05:22:58,097][train][INFO] - Epoch 471/2000, Val Acc=0.6143, Val Loss=1.7623, lr=0.0100
[2025-05-07 05:23:06,075][train][INFO] - Epoch 472/2000, Val Acc=0.6159, Val Loss=1.7263, lr=0.0100
[2025-05-07 05:23:13,785][train][INFO] - Epoch 473/2000, Val Acc=0.6134, Val Loss=1.7732, lr=0.0100
[2025-05-07 05:23:21,831][train][INFO] - Epoch 474/2000, Val Acc=0.5793, Val Loss=2.0225, lr=0.0100
[2025-05-07 05:23:30,192][train][INFO] - Epoch 475/2000, Val Acc=0.6050, Val Loss=1.7837, lr=0.0100
[2025-05-07 05:23:38,179][train][INFO] - Epoch 476/2000, Val Acc=0.6108, Val Loss=1.7865, lr=0.0100
[2025-05-07 05:23:46,496][train][INFO] - Epoch 477/2000, Val Acc=0.6193, Val Loss=1.7240, lr=0.0100
[2025-05-07 05:23:53,946][train][INFO] - Epoch 478/2000, Val Acc=0.6240, Val Loss=1.6747, lr=0.0100
[2025-05-07 05:24:01,848][train][INFO] - Epoch 479/2000, Val Acc=0.6238, Val Loss=1.7166, lr=0.0100
[2025-05-07 05:24:09,776][train][INFO] - Epoch 480/2000, Val Acc=0.6101, Val Loss=1.7370, lr=0.0100
[2025-05-07 05:24:17,249][train][INFO] - Epoch 481/2000, Val Acc=0.6234, Val Loss=1.6773, lr=0.0100
[2025-05-07 05:24:25,406][train][INFO] - Epoch 482/2000, Val Acc=0.6187, Val Loss=1.6925, lr=0.0100
[2025-05-07 05:24:33,546][train][INFO] - Epoch 483/2000, Val Acc=0.6103, Val Loss=1.7976, lr=0.0100
[2025-05-07 05:24:41,434][train][INFO] - Epoch 484/2000, Val Acc=0.6082, Val Loss=1.7672, lr=0.0100
[2025-05-07 05:24:49,787][train][INFO] - Epoch 485/2000, Val Acc=0.6024, Val Loss=1.8232, lr=0.0100
[2025-05-07 05:24:57,769][train][INFO] - Epoch 486/2000, Val Acc=0.6163, Val Loss=1.7716, lr=0.0100
[2025-05-07 05:25:05,967][train][INFO] - Epoch 487/2000, Val Acc=0.6009, Val Loss=1.8285, lr=0.0100
[2025-05-07 05:25:14,037][train][INFO] - Epoch 488/2000, Val Acc=0.6081, Val Loss=1.7574, lr=0.0100
[2025-05-07 05:25:21,455][train][INFO] - Epoch 489/2000, Val Acc=0.6143, Val Loss=1.7785, lr=0.0100
[2025-05-07 05:25:28,740][train][INFO] - Epoch 490/2000, Val Acc=0.6204, Val Loss=1.7132, lr=0.0100
[2025-05-07 05:25:36,502][train][INFO] - Epoch 491/2000, Val Acc=0.6060, Val Loss=1.7556, lr=0.0100
[2025-05-07 05:25:44,123][train][INFO] - Epoch 492/2000, Val Acc=0.6031, Val Loss=1.7664, lr=0.0100
[2025-05-07 05:25:51,478][train][INFO] - Epoch 493/2000, Val Acc=0.6248, Val Loss=1.7261, lr=0.0100
[2025-05-07 05:25:58,832][train][INFO] - Epoch 494/2000, Val Acc=0.6179, Val Loss=1.6846, lr=0.0100
[2025-05-07 05:26:06,373][train][INFO] - Epoch 495/2000, Val Acc=0.5997, Val Loss=1.7985, lr=0.0100
[2025-05-07 05:26:14,620][train][INFO] - Epoch 496/2000, Val Acc=0.6186, Val Loss=1.7121, lr=0.0100
[2025-05-07 05:26:23,249][train][INFO] - Epoch 497/2000, Val Acc=0.6165, Val Loss=1.7423, lr=0.0100
[2025-05-07 05:26:31,466][train][INFO] - Epoch 498/2000, Val Acc=0.6018, Val Loss=1.8457, lr=0.0100
[2025-05-07 05:26:39,685][train][INFO] - Epoch 499/2000, Val Acc=0.6043, Val Loss=1.8166, lr=0.0100
[2025-05-07 05:26:47,893][train][INFO] - Epoch 500/2000, Val Acc=0.6087, Val Loss=1.7801, lr=0.0100
[2025-05-07 05:26:55,664][train][INFO] - Epoch 501/2000, Val Acc=0.6185, Val Loss=1.7243, lr=0.0100
[2025-05-07 05:27:04,103][train][INFO] - Epoch 502/2000, Val Acc=0.6060, Val Loss=1.8096, lr=0.0100
[2025-05-07 05:27:12,459][train][INFO] - Epoch 503/2000, Val Acc=0.6201, Val Loss=1.7240, lr=0.0100
[2025-05-07 05:27:20,235][train][INFO] - Epoch 504/2000, Val Acc=0.6212, Val Loss=1.7453, lr=0.0100
[2025-05-07 05:27:27,230][train][INFO] - Epoch 505/2000, Val Acc=0.6167, Val Loss=1.7753, lr=0.0100
[2025-05-07 05:27:35,418][train][INFO] - Epoch 506/2000, Val Acc=0.6091, Val Loss=1.7955, lr=0.0100
[2025-05-07 05:27:43,230][train][INFO] - Epoch 507/2000, Val Acc=0.6209, Val Loss=1.7639, lr=0.0100
[2025-05-07 05:27:51,330][train][INFO] - Epoch 508/2000, Val Acc=0.6005, Val Loss=1.8241, lr=0.0100
[2025-05-07 05:27:59,516][train][INFO] - Epoch 509/2000, Val Acc=0.6258, Val Loss=1.6892, lr=0.0100
[2025-05-07 05:28:06,773][train][INFO] - Epoch 510/2000, Val Acc=0.6117, Val Loss=1.7586, lr=0.0100
[2025-05-07 05:28:14,400][train][INFO] - Epoch 511/2000, Val Acc=0.6187, Val Loss=1.7096, lr=0.0100
[2025-05-07 05:28:22,029][train][INFO] - Epoch 512/2000, Val Acc=0.6185, Val Loss=1.7458, lr=0.0100
[2025-05-07 05:28:28,726][train][INFO] - Epoch 513/2000, Val Acc=0.6149, Val Loss=1.7239, lr=0.0100
[2025-05-07 05:28:36,932][train][INFO] - Epoch 514/2000, Val Acc=0.6158, Val Loss=1.7314, lr=0.0100
[2025-05-07 05:28:44,960][train][INFO] - Epoch 515/2000, Val Acc=0.6220, Val Loss=1.7377, lr=0.0100
[2025-05-07 05:28:53,002][train][INFO] - Epoch 516/2000, Val Acc=0.6122, Val Loss=1.7448, lr=0.0100
[2025-05-07 05:29:00,609][train][INFO] - Epoch 517/2000, Val Acc=0.5929, Val Loss=1.8761, lr=0.0100
[2025-05-07 05:29:08,471][train][INFO] - Epoch 518/2000, Val Acc=0.6164, Val Loss=1.7191, lr=0.0100
[2025-05-07 05:29:16,607][train][INFO] - Epoch 519/2000, Val Acc=0.6197, Val Loss=1.7067, lr=0.0100
[2025-05-07 05:29:24,338][train][INFO] - Epoch 520/2000, Val Acc=0.6005, Val Loss=1.8650, lr=0.0100
[2025-05-07 05:29:32,678][train][INFO] - Epoch 521/2000, Val Acc=0.6174, Val Loss=1.7666, lr=0.0100
[2025-05-07 05:29:41,136][train][INFO] - Epoch 522/2000, Val Acc=0.5987, Val Loss=1.8911, lr=0.0100
[2025-05-07 05:29:49,502][train][INFO] - Epoch 523/2000, Val Acc=0.6056, Val Loss=1.7658, lr=0.0100
[2025-05-07 05:29:56,304][train][INFO] - Epoch 524/2000, Val Acc=0.6024, Val Loss=1.7793, lr=0.0100
[2025-05-07 05:30:04,914][train][INFO] - Epoch 525/2000, Val Acc=0.6099, Val Loss=1.7550, lr=0.0100
[2025-05-07 05:30:13,123][train][INFO] - Epoch 526/2000, Val Acc=0.6173, Val Loss=1.7390, lr=0.0100
[2025-05-07 05:30:20,768][train][INFO] - Epoch 527/2000, Val Acc=0.6040, Val Loss=1.7925, lr=0.0100
[2025-05-07 05:30:28,628][train][INFO] - Epoch 528/2000, Val Acc=0.6102, Val Loss=1.7541, lr=0.0100
[2025-05-07 05:30:36,180][train][INFO] - Epoch 529/2000, Val Acc=0.6164, Val Loss=1.7479, lr=0.0100
[2025-05-07 05:30:44,547][train][INFO] - Epoch 530/2000, Val Acc=0.6145, Val Loss=1.7473, lr=0.0100
[2025-05-07 05:30:52,881][train][INFO] - Epoch 531/2000, Val Acc=0.6201, Val Loss=1.7408, lr=0.0100
[2025-05-07 05:31:00,678][train][INFO] - Epoch 532/2000, Val Acc=0.6087, Val Loss=1.7696, lr=0.0100
[2025-05-07 05:31:07,858][train][INFO] - Epoch 533/2000, Val Acc=0.6033, Val Loss=1.7900, lr=0.0100
[2025-05-07 05:31:15,803][train][INFO] - Epoch 534/2000, Val Acc=0.6167, Val Loss=1.7733, lr=0.0100
[2025-05-07 05:31:23,921][train][INFO] - Epoch 535/2000, Val Acc=0.6074, Val Loss=1.8032, lr=0.0100
[2025-05-07 05:31:31,326][train][INFO] - Epoch 536/2000, Val Acc=0.6013, Val Loss=1.8203, lr=0.0100
[2025-05-07 05:31:39,301][train][INFO] - Epoch 537/2000, Val Acc=0.6267, Val Loss=1.6755, lr=0.0100
[2025-05-07 05:31:47,644][train][INFO] - Epoch 538/2000, Val Acc=0.6077, Val Loss=1.8242, lr=0.0100
[2025-05-07 05:31:55,813][train][INFO] - Epoch 539/2000, Val Acc=0.6028, Val Loss=1.8438, lr=0.0100
[2025-05-07 05:32:03,628][train][INFO] - Epoch 540/2000, Val Acc=0.6019, Val Loss=1.8374, lr=0.0100
[2025-05-07 05:32:12,120][train][INFO] - Epoch 541/2000, Val Acc=0.6127, Val Loss=1.7648, lr=0.0100
[2025-05-07 05:32:19,945][train][INFO] - Epoch 542/2000, Val Acc=0.5935, Val Loss=1.9150, lr=0.0100
[2025-05-07 05:32:28,033][train][INFO] - Epoch 543/2000, Val Acc=0.6174, Val Loss=1.7617, lr=0.0100
[2025-05-07 05:32:36,229][train][INFO] - Epoch 544/2000, Val Acc=0.6077, Val Loss=1.7507, lr=0.0100
[2025-05-07 05:32:43,318][train][INFO] - Epoch 545/2000, Val Acc=0.6249, Val Loss=1.7359, lr=0.0100
[2025-05-07 05:32:50,678][train][INFO] - Epoch 546/2000, Val Acc=0.6173, Val Loss=1.7787, lr=0.0100
[2025-05-07 05:32:58,659][train][INFO] - Epoch 547/2000, Val Acc=0.6175, Val Loss=1.7357, lr=0.0100
[2025-05-07 05:33:06,887][train][INFO] - Epoch 548/2000, Val Acc=0.6116, Val Loss=1.7517, lr=0.0100
[2025-05-07 05:33:13,871][train][INFO] - Epoch 549/2000, Val Acc=0.6039, Val Loss=1.7872, lr=0.0100
[2025-05-07 05:33:21,946][train][INFO] - Epoch 550/2000, Val Acc=0.5976, Val Loss=1.8970, lr=0.0100
[2025-05-07 05:33:30,234][train][INFO] - Epoch 551/2000, Val Acc=0.6106, Val Loss=1.8100, lr=0.0100
[2025-05-07 05:33:38,318][train][INFO] - Epoch 552/2000, Val Acc=0.6229, Val Loss=1.6878, lr=0.0100
[2025-05-07 05:33:45,826][train][INFO] - Epoch 553/2000, Val Acc=0.6144, Val Loss=1.7582, lr=0.0100
[2025-05-07 05:33:53,809][train][INFO] - Epoch 554/2000, Val Acc=0.6246, Val Loss=1.6944, lr=0.0100
[2025-05-07 05:34:01,701][train][INFO] - Epoch 555/2000, Val Acc=0.6078, Val Loss=1.7871, lr=0.0100
[2025-05-07 05:34:09,637][train][INFO] - Epoch 556/2000, Val Acc=0.5915, Val Loss=1.8982, lr=0.0100
[2025-05-07 05:34:17,861][train][INFO] - Epoch 557/2000, Val Acc=0.6174, Val Loss=1.7111, lr=0.0100
[2025-05-07 05:34:25,854][train][INFO] - Epoch 558/2000, Val Acc=0.6222, Val Loss=1.7440, lr=0.0100
[2025-05-07 05:34:33,403][train][INFO] - Epoch 559/2000, Val Acc=0.6101, Val Loss=1.7703, lr=0.0100
[2025-05-07 05:34:40,707][train][INFO] - Epoch 560/2000, Val Acc=0.6117, Val Loss=1.7816, lr=0.0100
[2025-05-07 05:34:48,316][train][INFO] - Epoch 561/2000, Val Acc=0.6057, Val Loss=1.8033, lr=0.0100
[2025-05-07 05:34:55,851][train][INFO] - Epoch 562/2000, Val Acc=0.6044, Val Loss=1.7905, lr=0.0100
[2025-05-07 05:35:04,473][train][INFO] - Epoch 563/2000, Val Acc=0.5916, Val Loss=1.8932, lr=0.0100
[2025-05-07 05:35:11,882][train][INFO] - Epoch 564/2000, Val Acc=0.6055, Val Loss=1.8286, lr=0.0100
[2025-05-07 05:35:19,904][train][INFO] - Epoch 565/2000, Val Acc=0.6098, Val Loss=1.8010, lr=0.0100
[2025-05-07 05:35:27,981][train][INFO] - Epoch 566/2000, Val Acc=0.6029, Val Loss=1.8312, lr=0.0100
[2025-05-07 05:35:36,383][train][INFO] - Epoch 567/2000, Val Acc=0.6224, Val Loss=1.7064, lr=0.0100
[2025-05-07 05:35:44,110][train][INFO] - Epoch 568/2000, Val Acc=0.6177, Val Loss=1.7329, lr=0.0100
[2025-05-07 05:35:52,280][train][INFO] - Epoch 569/2000, Val Acc=0.6036, Val Loss=1.8043, lr=0.0100
[2025-05-07 05:36:00,979][train][INFO] - Epoch 570/2000, Val Acc=0.6064, Val Loss=1.7672, lr=0.0100
[2025-05-07 05:36:07,823][train][INFO] - Epoch 571/2000, Val Acc=0.6102, Val Loss=1.8080, lr=0.0100
[2025-05-07 05:36:14,879][train][INFO] - Epoch 572/2000, Val Acc=0.6122, Val Loss=1.7768, lr=0.0100
[2025-05-07 05:36:22,938][train][INFO] - Epoch 573/2000, Val Acc=0.5999, Val Loss=1.8380, lr=0.0100
[2025-05-07 05:36:30,753][train][INFO] - Epoch 574/2000, Val Acc=0.6110, Val Loss=1.7599, lr=0.0100
[2025-05-07 05:36:38,279][train][INFO] - Epoch 575/2000, Val Acc=0.6144, Val Loss=1.7786, lr=0.0100
[2025-05-07 05:36:46,719][train][INFO] - Epoch 576/2000, Val Acc=0.5977, Val Loss=1.9100, lr=0.0100
[2025-05-07 05:36:54,789][train][INFO] - Epoch 577/2000, Val Acc=0.6073, Val Loss=1.7771, lr=0.0100
[2025-05-07 05:37:02,089][train][INFO] - Epoch 578/2000, Val Acc=0.6081, Val Loss=1.7843, lr=0.0100
[2025-05-07 05:37:09,997][train][INFO] - Epoch 579/2000, Val Acc=0.6130, Val Loss=1.8096, lr=0.0100
[2025-05-07 05:37:18,241][train][INFO] - Epoch 580/2000, Val Acc=0.6095, Val Loss=1.7945, lr=0.0100
[2025-05-07 05:37:25,768][train][INFO] - Epoch 581/2000, Val Acc=0.6193, Val Loss=1.7281, lr=0.0100
[2025-05-07 05:37:33,721][train][INFO] - Epoch 582/2000, Val Acc=0.5991, Val Loss=1.8415, lr=0.0100
[2025-05-07 05:37:41,319][train][INFO] - Epoch 583/2000, Val Acc=0.6078, Val Loss=1.7680, lr=0.0100
[2025-05-07 05:37:49,324][train][INFO] - Epoch 584/2000, Val Acc=0.6153, Val Loss=1.7628, lr=0.0100
[2025-05-07 05:37:57,220][train][INFO] - Epoch 585/2000, Val Acc=0.6291, Val Loss=1.6395, lr=0.0100
[2025-05-07 05:38:04,472][train][INFO] - Epoch 586/2000, Val Acc=0.6195, Val Loss=1.6987, lr=0.0100
[2025-05-07 05:38:12,292][train][INFO] - Epoch 587/2000, Val Acc=0.6159, Val Loss=1.7256, lr=0.0100
[2025-05-07 05:38:20,426][train][INFO] - Epoch 588/2000, Val Acc=0.6230, Val Loss=1.7448, lr=0.0100
[2025-05-07 05:38:28,829][train][INFO] - Epoch 589/2000, Val Acc=0.6146, Val Loss=1.7496, lr=0.0100
[2025-05-07 05:38:37,198][train][INFO] - Epoch 590/2000, Val Acc=0.5936, Val Loss=1.8833, lr=0.0100
[2025-05-07 05:38:45,369][train][INFO] - Epoch 591/2000, Val Acc=0.6227, Val Loss=1.7083, lr=0.0100
[2025-05-07 05:38:53,506][train][INFO] - Epoch 592/2000, Val Acc=0.6001, Val Loss=1.8158, lr=0.0100
[2025-05-07 05:39:00,925][train][INFO] - Epoch 593/2000, Val Acc=0.6169, Val Loss=1.7332, lr=0.0100
[2025-05-07 05:39:08,487][train][INFO] - Epoch 594/2000, Val Acc=0.6176, Val Loss=1.7334, lr=0.0100
[2025-05-07 05:39:15,754][train][INFO] - Epoch 595/2000, Val Acc=0.6115, Val Loss=1.7822, lr=0.0100
[2025-05-07 05:39:23,605][train][INFO] - Epoch 596/2000, Val Acc=0.6025, Val Loss=1.8426, lr=0.0100
[2025-05-07 05:39:32,104][train][INFO] - Epoch 597/2000, Val Acc=0.6102, Val Loss=1.7869, lr=0.0100
[2025-05-07 05:39:40,481][train][INFO] - Epoch 598/2000, Val Acc=0.6138, Val Loss=1.7555, lr=0.0100
[2025-05-07 05:39:49,032][train][INFO] - Epoch 599/2000, Val Acc=0.6073, Val Loss=1.8338, lr=0.0100
[2025-05-07 05:39:56,783][train][INFO] - Epoch 600/2000, Val Acc=0.6132, Val Loss=1.7513, lr=0.0100
[2025-05-07 05:40:04,636][train][INFO] - Epoch 601/2000, Val Acc=0.5993, Val Loss=1.7880, lr=0.0100
[2025-05-07 05:40:13,203][train][INFO] - Epoch 602/2000, Val Acc=0.6211, Val Loss=1.7134, lr=0.0100
[2025-05-07 05:40:21,608][train][INFO] - Epoch 603/2000, Val Acc=0.6122, Val Loss=1.7784, lr=0.0100
[2025-05-07 05:40:28,942][train][INFO] - Epoch 604/2000, Val Acc=0.6046, Val Loss=1.8319, lr=0.0100
[2025-05-07 05:40:37,274][train][INFO] - Epoch 605/2000, Val Acc=0.6054, Val Loss=1.8218, lr=0.0100
[2025-05-07 05:40:45,269][train][INFO] - Epoch 606/2000, Val Acc=0.6113, Val Loss=1.7613, lr=0.0100
[2025-05-07 05:40:53,592][train][INFO] - Epoch 607/2000, Val Acc=0.6192, Val Loss=1.7407, lr=0.0100
[2025-05-07 05:41:01,646][train][INFO] - Epoch 608/2000, Val Acc=0.6123, Val Loss=1.7309, lr=0.0100
[2025-05-07 05:41:09,524][train][INFO] - Epoch 609/2000, Val Acc=0.6128, Val Loss=1.8015, lr=0.0100
[2025-05-07 05:41:16,918][train][INFO] - Epoch 610/2000, Val Acc=0.6099, Val Loss=1.7623, lr=0.0100
[2025-05-07 05:41:24,964][train][INFO] - Epoch 611/2000, Val Acc=0.5891, Val Loss=1.8925, lr=0.0100
[2025-05-07 05:41:33,020][train][INFO] - Epoch 612/2000, Val Acc=0.6222, Val Loss=1.7011, lr=0.0100
[2025-05-07 05:41:40,883][train][INFO] - Epoch 613/2000, Val Acc=0.6068, Val Loss=1.8189, lr=0.0100
[2025-05-07 05:41:48,745][train][INFO] - Epoch 614/2000, Val Acc=0.6006, Val Loss=1.8456, lr=0.0100
[2025-05-07 05:41:56,912][train][INFO] - Epoch 615/2000, Val Acc=0.6077, Val Loss=1.7943, lr=0.0100
[2025-05-07 05:42:05,298][train][INFO] - Epoch 616/2000, Val Acc=0.6025, Val Loss=1.8189, lr=0.0100
[2025-05-07 05:42:13,339][train][INFO] - Epoch 617/2000, Val Acc=0.6099, Val Loss=1.7476, lr=0.0100
[2025-05-07 05:42:21,550][train][INFO] - Epoch 618/2000, Val Acc=0.6189, Val Loss=1.7369, lr=0.0100
[2025-05-07 05:42:29,610][train][INFO] - Epoch 619/2000, Val Acc=0.6139, Val Loss=1.7492, lr=0.0100
[2025-05-07 05:42:37,886][train][INFO] - Epoch 620/2000, Val Acc=0.6108, Val Loss=1.7380, lr=0.0100
[2025-05-07 05:42:46,305][train][INFO] - Epoch 621/2000, Val Acc=0.6098, Val Loss=1.7956, lr=0.0100
[2025-05-07 05:42:54,686][train][INFO] - Epoch 622/2000, Val Acc=0.6207, Val Loss=1.7083, lr=0.0100
[2025-05-07 05:43:02,982][train][INFO] - Epoch 623/2000, Val Acc=0.6011, Val Loss=1.8614, lr=0.0100
[2025-05-07 05:43:11,058][train][INFO] - Epoch 624/2000, Val Acc=0.6125, Val Loss=1.7840, lr=0.0100
[2025-05-07 05:43:19,110][train][INFO] - Epoch 625/2000, Val Acc=0.6003, Val Loss=1.8537, lr=0.0100
[2025-05-07 05:43:27,329][train][INFO] - Epoch 626/2000, Val Acc=0.6082, Val Loss=1.8249, lr=0.0100
[2025-05-07 05:43:35,283][train][INFO] - Epoch 627/2000, Val Acc=0.5896, Val Loss=1.9554, lr=0.0100
[2025-05-07 05:43:43,686][train][INFO] - Epoch 628/2000, Val Acc=0.6067, Val Loss=1.7829, lr=0.0100
[2025-05-07 05:43:51,312][train][INFO] - Epoch 629/2000, Val Acc=0.6146, Val Loss=1.7549, lr=0.0100
[2025-05-07 05:43:59,391][train][INFO] - Epoch 630/2000, Val Acc=0.6049, Val Loss=1.7844, lr=0.0100
[2025-05-07 05:44:06,652][train][INFO] - Epoch 631/2000, Val Acc=0.6123, Val Loss=1.7379, lr=0.0100
[2025-05-07 05:44:14,556][train][INFO] - Epoch 632/2000, Val Acc=0.6139, Val Loss=1.7911, lr=0.0100
[2025-05-07 05:44:22,582][train][INFO] - Epoch 633/2000, Val Acc=0.6088, Val Loss=1.7955, lr=0.0100
[2025-05-07 05:44:30,111][train][INFO] - Epoch 634/2000, Val Acc=0.6083, Val Loss=1.8344, lr=0.0100
[2025-05-07 05:44:38,530][train][INFO] - Epoch 635/2000, Val Acc=0.6107, Val Loss=1.7241, lr=0.0100
[2025-05-07 05:44:46,965][train][INFO] - Epoch 636/2000, Val Acc=0.6162, Val Loss=1.7432, lr=0.0100
[2025-05-07 05:44:55,444][train][INFO] - Epoch 637/2000, Val Acc=0.6152, Val Loss=1.7464, lr=0.0100
[2025-05-07 05:45:03,034][train][INFO] - Epoch 638/2000, Val Acc=0.6218, Val Loss=1.7159, lr=0.0100
[2025-05-07 05:45:11,284][train][INFO] - Epoch 639/2000, Val Acc=0.6126, Val Loss=1.7400, lr=0.0100
[2025-05-07 05:45:19,565][train][INFO] - Epoch 640/2000, Val Acc=0.6139, Val Loss=1.7789, lr=0.0100
[2025-05-07 05:45:26,957][train][INFO] - Epoch 641/2000, Val Acc=0.6166, Val Loss=1.7314, lr=0.0100
[2025-05-07 05:45:35,402][train][INFO] - Epoch 642/2000, Val Acc=0.6010, Val Loss=1.9483, lr=0.0100
[2025-05-07 05:45:43,502][train][INFO] - Epoch 643/2000, Val Acc=0.6067, Val Loss=1.7801, lr=0.0100
[2025-05-07 05:45:51,295][train][INFO] - Epoch 644/2000, Val Acc=0.5815, Val Loss=1.9870, lr=0.0100
[2025-05-07 05:45:59,469][train][INFO] - Epoch 645/2000, Val Acc=0.6057, Val Loss=1.7992, lr=0.0100
[2025-05-07 05:46:07,917][train][INFO] - Epoch 646/2000, Val Acc=0.6142, Val Loss=1.7128, lr=0.0100
[2025-05-07 05:46:15,998][train][INFO] - Epoch 647/2000, Val Acc=0.5924, Val Loss=1.9463, lr=0.0100
[2025-05-07 05:46:24,155][train][INFO] - Epoch 648/2000, Val Acc=0.6190, Val Loss=1.7368, lr=0.0100
[2025-05-07 05:46:31,947][train][INFO] - Epoch 649/2000, Val Acc=0.6181, Val Loss=1.7251, lr=0.0100
[2025-05-07 05:46:38,694][train][INFO] - Epoch 650/2000, Val Acc=0.6083, Val Loss=1.7566, lr=0.0100
[2025-05-07 05:46:46,078][train][INFO] - Epoch 651/2000, Val Acc=0.6009, Val Loss=1.8403, lr=0.0100
[2025-05-07 05:46:53,337][train][INFO] - Epoch 652/2000, Val Acc=0.6161, Val Loss=1.7587, lr=0.0100
[2025-05-07 05:47:01,547][train][INFO] - Epoch 653/2000, Val Acc=0.6266, Val Loss=1.7150, lr=0.0100
[2025-05-07 05:47:09,739][train][INFO] - Epoch 654/2000, Val Acc=0.6093, Val Loss=1.7834, lr=0.0100
[2025-05-07 05:47:18,077][train][INFO] - Epoch 655/2000, Val Acc=0.6161, Val Loss=1.7577, lr=0.0100
[2025-05-07 05:47:25,810][train][INFO] - Epoch 656/2000, Val Acc=0.5922, Val Loss=1.9058, lr=0.0100
[2025-05-07 05:47:33,835][train][INFO] - Epoch 657/2000, Val Acc=0.6112, Val Loss=1.7520, lr=0.0100
[2025-05-07 05:47:41,759][train][INFO] - Epoch 658/2000, Val Acc=0.6059, Val Loss=1.7689, lr=0.0100
[2025-05-07 05:47:49,446][train][INFO] - Epoch 659/2000, Val Acc=0.5970, Val Loss=1.8722, lr=0.0100
[2025-05-07 05:47:57,471][train][INFO] - Epoch 660/2000, Val Acc=0.6298, Val Loss=1.6881, lr=0.0100
[2025-05-07 05:48:06,055][train][INFO] - Epoch 661/2000, Val Acc=0.6177, Val Loss=1.7216, lr=0.0100
[2025-05-07 05:48:13,564][train][INFO] - Epoch 662/2000, Val Acc=0.6033, Val Loss=1.7862, lr=0.0100
[2025-05-07 05:48:21,897][train][INFO] - Epoch 663/2000, Val Acc=0.6102, Val Loss=1.7912, lr=0.0100
[2025-05-07 05:48:29,899][train][INFO] - Epoch 664/2000, Val Acc=0.6092, Val Loss=1.7569, lr=0.0100
[2025-05-07 05:48:38,458][train][INFO] - Epoch 665/2000, Val Acc=0.6133, Val Loss=1.7841, lr=0.0100
[2025-05-07 05:48:45,974][train][INFO] - Epoch 666/2000, Val Acc=0.5806, Val Loss=2.0038, lr=0.0100
[2025-05-07 05:48:53,716][train][INFO] - Epoch 667/2000, Val Acc=0.6023, Val Loss=1.8272, lr=0.0100
[2025-05-07 05:49:01,752][train][INFO] - Epoch 668/2000, Val Acc=0.6126, Val Loss=1.7506, lr=0.0100
[2025-05-07 05:49:09,600][train][INFO] - Epoch 669/2000, Val Acc=0.6005, Val Loss=1.8385, lr=0.0100
[2025-05-07 05:49:18,328][train][INFO] - Epoch 670/2000, Val Acc=0.6203, Val Loss=1.7306, lr=0.0100
[2025-05-07 05:49:26,776][train][INFO] - Epoch 671/2000, Val Acc=0.6324, Val Loss=1.6678, lr=0.0100
[2025-05-07 05:49:34,992][train][INFO] - Epoch 672/2000, Val Acc=0.6247, Val Loss=1.7323, lr=0.0100
[2025-05-07 05:49:42,881][train][INFO] - Epoch 673/2000, Val Acc=0.6068, Val Loss=1.8319, lr=0.0100
[2025-05-07 05:49:50,923][train][INFO] - Epoch 674/2000, Val Acc=0.6107, Val Loss=1.7773, lr=0.0100
[2025-05-07 05:49:58,687][train][INFO] - Epoch 675/2000, Val Acc=0.6095, Val Loss=1.8161, lr=0.0100
[2025-05-07 05:50:07,083][train][INFO] - Epoch 676/2000, Val Acc=0.6216, Val Loss=1.7153, lr=0.0100
[2025-05-07 05:50:14,293][train][INFO] - Epoch 677/2000, Val Acc=0.6158, Val Loss=1.7650, lr=0.0100
[2025-05-07 05:50:21,704][train][INFO] - Epoch 678/2000, Val Acc=0.6000, Val Loss=1.8518, lr=0.0100
[2025-05-07 05:50:30,044][train][INFO] - Epoch 679/2000, Val Acc=0.6126, Val Loss=1.8069, lr=0.0100
[2025-05-07 05:50:38,403][train][INFO] - Epoch 680/2000, Val Acc=0.6173, Val Loss=1.7525, lr=0.0100
[2025-05-07 05:50:46,418][train][INFO] - Epoch 681/2000, Val Acc=0.5977, Val Loss=1.8236, lr=0.0100
[2025-05-07 05:50:53,393][train][INFO] - Epoch 682/2000, Val Acc=0.6138, Val Loss=1.7642, lr=0.0100
[2025-05-07 05:51:01,216][train][INFO] - Epoch 683/2000, Val Acc=0.5727, Val Loss=2.0921, lr=0.0100
[2025-05-07 05:51:08,814][train][INFO] - Epoch 684/2000, Val Acc=0.6132, Val Loss=1.7597, lr=0.0100
[2025-05-07 05:51:17,461][train][INFO] - Epoch 685/2000, Val Acc=0.6141, Val Loss=1.7336, lr=0.0100
[2025-05-07 05:51:25,737][train][INFO] - Epoch 686/2000, Val Acc=0.6109, Val Loss=1.7758, lr=0.0100
[2025-05-07 05:51:33,993][train][INFO] - Epoch 687/2000, Val Acc=0.6191, Val Loss=1.7323, lr=0.0100
[2025-05-07 05:51:40,932][train][INFO] - Epoch 688/2000, Val Acc=0.6171, Val Loss=1.7486, lr=0.0100
[2025-05-07 05:51:49,174][train][INFO] - Epoch 689/2000, Val Acc=0.6077, Val Loss=1.8252, lr=0.0100
[2025-05-07 05:51:57,329][train][INFO] - Epoch 690/2000, Val Acc=0.6051, Val Loss=1.8327, lr=0.0100
[2025-05-07 05:52:04,817][train][INFO] - Epoch 691/2000, Val Acc=0.5949, Val Loss=1.8750, lr=0.0100
[2025-05-07 05:52:13,023][train][INFO] - Epoch 692/2000, Val Acc=0.6234, Val Loss=1.6901, lr=0.0100
[2025-05-07 05:52:20,417][train][INFO] - Epoch 693/2000, Val Acc=0.6139, Val Loss=1.7759, lr=0.0100
[2025-05-07 05:52:27,865][train][INFO] - Epoch 694/2000, Val Acc=0.6158, Val Loss=1.7474, lr=0.0100
[2025-05-07 05:52:35,659][train][INFO] - Epoch 695/2000, Val Acc=0.6124, Val Loss=1.7681, lr=0.0100
[2025-05-07 05:52:42,830][train][INFO] - Epoch 696/2000, Val Acc=0.6151, Val Loss=1.7729, lr=0.0100
[2025-05-07 05:52:50,763][train][INFO] - Epoch 697/2000, Val Acc=0.6108, Val Loss=1.8126, lr=0.0100
[2025-05-07 05:52:58,826][train][INFO] - Epoch 698/2000, Val Acc=0.6167, Val Loss=1.7191, lr=0.0100
[2025-05-07 05:53:06,962][train][INFO] - Epoch 699/2000, Val Acc=0.6070, Val Loss=1.7998, lr=0.0100
[2025-05-07 05:53:14,973][train][INFO] - Epoch 700/2000, Val Acc=0.5851, Val Loss=1.9233, lr=0.0100
[2025-05-07 05:53:23,340][train][INFO] - Epoch 701/2000, Val Acc=0.6053, Val Loss=1.8134, lr=0.0100
[2025-05-07 05:53:31,089][train][INFO] - Epoch 702/2000, Val Acc=0.6093, Val Loss=1.7613, lr=0.0100
[2025-05-07 05:53:38,913][train][INFO] - Epoch 703/2000, Val Acc=0.6085, Val Loss=1.8258, lr=0.0100
[2025-05-07 05:53:47,094][train][INFO] - Epoch 704/2000, Val Acc=0.6277, Val Loss=1.6625, lr=0.0100
[2025-05-07 05:53:55,119][train][INFO] - Epoch 705/2000, Val Acc=0.6074, Val Loss=1.8149, lr=0.0100
[2025-05-07 05:54:03,433][train][INFO] - Epoch 706/2000, Val Acc=0.5746, Val Loss=1.9811, lr=0.0100
[2025-05-07 05:54:11,558][train][INFO] - Epoch 707/2000, Val Acc=0.6120, Val Loss=1.7390, lr=0.0100
[2025-05-07 05:54:19,401][train][INFO] - Epoch 708/2000, Val Acc=0.6139, Val Loss=1.7630, lr=0.0100
[2025-05-07 05:54:27,662][train][INFO] - Epoch 709/2000, Val Acc=0.6235, Val Loss=1.7117, lr=0.0100
[2025-05-07 05:54:35,755][train][INFO] - Epoch 710/2000, Val Acc=0.6022, Val Loss=1.8408, lr=0.0100
[2025-05-07 05:54:43,389][train][INFO] - Epoch 711/2000, Val Acc=0.5953, Val Loss=1.8696, lr=0.0100
[2025-05-07 05:54:51,495][train][INFO] - Epoch 712/2000, Val Acc=0.6115, Val Loss=1.7809, lr=0.0100
[2025-05-07 05:54:59,775][train][INFO] - Epoch 713/2000, Val Acc=0.6260, Val Loss=1.6832, lr=0.0100
[2025-05-07 05:55:07,772][train][INFO] - Epoch 714/2000, Val Acc=0.6134, Val Loss=1.7650, lr=0.0100
[2025-05-07 05:55:15,887][train][INFO] - Epoch 715/2000, Val Acc=0.6249, Val Loss=1.6642, lr=0.0100
[2025-05-07 05:55:24,067][train][INFO] - Epoch 716/2000, Val Acc=0.5949, Val Loss=1.9082, lr=0.0100
[2025-05-07 05:55:31,917][train][INFO] - Epoch 717/2000, Val Acc=0.6130, Val Loss=1.7802, lr=0.0100
[2025-05-07 05:55:39,728][train][INFO] - Epoch 718/2000, Val Acc=0.6187, Val Loss=1.7629, lr=0.0100
[2025-05-07 05:55:48,200][train][INFO] - Epoch 719/2000, Val Acc=0.6052, Val Loss=1.8170, lr=0.0100
[2025-05-07 05:55:55,489][train][INFO] - Epoch 720/2000, Val Acc=0.6191, Val Loss=1.7384, lr=0.0100
[2025-05-07 05:56:03,815][train][INFO] - Epoch 721/2000, Val Acc=0.6105, Val Loss=1.7800, lr=0.0100
[2025-05-07 05:56:10,675][train][INFO] - Epoch 722/2000, Val Acc=0.5975, Val Loss=1.8804, lr=0.0100
[2025-05-07 05:56:18,727][train][INFO] - Epoch 723/2000, Val Acc=0.6157, Val Loss=1.7876, lr=0.0100
[2025-05-07 05:56:26,949][train][INFO] - Epoch 724/2000, Val Acc=0.5817, Val Loss=1.9461, lr=0.0100
[2025-05-07 05:56:35,027][train][INFO] - Epoch 725/2000, Val Acc=0.6256, Val Loss=1.7360, lr=0.0100
[2025-05-07 05:56:43,513][train][INFO] - Epoch 726/2000, Val Acc=0.6019, Val Loss=1.8208, lr=0.0100
[2025-05-07 05:56:51,759][train][INFO] - Epoch 727/2000, Val Acc=0.6102, Val Loss=1.8049, lr=0.0100
[2025-05-07 05:56:59,834][train][INFO] - Epoch 728/2000, Val Acc=0.6131, Val Loss=1.7686, lr=0.0100
[2025-05-07 05:57:08,046][train][INFO] - Epoch 729/2000, Val Acc=0.6137, Val Loss=1.7456, lr=0.0100
[2025-05-07 05:57:16,220][train][INFO] - Epoch 730/2000, Val Acc=0.6250, Val Loss=1.6933, lr=0.0100
[2025-05-07 05:57:24,183][train][INFO] - Epoch 731/2000, Val Acc=0.5924, Val Loss=1.9405, lr=0.0100
[2025-05-07 05:57:31,620][train][INFO] - Epoch 732/2000, Val Acc=0.6254, Val Loss=1.7085, lr=0.0100
[2025-05-07 05:57:39,848][train][INFO] - Epoch 733/2000, Val Acc=0.6211, Val Loss=1.7633, lr=0.0100
[2025-05-07 05:57:47,812][train][INFO] - Epoch 734/2000, Val Acc=0.6131, Val Loss=1.7732, lr=0.0100
[2025-05-07 05:57:55,870][train][INFO] - Epoch 735/2000, Val Acc=0.6113, Val Loss=1.7858, lr=0.0100
[2025-05-07 05:58:03,815][train][INFO] - Epoch 736/2000, Val Acc=0.6162, Val Loss=1.7615, lr=0.0100
[2025-05-07 05:58:10,867][train][INFO] - Epoch 737/2000, Val Acc=0.6254, Val Loss=1.6989, lr=0.0100
[2025-05-07 05:58:19,315][train][INFO] - Epoch 738/2000, Val Acc=0.6173, Val Loss=1.7610, lr=0.0100
[2025-05-07 05:58:26,893][train][INFO] - Epoch 739/2000, Val Acc=0.6100, Val Loss=1.8067, lr=0.0100
[2025-05-07 05:58:35,022][train][INFO] - Epoch 740/2000, Val Acc=0.6126, Val Loss=1.7386, lr=0.0100
[2025-05-07 05:58:42,948][train][INFO] - Epoch 741/2000, Val Acc=0.6335, Val Loss=1.6640, lr=0.0100
[2025-05-07 05:58:50,977][train][INFO] - Epoch 742/2000, Val Acc=0.6217, Val Loss=1.7220, lr=0.0100
[2025-05-07 05:58:58,479][train][INFO] - Epoch 743/2000, Val Acc=0.6100, Val Loss=1.8110, lr=0.0100
[2025-05-07 05:59:06,385][train][INFO] - Epoch 744/2000, Val Acc=0.6302, Val Loss=1.7023, lr=0.0100
[2025-05-07 05:59:14,793][train][INFO] - Epoch 745/2000, Val Acc=0.6172, Val Loss=1.7047, lr=0.0100
[2025-05-07 05:59:23,180][train][INFO] - Epoch 746/2000, Val Acc=0.6250, Val Loss=1.7150, lr=0.0100
[2025-05-07 05:59:30,598][train][INFO] - Epoch 747/2000, Val Acc=0.6166, Val Loss=1.7412, lr=0.0100
[2025-05-07 05:59:38,937][train][INFO] - Epoch 748/2000, Val Acc=0.6267, Val Loss=1.7296, lr=0.0100
[2025-05-07 05:59:47,209][train][INFO] - Epoch 749/2000, Val Acc=0.5901, Val Loss=1.8995, lr=0.0100
[2025-05-07 05:59:54,168][train][INFO] - Epoch 750/2000, Val Acc=0.6018, Val Loss=1.8430, lr=0.0100
[2025-05-07 06:00:01,290][train][INFO] - Epoch 751/2000, Val Acc=0.6092, Val Loss=1.8092, lr=0.0100
[2025-05-07 06:00:08,621][train][INFO] - Epoch 752/2000, Val Acc=0.6145, Val Loss=1.7463, lr=0.0100
[2025-05-07 06:00:16,200][train][INFO] - Epoch 753/2000, Val Acc=0.5921, Val Loss=1.8998, lr=0.0100
[2025-05-07 06:00:23,783][train][INFO] - Epoch 754/2000, Val Acc=0.6152, Val Loss=1.7990, lr=0.0100
[2025-05-07 06:00:31,801][train][INFO] - Epoch 755/2000, Val Acc=0.6127, Val Loss=1.7319, lr=0.0100
[2025-05-07 06:00:38,251][train][INFO] - Epoch 756/2000, Val Acc=0.6299, Val Loss=1.6571, lr=0.0100
[2025-05-07 06:00:46,644][train][INFO] - Epoch 757/2000, Val Acc=0.6177, Val Loss=1.7610, lr=0.0100
[2025-05-07 06:00:54,230][train][INFO] - Epoch 758/2000, Val Acc=0.5997, Val Loss=1.8668, lr=0.0100
[2025-05-07 06:01:01,843][train][INFO] - Epoch 759/2000, Val Acc=0.6172, Val Loss=1.7391, lr=0.0100
[2025-05-07 06:01:09,763][train][INFO] - Epoch 760/2000, Val Acc=0.6212, Val Loss=1.7265, lr=0.0100
[2025-05-07 06:01:17,424][train][INFO] - Epoch 761/2000, Val Acc=0.5966, Val Loss=1.8786, lr=0.0100
[2025-05-07 06:01:25,143][train][INFO] - Epoch 762/2000, Val Acc=0.6125, Val Loss=1.7685, lr=0.0100
[2025-05-07 06:01:32,705][train][INFO] - Epoch 763/2000, Val Acc=0.6050, Val Loss=1.8333, lr=0.0100
[2025-05-07 06:01:41,100][train][INFO] - Epoch 764/2000, Val Acc=0.6176, Val Loss=1.7134, lr=0.0100
[2025-05-07 06:01:48,832][train][INFO] - Epoch 765/2000, Val Acc=0.6088, Val Loss=1.8106, lr=0.0100
[2025-05-07 06:01:56,821][train][INFO] - Epoch 766/2000, Val Acc=0.6007, Val Loss=1.8360, lr=0.0100
[2025-05-07 06:02:04,991][train][INFO] - Epoch 767/2000, Val Acc=0.6178, Val Loss=1.7603, lr=0.0100
[2025-05-07 06:02:12,750][train][INFO] - Epoch 768/2000, Val Acc=0.6122, Val Loss=1.7658, lr=0.0100
[2025-05-07 06:02:20,746][train][INFO] - Epoch 769/2000, Val Acc=0.6047, Val Loss=1.8277, lr=0.0100
[2025-05-07 06:02:28,505][train][INFO] - Epoch 770/2000, Val Acc=0.6030, Val Loss=1.8394, lr=0.0100
[2025-05-07 06:02:36,619][train][INFO] - Epoch 771/2000, Val Acc=0.6109, Val Loss=1.7307, lr=0.0100
[2025-05-07 06:02:44,995][train][INFO] - Epoch 772/2000, Val Acc=0.6128, Val Loss=1.7702, lr=0.0100
[2025-05-07 06:02:53,474][train][INFO] - Epoch 773/2000, Val Acc=0.6279, Val Loss=1.6877, lr=0.0100
[2025-05-07 06:03:01,288][train][INFO] - Epoch 774/2000, Val Acc=0.6176, Val Loss=1.7463, lr=0.0100
[2025-05-07 06:03:09,635][train][INFO] - Epoch 775/2000, Val Acc=0.6088, Val Loss=1.8267, lr=0.0100
[2025-05-07 06:03:16,894][train][INFO] - Epoch 776/2000, Val Acc=0.6170, Val Loss=1.7442, lr=0.0100
[2025-05-07 06:03:24,884][train][INFO] - Epoch 777/2000, Val Acc=0.6169, Val Loss=1.7549, lr=0.0100
[2025-05-07 06:03:33,481][train][INFO] - Epoch 778/2000, Val Acc=0.6242, Val Loss=1.6791, lr=0.0100
[2025-05-07 06:03:40,916][train][INFO] - Epoch 779/2000, Val Acc=0.6056, Val Loss=1.8471, lr=0.0100
[2025-05-07 06:03:48,124][train][INFO] - Epoch 780/2000, Val Acc=0.6139, Val Loss=1.7679, lr=0.0100
[2025-05-07 06:03:56,117][train][INFO] - Epoch 781/2000, Val Acc=0.6191, Val Loss=1.7369, lr=0.0100
[2025-05-07 06:04:04,092][train][INFO] - Epoch 782/2000, Val Acc=0.6285, Val Loss=1.6667, lr=0.0100
[2025-05-07 06:04:11,904][train][INFO] - Epoch 783/2000, Val Acc=0.6137, Val Loss=1.7908, lr=0.0100
[2025-05-07 06:04:19,876][train][INFO] - Epoch 784/2000, Val Acc=0.6239, Val Loss=1.7119, lr=0.0100
[2025-05-07 06:04:27,656][train][INFO] - Epoch 785/2000, Val Acc=0.6208, Val Loss=1.7435, lr=0.0100
[2025-05-07 06:04:35,894][train][INFO] - Epoch 786/2000, Val Acc=0.6049, Val Loss=1.7819, lr=0.0100
[2025-05-07 06:04:43,823][train][INFO] - Epoch 787/2000, Val Acc=0.6239, Val Loss=1.7350, lr=0.0100
[2025-05-07 06:04:52,202][train][INFO] - Epoch 788/2000, Val Acc=0.6259, Val Loss=1.7139, lr=0.0100
[2025-05-07 06:04:59,755][train][INFO] - Epoch 789/2000, Val Acc=0.6170, Val Loss=1.7367, lr=0.0100
[2025-05-07 06:05:07,700][train][INFO] - Epoch 790/2000, Val Acc=0.6191, Val Loss=1.7622, lr=0.0100
[2025-05-07 06:05:15,286][train][INFO] - Epoch 791/2000, Val Acc=0.6015, Val Loss=1.8812, lr=0.0100
[2025-05-07 06:05:23,291][train][INFO] - Epoch 792/2000, Val Acc=0.6141, Val Loss=1.7099, lr=0.0100
[2025-05-07 06:05:31,610][train][INFO] - Epoch 793/2000, Val Acc=0.6155, Val Loss=1.7514, lr=0.0100
[2025-05-07 06:05:38,641][train][INFO] - Epoch 794/2000, Val Acc=0.6275, Val Loss=1.7389, lr=0.0100
[2025-05-07 06:05:46,431][train][INFO] - Epoch 795/2000, Val Acc=0.6067, Val Loss=1.8112, lr=0.0100
[2025-05-07 06:05:54,282][train][INFO] - Epoch 796/2000, Val Acc=0.6130, Val Loss=1.7634, lr=0.0100
[2025-05-07 06:06:02,360][train][INFO] - Epoch 797/2000, Val Acc=0.6186, Val Loss=1.7305, lr=0.0100
[2025-05-07 06:06:10,554][train][INFO] - Epoch 798/2000, Val Acc=0.6170, Val Loss=1.7811, lr=0.0100
[2025-05-07 06:06:17,174][train][INFO] - Epoch 799/2000, Val Acc=0.6101, Val Loss=1.7860, lr=0.0100
[2025-05-07 06:06:25,497][train][INFO] - Epoch 800/2000, Val Acc=0.5979, Val Loss=1.8881, lr=0.0100
[2025-05-07 06:06:32,366][train][INFO] - Epoch 801/2000, Val Acc=0.6124, Val Loss=1.7569, lr=0.0100
[2025-05-07 06:06:40,290][train][INFO] - Epoch 802/2000, Val Acc=0.6010, Val Loss=1.7955, lr=0.0100
[2025-05-07 06:06:47,847][train][INFO] - Epoch 803/2000, Val Acc=0.6149, Val Loss=1.7741, lr=0.0100
[2025-05-07 06:06:55,843][train][INFO] - Epoch 804/2000, Val Acc=0.5990, Val Loss=1.8392, lr=0.0100
[2025-05-07 06:07:03,324][train][INFO] - Epoch 805/2000, Val Acc=0.6089, Val Loss=1.8345, lr=0.0100
[2025-05-07 06:07:11,336][train][INFO] - Epoch 806/2000, Val Acc=0.6233, Val Loss=1.7523, lr=0.0100
[2025-05-07 06:07:18,866][train][INFO] - Epoch 807/2000, Val Acc=0.6251, Val Loss=1.7692, lr=0.0100
[2025-05-07 06:07:26,395][train][INFO] - Epoch 808/2000, Val Acc=0.6115, Val Loss=1.7834, lr=0.0100
[2025-05-07 06:07:34,708][train][INFO] - Epoch 809/2000, Val Acc=0.6057, Val Loss=1.7916, lr=0.0100
[2025-05-07 06:07:42,455][train][INFO] - Epoch 810/2000, Val Acc=0.6166, Val Loss=1.7834, lr=0.0100
[2025-05-07 06:07:50,091][train][INFO] - Epoch 811/2000, Val Acc=0.6166, Val Loss=1.7774, lr=0.0100
[2025-05-07 06:07:57,598][train][INFO] - Epoch 812/2000, Val Acc=0.6141, Val Loss=1.7289, lr=0.0100
[2025-05-07 06:08:05,322][train][INFO] - Epoch 813/2000, Val Acc=0.6000, Val Loss=1.8535, lr=0.0100
[2025-05-07 06:08:12,971][train][INFO] - Epoch 814/2000, Val Acc=0.6146, Val Loss=1.7809, lr=0.0100
[2025-05-07 06:08:21,034][train][INFO] - Epoch 815/2000, Val Acc=0.6154, Val Loss=1.7790, lr=0.0100
[2025-05-07 06:08:29,301][train][INFO] - Epoch 816/2000, Val Acc=0.6087, Val Loss=1.7894, lr=0.0100
[2025-05-07 06:08:37,132][train][INFO] - Epoch 817/2000, Val Acc=0.6203, Val Loss=1.7384, lr=0.0100
[2025-05-07 06:08:45,078][train][INFO] - Epoch 818/2000, Val Acc=0.6199, Val Loss=1.7532, lr=0.0100
[2025-05-07 06:08:51,870][train][INFO] - Epoch 819/2000, Val Acc=0.6095, Val Loss=1.8115, lr=0.0100
[2025-05-07 06:08:59,726][train][INFO] - Epoch 820/2000, Val Acc=0.6234, Val Loss=1.7189, lr=0.0100
[2025-05-07 06:09:07,725][train][INFO] - Epoch 821/2000, Val Acc=0.6011, Val Loss=1.8835, lr=0.0100
[2025-05-07 06:09:15,865][train][INFO] - Epoch 822/2000, Val Acc=0.6173, Val Loss=1.7696, lr=0.0100
[2025-05-07 06:09:23,528][train][INFO] - Epoch 823/2000, Val Acc=0.5922, Val Loss=1.9502, lr=0.0100
[2025-05-07 06:09:31,596][train][INFO] - Epoch 824/2000, Val Acc=0.6216, Val Loss=1.7156, lr=0.0100
[2025-05-07 06:09:39,237][train][INFO] - Epoch 825/2000, Val Acc=0.6060, Val Loss=1.7948, lr=0.0100
[2025-05-07 06:09:46,646][train][INFO] - Epoch 826/2000, Val Acc=0.6113, Val Loss=1.7508, lr=0.0100
[2025-05-07 06:09:55,223][train][INFO] - Epoch 827/2000, Val Acc=0.6093, Val Loss=1.7703, lr=0.0100
[2025-05-07 06:10:03,397][train][INFO] - Epoch 828/2000, Val Acc=0.6104, Val Loss=1.7685, lr=0.0100
[2025-05-07 06:10:10,588][train][INFO] - Epoch 829/2000, Val Acc=0.6071, Val Loss=1.8247, lr=0.0100
[2025-05-07 06:10:18,355][train][INFO] - Epoch 830/2000, Val Acc=0.6339, Val Loss=1.6896, lr=0.0100
[2025-05-07 06:10:26,510][train][INFO] - Epoch 831/2000, Val Acc=0.6207, Val Loss=1.7128, lr=0.0100
[2025-05-07 06:10:33,998][train][INFO] - Epoch 832/2000, Val Acc=0.6223, Val Loss=1.7241, lr=0.0100
[2025-05-07 06:10:41,721][train][INFO] - Epoch 833/2000, Val Acc=0.5917, Val Loss=1.9310, lr=0.0100
[2025-05-07 06:10:49,038][train][INFO] - Epoch 834/2000, Val Acc=0.6055, Val Loss=1.8306, lr=0.0100
[2025-05-07 06:10:57,207][train][INFO] - Epoch 835/2000, Val Acc=0.6163, Val Loss=1.7374, lr=0.0100
[2025-05-07 06:11:04,977][train][INFO] - Epoch 836/2000, Val Acc=0.5909, Val Loss=1.8790, lr=0.0100
[2025-05-07 06:11:12,684][train][INFO] - Epoch 837/2000, Val Acc=0.6035, Val Loss=1.8249, lr=0.0100
[2025-05-07 06:11:20,512][train][INFO] - Epoch 838/2000, Val Acc=0.6160, Val Loss=1.7553, lr=0.0100
[2025-05-07 06:11:28,151][train][INFO] - Epoch 839/2000, Val Acc=0.6183, Val Loss=1.6956, lr=0.0100
[2025-05-07 06:11:35,806][train][INFO] - Epoch 840/2000, Val Acc=0.6203, Val Loss=1.7639, lr=0.0100
[2025-05-07 06:11:43,303][train][INFO] - Epoch 841/2000, Val Acc=0.5907, Val Loss=1.9147, lr=0.0100
[2025-05-07 06:11:50,355][train][INFO] - Epoch 842/2000, Val Acc=0.6226, Val Loss=1.7105, lr=0.0100
[2025-05-07 06:11:58,012][train][INFO] - Epoch 843/2000, Val Acc=0.6108, Val Loss=1.7744, lr=0.0100
[2025-05-07 06:12:05,813][train][INFO] - Epoch 844/2000, Val Acc=0.6157, Val Loss=1.7178, lr=0.0100
[2025-05-07 06:12:13,660][train][INFO] - Epoch 845/2000, Val Acc=0.5982, Val Loss=1.8829, lr=0.0100
[2025-05-07 06:12:21,423][train][INFO] - Epoch 846/2000, Val Acc=0.6157, Val Loss=1.7473, lr=0.0100
[2025-05-07 06:12:29,542][train][INFO] - Epoch 847/2000, Val Acc=0.6059, Val Loss=1.8162, lr=0.0100
[2025-05-07 06:12:37,197][train][INFO] - Epoch 848/2000, Val Acc=0.6207, Val Loss=1.7225, lr=0.0100
[2025-05-07 06:12:45,414][train][INFO] - Epoch 849/2000, Val Acc=0.6100, Val Loss=1.8275, lr=0.0100
[2025-05-07 06:12:53,707][train][INFO] - Epoch 850/2000, Val Acc=0.6208, Val Loss=1.7177, lr=0.0100
[2025-05-07 06:13:01,677][train][INFO] - Epoch 851/2000, Val Acc=0.6118, Val Loss=1.7427, lr=0.0100
[2025-05-07 06:13:09,663][train][INFO] - Epoch 852/2000, Val Acc=0.6018, Val Loss=1.8359, lr=0.0100
[2025-05-07 06:13:17,345][train][INFO] - Epoch 853/2000, Val Acc=0.6205, Val Loss=1.7588, lr=0.0100
[2025-05-07 06:13:24,835][train][INFO] - Epoch 854/2000, Val Acc=0.6125, Val Loss=1.7695, lr=0.0100
[2025-05-07 06:13:32,581][train][INFO] - Epoch 855/2000, Val Acc=0.6023, Val Loss=1.8359, lr=0.0100
[2025-05-07 06:13:40,230][train][INFO] - Epoch 856/2000, Val Acc=0.6163, Val Loss=1.7309, lr=0.0100
[2025-05-07 06:13:47,891][train][INFO] - Epoch 857/2000, Val Acc=0.6171, Val Loss=1.7703, lr=0.0100
[2025-05-07 06:13:55,398][train][INFO] - Epoch 858/2000, Val Acc=0.6052, Val Loss=1.8026, lr=0.0100
[2025-05-07 06:14:03,318][train][INFO] - Epoch 859/2000, Val Acc=0.6039, Val Loss=1.8315, lr=0.0100
[2025-05-07 06:14:11,142][train][INFO] - Epoch 860/2000, Val Acc=0.6164, Val Loss=1.7914, lr=0.0100
[2025-05-07 06:14:18,244][train][INFO] - Epoch 861/2000, Val Acc=0.6219, Val Loss=1.7399, lr=0.0100
[2025-05-07 06:14:25,287][train][INFO] - Epoch 862/2000, Val Acc=0.6047, Val Loss=1.8094, lr=0.0100
[2025-05-07 06:14:33,529][train][INFO] - Epoch 863/2000, Val Acc=0.5965, Val Loss=1.8686, lr=0.0100
[2025-05-07 06:14:41,844][train][INFO] - Epoch 864/2000, Val Acc=0.6396, Val Loss=1.6504, lr=0.0100
[2025-05-07 06:14:49,545][train][INFO] - Epoch 865/2000, Val Acc=0.5999, Val Loss=1.8573, lr=0.0100
[2025-05-07 06:14:57,014][train][INFO] - Epoch 866/2000, Val Acc=0.6223, Val Loss=1.6939, lr=0.0100
[2025-05-07 06:15:04,538][train][INFO] - Epoch 867/2000, Val Acc=0.5941, Val Loss=1.9238, lr=0.0100
[2025-05-07 06:15:12,885][train][INFO] - Epoch 868/2000, Val Acc=0.6008, Val Loss=1.8274, lr=0.0100
[2025-05-07 06:15:20,907][train][INFO] - Epoch 869/2000, Val Acc=0.5974, Val Loss=1.8578, lr=0.0100
[2025-05-07 06:15:28,863][train][INFO] - Epoch 870/2000, Val Acc=0.6132, Val Loss=1.7717, lr=0.0100
[2025-05-07 06:15:35,782][train][INFO] - Epoch 871/2000, Val Acc=0.5997, Val Loss=1.8406, lr=0.0100
[2025-05-07 06:15:43,572][train][INFO] - Epoch 872/2000, Val Acc=0.6121, Val Loss=1.7435, lr=0.0100
[2025-05-07 06:15:49,870][train][INFO] - Epoch 873/2000, Val Acc=0.6203, Val Loss=1.7410, lr=0.0100
[2025-05-07 06:15:57,346][train][INFO] - Epoch 874/2000, Val Acc=0.5965, Val Loss=1.8242, lr=0.0100
[2025-05-07 06:16:05,380][train][INFO] - Epoch 875/2000, Val Acc=0.6026, Val Loss=1.8640, lr=0.0100
[2025-05-07 06:16:12,643][train][INFO] - Epoch 876/2000, Val Acc=0.6183, Val Loss=1.7411, lr=0.0100
[2025-05-07 06:16:20,205][train][INFO] - Epoch 877/2000, Val Acc=0.6219, Val Loss=1.7476, lr=0.0100
[2025-05-07 06:16:28,089][train][INFO] - Epoch 878/2000, Val Acc=0.5960, Val Loss=1.8807, lr=0.0100
[2025-05-07 06:16:36,000][train][INFO] - Epoch 879/2000, Val Acc=0.6203, Val Loss=1.7455, lr=0.0100
[2025-05-07 06:16:43,988][train][INFO] - Epoch 880/2000, Val Acc=0.6126, Val Loss=1.7987, lr=0.0100
[2025-05-07 06:16:51,441][train][INFO] - Epoch 881/2000, Val Acc=0.6301, Val Loss=1.7067, lr=0.0100
[2025-05-07 06:16:58,470][train][INFO] - Epoch 882/2000, Val Acc=0.6149, Val Loss=1.7371, lr=0.0100
[2025-05-07 06:17:05,420][train][INFO] - Epoch 883/2000, Val Acc=0.6196, Val Loss=1.7356, lr=0.0100
[2025-05-07 06:17:13,300][train][INFO] - Epoch 884/2000, Val Acc=0.6072, Val Loss=1.7949, lr=0.0100
[2025-05-07 06:17:21,222][train][INFO] - Epoch 885/2000, Val Acc=0.6069, Val Loss=1.7787, lr=0.0100
[2025-05-07 06:17:28,787][train][INFO] - Epoch 886/2000, Val Acc=0.6040, Val Loss=1.8670, lr=0.0100
[2025-05-07 06:17:36,714][train][INFO] - Epoch 887/2000, Val Acc=0.6280, Val Loss=1.6535, lr=0.0100
[2025-05-07 06:17:44,999][train][INFO] - Epoch 888/2000, Val Acc=0.6240, Val Loss=1.7071, lr=0.0100
[2025-05-07 06:17:52,993][train][INFO] - Epoch 889/2000, Val Acc=0.5992, Val Loss=1.8250, lr=0.0100
[2025-05-07 06:18:00,818][train][INFO] - Epoch 890/2000, Val Acc=0.6044, Val Loss=1.7999, lr=0.0100
[2025-05-07 06:18:08,685][train][INFO] - Epoch 891/2000, Val Acc=0.6050, Val Loss=1.7832, lr=0.0100
[2025-05-07 06:18:16,108][train][INFO] - Epoch 892/2000, Val Acc=0.6153, Val Loss=1.7595, lr=0.0100
[2025-05-07 06:18:24,212][train][INFO] - Epoch 893/2000, Val Acc=0.6147, Val Loss=1.7609, lr=0.0100
[2025-05-07 06:18:32,720][train][INFO] - Epoch 894/2000, Val Acc=0.5893, Val Loss=1.8838, lr=0.0100
[2025-05-07 06:18:40,636][train][INFO] - Epoch 895/2000, Val Acc=0.5968, Val Loss=1.8388, lr=0.0100
[2025-05-07 06:18:48,802][train][INFO] - Epoch 896/2000, Val Acc=0.6159, Val Loss=1.7489, lr=0.0100
[2025-05-07 06:18:55,426][train][INFO] - Epoch 897/2000, Val Acc=0.6019, Val Loss=1.8211, lr=0.0100
[2025-05-07 06:19:03,340][train][INFO] - Epoch 898/2000, Val Acc=0.6062, Val Loss=1.8173, lr=0.0100
[2025-05-07 06:19:10,983][train][INFO] - Epoch 899/2000, Val Acc=0.6266, Val Loss=1.6982, lr=0.0100
[2025-05-07 06:19:18,911][train][INFO] - Epoch 900/2000, Val Acc=0.6069, Val Loss=1.8459, lr=0.0100
[2025-05-07 06:19:26,883][train][INFO] - Epoch 901/2000, Val Acc=0.6262, Val Loss=1.7284, lr=0.0100
[2025-05-07 06:19:34,193][train][INFO] - Epoch 902/2000, Val Acc=0.6147, Val Loss=1.7556, lr=0.0100
[2025-05-07 06:19:42,510][train][INFO] - Epoch 903/2000, Val Acc=0.6213, Val Loss=1.7348, lr=0.0100
[2025-05-07 06:19:49,925][train][INFO] - Epoch 904/2000, Val Acc=0.6161, Val Loss=1.7464, lr=0.0100
[2025-05-07 06:19:57,914][train][INFO] - Epoch 905/2000, Val Acc=0.6121, Val Loss=1.7557, lr=0.0100
[2025-05-07 06:20:04,373][train][INFO] - Epoch 906/2000, Val Acc=0.6118, Val Loss=1.7863, lr=0.0100
[2025-05-07 06:20:12,469][train][INFO] - Epoch 907/2000, Val Acc=0.6100, Val Loss=1.7137, lr=0.0100
[2025-05-07 06:20:20,536][train][INFO] - Epoch 908/2000, Val Acc=0.6195, Val Loss=1.7550, lr=0.0100
[2025-05-07 06:20:28,865][train][INFO] - Epoch 909/2000, Val Acc=0.6201, Val Loss=1.7082, lr=0.0100
[2025-05-07 06:20:36,225][train][INFO] - Epoch 910/2000, Val Acc=0.6196, Val Loss=1.7173, lr=0.0100
[2025-05-07 06:20:44,455][train][INFO] - Epoch 911/2000, Val Acc=0.5975, Val Loss=1.8361, lr=0.0100
[2025-05-07 06:20:52,804][train][INFO] - Epoch 912/2000, Val Acc=0.6128, Val Loss=1.7780, lr=0.0100
[2025-05-07 06:21:00,964][train][INFO] - Epoch 913/2000, Val Acc=0.6072, Val Loss=1.8099, lr=0.0100
[2025-05-07 06:21:08,584][train][INFO] - Epoch 914/2000, Val Acc=0.6188, Val Loss=1.7409, lr=0.0100
[2025-05-07 06:21:16,852][train][INFO] - Epoch 915/2000, Val Acc=0.6136, Val Loss=1.7576, lr=0.0100
[2025-05-07 06:21:24,913][train][INFO] - Epoch 916/2000, Val Acc=0.6156, Val Loss=1.7642, lr=0.0100
[2025-05-07 06:21:33,137][train][INFO] - Epoch 917/2000, Val Acc=0.6057, Val Loss=1.8155, lr=0.0100
[2025-05-07 06:21:41,209][train][INFO] - Epoch 918/2000, Val Acc=0.6202, Val Loss=1.7363, lr=0.0100
[2025-05-07 06:21:49,233][train][INFO] - Epoch 919/2000, Val Acc=0.6164, Val Loss=1.7692, lr=0.0100
[2025-05-07 06:21:56,318][train][INFO] - Epoch 920/2000, Val Acc=0.6234, Val Loss=1.7157, lr=0.0100
[2025-05-07 06:22:03,805][train][INFO] - Epoch 921/2000, Val Acc=0.6089, Val Loss=1.7630, lr=0.0100
[2025-05-07 06:22:11,866][train][INFO] - Epoch 922/2000, Val Acc=0.6059, Val Loss=1.8428, lr=0.0100
[2025-05-07 06:22:20,476][train][INFO] - Epoch 923/2000, Val Acc=0.6180, Val Loss=1.7236, lr=0.0100
[2025-05-07 06:22:28,250][train][INFO] - Epoch 924/2000, Val Acc=0.6162, Val Loss=1.7947, lr=0.0100
[2025-05-07 06:22:36,838][train][INFO] - Epoch 925/2000, Val Acc=0.6075, Val Loss=1.8370, lr=0.0100
[2025-05-07 06:22:44,289][train][INFO] - Epoch 926/2000, Val Acc=0.6067, Val Loss=1.7996, lr=0.0100
[2025-05-07 06:22:51,722][train][INFO] - Epoch 927/2000, Val Acc=0.6181, Val Loss=1.7477, lr=0.0100
[2025-05-07 06:22:58,703][train][INFO] - Epoch 928/2000, Val Acc=0.6031, Val Loss=1.8071, lr=0.0100
[2025-05-07 06:23:06,748][train][INFO] - Epoch 929/2000, Val Acc=0.5933, Val Loss=1.8929, lr=0.0100
[2025-05-07 06:23:14,877][train][INFO] - Epoch 930/2000, Val Acc=0.6182, Val Loss=1.7087, lr=0.0100
[2025-05-07 06:23:22,566][train][INFO] - Epoch 931/2000, Val Acc=0.6118, Val Loss=1.8174, lr=0.0100
[2025-05-07 06:23:30,709][train][INFO] - Epoch 932/2000, Val Acc=0.6135, Val Loss=1.7569, lr=0.0100
[2025-05-07 06:23:38,326][train][INFO] - Epoch 933/2000, Val Acc=0.6135, Val Loss=1.7561, lr=0.0100
[2025-05-07 06:23:46,462][train][INFO] - Epoch 934/2000, Val Acc=0.6146, Val Loss=1.7231, lr=0.0100
[2025-05-07 06:23:53,999][train][INFO] - Epoch 935/2000, Val Acc=0.6068, Val Loss=1.7503, lr=0.0100
[2025-05-07 06:24:01,863][train][INFO] - Epoch 936/2000, Val Acc=0.6102, Val Loss=1.8595, lr=0.0100
[2025-05-07 06:24:10,538][train][INFO] - Epoch 937/2000, Val Acc=0.6088, Val Loss=1.7892, lr=0.0100
[2025-05-07 06:24:18,719][train][INFO] - Epoch 938/2000, Val Acc=0.6241, Val Loss=1.7348, lr=0.0100
[2025-05-07 06:24:26,884][train][INFO] - Epoch 939/2000, Val Acc=0.6213, Val Loss=1.7404, lr=0.0100
[2025-05-07 06:24:35,032][train][INFO] - Epoch 940/2000, Val Acc=0.6051, Val Loss=1.8744, lr=0.0100
[2025-05-07 06:24:42,280][train][INFO] - Epoch 941/2000, Val Acc=0.6180, Val Loss=1.7648, lr=0.0100
[2025-05-07 06:24:50,439][train][INFO] - Epoch 942/2000, Val Acc=0.6130, Val Loss=1.7924, lr=0.0100
[2025-05-07 06:24:58,761][train][INFO] - Epoch 943/2000, Val Acc=0.6197, Val Loss=1.6955, lr=0.0100
[2025-05-07 06:25:06,932][train][INFO] - Epoch 944/2000, Val Acc=0.6164, Val Loss=1.7714, lr=0.0100
[2025-05-07 06:25:14,460][train][INFO] - Epoch 945/2000, Val Acc=0.6148, Val Loss=1.7647, lr=0.0100
[2025-05-07 06:25:22,027][train][INFO] - Epoch 946/2000, Val Acc=0.6081, Val Loss=1.7682, lr=0.0100
[2025-05-07 06:25:29,469][train][INFO] - Epoch 947/2000, Val Acc=0.6222, Val Loss=1.7247, lr=0.0100
[2025-05-07 06:25:37,173][train][INFO] - Epoch 948/2000, Val Acc=0.6142, Val Loss=1.7640, lr=0.0100
[2025-05-07 06:25:43,847][train][INFO] - Epoch 949/2000, Val Acc=0.6038, Val Loss=1.8591, lr=0.0100
[2025-05-07 06:25:52,090][train][INFO] - Epoch 950/2000, Val Acc=0.5895, Val Loss=1.9308, lr=0.0100
[2025-05-07 06:26:00,488][train][INFO] - Epoch 951/2000, Val Acc=0.6048, Val Loss=1.8582, lr=0.0100
[2025-05-07 06:26:08,346][train][INFO] - Epoch 952/2000, Val Acc=0.6074, Val Loss=1.8292, lr=0.0100
[2025-05-07 06:26:17,168][train][INFO] - Epoch 953/2000, Val Acc=0.6113, Val Loss=1.7803, lr=0.0100
[2025-05-07 06:26:24,963][train][INFO] - Epoch 954/2000, Val Acc=0.6089, Val Loss=1.8003, lr=0.0100
[2025-05-07 06:26:31,884][train][INFO] - Epoch 955/2000, Val Acc=0.6131, Val Loss=1.7461, lr=0.0100
[2025-05-07 06:26:38,919][train][INFO] - Epoch 956/2000, Val Acc=0.6176, Val Loss=1.7149, lr=0.0100
[2025-05-07 06:26:46,794][train][INFO] - Epoch 957/2000, Val Acc=0.6047, Val Loss=1.8153, lr=0.0100
[2025-05-07 06:26:53,184][train][INFO] - Epoch 958/2000, Val Acc=0.6029, Val Loss=1.8020, lr=0.0100
[2025-05-07 06:27:00,460][train][INFO] - Epoch 959/2000, Val Acc=0.6109, Val Loss=1.7397, lr=0.0100
[2025-05-07 06:27:08,517][train][INFO] - Epoch 960/2000, Val Acc=0.5972, Val Loss=1.8855, lr=0.0100
[2025-05-07 06:27:16,392][train][INFO] - Epoch 961/2000, Val Acc=0.6129, Val Loss=1.7845, lr=0.0100
[2025-05-07 06:27:24,564][train][INFO] - Epoch 962/2000, Val Acc=0.6017, Val Loss=1.8537, lr=0.0100
[2025-05-07 06:27:32,779][train][INFO] - Epoch 963/2000, Val Acc=0.6212, Val Loss=1.6979, lr=0.0100
[2025-05-07 06:27:40,196][train][INFO] - Epoch 964/2000, Val Acc=0.6214, Val Loss=1.7164, lr=0.0100
[2025-05-07 06:27:48,793][train][INFO] - Epoch 965/2000, Val Acc=0.6147, Val Loss=1.7567, lr=0.0100
[2025-05-07 06:27:57,139][train][INFO] - Epoch 966/2000, Val Acc=0.6098, Val Loss=1.7433, lr=0.0100
[2025-05-07 06:28:05,087][train][INFO] - Epoch 967/2000, Val Acc=0.6148, Val Loss=1.7700, lr=0.0100
[2025-05-07 06:28:12,158][train][INFO] - Epoch 968/2000, Val Acc=0.6252, Val Loss=1.6847, lr=0.0100
[2025-05-07 06:28:20,060][train][INFO] - Epoch 969/2000, Val Acc=0.6144, Val Loss=1.7464, lr=0.0100
[2025-05-07 06:28:28,929][train][INFO] - Epoch 970/2000, Val Acc=0.6038, Val Loss=1.8275, lr=0.0100
[2025-05-07 06:28:36,459][train][INFO] - Epoch 971/2000, Val Acc=0.6046, Val Loss=1.8046, lr=0.0100
[2025-05-07 06:28:44,959][train][INFO] - Epoch 972/2000, Val Acc=0.6141, Val Loss=1.7572, lr=0.0100
[2025-05-07 06:28:53,001][train][INFO] - Epoch 973/2000, Val Acc=0.6026, Val Loss=1.8469, lr=0.0100
[2025-05-07 06:29:01,402][train][INFO] - Epoch 974/2000, Val Acc=0.6197, Val Loss=1.7310, lr=0.0100
[2025-05-07 06:29:10,144][train][INFO] - Epoch 975/2000, Val Acc=0.6212, Val Loss=1.7080, lr=0.0100
[2025-05-07 06:29:19,032][train][INFO] - Epoch 976/2000, Val Acc=0.6124, Val Loss=1.7841, lr=0.0100
[2025-05-07 06:29:27,277][train][INFO] - Epoch 977/2000, Val Acc=0.6147, Val Loss=1.7535, lr=0.0100
[2025-05-07 06:29:36,419][train][INFO] - Epoch 978/2000, Val Acc=0.6163, Val Loss=1.7402, lr=0.0100
[2025-05-07 06:29:44,766][train][INFO] - Epoch 979/2000, Val Acc=0.6121, Val Loss=1.8185, lr=0.0100
[2025-05-07 06:29:53,051][train][INFO] - Epoch 980/2000, Val Acc=0.6123, Val Loss=1.7630, lr=0.0100
[2025-05-07 06:30:00,621][train][INFO] - Epoch 981/2000, Val Acc=0.6242, Val Loss=1.7425, lr=0.0100
[2025-05-07 06:30:08,856][train][INFO] - Epoch 982/2000, Val Acc=0.6043, Val Loss=1.8543, lr=0.0100
[2025-05-07 06:30:16,735][train][INFO] - Epoch 983/2000, Val Acc=0.6128, Val Loss=1.8000, lr=0.0100
[2025-05-07 06:30:24,627][train][INFO] - Epoch 984/2000, Val Acc=0.6169, Val Loss=1.7979, lr=0.0100
[2025-05-07 06:30:33,160][train][INFO] - Epoch 985/2000, Val Acc=0.6148, Val Loss=1.7823, lr=0.0100
[2025-05-07 06:30:41,048][train][INFO] - Epoch 986/2000, Val Acc=0.6047, Val Loss=1.8198, lr=0.0100
[2025-05-07 06:30:49,358][train][INFO] - Epoch 987/2000, Val Acc=0.6133, Val Loss=1.7893, lr=0.0100
[2025-05-07 06:30:57,394][train][INFO] - Epoch 988/2000, Val Acc=0.6298, Val Loss=1.7019, lr=0.0100
[2025-05-07 06:31:05,642][train][INFO] - Epoch 989/2000, Val Acc=0.6099, Val Loss=1.7856, lr=0.0100
[2025-05-07 06:31:14,638][train][INFO] - Epoch 990/2000, Val Acc=0.6126, Val Loss=1.7673, lr=0.0100
[2025-05-07 06:31:23,245][train][INFO] - Epoch 991/2000, Val Acc=0.6084, Val Loss=1.8462, lr=0.0100
[2025-05-07 06:31:31,389][train][INFO] - Epoch 992/2000, Val Acc=0.6136, Val Loss=1.7755, lr=0.0100
[2025-05-07 06:31:39,380][train][INFO] - Epoch 993/2000, Val Acc=0.6112, Val Loss=1.8032, lr=0.0100
[2025-05-07 06:31:47,579][train][INFO] - Epoch 994/2000, Val Acc=0.6146, Val Loss=1.7848, lr=0.0100
[2025-05-07 06:31:56,313][train][INFO] - Epoch 995/2000, Val Acc=0.6112, Val Loss=1.7735, lr=0.0100
[2025-05-07 06:32:04,713][train][INFO] - Epoch 996/2000, Val Acc=0.6225, Val Loss=1.7201, lr=0.0100
[2025-05-07 06:32:12,976][train][INFO] - Epoch 997/2000, Val Acc=0.6083, Val Loss=1.8117, lr=0.0100
[2025-05-07 06:32:21,132][train][INFO] - Epoch 998/2000, Val Acc=0.6063, Val Loss=1.8046, lr=0.0100
[2025-05-07 06:32:29,351][train][INFO] - Epoch 999/2000, Val Acc=0.6219, Val Loss=1.7268, lr=0.0100
[2025-05-07 06:32:37,492][train][INFO] - Epoch 1000/2000, Val Acc=0.5989, Val Loss=1.8586, lr=0.0100
[2025-05-07 06:32:45,909][train][INFO] - Epoch 1001/2000, Val Acc=0.6240, Val Loss=1.7192, lr=0.0100
[2025-05-07 06:32:54,653][train][INFO] - Epoch 1002/2000, Val Acc=0.6127, Val Loss=1.8326, lr=0.0100
[2025-05-07 06:33:03,139][train][INFO] - Epoch 1003/2000, Val Acc=0.6169, Val Loss=1.7292, lr=0.0100
[2025-05-07 06:33:11,374][train][INFO] - Epoch 1004/2000, Val Acc=0.6163, Val Loss=1.7981, lr=0.0100
[2025-05-07 06:33:19,896][train][INFO] - Epoch 1005/2000, Val Acc=0.5936, Val Loss=1.8804, lr=0.0100
[2025-05-07 06:33:27,601][train][INFO] - Epoch 1006/2000, Val Acc=0.6241, Val Loss=1.6900, lr=0.0100
[2025-05-07 06:33:36,298][train][INFO] - Epoch 1007/2000, Val Acc=0.6227, Val Loss=1.7034, lr=0.0100
[2025-05-07 06:33:44,896][train][INFO] - Epoch 1008/2000, Val Acc=0.6103, Val Loss=1.8216, lr=0.0100
[2025-05-07 06:33:53,469][train][INFO] - Epoch 1009/2000, Val Acc=0.6146, Val Loss=1.7585, lr=0.0100
[2025-05-07 06:34:00,908][train][INFO] - Epoch 1010/2000, Val Acc=0.6164, Val Loss=1.7341, lr=0.0100
[2025-05-07 06:34:09,348][train][INFO] - Epoch 1011/2000, Val Acc=0.6078, Val Loss=1.8260, lr=0.0100
[2025-05-07 06:34:17,452][train][INFO] - Epoch 1012/2000, Val Acc=0.6096, Val Loss=1.8021, lr=0.0100
[2025-05-07 06:34:25,482][train][INFO] - Epoch 1013/2000, Val Acc=0.6161, Val Loss=1.8061, lr=0.0100
[2025-05-07 06:34:34,350][train][INFO] - Epoch 1014/2000, Val Acc=0.6157, Val Loss=1.8115, lr=0.0100
[2025-05-07 06:34:42,933][train][INFO] - Epoch 1015/2000, Val Acc=0.6235, Val Loss=1.7274, lr=0.0100
[2025-05-07 06:34:50,706][train][INFO] - Epoch 1016/2000, Val Acc=0.6170, Val Loss=1.7525, lr=0.0100
[2025-05-07 06:34:58,530][train][INFO] - Epoch 1017/2000, Val Acc=0.6101, Val Loss=1.7915, lr=0.0100
[2025-05-07 06:35:06,295][train][INFO] - Epoch 1018/2000, Val Acc=0.6170, Val Loss=1.7785, lr=0.0100
[2025-05-07 06:35:13,955][train][INFO] - Epoch 1019/2000, Val Acc=0.6077, Val Loss=1.7956, lr=0.0100
[2025-05-07 06:35:22,281][train][INFO] - Epoch 1020/2000, Val Acc=0.6105, Val Loss=1.8319, lr=0.0100
[2025-05-07 06:35:29,814][train][INFO] - Epoch 1021/2000, Val Acc=0.6196, Val Loss=1.7384, lr=0.0100
[2025-05-07 06:35:37,290][train][INFO] - Epoch 1022/2000, Val Acc=0.6268, Val Loss=1.6991, lr=0.0100
[2025-05-07 06:35:45,301][train][INFO] - Epoch 1023/2000, Val Acc=0.6146, Val Loss=1.7686, lr=0.0100
[2025-05-07 06:35:52,121][train][INFO] - Epoch 1024/2000, Val Acc=0.6188, Val Loss=1.7641, lr=0.0100
[2025-05-07 06:35:59,808][train][INFO] - Epoch 1025/2000, Val Acc=0.6228, Val Loss=1.7323, lr=0.0100
[2025-05-07 06:36:07,332][train][INFO] - Epoch 1026/2000, Val Acc=0.6121, Val Loss=1.7520, lr=0.0100
[2025-05-07 06:36:15,166][train][INFO] - Epoch 1027/2000, Val Acc=0.6156, Val Loss=1.7907, lr=0.0100
[2025-05-07 06:36:22,051][train][INFO] - Epoch 1028/2000, Val Acc=0.6005, Val Loss=1.8267, lr=0.0100
[2025-05-07 06:36:30,240][train][INFO] - Epoch 1029/2000, Val Acc=0.6072, Val Loss=1.8243, lr=0.0100
[2025-05-07 06:36:38,499][train][INFO] - Epoch 1030/2000, Val Acc=0.6279, Val Loss=1.6515, lr=0.0100
[2025-05-07 06:36:46,766][train][INFO] - Epoch 1031/2000, Val Acc=0.6228, Val Loss=1.7575, lr=0.0100
[2025-05-07 06:36:54,964][train][INFO] - Epoch 1032/2000, Val Acc=0.6210, Val Loss=1.7209, lr=0.0100
[2025-05-07 06:37:02,338][train][INFO] - Epoch 1033/2000, Val Acc=0.6204, Val Loss=1.7470, lr=0.0100
[2025-05-07 06:37:10,067][train][INFO] - Epoch 1034/2000, Val Acc=0.6202, Val Loss=1.8197, lr=0.0100
[2025-05-07 06:37:17,952][train][INFO] - Epoch 1035/2000, Val Acc=0.6031, Val Loss=1.8396, lr=0.0100
[2025-05-07 06:37:25,746][train][INFO] - Epoch 1036/2000, Val Acc=0.6080, Val Loss=1.8111, lr=0.0100
[2025-05-07 06:37:33,308][train][INFO] - Epoch 1037/2000, Val Acc=0.6088, Val Loss=1.8299, lr=0.0100
[2025-05-07 06:37:40,956][train][INFO] - Epoch 1038/2000, Val Acc=0.5939, Val Loss=1.9067, lr=0.0100
[2025-05-07 06:37:49,210][train][INFO] - Epoch 1039/2000, Val Acc=0.6129, Val Loss=1.7377, lr=0.0100
[2025-05-07 06:37:56,604][train][INFO] - Epoch 1040/2000, Val Acc=0.6143, Val Loss=1.7554, lr=0.0100
[2025-05-07 06:38:04,846][train][INFO] - Epoch 1041/2000, Val Acc=0.6150, Val Loss=1.7585, lr=0.0100
[2025-05-07 06:38:13,088][train][INFO] - Epoch 1042/2000, Val Acc=0.6160, Val Loss=1.7964, lr=0.0100
[2025-05-07 06:38:21,361][train][INFO] - Epoch 1043/2000, Val Acc=0.6165, Val Loss=1.7763, lr=0.0100
[2025-05-07 06:38:29,411][train][INFO] - Epoch 1044/2000, Val Acc=0.6116, Val Loss=1.8131, lr=0.0100
[2025-05-07 06:38:37,474][train][INFO] - Epoch 1045/2000, Val Acc=0.6177, Val Loss=1.7393, lr=0.0100
[2025-05-07 06:38:45,367][train][INFO] - Epoch 1046/2000, Val Acc=0.6136, Val Loss=1.7879, lr=0.0100
[2025-05-07 06:38:53,458][train][INFO] - Epoch 1047/2000, Val Acc=0.6103, Val Loss=1.7972, lr=0.0100
[2025-05-07 06:39:00,527][train][INFO] - Epoch 1048/2000, Val Acc=0.5800, Val Loss=1.9536, lr=0.0100
[2025-05-07 06:39:08,412][train][INFO] - Epoch 1049/2000, Val Acc=0.6086, Val Loss=1.7863, lr=0.0100
[2025-05-07 06:39:14,897][train][INFO] - Epoch 1050/2000, Val Acc=0.6106, Val Loss=1.8204, lr=0.0100
[2025-05-07 06:39:21,488][train][INFO] - Epoch 1051/2000, Val Acc=0.6230, Val Loss=1.7443, lr=0.0100
[2025-05-07 06:39:29,451][train][INFO] - Epoch 1052/2000, Val Acc=0.6058, Val Loss=1.8090, lr=0.0100
[2025-05-07 06:39:37,657][train][INFO] - Epoch 1053/2000, Val Acc=0.5955, Val Loss=1.8202, lr=0.0100
[2025-05-07 06:39:45,093][train][INFO] - Epoch 1054/2000, Val Acc=0.6203, Val Loss=1.7381, lr=0.0100
[2025-05-07 06:39:53,431][train][INFO] - Epoch 1055/2000, Val Acc=0.6178, Val Loss=1.7422, lr=0.0100
[2025-05-07 06:40:01,035][train][INFO] - Epoch 1056/2000, Val Acc=0.6106, Val Loss=1.7936, lr=0.0100
[2025-05-07 06:40:09,383][train][INFO] - Epoch 1057/2000, Val Acc=0.6097, Val Loss=1.7997, lr=0.0100
[2025-05-07 06:40:17,619][train][INFO] - Epoch 1058/2000, Val Acc=0.6022, Val Loss=1.8392, lr=0.0100
[2025-05-07 06:40:25,611][train][INFO] - Epoch 1059/2000, Val Acc=0.6175, Val Loss=1.7350, lr=0.0100
[2025-05-07 06:40:34,271][train][INFO] - Epoch 1060/2000, Val Acc=0.6153, Val Loss=1.7828, lr=0.0100
[2025-05-07 06:40:41,608][train][INFO] - Epoch 1061/2000, Val Acc=0.6168, Val Loss=1.7556, lr=0.0100
[2025-05-07 06:40:49,614][train][INFO] - Epoch 1062/2000, Val Acc=0.6207, Val Loss=1.7145, lr=0.0100
[2025-05-07 06:40:57,421][train][INFO] - Epoch 1063/2000, Val Acc=0.6088, Val Loss=1.8231, lr=0.0100
[2025-05-07 06:41:05,143][train][INFO] - Epoch 1064/2000, Val Acc=0.6078, Val Loss=1.7817, lr=0.0100
[2025-05-07 06:41:12,872][train][INFO] - Epoch 1065/2000, Val Acc=0.6135, Val Loss=1.7815, lr=0.0100
[2025-05-07 06:41:20,910][train][INFO] - Epoch 1066/2000, Val Acc=0.6021, Val Loss=1.8708, lr=0.0100
[2025-05-07 06:41:28,657][train][INFO] - Epoch 1067/2000, Val Acc=0.6036, Val Loss=1.8544, lr=0.0100
[2025-05-07 06:41:36,392][train][INFO] - Epoch 1068/2000, Val Acc=0.6249, Val Loss=1.7181, lr=0.0100
[2025-05-07 06:41:44,242][train][INFO] - Epoch 1069/2000, Val Acc=0.6300, Val Loss=1.7652, lr=0.0100
[2025-05-07 06:41:52,662][train][INFO] - Epoch 1070/2000, Val Acc=0.6122, Val Loss=1.7932, lr=0.0100
[2025-05-07 06:42:00,350][train][INFO] - Epoch 1071/2000, Val Acc=0.6072, Val Loss=1.7989, lr=0.0100
[2025-05-07 06:42:07,797][train][INFO] - Epoch 1072/2000, Val Acc=0.6202, Val Loss=1.7552, lr=0.0100
[2025-05-07 06:42:14,766][train][INFO] - Epoch 1073/2000, Val Acc=0.6095, Val Loss=1.8104, lr=0.0100
[2025-05-07 06:42:22,724][train][INFO] - Epoch 1074/2000, Val Acc=0.6018, Val Loss=1.8539, lr=0.0100
[2025-05-07 06:42:30,087][train][INFO] - Epoch 1075/2000, Val Acc=0.6267, Val Loss=1.6980, lr=0.0100
[2025-05-07 06:42:37,928][train][INFO] - Epoch 1076/2000, Val Acc=0.6151, Val Loss=1.7856, lr=0.0100
[2025-05-07 06:42:45,983][train][INFO] - Epoch 1077/2000, Val Acc=0.6132, Val Loss=1.7922, lr=0.0100
[2025-05-07 06:42:52,940][train][INFO] - Epoch 1078/2000, Val Acc=0.6119, Val Loss=1.7279, lr=0.0100
[2025-05-07 06:43:00,437][train][INFO] - Epoch 1079/2000, Val Acc=0.6085, Val Loss=1.7540, lr=0.0100
[2025-05-07 06:43:08,208][train][INFO] - Epoch 1080/2000, Val Acc=0.6103, Val Loss=1.8310, lr=0.0100
[2025-05-07 06:43:15,975][train][INFO] - Epoch 1081/2000, Val Acc=0.6060, Val Loss=1.7857, lr=0.0100
[2025-05-07 06:43:23,499][train][INFO] - Epoch 1082/2000, Val Acc=0.6111, Val Loss=1.7838, lr=0.0100
[2025-05-07 06:43:31,448][train][INFO] - Epoch 1083/2000, Val Acc=0.6153, Val Loss=1.7614, lr=0.0100
[2025-05-07 06:43:39,218][train][INFO] - Epoch 1084/2000, Val Acc=0.6194, Val Loss=1.7050, lr=0.0100
[2025-05-07 06:43:47,618][train][INFO] - Epoch 1085/2000, Val Acc=0.6150, Val Loss=1.7575, lr=0.0100
[2025-05-07 06:43:55,287][train][INFO] - Epoch 1086/2000, Val Acc=0.6178, Val Loss=1.7507, lr=0.0100
[2025-05-07 06:44:03,331][train][INFO] - Epoch 1087/2000, Val Acc=0.6165, Val Loss=1.7726, lr=0.0100
[2025-05-07 06:44:10,873][train][INFO] - Epoch 1088/2000, Val Acc=0.6035, Val Loss=1.8341, lr=0.0100
[2025-05-07 06:44:19,189][train][INFO] - Epoch 1089/2000, Val Acc=0.6203, Val Loss=1.7718, lr=0.0100
[2025-05-07 06:44:27,120][train][INFO] - Epoch 1090/2000, Val Acc=0.6253, Val Loss=1.6827, lr=0.0100
[2025-05-07 06:44:34,888][train][INFO] - Epoch 1091/2000, Val Acc=0.5910, Val Loss=1.8741, lr=0.0100
[2025-05-07 06:44:42,980][train][INFO] - Epoch 1092/2000, Val Acc=0.6225, Val Loss=1.7404, lr=0.0100
[2025-05-07 06:44:50,851][train][INFO] - Epoch 1093/2000, Val Acc=0.6183, Val Loss=1.7339, lr=0.0100
[2025-05-07 06:44:58,419][train][INFO] - Epoch 1094/2000, Val Acc=0.6148, Val Loss=1.7750, lr=0.0100
[2025-05-07 06:45:06,226][train][INFO] - Epoch 1095/2000, Val Acc=0.5843, Val Loss=1.9163, lr=0.0100
[2025-05-07 06:45:14,428][train][INFO] - Epoch 1096/2000, Val Acc=0.6125, Val Loss=1.7915, lr=0.0100
[2025-05-07 06:45:21,926][train][INFO] - Epoch 1097/2000, Val Acc=0.6058, Val Loss=1.8220, lr=0.0100
[2025-05-07 06:45:29,891][train][INFO] - Epoch 1098/2000, Val Acc=0.6083, Val Loss=1.7897, lr=0.0100
[2025-05-07 06:45:37,639][train][INFO] - Epoch 1099/2000, Val Acc=0.6250, Val Loss=1.7085, lr=0.0100
[2025-05-07 06:45:45,956][train][INFO] - Epoch 1100/2000, Val Acc=0.6189, Val Loss=1.7713, lr=0.0100
[2025-05-07 06:45:54,218][train][INFO] - Epoch 1101/2000, Val Acc=0.6182, Val Loss=1.7530, lr=0.0100
[2025-05-07 06:46:02,706][train][INFO] - Epoch 1102/2000, Val Acc=0.6266, Val Loss=1.6935, lr=0.0100
[2025-05-07 06:46:10,411][train][INFO] - Epoch 1103/2000, Val Acc=0.6137, Val Loss=1.7854, lr=0.0100
[2025-05-07 06:46:16,903][train][INFO] - Epoch 1104/2000, Val Acc=0.6169, Val Loss=1.7650, lr=0.0100
[2025-05-07 06:46:24,295][train][INFO] - Epoch 1105/2000, Val Acc=0.6054, Val Loss=1.8206, lr=0.0100
[2025-05-07 06:46:32,430][train][INFO] - Epoch 1106/2000, Val Acc=0.6125, Val Loss=1.8024, lr=0.0100
[2025-05-07 06:46:40,395][train][INFO] - Epoch 1107/2000, Val Acc=0.6192, Val Loss=1.7512, lr=0.0100
[2025-05-07 06:46:48,268][train][INFO] - Epoch 1108/2000, Val Acc=0.6210, Val Loss=1.7542, lr=0.0100
[2025-05-07 06:46:55,762][train][INFO] - Epoch 1109/2000, Val Acc=0.6118, Val Loss=1.7771, lr=0.0100
[2025-05-07 06:47:03,596][train][INFO] - Epoch 1110/2000, Val Acc=0.6117, Val Loss=1.7716, lr=0.0100
[2025-05-07 06:47:11,595][train][INFO] - Epoch 1111/2000, Val Acc=0.6241, Val Loss=1.7698, lr=0.0100
[2025-05-07 06:47:19,365][train][INFO] - Epoch 1112/2000, Val Acc=0.6033, Val Loss=1.8106, lr=0.0100
[2025-05-07 06:47:26,673][train][INFO] - Epoch 1113/2000, Val Acc=0.6104, Val Loss=1.7941, lr=0.0100
[2025-05-07 06:47:34,284][train][INFO] - Epoch 1114/2000, Val Acc=0.6147, Val Loss=1.7569, lr=0.0100
[2025-05-07 06:47:41,287][train][INFO] - Epoch 1115/2000, Val Acc=0.6240, Val Loss=1.7363, lr=0.0100
[2025-05-07 06:47:48,366][train][INFO] - Epoch 1116/2000, Val Acc=0.6024, Val Loss=1.8763, lr=0.0100
[2025-05-07 06:47:56,661][train][INFO] - Epoch 1117/2000, Val Acc=0.6126, Val Loss=1.7866, lr=0.0100
[2025-05-07 06:48:04,792][train][INFO] - Epoch 1118/2000, Val Acc=0.6228, Val Loss=1.7176, lr=0.0100
[2025-05-07 06:48:12,461][train][INFO] - Epoch 1119/2000, Val Acc=0.6400, Val Loss=1.6740, lr=0.0100
[2025-05-07 06:48:20,297][train][INFO] - Epoch 1120/2000, Val Acc=0.6122, Val Loss=1.7832, lr=0.0100
[2025-05-07 06:48:28,252][train][INFO] - Epoch 1121/2000, Val Acc=0.6231, Val Loss=1.7557, lr=0.0100
[2025-05-07 06:48:36,806][train][INFO] - Epoch 1122/2000, Val Acc=0.6196, Val Loss=1.7371, lr=0.0100
[2025-05-07 06:48:44,369][train][INFO] - Epoch 1123/2000, Val Acc=0.6223, Val Loss=1.7252, lr=0.0100
[2025-05-07 06:48:51,221][train][INFO] - Epoch 1124/2000, Val Acc=0.6202, Val Loss=1.7295, lr=0.0100
[2025-05-07 06:48:58,929][train][INFO] - Epoch 1125/2000, Val Acc=0.6079, Val Loss=1.7990, lr=0.0100
[2025-05-07 06:49:07,387][train][INFO] - Epoch 1126/2000, Val Acc=0.6139, Val Loss=1.7885, lr=0.0100
[2025-05-07 06:49:15,140][train][INFO] - Epoch 1127/2000, Val Acc=0.6290, Val Loss=1.6968, lr=0.0100
[2025-05-07 06:49:22,603][train][INFO] - Epoch 1128/2000, Val Acc=0.5911, Val Loss=1.9360, lr=0.0100
[2025-05-07 06:49:30,526][train][INFO] - Epoch 1129/2000, Val Acc=0.6055, Val Loss=1.8443, lr=0.0100
[2025-05-07 06:49:38,050][train][INFO] - Epoch 1130/2000, Val Acc=0.6255, Val Loss=1.6946, lr=0.0100
[2025-05-07 06:49:46,025][train][INFO] - Epoch 1131/2000, Val Acc=0.6174, Val Loss=1.8036, lr=0.0100
[2025-05-07 06:49:52,617][train][INFO] - Epoch 1132/2000, Val Acc=0.6137, Val Loss=1.7668, lr=0.0100
[2025-05-07 06:50:00,746][train][INFO] - Epoch 1133/2000, Val Acc=0.6058, Val Loss=1.8348, lr=0.0100
[2025-05-07 06:50:08,488][train][INFO] - Epoch 1134/2000, Val Acc=0.6286, Val Loss=1.6759, lr=0.0100
[2025-05-07 06:50:16,197][train][INFO] - Epoch 1135/2000, Val Acc=0.6103, Val Loss=1.7822, lr=0.0100
[2025-05-07 06:50:24,216][train][INFO] - Epoch 1136/2000, Val Acc=0.6138, Val Loss=1.7685, lr=0.0100
[2025-05-07 06:50:32,254][train][INFO] - Epoch 1137/2000, Val Acc=0.5985, Val Loss=1.8825, lr=0.0100
[2025-05-07 06:50:39,838][train][INFO] - Epoch 1138/2000, Val Acc=0.6252, Val Loss=1.7067, lr=0.0100
[2025-05-07 06:50:47,801][train][INFO] - Epoch 1139/2000, Val Acc=0.6146, Val Loss=1.7327, lr=0.0100
[2025-05-07 06:50:55,584][train][INFO] - Epoch 1140/2000, Val Acc=0.6076, Val Loss=1.8249, lr=0.0100
[2025-05-07 06:51:02,418][train][INFO] - Epoch 1141/2000, Val Acc=0.6133, Val Loss=1.7670, lr=0.0100
[2025-05-07 06:51:10,255][train][INFO] - Epoch 1142/2000, Val Acc=0.5977, Val Loss=1.8737, lr=0.0100
[2025-05-07 06:51:18,325][train][INFO] - Epoch 1143/2000, Val Acc=0.6220, Val Loss=1.7561, lr=0.0100
[2025-05-07 06:51:26,580][train][INFO] - Epoch 1144/2000, Val Acc=0.6095, Val Loss=1.7845, lr=0.0100
[2025-05-07 06:51:34,409][train][INFO] - Epoch 1145/2000, Val Acc=0.6095, Val Loss=1.8305, lr=0.0100
[2025-05-07 06:51:41,991][train][INFO] - Epoch 1146/2000, Val Acc=0.6025, Val Loss=1.8395, lr=0.0100
[2025-05-07 06:51:50,242][train][INFO] - Epoch 1147/2000, Val Acc=0.6216, Val Loss=1.7696, lr=0.0100
[2025-05-07 06:51:57,784][train][INFO] - Epoch 1148/2000, Val Acc=0.6191, Val Loss=1.7550, lr=0.0100
[2025-05-07 06:52:06,038][train][INFO] - Epoch 1149/2000, Val Acc=0.6164, Val Loss=1.7446, lr=0.0100
[2025-05-07 06:52:13,742][train][INFO] - Epoch 1150/2000, Val Acc=0.6048, Val Loss=1.8427, lr=0.0100
[2025-05-07 06:52:21,869][train][INFO] - Epoch 1151/2000, Val Acc=0.6123, Val Loss=1.7567, lr=0.0100
[2025-05-07 06:52:28,397][train][INFO] - Epoch 1152/2000, Val Acc=0.5951, Val Loss=1.9024, lr=0.0100
[2025-05-07 06:52:36,065][train][INFO] - Epoch 1153/2000, Val Acc=0.6083, Val Loss=1.8029, lr=0.0100
[2025-05-07 06:52:44,274][train][INFO] - Epoch 1154/2000, Val Acc=0.6138, Val Loss=1.7418, lr=0.0100
[2025-05-07 06:52:52,097][train][INFO] - Epoch 1155/2000, Val Acc=0.6047, Val Loss=1.7892, lr=0.0100
[2025-05-07 06:52:59,698][train][INFO] - Epoch 1156/2000, Val Acc=0.6235, Val Loss=1.7131, lr=0.0100
[2025-05-07 06:53:07,979][train][INFO] - Epoch 1157/2000, Val Acc=0.6109, Val Loss=1.7585, lr=0.0100
[2025-05-07 06:53:15,393][train][INFO] - Epoch 1158/2000, Val Acc=0.6268, Val Loss=1.7253, lr=0.0100
[2025-05-07 06:53:22,962][train][INFO] - Epoch 1159/2000, Val Acc=0.5955, Val Loss=1.8690, lr=0.0100
[2025-05-07 06:53:30,575][train][INFO] - Epoch 1160/2000, Val Acc=0.6165, Val Loss=1.7231, lr=0.0100
[2025-05-07 06:53:38,577][train][INFO] - Epoch 1161/2000, Val Acc=0.6067, Val Loss=1.7820, lr=0.0100
[2025-05-07 06:53:46,979][train][INFO] - Epoch 1162/2000, Val Acc=0.6111, Val Loss=1.8303, lr=0.0100
[2025-05-07 06:53:54,664][train][INFO] - Epoch 1163/2000, Val Acc=0.6162, Val Loss=1.7640, lr=0.0100
[2025-05-07 06:54:03,241][train][INFO] - Epoch 1164/2000, Val Acc=0.6024, Val Loss=1.9021, lr=0.0100
[2025-05-07 06:54:10,732][train][INFO] - Epoch 1165/2000, Val Acc=0.6124, Val Loss=1.7797, lr=0.0100
[2025-05-07 06:54:19,018][train][INFO] - Epoch 1166/2000, Val Acc=0.6252, Val Loss=1.6899, lr=0.0100
[2025-05-07 06:54:27,036][train][INFO] - Epoch 1167/2000, Val Acc=0.6071, Val Loss=1.8290, lr=0.0100
[2025-05-07 06:54:33,676][train][INFO] - Epoch 1168/2000, Val Acc=0.6188, Val Loss=1.7694, lr=0.0100
[2025-05-07 06:54:41,912][train][INFO] - Epoch 1169/2000, Val Acc=0.6061, Val Loss=1.8661, lr=0.0100
[2025-05-07 06:54:50,162][train][INFO] - Epoch 1170/2000, Val Acc=0.6047, Val Loss=1.8374, lr=0.0100
[2025-05-07 06:54:57,992][train][INFO] - Epoch 1171/2000, Val Acc=0.6128, Val Loss=1.7891, lr=0.0100
[2025-05-07 06:55:05,828][train][INFO] - Epoch 1172/2000, Val Acc=0.6177, Val Loss=1.7694, lr=0.0100
[2025-05-07 06:55:13,648][train][INFO] - Epoch 1173/2000, Val Acc=0.6124, Val Loss=1.7673, lr=0.0100
[2025-05-07 06:55:22,078][train][INFO] - Epoch 1174/2000, Val Acc=0.6341, Val Loss=1.7031, lr=0.0100
[2025-05-07 06:55:29,533][train][INFO] - Epoch 1175/2000, Val Acc=0.6069, Val Loss=1.8451, lr=0.0100
[2025-05-07 06:55:36,714][train][INFO] - Epoch 1176/2000, Val Acc=0.6028, Val Loss=1.8857, lr=0.0100
[2025-05-07 06:55:43,974][train][INFO] - Epoch 1177/2000, Val Acc=0.6126, Val Loss=1.7492, lr=0.0100
[2025-05-07 06:55:51,775][train][INFO] - Epoch 1178/2000, Val Acc=0.6185, Val Loss=1.7165, lr=0.0100
[2025-05-07 06:55:59,493][train][INFO] - Epoch 1179/2000, Val Acc=0.6198, Val Loss=1.7249, lr=0.0100
[2025-05-07 06:56:08,199][train][INFO] - Epoch 1180/2000, Val Acc=0.6203, Val Loss=1.6866, lr=0.0100
[2025-05-07 06:56:15,398][train][INFO] - Epoch 1181/2000, Val Acc=0.5897, Val Loss=1.9051, lr=0.0100
[2025-05-07 06:56:23,457][train][INFO] - Epoch 1182/2000, Val Acc=0.6079, Val Loss=1.8188, lr=0.0100
[2025-05-07 06:56:31,421][train][INFO] - Epoch 1183/2000, Val Acc=0.5988, Val Loss=1.8694, lr=0.0100
[2025-05-07 06:56:39,301][train][INFO] - Epoch 1184/2000, Val Acc=0.6087, Val Loss=1.7680, lr=0.0100
[2025-05-07 06:56:47,853][train][INFO] - Epoch 1185/2000, Val Acc=0.6028, Val Loss=1.8252, lr=0.0100
[2025-05-07 06:56:55,524][train][INFO] - Epoch 1186/2000, Val Acc=0.6245, Val Loss=1.7242, lr=0.0100
[2025-05-07 06:57:03,211][train][INFO] - Epoch 1187/2000, Val Acc=0.6082, Val Loss=1.7672, lr=0.0100
[2025-05-07 06:57:10,624][train][INFO] - Epoch 1188/2000, Val Acc=0.6064, Val Loss=1.8031, lr=0.0100
[2025-05-07 06:57:19,179][train][INFO] - Epoch 1189/2000, Val Acc=0.6054, Val Loss=1.8177, lr=0.0100
[2025-05-07 06:57:27,222][train][INFO] - Epoch 1190/2000, Val Acc=0.6190, Val Loss=1.7419, lr=0.0100
[2025-05-07 06:57:35,286][train][INFO] - Epoch 1191/2000, Val Acc=0.6150, Val Loss=1.8097, lr=0.0100
[2025-05-07 06:57:42,574][train][INFO] - Epoch 1192/2000, Val Acc=0.6074, Val Loss=1.8638, lr=0.0100
[2025-05-07 06:57:50,340][train][INFO] - Epoch 1193/2000, Val Acc=0.6060, Val Loss=1.8217, lr=0.0100
[2025-05-07 06:57:58,009][train][INFO] - Epoch 1194/2000, Val Acc=0.6147, Val Loss=1.7462, lr=0.0100
[2025-05-07 06:58:05,610][train][INFO] - Epoch 1195/2000, Val Acc=0.6038, Val Loss=1.8285, lr=0.0100
[2025-05-07 06:58:13,283][train][INFO] - Epoch 1196/2000, Val Acc=0.6004, Val Loss=1.8499, lr=0.0100
[2025-05-07 06:58:20,716][train][INFO] - Epoch 1197/2000, Val Acc=0.6203, Val Loss=1.7595, lr=0.0100
[2025-05-07 06:58:28,728][train][INFO] - Epoch 1198/2000, Val Acc=0.6100, Val Loss=1.8322, lr=0.0100
[2025-05-07 06:58:36,730][train][INFO] - Epoch 1199/2000, Val Acc=0.5916, Val Loss=1.9334, lr=0.0100
[2025-05-07 06:58:45,061][train][INFO] - Epoch 1200/2000, Val Acc=0.6247, Val Loss=1.6905, lr=0.0100
[2025-05-07 06:58:53,086][train][INFO] - Epoch 1201/2000, Val Acc=0.6056, Val Loss=1.8019, lr=0.0100
[2025-05-07 06:59:00,545][train][INFO] - Epoch 1202/2000, Val Acc=0.6232, Val Loss=1.7208, lr=0.0100
[2025-05-07 06:59:07,934][train][INFO] - Epoch 1203/2000, Val Acc=0.5930, Val Loss=1.8759, lr=0.0100
[2025-05-07 06:59:16,117][train][INFO] - Epoch 1204/2000, Val Acc=0.6135, Val Loss=1.7518, lr=0.0100
[2025-05-07 06:59:24,595][train][INFO] - Epoch 1205/2000, Val Acc=0.6189, Val Loss=1.7164, lr=0.0100
[2025-05-07 06:59:32,496][train][INFO] - Epoch 1206/2000, Val Acc=0.6092, Val Loss=1.7958, lr=0.0100
[2025-05-07 06:59:40,803][train][INFO] - Epoch 1207/2000, Val Acc=0.6109, Val Loss=1.7710, lr=0.0100
[2025-05-07 06:59:48,389][train][INFO] - Epoch 1208/2000, Val Acc=0.6211, Val Loss=1.7419, lr=0.0100
[2025-05-07 06:59:56,175][train][INFO] - Epoch 1209/2000, Val Acc=0.6191, Val Loss=1.7219, lr=0.0100
[2025-05-07 07:00:03,848][train][INFO] - Epoch 1210/2000, Val Acc=0.6226, Val Loss=1.7173, lr=0.0100
[2025-05-07 07:00:12,096][train][INFO] - Epoch 1211/2000, Val Acc=0.6151, Val Loss=1.7825, lr=0.0100
[2025-05-07 07:00:20,056][train][INFO] - Epoch 1212/2000, Val Acc=0.6017, Val Loss=1.8720, lr=0.0100
[2025-05-07 07:00:26,605][train][INFO] - Epoch 1213/2000, Val Acc=0.6073, Val Loss=1.8624, lr=0.0100
[2025-05-07 07:00:33,740][train][INFO] - Epoch 1214/2000, Val Acc=0.6159, Val Loss=1.7857, lr=0.0100
[2025-05-07 07:00:42,005][train][INFO] - Epoch 1215/2000, Val Acc=0.5949, Val Loss=1.9121, lr=0.0100
[2025-05-07 07:00:50,499][train][INFO] - Epoch 1216/2000, Val Acc=0.6114, Val Loss=1.8189, lr=0.0100
[2025-05-07 07:00:58,150][train][INFO] - Epoch 1217/2000, Val Acc=0.6193, Val Loss=1.7473, lr=0.0100
[2025-05-07 07:01:06,833][train][INFO] - Epoch 1218/2000, Val Acc=0.6069, Val Loss=1.8266, lr=0.0100
[2025-05-07 07:01:14,722][train][INFO] - Epoch 1219/2000, Val Acc=0.6293, Val Loss=1.7030, lr=0.0100
[2025-05-07 07:01:23,129][train][INFO] - Epoch 1220/2000, Val Acc=0.6031, Val Loss=1.8340, lr=0.0100
[2025-05-07 07:01:31,890][train][INFO] - Epoch 1221/2000, Val Acc=0.6038, Val Loss=1.8220, lr=0.0100
[2025-05-07 07:01:40,104][train][INFO] - Epoch 1222/2000, Val Acc=0.6191, Val Loss=1.7370, lr=0.0100
[2025-05-07 07:01:47,290][train][INFO] - Epoch 1223/2000, Val Acc=0.6228, Val Loss=1.7444, lr=0.0100
[2025-05-07 07:01:54,488][train][INFO] - Epoch 1224/2000, Val Acc=0.6089, Val Loss=1.7934, lr=0.0100
[2025-05-07 07:02:02,023][train][INFO] - Epoch 1225/2000, Val Acc=0.6265, Val Loss=1.7000, lr=0.0100
[2025-05-07 07:02:10,510][train][INFO] - Epoch 1226/2000, Val Acc=0.6077, Val Loss=1.7992, lr=0.0100
[2025-05-07 07:02:18,390][train][INFO] - Epoch 1227/2000, Val Acc=0.5989, Val Loss=1.8385, lr=0.0100
[2025-05-07 07:02:25,890][train][INFO] - Epoch 1228/2000, Val Acc=0.6176, Val Loss=1.7769, lr=0.0100
[2025-05-07 07:02:33,566][train][INFO] - Epoch 1229/2000, Val Acc=0.6236, Val Loss=1.7264, lr=0.0100
[2025-05-07 07:02:41,707][train][INFO] - Epoch 1230/2000, Val Acc=0.6128, Val Loss=1.7813, lr=0.0100
[2025-05-07 07:02:49,375][train][INFO] - Epoch 1231/2000, Val Acc=0.6182, Val Loss=1.7420, lr=0.0100
[2025-05-07 07:02:57,318][train][INFO] - Epoch 1232/2000, Val Acc=0.5997, Val Loss=1.8797, lr=0.0100
[2025-05-07 07:03:05,613][train][INFO] - Epoch 1233/2000, Val Acc=0.6007, Val Loss=1.8230, lr=0.0100
[2025-05-07 07:03:13,353][train][INFO] - Epoch 1234/2000, Val Acc=0.6243, Val Loss=1.7324, lr=0.0100
[2025-05-07 07:03:20,382][train][INFO] - Epoch 1235/2000, Val Acc=0.6169, Val Loss=1.7957, lr=0.0100
[2025-05-07 07:03:28,452][train][INFO] - Epoch 1236/2000, Val Acc=0.6144, Val Loss=1.7319, lr=0.0100
[2025-05-07 07:03:36,211][train][INFO] - Epoch 1237/2000, Val Acc=0.6081, Val Loss=1.8338, lr=0.0100
[2025-05-07 07:03:44,775][train][INFO] - Epoch 1238/2000, Val Acc=0.6008, Val Loss=1.8773, lr=0.0100
[2025-05-07 07:03:52,663][train][INFO] - Epoch 1239/2000, Val Acc=0.6218, Val Loss=1.7465, lr=0.0100
[2025-05-07 07:04:00,206][train][INFO] - Epoch 1240/2000, Val Acc=0.6200, Val Loss=1.7510, lr=0.0100
[2025-05-07 07:04:07,176][train][INFO] - Epoch 1241/2000, Val Acc=0.6058, Val Loss=1.8767, lr=0.0100
[2025-05-07 07:04:15,316][train][INFO] - Epoch 1242/2000, Val Acc=0.6165, Val Loss=1.7511, lr=0.0100
[2025-05-07 07:04:23,515][train][INFO] - Epoch 1243/2000, Val Acc=0.6220, Val Loss=1.7039, lr=0.0100
[2025-05-07 07:04:31,332][train][INFO] - Epoch 1244/2000, Val Acc=0.6130, Val Loss=1.7720, lr=0.0100
[2025-05-07 07:04:40,196][train][INFO] - Epoch 1245/2000, Val Acc=0.5996, Val Loss=1.8553, lr=0.0100
[2025-05-07 07:04:48,081][train][INFO] - Epoch 1246/2000, Val Acc=0.5838, Val Loss=1.9785, lr=0.0100
[2025-05-07 07:04:55,489][train][INFO] - Epoch 1247/2000, Val Acc=0.6108, Val Loss=1.7810, lr=0.0100
[2025-05-07 07:05:02,742][train][INFO] - Epoch 1248/2000, Val Acc=0.6124, Val Loss=1.7916, lr=0.0100
[2025-05-07 07:05:09,754][train][INFO] - Epoch 1249/2000, Val Acc=0.6212, Val Loss=1.7305, lr=0.0100
[2025-05-07 07:05:17,262][train][INFO] - Epoch 1250/2000, Val Acc=0.6249, Val Loss=1.6834, lr=0.0100
[2025-05-07 07:05:24,944][train][INFO] - Epoch 1251/2000, Val Acc=0.6086, Val Loss=1.7998, lr=0.0100
[2025-05-07 07:05:31,771][train][INFO] - Epoch 1252/2000, Val Acc=0.6050, Val Loss=1.8464, lr=0.0100
[2025-05-07 07:05:39,408][train][INFO] - Epoch 1253/2000, Val Acc=0.6091, Val Loss=1.8051, lr=0.0100
[2025-05-07 07:05:46,575][train][INFO] - Epoch 1254/2000, Val Acc=0.6107, Val Loss=1.8220, lr=0.0100
[2025-05-07 07:05:53,949][train][INFO] - Epoch 1255/2000, Val Acc=0.6157, Val Loss=1.7907, lr=0.0100
[2025-05-07 07:06:00,973][train][INFO] - Epoch 1256/2000, Val Acc=0.6170, Val Loss=1.7597, lr=0.0100
[2025-05-07 07:06:08,598][train][INFO] - Epoch 1257/2000, Val Acc=0.6137, Val Loss=1.7519, lr=0.0100
[2025-05-07 07:06:16,692][train][INFO] - Epoch 1258/2000, Val Acc=0.6196, Val Loss=1.7525, lr=0.0100
[2025-05-07 07:06:23,890][train][INFO] - Epoch 1259/2000, Val Acc=0.5983, Val Loss=1.8559, lr=0.0100
[2025-05-07 07:06:31,377][train][INFO] - Epoch 1260/2000, Val Acc=0.5609, Val Loss=2.1096, lr=0.0100
[2025-05-07 07:06:38,108][train][INFO] - Epoch 1261/2000, Val Acc=0.6005, Val Loss=1.9017, lr=0.0100
[2025-05-07 07:06:45,604][train][INFO] - Epoch 1262/2000, Val Acc=0.6147, Val Loss=1.7927, lr=0.0100
[2025-05-07 07:06:53,024][train][INFO] - Epoch 1263/2000, Val Acc=0.6205, Val Loss=1.7546, lr=0.0100
[2025-05-07 07:07:00,460][train][INFO] - Epoch 1264/2000, Val Acc=0.5967, Val Loss=1.8546, lr=0.0100
[2025-05-07 07:07:07,816][train][INFO] - Epoch 1265/2000, Val Acc=0.6175, Val Loss=1.7220, lr=0.0100
[2025-05-07 07:07:15,272][train][INFO] - Epoch 1266/2000, Val Acc=0.6087, Val Loss=1.8254, lr=0.0100
[2025-05-07 07:07:22,734][train][INFO] - Epoch 1267/2000, Val Acc=0.6162, Val Loss=1.7433, lr=0.0100
[2025-05-07 07:07:29,913][train][INFO] - Epoch 1268/2000, Val Acc=0.6120, Val Loss=1.7763, lr=0.0100
[2025-05-07 07:07:37,175][train][INFO] - Epoch 1269/2000, Val Acc=0.6018, Val Loss=1.8259, lr=0.0100
[2025-05-07 07:07:44,389][train][INFO] - Epoch 1270/2000, Val Acc=0.6256, Val Loss=1.7016, lr=0.0100
[2025-05-07 07:07:52,094][train][INFO] - Epoch 1271/2000, Val Acc=0.5996, Val Loss=1.9099, lr=0.0100
[2025-05-07 07:07:59,235][train][INFO] - Epoch 1272/2000, Val Acc=0.6147, Val Loss=1.7203, lr=0.0100
[2025-05-07 07:08:06,020][train][INFO] - Epoch 1273/2000, Val Acc=0.6276, Val Loss=1.6605, lr=0.0100
[2025-05-07 07:08:13,264][train][INFO] - Epoch 1274/2000, Val Acc=0.6126, Val Loss=1.7984, lr=0.0100
[2025-05-07 07:08:20,678][train][INFO] - Epoch 1275/2000, Val Acc=0.6139, Val Loss=1.7617, lr=0.0100
[2025-05-07 07:08:28,392][train][INFO] - Epoch 1276/2000, Val Acc=0.6196, Val Loss=1.7035, lr=0.0100
[2025-05-07 07:08:36,049][train][INFO] - Epoch 1277/2000, Val Acc=0.6232, Val Loss=1.7104, lr=0.0100
[2025-05-07 07:08:43,034][train][INFO] - Epoch 1278/2000, Val Acc=0.6285, Val Loss=1.6948, lr=0.0100
[2025-05-07 07:08:49,973][train][INFO] - Epoch 1279/2000, Val Acc=0.6181, Val Loss=1.7744, lr=0.0100
[2025-05-07 07:08:57,386][train][INFO] - Epoch 1280/2000, Val Acc=0.6166, Val Loss=1.7367, lr=0.0100
[2025-05-07 07:09:03,779][train][INFO] - Epoch 1281/2000, Val Acc=0.6010, Val Loss=1.8541, lr=0.0100
[2025-05-07 07:09:10,687][train][INFO] - Epoch 1282/2000, Val Acc=0.6214, Val Loss=1.7415, lr=0.0100
[2025-05-07 07:09:18,181][train][INFO] - Epoch 1283/2000, Val Acc=0.6123, Val Loss=1.7487, lr=0.0100
[2025-05-07 07:09:26,325][train][INFO] - Epoch 1284/2000, Val Acc=0.6244, Val Loss=1.7069, lr=0.0100
[2025-05-07 07:09:33,484][train][INFO] - Epoch 1285/2000, Val Acc=0.5999, Val Loss=1.8952, lr=0.0100
[2025-05-07 07:09:40,681][train][INFO] - Epoch 1286/2000, Val Acc=0.6108, Val Loss=1.7389, lr=0.0100
[2025-05-07 07:09:47,862][train][INFO] - Epoch 1287/2000, Val Acc=0.6056, Val Loss=1.8208, lr=0.0100
[2025-05-07 07:09:55,046][train][INFO] - Epoch 1288/2000, Val Acc=0.6223, Val Loss=1.7398, lr=0.0100
[2025-05-07 07:10:02,489][train][INFO] - Epoch 1289/2000, Val Acc=0.6207, Val Loss=1.7481, lr=0.0100
[2025-05-07 07:10:09,743][train][INFO] - Epoch 1290/2000, Val Acc=0.6168, Val Loss=1.7556, lr=0.0100
[2025-05-07 07:10:17,173][train][INFO] - Epoch 1291/2000, Val Acc=0.6056, Val Loss=1.7974, lr=0.0100
[2025-05-07 07:10:25,070][train][INFO] - Epoch 1292/2000, Val Acc=0.6122, Val Loss=1.7457, lr=0.0100
[2025-05-07 07:10:32,652][train][INFO] - Epoch 1293/2000, Val Acc=0.5977, Val Loss=1.8581, lr=0.0100
[2025-05-07 07:10:40,344][train][INFO] - Epoch 1294/2000, Val Acc=0.6171, Val Loss=1.7566, lr=0.0100
[2025-05-07 07:10:47,324][train][INFO] - Epoch 1295/2000, Val Acc=0.6173, Val Loss=1.7602, lr=0.0100
[2025-05-07 07:10:54,173][train][INFO] - Epoch 1296/2000, Val Acc=0.6121, Val Loss=1.7936, lr=0.0100
[2025-05-07 07:11:01,437][train][INFO] - Epoch 1297/2000, Val Acc=0.6063, Val Loss=1.7922, lr=0.0100
[2025-05-07 07:11:09,041][train][INFO] - Epoch 1298/2000, Val Acc=0.6193, Val Loss=1.7452, lr=0.0100
[2025-05-07 07:11:16,690][train][INFO] - Epoch 1299/2000, Val Acc=0.6086, Val Loss=1.8151, lr=0.0100
[2025-05-07 07:11:24,344][train][INFO] - Epoch 1300/2000, Val Acc=0.6195, Val Loss=1.7391, lr=0.0100
[2025-05-07 07:11:32,006][train][INFO] - Epoch 1301/2000, Val Acc=0.5966, Val Loss=1.8737, lr=0.0100
[2025-05-07 07:11:39,397][train][INFO] - Epoch 1302/2000, Val Acc=0.6256, Val Loss=1.7277, lr=0.0100
[2025-05-07 07:11:47,050][train][INFO] - Epoch 1303/2000, Val Acc=0.6072, Val Loss=1.7889, lr=0.0100
[2025-05-07 07:11:54,776][train][INFO] - Epoch 1304/2000, Val Acc=0.6238, Val Loss=1.7212, lr=0.0100
[2025-05-07 07:12:02,271][train][INFO] - Epoch 1305/2000, Val Acc=0.6275, Val Loss=1.7405, lr=0.0100
[2025-05-07 07:12:09,310][train][INFO] - Epoch 1306/2000, Val Acc=0.6083, Val Loss=1.8008, lr=0.0100
[2025-05-07 07:12:17,167][train][INFO] - Epoch 1307/2000, Val Acc=0.6133, Val Loss=1.7668, lr=0.0100
[2025-05-07 07:12:24,989][train][INFO] - Epoch 1308/2000, Val Acc=0.6120, Val Loss=1.7641, lr=0.0100
[2025-05-07 07:12:32,022][train][INFO] - Epoch 1309/2000, Val Acc=0.6195, Val Loss=1.7281, lr=0.0100
[2025-05-07 07:12:39,203][train][INFO] - Epoch 1310/2000, Val Acc=0.6202, Val Loss=1.7654, lr=0.0100
[2025-05-07 07:12:46,836][train][INFO] - Epoch 1311/2000, Val Acc=0.6174, Val Loss=1.7424, lr=0.0100
[2025-05-07 07:12:54,236][train][INFO] - Epoch 1312/2000, Val Acc=0.6151, Val Loss=1.7427, lr=0.0100
[2025-05-07 07:13:02,001][train][INFO] - Epoch 1313/2000, Val Acc=0.6007, Val Loss=1.8222, lr=0.0100
[2025-05-07 07:13:09,826][train][INFO] - Epoch 1314/2000, Val Acc=0.6141, Val Loss=1.7597, lr=0.0100
[2025-05-07 07:13:17,006][train][INFO] - Epoch 1315/2000, Val Acc=0.6217, Val Loss=1.7144, lr=0.0100
[2025-05-07 07:13:24,438][train][INFO] - Epoch 1316/2000, Val Acc=0.6100, Val Loss=1.7885, lr=0.0100
[2025-05-07 07:13:31,997][train][INFO] - Epoch 1317/2000, Val Acc=0.6185, Val Loss=1.7119, lr=0.0100
[2025-05-07 07:13:38,833][train][INFO] - Epoch 1318/2000, Val Acc=0.6115, Val Loss=1.8047, lr=0.0100
[2025-05-07 07:13:45,872][train][INFO] - Epoch 1319/2000, Val Acc=0.6132, Val Loss=1.7781, lr=0.0100
[2025-05-07 07:13:53,246][train][INFO] - Epoch 1320/2000, Val Acc=0.6217, Val Loss=1.7383, lr=0.0100
[2025-05-07 07:14:00,491][train][INFO] - Epoch 1321/2000, Val Acc=0.6136, Val Loss=1.7746, lr=0.0100
[2025-05-07 07:14:08,202][train][INFO] - Epoch 1322/2000, Val Acc=0.6068, Val Loss=1.8271, lr=0.0100
[2025-05-07 07:14:15,870][train][INFO] - Epoch 1323/2000, Val Acc=0.6323, Val Loss=1.7098, lr=0.0100
[2025-05-07 07:14:23,285][train][INFO] - Epoch 1324/2000, Val Acc=0.6160, Val Loss=1.7598, lr=0.0100
[2025-05-07 07:14:30,889][train][INFO] - Epoch 1325/2000, Val Acc=0.6207, Val Loss=1.7275, lr=0.0100
[2025-05-07 07:14:37,701][train][INFO] - Epoch 1326/2000, Val Acc=0.6187, Val Loss=1.7696, lr=0.0100
[2025-05-07 07:14:45,346][train][INFO] - Epoch 1327/2000, Val Acc=0.6153, Val Loss=1.7509, lr=0.0100
[2025-05-07 07:14:52,756][train][INFO] - Epoch 1328/2000, Val Acc=0.6236, Val Loss=1.7143, lr=0.0100
[2025-05-07 07:14:59,781][train][INFO] - Epoch 1329/2000, Val Acc=0.6026, Val Loss=1.8513, lr=0.0100
[2025-05-07 07:15:07,241][train][INFO] - Epoch 1330/2000, Val Acc=0.6135, Val Loss=1.7498, lr=0.0100
[2025-05-07 07:15:14,853][train][INFO] - Epoch 1331/2000, Val Acc=0.6213, Val Loss=1.7188, lr=0.0100
[2025-05-07 07:15:22,292][train][INFO] - Epoch 1332/2000, Val Acc=0.6040, Val Loss=1.8297, lr=0.0100
[2025-05-07 07:15:29,715][train][INFO] - Epoch 1333/2000, Val Acc=0.6127, Val Loss=1.8104, lr=0.0100
[2025-05-07 07:15:37,609][train][INFO] - Epoch 1334/2000, Val Acc=0.6085, Val Loss=1.8303, lr=0.0100
[2025-05-07 07:15:45,276][train][INFO] - Epoch 1335/2000, Val Acc=0.6219, Val Loss=1.7010, lr=0.0100
[2025-05-07 07:15:52,616][train][INFO] - Epoch 1336/2000, Val Acc=0.6177, Val Loss=1.7410, lr=0.0100
[2025-05-07 07:16:00,637][train][INFO] - Epoch 1337/2000, Val Acc=0.6222, Val Loss=1.7259, lr=0.0100
[2025-05-07 07:16:08,218][train][INFO] - Epoch 1338/2000, Val Acc=0.6204, Val Loss=1.7630, lr=0.0100
[2025-05-07 07:16:15,855][train][INFO] - Epoch 1339/2000, Val Acc=0.6085, Val Loss=1.8505, lr=0.0100
[2025-05-07 07:16:23,428][train][INFO] - Epoch 1340/2000, Val Acc=0.6043, Val Loss=1.8644, lr=0.0100
[2025-05-07 07:16:30,777][train][INFO] - Epoch 1341/2000, Val Acc=0.6038, Val Loss=1.8616, lr=0.0100
[2025-05-07 07:16:37,991][train][INFO] - Epoch 1342/2000, Val Acc=0.6179, Val Loss=1.7545, lr=0.0100
[2025-05-07 07:16:45,410][train][INFO] - Epoch 1343/2000, Val Acc=0.6129, Val Loss=1.7766, lr=0.0100
[2025-05-07 07:16:52,944][train][INFO] - Epoch 1344/2000, Val Acc=0.6240, Val Loss=1.7078, lr=0.0100
[2025-05-07 07:17:00,118][train][INFO] - Epoch 1345/2000, Val Acc=0.6126, Val Loss=1.8350, lr=0.0100
[2025-05-07 07:17:08,011][train][INFO] - Epoch 1346/2000, Val Acc=0.6079, Val Loss=1.7976, lr=0.0100
[2025-05-07 07:17:15,270][train][INFO] - Epoch 1347/2000, Val Acc=0.5961, Val Loss=1.8772, lr=0.0100
[2025-05-07 07:17:22,546][train][INFO] - Epoch 1348/2000, Val Acc=0.6070, Val Loss=1.8560, lr=0.0100
[2025-05-07 07:17:30,137][train][INFO] - Epoch 1349/2000, Val Acc=0.6010, Val Loss=1.8243, lr=0.0100
[2025-05-07 07:17:36,954][train][INFO] - Epoch 1350/2000, Val Acc=0.6277, Val Loss=1.6931, lr=0.0100
[2025-05-07 07:17:43,916][train][INFO] - Epoch 1351/2000, Val Acc=0.6218, Val Loss=1.7675, lr=0.0100
[2025-05-07 07:17:51,195][train][INFO] - Epoch 1352/2000, Val Acc=0.6143, Val Loss=1.8053, lr=0.0100
[2025-05-07 07:17:58,905][train][INFO] - Epoch 1353/2000, Val Acc=0.6191, Val Loss=1.8042, lr=0.0100
[2025-05-07 07:18:05,634][train][INFO] - Epoch 1354/2000, Val Acc=0.6044, Val Loss=1.7949, lr=0.0100
[2025-05-07 07:18:12,628][train][INFO] - Epoch 1355/2000, Val Acc=0.6191, Val Loss=1.7345, lr=0.0100
[2025-05-07 07:18:20,148][train][INFO] - Epoch 1356/2000, Val Acc=0.5984, Val Loss=1.8857, lr=0.0100
[2025-05-07 07:18:27,804][train][INFO] - Epoch 1357/2000, Val Acc=0.6132, Val Loss=1.7485, lr=0.0100
[2025-05-07 07:18:35,164][train][INFO] - Epoch 1358/2000, Val Acc=0.6101, Val Loss=1.7618, lr=0.0100
[2025-05-07 07:18:42,164][train][INFO] - Epoch 1359/2000, Val Acc=0.6185, Val Loss=1.8115, lr=0.0100
[2025-05-07 07:18:49,584][train][INFO] - Epoch 1360/2000, Val Acc=0.6156, Val Loss=1.7573, lr=0.0100
[2025-05-07 07:18:57,293][train][INFO] - Epoch 1361/2000, Val Acc=0.6116, Val Loss=1.7680, lr=0.0100
[2025-05-07 07:19:03,849][train][INFO] - Epoch 1362/2000, Val Acc=0.6205, Val Loss=1.7686, lr=0.0100
[2025-05-07 07:19:11,396][train][INFO] - Epoch 1363/2000, Val Acc=0.6155, Val Loss=1.7695, lr=0.0100
[2025-05-07 07:19:18,974][train][INFO] - Epoch 1364/2000, Val Acc=0.5995, Val Loss=1.8115, lr=0.0100
[2025-05-07 07:19:26,565][train][INFO] - Epoch 1365/2000, Val Acc=0.6301, Val Loss=1.6995, lr=0.0100
[2025-05-07 07:19:33,520][train][INFO] - Epoch 1366/2000, Val Acc=0.6122, Val Loss=1.7545, lr=0.0100
[2025-05-07 07:19:40,904][train][INFO] - Epoch 1367/2000, Val Acc=0.6211, Val Loss=1.7277, lr=0.0100
[2025-05-07 07:19:48,430][train][INFO] - Epoch 1368/2000, Val Acc=0.6056, Val Loss=1.8251, lr=0.0100
[2025-05-07 07:19:55,038][train][INFO] - Epoch 1369/2000, Val Acc=0.6167, Val Loss=1.7943, lr=0.0100
[2025-05-07 07:20:02,793][train][INFO] - Epoch 1370/2000, Val Acc=0.6113, Val Loss=1.7950, lr=0.0100
[2025-05-07 07:20:10,083][train][INFO] - Epoch 1371/2000, Val Acc=0.6177, Val Loss=1.7826, lr=0.0100
[2025-05-07 07:20:17,191][train][INFO] - Epoch 1372/2000, Val Acc=0.6182, Val Loss=1.7469, lr=0.0100
[2025-05-07 07:20:24,659][train][INFO] - Epoch 1373/2000, Val Acc=0.6092, Val Loss=1.7852, lr=0.0100
[2025-05-07 07:20:32,004][train][INFO] - Epoch 1374/2000, Val Acc=0.6077, Val Loss=1.7870, lr=0.0100
[2025-05-07 07:20:39,227][train][INFO] - Epoch 1375/2000, Val Acc=0.6230, Val Loss=1.7225, lr=0.0100
[2025-05-07 07:20:46,018][train][INFO] - Epoch 1376/2000, Val Acc=0.6180, Val Loss=1.7556, lr=0.0100
[2025-05-07 07:20:53,420][train][INFO] - Epoch 1377/2000, Val Acc=0.6152, Val Loss=1.7884, lr=0.0100
[2025-05-07 07:21:00,643][train][INFO] - Epoch 1378/2000, Val Acc=0.5914, Val Loss=1.8997, lr=0.0100
[2025-05-07 07:21:07,651][train][INFO] - Epoch 1379/2000, Val Acc=0.6128, Val Loss=1.7766, lr=0.0100
[2025-05-07 07:21:15,172][train][INFO] - Epoch 1380/2000, Val Acc=0.6130, Val Loss=1.7797, lr=0.0100
[2025-05-07 07:21:22,603][train][INFO] - Epoch 1381/2000, Val Acc=0.6112, Val Loss=1.8083, lr=0.0100
[2025-05-07 07:21:29,234][train][INFO] - Epoch 1382/2000, Val Acc=0.6143, Val Loss=1.7476, lr=0.0100
[2025-05-07 07:21:36,144][train][INFO] - Epoch 1383/2000, Val Acc=0.6216, Val Loss=1.7118, lr=0.0100
[2025-05-07 07:21:44,040][train][INFO] - Epoch 1384/2000, Val Acc=0.6250, Val Loss=1.7151, lr=0.0100
[2025-05-07 07:21:51,397][train][INFO] - Epoch 1385/2000, Val Acc=0.6105, Val Loss=1.8383, lr=0.0100
[2025-05-07 07:21:58,403][train][INFO] - Epoch 1386/2000, Val Acc=0.6195, Val Loss=1.7507, lr=0.0100
[2025-05-07 07:22:05,913][train][INFO] - Epoch 1387/2000, Val Acc=0.6019, Val Loss=1.8282, lr=0.0100
[2025-05-07 07:22:13,623][train][INFO] - Epoch 1388/2000, Val Acc=0.5940, Val Loss=1.9252, lr=0.0100
[2025-05-07 07:22:21,124][train][INFO] - Epoch 1389/2000, Val Acc=0.6119, Val Loss=1.7804, lr=0.0100
[2025-05-07 07:22:27,794][train][INFO] - Epoch 1390/2000, Val Acc=0.6047, Val Loss=1.8298, lr=0.0100
[2025-05-07 07:22:35,091][train][INFO] - Epoch 1391/2000, Val Acc=0.6138, Val Loss=1.7783, lr=0.0100
[2025-05-07 07:22:42,237][train][INFO] - Epoch 1392/2000, Val Acc=0.6137, Val Loss=1.7834, lr=0.0100
[2025-05-07 07:22:49,818][train][INFO] - Epoch 1393/2000, Val Acc=0.6096, Val Loss=1.7955, lr=0.0100
[2025-05-07 07:22:57,652][train][INFO] - Epoch 1394/2000, Val Acc=0.6146, Val Loss=1.7872, lr=0.0100
[2025-05-07 07:23:04,836][train][INFO] - Epoch 1395/2000, Val Acc=0.6021, Val Loss=1.8378, lr=0.0100
[2025-05-07 07:23:11,749][train][INFO] - Epoch 1396/2000, Val Acc=0.6128, Val Loss=1.7609, lr=0.0100
[2025-05-07 07:23:18,799][train][INFO] - Epoch 1397/2000, Val Acc=0.5948, Val Loss=1.9029, lr=0.0100
[2025-05-07 07:23:26,062][train][INFO] - Epoch 1398/2000, Val Acc=0.6165, Val Loss=1.7197, lr=0.0100
[2025-05-07 07:23:33,256][train][INFO] - Epoch 1399/2000, Val Acc=0.6026, Val Loss=1.8713, lr=0.0100
[2025-05-07 07:23:40,540][train][INFO] - Epoch 1400/2000, Val Acc=0.6114, Val Loss=1.7762, lr=0.0100
[2025-05-07 07:23:48,040][train][INFO] - Epoch 1401/2000, Val Acc=0.6119, Val Loss=1.7344, lr=0.0100
[2025-05-07 07:23:55,504][train][INFO] - Epoch 1402/2000, Val Acc=0.6084, Val Loss=1.8668, lr=0.0100
[2025-05-07 07:24:02,980][train][INFO] - Epoch 1403/2000, Val Acc=0.6168, Val Loss=1.7382, lr=0.0100
[2025-05-07 07:24:10,680][train][INFO] - Epoch 1404/2000, Val Acc=0.5781, Val Loss=2.0064, lr=0.0100
[2025-05-07 07:24:18,403][train][INFO] - Epoch 1405/2000, Val Acc=0.6070, Val Loss=1.8080, lr=0.0100
[2025-05-07 07:24:26,070][train][INFO] - Epoch 1406/2000, Val Acc=0.6036, Val Loss=1.7648, lr=0.0100
[2025-05-07 07:24:33,566][train][INFO] - Epoch 1407/2000, Val Acc=0.6177, Val Loss=1.7720, lr=0.0100
[2025-05-07 07:24:40,404][train][INFO] - Epoch 1408/2000, Val Acc=0.6178, Val Loss=1.7377, lr=0.0100
[2025-05-07 07:24:47,808][train][INFO] - Epoch 1409/2000, Val Acc=0.6015, Val Loss=1.8477, lr=0.0100
[2025-05-07 07:24:54,629][train][INFO] - Epoch 1410/2000, Val Acc=0.6221, Val Loss=1.7447, lr=0.0100
[2025-05-07 07:25:02,181][train][INFO] - Epoch 1411/2000, Val Acc=0.6306, Val Loss=1.7371, lr=0.0100
[2025-05-07 07:25:09,642][train][INFO] - Epoch 1412/2000, Val Acc=0.6096, Val Loss=1.8177, lr=0.0100
[2025-05-07 07:25:16,778][train][INFO] - Epoch 1413/2000, Val Acc=0.6116, Val Loss=1.8118, lr=0.0100
[2025-05-07 07:25:23,792][train][INFO] - Epoch 1414/2000, Val Acc=0.6169, Val Loss=1.7603, lr=0.0100
[2025-05-07 07:25:31,617][train][INFO] - Epoch 1415/2000, Val Acc=0.6151, Val Loss=1.7871, lr=0.0100
[2025-05-07 07:25:39,186][train][INFO] - Epoch 1416/2000, Val Acc=0.5984, Val Loss=1.8535, lr=0.0100
[2025-05-07 07:25:46,525][train][INFO] - Epoch 1417/2000, Val Acc=0.6244, Val Loss=1.7255, lr=0.0100
[2025-05-07 07:25:54,142][train][INFO] - Epoch 1418/2000, Val Acc=0.6185, Val Loss=1.7321, lr=0.0100
[2025-05-07 07:26:01,341][train][INFO] - Epoch 1419/2000, Val Acc=0.6126, Val Loss=1.7868, lr=0.0100
[2025-05-07 07:26:08,584][train][INFO] - Epoch 1420/2000, Val Acc=0.6244, Val Loss=1.7259, lr=0.0100
[2025-05-07 07:26:15,817][train][INFO] - Epoch 1421/2000, Val Acc=0.6163, Val Loss=1.7212, lr=0.0100
[2025-05-07 07:26:23,443][train][INFO] - Epoch 1422/2000, Val Acc=0.6090, Val Loss=1.8644, lr=0.0100
[2025-05-07 07:26:30,963][train][INFO] - Epoch 1423/2000, Val Acc=0.6112, Val Loss=1.7871, lr=0.0100
[2025-05-07 07:26:37,892][train][INFO] - Epoch 1424/2000, Val Acc=0.5989, Val Loss=1.8766, lr=0.0100
[2025-05-07 07:26:45,421][train][INFO] - Epoch 1425/2000, Val Acc=0.6132, Val Loss=1.7999, lr=0.0100
[2025-05-07 07:26:52,630][train][INFO] - Epoch 1426/2000, Val Acc=0.6084, Val Loss=1.7957, lr=0.0100
[2025-05-07 07:27:00,316][train][INFO] - Epoch 1427/2000, Val Acc=0.6034, Val Loss=1.7978, lr=0.0100
[2025-05-07 07:27:07,810][train][INFO] - Epoch 1428/2000, Val Acc=0.6097, Val Loss=1.8188, lr=0.0100
[2025-05-07 07:27:15,132][train][INFO] - Epoch 1429/2000, Val Acc=0.6131, Val Loss=1.7601, lr=0.0100
[2025-05-07 07:27:22,437][train][INFO] - Epoch 1430/2000, Val Acc=0.6186, Val Loss=1.7656, lr=0.0100
[2025-05-07 07:27:29,594][train][INFO] - Epoch 1431/2000, Val Acc=0.6105, Val Loss=1.8068, lr=0.0100
[2025-05-07 07:27:37,058][train][INFO] - Epoch 1432/2000, Val Acc=0.6213, Val Loss=1.7292, lr=0.0100
[2025-05-07 07:27:44,640][train][INFO] - Epoch 1433/2000, Val Acc=0.6143, Val Loss=1.7387, lr=0.0100
[2025-05-07 07:27:52,023][train][INFO] - Epoch 1434/2000, Val Acc=0.6121, Val Loss=1.7849, lr=0.0100
[2025-05-07 07:27:59,166][train][INFO] - Epoch 1435/2000, Val Acc=0.6135, Val Loss=1.7879, lr=0.0100
[2025-05-07 07:28:06,605][train][INFO] - Epoch 1436/2000, Val Acc=0.6177, Val Loss=1.7268, lr=0.0100
[2025-05-07 07:28:14,190][train][INFO] - Epoch 1437/2000, Val Acc=0.6066, Val Loss=1.7938, lr=0.0100
[2025-05-07 07:28:21,606][train][INFO] - Epoch 1438/2000, Val Acc=0.6130, Val Loss=1.8114, lr=0.0100
[2025-05-07 07:28:29,359][train][INFO] - Epoch 1439/2000, Val Acc=0.6055, Val Loss=1.8300, lr=0.0100
[2025-05-07 07:28:36,310][train][INFO] - Epoch 1440/2000, Val Acc=0.6111, Val Loss=1.7477, lr=0.0100
[2025-05-07 07:28:43,651][train][INFO] - Epoch 1441/2000, Val Acc=0.6155, Val Loss=1.7887, lr=0.0100
[2025-05-07 07:28:49,848][train][INFO] - Epoch 1442/2000, Val Acc=0.6143, Val Loss=1.7603, lr=0.0100
[2025-05-07 07:28:57,426][train][INFO] - Epoch 1443/2000, Val Acc=0.6123, Val Loss=1.8068, lr=0.0100
[2025-05-07 07:29:05,044][train][INFO] - Epoch 1444/2000, Val Acc=0.6078, Val Loss=1.7832, lr=0.0100
[2025-05-07 07:29:12,411][train][INFO] - Epoch 1445/2000, Val Acc=0.6054, Val Loss=1.8032, lr=0.0100
[2025-05-07 07:29:19,539][train][INFO] - Epoch 1446/2000, Val Acc=0.6052, Val Loss=1.8788, lr=0.0100
[2025-05-07 07:29:26,606][train][INFO] - Epoch 1447/2000, Val Acc=0.6108, Val Loss=1.7873, lr=0.0100
[2025-05-07 07:29:34,279][train][INFO] - Epoch 1448/2000, Val Acc=0.5946, Val Loss=1.8675, lr=0.0100
[2025-05-07 07:29:41,820][train][INFO] - Epoch 1449/2000, Val Acc=0.6090, Val Loss=1.8646, lr=0.0100
[2025-05-07 07:29:49,550][train][INFO] - Epoch 1450/2000, Val Acc=0.6240, Val Loss=1.7049, lr=0.0100
[2025-05-07 07:29:56,736][train][INFO] - Epoch 1451/2000, Val Acc=0.6142, Val Loss=1.7899, lr=0.0100
[2025-05-07 07:30:04,128][train][INFO] - Epoch 1452/2000, Val Acc=0.6162, Val Loss=1.7746, lr=0.0100
[2025-05-07 07:30:11,299][train][INFO] - Epoch 1453/2000, Val Acc=0.6126, Val Loss=1.7662, lr=0.0100
[2025-05-07 07:30:18,664][train][INFO] - Epoch 1454/2000, Val Acc=0.6050, Val Loss=1.8148, lr=0.0100
[2025-05-07 07:30:26,223][train][INFO] - Epoch 1455/2000, Val Acc=0.6100, Val Loss=1.7937, lr=0.0100
[2025-05-07 07:30:33,536][train][INFO] - Epoch 1456/2000, Val Acc=0.6187, Val Loss=1.7325, lr=0.0100
[2025-05-07 07:30:41,185][train][INFO] - Epoch 1457/2000, Val Acc=0.6169, Val Loss=1.7945, lr=0.0100
[2025-05-07 07:30:48,862][train][INFO] - Epoch 1458/2000, Val Acc=0.6032, Val Loss=1.7960, lr=0.0100
[2025-05-07 07:30:55,956][train][INFO] - Epoch 1459/2000, Val Acc=0.6161, Val Loss=1.7491, lr=0.0100
[2025-05-07 07:31:03,809][train][INFO] - Epoch 1460/2000, Val Acc=0.5962, Val Loss=1.8782, lr=0.0100
[2025-05-07 07:31:11,274][train][INFO] - Epoch 1461/2000, Val Acc=0.6308, Val Loss=1.6599, lr=0.0100
[2025-05-07 07:31:18,054][train][INFO] - Epoch 1462/2000, Val Acc=0.6185, Val Loss=1.7164, lr=0.0100
[2025-05-07 07:31:24,949][train][INFO] - Epoch 1463/2000, Val Acc=0.6081, Val Loss=1.8052, lr=0.0100
[2025-05-07 07:31:32,566][train][INFO] - Epoch 1464/2000, Val Acc=0.6272, Val Loss=1.7062, lr=0.0100
[2025-05-07 07:31:40,076][train][INFO] - Epoch 1465/2000, Val Acc=0.6235, Val Loss=1.7935, lr=0.0100
[2025-05-07 07:31:47,695][train][INFO] - Epoch 1466/2000, Val Acc=0.6108, Val Loss=1.8452, lr=0.0100
[2025-05-07 07:31:54,915][train][INFO] - Epoch 1467/2000, Val Acc=0.6151, Val Loss=1.7435, lr=0.0100
[2025-05-07 07:32:01,998][train][INFO] - Epoch 1468/2000, Val Acc=0.5871, Val Loss=1.9822, lr=0.0100
[2025-05-07 07:32:09,496][train][INFO] - Epoch 1469/2000, Val Acc=0.6014, Val Loss=1.8616, lr=0.0100
[2025-05-07 07:32:16,562][train][INFO] - Epoch 1470/2000, Val Acc=0.6052, Val Loss=1.8315, lr=0.0100
[2025-05-07 07:32:23,781][train][INFO] - Epoch 1471/2000, Val Acc=0.6147, Val Loss=1.8151, lr=0.0100
[2025-05-07 07:32:31,295][train][INFO] - Epoch 1472/2000, Val Acc=0.6127, Val Loss=1.7950, lr=0.0100
[2025-05-07 07:32:38,501][train][INFO] - Epoch 1473/2000, Val Acc=0.6214, Val Loss=1.7273, lr=0.0100
[2025-05-07 07:32:46,281][train][INFO] - Epoch 1474/2000, Val Acc=0.6098, Val Loss=1.8261, lr=0.0100
[2025-05-07 07:32:53,624][train][INFO] - Epoch 1475/2000, Val Acc=0.6125, Val Loss=1.7838, lr=0.0100
[2025-05-07 07:33:00,842][train][INFO] - Epoch 1476/2000, Val Acc=0.6167, Val Loss=1.7655, lr=0.0100
[2025-05-07 07:33:08,073][train][INFO] - Epoch 1477/2000, Val Acc=0.6120, Val Loss=1.8161, lr=0.0100
[2025-05-07 07:33:16,083][train][INFO] - Epoch 1478/2000, Val Acc=0.6121, Val Loss=1.7955, lr=0.0100
[2025-05-07 07:33:23,450][train][INFO] - Epoch 1479/2000, Val Acc=0.6074, Val Loss=1.7903, lr=0.0100
[2025-05-07 07:33:30,525][train][INFO] - Epoch 1480/2000, Val Acc=0.6015, Val Loss=1.8091, lr=0.0100
[2025-05-07 07:33:38,131][train][INFO] - Epoch 1481/2000, Val Acc=0.6294, Val Loss=1.6967, lr=0.0100
[2025-05-07 07:33:44,689][train][INFO] - Epoch 1482/2000, Val Acc=0.6110, Val Loss=1.7514, lr=0.0100
[2025-05-07 07:33:51,883][train][INFO] - Epoch 1483/2000, Val Acc=0.6186, Val Loss=1.7658, lr=0.0100
[2025-05-07 07:33:58,125][train][INFO] - Epoch 1484/2000, Val Acc=0.6196, Val Loss=1.7287, lr=0.0100
[2025-05-07 07:34:05,594][train][INFO] - Epoch 1485/2000, Val Acc=0.6209, Val Loss=1.7120, lr=0.0100
[2025-05-07 07:34:13,329][train][INFO] - Epoch 1486/2000, Val Acc=0.6336, Val Loss=1.6731, lr=0.0100
[2025-05-07 07:34:20,238][train][INFO] - Epoch 1487/2000, Val Acc=0.6036, Val Loss=1.8202, lr=0.0100
[2025-05-07 07:34:27,387][train][INFO] - Epoch 1488/2000, Val Acc=0.6179, Val Loss=1.7247, lr=0.0100
[2025-05-07 07:34:34,316][train][INFO] - Epoch 1489/2000, Val Acc=0.6217, Val Loss=1.6952, lr=0.0100
[2025-05-07 07:34:41,623][train][INFO] - Epoch 1490/2000, Val Acc=0.6108, Val Loss=1.8341, lr=0.0100
[2025-05-07 07:34:49,365][train][INFO] - Epoch 1491/2000, Val Acc=0.5989, Val Loss=1.8794, lr=0.0100
[2025-05-07 07:34:55,449][train][INFO] - Epoch 1492/2000, Val Acc=0.5908, Val Loss=1.9572, lr=0.0100
[2025-05-07 07:35:02,581][train][INFO] - Epoch 1493/2000, Val Acc=0.6150, Val Loss=1.7527, lr=0.0100
[2025-05-07 07:35:10,193][train][INFO] - Epoch 1494/2000, Val Acc=0.6141, Val Loss=1.8178, lr=0.0100
[2025-05-07 07:35:16,994][train][INFO] - Epoch 1495/2000, Val Acc=0.6149, Val Loss=1.8031, lr=0.0100
[2025-05-07 07:35:24,412][train][INFO] - Epoch 1496/2000, Val Acc=0.6221, Val Loss=1.7347, lr=0.0100
[2025-05-07 07:35:31,877][train][INFO] - Epoch 1497/2000, Val Acc=0.6199, Val Loss=1.7508, lr=0.0100
[2025-05-07 07:35:39,374][train][INFO] - Epoch 1498/2000, Val Acc=0.5903, Val Loss=1.9533, lr=0.0100
[2025-05-07 07:35:46,917][train][INFO] - Epoch 1499/2000, Val Acc=0.6121, Val Loss=1.8044, lr=0.0100
[2025-05-07 07:35:53,637][train][INFO] - Epoch 1500/2000, Val Acc=0.6159, Val Loss=1.8289, lr=0.0100
[2025-05-07 07:36:00,745][train][INFO] - Epoch 1501/2000, Val Acc=0.6120, Val Loss=1.8491, lr=0.0100
[2025-05-07 07:36:08,382][train][INFO] - Epoch 1502/2000, Val Acc=0.6098, Val Loss=1.7629, lr=0.0100
[2025-05-07 07:36:15,563][train][INFO] - Epoch 1503/2000, Val Acc=0.6127, Val Loss=1.8107, lr=0.0100
[2025-05-07 07:36:23,247][train][INFO] - Epoch 1504/2000, Val Acc=0.6040, Val Loss=1.8751, lr=0.0100
[2025-05-07 07:36:30,647][train][INFO] - Epoch 1505/2000, Val Acc=0.6129, Val Loss=1.7664, lr=0.0100
[2025-05-07 07:36:38,036][train][INFO] - Epoch 1506/2000, Val Acc=0.6296, Val Loss=1.6752, lr=0.0100
[2025-05-07 07:36:46,086][train][INFO] - Epoch 1507/2000, Val Acc=0.6051, Val Loss=1.8353, lr=0.0100
[2025-05-07 07:36:53,442][train][INFO] - Epoch 1508/2000, Val Acc=0.5880, Val Loss=1.9873, lr=0.0100
[2025-05-07 07:37:01,467][train][INFO] - Epoch 1509/2000, Val Acc=0.6144, Val Loss=1.7869, lr=0.0100
[2025-05-07 07:37:09,075][train][INFO] - Epoch 1510/2000, Val Acc=0.6144, Val Loss=1.7670, lr=0.0100
[2025-05-07 07:37:16,205][train][INFO] - Epoch 1511/2000, Val Acc=0.6182, Val Loss=1.6988, lr=0.0100
[2025-05-07 07:37:24,064][train][INFO] - Epoch 1512/2000, Val Acc=0.6163, Val Loss=1.7530, lr=0.0100
[2025-05-07 07:37:31,742][train][INFO] - Epoch 1513/2000, Val Acc=0.6169, Val Loss=1.7591, lr=0.0100
[2025-05-07 07:37:39,386][train][INFO] - Epoch 1514/2000, Val Acc=0.6064, Val Loss=1.7973, lr=0.0100
[2025-05-07 07:37:46,588][train][INFO] - Epoch 1515/2000, Val Acc=0.5981, Val Loss=1.8165, lr=0.0100
[2025-05-07 07:37:54,021][train][INFO] - Epoch 1516/2000, Val Acc=0.6000, Val Loss=1.8565, lr=0.0100
[2025-05-07 07:38:01,769][train][INFO] - Epoch 1517/2000, Val Acc=0.5964, Val Loss=1.9036, lr=0.0100
[2025-05-07 07:38:09,259][train][INFO] - Epoch 1518/2000, Val Acc=0.6174, Val Loss=1.7929, lr=0.0100
[2025-05-07 07:38:16,223][train][INFO] - Epoch 1519/2000, Val Acc=0.5969, Val Loss=1.9197, lr=0.0100
[2025-05-07 07:38:23,975][train][INFO] - Epoch 1520/2000, Val Acc=0.6114, Val Loss=1.7944, lr=0.0100
[2025-05-07 07:38:31,403][train][INFO] - Epoch 1521/2000, Val Acc=0.6019, Val Loss=1.9018, lr=0.0100
[2025-05-07 07:38:39,106][train][INFO] - Epoch 1522/2000, Val Acc=0.6243, Val Loss=1.7380, lr=0.0100
[2025-05-07 07:38:46,076][train][INFO] - Epoch 1523/2000, Val Acc=0.6150, Val Loss=1.7733, lr=0.0100
[2025-05-07 07:38:53,673][train][INFO] - Epoch 1524/2000, Val Acc=0.6208, Val Loss=1.7325, lr=0.0100
[2025-05-07 07:39:01,168][train][INFO] - Epoch 1525/2000, Val Acc=0.6225, Val Loss=1.7561, lr=0.0100
[2025-05-07 07:39:08,610][train][INFO] - Epoch 1526/2000, Val Acc=0.6243, Val Loss=1.7417, lr=0.0100
[2025-05-07 07:39:15,713][train][INFO] - Epoch 1527/2000, Val Acc=0.6222, Val Loss=1.7446, lr=0.0100
[2025-05-07 07:39:22,987][train][INFO] - Epoch 1528/2000, Val Acc=0.6157, Val Loss=1.8043, lr=0.0100
[2025-05-07 07:39:30,648][train][INFO] - Epoch 1529/2000, Val Acc=0.6061, Val Loss=1.8164, lr=0.0100
[2025-05-07 07:39:37,897][train][INFO] - Epoch 1530/2000, Val Acc=0.6048, Val Loss=1.8362, lr=0.0100
[2025-05-07 07:39:45,345][train][INFO] - Epoch 1531/2000, Val Acc=0.6138, Val Loss=1.7457, lr=0.0100
[2025-05-07 07:39:51,213][train][INFO] - Epoch 1532/2000, Val Acc=0.6100, Val Loss=1.7474, lr=0.0100
[2025-05-07 07:39:58,661][train][INFO] - Epoch 1533/2000, Val Acc=0.6201, Val Loss=1.7396, lr=0.0100
[2025-05-07 07:40:06,229][train][INFO] - Epoch 1534/2000, Val Acc=0.6102, Val Loss=1.8416, lr=0.0100
[2025-05-07 07:40:13,374][train][INFO] - Epoch 1535/2000, Val Acc=0.6165, Val Loss=1.8045, lr=0.0100
[2025-05-07 07:40:21,309][train][INFO] - Epoch 1536/2000, Val Acc=0.6031, Val Loss=1.7960, lr=0.0100
[2025-05-07 07:40:28,723][train][INFO] - Epoch 1537/2000, Val Acc=0.6231, Val Loss=1.7168, lr=0.0100
[2025-05-07 07:40:36,058][train][INFO] - Epoch 1538/2000, Val Acc=0.6133, Val Loss=1.7328, lr=0.0100
[2025-05-07 07:40:43,749][train][INFO] - Epoch 1539/2000, Val Acc=0.6050, Val Loss=1.8105, lr=0.0100
[2025-05-07 07:40:51,005][train][INFO] - Epoch 1540/2000, Val Acc=0.6124, Val Loss=1.8283, lr=0.0100
[2025-05-07 07:40:58,536][train][INFO] - Epoch 1541/2000, Val Acc=0.6004, Val Loss=1.9051, lr=0.0100
[2025-05-07 07:41:06,037][train][INFO] - Epoch 1542/2000, Val Acc=0.6040, Val Loss=1.8254, lr=0.0100
[2025-05-07 07:41:13,562][train][INFO] - Epoch 1543/2000, Val Acc=0.6216, Val Loss=1.7450, lr=0.0100
[2025-05-07 07:41:20,496][train][INFO] - Epoch 1544/2000, Val Acc=0.6159, Val Loss=1.7884, lr=0.0100
[2025-05-07 07:41:27,797][train][INFO] - Epoch 1545/2000, Val Acc=0.6149, Val Loss=1.7796, lr=0.0100
[2025-05-07 07:41:35,131][train][INFO] - Epoch 1546/2000, Val Acc=0.6142, Val Loss=1.8098, lr=0.0100
[2025-05-07 07:41:42,342][train][INFO] - Epoch 1547/2000, Val Acc=0.6104, Val Loss=1.7764, lr=0.0100
[2025-05-07 07:41:49,967][train][INFO] - Epoch 1548/2000, Val Acc=0.6172, Val Loss=1.7228, lr=0.0100
[2025-05-07 07:41:56,973][train][INFO] - Epoch 1549/2000, Val Acc=0.6016, Val Loss=1.8387, lr=0.0100
[2025-05-07 07:42:04,176][train][INFO] - Epoch 1550/2000, Val Acc=0.6150, Val Loss=1.7899, lr=0.0100
[2025-05-07 07:42:11,491][train][INFO] - Epoch 1551/2000, Val Acc=0.6073, Val Loss=1.8472, lr=0.0100
[2025-05-07 07:42:18,210][train][INFO] - Epoch 1552/2000, Val Acc=0.6214, Val Loss=1.7048, lr=0.0100
[2025-05-07 07:42:26,110][train][INFO] - Epoch 1553/2000, Val Acc=0.6285, Val Loss=1.7082, lr=0.0100
[2025-05-07 07:42:34,058][train][INFO] - Epoch 1554/2000, Val Acc=0.5890, Val Loss=1.9033, lr=0.0100
[2025-05-07 07:42:41,535][train][INFO] - Epoch 1555/2000, Val Acc=0.6074, Val Loss=1.8178, lr=0.0100
[2025-05-07 07:42:48,711][train][INFO] - Epoch 1556/2000, Val Acc=0.5941, Val Loss=1.8864, lr=0.0100
[2025-05-07 07:42:55,364][train][INFO] - Epoch 1557/2000, Val Acc=0.5999, Val Loss=1.9107, lr=0.0100
[2025-05-07 07:43:02,439][train][INFO] - Epoch 1558/2000, Val Acc=0.6124, Val Loss=1.7996, lr=0.0100
[2025-05-07 07:43:09,714][train][INFO] - Epoch 1559/2000, Val Acc=0.6176, Val Loss=1.7478, lr=0.0100
[2025-05-07 07:43:17,169][train][INFO] - Epoch 1560/2000, Val Acc=0.6177, Val Loss=1.7595, lr=0.0100
[2025-05-07 07:43:23,068][train][INFO] - Epoch 1561/2000, Val Acc=0.6128, Val Loss=1.7626, lr=0.0100
[2025-05-07 07:43:29,474][train][INFO] - Epoch 1562/2000, Val Acc=0.6159, Val Loss=1.7726, lr=0.0100
[2025-05-07 07:43:37,036][train][INFO] - Epoch 1563/2000, Val Acc=0.6259, Val Loss=1.7613, lr=0.0100
[2025-05-07 07:43:44,223][train][INFO] - Epoch 1564/2000, Val Acc=0.6156, Val Loss=1.8084, lr=0.0100
[2025-05-07 07:43:52,082][train][INFO] - Epoch 1565/2000, Val Acc=0.6145, Val Loss=1.7738, lr=0.0100
[2025-05-07 07:43:59,403][train][INFO] - Epoch 1566/2000, Val Acc=0.5988, Val Loss=1.9180, lr=0.0100
[2025-05-07 07:44:06,717][train][INFO] - Epoch 1567/2000, Val Acc=0.6216, Val Loss=1.7383, lr=0.0100
[2025-05-07 07:44:14,134][train][INFO] - Epoch 1568/2000, Val Acc=0.6083, Val Loss=1.8531, lr=0.0100
[2025-05-07 07:44:21,845][train][INFO] - Epoch 1569/2000, Val Acc=0.6078, Val Loss=1.8838, lr=0.0100
[2025-05-07 07:44:28,515][train][INFO] - Epoch 1570/2000, Val Acc=0.6187, Val Loss=1.7154, lr=0.0100
[2025-05-07 07:44:35,229][train][INFO] - Epoch 1571/2000, Val Acc=0.6137, Val Loss=1.7904, lr=0.0100
[2025-05-07 07:44:42,359][train][INFO] - Epoch 1572/2000, Val Acc=0.6143, Val Loss=1.7551, lr=0.0100
[2025-05-07 07:44:50,089][train][INFO] - Epoch 1573/2000, Val Acc=0.6216, Val Loss=1.7187, lr=0.0100
[2025-05-07 07:44:57,533][train][INFO] - Epoch 1574/2000, Val Acc=0.6221, Val Loss=1.7775, lr=0.0100
[2025-05-07 07:45:05,265][train][INFO] - Epoch 1575/2000, Val Acc=0.6160, Val Loss=1.8125, lr=0.0100
[2025-05-07 07:45:12,373][train][INFO] - Epoch 1576/2000, Val Acc=0.6114, Val Loss=1.8141, lr=0.0100
[2025-05-07 07:45:19,601][train][INFO] - Epoch 1577/2000, Val Acc=0.6219, Val Loss=1.7359, lr=0.0100
[2025-05-07 07:45:27,085][train][INFO] - Epoch 1578/2000, Val Acc=0.6254, Val Loss=1.7106, lr=0.0100
[2025-05-07 07:45:34,177][train][INFO] - Epoch 1579/2000, Val Acc=0.6173, Val Loss=1.7776, lr=0.0100
[2025-05-07 07:45:41,126][train][INFO] - Epoch 1580/2000, Val Acc=0.6156, Val Loss=1.7650, lr=0.0100
[2025-05-07 07:45:48,740][train][INFO] - Epoch 1581/2000, Val Acc=0.5957, Val Loss=1.8794, lr=0.0100
[2025-05-07 07:45:55,950][train][INFO] - Epoch 1582/2000, Val Acc=0.6018, Val Loss=1.8460, lr=0.0100
[2025-05-07 07:46:02,979][train][INFO] - Epoch 1583/2000, Val Acc=0.6146, Val Loss=1.7399, lr=0.0100
[2025-05-07 07:46:10,547][train][INFO] - Epoch 1584/2000, Val Acc=0.6178, Val Loss=1.7710, lr=0.0100
[2025-05-07 07:46:18,021][train][INFO] - Epoch 1585/2000, Val Acc=0.6146, Val Loss=1.7848, lr=0.0100
[2025-05-07 07:46:25,647][train][INFO] - Epoch 1586/2000, Val Acc=0.6309, Val Loss=1.6793, lr=0.0100
[2025-05-07 07:46:32,703][train][INFO] - Epoch 1587/2000, Val Acc=0.6151, Val Loss=1.7629, lr=0.0100
[2025-05-07 07:46:40,361][train][INFO] - Epoch 1588/2000, Val Acc=0.6018, Val Loss=1.8514, lr=0.0100
[2025-05-07 07:46:47,815][train][INFO] - Epoch 1589/2000, Val Acc=0.6199, Val Loss=1.7239, lr=0.0100
[2025-05-07 07:46:54,840][train][INFO] - Epoch 1590/2000, Val Acc=0.6232, Val Loss=1.6822, lr=0.0100
[2025-05-07 07:47:02,028][train][INFO] - Epoch 1591/2000, Val Acc=0.5855, Val Loss=1.9342, lr=0.0100
[2025-05-07 07:47:09,369][train][INFO] - Epoch 1592/2000, Val Acc=0.6252, Val Loss=1.6755, lr=0.0100
[2025-05-07 07:47:16,883][train][INFO] - Epoch 1593/2000, Val Acc=0.6107, Val Loss=1.7767, lr=0.0100
[2025-05-07 07:47:23,697][train][INFO] - Epoch 1594/2000, Val Acc=0.6148, Val Loss=1.7752, lr=0.0100
[2025-05-07 07:47:30,855][train][INFO] - Epoch 1595/2000, Val Acc=0.6061, Val Loss=1.7962, lr=0.0100
[2025-05-07 07:47:38,045][train][INFO] - Epoch 1596/2000, Val Acc=0.6157, Val Loss=1.7570, lr=0.0100
[2025-05-07 07:47:44,604][train][INFO] - Epoch 1597/2000, Val Acc=0.6112, Val Loss=1.7624, lr=0.0100
[2025-05-07 07:47:51,763][train][INFO] - Epoch 1598/2000, Val Acc=0.6126, Val Loss=1.7664, lr=0.0100
[2025-05-07 07:47:58,640][train][INFO] - Epoch 1599/2000, Val Acc=0.6131, Val Loss=1.8112, lr=0.0100
[2025-05-07 07:48:05,898][train][INFO] - Epoch 1600/2000, Val Acc=0.6063, Val Loss=1.8170, lr=0.0100
[2025-05-07 07:48:12,515][train][INFO] - Epoch 1601/2000, Val Acc=0.6103, Val Loss=1.8092, lr=0.0100
[2025-05-07 07:48:19,499][train][INFO] - Epoch 1602/2000, Val Acc=0.6166, Val Loss=1.7704, lr=0.0100
[2025-05-07 07:48:26,886][train][INFO] - Epoch 1603/2000, Val Acc=0.6053, Val Loss=1.8236, lr=0.0100
[2025-05-07 07:48:34,657][train][INFO] - Epoch 1604/2000, Val Acc=0.6082, Val Loss=1.8295, lr=0.0100
[2025-05-07 07:48:42,004][train][INFO] - Epoch 1605/2000, Val Acc=0.6106, Val Loss=1.7658, lr=0.0100
[2025-05-07 07:48:49,258][train][INFO] - Epoch 1606/2000, Val Acc=0.6208, Val Loss=1.7396, lr=0.0100
[2025-05-07 07:48:56,714][train][INFO] - Epoch 1607/2000, Val Acc=0.6076, Val Loss=1.8344, lr=0.0100
[2025-05-07 07:49:03,994][train][INFO] - Epoch 1608/2000, Val Acc=0.6039, Val Loss=1.8561, lr=0.0100
[2025-05-07 07:49:10,887][train][INFO] - Epoch 1609/2000, Val Acc=0.6029, Val Loss=1.8125, lr=0.0100
[2025-05-07 07:49:17,883][train][INFO] - Epoch 1610/2000, Val Acc=0.6046, Val Loss=1.8343, lr=0.0100
[2025-05-07 07:49:25,232][train][INFO] - Epoch 1611/2000, Val Acc=0.6134, Val Loss=1.7933, lr=0.0100
[2025-05-07 07:49:32,887][train][INFO] - Epoch 1612/2000, Val Acc=0.6137, Val Loss=1.7631, lr=0.0100
[2025-05-07 07:49:40,025][train][INFO] - Epoch 1613/2000, Val Acc=0.6308, Val Loss=1.6726, lr=0.0100
[2025-05-07 07:49:47,154][train][INFO] - Epoch 1614/2000, Val Acc=0.5871, Val Loss=1.9690, lr=0.0100
[2025-05-07 07:49:54,725][train][INFO] - Epoch 1615/2000, Val Acc=0.6352, Val Loss=1.6664, lr=0.0100
[2025-05-07 07:50:01,940][train][INFO] - Epoch 1616/2000, Val Acc=0.6100, Val Loss=1.7749, lr=0.0100
[2025-05-07 07:50:09,427][train][INFO] - Epoch 1617/2000, Val Acc=0.5994, Val Loss=1.8533, lr=0.0100
[2025-05-07 07:50:16,319][train][INFO] - Epoch 1618/2000, Val Acc=0.6090, Val Loss=1.7928, lr=0.0100
[2025-05-07 07:50:23,485][train][INFO] - Epoch 1619/2000, Val Acc=0.6188, Val Loss=1.7700, lr=0.0100
[2025-05-07 07:50:30,253][train][INFO] - Epoch 1620/2000, Val Acc=0.6226, Val Loss=1.7775, lr=0.0100
[2025-05-07 07:50:37,585][train][INFO] - Epoch 1621/2000, Val Acc=0.6088, Val Loss=1.7955, lr=0.0100
[2025-05-07 07:50:44,798][train][INFO] - Epoch 1622/2000, Val Acc=0.6102, Val Loss=1.7942, lr=0.0100
[2025-05-07 07:50:51,743][train][INFO] - Epoch 1623/2000, Val Acc=0.6293, Val Loss=1.6812, lr=0.0100
[2025-05-07 07:50:58,427][train][INFO] - Epoch 1624/2000, Val Acc=0.6156, Val Loss=1.7706, lr=0.0100
[2025-05-07 07:51:05,688][train][INFO] - Epoch 1625/2000, Val Acc=0.6093, Val Loss=1.8135, lr=0.0100
[2025-05-07 07:51:13,269][train][INFO] - Epoch 1626/2000, Val Acc=0.6211, Val Loss=1.7132, lr=0.0100
[2025-05-07 07:51:19,267][train][INFO] - Epoch 1627/2000, Val Acc=0.6266, Val Loss=1.7040, lr=0.0100
[2025-05-07 07:51:26,163][train][INFO] - Epoch 1628/2000, Val Acc=0.6223, Val Loss=1.7324, lr=0.0100
[2025-05-07 07:51:33,503][train][INFO] - Epoch 1629/2000, Val Acc=0.6283, Val Loss=1.7026, lr=0.0100
[2025-05-07 07:51:40,863][train][INFO] - Epoch 1630/2000, Val Acc=0.6071, Val Loss=1.7700, lr=0.0100
[2025-05-07 07:51:48,057][train][INFO] - Epoch 1631/2000, Val Acc=0.6207, Val Loss=1.7154, lr=0.0100
[2025-05-07 07:51:55,376][train][INFO] - Epoch 1632/2000, Val Acc=0.6159, Val Loss=1.7924, lr=0.0100
[2025-05-07 07:52:02,812][train][INFO] - Epoch 1633/2000, Val Acc=0.6126, Val Loss=1.8013, lr=0.0100
[2025-05-07 07:52:10,268][train][INFO] - Epoch 1634/2000, Val Acc=0.6204, Val Loss=1.7434, lr=0.0100
[2025-05-07 07:52:18,090][train][INFO] - Epoch 1635/2000, Val Acc=0.6141, Val Loss=1.8295, lr=0.0100
[2025-05-07 07:52:25,400][train][INFO] - Epoch 1636/2000, Val Acc=0.6190, Val Loss=1.7776, lr=0.0100
[2025-05-07 07:52:33,106][train][INFO] - Epoch 1637/2000, Val Acc=0.6152, Val Loss=1.7450, lr=0.0100
[2025-05-07 07:52:40,548][train][INFO] - Epoch 1638/2000, Val Acc=0.6173, Val Loss=1.8298, lr=0.0100
[2025-05-07 07:52:47,597][train][INFO] - Epoch 1639/2000, Val Acc=0.6127, Val Loss=1.7960, lr=0.0100
[2025-05-07 07:52:54,962][train][INFO] - Epoch 1640/2000, Val Acc=0.6163, Val Loss=1.7589, lr=0.0100
[2025-05-07 07:53:02,073][train][INFO] - Epoch 1641/2000, Val Acc=0.6068, Val Loss=1.8577, lr=0.0100
[2025-05-07 07:53:09,450][train][INFO] - Epoch 1642/2000, Val Acc=0.6230, Val Loss=1.7177, lr=0.0100
[2025-05-07 07:53:17,164][train][INFO] - Epoch 1643/2000, Val Acc=0.6198, Val Loss=1.7403, lr=0.0100
[2025-05-07 07:53:25,073][train][INFO] - Epoch 1644/2000, Val Acc=0.6182, Val Loss=1.7555, lr=0.0100
[2025-05-07 07:53:32,425][train][INFO] - Epoch 1645/2000, Val Acc=0.6234, Val Loss=1.7581, lr=0.0100
[2025-05-07 07:53:39,822][train][INFO] - Epoch 1646/2000, Val Acc=0.6171, Val Loss=1.7545, lr=0.0100
[2025-05-07 07:53:47,033][train][INFO] - Epoch 1647/2000, Val Acc=0.6070, Val Loss=1.7896, lr=0.0100
[2025-05-07 07:53:54,175][train][INFO] - Epoch 1648/2000, Val Acc=0.6301, Val Loss=1.6673, lr=0.0100
[2025-05-07 07:54:01,729][train][INFO] - Epoch 1649/2000, Val Acc=0.6176, Val Loss=1.7825, lr=0.0100
[2025-05-07 07:54:09,015][train][INFO] - Epoch 1650/2000, Val Acc=0.6103, Val Loss=1.8036, lr=0.0100
[2025-05-07 07:54:17,056][train][INFO] - Epoch 1651/2000, Val Acc=0.6156, Val Loss=1.7466, lr=0.0100
[2025-05-07 07:54:25,162][train][INFO] - Epoch 1652/2000, Val Acc=0.6212, Val Loss=1.7590, lr=0.0100
[2025-05-07 07:54:32,861][train][INFO] - Epoch 1653/2000, Val Acc=0.6192, Val Loss=1.7539, lr=0.0100
[2025-05-07 07:54:39,991][train][INFO] - Epoch 1654/2000, Val Acc=0.6122, Val Loss=1.7852, lr=0.0100
[2025-05-07 07:54:47,318][train][INFO] - Epoch 1655/2000, Val Acc=0.6155, Val Loss=1.7458, lr=0.0100
[2025-05-07 07:54:54,795][train][INFO] - Epoch 1656/2000, Val Acc=0.5948, Val Loss=1.8949, lr=0.0100
[2025-05-07 07:55:02,671][train][INFO] - Epoch 1657/2000, Val Acc=0.6181, Val Loss=1.7727, lr=0.0100
[2025-05-07 07:55:09,903][train][INFO] - Epoch 1658/2000, Val Acc=0.5986, Val Loss=1.8464, lr=0.0100
[2025-05-07 07:55:17,731][train][INFO] - Epoch 1659/2000, Val Acc=0.6036, Val Loss=1.8078, lr=0.0100
[2025-05-07 07:55:24,832][train][INFO] - Epoch 1660/2000, Val Acc=0.6119, Val Loss=1.8214, lr=0.0100
[2025-05-07 07:55:32,260][train][INFO] - Epoch 1661/2000, Val Acc=0.6148, Val Loss=1.8064, lr=0.0100
[2025-05-07 07:55:39,599][train][INFO] - Epoch 1662/2000, Val Acc=0.6161, Val Loss=1.7596, lr=0.0100
[2025-05-07 07:55:46,892][train][INFO] - Epoch 1663/2000, Val Acc=0.6095, Val Loss=1.7774, lr=0.0100
[2025-05-07 07:55:53,493][train][INFO] - Epoch 1664/2000, Val Acc=0.6067, Val Loss=1.7930, lr=0.0100
[2025-05-07 07:56:01,159][train][INFO] - Epoch 1665/2000, Val Acc=0.6132, Val Loss=1.8012, lr=0.0100
[2025-05-07 07:56:08,727][train][INFO] - Epoch 1666/2000, Val Acc=0.6242, Val Loss=1.7262, lr=0.0100
[2025-05-07 07:56:15,890][train][INFO] - Epoch 1667/2000, Val Acc=0.6247, Val Loss=1.7127, lr=0.0100
[2025-05-07 07:56:23,026][train][INFO] - Epoch 1668/2000, Val Acc=0.6116, Val Loss=1.7699, lr=0.0100
[2025-05-07 07:56:30,834][train][INFO] - Epoch 1669/2000, Val Acc=0.5936, Val Loss=1.9330, lr=0.0100
[2025-05-07 07:56:38,203][train][INFO] - Epoch 1670/2000, Val Acc=0.6266, Val Loss=1.7003, lr=0.0100
[2025-05-07 07:56:45,150][train][INFO] - Epoch 1671/2000, Val Acc=0.6192, Val Loss=1.7537, lr=0.0100
[2025-05-07 07:56:52,417][train][INFO] - Epoch 1672/2000, Val Acc=0.6032, Val Loss=1.8163, lr=0.0100
[2025-05-07 07:57:00,094][train][INFO] - Epoch 1673/2000, Val Acc=0.6113, Val Loss=1.8294, lr=0.0100
[2025-05-07 07:57:06,794][train][INFO] - Epoch 1674/2000, Val Acc=0.6229, Val Loss=1.7149, lr=0.0100
[2025-05-07 07:57:14,302][train][INFO] - Epoch 1675/2000, Val Acc=0.6001, Val Loss=1.8825, lr=0.0100
[2025-05-07 07:57:21,238][train][INFO] - Epoch 1676/2000, Val Acc=0.6144, Val Loss=1.7354, lr=0.0100
[2025-05-07 07:57:28,249][train][INFO] - Epoch 1677/2000, Val Acc=0.6058, Val Loss=1.8070, lr=0.0100
[2025-05-07 07:57:35,327][train][INFO] - Epoch 1678/2000, Val Acc=0.6147, Val Loss=1.7482, lr=0.0100
[2025-05-07 07:57:42,288][train][INFO] - Epoch 1679/2000, Val Acc=0.6045, Val Loss=1.8410, lr=0.0100
[2025-05-07 07:57:50,405][train][INFO] - Epoch 1680/2000, Val Acc=0.6120, Val Loss=1.8166, lr=0.0100
[2025-05-07 07:57:58,042][train][INFO] - Epoch 1681/2000, Val Acc=0.6232, Val Loss=1.7086, lr=0.0100
[2025-05-07 07:58:05,303][train][INFO] - Epoch 1682/2000, Val Acc=0.6114, Val Loss=1.8078, lr=0.0100
[2025-05-07 07:58:12,303][train][INFO] - Epoch 1683/2000, Val Acc=0.6191, Val Loss=1.7701, lr=0.0100
[2025-05-07 07:58:19,346][train][INFO] - Epoch 1684/2000, Val Acc=0.6169, Val Loss=1.7745, lr=0.0100
[2025-05-07 07:58:26,661][train][INFO] - Epoch 1685/2000, Val Acc=0.6198, Val Loss=1.7723, lr=0.0100
[2025-05-07 07:58:34,352][train][INFO] - Epoch 1686/2000, Val Acc=0.6176, Val Loss=1.7168, lr=0.0100
[2025-05-07 07:58:41,661][train][INFO] - Epoch 1687/2000, Val Acc=0.6106, Val Loss=1.7855, lr=0.0100
[2025-05-07 07:58:49,374][train][INFO] - Epoch 1688/2000, Val Acc=0.6253, Val Loss=1.7301, lr=0.0100
[2025-05-07 07:58:57,093][train][INFO] - Epoch 1689/2000, Val Acc=0.6183, Val Loss=1.7276, lr=0.0100
[2025-05-07 07:59:04,903][train][INFO] - Epoch 1690/2000, Val Acc=0.6179, Val Loss=1.7393, lr=0.0100
[2025-05-07 07:59:12,705][train][INFO] - Epoch 1691/2000, Val Acc=0.6191, Val Loss=1.7489, lr=0.0100
[2025-05-07 07:59:20,530][train][INFO] - Epoch 1692/2000, Val Acc=0.6136, Val Loss=1.7757, lr=0.0100
[2025-05-07 07:59:27,561][train][INFO] - Epoch 1693/2000, Val Acc=0.6114, Val Loss=1.8112, lr=0.0100
[2025-05-07 07:59:35,103][train][INFO] - Epoch 1694/2000, Val Acc=0.6127, Val Loss=1.7692, lr=0.0100
[2025-05-07 07:59:42,839][train][INFO] - Epoch 1695/2000, Val Acc=0.6162, Val Loss=1.7647, lr=0.0100
[2025-05-07 07:59:48,936][train][INFO] - Epoch 1696/2000, Val Acc=0.6142, Val Loss=1.7926, lr=0.0100
[2025-05-07 07:59:56,726][train][INFO] - Epoch 1697/2000, Val Acc=0.6142, Val Loss=1.7476, lr=0.0100
[2025-05-07 08:00:03,960][train][INFO] - Epoch 1698/2000, Val Acc=0.6223, Val Loss=1.7322, lr=0.0100
[2025-05-07 08:00:10,935][train][INFO] - Epoch 1699/2000, Val Acc=0.6135, Val Loss=1.7369, lr=0.0100
[2025-05-07 08:00:18,755][train][INFO] - Epoch 1700/2000, Val Acc=0.6135, Val Loss=1.7945, lr=0.0100
[2025-05-07 08:00:26,568][train][INFO] - Epoch 1701/2000, Val Acc=0.6114, Val Loss=1.8100, lr=0.0100
[2025-05-07 08:00:34,276][train][INFO] - Epoch 1702/2000, Val Acc=0.6098, Val Loss=1.8016, lr=0.0100
[2025-05-07 08:00:41,583][train][INFO] - Epoch 1703/2000, Val Acc=0.6052, Val Loss=1.8326, lr=0.0100
[2025-05-07 08:00:49,243][train][INFO] - Epoch 1704/2000, Val Acc=0.6171, Val Loss=1.7809, lr=0.0100
[2025-05-07 08:00:57,042][train][INFO] - Epoch 1705/2000, Val Acc=0.6225, Val Loss=1.7427, lr=0.0100
[2025-05-07 08:01:04,581][train][INFO] - Epoch 1706/2000, Val Acc=0.6133, Val Loss=1.7637, lr=0.0100
[2025-05-07 08:01:11,510][train][INFO] - Epoch 1707/2000, Val Acc=0.5875, Val Loss=1.9439, lr=0.0100
[2025-05-07 08:01:19,010][train][INFO] - Epoch 1708/2000, Val Acc=0.6125, Val Loss=1.7893, lr=0.0100
[2025-05-07 08:01:26,474][train][INFO] - Epoch 1709/2000, Val Acc=0.6140, Val Loss=1.8038, lr=0.0100
[2025-05-07 08:01:34,088][train][INFO] - Epoch 1710/2000, Val Acc=0.6186, Val Loss=1.7243, lr=0.0100
[2025-05-07 08:01:42,162][train][INFO] - Epoch 1711/2000, Val Acc=0.6161, Val Loss=1.7278, lr=0.0100
[2025-05-07 08:01:49,772][train][INFO] - Epoch 1712/2000, Val Acc=0.6248, Val Loss=1.6860, lr=0.0100
[2025-05-07 08:01:56,824][train][INFO] - Epoch 1713/2000, Val Acc=0.6105, Val Loss=1.7986, lr=0.0100
[2025-05-07 08:02:04,045][train][INFO] - Epoch 1714/2000, Val Acc=0.6142, Val Loss=1.7891, lr=0.0100
[2025-05-07 08:02:11,569][train][INFO] - Epoch 1715/2000, Val Acc=0.6161, Val Loss=1.7414, lr=0.0100
[2025-05-07 08:02:19,081][train][INFO] - Epoch 1716/2000, Val Acc=0.6126, Val Loss=1.8021, lr=0.0100
[2025-05-07 08:02:26,168][train][INFO] - Epoch 1717/2000, Val Acc=0.6277, Val Loss=1.7107, lr=0.0100
[2025-05-07 08:02:33,473][train][INFO] - Epoch 1718/2000, Val Acc=0.6170, Val Loss=1.7780, lr=0.0100
[2025-05-07 08:02:40,354][train][INFO] - Epoch 1719/2000, Val Acc=0.6132, Val Loss=1.7316, lr=0.0100
[2025-05-07 08:02:47,715][train][INFO] - Epoch 1720/2000, Val Acc=0.6279, Val Loss=1.6844, lr=0.0100
[2025-05-07 08:02:55,188][train][INFO] - Epoch 1721/2000, Val Acc=0.6122, Val Loss=1.7466, lr=0.0100
[2025-05-07 08:03:02,953][train][INFO] - Epoch 1722/2000, Val Acc=0.6261, Val Loss=1.7148, lr=0.0100
[2025-05-07 08:03:10,378][train][INFO] - Epoch 1723/2000, Val Acc=0.6206, Val Loss=1.7443, lr=0.0100
[2025-05-07 08:03:16,950][train][INFO] - Epoch 1724/2000, Val Acc=0.5984, Val Loss=1.8811, lr=0.0100
[2025-05-07 08:03:23,758][train][INFO] - Epoch 1725/2000, Val Acc=0.6109, Val Loss=1.7430, lr=0.0100
[2025-05-07 08:03:30,739][train][INFO] - Epoch 1726/2000, Val Acc=0.6064, Val Loss=1.8029, lr=0.0100
[2025-05-07 08:03:37,808][train][INFO] - Epoch 1727/2000, Val Acc=0.6163, Val Loss=1.7465, lr=0.0100
[2025-05-07 08:03:44,781][train][INFO] - Epoch 1728/2000, Val Acc=0.6145, Val Loss=1.7451, lr=0.0100
[2025-05-07 08:03:52,342][train][INFO] - Epoch 1729/2000, Val Acc=0.5917, Val Loss=1.9280, lr=0.0100
[2025-05-07 08:03:59,483][train][INFO] - Epoch 1730/2000, Val Acc=0.6164, Val Loss=1.7738, lr=0.0100
[2025-05-07 08:04:05,381][train][INFO] - Epoch 1731/2000, Val Acc=0.6159, Val Loss=1.7865, lr=0.0100
[2025-05-07 08:04:13,046][train][INFO] - Epoch 1732/2000, Val Acc=0.6072, Val Loss=1.8662, lr=0.0100
[2025-05-07 08:04:20,631][train][INFO] - Epoch 1733/2000, Val Acc=0.6239, Val Loss=1.7431, lr=0.0100
[2025-05-07 08:04:28,266][train][INFO] - Epoch 1734/2000, Val Acc=0.6277, Val Loss=1.6970, lr=0.0100
[2025-05-07 08:04:35,730][train][INFO] - Epoch 1735/2000, Val Acc=0.6184, Val Loss=1.7753, lr=0.0100
[2025-05-07 08:04:43,461][train][INFO] - Epoch 1736/2000, Val Acc=0.5891, Val Loss=1.8830, lr=0.0100
[2025-05-07 08:04:50,912][train][INFO] - Epoch 1737/2000, Val Acc=0.6263, Val Loss=1.6842, lr=0.0100
[2025-05-07 08:04:57,962][train][INFO] - Epoch 1738/2000, Val Acc=0.5991, Val Loss=1.8684, lr=0.0100
[2025-05-07 08:05:05,392][train][INFO] - Epoch 1739/2000, Val Acc=0.6311, Val Loss=1.7276, lr=0.0100
[2025-05-07 08:05:13,026][train][INFO] - Epoch 1740/2000, Val Acc=0.6056, Val Loss=1.8446, lr=0.0100
[2025-05-07 08:05:20,558][train][INFO] - Epoch 1741/2000, Val Acc=0.6257, Val Loss=1.7355, lr=0.0100
[2025-05-07 08:05:27,937][train][INFO] - Epoch 1742/2000, Val Acc=0.6130, Val Loss=1.7823, lr=0.0100
[2025-05-07 08:05:35,323][train][INFO] - Epoch 1743/2000, Val Acc=0.6122, Val Loss=1.7869, lr=0.0100
[2025-05-07 08:05:43,058][train][INFO] - Epoch 1744/2000, Val Acc=0.6136, Val Loss=1.7938, lr=0.0100
[2025-05-07 08:05:50,717][train][INFO] - Epoch 1745/2000, Val Acc=0.6275, Val Loss=1.7034, lr=0.0100
[2025-05-07 08:05:57,276][train][INFO] - Epoch 1746/2000, Val Acc=0.6144, Val Loss=1.7412, lr=0.0100
[2025-05-07 08:06:04,603][train][INFO] - Epoch 1747/2000, Val Acc=0.6010, Val Loss=1.8698, lr=0.0100
[2025-05-07 08:06:11,749][train][INFO] - Epoch 1748/2000, Val Acc=0.5975, Val Loss=1.8319, lr=0.0100
[2025-05-07 08:06:19,104][train][INFO] - Epoch 1749/2000, Val Acc=0.6136, Val Loss=1.8030, lr=0.0100
[2025-05-07 08:06:26,042][train][INFO] - Epoch 1750/2000, Val Acc=0.6194, Val Loss=1.7802, lr=0.0100
[2025-05-07 08:06:33,370][train][INFO] - Epoch 1751/2000, Val Acc=0.6142, Val Loss=1.8154, lr=0.0100
[2025-05-07 08:06:40,161][train][INFO] - Epoch 1752/2000, Val Acc=0.6083, Val Loss=1.7815, lr=0.0100
[2025-05-07 08:06:47,413][train][INFO] - Epoch 1753/2000, Val Acc=0.6125, Val Loss=1.7655, lr=0.0100
[2025-05-07 08:06:54,787][train][INFO] - Epoch 1754/2000, Val Acc=0.6059, Val Loss=1.8992, lr=0.0100
[2025-05-07 08:07:02,156][train][INFO] - Epoch 1755/2000, Val Acc=0.6040, Val Loss=1.8184, lr=0.0100
[2025-05-07 08:07:09,632][train][INFO] - Epoch 1756/2000, Val Acc=0.6164, Val Loss=1.7423, lr=0.0100
[2025-05-07 08:07:16,257][train][INFO] - Epoch 1757/2000, Val Acc=0.6148, Val Loss=1.7737, lr=0.0100
[2025-05-07 08:07:23,833][train][INFO] - Epoch 1758/2000, Val Acc=0.6253, Val Loss=1.6971, lr=0.0100
[2025-05-07 08:07:31,136][train][INFO] - Epoch 1759/2000, Val Acc=0.6205, Val Loss=1.7159, lr=0.0100
[2025-05-07 08:07:38,573][train][INFO] - Epoch 1760/2000, Val Acc=0.6173, Val Loss=1.7705, lr=0.0100
[2025-05-07 08:07:45,804][train][INFO] - Epoch 1761/2000, Val Acc=0.6171, Val Loss=1.7834, lr=0.0100
[2025-05-07 08:07:53,079][train][INFO] - Epoch 1762/2000, Val Acc=0.6078, Val Loss=1.8043, lr=0.0100
[2025-05-07 08:08:00,586][train][INFO] - Epoch 1763/2000, Val Acc=0.6166, Val Loss=1.7723, lr=0.0100
[2025-05-07 08:08:07,857][train][INFO] - Epoch 1764/2000, Val Acc=0.6142, Val Loss=1.7974, lr=0.0100
[2025-05-07 08:08:15,233][train][INFO] - Epoch 1765/2000, Val Acc=0.6192, Val Loss=1.7433, lr=0.0100
[2025-05-07 08:08:22,614][train][INFO] - Epoch 1766/2000, Val Acc=0.6202, Val Loss=1.7762, lr=0.0100
[2025-05-07 08:08:30,053][train][INFO] - Epoch 1767/2000, Val Acc=0.6169, Val Loss=1.7623, lr=0.0100
[2025-05-07 08:08:37,486][train][INFO] - Epoch 1768/2000, Val Acc=0.6189, Val Loss=1.7340, lr=0.0100
[2025-05-07 08:08:44,710][train][INFO] - Epoch 1769/2000, Val Acc=0.5884, Val Loss=1.9336, lr=0.0100
[2025-05-07 08:08:52,130][train][INFO] - Epoch 1770/2000, Val Acc=0.6125, Val Loss=1.7798, lr=0.0100
[2025-05-07 08:08:59,851][train][INFO] - Epoch 1771/2000, Val Acc=0.5919, Val Loss=1.8647, lr=0.0100
[2025-05-07 08:09:07,404][train][INFO] - Epoch 1772/2000, Val Acc=0.6208, Val Loss=1.7622, lr=0.0100
[2025-05-07 08:09:14,755][train][INFO] - Epoch 1773/2000, Val Acc=0.6199, Val Loss=1.7331, lr=0.0100
[2025-05-07 08:09:22,248][train][INFO] - Epoch 1774/2000, Val Acc=0.6082, Val Loss=1.8201, lr=0.0100
[2025-05-07 08:09:29,086][train][INFO] - Epoch 1775/2000, Val Acc=0.6046, Val Loss=1.8183, lr=0.0100
[2025-05-07 08:09:36,400][train][INFO] - Epoch 1776/2000, Val Acc=0.6077, Val Loss=1.7696, lr=0.0100
[2025-05-07 08:09:43,626][train][INFO] - Epoch 1777/2000, Val Acc=0.6091, Val Loss=1.8030, lr=0.0100
[2025-05-07 08:09:51,006][train][INFO] - Epoch 1778/2000, Val Acc=0.6138, Val Loss=1.7503, lr=0.0100
[2025-05-07 08:09:58,580][train][INFO] - Epoch 1779/2000, Val Acc=0.6053, Val Loss=1.8779, lr=0.0100
[2025-05-07 08:10:06,244][train][INFO] - Epoch 1780/2000, Val Acc=0.6185, Val Loss=1.7417, lr=0.0100
[2025-05-07 08:10:13,510][train][INFO] - Epoch 1781/2000, Val Acc=0.6113, Val Loss=1.7675, lr=0.0100
[2025-05-07 08:10:20,782][train][INFO] - Epoch 1782/2000, Val Acc=0.6096, Val Loss=1.7938, lr=0.0100
[2025-05-07 08:10:28,448][train][INFO] - Epoch 1783/2000, Val Acc=0.6208, Val Loss=1.7433, lr=0.0100
[2025-05-07 08:10:35,886][train][INFO] - Epoch 1784/2000, Val Acc=0.6047, Val Loss=1.8178, lr=0.0100
[2025-05-07 08:10:43,054][train][INFO] - Epoch 1785/2000, Val Acc=0.6175, Val Loss=1.7412, lr=0.0100
[2025-05-07 08:10:50,581][train][INFO] - Epoch 1786/2000, Val Acc=0.6048, Val Loss=1.8380, lr=0.0100
[2025-05-07 08:10:57,966][train][INFO] - Epoch 1787/2000, Val Acc=0.6043, Val Loss=1.8569, lr=0.0100
[2025-05-07 08:11:06,179][train][INFO] - Epoch 1788/2000, Val Acc=0.6038, Val Loss=1.8320, lr=0.0100
[2025-05-07 08:11:13,349][train][INFO] - Epoch 1789/2000, Val Acc=0.6204, Val Loss=1.7497, lr=0.0100
[2025-05-07 08:11:20,554][train][INFO] - Epoch 1790/2000, Val Acc=0.6099, Val Loss=1.8274, lr=0.0100
[2025-05-07 08:11:27,937][train][INFO] - Epoch 1791/2000, Val Acc=0.6111, Val Loss=1.7817, lr=0.0100
[2025-05-07 08:11:35,368][train][INFO] - Epoch 1792/2000, Val Acc=0.6254, Val Loss=1.7134, lr=0.0100
[2025-05-07 08:11:42,909][train][INFO] - Epoch 1793/2000, Val Acc=0.6176, Val Loss=1.7361, lr=0.0100
[2025-05-07 08:11:50,220][train][INFO] - Epoch 1794/2000, Val Acc=0.6043, Val Loss=1.8379, lr=0.0100
[2025-05-07 08:11:57,329][train][INFO] - Epoch 1795/2000, Val Acc=0.6135, Val Loss=1.7690, lr=0.0100
[2025-05-07 08:12:05,305][train][INFO] - Epoch 1796/2000, Val Acc=0.6197, Val Loss=1.7180, lr=0.0100
[2025-05-07 08:12:12,909][train][INFO] - Epoch 1797/2000, Val Acc=0.6110, Val Loss=1.7906, lr=0.0100
[2025-05-07 08:12:19,749][train][INFO] - Epoch 1798/2000, Val Acc=0.6238, Val Loss=1.7215, lr=0.0100
[2025-05-07 08:12:27,507][train][INFO] - Epoch 1799/2000, Val Acc=0.6091, Val Loss=1.8047, lr=0.0100
[2025-05-07 08:12:35,145][train][INFO] - Epoch 1800/2000, Val Acc=0.6228, Val Loss=1.7142, lr=0.0100
[2025-05-07 08:12:42,324][train][INFO] - Epoch 1801/2000, Val Acc=0.6057, Val Loss=1.8536, lr=0.0100
[2025-05-07 08:12:49,878][train][INFO] - Epoch 1802/2000, Val Acc=0.6069, Val Loss=1.8047, lr=0.0100
[2025-05-07 08:12:57,730][train][INFO] - Epoch 1803/2000, Val Acc=0.6186, Val Loss=1.7473, lr=0.0100
[2025-05-07 08:13:05,153][train][INFO] - Epoch 1804/2000, Val Acc=0.6142, Val Loss=1.8009, lr=0.0100
[2025-05-07 08:13:12,672][train][INFO] - Epoch 1805/2000, Val Acc=0.6056, Val Loss=1.8658, lr=0.0100
[2025-05-07 08:13:20,170][train][INFO] - Epoch 1806/2000, Val Acc=0.5997, Val Loss=1.8119, lr=0.0100
[2025-05-07 08:13:27,103][train][INFO] - Epoch 1807/2000, Val Acc=0.6073, Val Loss=1.8354, lr=0.0100
[2025-05-07 08:13:34,066][train][INFO] - Epoch 1808/2000, Val Acc=0.6249, Val Loss=1.7144, lr=0.0100
[2025-05-07 08:13:41,225][train][INFO] - Epoch 1809/2000, Val Acc=0.6140, Val Loss=1.7488, lr=0.0100
[2025-05-07 08:13:48,008][train][INFO] - Epoch 1810/2000, Val Acc=0.6243, Val Loss=1.7354, lr=0.0100
[2025-05-07 08:13:55,785][train][INFO] - Epoch 1811/2000, Val Acc=0.6183, Val Loss=1.7510, lr=0.0100
[2025-05-07 08:14:03,748][train][INFO] - Epoch 1812/2000, Val Acc=0.6086, Val Loss=1.7828, lr=0.0100
[2025-05-07 08:14:11,387][train][INFO] - Epoch 1813/2000, Val Acc=0.6399, Val Loss=1.6346, lr=0.0100
[2025-05-07 08:14:18,652][train][INFO] - Epoch 1814/2000, Val Acc=0.6218, Val Loss=1.7220, lr=0.0100
[2025-05-07 08:14:26,447][train][INFO] - Epoch 1815/2000, Val Acc=0.6078, Val Loss=1.7881, lr=0.0100
[2025-05-07 08:14:33,878][train][INFO] - Epoch 1816/2000, Val Acc=0.6151, Val Loss=1.7773, lr=0.0100
[2025-05-07 08:14:41,684][train][INFO] - Epoch 1817/2000, Val Acc=0.6091, Val Loss=1.8313, lr=0.0100
[2025-05-07 08:14:49,014][train][INFO] - Epoch 1818/2000, Val Acc=0.6154, Val Loss=1.8051, lr=0.0100
[2025-05-07 08:14:56,130][train][INFO] - Epoch 1819/2000, Val Acc=0.6155, Val Loss=1.7837, lr=0.0100
[2025-05-07 08:15:02,840][train][INFO] - Epoch 1820/2000, Val Acc=0.6102, Val Loss=1.8011, lr=0.0100
[2025-05-07 08:15:09,883][train][INFO] - Epoch 1821/2000, Val Acc=0.6156, Val Loss=1.7316, lr=0.0100
[2025-05-07 08:15:16,969][train][INFO] - Epoch 1822/2000, Val Acc=0.6243, Val Loss=1.7330, lr=0.0100
[2025-05-07 08:15:24,560][train][INFO] - Epoch 1823/2000, Val Acc=0.6066, Val Loss=1.8508, lr=0.0100
[2025-05-07 08:15:32,169][train][INFO] - Epoch 1824/2000, Val Acc=0.6191, Val Loss=1.7342, lr=0.0100
[2025-05-07 08:15:39,768][train][INFO] - Epoch 1825/2000, Val Acc=0.6072, Val Loss=1.8364, lr=0.0100
[2025-05-07 08:15:47,067][train][INFO] - Epoch 1826/2000, Val Acc=0.5811, Val Loss=1.9625, lr=0.0100
[2025-05-07 08:15:54,282][train][INFO] - Epoch 1827/2000, Val Acc=0.6034, Val Loss=1.8247, lr=0.0100
[2025-05-07 08:16:01,592][train][INFO] - Epoch 1828/2000, Val Acc=0.6003, Val Loss=1.9183, lr=0.0100
[2025-05-07 08:16:09,192][train][INFO] - Epoch 1829/2000, Val Acc=0.6055, Val Loss=1.8197, lr=0.0100
[2025-05-07 08:16:16,918][train][INFO] - Epoch 1830/2000, Val Acc=0.6196, Val Loss=1.7859, lr=0.0100
[2025-05-07 08:16:24,077][train][INFO] - Epoch 1831/2000, Val Acc=0.6155, Val Loss=1.7910, lr=0.0100
[2025-05-07 08:16:31,219][train][INFO] - Epoch 1832/2000, Val Acc=0.5990, Val Loss=1.9024, lr=0.0100
[2025-05-07 08:16:38,396][train][INFO] - Epoch 1833/2000, Val Acc=0.6209, Val Loss=1.7368, lr=0.0100
[2025-05-07 08:16:45,426][train][INFO] - Epoch 1834/2000, Val Acc=0.6042, Val Loss=1.8326, lr=0.0100
[2025-05-07 08:16:53,061][train][INFO] - Epoch 1835/2000, Val Acc=0.6071, Val Loss=1.8469, lr=0.0100
[2025-05-07 08:17:00,308][train][INFO] - Epoch 1836/2000, Val Acc=0.5998, Val Loss=1.8860, lr=0.0100
[2025-05-07 08:17:07,080][train][INFO] - Epoch 1837/2000, Val Acc=0.6138, Val Loss=1.7625, lr=0.0100
[2025-05-07 08:17:14,458][train][INFO] - Epoch 1838/2000, Val Acc=0.6273, Val Loss=1.7258, lr=0.0100
[2025-05-07 08:17:22,319][train][INFO] - Epoch 1839/2000, Val Acc=0.6131, Val Loss=1.8189, lr=0.0100
[2025-05-07 08:17:29,749][train][INFO] - Epoch 1840/2000, Val Acc=0.6110, Val Loss=1.8380, lr=0.0100
[2025-05-07 08:17:36,510][train][INFO] - Epoch 1841/2000, Val Acc=0.6030, Val Loss=1.8581, lr=0.0100
[2025-05-07 08:17:43,524][train][INFO] - Epoch 1842/2000, Val Acc=0.6177, Val Loss=1.7622, lr=0.0100
[2025-05-07 08:17:50,409][train][INFO] - Epoch 1843/2000, Val Acc=0.6112, Val Loss=1.7536, lr=0.0100
[2025-05-07 08:17:57,549][train][INFO] - Epoch 1844/2000, Val Acc=0.6019, Val Loss=1.8587, lr=0.0100
[2025-05-07 08:18:05,103][train][INFO] - Epoch 1845/2000, Val Acc=0.6252, Val Loss=1.6861, lr=0.0100
[2025-05-07 08:18:12,149][train][INFO] - Epoch 1846/2000, Val Acc=0.6163, Val Loss=1.7582, lr=0.0100
[2025-05-07 08:18:19,684][train][INFO] - Epoch 1847/2000, Val Acc=0.6221, Val Loss=1.7409, lr=0.0100
[2025-05-07 08:18:27,733][train][INFO] - Epoch 1848/2000, Val Acc=0.6136, Val Loss=1.7673, lr=0.0100
[2025-05-07 08:18:35,098][train][INFO] - Epoch 1849/2000, Val Acc=0.6032, Val Loss=1.8263, lr=0.0100
[2025-05-07 08:18:42,328][train][INFO] - Epoch 1850/2000, Val Acc=0.6250, Val Loss=1.7409, lr=0.0100
[2025-05-07 08:18:50,014][train][INFO] - Epoch 1851/2000, Val Acc=0.6799, Val Loss=1.4634, lr=0.0010
[2025-05-07 08:18:57,217][train][INFO] - Epoch 1852/2000, Val Acc=0.6837, Val Loss=1.4750, lr=0.0010
[2025-05-07 08:19:04,429][train][INFO] - Epoch 1853/2000, Val Acc=0.6834, Val Loss=1.4818, lr=0.0010
[2025-05-07 08:19:11,790][train][INFO] - Epoch 1854/2000, Val Acc=0.6866, Val Loss=1.4971, lr=0.0010
[2025-05-07 08:19:19,074][train][INFO] - Epoch 1855/2000, Val Acc=0.6828, Val Loss=1.5065, lr=0.0010
[2025-05-07 08:19:26,672][train][INFO] - Epoch 1856/2000, Val Acc=0.6879, Val Loss=1.5105, lr=0.0010
[2025-05-07 08:19:34,212][train][INFO] - Epoch 1857/2000, Val Acc=0.6844, Val Loss=1.5191, lr=0.0010
[2025-05-07 08:19:41,543][train][INFO] - Epoch 1858/2000, Val Acc=0.6876, Val Loss=1.5303, lr=0.0010
[2025-05-07 08:19:49,150][train][INFO] - Epoch 1859/2000, Val Acc=0.6870, Val Loss=1.5376, lr=0.0010
[2025-05-07 08:19:56,728][train][INFO] - Epoch 1860/2000, Val Acc=0.6869, Val Loss=1.5518, lr=0.0010
[2025-05-07 08:20:03,914][train][INFO] - Epoch 1861/2000, Val Acc=0.6858, Val Loss=1.5523, lr=0.0010
[2025-05-07 08:20:11,251][train][INFO] - Epoch 1862/2000, Val Acc=0.6881, Val Loss=1.5680, lr=0.0010
[2025-05-07 08:20:18,985][train][INFO] - Epoch 1863/2000, Val Acc=0.6842, Val Loss=1.5644, lr=0.0010
[2025-05-07 08:20:26,239][train][INFO] - Epoch 1864/2000, Val Acc=0.6851, Val Loss=1.5707, lr=0.0010
[2025-05-07 08:20:33,796][train][INFO] - Epoch 1865/2000, Val Acc=0.6835, Val Loss=1.5805, lr=0.0010
[2025-05-07 08:20:41,051][train][INFO] - Epoch 1866/2000, Val Acc=0.6863, Val Loss=1.5882, lr=0.0010
[2025-05-07 08:20:48,682][train][INFO] - Epoch 1867/2000, Val Acc=0.6898, Val Loss=1.5935, lr=0.0010
[2025-05-07 08:20:56,174][train][INFO] - Epoch 1868/2000, Val Acc=0.6888, Val Loss=1.5954, lr=0.0010
[2025-05-07 08:21:03,362][train][INFO] - Epoch 1869/2000, Val Acc=0.6890, Val Loss=1.6013, lr=0.0010
[2025-05-07 08:21:10,530][train][INFO] - Epoch 1870/2000, Val Acc=0.6863, Val Loss=1.6213, lr=0.0010
[2025-05-07 08:21:18,112][train][INFO] - Epoch 1871/2000, Val Acc=0.6901, Val Loss=1.6079, lr=0.0010
[2025-05-07 08:21:25,491][train][INFO] - Epoch 1872/2000, Val Acc=0.6884, Val Loss=1.6122, lr=0.0010
[2025-05-07 08:21:32,882][train][INFO] - Epoch 1873/2000, Val Acc=0.6876, Val Loss=1.6229, lr=0.0010
[2025-05-07 08:21:40,467][train][INFO] - Epoch 1874/2000, Val Acc=0.6872, Val Loss=1.6362, lr=0.0010
[2025-05-07 08:21:47,571][train][INFO] - Epoch 1875/2000, Val Acc=0.6856, Val Loss=1.6382, lr=0.0010
[2025-05-07 08:21:54,779][train][INFO] - Epoch 1876/2000, Val Acc=0.6854, Val Loss=1.6346, lr=0.0010
[2025-05-07 08:22:02,066][train][INFO] - Epoch 1877/2000, Val Acc=0.6832, Val Loss=1.6313, lr=0.0010
[2025-05-07 08:22:10,125][train][INFO] - Epoch 1878/2000, Val Acc=0.6875, Val Loss=1.6388, lr=0.0010
[2025-05-07 08:22:18,062][train][INFO] - Epoch 1879/2000, Val Acc=0.6883, Val Loss=1.6428, lr=0.0010
[2025-05-07 08:22:24,969][train][INFO] - Epoch 1880/2000, Val Acc=0.6865, Val Loss=1.6439, lr=0.0010
[2025-05-07 08:22:32,580][train][INFO] - Epoch 1881/2000, Val Acc=0.6830, Val Loss=1.6669, lr=0.0010
[2025-05-07 08:22:39,717][train][INFO] - Epoch 1882/2000, Val Acc=0.6858, Val Loss=1.6567, lr=0.0010
[2025-05-07 08:22:46,639][train][INFO] - Epoch 1883/2000, Val Acc=0.6860, Val Loss=1.6598, lr=0.0010
[2025-05-07 08:22:54,674][train][INFO] - Epoch 1884/2000, Val Acc=0.6842, Val Loss=1.6719, lr=0.0010
[2025-05-07 08:23:01,707][train][INFO] - Epoch 1885/2000, Val Acc=0.6835, Val Loss=1.6669, lr=0.0010
[2025-05-07 08:23:09,425][train][INFO] - Epoch 1886/2000, Val Acc=0.6866, Val Loss=1.6692, lr=0.0010
[2025-05-07 08:23:17,059][train][INFO] - Epoch 1887/2000, Val Acc=0.6839, Val Loss=1.6659, lr=0.0010
[2025-05-07 08:23:24,455][train][INFO] - Epoch 1888/2000, Val Acc=0.6824, Val Loss=1.6754, lr=0.0010
[2025-05-07 08:23:30,997][train][INFO] - Epoch 1889/2000, Val Acc=0.6854, Val Loss=1.6640, lr=0.0010
[2025-05-07 08:23:38,317][train][INFO] - Epoch 1890/2000, Val Acc=0.6853, Val Loss=1.6841, lr=0.0010
[2025-05-07 08:23:45,893][train][INFO] - Epoch 1891/2000, Val Acc=0.6858, Val Loss=1.6829, lr=0.0010
[2025-05-07 08:23:53,219][train][INFO] - Epoch 1892/2000, Val Acc=0.6852, Val Loss=1.6901, lr=0.0010
[2025-05-07 08:24:00,517][train][INFO] - Epoch 1893/2000, Val Acc=0.6874, Val Loss=1.6912, lr=0.0010
[2025-05-07 08:24:07,996][train][INFO] - Epoch 1894/2000, Val Acc=0.6864, Val Loss=1.7016, lr=0.0010
[2025-05-07 08:24:15,301][train][INFO] - Epoch 1895/2000, Val Acc=0.6842, Val Loss=1.7046, lr=0.0010
[2025-05-07 08:24:22,468][train][INFO] - Epoch 1896/2000, Val Acc=0.6868, Val Loss=1.7033, lr=0.0010
[2025-05-07 08:24:29,513][train][INFO] - Epoch 1897/2000, Val Acc=0.6830, Val Loss=1.7075, lr=0.0010
[2025-05-07 08:24:36,891][train][INFO] - Epoch 1898/2000, Val Acc=0.6865, Val Loss=1.7031, lr=0.0010
[2025-05-07 08:24:44,007][train][INFO] - Epoch 1899/2000, Val Acc=0.6841, Val Loss=1.7125, lr=0.0010
[2025-05-07 08:24:51,323][train][INFO] - Epoch 1900/2000, Val Acc=0.6849, Val Loss=1.7084, lr=0.0010
[2025-05-07 08:24:58,942][train][INFO] - Epoch 1901/2000, Val Acc=0.6851, Val Loss=1.7032, lr=0.0010
[2025-05-07 08:25:06,445][train][INFO] - Epoch 1902/2000, Val Acc=0.6834, Val Loss=1.7213, lr=0.0010
[2025-05-07 08:25:13,149][train][INFO] - Epoch 1903/2000, Val Acc=0.6831, Val Loss=1.7088, lr=0.0010
[2025-05-07 08:25:20,163][train][INFO] - Epoch 1904/2000, Val Acc=0.6822, Val Loss=1.7276, lr=0.0010
[2025-05-07 08:25:27,500][train][INFO] - Epoch 1905/2000, Val Acc=0.6852, Val Loss=1.7257, lr=0.0010
[2025-05-07 08:25:34,542][train][INFO] - Epoch 1906/2000, Val Acc=0.6864, Val Loss=1.7161, lr=0.0010
[2025-05-07 08:25:42,203][train][INFO] - Epoch 1907/2000, Val Acc=0.6841, Val Loss=1.7338, lr=0.0010
[2025-05-07 08:25:49,394][train][INFO] - Epoch 1908/2000, Val Acc=0.6831, Val Loss=1.7143, lr=0.0010
[2025-05-07 08:25:56,731][train][INFO] - Epoch 1909/2000, Val Acc=0.6835, Val Loss=1.7223, lr=0.0010
[2025-05-07 08:26:03,331][train][INFO] - Epoch 1910/2000, Val Acc=0.6820, Val Loss=1.7299, lr=0.0010
[2025-05-07 08:26:10,882][train][INFO] - Epoch 1911/2000, Val Acc=0.6848, Val Loss=1.7239, lr=0.0010
[2025-05-07 08:26:18,171][train][INFO] - Epoch 1912/2000, Val Acc=0.6852, Val Loss=1.7324, lr=0.0010
[2025-05-07 08:26:26,047][train][INFO] - Epoch 1913/2000, Val Acc=0.6839, Val Loss=1.7364, lr=0.0010
[2025-05-07 08:26:33,056][train][INFO] - Epoch 1914/2000, Val Acc=0.6843, Val Loss=1.7330, lr=0.0010
[2025-05-07 08:26:40,669][train][INFO] - Epoch 1915/2000, Val Acc=0.6850, Val Loss=1.7228, lr=0.0010
[2025-05-07 08:26:47,993][train][INFO] - Epoch 1916/2000, Val Acc=0.6838, Val Loss=1.7364, lr=0.0010
[2025-05-07 08:26:55,085][train][INFO] - Epoch 1917/2000, Val Acc=0.6830, Val Loss=1.7252, lr=0.0010
[2025-05-07 08:27:02,449][train][INFO] - Epoch 1918/2000, Val Acc=0.6894, Val Loss=1.7195, lr=0.0010
[2025-05-07 08:27:09,979][train][INFO] - Epoch 1919/2000, Val Acc=0.6870, Val Loss=1.7295, lr=0.0010
[2025-05-07 08:27:17,341][train][INFO] - Epoch 1920/2000, Val Acc=0.6853, Val Loss=1.7314, lr=0.0010
[2025-05-07 08:27:24,818][train][INFO] - Epoch 1921/2000, Val Acc=0.6857, Val Loss=1.7333, lr=0.0010
[2025-05-07 08:27:32,685][train][INFO] - Epoch 1922/2000, Val Acc=0.6852, Val Loss=1.7315, lr=0.0010
[2025-05-07 08:27:39,983][train][INFO] - Epoch 1923/2000, Val Acc=0.6851, Val Loss=1.7269, lr=0.0010
[2025-05-07 08:27:47,976][train][INFO] - Epoch 1924/2000, Val Acc=0.6866, Val Loss=1.7468, lr=0.0010
[2025-05-07 08:27:55,520][train][INFO] - Epoch 1925/2000, Val Acc=0.6841, Val Loss=1.7480, lr=0.0010
[2025-05-07 08:28:02,947][train][INFO] - Epoch 1926/2000, Val Acc=0.6837, Val Loss=1.7344, lr=0.0010
[2025-05-07 08:28:10,687][train][INFO] - Epoch 1927/2000, Val Acc=0.6841, Val Loss=1.7401, lr=0.0010
[2025-05-07 08:28:17,753][train][INFO] - Epoch 1928/2000, Val Acc=0.6839, Val Loss=1.7555, lr=0.0010
[2025-05-07 08:28:24,611][train][INFO] - Epoch 1929/2000, Val Acc=0.6832, Val Loss=1.7491, lr=0.0010
[2025-05-07 08:28:32,041][train][INFO] - Epoch 1930/2000, Val Acc=0.6790, Val Loss=1.7556, lr=0.0010
[2025-05-07 08:28:39,677][train][INFO] - Epoch 1931/2000, Val Acc=0.6839, Val Loss=1.7474, lr=0.0010
[2025-05-07 08:28:46,787][train][INFO] - Epoch 1932/2000, Val Acc=0.6849, Val Loss=1.7438, lr=0.0010
[2025-05-07 08:28:54,099][train][INFO] - Epoch 1933/2000, Val Acc=0.6850, Val Loss=1.7552, lr=0.0010
[2025-05-07 08:29:00,903][train][INFO] - Epoch 1934/2000, Val Acc=0.6821, Val Loss=1.7606, lr=0.0010
[2025-05-07 08:29:08,598][train][INFO] - Epoch 1935/2000, Val Acc=0.6838, Val Loss=1.7733, lr=0.0010
[2025-05-07 08:29:14,986][train][INFO] - Epoch 1936/2000, Val Acc=0.6829, Val Loss=1.7667, lr=0.0010
[2025-05-07 08:29:22,295][train][INFO] - Epoch 1937/2000, Val Acc=0.6847, Val Loss=1.7686, lr=0.0010
[2025-05-07 08:29:30,188][train][INFO] - Epoch 1938/2000, Val Acc=0.6811, Val Loss=1.7550, lr=0.0010
[2025-05-07 08:29:37,860][train][INFO] - Epoch 1939/2000, Val Acc=0.6818, Val Loss=1.7618, lr=0.0010
[2025-05-07 08:29:45,229][train][INFO] - Epoch 1940/2000, Val Acc=0.6872, Val Loss=1.7547, lr=0.0010
[2025-05-07 08:29:52,953][train][INFO] - Epoch 1941/2000, Val Acc=0.6834, Val Loss=1.7698, lr=0.0010
[2025-05-07 08:30:00,722][train][INFO] - Epoch 1942/2000, Val Acc=0.6860, Val Loss=1.7538, lr=0.0010
[2025-05-07 08:30:07,722][train][INFO] - Epoch 1943/2000, Val Acc=0.6839, Val Loss=1.7597, lr=0.0010
[2025-05-07 08:30:15,420][train][INFO] - Epoch 1944/2000, Val Acc=0.6824, Val Loss=1.7690, lr=0.0010
[2025-05-07 08:30:23,207][train][INFO] - Epoch 1945/2000, Val Acc=0.6807, Val Loss=1.7724, lr=0.0010
[2025-05-07 08:30:30,461][train][INFO] - Epoch 1946/2000, Val Acc=0.6814, Val Loss=1.7638, lr=0.0010
[2025-05-07 08:30:37,386][train][INFO] - Epoch 1947/2000, Val Acc=0.6826, Val Loss=1.7813, lr=0.0010
[2025-05-07 08:30:45,156][train][INFO] - Epoch 1948/2000, Val Acc=0.6852, Val Loss=1.7788, lr=0.0010
[2025-05-07 08:30:52,662][train][INFO] - Epoch 1949/2000, Val Acc=0.6852, Val Loss=1.7696, lr=0.0010
[2025-05-07 08:30:59,605][train][INFO] - Epoch 1950/2000, Val Acc=0.6853, Val Loss=1.7645, lr=0.0010
[2025-05-07 08:31:07,035][train][INFO] - Epoch 1951/2000, Val Acc=0.6868, Val Loss=1.7558, lr=0.0001
[2025-05-07 08:31:14,501][train][INFO] - Epoch 1952/2000, Val Acc=0.6874, Val Loss=1.7585, lr=0.0001
[2025-05-07 08:31:20,459][train][INFO] - Epoch 1953/2000, Val Acc=0.6870, Val Loss=1.7578, lr=0.0001
[2025-05-07 08:31:27,719][train][INFO] - Epoch 1954/2000, Val Acc=0.6884, Val Loss=1.7542, lr=0.0001
[2025-05-07 08:31:34,984][train][INFO] - Epoch 1955/2000, Val Acc=0.6885, Val Loss=1.7560, lr=0.0001
[2025-05-07 08:31:42,122][train][INFO] - Epoch 1956/2000, Val Acc=0.6885, Val Loss=1.7570, lr=0.0001
[2025-05-07 08:31:48,635][train][INFO] - Epoch 1957/2000, Val Acc=0.6883, Val Loss=1.7535, lr=0.0001
[2025-05-07 08:31:56,076][train][INFO] - Epoch 1958/2000, Val Acc=0.6888, Val Loss=1.7599, lr=0.0001
[2025-05-07 08:32:03,434][train][INFO] - Epoch 1959/2000, Val Acc=0.6874, Val Loss=1.7585, lr=0.0001
[2025-05-07 08:32:11,374][train][INFO] - Epoch 1960/2000, Val Acc=0.6879, Val Loss=1.7555, lr=0.0001
[2025-05-07 08:32:18,772][train][INFO] - Epoch 1961/2000, Val Acc=0.6882, Val Loss=1.7604, lr=0.0001
[2025-05-07 08:32:25,257][train][INFO] - Epoch 1962/2000, Val Acc=0.6882, Val Loss=1.7558, lr=0.0001
[2025-05-07 08:32:33,220][train][INFO] - Epoch 1963/2000, Val Acc=0.6873, Val Loss=1.7574, lr=0.0001
[2025-05-07 08:32:40,671][train][INFO] - Epoch 1964/2000, Val Acc=0.6874, Val Loss=1.7585, lr=0.0001
[2025-05-07 08:32:48,327][train][INFO] - Epoch 1965/2000, Val Acc=0.6897, Val Loss=1.7581, lr=0.0001
[2025-05-07 08:32:55,753][train][INFO] - Epoch 1966/2000, Val Acc=0.6883, Val Loss=1.7586, lr=0.0001
[2025-05-07 08:33:03,236][train][INFO] - Epoch 1967/2000, Val Acc=0.6899, Val Loss=1.7616, lr=0.0001
[2025-05-07 08:33:10,464][train][INFO] - Epoch 1968/2000, Val Acc=0.6891, Val Loss=1.7609, lr=0.0001
[2025-05-07 08:33:17,849][train][INFO] - Epoch 1969/2000, Val Acc=0.6885, Val Loss=1.7561, lr=0.0001
[2025-05-07 08:33:25,554][train][INFO] - Epoch 1970/2000, Val Acc=0.6878, Val Loss=1.7652, lr=0.0001
[2025-05-07 08:33:32,543][train][INFO] - Epoch 1971/2000, Val Acc=0.6858, Val Loss=1.7698, lr=0.0001
[2025-05-07 08:33:40,336][train][INFO] - Epoch 1972/2000, Val Acc=0.6874, Val Loss=1.7633, lr=0.0001
[2025-05-07 08:33:47,409][train][INFO] - Epoch 1973/2000, Val Acc=0.6862, Val Loss=1.7700, lr=0.0001
[2025-05-07 08:33:54,938][train][INFO] - Epoch 1974/2000, Val Acc=0.6866, Val Loss=1.7677, lr=0.0001
[2025-05-07 08:34:02,519][train][INFO] - Epoch 1975/2000, Val Acc=0.6862, Val Loss=1.7639, lr=0.0001
[2025-05-07 08:34:09,881][train][INFO] - Epoch 1976/2000, Val Acc=0.6876, Val Loss=1.7687, lr=0.0001
[2025-05-07 08:34:16,767][train][INFO] - Epoch 1977/2000, Val Acc=0.6872, Val Loss=1.7675, lr=0.0001
[2025-05-07 08:34:24,281][train][INFO] - Epoch 1978/2000, Val Acc=0.6887, Val Loss=1.7669, lr=0.0001
[2025-05-07 08:34:32,000][train][INFO] - Epoch 1979/2000, Val Acc=0.6891, Val Loss=1.7671, lr=0.0001
[2025-05-07 08:34:39,735][train][INFO] - Epoch 1980/2000, Val Acc=0.6886, Val Loss=1.7656, lr=0.0001
[2025-05-07 08:34:46,929][train][INFO] - Epoch 1981/2000, Val Acc=0.6890, Val Loss=1.7679, lr=0.0001
[2025-05-07 08:34:54,659][train][INFO] - Epoch 1982/2000, Val Acc=0.6865, Val Loss=1.7652, lr=0.0001
[2025-05-07 08:35:02,296][train][INFO] - Epoch 1983/2000, Val Acc=0.6873, Val Loss=1.7658, lr=0.0001
[2025-05-07 08:35:09,451][train][INFO] - Epoch 1984/2000, Val Acc=0.6878, Val Loss=1.7729, lr=0.0001
[2025-05-07 08:35:17,000][train][INFO] - Epoch 1985/2000, Val Acc=0.6875, Val Loss=1.7640, lr=0.0001
[2025-05-07 08:35:24,571][train][INFO] - Epoch 1986/2000, Val Acc=0.6879, Val Loss=1.7665, lr=0.0001
[2025-05-07 08:35:31,964][train][INFO] - Epoch 1987/2000, Val Acc=0.6878, Val Loss=1.7690, lr=0.0001
[2025-05-07 08:35:39,589][train][INFO] - Epoch 1988/2000, Val Acc=0.6879, Val Loss=1.7704, lr=0.0001
[2025-05-07 08:35:46,959][train][INFO] - Epoch 1989/2000, Val Acc=0.6889, Val Loss=1.7684, lr=0.0001
[2025-05-07 08:35:54,680][train][INFO] - Epoch 1990/2000, Val Acc=0.6880, Val Loss=1.7674, lr=0.0001
[2025-05-07 08:36:02,080][train][INFO] - Epoch 1991/2000, Val Acc=0.6881, Val Loss=1.7677, lr=0.0001
[2025-05-07 08:36:09,739][train][INFO] - Epoch 1992/2000, Val Acc=0.6884, Val Loss=1.7669, lr=0.0001
[2025-05-07 08:36:17,173][train][INFO] - Epoch 1993/2000, Val Acc=0.6876, Val Loss=1.7724, lr=0.0001
[2025-05-07 08:36:24,005][train][INFO] - Epoch 1994/2000, Val Acc=0.6883, Val Loss=1.7686, lr=0.0001
[2025-05-07 08:36:31,572][train][INFO] - Epoch 1995/2000, Val Acc=0.6880, Val Loss=1.7629, lr=0.0001
[2025-05-07 08:36:39,114][train][INFO] - Epoch 1996/2000, Val Acc=0.6879, Val Loss=1.7692, lr=0.0001
[2025-05-07 08:36:46,602][train][INFO] - Epoch 1997/2000, Val Acc=0.6885, Val Loss=1.7672, lr=0.0001
[2025-05-07 08:36:54,370][train][INFO] - Epoch 1998/2000, Val Acc=0.6869, Val Loss=1.7713, lr=0.0001
[2025-05-07 08:37:01,614][train][INFO] - Epoch 1999/2000, Val Acc=0.6871, Val Loss=1.7760, lr=0.0001
[2025-05-07 08:37:08,315][train][INFO] - Epoch 2000/2000, Val Acc=0.6876, Val Loss=1.7732, lr=0.0001
[2025-05-07 08:37:13,512][train][INFO] - After training : Train Acc=0.9861  Val Acc=0.6901
[2025-05-07 08:37:13,529][Pruning][INFO] - 
MyVGG(
  (block0): Sequential(
    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(5, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(39, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(85, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(95, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(108, 154, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(154, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(116, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(18, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(39, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(85, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(2, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(37, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(31, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(79, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=42, out_features=100, bias=True)
)
[2025-05-07 08:37:13,529][Pruning][INFO] - Origin val acc : 0.7368999719619751 Final val acc : 0.6900999546051025
                      Speed up: 4.47   Final speed up: 8.95
