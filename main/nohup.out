[2025-04-29 21:13:23,851][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:13:23,944][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:14:03,561][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:14:12,902][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:14:21,889][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:14:30,912][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:14:40,013][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:14:42,376][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 10.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:14:42,454][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:14:49,391][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:14:58,495][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:15:07,785][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:15:17,011][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:15:22,823][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
[2025-04-29 21:15:32,098][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:16:34,886][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 40

[2025-04-29 21:16:34,945][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:34,946][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:16:40,713][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 20

[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:16:40,808][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:14,621][train][INFO] - Before training : Train Acc=0.2349  Val Acc=0.2296
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:17:20,891][train][INFO] - Before training : Train Acc=0.8401  Val Acc=0.6331
[2025-04-29 21:17:23,878][train][INFO] - Epoch 1/100, Val Acc=0.6397, Val Loss=1.6039, lr=0.0100
[2025-04-29 21:17:30,197][train][INFO] - Epoch 1/100, Val Acc=0.6532, Val Loss=1.5826, lr=0.0100
[2025-04-29 21:17:33,278][train][INFO] - Epoch 2/100, Val Acc=0.6559, Val Loss=1.4929, lr=0.0100
[2025-04-29 21:17:38,508][train][INFO] - Epoch 2/100, Val Acc=0.6527, Val Loss=1.5607, lr=0.0100
[2025-04-29 21:17:42,589][train][INFO] - Epoch 3/100, Val Acc=0.6493, Val Loss=1.5717, lr=0.0100
[2025-04-29 21:17:47,386][train][INFO] - Epoch 3/100, Val Acc=0.6599, Val Loss=1.5096, lr=0.0100
[2025-04-29 21:17:51,819][train][INFO] - Epoch 4/100, Val Acc=0.6716, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:17:56,599][train][INFO] - Epoch 4/100, Val Acc=0.6626, Val Loss=1.5196, lr=0.0100
[2025-04-29 21:18:00,836][train][INFO] - Epoch 5/100, Val Acc=0.6541, Val Loss=1.5486, lr=0.0100
[2025-04-29 21:18:05,679][train][INFO] - Epoch 5/100, Val Acc=0.6649, Val Loss=1.5178, lr=0.0100
[2025-04-29 21:18:10,016][train][INFO] - Epoch 6/100, Val Acc=0.6787, Val Loss=1.4316, lr=0.0100
[2025-04-29 21:18:14,550][train][INFO] - Epoch 6/100, Val Acc=0.6714, Val Loss=1.4762, lr=0.0100
[2025-04-29 21:18:19,288][train][INFO] - Epoch 7/100, Val Acc=0.6565, Val Loss=1.5439, lr=0.0100
[2025-04-29 21:18:23,413][train][INFO] - Epoch 7/100, Val Acc=0.6689, Val Loss=1.4980, lr=0.0100
[2025-04-29 21:18:28,294][train][INFO] - Epoch 8/100, Val Acc=0.6681, Val Loss=1.4811, lr=0.0100
[2025-04-29 21:18:32,758][train][INFO] - Epoch 8/100, Val Acc=0.6653, Val Loss=1.5062, lr=0.0100
[2025-04-29 21:18:37,477][train][INFO] - Epoch 9/100, Val Acc=0.6764, Val Loss=1.4338, lr=0.0100
[2025-04-29 21:18:41,660][train][INFO] - Epoch 9/100, Val Acc=0.6719, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:18:46,369][train][INFO] - Epoch 10/100, Val Acc=0.6658, Val Loss=1.5013, lr=0.0100
[2025-04-29 21:18:50,398][train][INFO] - Epoch 10/100, Val Acc=0.6556, Val Loss=1.5865, lr=0.0100
[2025-04-29 21:18:55,742][train][INFO] - Epoch 11/100, Val Acc=0.6583, Val Loss=1.5674, lr=0.0100
[2025-04-29 21:18:59,225][train][INFO] - Epoch 11/100, Val Acc=0.6695, Val Loss=1.5202, lr=0.0100
[2025-04-29 21:19:04,889][train][INFO] - Epoch 12/100, Val Acc=0.6701, Val Loss=1.4855, lr=0.0100
[2025-04-29 21:19:08,313][train][INFO] - Epoch 12/100, Val Acc=0.6802, Val Loss=1.4586, lr=0.0100
[2025-04-29 21:19:14,153][train][INFO] - Epoch 13/100, Val Acc=0.6571, Val Loss=1.5929, lr=0.0100
[2025-04-29 21:19:17,399][train][INFO] - Epoch 13/100, Val Acc=0.6604, Val Loss=1.5724, lr=0.0100
[2025-04-29 21:19:23,264][train][INFO] - Epoch 14/100, Val Acc=0.6777, Val Loss=1.4617, lr=0.0100
[2025-04-29 21:19:26,446][train][INFO] - Epoch 14/100, Val Acc=0.6765, Val Loss=1.4714, lr=0.0100
[2025-04-29 21:19:32,312][train][INFO] - Epoch 15/100, Val Acc=0.6640, Val Loss=1.5570, lr=0.0100
[2025-04-29 21:19:35,772][train][INFO] - Epoch 15/100, Val Acc=0.6735, Val Loss=1.5166, lr=0.0100
[2025-04-29 21:19:41,335][train][INFO] - Epoch 16/100, Val Acc=0.6544, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:19:44,730][train][INFO] - Epoch 16/100, Val Acc=0.6552, Val Loss=1.5888, lr=0.0100
[2025-04-29 21:19:50,304][train][INFO] - Epoch 17/100, Val Acc=0.6663, Val Loss=1.5376, lr=0.0100
[2025-04-29 21:19:53,648][train][INFO] - Epoch 17/100, Val Acc=0.6639, Val Loss=1.5253, lr=0.0100
[2025-04-29 21:19:59,540][train][INFO] - Epoch 18/100, Val Acc=0.6688, Val Loss=1.5059, lr=0.0100
[2025-04-29 21:20:02,832][train][INFO] - Epoch 18/100, Val Acc=0.6749, Val Loss=1.4825, lr=0.0100
[2025-04-29 21:20:08,602][train][INFO] - Epoch 19/100, Val Acc=0.6693, Val Loss=1.5015, lr=0.0100
[2025-04-29 21:20:11,990][train][INFO] - Epoch 19/100, Val Acc=0.6623, Val Loss=1.5542, lr=0.0100
[2025-04-29 21:20:17,857][train][INFO] - Epoch 20/100, Val Acc=0.6786, Val Loss=1.4801, lr=0.0100
[2025-04-29 21:20:21,120][train][INFO] - Epoch 20/100, Val Acc=0.6681, Val Loss=1.5447, lr=0.0100
[2025-04-29 21:20:26,928][train][INFO] - Epoch 21/100, Val Acc=0.6652, Val Loss=1.5553, lr=0.0100
[2025-04-29 21:20:30,353][train][INFO] - Epoch 21/100, Val Acc=0.6668, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:20:35,936][train][INFO] - Epoch 22/100, Val Acc=0.6623, Val Loss=1.5446, lr=0.0100
[2025-04-29 21:20:39,397][train][INFO] - Epoch 22/100, Val Acc=0.6714, Val Loss=1.5311, lr=0.0100
[2025-04-29 21:20:45,096][train][INFO] - Epoch 23/100, Val Acc=0.6570, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:20:48,478][train][INFO] - Epoch 23/100, Val Acc=0.6782, Val Loss=1.5189, lr=0.0100
[2025-04-29 21:20:54,211][train][INFO] - Epoch 24/100, Val Acc=0.6686, Val Loss=1.5338, lr=0.0100
[2025-04-29 21:20:57,535][train][INFO] - Epoch 24/100, Val Acc=0.6779, Val Loss=1.4810, lr=0.0100
[2025-04-29 21:21:03,579][train][INFO] - Epoch 25/100, Val Acc=0.6705, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:21:06,771][train][INFO] - Epoch 25/100, Val Acc=0.6698, Val Loss=1.5511, lr=0.0100
[2025-04-29 21:21:12,286][train][INFO] - Epoch 26/100, Val Acc=0.6787, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:21:16,104][train][INFO] - Epoch 26/100, Val Acc=0.6764, Val Loss=1.5026, lr=0.0100
[2025-04-29 21:21:21,306][train][INFO] - Epoch 27/100, Val Acc=0.6724, Val Loss=1.5572, lr=0.0100
[2025-04-29 21:21:25,241][train][INFO] - Epoch 27/100, Val Acc=0.6646, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:21:30,243][train][INFO] - Epoch 28/100, Val Acc=0.6703, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:21:34,198][train][INFO] - Epoch 28/100, Val Acc=0.6731, Val Loss=1.5143, lr=0.0100
[2025-04-29 21:21:39,380][train][INFO] - Epoch 29/100, Val Acc=0.6740, Val Loss=1.5151, lr=0.0100
[2025-04-29 21:21:42,714][train][INFO] - Epoch 29/100, Val Acc=0.6692, Val Loss=1.5227, lr=0.0100
[2025-04-29 21:21:48,492][train][INFO] - Epoch 30/100, Val Acc=0.6677, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:21:51,975][train][INFO] - Epoch 30/100, Val Acc=0.6649, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:21:57,656][train][INFO] - Epoch 31/100, Val Acc=0.6735, Val Loss=1.5356, lr=0.0100
[2025-04-29 21:22:01,180][train][INFO] - Epoch 31/100, Val Acc=0.6602, Val Loss=1.6021, lr=0.0100
[2025-04-29 21:22:06,563][train][INFO] - Epoch 32/100, Val Acc=0.6737, Val Loss=1.5019, lr=0.0100
[2025-04-29 21:22:10,005][train][INFO] - Epoch 32/100, Val Acc=0.6616, Val Loss=1.6076, lr=0.0100
[2025-04-29 21:22:15,600][train][INFO] - Epoch 33/100, Val Acc=0.6670, Val Loss=1.5622, lr=0.0100
[2025-04-29 21:22:19,252][train][INFO] - Epoch 33/100, Val Acc=0.6703, Val Loss=1.5599, lr=0.0100
[2025-04-29 21:22:24,710][train][INFO] - Epoch 34/100, Val Acc=0.6643, Val Loss=1.5657, lr=0.0100
[2025-04-29 21:22:28,393][train][INFO] - Epoch 34/100, Val Acc=0.6721, Val Loss=1.5672, lr=0.0100
[2025-04-29 21:22:33,739][train][INFO] - Epoch 35/100, Val Acc=0.6763, Val Loss=1.4823, lr=0.0100
[2025-04-29 21:22:37,296][train][INFO] - Epoch 35/100, Val Acc=0.6757, Val Loss=1.5177, lr=0.0100
[2025-04-29 21:22:43,087][train][INFO] - Epoch 36/100, Val Acc=0.6689, Val Loss=1.5290, lr=0.0100
[2025-04-29 21:22:46,304][train][INFO] - Epoch 36/100, Val Acc=0.6649, Val Loss=1.5882, lr=0.0100
[2025-04-29 21:22:51,828][train][INFO] - Epoch 37/100, Val Acc=0.6836, Val Loss=1.4839, lr=0.0100
[2025-04-29 21:22:55,664][train][INFO] - Epoch 37/100, Val Acc=0.6519, Val Loss=1.6584, lr=0.0100
[2025-04-29 21:23:01,091][train][INFO] - Epoch 38/100, Val Acc=0.6853, Val Loss=1.4466, lr=0.0100
[2025-04-29 21:23:04,566][train][INFO] - Epoch 38/100, Val Acc=0.6642, Val Loss=1.5531, lr=0.0100
[2025-04-29 21:23:10,010][train][INFO] - Epoch 39/100, Val Acc=0.6598, Val Loss=1.5953, lr=0.0100
[2025-04-29 21:23:13,235][train][INFO] - Epoch 39/100, Val Acc=0.6693, Val Loss=1.5533, lr=0.0100
[2025-04-29 21:23:19,167][train][INFO] - Epoch 40/100, Val Acc=0.6694, Val Loss=1.5803, lr=0.0100
[2025-04-29 21:23:22,205][train][INFO] - Epoch 40/100, Val Acc=0.6578, Val Loss=1.6153, lr=0.0100
[2025-04-29 21:23:27,931][train][INFO] - Epoch 41/100, Val Acc=0.6581, Val Loss=1.6272, lr=0.0100
[2025-04-29 21:23:31,274][train][INFO] - Epoch 41/100, Val Acc=0.6810, Val Loss=1.4824, lr=0.0100
[2025-04-29 21:23:37,095][train][INFO] - Epoch 42/100, Val Acc=0.6684, Val Loss=1.5407, lr=0.0100
[2025-04-29 21:23:40,058][train][INFO] - Epoch 42/100, Val Acc=0.6686, Val Loss=1.5701, lr=0.0100
[2025-04-29 21:23:46,045][train][INFO] - Epoch 43/100, Val Acc=0.6854, Val Loss=1.4351, lr=0.0100
[2025-04-29 21:23:48,377][train][INFO] - Epoch 43/100, Val Acc=0.6726, Val Loss=1.5278, lr=0.0100
[2025-04-29 21:23:55,432][train][INFO] - Epoch 44/100, Val Acc=0.6699, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:23:57,697][train][INFO] - Epoch 44/100, Val Acc=0.6675, Val Loss=1.5595, lr=0.0100
[2025-04-29 21:24:04,231][train][INFO] - Epoch 45/100, Val Acc=0.6640, Val Loss=1.5884, lr=0.0100
[2025-04-29 21:24:06,934][train][INFO] - Epoch 45/100, Val Acc=0.6594, Val Loss=1.5987, lr=0.0100
[2025-04-29 21:24:13,340][train][INFO] - Epoch 46/100, Val Acc=0.6711, Val Loss=1.5410, lr=0.0100
[2025-04-29 21:24:15,878][train][INFO] - Epoch 46/100, Val Acc=0.6762, Val Loss=1.5517, lr=0.0100
[2025-04-29 21:24:22,498][train][INFO] - Epoch 47/100, Val Acc=0.6741, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:24:25,176][train][INFO] - Epoch 47/100, Val Acc=0.6680, Val Loss=1.5546, lr=0.0100
[2025-04-29 21:24:31,408][train][INFO] - Epoch 48/100, Val Acc=0.6663, Val Loss=1.5747, lr=0.0100
[2025-04-29 21:24:34,442][train][INFO] - Epoch 48/100, Val Acc=0.6703, Val Loss=1.5437, lr=0.0100
[2025-04-29 21:24:40,641][train][INFO] - Epoch 49/100, Val Acc=0.6698, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:24:43,323][train][INFO] - Epoch 49/100, Val Acc=0.6805, Val Loss=1.5006, lr=0.0100
[2025-04-29 21:24:50,009][train][INFO] - Epoch 50/100, Val Acc=0.6754, Val Loss=1.5466, lr=0.0100
[2025-04-29 21:24:52,339][train][INFO] - Epoch 50/100, Val Acc=0.6671, Val Loss=1.6240, lr=0.0100
[2025-04-29 21:24:59,344][train][INFO] - Epoch 51/100, Val Acc=0.6635, Val Loss=1.5881, lr=0.0100
[2025-04-29 21:25:01,259][train][INFO] - Epoch 51/100, Val Acc=0.6786, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:25:08,406][train][INFO] - Epoch 52/100, Val Acc=0.6664, Val Loss=1.5959, lr=0.0100
[2025-04-29 21:25:10,043][train][INFO] - Epoch 52/100, Val Acc=0.6670, Val Loss=1.5614, lr=0.0100
[2025-04-29 21:25:17,258][train][INFO] - Epoch 53/100, Val Acc=0.6583, Val Loss=1.6056, lr=0.0100
[2025-04-29 21:25:19,222][train][INFO] - Epoch 53/100, Val Acc=0.6748, Val Loss=1.5412, lr=0.0100
[2025-04-29 21:25:26,404][train][INFO] - Epoch 54/100, Val Acc=0.6694, Val Loss=1.5694, lr=0.0100
[2025-04-29 21:25:28,179][train][INFO] - Epoch 54/100, Val Acc=0.6646, Val Loss=1.5513, lr=0.0100
[2025-04-29 21:25:35,619][train][INFO] - Epoch 55/100, Val Acc=0.6669, Val Loss=1.6020, lr=0.0100
[2025-04-29 21:25:37,223][train][INFO] - Epoch 55/100, Val Acc=0.6703, Val Loss=1.5565, lr=0.0100
[2025-04-29 21:25:44,899][train][INFO] - Epoch 56/100, Val Acc=0.6681, Val Loss=1.5422, lr=0.0100
[2025-04-29 21:25:46,321][train][INFO] - Epoch 56/100, Val Acc=0.6579, Val Loss=1.6059, lr=0.0100
[2025-04-29 21:25:54,098][train][INFO] - Epoch 57/100, Val Acc=0.6557, Val Loss=1.6307, lr=0.0100
[2025-04-29 21:25:55,486][train][INFO] - Epoch 57/100, Val Acc=0.6711, Val Loss=1.5596, lr=0.0100
[2025-04-29 21:26:03,454][train][INFO] - Epoch 58/100, Val Acc=0.6596, Val Loss=1.6495, lr=0.0100
[2025-04-29 21:26:04,375][train][INFO] - Epoch 58/100, Val Acc=0.6715, Val Loss=1.5329, lr=0.0100
[2025-04-29 21:26:12,593][train][INFO] - Epoch 59/100, Val Acc=0.6525, Val Loss=1.6634, lr=0.0100
[2025-04-29 21:26:13,454][train][INFO] - Epoch 59/100, Val Acc=0.6542, Val Loss=1.6370, lr=0.0100
[2025-04-29 21:26:21,637][train][INFO] - Epoch 60/100, Val Acc=0.6810, Val Loss=1.5055, lr=0.0100
[2025-04-29 21:26:22,690][train][INFO] - Epoch 60/100, Val Acc=0.6723, Val Loss=1.5387, lr=0.0100
[2025-04-29 21:26:31,026][train][INFO] - Epoch 61/100, Val Acc=0.7232, Val Loss=1.2862, lr=0.0010
[2025-04-29 21:26:31,900][train][INFO] - Epoch 61/100, Val Acc=0.7273, Val Loss=1.2891, lr=0.0010
[2025-04-29 21:26:40,272][train][INFO] - Epoch 62/100, Val Acc=0.7291, Val Loss=1.2759, lr=0.0010
[2025-04-29 21:26:41,137][train][INFO] - Epoch 62/100, Val Acc=0.7330, Val Loss=1.2826, lr=0.0010
[2025-04-29 21:26:49,494][train][INFO] - Epoch 63/100, Val Acc=0.7307, Val Loss=1.2847, lr=0.0010
[2025-04-29 21:26:50,483][train][INFO] - Epoch 63/100, Val Acc=0.7335, Val Loss=1.2901, lr=0.0010
[2025-04-29 21:26:58,657][train][INFO] - Epoch 64/100, Val Acc=0.7330, Val Loss=1.2842, lr=0.0010
[2025-04-29 21:26:59,379][train][INFO] - Epoch 64/100, Val Acc=0.7332, Val Loss=1.2855, lr=0.0010
[2025-04-29 21:27:07,826][train][INFO] - Epoch 65/100, Val Acc=0.7337, Val Loss=1.2950, lr=0.0010
[2025-04-29 21:27:07,989][train][INFO] - Epoch 65/100, Val Acc=0.7351, Val Loss=1.2947, lr=0.0010
[2025-04-29 21:27:17,073][train][INFO] - Epoch 66/100, Val Acc=0.7359, Val Loss=1.3000, lr=0.0010
[2025-04-29 21:27:17,100][train][INFO] - Epoch 66/100, Val Acc=0.7319, Val Loss=1.3047, lr=0.0010
[2025-04-29 21:27:26,347][train][INFO] - Epoch 67/100, Val Acc=0.7374, Val Loss=1.2985, lr=0.0010
[2025-04-29 21:27:26,498][train][INFO] - Epoch 67/100, Val Acc=0.7322, Val Loss=1.3034, lr=0.0010
[2025-04-29 21:27:35,611][train][INFO] - Epoch 68/100, Val Acc=0.7392, Val Loss=1.2936, lr=0.0010
[2025-04-29 21:27:36,026][train][INFO] - Epoch 68/100, Val Acc=0.7371, Val Loss=1.2959, lr=0.0010
[2025-04-29 21:27:44,174][train][INFO] - Epoch 69/100, Val Acc=0.7383, Val Loss=1.3065, lr=0.0010
[2025-04-29 21:27:45,122][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.2939, lr=0.0010
[2025-04-29 21:27:53,267][train][INFO] - Epoch 70/100, Val Acc=0.7368, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:27:54,395][train][INFO] - Epoch 70/100, Val Acc=0.7358, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:02,331][train][INFO] - Epoch 71/100, Val Acc=0.7374, Val Loss=1.3147, lr=0.0010
[2025-04-29 21:28:03,543][train][INFO] - Epoch 71/100, Val Acc=0.7372, Val Loss=1.3052, lr=0.0010
[2025-04-29 21:28:11,422][train][INFO] - Epoch 72/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:28:12,568][train][INFO] - Epoch 72/100, Val Acc=0.7371, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:28:20,660][train][INFO] - Epoch 73/100, Val Acc=0.7386, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:21,731][train][INFO] - Epoch 73/100, Val Acc=0.7362, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:29,893][train][INFO] - Epoch 74/100, Val Acc=0.7397, Val Loss=1.3074, lr=0.0010
[2025-04-29 21:28:30,857][train][INFO] - Epoch 74/100, Val Acc=0.7361, Val Loss=1.3060, lr=0.0010
[2025-04-29 21:28:39,203][train][INFO] - Epoch 75/100, Val Acc=0.7408, Val Loss=1.3127, lr=0.0010
[2025-04-29 21:28:39,488][train][INFO] - Epoch 75/100, Val Acc=0.7362, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:28:48,144][train][INFO] - Epoch 76/100, Val Acc=0.7401, Val Loss=1.3140, lr=0.0010
[2025-04-29 21:28:48,618][train][INFO] - Epoch 76/100, Val Acc=0.7370, Val Loss=1.3153, lr=0.0010
[2025-04-29 21:28:57,139][train][INFO] - Epoch 77/100, Val Acc=0.7395, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:28:57,734][train][INFO] - Epoch 77/100, Val Acc=0.7374, Val Loss=1.3039, lr=0.0010
[2025-04-29 21:29:06,341][train][INFO] - Epoch 78/100, Val Acc=0.7398, Val Loss=1.3136, lr=0.0010
[2025-04-29 21:29:06,864][train][INFO] - Epoch 78/100, Val Acc=0.7354, Val Loss=1.3030, lr=0.0010
[2025-04-29 21:29:15,003][train][INFO] - Epoch 79/100, Val Acc=0.7385, Val Loss=1.3145, lr=0.0010
[2025-04-29 21:29:16,025][train][INFO] - Epoch 79/100, Val Acc=0.7386, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:24,196][train][INFO] - Epoch 80/100, Val Acc=0.7397, Val Loss=1.3122, lr=0.0010
[2025-04-29 21:29:25,254][train][INFO] - Epoch 80/100, Val Acc=0.7361, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:29:32,884][train][INFO] - Epoch 81/100, Val Acc=0.7401, Val Loss=1.3084, lr=0.0010
[2025-04-29 21:29:34,433][train][INFO] - Epoch 81/100, Val Acc=0.7382, Val Loss=1.3083, lr=0.0010
[2025-04-29 21:29:42,096][train][INFO] - Epoch 82/100, Val Acc=0.7376, Val Loss=1.3108, lr=0.0010
[2025-04-29 21:29:43,544][train][INFO] - Epoch 82/100, Val Acc=0.7361, Val Loss=1.3168, lr=0.0010
[2025-04-29 21:29:51,114][train][INFO] - Epoch 83/100, Val Acc=0.7397, Val Loss=1.3125, lr=0.0010
[2025-04-29 21:29:52,840][train][INFO] - Epoch 83/100, Val Acc=0.7373, Val Loss=1.3154, lr=0.0010
[2025-04-29 21:30:00,216][train][INFO] - Epoch 84/100, Val Acc=0.7393, Val Loss=1.3120, lr=0.0010
[2025-04-29 21:30:02,021][train][INFO] - Epoch 84/100, Val Acc=0.7389, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:30:09,578][train][INFO] - Epoch 85/100, Val Acc=0.7397, Val Loss=1.3131, lr=0.0010
[2025-04-29 21:30:11,389][train][INFO] - Epoch 85/100, Val Acc=0.7379, Val Loss=1.3130, lr=0.0010
[2025-04-29 21:30:18,697][train][INFO] - Epoch 86/100, Val Acc=0.7412, Val Loss=1.3069, lr=0.0010
[2025-04-29 21:30:20,684][train][INFO] - Epoch 86/100, Val Acc=0.7407, Val Loss=1.3142, lr=0.0010
[2025-04-29 21:30:27,407][train][INFO] - Epoch 87/100, Val Acc=0.7403, Val Loss=1.3053, lr=0.0010
[2025-04-29 21:30:29,862][train][INFO] - Epoch 87/100, Val Acc=0.7395, Val Loss=1.3100, lr=0.0010
[2025-04-29 21:30:36,218][train][INFO] - Epoch 88/100, Val Acc=0.7402, Val Loss=1.3075, lr=0.0010
[2025-04-29 21:30:38,935][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3163, lr=0.0010
[2025-04-29 21:30:44,864][train][INFO] - Epoch 89/100, Val Acc=0.7415, Val Loss=1.3162, lr=0.0010
[2025-04-29 21:30:48,196][train][INFO] - Epoch 89/100, Val Acc=0.7378, Val Loss=1.3224, lr=0.0010
[2025-04-29 21:30:53,860][train][INFO] - Epoch 90/100, Val Acc=0.7402, Val Loss=1.3160, lr=0.0010
[2025-04-29 21:30:57,502][train][INFO] - Epoch 90/100, Val Acc=0.7369, Val Loss=1.3185, lr=0.0010
[2025-04-29 21:31:02,792][train][INFO] - Epoch 91/100, Val Acc=0.7417, Val Loss=1.3142, lr=0.0001
[2025-04-29 21:31:06,880][train][INFO] - Epoch 91/100, Val Acc=0.7375, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:31:12,031][train][INFO] - Epoch 92/100, Val Acc=0.7388, Val Loss=1.3165, lr=0.0001
[2025-04-29 21:31:15,980][train][INFO] - Epoch 92/100, Val Acc=0.7381, Val Loss=1.3166, lr=0.0001
[2025-04-29 21:31:21,020][train][INFO] - Epoch 93/100, Val Acc=0.7403, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:31:25,126][train][INFO] - Epoch 93/100, Val Acc=0.7385, Val Loss=1.3141, lr=0.0001
[2025-04-29 21:31:30,116][train][INFO] - Epoch 94/100, Val Acc=0.7407, Val Loss=1.3087, lr=0.0001
[2025-04-29 21:31:34,200][train][INFO] - Epoch 94/100, Val Acc=0.7397, Val Loss=1.3102, lr=0.0001
[2025-04-29 21:31:39,116][train][INFO] - Epoch 95/100, Val Acc=0.7404, Val Loss=1.3131, lr=0.0001
[2025-04-29 21:31:43,537][train][INFO] - Epoch 95/100, Val Acc=0.7387, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:31:48,063][train][INFO] - Epoch 96/100, Val Acc=0.7429, Val Loss=1.3081, lr=0.0001
[2025-04-29 21:31:52,704][train][INFO] - Epoch 96/100, Val Acc=0.7398, Val Loss=1.3067, lr=0.0001
[2025-04-29 21:31:56,974][train][INFO] - Epoch 97/100, Val Acc=0.7415, Val Loss=1.3128, lr=0.0001
[2025-04-29 21:32:02,041][train][INFO] - Epoch 97/100, Val Acc=0.7418, Val Loss=1.3118, lr=0.0001
[2025-04-29 21:32:05,975][train][INFO] - Epoch 98/100, Val Acc=0.7413, Val Loss=1.3096, lr=0.0001
[2025-04-29 21:32:11,084][train][INFO] - Epoch 98/100, Val Acc=0.7389, Val Loss=1.3101, lr=0.0001
[2025-04-29 21:32:14,921][train][INFO] - Epoch 99/100, Val Acc=0.7422, Val Loss=1.3129, lr=0.0001
[2025-04-29 21:32:20,279][train][INFO] - Epoch 99/100, Val Acc=0.7410, Val Loss=1.3169, lr=0.0001
[2025-04-29 21:32:23,991][train][INFO] - Epoch 100/100, Val Acc=0.7418, Val Loss=1.3116, lr=0.0001
[2025-04-29 21:32:29,324][train][INFO] - After training : Train Acc=0.9995  Val Acc=0.7429
[2025-04-29 21:32:29,328][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:32:29,545][train][INFO] - Epoch 100/100, Val Acc=0.7375, Val Loss=1.3119, lr=0.0001
[2025-04-29 21:32:34,979][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7418
[2025-04-29 21:32:34,984][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:34:53,903][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:34:59,489][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:37:17,383][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:17,921][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:37:22,790][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 21:37:23,228][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 21:40:10,349][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 60

[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:10,407][get_dataset_model_loader][INFO] - ==================================================
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:40:49,882][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:40:53,370][root][INFO] - 

task:
  _recursive_: true
  model_name: VGG19
  task_name: ${task.model_name}_on_${task.dataset.dataset_name}
  dataset:
    dataset_name: CIFAR100
    num_workers: 4
    big_batch: 500
    small_batch: 128
    dataset_path: ../dataset/${task.dataset.dataset_name}
    seed: ${seed}
  big_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.big_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  small_batch_dataset:
    dataset_name: ${task.dataset.dataset_name}
    batch_size: ${task.dataset.small_batch}
    num_workers: ${task.dataset.num_workers}
    dataset_path: ${task.dataset.dataset_path}
    seed: ${seed}
  dataset_model:
    dataset_model_name: VGG19_on_CIFAR100
    train_split: 0.8
    dataset_model_path: ../dataset_model/${task.dataset_model.dataset_model_name}_level_${level}
    seed: ${seed}
  meta_train:
    epochs: 100
    lr: 0.001
    lr_decay_milestones: '10'
    lr_decay_gamma: 0.1
    weight_decay: 0.0005
    method: ${method}
    pruner_reg:
    - 10
    - 10
    save_every_epoch: 1
    warm_up: 0
    level: ${level}
    model_name: ${task.model_name}
    dataset_name: ${task.dataset.dataset_name}
    save_path: save/metanetwork/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    use_meta_eval: false
    meta_eval:
      speed_up_threshold: 0.68
      epochs: ${task.pruning.finetune.after_metanetwork.epochs}
      lr: ${task.pruning.finetune.after_metanetwork.lr}
      lr_decay_milestones: ${task.pruning.finetune.after_metanetwork.lr_decay_milestones}
      lr_decay_gamma: ${task.pruning.finetune.after_metanetwork.lr_decay_gamma}
      weight_decay: ${task.pruning.finetune.after_metanetwork.weight_decay}
  metanetwork:
    '0':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 4
      hiddim: 16
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
    '1':
      _target_: nn.GNN.MyGNN
      _recursive_: true
      num_layer: 8
      hiddim: 64
      in_node_dim: 5
      in_edge_dim: 9
      node_res_ratio: 0.01
      edge_res_ratio: 0.01
  visualize:
    max_speed_up: 5.0
    marker: o
    save_path: save/visualize/${task.dataset_model.dataset_model_name}/${name}/level_${level}/
    ylim:
    - 0.0
    - 1.0
  pruning:
    pruning_index:
    - 2.2
    - 1.6
    level: ${level}
    method: ${method}
    finetune:
      after_pruning:
        epochs: 140
        lr: 0.01
        lr_decay_milestones: 80,120
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
      after_metanetwork:
        epochs: 100
        lr: 0.01
        lr_decay_milestones: 60,90
        lr_decay_gamma: 0.1
        weight_decay: 0.0005
__recursive_: true
name: Ana
level: 0
run: visualize
method: group_sl
log: true
reproduce_index: 20
seed: 7
index: 80

[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - train dataset model size: 8
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - val dataset model size: 2
[2025-04-29 21:40:53,431][get_dataset_model_loader][INFO] - ==================================================
[2025-04-29 21:40:59,065][train][INFO] - Epoch 1/100, Val Acc=0.6257, Val Loss=1.6543, lr=0.0100
[2025-04-29 21:41:08,027][train][INFO] - Epoch 2/100, Val Acc=0.6428, Val Loss=1.5324, lr=0.0100
[2025-04-29 21:41:16,885][train][INFO] - Epoch 3/100, Val Acc=0.6496, Val Loss=1.5084, lr=0.0100
[2025-04-29 21:41:25,890][train][INFO] - Epoch 4/100, Val Acc=0.6656, Val Loss=1.4503, lr=0.0100
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[2025-04-29 21:41:34,452][train][INFO] - Before training : Train Acc=0.0100  Val Acc=0.0100
[2025-04-29 21:41:35,197][train][INFO] - Epoch 5/100, Val Acc=0.6521, Val Loss=1.5174, lr=0.0100
[2025-04-29 21:41:44,066][train][INFO] - Epoch 1/100, Val Acc=0.6369, Val Loss=1.5627, lr=0.0100
[2025-04-29 21:41:44,412][train][INFO] - Epoch 6/100, Val Acc=0.6654, Val Loss=1.5012, lr=0.0100
[2025-04-29 21:41:53,151][train][INFO] - Epoch 2/100, Val Acc=0.6300, Val Loss=1.5685, lr=0.0100
[2025-04-29 21:41:53,576][train][INFO] - Epoch 7/100, Val Acc=0.6622, Val Loss=1.4976, lr=0.0100
[2025-04-29 21:42:02,386][train][INFO] - Epoch 8/100, Val Acc=0.6701, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:42:02,554][train][INFO] - Epoch 3/100, Val Acc=0.6416, Val Loss=1.5501, lr=0.0100
[2025-04-29 21:42:11,564][train][INFO] - Epoch 9/100, Val Acc=0.6665, Val Loss=1.4876, lr=0.0100
[2025-04-29 21:42:11,822][train][INFO] - Epoch 4/100, Val Acc=0.6620, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:42:20,752][train][INFO] - Epoch 10/100, Val Acc=0.6711, Val Loss=1.4776, lr=0.0100
[2025-04-29 21:42:21,144][train][INFO] - Epoch 5/100, Val Acc=0.6422, Val Loss=1.5505, lr=0.0100
[2025-04-29 21:42:29,739][train][INFO] - Epoch 11/100, Val Acc=0.6648, Val Loss=1.5057, lr=0.0100
[2025-04-29 21:42:30,670][train][INFO] - Epoch 6/100, Val Acc=0.6635, Val Loss=1.4302, lr=0.0100
[2025-04-29 21:42:38,897][train][INFO] - Epoch 12/100, Val Acc=0.6631, Val Loss=1.5293, lr=0.0100
[2025-04-29 21:42:40,063][train][INFO] - Epoch 7/100, Val Acc=0.6482, Val Loss=1.5347, lr=0.0100
[2025-04-29 21:42:48,128][train][INFO] - Epoch 13/100, Val Acc=0.6671, Val Loss=1.4912, lr=0.0100
[2025-04-29 21:42:49,571][train][INFO] - Epoch 8/100, Val Acc=0.6711, Val Loss=1.4325, lr=0.0100
[2025-04-29 21:42:57,114][train][INFO] - Epoch 14/100, Val Acc=0.6543, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:42:58,797][train][INFO] - Epoch 9/100, Val Acc=0.6535, Val Loss=1.5438, lr=0.0100
[2025-04-29 21:43:05,637][train][INFO] - Epoch 15/100, Val Acc=0.6600, Val Loss=1.5129, lr=0.0100
[2025-04-29 21:43:07,825][train][INFO] - Epoch 10/100, Val Acc=0.6637, Val Loss=1.4938, lr=0.0100
[2025-04-29 21:43:14,509][train][INFO] - Epoch 16/100, Val Acc=0.6548, Val Loss=1.5180, lr=0.0100
[2025-04-29 21:43:17,141][train][INFO] - Epoch 11/100, Val Acc=0.6624, Val Loss=1.4939, lr=0.0100
[2025-04-29 21:43:23,482][train][INFO] - Epoch 17/100, Val Acc=0.6656, Val Loss=1.5355, lr=0.0100
[2025-04-29 21:43:26,650][train][INFO] - Epoch 12/100, Val Acc=0.6768, Val Loss=1.4102, lr=0.0100
[2025-04-29 21:43:32,503][train][INFO] - Epoch 18/100, Val Acc=0.6606, Val Loss=1.5428, lr=0.0100
[2025-04-29 21:43:36,129][train][INFO] - Epoch 13/100, Val Acc=0.6710, Val Loss=1.4696, lr=0.0100
[2025-04-29 21:43:41,500][train][INFO] - Epoch 19/100, Val Acc=0.6796, Val Loss=1.4513, lr=0.0100
[2025-04-29 21:43:45,401][train][INFO] - Epoch 14/100, Val Acc=0.6739, Val Loss=1.4676, lr=0.0100
[2025-04-29 21:43:50,499][train][INFO] - Epoch 20/100, Val Acc=0.6700, Val Loss=1.5303, lr=0.0100
[2025-04-29 21:43:54,513][train][INFO] - Epoch 15/100, Val Acc=0.6568, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:43:59,352][train][INFO] - Epoch 21/100, Val Acc=0.6711, Val Loss=1.4985, lr=0.0100
[2025-04-29 21:44:04,005][train][INFO] - Epoch 16/100, Val Acc=0.6543, Val Loss=1.5705, lr=0.0100
[2025-04-29 21:44:08,305][train][INFO] - Epoch 22/100, Val Acc=0.6486, Val Loss=1.5823, lr=0.0100
[2025-04-29 21:44:13,200][train][INFO] - Epoch 17/100, Val Acc=0.6529, Val Loss=1.6048, lr=0.0100
[2025-04-29 21:44:17,314][train][INFO] - Epoch 23/100, Val Acc=0.6618, Val Loss=1.5304, lr=0.0100
[2025-04-29 21:44:22,658][train][INFO] - Epoch 18/100, Val Acc=0.6823, Val Loss=1.4386, lr=0.0100
[2025-04-29 21:44:26,595][train][INFO] - Epoch 24/100, Val Acc=0.6651, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:44:32,118][train][INFO] - Epoch 19/100, Val Acc=0.6751, Val Loss=1.4674, lr=0.0100
[2025-04-29 21:44:35,312][train][INFO] - Epoch 25/100, Val Acc=0.6714, Val Loss=1.5076, lr=0.0100
[2025-04-29 21:44:41,401][train][INFO] - Epoch 20/100, Val Acc=0.6716, Val Loss=1.4960, lr=0.0100
[2025-04-29 21:44:44,435][train][INFO] - Epoch 26/100, Val Acc=0.6693, Val Loss=1.4964, lr=0.0100
[2025-04-29 21:44:50,722][train][INFO] - Epoch 21/100, Val Acc=0.6706, Val Loss=1.5384, lr=0.0100
[2025-04-29 21:44:53,423][train][INFO] - Epoch 27/100, Val Acc=0.6747, Val Loss=1.4802, lr=0.0100
[2025-04-29 21:44:59,699][train][INFO] - Epoch 22/100, Val Acc=0.6757, Val Loss=1.4804, lr=0.0100
[2025-04-29 21:45:02,423][train][INFO] - Epoch 28/100, Val Acc=0.6645, Val Loss=1.5490, lr=0.0100
[2025-04-29 21:45:08,977][train][INFO] - Epoch 23/100, Val Acc=0.6674, Val Loss=1.4937, lr=0.0100
[2025-04-29 21:45:11,718][train][INFO] - Epoch 29/100, Val Acc=0.6800, Val Loss=1.4548, lr=0.0100
[2025-04-29 21:45:18,377][train][INFO] - Epoch 24/100, Val Acc=0.6720, Val Loss=1.5217, lr=0.0100
[2025-04-29 21:45:21,984][train][INFO] - Epoch 30/100, Val Acc=0.6764, Val Loss=1.5024, lr=0.0100
[2025-04-29 21:45:27,498][train][INFO] - Epoch 25/100, Val Acc=0.6731, Val Loss=1.5116, lr=0.0100
[2025-04-29 21:45:36,367][train][INFO] - Epoch 31/100, Val Acc=0.6687, Val Loss=1.5228, lr=0.0100
[2025-04-29 21:45:36,565][train][INFO] - Epoch 26/100, Val Acc=0.6663, Val Loss=1.5383, lr=0.0100
[2025-04-29 21:45:45,666][train][INFO] - Epoch 27/100, Val Acc=0.6596, Val Loss=1.6001, lr=0.0100
[2025-04-29 21:45:50,939][train][INFO] - Epoch 32/100, Val Acc=0.6559, Val Loss=1.6182, lr=0.0100
[2025-04-29 21:45:54,779][train][INFO] - Epoch 28/100, Val Acc=0.6818, Val Loss=1.4463, lr=0.0100
[2025-04-29 21:46:04,196][train][INFO] - Epoch 29/100, Val Acc=0.6621, Val Loss=1.5992, lr=0.0100
[2025-04-29 21:46:05,262][train][INFO] - Epoch 33/100, Val Acc=0.6615, Val Loss=1.5968, lr=0.0100
[2025-04-29 21:46:13,400][train][INFO] - Epoch 30/100, Val Acc=0.6728, Val Loss=1.5461, lr=0.0100
[2025-04-29 21:46:19,443][train][INFO] - Epoch 34/100, Val Acc=0.6671, Val Loss=1.5877, lr=0.0100
[2025-04-29 21:46:22,452][train][INFO] - Epoch 31/100, Val Acc=0.6721, Val Loss=1.5289, lr=0.0100
[2025-04-29 21:46:31,571][train][INFO] - Epoch 32/100, Val Acc=0.6674, Val Loss=1.5620, lr=0.0100
[2025-04-29 21:46:33,794][train][INFO] - Epoch 35/100, Val Acc=0.6700, Val Loss=1.5275, lr=0.0100
[2025-04-29 21:46:40,841][train][INFO] - Epoch 33/100, Val Acc=0.6763, Val Loss=1.4837, lr=0.0100
[2025-04-29 21:46:48,024][train][INFO] - Epoch 36/100, Val Acc=0.6624, Val Loss=1.5998, lr=0.0100
[2025-04-29 21:46:49,868][train][INFO] - Epoch 34/100, Val Acc=0.6692, Val Loss=1.5875, lr=0.0100
[2025-04-29 21:46:58,977][train][INFO] - Epoch 35/100, Val Acc=0.6677, Val Loss=1.5485, lr=0.0100
[2025-04-29 21:47:02,140][train][INFO] - Epoch 37/100, Val Acc=0.6816, Val Loss=1.4639, lr=0.0100
[2025-04-29 21:47:08,240][train][INFO] - Epoch 36/100, Val Acc=0.6677, Val Loss=1.5615, lr=0.0100
[2025-04-29 21:47:16,411][train][INFO] - Epoch 38/100, Val Acc=0.6778, Val Loss=1.5033, lr=0.0100
[2025-04-29 21:47:17,232][train][INFO] - Epoch 37/100, Val Acc=0.6747, Val Loss=1.5414, lr=0.0100
[2025-04-29 21:47:26,377][train][INFO] - Epoch 38/100, Val Acc=0.6708, Val Loss=1.5313, lr=0.0100
[2025-04-29 21:47:30,910][train][INFO] - Epoch 39/100, Val Acc=0.6669, Val Loss=1.5918, lr=0.0100
[2025-04-29 21:47:35,408][train][INFO] - Epoch 39/100, Val Acc=0.6698, Val Loss=1.5529, lr=0.0100
[2025-04-29 21:47:44,495][train][INFO] - Epoch 40/100, Val Acc=0.6711, Val Loss=1.5507, lr=0.0100
[2025-04-29 21:47:45,491][train][INFO] - Epoch 40/100, Val Acc=0.6797, Val Loss=1.4993, lr=0.0100
[2025-04-29 21:47:53,749][train][INFO] - Epoch 41/100, Val Acc=0.6734, Val Loss=1.5220, lr=0.0100
[2025-04-29 21:47:59,609][train][INFO] - Epoch 41/100, Val Acc=0.6657, Val Loss=1.5604, lr=0.0100
[2025-04-29 21:48:02,823][train][INFO] - Epoch 42/100, Val Acc=0.6822, Val Loss=1.4934, lr=0.0100
[2025-04-29 21:48:12,209][train][INFO] - Epoch 43/100, Val Acc=0.6812, Val Loss=1.5135, lr=0.0100
[2025-04-29 21:48:13,873][train][INFO] - Epoch 42/100, Val Acc=0.6679, Val Loss=1.5395, lr=0.0100
[2025-04-29 21:48:21,452][train][INFO] - Epoch 44/100, Val Acc=0.6608, Val Loss=1.6318, lr=0.0100
[2025-04-29 21:48:28,061][train][INFO] - Epoch 43/100, Val Acc=0.6785, Val Loss=1.5146, lr=0.0100
[2025-04-29 21:48:30,585][train][INFO] - Epoch 45/100, Val Acc=0.6687, Val Loss=1.5555, lr=0.0100
[2025-04-29 21:48:39,776][train][INFO] - Epoch 46/100, Val Acc=0.6768, Val Loss=1.5056, lr=0.0100
[2025-04-29 21:48:42,382][train][INFO] - Epoch 44/100, Val Acc=0.6695, Val Loss=1.5718, lr=0.0100
[2025-04-29 21:48:48,954][train][INFO] - Epoch 47/100, Val Acc=0.6723, Val Loss=1.5183, lr=0.0100
[2025-04-29 21:48:56,599][train][INFO] - Epoch 45/100, Val Acc=0.6679, Val Loss=1.5633, lr=0.0100
[2025-04-29 21:48:58,321][train][INFO] - Epoch 48/100, Val Acc=0.6612, Val Loss=1.6375, lr=0.0100
[2025-04-29 21:49:07,490][train][INFO] - Epoch 49/100, Val Acc=0.6736, Val Loss=1.5120, lr=0.0100
[2025-04-29 21:49:10,847][train][INFO] - Epoch 46/100, Val Acc=0.6659, Val Loss=1.5629, lr=0.0100
[2025-04-29 21:49:16,617][train][INFO] - Epoch 50/100, Val Acc=0.6772, Val Loss=1.4901, lr=0.0100
[2025-04-29 21:49:25,304][train][INFO] - Epoch 47/100, Val Acc=0.6548, Val Loss=1.6385, lr=0.0100
[2025-04-29 21:49:26,124][train][INFO] - Epoch 51/100, Val Acc=0.6860, Val Loss=1.4603, lr=0.0100
[2025-04-29 21:49:35,242][train][INFO] - Epoch 52/100, Val Acc=0.6715, Val Loss=1.5797, lr=0.0100
[2025-04-29 21:49:39,833][train][INFO] - Epoch 48/100, Val Acc=0.6624, Val Loss=1.6049, lr=0.0100
[2025-04-29 21:49:44,272][train][INFO] - Epoch 53/100, Val Acc=0.6779, Val Loss=1.5066, lr=0.0100
[2025-04-29 21:49:53,524][train][INFO] - Epoch 54/100, Val Acc=0.6751, Val Loss=1.5483, lr=0.0100
[2025-04-29 21:49:54,092][train][INFO] - Epoch 49/100, Val Acc=0.6851, Val Loss=1.4923, lr=0.0100
[2025-04-29 21:50:02,931][train][INFO] - Epoch 55/100, Val Acc=0.6654, Val Loss=1.6669, lr=0.0100
[2025-04-29 21:50:08,193][train][INFO] - Epoch 50/100, Val Acc=0.6644, Val Loss=1.5961, lr=0.0100
[2025-04-29 21:50:12,154][train][INFO] - Epoch 56/100, Val Acc=0.6662, Val Loss=1.5693, lr=0.0100
[2025-04-29 21:50:21,400][train][INFO] - Epoch 57/100, Val Acc=0.6684, Val Loss=1.5478, lr=0.0100
[2025-04-29 21:50:22,470][train][INFO] - Epoch 51/100, Val Acc=0.6632, Val Loss=1.5834, lr=0.0100
[2025-04-29 21:50:30,522][train][INFO] - Epoch 58/100, Val Acc=0.6637, Val Loss=1.5977, lr=0.0100
[2025-04-29 21:50:36,634][train][INFO] - Epoch 52/100, Val Acc=0.6738, Val Loss=1.5234, lr=0.0100
[2025-04-29 21:50:39,764][train][INFO] - Epoch 59/100, Val Acc=0.6696, Val Loss=1.5741, lr=0.0100
[2025-04-29 21:50:49,192][train][INFO] - Epoch 60/100, Val Acc=0.6658, Val Loss=1.6064, lr=0.0100
[2025-04-29 21:50:50,929][train][INFO] - Epoch 53/100, Val Acc=0.6771, Val Loss=1.5226, lr=0.0100
[2025-04-29 21:50:58,358][train][INFO] - Epoch 61/100, Val Acc=0.7230, Val Loss=1.2880, lr=0.0010
[2025-04-29 21:51:05,178][train][INFO] - Epoch 54/100, Val Acc=0.6602, Val Loss=1.6317, lr=0.0100
[2025-04-29 21:51:07,630][train][INFO] - Epoch 62/100, Val Acc=0.7252, Val Loss=1.2812, lr=0.0010
[2025-04-29 21:51:16,909][train][INFO] - Epoch 63/100, Val Acc=0.7286, Val Loss=1.2853, lr=0.0010
[2025-04-29 21:51:19,590][train][INFO] - Epoch 55/100, Val Acc=0.6769, Val Loss=1.5502, lr=0.0100
[2025-04-29 21:51:26,175][train][INFO] - Epoch 64/100, Val Acc=0.7316, Val Loss=1.2868, lr=0.0010
[2025-04-29 21:51:34,240][train][INFO] - Epoch 56/100, Val Acc=0.6628, Val Loss=1.5731, lr=0.0100
[2025-04-29 21:51:35,675][train][INFO] - Epoch 65/100, Val Acc=0.7298, Val Loss=1.2904, lr=0.0010
[2025-04-29 21:51:44,878][train][INFO] - Epoch 66/100, Val Acc=0.7295, Val Loss=1.3033, lr=0.0010
[2025-04-29 21:51:48,524][train][INFO] - Epoch 57/100, Val Acc=0.6633, Val Loss=1.6350, lr=0.0100
[2025-04-29 21:51:54,179][train][INFO] - Epoch 67/100, Val Acc=0.7340, Val Loss=1.3009, lr=0.0010
[2025-04-29 21:52:02,745][train][INFO] - Epoch 58/100, Val Acc=0.6603, Val Loss=1.6075, lr=0.0100
[2025-04-29 21:52:03,420][train][INFO] - Epoch 68/100, Val Acc=0.7342, Val Loss=1.3043, lr=0.0010
[2025-04-29 21:52:12,503][train][INFO] - Epoch 69/100, Val Acc=0.7336, Val Loss=1.3058, lr=0.0010
[2025-04-29 21:52:16,927][train][INFO] - Epoch 59/100, Val Acc=0.6693, Val Loss=1.5958, lr=0.0100
[2025-04-29 21:52:21,632][train][INFO] - Epoch 70/100, Val Acc=0.7332, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:52:31,025][train][INFO] - Epoch 71/100, Val Acc=0.7343, Val Loss=1.3237, lr=0.0010
[2025-04-29 21:52:31,232][train][INFO] - Epoch 60/100, Val Acc=0.6681, Val Loss=1.5341, lr=0.0100
[2025-04-29 21:52:40,401][train][INFO] - Epoch 72/100, Val Acc=0.7343, Val Loss=1.3195, lr=0.0010
[2025-04-29 21:52:45,514][train][INFO] - Epoch 61/100, Val Acc=0.7206, Val Loss=1.2915, lr=0.0010
[2025-04-29 21:52:49,781][train][INFO] - Epoch 73/100, Val Acc=0.7360, Val Loss=1.3172, lr=0.0010
[2025-04-29 21:52:58,861][train][INFO] - Epoch 74/100, Val Acc=0.7359, Val Loss=1.3144, lr=0.0010
[2025-04-29 21:52:59,752][train][INFO] - Epoch 62/100, Val Acc=0.7243, Val Loss=1.2888, lr=0.0010
[2025-04-29 21:53:08,145][train][INFO] - Epoch 75/100, Val Acc=0.7356, Val Loss=1.3261, lr=0.0010
[2025-04-29 21:53:14,234][train][INFO] - Epoch 63/100, Val Acc=0.7244, Val Loss=1.2993, lr=0.0010
[2025-04-29 21:53:17,319][train][INFO] - Epoch 76/100, Val Acc=0.7378, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:53:26,442][train][INFO] - Epoch 77/100, Val Acc=0.7389, Val Loss=1.3124, lr=0.0010
[2025-04-29 21:53:28,773][train][INFO] - Epoch 64/100, Val Acc=0.7271, Val Loss=1.3022, lr=0.0010
[2025-04-29 21:53:35,810][train][INFO] - Epoch 78/100, Val Acc=0.7382, Val Loss=1.3103, lr=0.0010
[2025-04-29 21:53:42,992][train][INFO] - Epoch 65/100, Val Acc=0.7274, Val Loss=1.3041, lr=0.0010
[2025-04-29 21:53:45,163][train][INFO] - Epoch 79/100, Val Acc=0.7372, Val Loss=1.3201, lr=0.0010
[2025-04-29 21:53:54,433][train][INFO] - Epoch 80/100, Val Acc=0.7377, Val Loss=1.3215, lr=0.0010
[2025-04-29 21:53:57,122][train][INFO] - Epoch 66/100, Val Acc=0.7301, Val Loss=1.3166, lr=0.0010
[2025-04-29 21:54:03,397][train][INFO] - Epoch 81/100, Val Acc=0.7378, Val Loss=1.3244, lr=0.0010
[2025-04-29 21:54:11,312][train][INFO] - Epoch 67/100, Val Acc=0.7312, Val Loss=1.3091, lr=0.0010
[2025-04-29 21:54:12,604][train][INFO] - Epoch 82/100, Val Acc=0.7399, Val Loss=1.3225, lr=0.0010
[2025-04-29 21:54:21,971][train][INFO] - Epoch 83/100, Val Acc=0.7383, Val Loss=1.3155, lr=0.0010
[2025-04-29 21:54:25,661][train][INFO] - Epoch 68/100, Val Acc=0.7330, Val Loss=1.3048, lr=0.0010
[2025-04-29 21:54:31,353][train][INFO] - Epoch 84/100, Val Acc=0.7376, Val Loss=1.3248, lr=0.0010
[2025-04-29 21:54:39,857][train][INFO] - Epoch 69/100, Val Acc=0.7315, Val Loss=1.3129, lr=0.0010
[2025-04-29 21:54:40,699][train][INFO] - Epoch 85/100, Val Acc=0.7370, Val Loss=1.3245, lr=0.0010
[2025-04-29 21:54:49,791][train][INFO] - Epoch 86/100, Val Acc=0.7360, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:54:54,116][train][INFO] - Epoch 70/100, Val Acc=0.7331, Val Loss=1.3243, lr=0.0010
[2025-04-29 21:54:58,976][train][INFO] - Epoch 87/100, Val Acc=0.7366, Val Loss=1.3203, lr=0.0010
[2025-04-29 21:55:08,154][train][INFO] - Epoch 88/100, Val Acc=0.7395, Val Loss=1.3270, lr=0.0010
[2025-04-29 21:55:08,577][train][INFO] - Epoch 71/100, Val Acc=0.7304, Val Loss=1.3285, lr=0.0010
[2025-04-29 21:55:17,263][train][INFO] - Epoch 89/100, Val Acc=0.7379, Val Loss=1.3318, lr=0.0010
[2025-04-29 21:55:23,134][train][INFO] - Epoch 72/100, Val Acc=0.7312, Val Loss=1.3351, lr=0.0010
[2025-04-29 21:55:26,509][train][INFO] - Epoch 90/100, Val Acc=0.7372, Val Loss=1.3340, lr=0.0010
[2025-04-29 21:55:35,655][train][INFO] - Epoch 91/100, Val Acc=0.7373, Val Loss=1.3271, lr=0.0001
[2025-04-29 21:55:37,306][train][INFO] - Epoch 73/100, Val Acc=0.7317, Val Loss=1.3323, lr=0.0010
[2025-04-29 21:55:44,969][train][INFO] - Epoch 92/100, Val Acc=0.7370, Val Loss=1.3286, lr=0.0001
[2025-04-29 21:55:51,550][train][INFO] - Epoch 74/100, Val Acc=0.7329, Val Loss=1.3267, lr=0.0010
[2025-04-29 21:55:54,252][train][INFO] - Epoch 93/100, Val Acc=0.7380, Val Loss=1.3234, lr=0.0001
[2025-04-29 21:56:03,709][train][INFO] - Epoch 94/100, Val Acc=0.7380, Val Loss=1.3253, lr=0.0001
[2025-04-29 21:56:05,736][train][INFO] - Epoch 75/100, Val Acc=0.7322, Val Loss=1.3356, lr=0.0010
[2025-04-29 21:56:13,133][train][INFO] - Epoch 95/100, Val Acc=0.7380, Val Loss=1.3265, lr=0.0001
[2025-04-29 21:56:19,978][train][INFO] - Epoch 76/100, Val Acc=0.7327, Val Loss=1.3364, lr=0.0010
[2025-04-29 21:56:22,374][train][INFO] - Epoch 96/100, Val Acc=0.7382, Val Loss=1.3228, lr=0.0001
[2025-04-29 21:56:31,637][train][INFO] - Epoch 97/100, Val Acc=0.7374, Val Loss=1.3227, lr=0.0001
[2025-04-29 21:56:34,230][train][INFO] - Epoch 77/100, Val Acc=0.7326, Val Loss=1.3347, lr=0.0010
[2025-04-29 21:56:40,905][train][INFO] - Epoch 98/100, Val Acc=0.7373, Val Loss=1.3235, lr=0.0001
[2025-04-29 21:56:48,515][train][INFO] - Epoch 78/100, Val Acc=0.7315, Val Loss=1.3324, lr=0.0010
[2025-04-29 21:56:50,109][train][INFO] - Epoch 99/100, Val Acc=0.7371, Val Loss=1.3252, lr=0.0001
[2025-04-29 21:56:59,506][train][INFO] - Epoch 100/100, Val Acc=0.7382, Val Loss=1.3263, lr=0.0001
[2025-04-29 21:57:03,092][train][INFO] - Epoch 79/100, Val Acc=0.7353, Val Loss=1.3338, lr=0.0010
[2025-04-29 21:57:05,043][train][INFO] - After training : Train Acc=0.9985  Val Acc=0.7399
[2025-04-29 21:57:05,048][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 21:57:17,660][train][INFO] - Epoch 80/100, Val Acc=0.7349, Val Loss=1.3414, lr=0.0010
[2025-04-29 21:57:31,910][train][INFO] - Epoch 81/100, Val Acc=0.7341, Val Loss=1.3427, lr=0.0010
[2025-04-29 21:57:46,175][train][INFO] - Epoch 82/100, Val Acc=0.7350, Val Loss=1.3407, lr=0.0010
[2025-04-29 21:58:00,344][train][INFO] - Epoch 83/100, Val Acc=0.7353, Val Loss=1.3484, lr=0.0010
[2025-04-29 21:58:14,672][train][INFO] - Epoch 84/100, Val Acc=0.7349, Val Loss=1.3521, lr=0.0010
[2025-04-29 21:58:28,912][train][INFO] - Epoch 85/100, Val Acc=0.7341, Val Loss=1.3379, lr=0.0010
[2025-04-29 21:58:43,184][train][INFO] - Epoch 86/100, Val Acc=0.7362, Val Loss=1.3448, lr=0.0010
[2025-04-29 21:58:57,470][train][INFO] - Epoch 87/100, Val Acc=0.7361, Val Loss=1.3424, lr=0.0010
[2025-04-29 21:59:12,035][train][INFO] - Epoch 88/100, Val Acc=0.7351, Val Loss=1.3510, lr=0.0010
[2025-04-29 21:59:26,523][train][INFO] - Epoch 89/100, Val Acc=0.7370, Val Loss=1.3482, lr=0.0010
[2025-04-29 21:59:31,660][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 21:59:40,781][train][INFO] - Epoch 90/100, Val Acc=0.7366, Val Loss=1.3503, lr=0.0010
[2025-04-29 21:59:55,084][train][INFO] - Epoch 91/100, Val Acc=0.7368, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:00:09,277][train][INFO] - Epoch 92/100, Val Acc=0.7379, Val Loss=1.3508, lr=0.0001
[2025-04-29 22:00:23,596][train][INFO] - Epoch 93/100, Val Acc=0.7367, Val Loss=1.3444, lr=0.0001
[2025-04-29 22:00:37,848][train][INFO] - Epoch 94/100, Val Acc=0.7372, Val Loss=1.3434, lr=0.0001
[2025-04-29 22:00:52,206][train][INFO] - Epoch 95/100, Val Acc=0.7360, Val Loss=1.3468, lr=0.0001
[2025-04-29 22:01:06,806][train][INFO] - Epoch 96/100, Val Acc=0.7360, Val Loss=1.3439, lr=0.0001
[2025-04-29 22:01:21,028][train][INFO] - Epoch 97/100, Val Acc=0.7365, Val Loss=1.3457, lr=0.0001
[2025-04-29 22:01:35,385][train][INFO] - Epoch 98/100, Val Acc=0.7364, Val Loss=1.3448, lr=0.0001
[2025-04-29 22:01:49,735][train][INFO] - Epoch 99/100, Val Acc=0.7352, Val Loss=1.3470, lr=0.0001
[2025-04-29 22:01:56,143][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:01:56,637][Visualize acc speed up curve][INFO] - End visualizing
[2025-04-29 22:02:03,915][train][INFO] - Epoch 100/100, Val Acc=0.7362, Val Loss=1.3461, lr=0.0001
[2025-04-29 22:02:09,533][train][INFO] - After training : Train Acc=0.9993  Val Acc=0.7379
[2025-04-29 22:02:09,537][Visualize acc speed up curve][INFO] - Start visualizing
[2025-04-29 22:04:56,467][Visualize acc speed up curve][INFO] - Model 1/2 visualized
[2025-04-29 22:07:44,794][Visualize acc speed up curve][INFO] - Model 2/2 visualized
[2025-04-29 22:07:45,261][Visualize acc speed up curve][INFO] - End visualizing
